[
    [
        "\"\"\"This URLconf exists because Django expects ROOT_URLCONF to exist. URLs",
        "\"\"\"This URLconf exists because Django expects ROOT_URLCONF to exist."
    ],
    [
        "should be added within the test folders, and use TestCase.urls to set them.",
        "should be added within the test folders, and"
    ],
    [
        "This helps the tests remain isolated.",
        "This helps the tests remain"
    ],
    [
        "\"Django module not found, reference tests/README.rst for instructions.\"",
        "\"Django module not found, reference tests/README.rst for"
    ],
    [
        "from django.test.utils import NullTimeKeeper, TimeKeeper, get_runner",
        "from django.test.utils import NullTimeKeeper, TimeKeeper,"
    ],
    [
        "Scan the tests directory and yield the names of all test modules.",
        "Scan the tests directory and yield the names of all"
    ],
    [
        "The yielded names have either one dotted part like \"test_runner\" or, in",
        "The yielded names have either one dotted"
    ],
    [
        "the case of GIS tests, two dotted parts like \"gis_tests.gdal_tests\".",
        "the case of GIS tests, two"
    ],
    [
        "test_module = dirname + \".\" + test_module",
        "test_module = dirname +"
    ],
    [
        "\"\"\"Return the top-level module part for a test label.\"\"\"",
        "\"\"\"Return the top-level module part"
    ],
    [
        "raise RuntimeError(f\"Test label path {label} does not exist\")",
        "raise RuntimeError(f\"Test label path"
    ],
    [
        "if \"gis_tests\" in label_modules and not gis_enabled:",
        "if \"gis_tests\" in label_modules and"
    ],
    [
        "print(\"Aborting: A GIS database backend is required to run gis_tests.\")",
        "print(\"Aborting: A GIS database backend is required to"
    ],
    [
        "return module_name == label or module_name.startswith(label + \".\")",
        "return module_name == label or module_name.startswith(label"
    ],
    [
        "return [app_config.name for app_config in apps.get_app_configs()]",
        "return [app_config.name for app_config"
    ],
    [
        "\"Please define available_apps in TransactionTestCase and its subclasses.\"",
        "\"Please define available_apps in TransactionTestCase"
    ],
    [
        "Validate the comma-separated list of requested browsers.",
        "Validate the comma-separated list of requested"
    ],
    [
        "def __call__(self, parser, namespace, values, option_string=None):",
        "def __call__(self, parser, namespace,"
    ],
    [
        "raise ImproperlyConfigured(f\"Error loading selenium module: {e}\")",
        "raise ImproperlyConfigured(f\"Error loading selenium module:"
    ],
    [
        "self, \"Selenium browser specification '%s' is not valid.\" % browser",
        "self, \"Selenium browser specification '%s' is"
    ],
    [
        "msg = \"Testing against Django installed in '%s'\" % os.path.dirname(",
        "msg = \"Testing against Django installed in"
    ],
    [
        "msg += \" with up to %d processes\" % max_parallel",
        "msg += \" with up to %d processes\""
    ],
    [
        "process_setup_args = (verbosity, start_at, start_after, test_labels)",
        "process_setup_args = (verbosity, start_at, start_after,"
    ],
    [
        "if all(conn.features.can_clone_databases for conn in connections.all()):",
        "if all(conn.features.can_clone_databases for conn in"
    ],
    [
        "subprocess_args = [sys.executable, __file__, \"--settings=%s\" % options.settings]",
        "subprocess_args = [sys.executable, __file__,"
    ],
    [
        "def bisect_tests(bisection_label, options, test_labels, start_at, start_after):",
        "def bisect_tests(bisection_label, options,"
    ],
    [
        "print(\"***** Bisecting test suite: %s\" % \" \".join(test_labels))",
        "print(\"***** Bisecting test suite: %s\" % \""
    ],
    [
        "print(\"***** Pass %da: Running the first half of the test suite\" % iteration)",
        "print(\"***** Pass %da: Running the first half of"
    ],
    [
        "print(\"***** Test labels: %s\" % \" \".join(test_labels_a))",
        "print(\"***** Test labels: %s\" % \""
    ],
    [
        "print(\"***** Pass %db: Running the second half of the test suite\" % iteration)",
        "print(\"***** Pass %db: Running the second half of"
    ],
    [
        "print(\"***** Test labels: %s\" % \" \".join(test_labels_b))",
        "print(\"***** Test labels: %s\" % \""
    ],
    [
        "print(\"***** Problem found in first half. Bisecting again...\")",
        "print(\"***** Problem found in first half."
    ],
    [
        "print(\"***** Problem found in second half. Bisecting again...\")",
        "print(\"***** Problem found in"
    ],
    [
        "print(\"***** Multiple sources of failure found\")",
        "print(\"***** Multiple sources of"
    ],
    [
        "print(\"***** No source of failure found... try pair execution (--pair)\")",
        "print(\"***** No source of failure found..."
    ],
    [
        "def paired_tests(paired_test, options, test_labels, start_at, start_after):",
        "def paired_tests(paired_test, options, test_labels,"
    ],
    [
        "\"***** %d of %d: Check test pairing with %s\"",
        "\"***** %d of %d: Check test pairing with"
    ],
    [
        "failures = subprocess.call(subprocess_args + [label, paired_test])",
        "failures = subprocess.call(subprocess_args +"
    ],
    [
        "print(\"***** Found problem pair with %s\" % label)",
        "print(\"***** Found problem pair with"
    ],
    [
        "parser = argparse.ArgumentParser(description=\"Run the Django test suite.\")",
        "parser = argparse.ArgumentParser(description=\"Run the"
    ],
    [
        "help=\"Tells Django to NOT prompt the user for input of any kind.\",",
        "help=\"Tells Django to NOT prompt the user for"
    ],
    [
        "help=\"Tells Django to stop running the test suite after first failed test.\",",
        "help=\"Tells Django to stop running the"
    ],
    [
        "help=\"Tells Django to preserve the test database between runs.\",",
        "help=\"Tells Django to preserve the test database between"
    ],
    [
        "help='Python path to settings module, e.g. \"myproject.settings\". If '",
        "help='Python path to settings module,"
    ],
    [
        "\"this isn't provided, either the DJANGO_SETTINGS_MODULE \"",
        "\"this isn't provided, either the DJANGO_SETTINGS_MODULE"
    ],
    [
        "'environment variable or \"test_sqlite\" will be used.',",
        "'environment variable or \"test_sqlite\" will be"
    ],
    [
        "help=\"Bisect the test suite to discover a test that causes a test \"",
        "help=\"Bisect the test suite to discover a"
    ],
    [
        "\"failure when combined with the named test.\",",
        "\"failure when combined with the"
    ],
    [
        "help=\"Run the test suite in pairs with the named test to find problem pairs.\",",
        "help=\"Run the test suite in pairs with the named test to find problem"
    ],
    [
        "\"Shuffle the order of test cases to help check that tests are \"",
        "\"Shuffle the order of test cases to help check that tests are"
    ],
    [
        "help=\"Sort test suites and test cases in opposite order to debug \"",
        "help=\"Sort test suites and test cases"
    ],
    [
        "\"test side effects not apparent with normal execution lineup.\",",
        "\"test side effects not apparent with normal"
    ],
    [
        "help=\"A comma-separated list of browsers to run the Selenium tests against.\",",
        "help=\"A comma-separated list of browsers to run"
    ],
    [
        "help=\"Take screenshots during selenium tests to capture the user interface.\",",
        "help=\"Take screenshots during selenium tests to"
    ],
    [
        "help=\"Run selenium tests in headless mode, if the browser supports the option.\",",
        "help=\"Run selenium tests in headless mode, if the"
    ],
    [
        "help=\"A URL for a selenium hub instance to use in combination with --selenium.\",",
        "help=\"A URL for a selenium hub instance to use"
    ],
    [
        "\"The external host that can be reached by the selenium hub instance when \"",
        "\"The external host that can be reached by the selenium hub instance"
    ],
    [
        "\"running Selenium tests via Selenium Hub.\"",
        "\"running Selenium tests via Selenium"
    ],
    [
        "help=\"Turn on the SQL query logger within tests.\",",
        "help=\"Turn on the SQL query logger"
    ],
    [
        "'Run tests using up to N parallel processes. Use the value \"auto\" '",
        "'Run tests using up to N parallel processes."
    ],
    [
        "\"to run one test process for each processor core.\"",
        "\"to run one test process for"
    ],
    [
        "help=\"Run only tests with the specified tags. Can be used multiple times.\",",
        "help=\"Run only tests with the specified tags. Can"
    ],
    [
        "help=\"Do not run tests with the specified tag. Can be used multiple times.\",",
        "help=\"Do not run tests with the specified tag. Can be used"
    ],
    [
        "help=\"Run tests starting after the specified top-level module.\",",
        "help=\"Run tests starting after"
    ],
    [
        "help=\"Run tests starting at the specified top-level module.\",",
        "help=\"Run tests starting at the specified"
    ],
    [
        "\"--pdb\", action=\"store_true\", help=\"Runs the PDB debugger on error or failure.\"",
        "\"--pdb\", action=\"store_true\", help=\"Runs the PDB debugger on error or"
    ],
    [
        "help=\"Output timings, including database set up and total run time.\",",
        "help=\"Output timings, including database set up and total run"
    ],
    [
        "\"Only run test methods and classes matching test name pattern. \"",
        "\"Only run test methods and classes matching test"
    ],
    [
        "\"Same as unittest -k option. Can be used multiple times.\"",
        "\"Same as unittest -k option. Can be used multiple"
    ],
    [
        "\"--selenium-hub and --external-host require --selenium to be used.\"",
        "\"--selenium-hub and --external-host require --selenium to be"
    ],
    [
        "parser.error(\"--selenium-hub and --external-host must be used together.\")",
        "parser.error(\"--selenium-hub and --external-host must"
    ],
    [
        "parser.error(\"--screenshots require --selenium to be used.\")",
        "parser.error(\"--screenshots require --selenium"
    ],
    [
        "parser.error(\"--screenshots and --tag are mutually exclusive.\")",
        "parser.error(\"--screenshots and --tag are"
    ],
    [
        "options.modules = [os.path.normpath(labels) for labels in options.modules]",
        "options.modules = [os.path.normpath(labels) for labels in"
    ],
    [
        "\"Aborting: --start-at, --start-after, and test labels are mutually \"",
        "\"Aborting: --start-at, --start-after, and test labels are"
    ],
    [
        "\"Aborting: --%s must be a top-level module.\"",
        "\"Aborting: --%s must be a top-level"
    ],
    [
        "\"You cannot use --selenium with parallel tests on this system. \"",
        "\"You cannot use --selenium with parallel tests on"
    ],
    [
        "time_keeper = TimeKeeper() if options.timing else NullTimeKeeper()",
        "time_keeper = TimeKeeper() if options.timing else"
    ],
    [
        "from .models import Artist, Author, Book, Page",
        "from .models import Artist, Author,"
    ],
    [
        "content=\"I was once bitten by a moose.\",",
        "content=\"I was once bitten by"
    ],
    [
        "\"AuthorList is missing a QuerySet. Define AuthorList.model, \"",
        "\"AuthorList is missing a QuerySet."
    ],
    [
        "\"AuthorListGetQuerysetReturnsNone requires either a 'template_name' \"",
        "\"AuthorListGetQuerysetReturnsNone requires either a"
    ],
    [
        "\"attribute or a get_queryset() method that returns a QuerySet.\"",
        "\"attribute or a get_queryset() method that returns a"
    ],
    [
        "from .models import Artist, Author, Book, Page",
        "from .models import Artist,"
    ],
    [
        "content=\"I was once bitten by a moose.\",",
        "content=\"I was once bitten by"
    ],
    [
        "AuthorCustomDetail overrides get() and ensures that",
        "AuthorCustomDetail overrides get()"
    ],
    [
        "\"AuthorDetail is missing a QuerySet. Define AuthorDetail.model, \"",
        "\"AuthorDetail is missing a"
    ],
    [
        "from django.test import TestCase, override_settings, skipUnlessDBFeature",
        "from django.test import"
    ],
    [
        "from .models import Artist, Author, Book, BookSigning, Page",
        "from .models import Artist,"
    ],
    [
        "content=\"I was once bitten by a moose.\",",
        "content=\"I was once bitten"
    ],
    [
        "\"BookArchive is missing a QuerySet. Define BookArchive.model, \"",
        "\"BookArchive is missing a QuerySet. Define"
    ],
    [
        "\"\"\"date_list should be sorted descending in index\"\"\"",
        "\"\"\"date_list should be sorted"
    ],
    [
        "\"\"\"date_list should be sorted ascending in year view\"\"\"",
        "\"\"\"date_list should be sorted ascending in year"
    ],
    [
        "MultipleObjectMixin.get_context_data() receives the context set by",
        "MultipleObjectMixin.get_context_data() receives the context"
    ],
    [
        "BaseYearArchiveView.get_dated_items(). This behavior is implemented in",
        "BaseYearArchiveView.get_dated_items(). This behavior is"
    ],
    [
        "TypeError, \"context must be a dict rather than MagicMock.\"",
        "TypeError, \"context must be a dict"
    ],
    [
        "msg = \"A DateView must provide an implementation of get_dated_items()\"",
        "msg = \"A DateView must provide an implementation of"
    ],
    [
        "\"\"\"date_list should be sorted ascending in month view\"\"\"",
        "\"\"\"date_list should be sorted ascending"
    ],
    [
        "msg = \"Unknown week format '%T'. Choices are: %U, %V, %W\"",
        "msg = \"Unknown week format '%T'. Choices are:"
    ],
    [
        "\"ISO week directive '%V' is incompatible with the year directive \"",
        "\"ISO week directive '%V' is incompatible with the year"
    ],
    [
        "\"'%Y'. Use the ISO year '%G' instead.\"",
        "\"'%Y'. Use the ISO"
    ],
    [
        "res = self.client.get(\"/dates/books/%s/%s/allow_future/\" % (urlbit, b.id))",
        "res = self.client.get(\"/dates/books/%s/%s/allow_future/\" % (urlbit,"
    ],
    [
        "\"Generic detail view BookDetail must be called with either an \"",
        "\"Generic detail view BookDetail must be called with either"
    ],
    [
        "\"object pk or a slug in the URLconf.\"",
        "\"object pk or a"
    ],
    [
        "Custom querysets are used when provided to",
        "Custom querysets are used when provided"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import SimpleTestCase,"
    ],
    [
        "from django.views.generic.edit import CreateView, FormMixin, ModelFormMixin",
        "from django.views.generic.edit import CreateView, FormMixin,"
    ],
    [
        "\"get_form() should use provided form class.\",",
        "\"get_form() should use"
    ],
    [
        "\"get_form() should fallback to get_form_class() if none is provided.\",",
        "\"get_form() should fallback to get_form_class() if none is"
    ],
    [
        "res = self.client.post(\"/contact/\", {\"name\": \"Me\", \"message\": \"Hello\"})",
        "res = self.client.post(\"/contact/\", {\"name\": \"Me\","
    ],
    [
        "res = self.client.post(\"/late-validation/\", {\"name\": \"Me\", \"message\": \"Hello\"})",
        "res = self.client.post(\"/late-validation/\", {\"name\": \"Me\", \"message\":"
    ],
    [
        "res = self.client.post(\"/edit/artists/create/\", {\"name\": \"Rene Magritte\"})",
        "res = self.client.post(\"/edit/artists/create/\","
    ],
    [
        "\"No URL to redirect to.  Either provide a url or define a \"",
        "\"No URL to redirect to. Either provide a url or"
    ],
    [
        "\"Using ModelFormMixin (base class of MyCreateView) without the \"",
        "\"Using ModelFormMixin (base class of MyCreateView) without the"
    ],
    [
        "message = \"Specifying both 'fields' and 'form_class' is not permitted.\"",
        "message = \"Specifying both 'fields'"
    ],
    [
        "{\"name\": \"Randall Munroe (xkcd)\", \"slug\": \"randall-munroe\"},",
        "{\"name\": \"Randall Munroe (xkcd)\","
    ],
    [
        "\"/edit/artists/%d/update/\" % a.pk, {\"name\": \"Rene Magritte\"}",
        "\"/edit/artists/%d/update/\" % a.pk, {\"name\": \"Rene"
    ],
    [
        "{\"name\": \"Randall Munroe (author of xkcd)\", \"slug\": \"randall-munroe\"},",
        "{\"name\": \"Randall Munroe (author of xkcd)\", \"slug\":"
    ],
    [
        "{\"name\": \"Randall Munroe (author of xkcd)\", \"slug\": \"randall-munroe\"},",
        "{\"name\": \"Randall Munroe (author of"
    ],
    [
        "{\"name\": \"Randall Munroe (author of xkcd)\", \"slug\": \"randall-munroe\"},",
        "{\"name\": \"Randall Munroe (author of xkcd)\", \"slug\":"
    ],
    [
        "\"No URL to redirect to.  Either provide a url or define a \"",
        "\"No URL to redirect to. Either provide a"
    ],
    [
        "{\"name\": \"Randall Munroe (author of xkcd)\", \"slug\": \"randall-munroe\"},",
        "{\"name\": \"Randall Munroe (author of xkcd)\", \"slug\":"
    ],
    [
        "{\"name\": \"Randall Munroe (xkcd)\", \"slug\": \"randall-munroe\"},",
        "{\"name\": \"Randall Munroe (xkcd)\","
    ],
    [
        "msg = \"No URL to redirect to. Provide a success_url.\"",
        "msg = \"No URL to redirect"
    ],
    [
        "raise forms.ValidationError(\"You must confirm the delete.\")",
        "raise forms.ValidationError(\"You must confirm the"
    ],
    [
        "from django.contrib.auth import views as auth_views",
        "from django.contrib.auth import"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import RequestFactory, SimpleTestCase,"
    ],
    [
        "from django.views.generic import RedirectView, TemplateView, View",
        "from django.views.generic import"
    ],
    [
        "A simple view with a docstring.",
        "A simple view with a"
    ],
    [
        "return HttpResponse(\"This is a simple view\")",
        "return HttpResponse(\"This is a"
    ],
    [
        "return HttpResponse(\"This view only accepts POST\")",
        "return HttpResponse(\"This view"
    ],
    [
        "self.assertEqual(response.content, b\"This is a simple view\")",
        "self.assertEqual(response.content, b\"This is a simple"
    ],
    [
        "A view can't be accidentally instantiated before deployment",
        "A view can't be"
    ],
    [
        "msg = \"This method is available only on the class, not on instances.\"",
        "msg = \"This method is available only on"
    ],
    [
        "A view can't be accidentally instantiated before deployment",
        "A view can't be accidentally instantiated"
    ],
    [
        "The edge case of an HTTP request that spoofs an existing method name is",
        "The edge case of an HTTP request"
    ],
    [
        "Test a view which only allows GET doesn't allow other methods.",
        "Test a view which only allows GET doesn't"
    ],
    [
        "Test a view which supplies a GET method also responds correctly to HEAD.",
        "Test a view which supplies a GET method also"
    ],
    [
        "Test a view which only allows both GET and POST.",
        "Test a view which only allows both GET and"
    ],
    [
        "View arguments must be predefined on the class and can't",
        "View arguments must be predefined on the class and"
    ],
    [
        "be named like an HTTP method.",
        "be named like"
    ],
    [
        "\"The method name %s is not accepted as a keyword argument to \"",
        "\"The method name %s is not accepted"
    ],
    [
        "\"CustomizableView() received an invalid keyword 'foobar'. \"",
        "\"CustomizableView() received an invalid keyword 'foobar'."
    ],
    [
        "\"as_view only accepts arguments that are already attributes of \"",
        "\"as_view only accepts arguments that are"
    ],
    [
        "Test a view can only be called once.",
        "Test a view can only"
    ],
    [
        "The callable returned from as_view() has proper special attributes.",
        "The callable returned from as_view() has proper"
    ],
    [
        "Attributes set by decorators on the dispatch method",
        "Attributes set by decorators on"
    ],
    [
        "are also present on the closure.",
        "are also present on the"
    ],
    [
        "Views respond to HTTP OPTIONS requests with an Allow header",
        "Views respond to HTTP OPTIONS requests with"
    ],
    [
        "appropriate for the methods implemented by the view class.",
        "appropriate for the methods implemented by the view"
    ],
    [
        "A view implementing GET allows GET and HEAD.",
        "A view implementing GET allows GET"
    ],
    [
        "A view implementing GET and POST allows GET, HEAD, and POST.",
        "A view implementing GET and POST allows GET,"
    ],
    [
        "A view implementing POST allows POST.",
        "A view implementing"
    ],
    [
        "\"Assert allowed HTTP methods reported in the Allow response header\"",
        "\"Assert allowed HTTP methods reported in the"
    ],
    [
        "Test a view only has args, kwargs & request once `as_view`",
        "Test a view only has args, kwargs &"
    ],
    [
        "for attribute in (\"args\", \"kwargs\", \"request\"):",
        "for attribute in (\"args\", \"kwargs\","
    ],
    [
        "\"TestView instance has no 'request' attribute. Did you override \"",
        "\"TestView instance has no 'request' attribute. Did"
    ],
    [
        "\"setup() and forget to call super()?\"",
        "\"setup() and forget"
    ],
    [
        "It should be possible to use the view by directly instantiating it",
        "It should be possible to use the view by"
    ],
    [
        "Test a view that simply renders a template on GET",
        "Test a view that simply renders a"
    ],
    [
        "Test a TemplateView responds correctly to HEAD",
        "Test a TemplateView responds correctly"
    ],
    [
        "Test a view that renders a template on GET with the template name as",
        "Test a view that renders a template on"
    ],
    [
        "Test a completely generic view that renders a template on GET",
        "Test a completely generic view that"
    ],
    [
        "with the template name as an argument at instantiation.",
        "with the template name as"
    ],
    [
        "A template view must provide a template name.",
        "A template view must"
    ],
    [
        "\"TemplateResponseMixin requires either a definition of \"",
        "\"TemplateResponseMixin requires either a"
    ],
    [
        "\"'template_name' or an implementation of 'get_template_names()'\"",
        "\"'template_name' or an implementation of"
    ],
    [
        "A template view may provide a template engine.",
        "A template view may provide a"
    ],
    [
        "A generic template view passes kwargs as context.",
        "A generic template view passes kwargs"
    ],
    [
        "A template view can be customized to return extra context.",
        "A template view can be customized"
    ],
    [
        "A template view can be cached",
        "A template view can be"
    ],
    [
        "\"GET arguments can be included in the redirected URL\"",
        "\"GET arguments can be included"
    ],
    [
        "\"GET arguments can be URL-encoded when included in the redirected URL\"",
        "\"GET arguments can be URL-encoded when"
    ],
    [
        "\"Named pattern parameter should reverse to the matching pattern\"",
        "\"Named pattern parameter should reverse"
    ],
    [
        "It should be possible to use the view without going through .as_view()",
        "It should be possible to use the view"
    ],
    [
        "queryset = [{\"name\": \"Lennon\"}, {\"name\": \"Ono\"}]",
        "queryset = [{\"name\": \"Lennon\"},"
    ],
    [
        "We want to makes sure that if you use a template mixin, but forget the",
        "We want to makes sure that if you use"
    ],
    [
        "template, it still tells you it's ImproperlyConfigured instead of",
        "template, it still tells you"
    ],
    [
        "\"of 'template_name', 'template_name_field', or 'model'; \"",
        "\"of 'template_name', 'template_name_field', or 'model';"
    ],
    [
        "from .forms import AuthorForm, ConfirmDeleteForm, ContactForm",
        "from .forms import"
    ],
    [
        "from .models import Artist, Author, Book, BookSigning, Page",
        "from .models import Artist, Author, Book,"
    ],
    [
        "context = {\"custom_\" + self.get_context_object_name(author): author}",
        "context = {\"custom_\" + self.get_context_object_name(author):"
    ],
    [
        "\"\"\"A ListView that doesn't use a model.\"\"\"",
        "\"\"\"A ListView that doesn't use a"
    ],
    [
        "queryset = [{\"first\": \"John\", \"last\": \"Lennon\"}, {\"first\": \"Yoko\", \"last\": \"Ono\"}]",
        "queryset = [{\"first\": \"John\", \"last\": \"Lennon\"},"
    ],
    [
        "Strings can be used instead of model literals to set up \"lazy\" relations.",
        "Strings can be used instead of model literals to set up \"lazy\""
    ],
    [
        "from datetime import date, datetime, time, timedelta",
        "from datetime import date, datetime,"
    ],
    [
        "self.assertTrue(all(obj.selected == \"not selected\" for obj in objects))",
        "self.assertTrue(all(obj.selected == \"not selected\" for obj"
    ],
    [
        "self.assertTrue(all(obj.selected == \"selected\" for obj in objects))",
        "self.assertTrue(all(obj.selected == \"selected\" for obj in"
    ],
    [
        "FieldError, \"Joined field references are not permitted in this query\"",
        "FieldError, \"Joined field references are not permitted in"
    ],
    [
        "FieldError, \"Joined field references are not permitted in this query\"",
        "FieldError, \"Joined field references are not"
    ],
    [
        "[(\"Jane Doe\", \"G\"), (\"James Smith\", \"R\"), (\"Jack Black\", \"P\")],",
        "[(\"Jane Doe\", \"G\"), (\"James Smith\", \"R\"),"
    ],
    [
        "msg = \"Positional arguments must all be When objects.\"",
        "msg = \"Positional arguments must"
    ],
    [
        "\"When() supports a Q object, a boolean expression, or lookups as \"",
        "\"When() supports a Q object, a boolean expression, or"
    ],
    [
        "msg = \"An empty Q() can't be used as a When() condition.\"",
        "msg = \"An empty Q() can't"
    ],
    [
        "from .models import Article, Author, Book, Category, ExplicitPK, Writer",
        "from .models import Article, Author, Book, Category,"
    ],
    [
        "\"['Select a valid choice. That choice is not one of the available \"",
        "\"['Select a valid choice. That choice is not"
    ],
    [
        "\"['Select a valid choice. That choice is not one of the available \"",
        "\"['Select a valid choice. That choice is not one of the"
    ],
    [
        "msg = \"Null characters are not allowed.\"",
        "msg = \"Null characters are not"
    ],
    [
        "f.label_from_instance = lambda obj: \"category \" + str(obj)",
        "f.label_from_instance = lambda obj: \"category"
    ],
    [
        "[(\"\", \"---------\")] + choices if blank else choices,",
        "[(\"\", \"---------\")] + choices if"
    ],
    [
        "ModelChoiceField with RadioSelect widget doesn't produce unnecessary",
        "ModelChoiceField with RadioSelect widget doesn't"
    ],
    [
        "db queries when accessing its BoundField's attrs.",
        "db queries when accessing its"
    ],
    [
        "template = Template(\"{{ field.name }}{{ field }}{{ field.help_text }}\")",
        "template = Template(\"{{ field.name }}{{ field"
    ],
    [
        "[\"Select a valid choice. That choice is not one of the available choices.\"],",
        "[\"Select a valid choice. That choice is not one of the available"
    ],
    [
        "Iterator defaults to ModelChoiceIterator and can be overridden with",
        "Iterator defaults to ModelChoiceIterator and"
    ],
    [
        "the iterator attribute on a ModelChoiceField subclass.",
        "the iterator attribute on a"
    ],
    [
        "self, name, value, label, selected, index, subindex=None, attrs=None",
        "self, name, value, label,"
    ],
    [
        "name, value, label, selected, index, subindex, attrs",
        "name, value, label, selected, index,"
    ],
    [
        "self, name, value, label, selected, index, subindex=None, attrs=None",
        "self, name, value, label,"
    ],
    [
        "name, value, label, selected, index, subindex, attrs",
        "name, value, label, selected, index, subindex,"
    ],
    [
        "<input type=\"checkbox\" name=\"name\" value=\"%d\" data-slug=\"test\">A test",
        "<input type=\"checkbox\" name=\"name\""
    ],
    [
        "Widgets that render multiple subwidgets shouldn't make more than one",
        "Widgets that render multiple subwidgets"
    ],
    [
        "\"{% for widget in form.checkbox %}{{ widget }}{% endfor %}\"",
        "\"{% for widget in form.checkbox"
    ],
    [
        "\"{% for widget in form.radio %}{{ widget }}{% endfor %}\"",
        "\"{% for widget in form.radio %}{{ widget"
    ],
    [
        "MODE_CHOICES = ((\"di\", \"direct\"), (\"de\", \"delayed\"))",
        "MODE_CHOICES = ((\"di\", \"direct\"),"
    ],
    [
        "return \"%s is %s\" % (self.writer, self.age)",
        "return \"%s is %s\""
    ],
    [
        "assert not been_here, \"save_form_data called more than once\"",
        "assert not been_here, \"save_form_data called more"
    ],
    [
        "return \"%s for %s\" % (self.quantity, self.price)",
        "return \"%s for %s\""
    ],
    [
        "unique_together = ((\"left\", \"middle\"), (\"middle\", \"right\"))",
        "unique_together = ((\"left\", \"middle\"), (\"middle\","
    ],
    [
        "author = models.ForeignKey(Writer, models.SET_NULL, blank=True, null=True)",
        "author = models.ForeignKey(Writer, models.SET_NULL, blank=True,"
    ],
    [
        "raise ValidationError(message={key: \"Cannot set attribute\"}, code=\"invalid\")",
        "raise ValidationError(message={key: \"Cannot"
    ],
    [
        "character = models.ForeignKey(Character, models.SET_NULL, blank=False, null=True)",
        "character = models.ForeignKey(Character,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "from .models import ImageFile, NoExtensionImageFile, OptionalImageFile",
        "from .models import"
    ],
    [
        "ValueError, \"ModelForm has no model class specified.\"",
        "ValueError, \"ModelForm has no model class"
    ],
    [
        "An argument of fields=() to fields_for_model should return an empty dictionary",
        "An argument of fields=() to fields_for_model should"
    ],
    [
        "No fields on a ModelForm should actually result in no fields.",
        "No fields on a ModelForm should actually result in"
    ],
    [
        "No fields should be set on a model instance if construct_instance",
        "No fields should be set on"
    ],
    [
        "form = modelform_factory(Person, fields=\"__all__\")({\"name\": \"John Doe\"})",
        "form = modelform_factory(Person,"
    ],
    [
        "A ModelForm with a model having ForeignKey(blank=False, null=True)",
        "A ModelForm with a"
    ],
    [
        "and the form field set to required=False should allow the field to be",
        "and the form field set to required=False should allow the field"
    ],
    [
        "A ModelForm with a model with a field set to blank=False and the form",
        "A ModelForm with a model with a"
    ],
    [
        "field set to required=False should allow the field to be unset.",
        "field set to required=False should allow the field to be"
    ],
    [
        "\"Creating a ModelForm without either the 'fields' attribute \"",
        "\"Creating a ModelForm without either"
    ],
    [
        "\"or the 'exclude' attribute is prohibited; form \"",
        "\"or the 'exclude' attribute is"
    ],
    [
        "FieldError, \"Unknown field(s) (no-field) specified for Person\"",
        "FieldError, \"Unknown field(s) (no-field) specified for"
    ],
    [
        "expected_msg = \"Unknown field(s) (nonexistent) specified for Category\"",
        "expected_msg = \"Unknown field(s) (nonexistent) specified for"
    ],
    [
        "\"CategoryForm.Meta.fields cannot be a string. Did you mean to type: \"",
        "\"CategoryForm.Meta.fields cannot be a string. Did you mean"
    ],
    [
        "\"CategoryForm.Meta.exclude cannot be a string. Did you mean to type: \"",
        "\"CategoryForm.Meta.exclude cannot be a string. Did you mean to"
    ],
    [
        "msg = \"{'quantity': ['This field cannot be null.']}\"",
        "msg = \"{'quantity': ['This field cannot be"
    ],
    [
        "\"\"\"Using 'fields' *and* 'exclude'. Not sure why you'd want to do",
        "\"\"\"Using 'fields' *and* 'exclude'. Not sure why you'd want"
    ],
    [
        "this, but uh, \"be liberal in what you accept\" and all.",
        "this, but uh, \"be liberal in what you"
    ],
    [
        "\"\"\"Don't allow more than one 'model' definition in the",
        "\"\"\"Don't allow more than one 'model' definition"
    ],
    [
        "inheritance hierarchy.  Technically, it would generate a valid",
        "inheritance hierarchy. Technically, it would generate a"
    ],
    [
        "form, but the fact that the resulting save method won't deal with",
        "form, but the fact that the resulting save method won't deal"
    ],
    [
        "multiple objects is likely to trip up people not familiar with the",
        "multiple objects is likely to trip up people"
    ],
    [
        "msg = \"ModelForm has no model class specified.\"",
        "msg = \"ModelForm has no model"
    ],
    [
        "\"\"\"Subclassing without specifying a Meta on the class will use",
        "\"\"\"Subclassing without specifying a Meta on"
    ],
    [
        "the parent's Meta (or the first parent in the MRO if there are",
        "the parent's Meta (or the first parent in the"
    ],
    [
        "\"\"\"We can also subclass the Meta inner class to change the fields",
        "\"\"\"We can also subclass the Meta inner"
    ],
    [
        "\"slug\": \"Watch out! Letters, numbers, underscores and hyphens only.\",",
        "\"slug\": \"Watch out! Letters, numbers,"
    ],
    [
        "\"Didn't you read the help text? \"",
        "\"Didn't you read the help"
    ],
    [
        "\"We said letters, numbers, underscores and hyphens only!\"",
        "\"We said letters, numbers, underscores"
    ],
    [
        "\"Watch out! Letters, numbers, underscores and hyphens only.\",",
        "\"Watch out! Letters, numbers, underscores and hyphens"
    ],
    [
        "\"Didn't you read the help text? \"",
        "\"Didn't you read the"
    ],
    [
        "\"We said letters, numbers, underscores and hyphens only!\",",
        "\"We said letters, numbers, underscores and"
    ],
    [
        "A form that replaces the model's url field with a custom one. This should",
        "A form that replaces the model's url field"
    ],
    [
        "prevent the model field's validation from being called.",
        "prevent the model field's"
    ],
    [
        "A form that replaces the model's url field with a custom one. This should",
        "A form that replaces the model's url field with a custom one. This"
    ],
    [
        "prevent the model field's validation from being called.",
        "prevent the model field's validation from being"
    ],
    [
        "form.errors[\"slug\"], [\"Product with this Slug already exists.\"]",
        "form.errors[\"slug\"], [\"Product with this Slug"
    ],
    [
        "[\"Price with this Price and Quantity already exists.\"],",
        "[\"Price with this Price"
    ],
    [
        "Forms don't validate unique_together constraints when only part of the",
        "Forms don't validate unique_together constraints when"
    ],
    [
        "constraint is included in the form's fields. This allows using",
        "constraint is included in the"
    ],
    [
        "form.save(commit=False) and then assigning the missing field(s) to the",
        "form.save(commit=False) and then assigning the missing field(s) to"
    ],
    [
        "When the same field is involved in multiple unique_together",
        "When the same field is involved in multiple"
    ],
    [
        "constraints, we need to make sure we don't remove the data for it",
        "constraints, we need to make sure we don't remove the data"
    ],
    [
        "before doing all the validation checking (not just failing after",
        "before doing all the validation checking (not just failing"
    ],
    [
        "title = \"I May Be Wrong But I Doubt It\"",
        "title = \"I May Be Wrong But"
    ],
    [
        "form = BookForm({\"title\": title, \"author\": self.writer.pk})",
        "form = BookForm({\"title\": title,"
    ],
    [
        "form = BookForm({\"title\": title, \"author\": self.writer.pk})",
        "form = BookForm({\"title\": title,"
    ],
    [
        "form.errors[\"__all__\"], [\"Book with this Title and Author already exists.\"]",
        "form.errors[\"__all__\"], [\"Book with this Title and Author"
    ],
    [
        "form.errors[\"special_id\"], [\"Book with this Special id already exists.\"]",
        "form.errors[\"special_id\"], [\"Book with this Special"
    ],
    [
        "form = BookForm({\"title\": title, \"author\": self.writer.pk})",
        "form = BookForm({\"title\":"
    ],
    [
        "form.errors[\"__all__\"], [\"Book with this Title and Author already exists.\"]",
        "form.errors[\"__all__\"], [\"Book with this Title and Author"
    ],
    [
        "form.errors[\"isbn\"], [\"Derived book with this Isbn already exists.\"]",
        "form.errors[\"isbn\"], [\"Derived book with"
    ],
    [
        "\"\"\"Test for primary_key being in the form and failing validation.\"\"\"",
        "\"\"\"Test for primary_key being in the form and"
    ],
    [
        "form = ExplicitPKForm({\"key\": \"\", \"desc\": \"\"})",
        "form = ExplicitPKForm({\"key\": \"\","
    ],
    [
        "\"\"\"Ensure keys and blank character strings are tested for uniqueness.\"\"\"",
        "\"\"\"Ensure keys and blank character strings are tested for"
    ],
    [
        "form.errors[\"key\"], [\"Explicit pk with this Key already exists.\"]",
        "form.errors[\"key\"], [\"Explicit pk with"
    ],
    [
        "[\"Explicit pk with this Key and Desc already exists.\"],",
        "[\"Explicit pk with this Key and"
    ],
    [
        "form.errors[\"desc\"], [\"Explicit pk with this Desc already exists.\"]",
        "form.errors[\"desc\"], [\"Explicit pk with this Desc"
    ],
    [
        "form.errors[\"key\"], [\"Explicit pk with this Key already exists.\"]",
        "form.errors[\"key\"], [\"Explicit pk with this Key already"
    ],
    [
        "form.errors[\"title\"], [\"Title must be unique for Posted date.\"]",
        "form.errors[\"title\"], [\"Title must be unique"
    ],
    [
        "self.assertEqual(form.errors[\"slug\"], [\"Slug must be unique for Posted year.\"])",
        "self.assertEqual(form.errors[\"slug\"], [\"Slug must be unique for Posted"
    ],
    [
        "form.errors[\"subtitle\"], [\"Subtitle must be unique for Posted month.\"]",
        "form.errors[\"subtitle\"], [\"Subtitle must be unique for"
    ],
    [
        "If the date for unique_for_* constraints is excluded from the",
        "If the date for unique_for_* constraints is excluded"
    ],
    [
        "ModelForm (in this case 'posted' has editable=False, then the",
        "ModelForm (in this case 'posted' has editable=False,"
    ],
    [
        "form.errors[\"title\"], [\"Title must be unique for Posted date.\"]",
        "form.errors[\"title\"], [\"Title must be unique for"
    ],
    [
        "self.assertEqual(form.errors[\"slug\"], [\"Slug must be unique for Posted year.\"])",
        "self.assertEqual(form.errors[\"slug\"], [\"Slug must be unique for"
    ],
    [
        "form.errors[\"subtitle\"], [\"Subtitle must be unique for Posted month.\"]",
        "form.errors[\"subtitle\"], [\"Subtitle must be unique for Posted"
    ],
    [
        "form.errors[NON_FIELD_ERRORS], [\"Price's Price and Quantity not unique.\"]",
        "form.errors[NON_FIELD_ERRORS], [\"Price's Price and Quantity"
    ],
    [
        "form.errors[\"title\"], [\"Post's Title not unique for Posted date.\"]",
        "form.errors[\"title\"], [\"Post's Title not unique for Posted"
    ],
    [
        "<li>Pub date: <input type=\"text\" name=\"pub_date\" required></li>",
        "<li>Pub date: <input type=\"text\" name=\"pub_date\""
    ],
    [
        "'<div>Name:<div class=\"helptext\">Use both first and last names.</div>'",
        "'<div>Name:<div class=\"helptext\">Use both first and last"
    ],
    [
        "{\"name\": \"Third test\", \"slug\": \"third-test\", \"url\": \"third\"}",
        "{\"name\": \"Third test\", \"slug\": \"third-test\","
    ],
    [
        "f = BaseCategoryForm({\"name\": \"\", \"slug\": \"not a slug!\", \"url\": \"foo\"})",
        "f = BaseCategoryForm({\"name\": \"\", \"slug\": \"not a"
    ],
    [
        "\"Enter a valid “slug” consisting of letters, numbers, underscores or \"",
        "\"Enter a valid “slug” consisting of letters, numbers, underscores"
    ],
    [
        "msg = \"The Category could not be created because the data didn't validate.\"",
        "msg = \"The Category could not be created because the data"
    ],
    [
        "f = BaseCategoryForm({\"name\": \"\", \"slug\": \"\", \"url\": \"foo\"})",
        "f = BaseCategoryForm({\"name\": \"\","
    ],
    [
        "'<li>Pub date: <input type=\"text\" name=\"pub_date\" required></li>'",
        "'<li>Pub date: <input type=\"text\" name=\"pub_date\""
    ],
    [
        "'<li>Pub date: <input type=\"text\" name=\"pub_date\" required></li>'",
        "'<li>Pub date: <input"
    ],
    [
        "models.BLANK_CHOICE_DASH + [(\"LION\", \"Lion\"), (\"ZEBRA\", \"Zebra\")],",
        "models.BLANK_CHOICE_DASH + [(\"LION\","
    ],
    [
        "Re-cleaning an instance that was added via a ModelForm shouldn't raise",
        "Re-cleaning an instance that was added via a ModelForm shouldn't"
    ],
    [
        "\"Select a valid choice. That choice is not one of the available \"",
        "\"Select a valid choice. That choice is not"
    ],
    [
        "f.label_from_instance = lambda obj: \"multicategory \" + str(obj)",
        "f.label_from_instance = lambda obj: \"multicategory"
    ],
    [
        "msg = \"Null characters are not allowed.\"",
        "msg = \"Null characters are not"
    ],
    [
        "Test support of show_hidden_initial by ModelMultipleChoiceField.",
        "Test support of show_hidden_initial"
    ],
    [
        "CheckboxSelectMultiple widget doesn't produce unnecessary db queries",
        "CheckboxSelectMultiple widget doesn't produce"
    ],
    [
        "template = Template(\"{{ field.name }}{{ field }}{{ field.help_text }}\")",
        "template = Template(\"{{ field.name }}{{ field"
    ],
    [
        "writer_pks = tuple(x.pk for x in writers)",
        "writer_pks = tuple(x.pk for x in"
    ],
    [
        "sorted(model_to_dict(bw, exclude=[])), [\"id\", \"name\", \"score\", \"writer_ptr\"]",
        "sorted(model_to_dict(bw, exclude=[])), [\"id\","
    ],
    [
        "form = AuthorForm({\"publication\": \"\", \"full_name\": \"John Doe\"}, instance=author)",
        "form = AuthorForm({\"publication\": \"\", \"full_name\": \"John"
    ],
    [
        "form = AuthorForm({\"publication\": \"\", \"full_name\": \"John Doe\"}, instance=author)",
        "form = AuthorForm({\"publication\": \"\","
    ],
    [
        "If the ``clean`` method on a non-required FileField receives False as",
        "If the ``clean`` method on a non-required FileField receives False"
    ],
    [
        "the data (meaning clear the field value), it returns False, regardless",
        "the data (meaning clear the field value), it"
    ],
    [
        "If the ``clean`` method on a required FileField receives False as the",
        "If the ``clean`` method on a required"
    ],
    [
        "data, it has the same effect as None: initial is returned if non-empty,",
        "data, it has the same effect as None: initial is"
    ],
    [
        "otherwise the validation catches the lack of a required value.",
        "otherwise the validation catches the"
    ],
    [
        "Integration happy-path test that a model FileField can actually be set",
        "Integration happy-path test that a model FileField can actually be"
    ],
    [
        "If the user submits a new file upload AND checks the clear checkbox,",
        "If the user submits a new file upload AND"
    ],
    [
        "they get a validation error, and the bound redisplay of the form still",
        "they get a validation error, and the bound"
    ],
    [
        "includes the current file and the clear checkbox.",
        "includes the current file and the"
    ],
    [
        "[\"Please either submit a file or check the clear checkbox, not both.\"],",
        "[\"Please either submit a file or check the"
    ],
    [
        "f = TextFileForm({\"description\": \"New Description\"}, instance=instance)",
        "f = TextFileForm({\"description\": \"New Description\"},"
    ],
    [
        "Simulate a file upload and check how many times Model.save() gets",
        "Simulate a file upload and check how many times Model.save()"
    ],
    [
        "files = {\"image\": SimpleUploadedFile(\"test.png\", img, \"image/png\")}",
        "files = {\"image\":"
    ],
    [
        "[name for _, name in form[\"path\"].field.choices], [\"---------\", \"models.py\"]",
        "[name for _, name in form[\"path\"].field.choices],"
    ],
    [
        "with open(os.path.join(os.path.dirname(__file__), \"test.png\"), \"rb\") as fp:",
        "with open(os.path.join(os.path.dirname(__file__), \"test.png\"), \"rb\") as"
    ],
    [
        "f = ImageFileForm(data={\"description\": \"Look, it changed\"}, instance=instance)",
        "f = ImageFileForm(data={\"description\": \"Look,"
    ],
    [
        "f = OptionalImageFileForm({\"description\": \"New Description\"}, instance=instance)",
        "f = OptionalImageFileForm({\"description\": \"New Description\"},"
    ],
    [
        "data={\"description\": \"And a final one\", \"path\": \"foo\"},",
        "data={\"description\": \"And a final one\", \"path\":"
    ],
    [
        "\"Ensure this value is greater than or equal to \"",
        "\"Ensure this value is greater than or equal to"
    ],
    [
        "\"Check basic URL field validation on model forms\"",
        "\"Check basic URL field validation"
    ],
    [
        "When explicitly including a non-editable field in a ModelForm, the",
        "When explicitly including a non-editable"
    ],
    [
        "\"'created' cannot be specified for Article model form as it is a \"",
        "\"'created' cannot be specified for Article model form"
    ],
    [
        "If the https:// prefix is omitted on form input, the field adds it",
        "If the https:// prefix is omitted on form"
    ],
    [
        "ModelChoiceField should respect a prefetch_related() on its queryset.",
        "ModelChoiceField should respect a prefetch_related() on its"
    ],
    [
        "return \", \".join(c.name for c in obj.colours.all())",
        "return \", \".join(c.name for c in"
    ],
    [
        "'<label for=\"id_url\">The URL:</label><input type=\"text\" name=\"url\" '",
        "'<label for=\"id_url\">The URL:</label><input type=\"text\""
    ],
    [
        "fields = (\"title\", \"date_published\", \"mode\", \"category\")",
        "fields = (\"title\", \"date_published\", \"mode\","
    ],
    [
        "raise ValidationError(\"Left and right should be equal\")",
        "raise ValidationError(\"Left and right"
    ],
    [
        "ModelForm.clean() is applied to the model instance.",
        "ModelForm.clean() is applied to the"
    ],
    [
        "data = {\"name\": \"Test\", \"slug\": \"test\", \"url\": \"/test\"}",
        "data = {\"name\": \"Test\", \"slug\": \"test\", \"url\":"
    ],
    [
        "list(type(\"NewForm\", (Mixin, ModelForm, Form), {})().fields), [\"name\"]",
        "list(type(\"NewForm\", (Mixin, ModelForm,"
    ],
    [
        "list(type(\"NewForm\", (ModelForm, Mixin, Form), {})().fields), [\"name\"]",
        "list(type(\"NewForm\", (ModelForm, Mixin,"
    ],
    [
        "list(type(\"NewForm\", (ModelForm, Form), {\"age\": None})().fields), [\"name\"]",
        "list(type(\"NewForm\", (ModelForm, Form), {\"age\": None})().fields),"
    ],
    [
        "Form fields can be removed in subclasses by setting them to None",
        "Form fields can be removed in subclasses"
    ],
    [
        "A custom field with a `queryset` attribute but no `limit_choices_to`",
        "A custom field with a `queryset` attribute but no"
    ],
    [
        "Using base forms with widgets defined in Meta should not raise errors.",
        "Using base forms with widgets defined in Meta should not"
    ],
    [
        "Form = modelform_factory(Person, fields=\"__all__\", widgets={\"name\": widget})",
        "Form = modelform_factory(Person,"
    ],
    [
        "\"Calling modelform_factory without defining 'fields' or 'exclude' \"",
        "\"Calling modelform_factory without defining 'fields' or"
    ],
    [
        "\"\"\"A custom formfield_callback is used if provided\"\"\"",
        "\"\"\"A custom formfield_callback is used if"
    ],
    [
        "callback_args, [(id_field, {}), (name_field, {\"widget\": widget})]",
        "callback_args, [(id_field, {}),"
    ],
    [
        "\"cannot be a string. Did you mean to type: ('foo',)?\"",
        "\"cannot be a string. Did you"
    ],
    [
        "new = super().__new__(cls, name, bases, attrs)",
        "new = super().__new__(cls, name,"
    ],
    [
        "Should a model do anything special with __setattr__() or descriptors which",
        "Should a model do anything special with __setattr__() or"
    ],
    [
        "A model ValidationError using the dict form should put the error",
        "A model ValidationError using the dict form should put the"
    ],
    [
        "message into the correct key of form.errors.",
        "message into the correct"
    ],
    [
        "form = form_class(data={\"title\": \"testing setattr\"}, files=None)",
        "form = form_class(data={\"title\":"
    ],
    [
        "{\"title\": [\"Cannot set attribute\", \"This field cannot be blank.\"]},",
        "{\"title\": [\"Cannot set attribute\", \"This field"
    ],
    [
        "A model ValidationError not using the dict form should put the error",
        "A model ValidationError not using the dict form"
    ],
    [
        "message into __all__ (i.e. non-field errors) on the form.",
        "message into __all__ (i.e. non-field"
    ],
    [
        "form = form_class(data={\"title\": \"testing setattr\"}, files=None)",
        "form = form_class(data={\"title\": \"testing"
    ],
    [
        "\"title\": [\"This field cannot be blank.\"],",
        "\"title\": [\"This field"
    ],
    [
        "\"\"\"Data for a ManyToManyField is a list rather than a lazy QuerySet.\"\"\"",
        "\"\"\"Data for a ManyToManyField is a list rather than a lazy"
    ],
    [
        "msg = \"The UUIDPK could not be created because the data didn't validate.\"",
        "msg = \"The UUIDPK could not be created"
    ],
    [
        "msg = \"The UUIDPK could not be changed because the data didn't validate.\"",
        "msg = \"The UUIDPK could not be changed"
    ],
    [
        "ValidationError, \"“invalid_uuid” is not a valid UUID.\"",
        "ValidationError, \"“invalid_uuid” is not"
    ],
    [
        "return self.name + \" is owned by \" + str(self.owner)",
        "return self.name + \" is owned by \" +"
    ],
    [
        "return \"%s by %s (available at %s)\" % (",
        "return \"%s by %s (available at"
    ],
    [
        "\", \".join(s.name for s in self.stores.all()),",
        "\", \".join(s.name for s in"
    ],
    [
        "return \"NKChild %s:%s\" % (self.name, self.data)",
        "return \"NKChild %s:%s\""
    ],
    [
        "return \"%s: Reference to %s [%s]\" % (",
        "return \"%s: Reference to"
    ],
    [
        "Base model with a natural_key and a manager with `get_by_natural_key`",
        "Base model with a natural_key and a manager with"
    ],
    [
        "def animal_pre_save_check(self, signal, sender, instance, **kwargs):",
        "def animal_pre_save_check(self, signal,"
    ],
    [
        "\"Count = %s (%s)\" % (instance.count, type(instance.count)),",
        "\"Count = %s (%s)\""
    ],
    [
        "\"Weight = %s (%s)\" % (instance.weight, type(instance.weight)),",
        "\"Weight = %s (%s)\""
    ],
    [
        "the serialized data for fields that have been removed",
        "the serialized data for fields"
    ],
    [
        "from the database when not ignored.",
        "from the database when not"
    ],
    [
        "the serialized data for fields that have been removed",
        "the serialized data for fields that have"
    ],
    [
        "for fields that have been removed from the model definition.",
        "for fields that have been removed"
    ],
    [
        "doesn't affect parsing of None values.",
        "doesn't affect parsing of"
    ],
    [
        "doesn't affect parsing of None values.",
        "doesn't affect parsing"
    ],
    [
        "os.path.join will throw away the initial parts of a path if it",
        "os.path.join will throw away the initial parts of a path"
    ],
    [
        "This means that if a fixture is specified as an absolute path,",
        "This means that if a fixture is specified as an absolute"
    ],
    [
        "we need to make sure we don't discover the absolute path in every",
        "we need to make sure we don't discover the absolute path in"
    ],
    [
        "Validate that error conditions are caught correctly",
        "Validate that error conditions"
    ],
    [
        "Failing serializer import raises the proper error",
        "Failing serializer import raises the"
    ],
    [
        "with self.assertRaisesMessage(ImportError, \"No module named 'unexistent'\"):",
        "with self.assertRaisesMessage(ImportError, \"No module"
    ],
    [
        "msg = \"No fixture data found for 'empty'. (File format may be invalid.)\"",
        "msg = \"No fixture data found for 'empty'. (File format"
    ],
    [
        "ascend to parent models when inheritance is used",
        "ascend to parent models when"
    ],
    [
        "used to create tables, load data, and then query over that data.",
        "used to create tables, load data, and then query"
    ],
    [
        "To compensate, we close the connection after running loaddata.",
        "To compensate, we close the connection"
    ],
    [
        "This ensures that a new connection is opened when test queries are",
        "This ensures that a new connection is opened when test queries"
    ],
    [
        "correct type by the deserializer, not as part of the database write.",
        "correct type by the deserializer, not as part"
    ],
    [
        "Dumpdata honors the default manager. Dump the current contents of",
        "Dumpdata honors the default manager. Dump the current"
    ],
    [
        "the database as a JSON fixture",
        "the database as"
    ],
    [
        "data = sorted(json.loads(data), key=lambda x: x[\"pk\"])",
        "data = sorted(json.loads(data), key=lambda x:"
    ],
    [
        "Forward references cause fixtures not to load in MySQL (InnoDB).",
        "Forward references cause fixtures not to load in MySQL"
    ],
    [
        "Data with nonexistent child key references raises error.",
        "Data with nonexistent child key references"
    ],
    [
        "when the fixtures are not in the same files or directories.",
        "when the fixtures are not in the same files or"
    ],
    [
        "Error is quickly reported when no fixtures is provided in the command",
        "Error is quickly reported when no"
    ],
    [
        "\"No database fixture specified. Please provide the path of at least one \"",
        "\"No database fixture specified. Please provide the path of at least"
    ],
    [
        "settings.FIXTURE_DIRS cannot contain duplicates in order to avoid",
        "settings.FIXTURE_DIRS cannot contain duplicates in"
    ],
    [
        "settings.FIXTURE_DIRS cannot contain a default fixtures directory",
        "settings.FIXTURE_DIRS cannot contain a default"
    ],
    [
        "for application (app/fixtures) in order to avoid repeated fixture loading.",
        "for application (app/fixtures) in order"
    ],
    [
        "\"'%s' is a default fixture directory for the '%s' app \"",
        "\"'%s' is a default fixture directory for"
    ],
    [
        "\"and cannot be listed in settings.FIXTURE_DIRS.\"",
        "\"and cannot be"
    ],
    [
        "settings.FIXTURE_DIRS cannot contain a default fixtures directory",
        "settings.FIXTURE_DIRS cannot contain a"
    ],
    [
        "for application (app/fixtures) in order to avoid repeated fixture loading.",
        "for application (app/fixtures) in order to avoid repeated fixture"
    ],
    [
        "\"'%s' is a default fixture directory for the '%s' app \"",
        "\"'%s' is a default fixture directory for"
    ],
    [
        "\"and cannot be listed in settings.FIXTURE_DIRS.\"",
        "\"and cannot be listed"
    ],
    [
        "natural keys deserialize with fk to inheriting model",
        "natural keys deserialize with fk to inheriting"
    ],
    [
        "natural keys deserialize with fk to inheriting model",
        "natural keys deserialize with"
    ],
    [
        "Natural key requirements are taken into account when serializing models.",
        "Natural key requirements are taken into account"
    ],
    [
        "{\"fields\": {\"name\": \"Neal Stephenson\"}, \"model\": \"fixtures_regress.person\"},",
        "{\"fields\": {\"name\": \"Neal Stephenson\"},"
    ],
    [
        "It doesn't matter what order you mention the models,  Store *must* be",
        "It doesn't matter what order you"
    ],
    [
        "serialized before then Person, and both must be serialized before Book.",
        "serialized before then Person, and both must be"
    ],
    [
        "Normal primary keys work on a model with natural key capabilities.",
        "Normal primary keys work on a model with natural"
    ],
    [
        "\"<Book: Cryptonomicon by Neal Stephenson (available at Amazon, \"",
        "\"<Book: Cryptonomicon by Neal Stephenson (available"
    ],
    [
        "\"<Book: Ender's Game by Orson Scott Card (available at Collins \"",
        "\"<Book: Ender's Game by Orson Scott Card (available"
    ],
    [
        "\"<Book: Permutation City by Greg Egan (available at Angus and \"",
        "\"<Book: Permutation City by Greg Egan (available"
    ],
    [
        "Natural keys with foreign keys in dependencies works in a multiple",
        "Natural keys with foreign keys in dependencies works in a"
    ],
    [
        "self.assertEqual(obj.name, \"The Lord of the Rings\")",
        "self.assertEqual(obj.name, \"The Lord of the"
    ],
    [
        "Regression test for bugs that could be caused by flawed fixes to",
        "Regression test for bugs that could be caused by flawed"
    ],
    [
        "dependencies.  The through model itself will have dependencies, though.",
        "dependencies. The through model itself will have dependencies,"
    ],
    [
        "A, B, C, AtoB, BtoC, CtoA = (",
        "A, B, C, AtoB, BtoC, CtoA ="
    ],
    [
        "[(\"fixtures_regress\", [A, B, C, AtoB, BtoC, CtoA])]",
        "[(\"fixtures_regress\", [A, B, C, AtoB, BtoC,"
    ],
    [
        "This test tests the circularity with explicit natural_key.dependencies",
        "This test tests the circularity with"
    ],
    [
        "from .models import Author, Book, Publisher, Store",
        "from .models import Author, Book,"
    ],
    [
        "name=\"The Definitive Guide to Django: Web Development Done Right\",",
        "name=\"The Definitive Guide to Django: Web"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming:"
    ],
    [
        "\"Using an aggregate in order_by() without also including it in \"",
        "\"Using an aggregate in order_by() without also"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django: Web Development"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming: Case Studies"
    ],
    [
        "b.name, \"The Definitive Guide to Django: Web Development Done Right\"",
        "b.name, \"The Definitive Guide to"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django: Web"
    ],
    [
        "qs.order_by(\"pk\"), rows, lambda r: (r.id, r.isbn, r.page_sum, r.name)",
        "qs.order_by(\"pk\"), rows, lambda r: (r.id, r.isbn,"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django:"
    ],
    [
        "lambda r: (r.id, r.isbn, r.page_sum, r.contact.name, r.name),",
        "lambda r: (r.id, r.isbn,"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming:"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming: Case"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\"",
        "\"The Definitive Guide to Django:"
    ],
    [
        "[{\"name\": \"The Definitive Guide to Django: Web Development Done Right\"}],",
        "[{\"name\": \"The Definitive Guide to"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\"",
        "\"The Definitive Guide to Django: Web"
    ],
    [
        "An annotation not included in values() before an aggregate should be",
        "An annotation not included in values() before an aggregate"
    ],
    [
        "excluded from the group by clause.",
        "excluded from the"
    ],
    [
        "An annotation included in values() before an aggregate should be",
        "An annotation included in values() before an"
    ],
    [
        "included in the group by clause.",
        "included in the group"
    ],
    [
        "Sum on a distinct() QuerySet should aggregate only the distinct items.",
        "Sum on a distinct() QuerySet should aggregate only the"
    ],
    [
        "[\"Apress\", \"Sams\", \"Prentice Hall\", \"Morgan Kaufmann\"],",
        "[\"Apress\", \"Sams\", \"Prentice Hall\", \"Morgan"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django: Web Development"
    ],
    [
        "self.assertQuerySetEqual(authors, [\"Brad Dayley\"], lambda a: a.name)",
        "self.assertQuerySetEqual(authors, [\"Brad Dayley\"],"
    ],
    [
        "publishers, [\"Apress\", \"Prentice Hall\"], lambda p: p.name",
        "publishers, [\"Apress\", \"Prentice Hall\"], lambda p:"
    ],
    [
        "books, [\"Artificial Intelligence: A Modern Approach\"], lambda b: b.name",
        "books, [\"Artificial Intelligence: A Modern Approach\"], lambda b:"
    ],
    [
        ".dates() returns a distinct set of dates when applied to a",
        ".dates() returns a distinct set of dates when applied to"
    ],
    [
        "Doing exclude() on a foreign model after annotate() doesn't crash.",
        "Doing exclude() on a foreign model after"
    ],
    [
        "Aggregation over sliced queryset works correctly.",
        "Aggregation over sliced queryset"
    ],
    [
        "Subqueries do not needlessly contain ORDER BY, SELECT FOR UPDATE or",
        "Subqueries do not needlessly contain ORDER BY, SELECT"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"fail is not an aggregate expression\"):",
        "with self.assertRaisesMessage(TypeError, \"fail is not an aggregate"
    ],
    [
        "\"Cannot infer type of '+' expression involving these types: FloatField, \"",
        "\"Cannot infer type of '+' expression involving these"
    ],
    [
        "qs = Book.objects.annotate(sums=Sum(\"rating\") + Sum(\"pages\") + Sum(\"price\"))",
        "qs = Book.objects.annotate(sums=Sum(\"rating\") +"
    ],
    [
        "sums=Sum(F(\"rating\") + F(\"pages\") + F(\"price\"), output_field=IntegerField())",
        "sums=Sum(F(\"rating\") + F(\"pages\")"
    ],
    [
        "sums=Sum(F(\"rating\") + F(\"pages\") + F(\"price\"), output_field=FloatField())",
        "sums=Sum(F(\"rating\") + F(\"pages\") + F(\"price\"),"
    ],
    [
        "sums=Sum(F(\"rating\") + F(\"pages\") + F(\"price\"), output_field=DecimalField())",
        "sums=Sum(F(\"rating\") + F(\"pages\") + F(\"price\"),"
    ],
    [
        "TypeError, \"Complex annotations require an alias\"",
        "TypeError, \"Complex annotations"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"Complex aggregates require an alias\"):",
        "with self.assertRaisesMessage(TypeError, \"Complex aggregates"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"Complex aggregates require an alias\"):",
        "with self.assertRaisesMessage(TypeError, \"Complex aggregates require"
    ],
    [
        "msg = \"Cannot compute Avg('age_agg'): 'age_agg' is an aggregate\"",
        "msg = \"Cannot compute Avg('age_agg'): 'age_agg' is an"
    ],
    [
        "FieldError, \"Cannot compute Sum('id__max'): 'id__max' is an aggregate\"",
        "FieldError, \"Cannot compute Sum('id__max'):"
    ],
    [
        "FieldError, \"Cannot compute Max('id__max'): 'id__max' is an aggregate\"",
        "FieldError, \"Cannot compute Max('id__max'): 'id__max'"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"Complex aggregates require an alias\"):",
        "with self.assertRaisesMessage(TypeError, \"Complex aggregates require"
    ],
    [
        "TypeError, \"Complex annotations require an alias\"",
        "TypeError, \"Complex annotations"
    ],
    [
        "F(\"rating\") + F(\"pages\") + F(\"price\"), output_field=IntegerField()",
        "F(\"rating\") + F(\"pages\") + F(\"price\"),"
    ],
    [
        "F(\"rating\") + F(\"pages\") + F(\"price\"), output_field=IntegerField()",
        "F(\"rating\") + F(\"pages\") + F(\"price\"),"
    ],
    [
        "F(\"rating\") + F(\"pages\") + F(\"price\"), output_field=IntegerField()",
        "F(\"rating\") + F(\"pages\") +"
    ],
    [
        "msg = \"QuerySet.aggregate() received non-expression(s): %s.\"",
        "msg = \"QuerySet.aggregate() received"
    ],
    [
        "TypeError, msg % \", \".join([str(FloatField()), \"True\"])",
        "TypeError, msg % \","
    ],
    [
        "\"\"\"Subquery annotations are excluded from the GROUP BY if they are",
        "\"\"\"Subquery annotations are excluded from the GROUP BY if they"
    ],
    [
        "Subquery annotations and external aliases are excluded from the GROUP",
        "Subquery annotations and external aliases are"
    ],
    [
        "BY if they are not selected.",
        "BY if they"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\"",
        "\"The Definitive Guide to Django:"
    ],
    [
        "Subquery annotations must be included in the GROUP BY if they use",
        "Subquery annotations must be included in the GROUP BY if"
    ],
    [
        "potentially multivalued relations (contain the LOOKUP_SEP).",
        "potentially multivalued relations"
    ],
    [
        "Subquery annotations are included in the GROUP BY if they are",
        "Subquery annotations are included in the GROUP BY if they"
    ],
    [
        "Exists annotations are included in the GROUP BY if they are",
        "Exists annotations are included in the GROUP"
    ],
    [
        "Filtering against an aggregate requires the usage of the HAVING clause.",
        "Filtering against an aggregate requires the usage"
    ],
    [
        "If such a filter is unionized to a non-aggregate one the latter will",
        "If such a filter is unionized to a non-aggregate one the"
    ],
    [
        "also need to be moved to the HAVING clause and have its grouping",
        "also need to be moved to the HAVING clause"
    ],
    [
        "columns used in the GROUP BY.",
        "columns used in the GROUP"
    ],
    [
        "When this is done with a subquery the specialized logic in charge of",
        "When this is done with a subquery"
    ],
    [
        "using outer reference columns to group should be used instead of the",
        "using outer reference columns to group should be used"
    ],
    [
        "subquery itself as the latter might return multiple rows.",
        "subquery itself as the latter might"
    ],
    [
        "\"\"\"Random() is not included in the GROUP BY when used for ordering.\"\"\"",
        "\"\"\"Random() is not included in the GROUP BY"
    ],
    [
        "msg = \"Count does not allow default.\"",
        "msg = \"Count does not allow"
    ],
    [
        "for Aggregate in [Avg, Max, Min, StdDev, Sum, Variance]:",
        "for Aggregate in [Avg, Max, Min,"
    ],
    [
        "for Aggregate in [Avg, Max, Min, StdDev, Sum, Variance]:",
        "for Aggregate in [Avg, Max, Min,"
    ],
    [
        "for Aggregate in [Avg, Max, Min, StdDev, Sum, Variance]:",
        "for Aggregate in [Avg, Max, Min,"
    ],
    [
        "for Aggregate in [Avg, Max, Min, StdDev, Sum, Variance]:",
        "for Aggregate in [Avg, Max, Min, StdDev, Sum,"
    ],
    [
        "{\"name\": \"Jonno's House of Books\", \"earliest_pubdate\": now.date()},",
        "{\"name\": \"Jonno's House of"
    ],
    [
        "crafted_alias = \"\"\"injected_name\" from \"aggregation_author\"; --\"\"\"",
        "crafted_alias = \"\"\"injected_name\""
    ],
    [
        "\"Column aliases cannot contain whitespace characters, quotation marks, \"",
        "\"Column aliases cannot contain whitespace characters,"
    ],
    [
        "funcs_with_inherited_constructors = [Avg, Max, Min, Sum]",
        "funcs_with_inherited_constructors = [Avg, Max, Min,"
    ],
    [
        "from .models import Author, Book, Publisher",
        "from .models import Author, Book,"
    ],
    [
        "name=\"The Definitive Guide to Django: Web Development Done Right\",",
        "name=\"The Definitive Guide to Django: Web"
    ],
    [
        "msg = \"Star cannot be used with filter. Please specify a field.\"",
        "msg = \"Star cannot be used"
    ],
    [
        "from .models import Comment, Tenant, User",
        "from .models import Comment,"
    ],
    [
        "msg = \"CompositePrimaryKey cannot be used as a lookup value.\"",
        "msg = \"CompositePrimaryKey cannot be used as a lookup"
    ],
    [
        "msg = \"CombinedExpression expression does not support composite primary keys.\"",
        "msg = \"CombinedExpression expression does not support composite"
    ],
    [
        "pks = [obj.pk for obj in objs]",
        "pks = [obj.pk for"
    ],
    [
        "msg = \"Cast expression does not support composite primary keys.\"",
        "msg = \"Cast expression does not support composite primary"
    ],
    [
        "msg = \"When expression does not support composite primary keys.\"",
        "msg = \"When expression does not support composite primary"
    ],
    [
        "msg = \"Case expression does not support composite primary keys.\"",
        "msg = \"Case expression does"
    ],
    [
        "\"'exact' subquery lookup of 'pk' only supports OuterRef \"",
        "\"'exact' subquery lookup of 'pk' only supports"
    ],
    [
        "msg = \"Composite field lookups only work with composite expressions.\"",
        "msg = \"Composite field lookups only"
    ],
    [
        "\"This queryset contains a reference to an outer query and may only be used \"",
        "\"This queryset contains a reference to an outer query and may only be"
    ],
    [
        "from .models import Comment, Tenant, User",
        "from .models import Comment,"
    ],
    [
        "path, final_field, targets, rest = query.names_to_path([\"id\"], User._meta)",
        "path, final_field, targets, rest ="
    ],
    [
        "path, final_field, targets, rest = query.names_to_path([\"pk\"], User._meta)",
        "path, final_field, targets, rest = query.names_to_path([\"pk\"],"
    ],
    [
        "path, final_field, targets, rest = query.names_to_path(",
        "path, final_field, targets,"
    ],
    [
        "path, final_field, targets, rest = query.names_to_path(",
        "path, final_field, targets, rest"
    ],
    [
        "path, final_field, targets, rest = query.names_to_path(",
        "path, final_field, targets, rest ="
    ],
    [
        "path, final_field, targets, rest = query.names_to_path([\"comments\"], User._meta)",
        "path, final_field, targets, rest = query.names_to_path([\"comments\"],"
    ],
    [
        "from .models import Comment, Tenant, User",
        "from .models import Comment,"
    ],
    [
        "\"Comment object can't be deleted because its pk attribute is set \"",
        "\"Comment object can't be deleted because its"
    ],
    [
        "from .models import Comment, Tenant, TimeStamped, Token, User",
        "from .models import Comment,"
    ],
    [
        "\"primary keys, or are non-concrete fields: id\"",
        "\"primary keys, or are non-concrete"
    ],
    [
        "message = \"bulk_update() cannot be used with primary key fields.\"",
        "message = \"bulk_update() cannot be"
    ],
    [
        "\"Unsaved model instance <User: User object ((None, None))> cannot be used \"",
        "\"Unsaved model instance <User: User object"
    ],
    [
        "msg = \"Composite primary key fields must be updated individually.\"",
        "msg = \"Composite primary key"
    ],
    [
        "\"Composite primary keys expressions are not allowed in this \"",
        "\"Composite primary keys expressions are not allowed"
    ],
    [
        "from .models import Post, Tenant, User",
        "from .models import Post,"
    ],
    [
        "from django.db.models import Count, Max, Q",
        "from django.db.models import Count,"
    ],
    [
        "from .models import Comment, Tenant, User",
        "from .models import Comment,"
    ],
    [
        "ValueError, \"COUNT(DISTINCT) doesn't support composite primary keys\"",
        "ValueError, \"COUNT(DISTINCT) doesn't support composite primary"
    ],
    [
        "msg = \"Max expression does not support composite primary keys.\"",
        "msg = \"Max expression does"
    ],
    [
        "from .models import Comment, Tenant, TimeStamped, User",
        "from .models import Comment, Tenant,"
    ],
    [
        "m_tuple = \"'%s' lookup of 'pk' must be a tuple or a list\"",
        "m_tuple = \"'%s' lookup of 'pk' must be a tuple or"
    ],
    [
        "\"'in' lookup of 'pk' must be a collection of tuples or lists\"",
        "\"'in' lookup of 'pk' must be a"
    ],
    [
        "msg = \"get_next/get_previous cannot be used on unsaved objects.\"",
        "msg = \"get_next/get_previous cannot be used on"
    ],
    [
        "from .models import Post, Tenant, User",
        "from .models import Post, Tenant,"
    ],
    [
        "msg = \"bulk_create() cannot be used with primary keys in update_fields.\"",
        "msg = \"bulk_create() cannot be used with primary keys in"
    ],
    [
        "from .models import Comment, Tenant, Token, User",
        "from .models import Comment, Tenant,"
    ],
    [
        "e_tenant_and_id = \"User with this Tenant and Id already exists.\"",
        "e_tenant_and_id = \"User with this Tenant and"
    ],
    [
        "e_id = \"User with this Id already exists.\"",
        "e_id = \"User with this Id"
    ],
    [
        "for kwargs, exclude, messages in test_cases:",
        "for kwargs, exclude,"
    ],
    [
        "ctx.exception.messages, (\"User with this Email already exists.\",)",
        "ctx.exception.messages, (\"User with this Email"
    ],
    [
        "from .models import Comment, Tenant, User",
        "from .models import Comment, Tenant,"
    ],
    [
        "from .models import Comment, Post, Tenant, TimeStamped, User",
        "from .models import Comment, Post, Tenant,"
    ],
    [
        "msg = \"Model instances without primary key value are unhashable\"",
        "msg = \"Model instances without primary"
    ],
    [
        "ValueError, \"'pk' must be a list or a tuple.\"",
        "ValueError, \"'pk' must be a"
    ],
    [
        "user_fields = {f.name for f in User._meta.get_fields()}",
        "user_fields = {f.name for f in"
    ],
    [
        "comment_fields = {f.name for f in Comment._meta.get_fields()}",
        "comment_fields = {f.name for f"
    ],
    [
        "Test the .in_bulk() method of composite_pk models.",
        "Test the .in_bulk() method"
    ],
    [
        "Test the .iterator() method of composite_pk models.",
        "Test the .iterator() method of composite_pk"
    ],
    [
        "fields = [\"tenant\", \"id\", \"user_id\", \"text\", \"integer\"]",
        "fields = [\"tenant\", \"id\", \"user_id\", \"text\","
    ],
    [
        "FieldError, \"Unknown field(s) (pk) specified for Comment\"",
        "FieldError, \"Unknown field(s) (pk) specified"
    ],
    [
        "ValueError, \"CompositePrimaryKey args must be unique strings.\"",
        "ValueError, \"CompositePrimaryKey args must be unique"
    ],
    [
        "expected_message = \"CompositePrimaryKey must include at least two fields.\"",
        "expected_message = \"CompositePrimaryKey must include"
    ],
    [
        "expected_message = \"CompositePrimaryKey cannot have a default.\"",
        "expected_message = \"CompositePrimaryKey cannot have a"
    ],
    [
        "expected_message = \"CompositePrimaryKey cannot have a database default.\"",
        "expected_message = \"CompositePrimaryKey cannot have"
    ],
    [
        "expected_message = \"CompositePrimaryKey cannot have a db_column.\"",
        "expected_message = \"CompositePrimaryKey cannot have"
    ],
    [
        "expected_message = \"CompositePrimaryKey cannot be editable.\"",
        "expected_message = \"CompositePrimaryKey"
    ],
    [
        "expected_message = \"CompositePrimaryKey must be a primary key.\"",
        "expected_message = \"CompositePrimaryKey must"
    ],
    [
        "expected_message = \"CompositePrimaryKey must be blank.\"",
        "expected_message = \"CompositePrimaryKey"
    ],
    [
        "\"The model cannot have more than one field with \"",
        "\"The model cannot have more than one field with"
    ],
    [
        "\"'id' cannot be included in the composite primary key.\",",
        "\"'id' cannot be included in the"
    ],
    [
        "hint=\"'id' field may not set 'null=True'.\",",
        "hint=\"'id' field may not"
    ],
    [
        "\"'foo_id' cannot be included in the composite primary key.\",",
        "\"'foo_id' cannot be included in"
    ],
    [
        "hint=\"'foo_id' and 'foo' are the same fields.\",",
        "hint=\"'foo_id' and 'foo' are the"
    ],
    [
        "\"'pk' cannot be included in the composite primary key.\",",
        "\"'pk' cannot be included in the composite"
    ],
    [
        "\"'foo_id' cannot be included in the composite primary key.\",",
        "\"'foo_id' cannot be included in"
    ],
    [
        "hint=\"'foo_id' is not a valid field.\",",
        "hint=\"'foo_id' is not a valid"
    ],
    [
        "\"'bar_id' cannot be included in the composite primary key.\",",
        "\"'bar_id' cannot be included in the composite primary"
    ],
    [
        "hint=\"'bar_id' is not a valid field.\",",
        "hint=\"'bar_id' is not"
    ],
    [
        "\"'foo' cannot be included in the composite primary key.\",",
        "\"'foo' cannot be included in"
    ],
    [
        "hint=\"'foo' field is a generated field.\",",
        "hint=\"'foo' field is a"
    ],
    [
        "\"'a' cannot be included in the composite primary key.\",",
        "\"'a' cannot be included in the composite primary"
    ],
    [
        "hint=\"'a' field is not a local field.\",",
        "hint=\"'a' field is not a local"
    ],
    [
        "from .tenant import Comment, Post, Tenant, TimeStamped, Token, User",
        "from .tenant import Comment, Post, Tenant, TimeStamped, Token,"
    ],
    [
        "def process_response(self, *args, secure=False, request=None, **kwargs):",
        "def process_response(self, *args, secure=False, request=None,"
    ],
    [
        "def process_request(self, method, *args, secure=False, **kwargs):",
        "def process_request(self, method, *args, secure=False,"
    ],
    [
        "The middleware will not override a \"Strict-Transport-Security\" header",
        "The middleware will not override"
    ],
    [
        "The \"Strict-Transport-Security\" header is not added to responses going",
        "The \"Strict-Transport-Security\" header is not"
    ],
    [
        "True, the middleware adds a \"Strict-Transport-Security\" header with the",
        "True, the middleware adds a \"Strict-Transport-Security\" header with"
    ],
    [
        "False, the middleware adds a \"Strict-Transport-Security\" header without",
        "False, the middleware adds a \"Strict-Transport-Security\""
    ],
    [
        "the \"includeSubDomains\" directive to the response.",
        "the \"includeSubDomains\" directive to"
    ],
    [
        "With SECURE_HSTS_SECONDS non-zero and SECURE_HSTS_PRELOAD True, the",
        "With SECURE_HSTS_SECONDS non-zero and"
    ],
    [
        "middleware adds a \"Strict-Transport-Security\" header with the \"preload\"",
        "middleware adds a \"Strict-Transport-Security\" header with the"
    ],
    [
        "SECURE_HSTS_PRELOAD True, the middleware adds a \"Strict-Transport-Security\"",
        "SECURE_HSTS_PRELOAD True, the middleware"
    ],
    [
        "header containing both the \"includeSubDomains\" and \"preload\" directives",
        "header containing both the"
    ],
    [
        "False, the middleware adds a \"Strict-Transport-Security\" header without",
        "False, the middleware adds a \"Strict-Transport-Security\" header"
    ],
    [
        "the \"preload\" directive to the response.",
        "the \"preload\" directive to the"
    ],
    [
        "With SECURE_CONTENT_TYPE_NOSNIFF set to True, the middleware adds",
        "With SECURE_CONTENT_TYPE_NOSNIFF set to"
    ],
    [
        "\"X-Content-Type-Options: nosniff\" header to the response.",
        "\"X-Content-Type-Options: nosniff\" header to the"
    ],
    [
        "The middleware will not override an \"X-Content-Type-Options\" header",
        "The middleware will not override"
    ],
    [
        "With SECURE_CONTENT_TYPE_NOSNIFF False, the middleware does not add an",
        "With SECURE_CONTENT_TYPE_NOSNIFF False, the middleware does"
    ],
    [
        "With SECURE_SSL_REDIRECT True, the middleware redirects any non-secure",
        "With SECURE_SSL_REDIRECT True, the middleware redirects any"
    ],
    [
        "requests to the https:// version of the same URL.",
        "requests to the https:// version"
    ],
    [
        "The middleware does not redirect secure requests.",
        "The middleware does not"
    ],
    [
        "The middleware does not redirect requests with URL path matching an",
        "The middleware does not redirect requests with URL path matching"
    ],
    [
        "The middleware redirects to SECURE_SSL_HOST if given.",
        "The middleware redirects to"
    ],
    [
        "With SECURE_SSL_REDIRECT False, the middleware does not redirect.",
        "With SECURE_SSL_REDIRECT False, the"
    ],
    [
        "With SECURE_REFERRER_POLICY set to None, the middleware does not add a",
        "With SECURE_REFERRER_POLICY set to None, the"
    ],
    [
        "With SECURE_REFERRER_POLICY set to a valid value, the middleware adds a",
        "With SECURE_REFERRER_POLICY set to a valid value, the"
    ],
    [
        "The middleware will not override a \"Referrer-Policy\" header already",
        "The middleware will not override a"
    ],
    [
        "With SECURE_CROSS_ORIGIN_OPENER_POLICY set to None, the middleware does",
        "With SECURE_CROSS_ORIGIN_OPENER_POLICY set to"
    ],
    [
        "not add a \"Cross-Origin-Opener-Policy\" header to the response.",
        "not add a \"Cross-Origin-Opener-Policy\" header to"
    ],
    [
        "With SECURE_CROSS_ORIGIN_OPENER_POLICY set to a valid value, the",
        "With SECURE_CROSS_ORIGIN_OPENER_POLICY set to a"
    ],
    [
        "middleware adds a \"Cross-Origin_Opener-Policy\" header to the response.",
        "middleware adds a \"Cross-Origin_Opener-Policy\" header"
    ],
    [
        "The middleware doesn't override a \"Cross-Origin-Opener-Policy\" header",
        "The middleware doesn't override a \"Cross-Origin-Opener-Policy\""
    ],
    [
        "path(\"\", lambda request: HttpResponse(\"root is here\")),",
        "path(\"\", lambda request: HttpResponse(\"root is"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import RequestFactory, SimpleTestCase,"
    ],
    [
        "URLs with slashes should go unmolested.",
        "URLs with slashes should"
    ],
    [
        "Matches to explicit slashless URLs should go unmolested.",
        "Matches to explicit slashless URLs"
    ],
    [
        "return HttpResponse(\"Here's the text of the web page.\")",
        "return HttpResponse(\"Here's the text of the web"
    ],
    [
        "b\"Here's the text of the web page.\",",
        "b\"Here's the text of the"
    ],
    [
        "APPEND_SLASH should not redirect to unknown resources.",
        "APPEND_SLASH should not redirect to"
    ],
    [
        "APPEND_SLASH should redirect slashless URLs to a valid pattern.",
        "APPEND_SLASH should redirect slashless URLs"
    ],
    [
        "APPEND_SLASH should preserve querystrings when redirecting.",
        "APPEND_SLASH should preserve querystrings"
    ],
    [
        "APPEND_SLASH should append slash to path when redirecting a request",
        "APPEND_SLASH should append slash to path"
    ],
    [
        "with a querystring ending with slash.",
        "with a querystring ending with"
    ],
    [
        "While in debug mode, an exception is raised with a warning",
        "While in debug mode, an exception is raised"
    ],
    [
        "when a failed attempt is made to DELETE, POST, PUT, or PATCH to an URL",
        "when a failed attempt is made to DELETE, POST,"
    ],
    [
        "which would normally be redirected to a slashed version.",
        "which would normally be redirected to"
    ],
    [
        "msg = \"maintaining %s data. Change your form to point to testserver/slash/\"",
        "msg = \"maintaining %s data. Change your form to"
    ],
    [
        "Disabling append slash functionality should leave slashless URLs alone.",
        "Disabling append slash functionality should leave slashless"
    ],
    [
        "Views marked with @no_append_slash should be left alone.",
        "Views marked with @no_append_slash should be"
    ],
    [
        "URLs which require quoting should be redirected to their slash version.",
        "URLs which require quoting should be redirected"
    ],
    [
        "Paths starting with two slashes are escaped to prevent open redirects.",
        "Paths starting with two slashes are escaped to prevent"
    ],
    [
        "If there's a URL pattern that allows paths to start with two slashes, a",
        "If there's a URL pattern that allows"
    ],
    [
        "request with path //evil.com must not redirect to //evil.com/ (appended",
        "request with path //evil.com must not redirect to"
    ],
    [
        "slash) which is a schemaless absolute URL. The browser would navigate",
        "slash) which is a schemaless absolute"
    ],
    [
        "URLs with slashes should go unmolested.",
        "URLs with slashes"
    ],
    [
        "Matches to explicit slashless URLs should go unmolested.",
        "Matches to explicit slashless URLs should go"
    ],
    [
        "APPEND_SLASH should not redirect to unknown resources.",
        "APPEND_SLASH should not redirect to unknown"
    ],
    [
        "APPEND_SLASH should redirect slashless URLs to a valid pattern.",
        "APPEND_SLASH should redirect slashless URLs to a valid"
    ],
    [
        "\"CommonMiddleware failed to return APPEND_SLASH redirect using \"",
        "\"CommonMiddleware failed to return APPEND_SLASH redirect using"
    ],
    [
        "While in debug mode, an exception is raised with a warning",
        "While in debug mode, an exception is raised with a"
    ],
    [
        "when a failed attempt is made to POST to an URL which would normally be",
        "when a failed attempt is made to POST to"
    ],
    [
        "with self.assertRaisesMessage(RuntimeError, \"end in a slash\"):",
        "with self.assertRaisesMessage(RuntimeError, \"end in a"
    ],
    [
        "Disabling append slash functionality should leave slashless URLs alone.",
        "Disabling append slash functionality should leave slashless"
    ],
    [
        "URLs which require quoting should be redirected to their slash version.",
        "URLs which require quoting should be redirected"
    ],
    [
        "\"CommonMiddleware failed to return APPEND_SLASH redirect using \"",
        "\"CommonMiddleware failed to return APPEND_SLASH redirect using"
    ],
    [
        "def is_ignorable_request(self, request, uri, domain, referer):",
        "def is_ignorable_request(self, request, uri,"
    ],
    [
        "\"\"\"Check user-agent in addition to normal checks.\"\"\"",
        "\"\"\"Check user-agent in addition to normal"
    ],
    [
        "Some bots set the referer to the current URL to avoid being blocked by",
        "Some bots set the referer to the current URL"
    ],
    [
        "ConditionalGetMiddleware shouldn't return a conditional response on an",
        "ConditionalGetMiddleware shouldn't return a conditional"
    ],
    [
        "unsafe request. A response has already been generated by the time",
        "unsafe request. A response has already been"
    ],
    [
        "ConditionalGetMiddleware shouldn't compute and return an ETag on a",
        "ConditionalGetMiddleware shouldn't compute and return an ETag on"
    ],
    [
        "HEAD request since it can't do so accurately without access to the",
        "HEAD request since it can't do so accurately"
    ],
    [
        "response body of the corresponding GET.",
        "response body of"
    ],
    [
        "Tests for the X-Frame-Options clickjacking prevention middleware.",
        "Tests for the X-Frame-Options"
    ],
    [
        "The X_FRAME_OPTIONS setting can be set to SAMEORIGIN to have the",
        "The X_FRAME_OPTIONS setting can be set to SAMEORIGIN to"
    ],
    [
        "middleware use that value for the HTTP header.",
        "middleware use that value"
    ],
    [
        "The X_FRAME_OPTIONS setting can be set to DENY to have the middleware",
        "The X_FRAME_OPTIONS setting can be set to DENY to"
    ],
    [
        "use that value for the HTTP header.",
        "use that value for the HTTP"
    ],
    [
        "If the X_FRAME_OPTIONS setting is not set then it defaults to",
        "If the X_FRAME_OPTIONS setting is not set then"
    ],
    [
        "If the X-Frame-Options header is already set then the middleware does",
        "If the X-Frame-Options header is already set then the"
    ],
    [
        "If the response has an xframe_options_exempt attribute set to False",
        "If the response has an"
    ],
    [
        "then it still sets the header, but if it's set to True then it doesn't.",
        "then it still sets the header, but if it's set"
    ],
    [
        "The XFrameOptionsMiddleware method that determines the X-Frame-Options",
        "The XFrameOptionsMiddleware method that determines"
    ],
    [
        "header value can be overridden based on something in the request or",
        "header value can be overridden based on something"
    ],
    [
        "short_string = b\"This string is too short to be worth compressing.\"",
        "short_string = b\"This string is too short"
    ],
    [
        "Compression is performed on responses with compressible content.",
        "Compression is performed on responses with compressible"
    ],
    [
        "Compression is performed on responses with streaming content.",
        "Compression is performed on responses"
    ],
    [
        "Compression is performed on responses with async streaming content.",
        "Compression is performed on responses with async"
    ],
    [
        "self.decompress(b\"\".join([chunk async for chunk in r])),",
        "self.decompress(b\"\".join([chunk async for"
    ],
    [
        "Compression is performed on responses with streaming Unicode content.",
        "Compression is performed on responses with streaming"
    ],
    [
        "Compression isn't performed on responses with short content.",
        "Compression isn't performed on responses with short"
    ],
    [
        "Compression isn't performed on responses that are already compressed.",
        "Compression isn't performed on responses that are"
    ],
    [
        "Compression isn't performed on responses with incompressible content.",
        "Compression isn't performed on responses with incompressible"
    ],
    [
        "Compression results are the same for the same content and don't",
        "Compression results are the same for the same"
    ],
    [
        "include a modification time (since that would make the results",
        "include a modification time (since"
    ],
    [
        "\"\"\"A random number of bytes is added to mitigate the BREACH attack.\"\"\"",
        "\"\"\"A random number of bytes is added to mitigate"
    ],
    [
        "\"\"\"A random number of bytes is added to mitigate the BREACH attack.\"\"\"",
        "\"\"\"A random number of bytes is added to mitigate the"
    ],
    [
        "ETags are handled properly by GZipMiddleware.",
        "ETags are handled properly"
    ],
    [
        "GZipMiddleware makes a strong ETag weak.",
        "GZipMiddleware makes a strong"
    ],
    [
        "request = self.rf.get(\"/\", headers={\"accept-encoding\": \"gzip, deflate\"})",
        "request = self.rf.get(\"/\", headers={\"accept-encoding\": \"gzip,"
    ],
    [
        "GZipMiddleware doesn't modify a weak ETag.",
        "GZipMiddleware doesn't modify a weak"
    ],
    [
        "request = self.rf.get(\"/\", headers={\"accept-encoding\": \"gzip, deflate\"})",
        "request = self.rf.get(\"/\", headers={\"accept-encoding\":"
    ],
    [
        "request = self.rf.get(\"/\", headers={\"accept-encoding\": \"gzip, deflate\"})",
        "request = self.rf.get(\"/\", headers={\"accept-encoding\":"
    ],
    [
        "from unittest import TestSuite, TextTestRunner, defaultTestLoader, mock",
        "from unittest import TestSuite, TextTestRunner,"
    ],
    [
        "msg = \"argument --parallel: 'unaccepted' is not an integer or the string 'auto'\"",
        "msg = \"argument --parallel: 'unaccepted' is not an integer or the"
    ],
    [
        "return [t.__class__.__name__ + \".\" + t._testMethodName for t in suite._tests]",
        "return [t.__class__.__name__ + \".\" + t._testMethodName for t in"
    ],
    [
        "\"One of the test labels is a path to a file: \"",
        "\"One of the test labels is a path to a file:"
    ],
    [
        "\"'test_discover_runner.py', which is not supported. Use a \"",
        "\"'test_discover_runner.py', which is not supported. Use"
    ],
    [
        "\"dotted module name or path to a directory instead.\"",
        "\"dotted module name or path to a directory"
    ],
    [
        "If the test label is empty, discovery should happen on the current",
        "If the test label is empty, discovery"
    ],
    [
        "When given a dotted path to a module, unittest discovery searches",
        "When given a dotted path to a module, unittest"
    ],
    [
        "not just the module, but also the directory containing the module.",
        "not just the module, but also the"
    ],
    [
        "This results in tests from adjacent modules being run when they",
        "This results in tests from adjacent modules being"
    ],
    [
        "should not. The discover runner avoids this behavior.",
        "should not. The discover runner avoids this"
    ],
    [
        "msg=\"TestDjangoTestCase should be the first test case\",",
        "msg=\"TestDjangoTestCase should be the first test"
    ],
    [
        "msg=\"TestZimpleTestCase should be the second test case\",",
        "msg=\"TestZimpleTestCase should be the second test"
    ],
    [
        "Tests shouldn't be discovered twice when discovering on overlapping paths.",
        "Tests shouldn't be discovered twice when"
    ],
    [
        "Reverse should reorder tests while maintaining the grouping specified",
        "Reverse should reorder tests while maintaining the"
    ],
    [
        "msg=\"Unittest test cases should be reversed.\",",
        "msg=\"Unittest test cases"
    ],
    [
        "self.assertIn(\"Including test tag(s): bar, foo.\\n\", stdout.getvalue())",
        "self.assertIn(\"Including test tag(s): bar, foo.\\n\","
    ],
    [
        "self.assertIn(\"Excluding test tag(s): bar, foo.\\n\", stdout.getvalue())",
        "self.assertIn(\"Excluding test tag(s):"
    ],
    [
        "\"\"\"Number of processes doesn't exceed the number of TestCases.\"\"\"",
        "\"\"\"Number of processes doesn't exceed the"
    ],
    [
        "Number of databases doesn't exceed the number of TestCases with",
        "Number of databases doesn't exceed the"
    ],
    [
        "Number of databases doesn't exceed the number of TestCases with",
        "Number of databases doesn't exceed the number of"
    ],
    [
        "with captured_stdout() as stdout, captured_stderr() as stderr:",
        "with captured_stdout() as stdout,"
    ],
    [
        "with captured_stdout() as stdout, captured_stderr() as stderr:",
        "with captured_stdout() as stdout, captured_stderr()"
    ],
    [
        "run_suite() logs the seed when TestRunner.run() raises an exception.",
        "run_suite() logs the seed when TestRunner.run()"
    ],
    [
        "for verbosity, level, output in cases:",
        "for verbosity, level,"
    ],
    [
        "self.assertEqual(stdout.getvalue(), f\"{msg}\\n\" if output else \"\")",
        "self.assertEqual(stdout.getvalue(), f\"{msg}\\n\" if"
    ],
    [
        "skip_msg = \"Skipping setup of unused database(s): \"",
        "skip_msg = \"Skipping setup of unused database(s):"
    ],
    [
        "self.assertEqual(databases, {alias: False for alias in connections})",
        "self.assertEqual(databases, {alias: False for"
    ],
    [
        "After pickling, this class fails unpickling with an error about incorrect",
        "After pickling, this class fails unpickling"
    ],
    [
        "End-to-end tests of the parallel test runner.",
        "End-to-end tests of the parallel test"
    ],
    [
        "These tests are only meaningful when running tests in parallel using",
        "These tests are only meaningful when"
    ],
    [
        "the --parallel option, though it doesn't hurt to run them not in",
        "the --parallel option, though it doesn't hurt"
    ],
    [
        "A dummy test for testing subTest failures.",
        "A dummy test for"
    ],
    [
        "with self.subTest(\"TypeError: cannot pickle memoryview object\"):",
        "with self.subTest(\"TypeError: cannot pickle memoryview"
    ],
    [
        "@unittest.skipUnless(tblib is not None, \"requires tblib to be installed\")",
        "@unittest.skipUnless(tblib is not None, \"requires tblib to"
    ],
    [
        "@unittest.skipUnless(tblib is not None, \"requires tblib to be installed\")",
        "@unittest.skipUnless(tblib is not None, \"requires tblib to"
    ],
    [
        "@unittest.skipUnless(tblib is not None, \"requires tblib to be installed\")",
        "@unittest.skipUnless(tblib is not None, \"requires"
    ],
    [
        "@unittest.skipUnless(tblib is not None, \"requires tblib to be installed\")",
        "@unittest.skipUnless(tblib is not None, \"requires tblib to be"
    ],
    [
        "@unittest.skipUnless(tblib is not None, \"requires tblib to be installed\")",
        "@unittest.skipUnless(tblib is not None, \"requires tblib to"
    ],
    [
        "Failing subtests are added correctly using addSubTest().",
        "Failing subtests are added correctly"
    ],
    [
        "@unittest.skipUnless(tblib is not None, \"requires tblib to be installed\")",
        "@unittest.skipUnless(tblib is not None, \"requires"
    ],
    [
        "self.assertIn(\"Traceback (most recent call last):\", tb_and_details_str)",
        "self.assertIn(\"Traceback (most recent"
    ],
    [
        "self.assertIn(\"Traceback (most recent call last):\", tb_and_details_str)",
        "self.assertIn(\"Traceback (most recent call"
    ],
    [
        "self.assertIn(\"Traceback (most recent call last):\", tb_and_details_str)",
        "self.assertIn(\"Traceback (most recent"
    ],
    [
        "actual = shuffler._hash_item(\"abc\", lambda x: x)",
        "actual = shuffler._hash_item(\"abc\","
    ],
    [
        "(lambda x: x, [\"a\", \"d\", \"b\", \"c\"]),",
        "(lambda x: x, [\"a\","
    ],
    [
        "(lambda x: x.upper(), [\"d\", \"c\", \"a\", \"b\"]),",
        "(lambda x: x.upper(), [\"d\", \"c\", \"a\","
    ],
    [
        "actual = shuffler.shuffle([\"a\", \"b\", \"c\", \"d\"], key)",
        "actual = shuffler.shuffle([\"a\", \"b\", \"c\", \"d\"],"
    ],
    [
        "actual = shuffler.shuffle(new_seq, lambda x: x)",
        "actual = shuffler.shuffle(new_seq, lambda"
    ],
    [
        "shuffler.shuffle([\"a\", \"b\", \"A\"], lambda x: x.upper())",
        "shuffler.shuffle([\"a\", \"b\", \"A\"], lambda x:"
    ],
    [
        "connection.vendor == \"sqlite\", \"Only run on sqlite so we can check output SQL.\"",
        "connection.vendor == \"sqlite\", \"Only run on sqlite so we can check output"
    ],
    [
        "from django.test import SimpleTestCase, TransactionTestCase, skipUnlessDBFeature",
        "from django.test import"
    ],
    [
        "from .models import B, Person, Through",
        "from .models import B, Person,"
    ],
    [
        "\"Test 'a' must be a test case or test suite not string (was found \"",
        "\"Test 'a' must be a test case or"
    ],
    [
        "\"\"\"Tests of the same type are made consecutive.\"\"\"",
        "\"\"\"Tests of the same type"
    ],
    [
        "ordered_sigs = [sig for sig, value in ordered]",
        "ordered_sigs = [sig for sig,"
    ],
    [
        "ordered_sigs = [sig for sig, value in ordered]",
        "ordered_sigs = [sig for sig,"
    ],
    [
        "ordered_sigs = [sig for sig, aliases in ordered]",
        "ordered_sigs = [sig for"
    ],
    [
        "Custom runners can add command line arguments. The runner is specified",
        "Custom runners can add command line arguments. The runner"
    ],
    [
        "args = [\"test\", \"--settings=test_project.settings\", \"--option_b\", \"foo\"]",
        "args = [\"test\", \"--settings=test_project.settings\", \"--option_b\","
    ],
    [
        "Custom runners can add command line arguments when the runner is specified",
        "Custom runners can add command line"
    ],
    [
        "The test suite's initialize_suite() method must always be called when",
        "The test suite's initialize_suite() method must always"
    ],
    [
        "using spawn. It cannot rely on a test runner implementation.",
        "using spawn. It cannot rely"
    ],
    [
        "all(db.connections[conn].vendor == \"sqlite\" for conn in db.connections),",
        "all(db.connections[conn].vendor == \"sqlite\" for"
    ],
    [
        "\"Global connection object shouldn't be manipulated.\"",
        "\"Global connection object shouldn't be"
    ],
    [
        "\"':memory:' value shouldn't interfere with transaction support \"",
        "\"':memory:' value shouldn't interfere with transaction support"
    ],
    [
        "for test_connection, _, _ in new_test_connections:",
        "for test_connection, _,"
    ],
    [
        "setup_databases() doesn't fail with dummy database backend.",
        "setup_databases() doesn't fail with"
    ],
    [
        "setup_databases() doesn't fail when 'default' is aliased",
        "setup_databases() doesn't fail when 'default' is"
    ],
    [
        "{\"default\": {\"NAME\": \"dummy\"}, \"aliased\": {\"NAME\": \"dummy\"}}",
        "{\"default\": {\"NAME\": \"dummy\"}, \"aliased\": {\"NAME\":"
    ],
    [
        "The default database must be the first because data migrations",
        "The default database must be the first"
    ],
    [
        "use the default alias by default.",
        "use the default alias"
    ],
    [
        "Creating the same models in different test methods receive the same PK",
        "Creating the same models in different test"
    ],
    [
        "values since the sequences are reset before each test method.",
        "values since the sequences are reset before each"
    ],
    [
        "An empty default database in settings does not raise an ImproperlyConfigured",
        "An empty default database in settings does"
    ],
    [
        "error when running a unit test that does not use a database.",
        "error when running a unit test that does"
    ],
    [
        "Teardown functions are run when run_checks() raises SystemCheckError.",
        "Teardown functions are run when run_checks()"
    ],
    [
        "SystemCheckError is surfaced when run_checks() raises SystemCheckError",
        "SystemCheckError is surfaced when"
    ],
    [
        "Exceptions on teardown are surfaced if no exceptions happen during",
        "Exceptions on teardown are surfaced if no"
    ],
    [
        "from django.contrib.admin.models import ADDITION, CHANGE, DELETION, LogEntry",
        "from django.contrib.admin.models import ADDITION, CHANGE, DELETION,"
    ],
    [
        "from .models import Article, ArticleProxy, Car, Site",
        "from .models import Article, ArticleProxy, Car,"
    ],
    [
        "LogEntry.action_time is a timestamp of the date when the entry was",
        "LogEntry.action_time is a timestamp of the"
    ],
    [
        "created. It shouldn't be updated on a subsequent save().",
        "created. It shouldn't be updated on"
    ],
    [
        "LogEntry.change_message is stored as a dumped JSON structure to be able",
        "LogEntry.change_message is stored as a dumped JSON structure to be"
    ],
    [
        "to get the message dynamically translated at display time.",
        "to get the message dynamically translated at"
    ],
    [
        "logentry.get_change_message(), \"Modification de Title et Historique.\"",
        "logentry.get_change_message(), \"Modification de Title et"
    ],
    [
        "Localized date/time inputs shouldn't affect changed form data detection.",
        "Localized date/time inputs shouldn't affect changed form data"
    ],
    [
        "All messages for changed formsets are logged in a change message.",
        "All messages for changed formsets are logged in a change"
    ],
    [
        "{\"added\": {\"object\": \"Added article\", \"name\": \"article\"}},",
        "{\"added\": {\"object\": \"Added"
    ],
    [
        "{\"deleted\": {\"object\": \"Title second article\", \"name\": \"article\"}},",
        "{\"deleted\": {\"object\": \"Title second article\", \"name\":"
    ],
    [
        "\"Changed Domain. Added article “Added article”. \"",
        "\"Changed Domain. Added article"
    ],
    [
        "\"Changed Title and not_a_form_field for article “Changed Title”. \"",
        "\"Changed Title and not_a_form_field for"
    ],
    [
        "\"Modification de Domain. Ajout de article « Added article ». \"",
        "\"Modification de Domain. Ajout de article «"
    ],
    [
        "\"Modification de Title et not_a_form_field pour l'objet \"",
        "\"Modification de Title et not_a_form_field pour l'objet"
    ],
    [
        "\"article « Changed Title ». \"",
        "\"article « Changed Title"
    ],
    [
        "\"Suppression de article « Title second article ».\",",
        "\"Suppression de article « Title second article"
    ],
    [
        "LogEntry.get_edited_object() returns the edited object of a LogEntry",
        "LogEntry.get_edited_object() returns the edited object of a"
    ],
    [
        "LogEntry.get_admin_url returns a URL to edit the entry's object or",
        "LogEntry.get_admin_url returns a URL to edit the entry's object"
    ],
    [
        "None for nonexistent (possibly deleted) models.",
        "None for nonexistent (possibly"
    ],
    [
        "If a LogEntry is missing content_type it will not display it in span",
        "If a LogEntry is missing content_type it will not"
    ],
    [
        "should_contain = \"\"\"<a href=\"%s\">%s</a>\"\"\" % (",
        "should_contain = \"\"\"<a href=\"%s\">%s</a>\"\"\""
    ],
    [
        "Log entries for proxy models should have the proxy model's contenttype",
        "Log entries for proxy models should have the proxy model's"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "A simple Article model for testing",
        "A simple Article"
    ],
    [
        "event = models.OneToOneField(Event, models.CASCADE, verbose_name=\"awesome event\")",
        "event = models.OneToOneField(Event, models.CASCADE, verbose_name=\"awesome"
    ],
    [
        "from .models import Article, ArticleProxy, Site",
        "from .models import"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import"
    ],
    [
        "from .models import Article, Car, Count, Event, EventGuide, Location, Site, Vehicle",
        "from .models import Article, Car, Count,"
    ],
    [
        "The nested collector doesn't query for DO_NOTHING objects.",
        "The nested collector doesn't query for"
    ],
    [
        "NestedObjects.collect() doesn't trip (AttributeError) on the special",
        "NestedObjects.collect() doesn't trip (AttributeError)"
    ],
    [
        "notation for relations on abstract models (related_name that contains",
        "notation for relations on abstract models (related_name that"
    ],
    [
        "field, attr, resolved_value = lookup_field(name, article, mock_admin)",
        "field, attr, resolved_value = lookup_field(name,"
    ],
    [
        "({\"a\": {\"b\": \"c\"}}, '{\"a\": {\"b\": \"c\"}}'),",
        "({\"a\": {\"b\": \"c\"}}, '{\"a\": {\"b\":"
    ],
    [
        "({\"a\": \"你好 世界\"}, '{\"a\": \"你好 世界\"}'),",
        "({\"a\": \"你好 世界\"},"
    ],
    [
        "AttributeError, \"Unable to lookup 'unknown' on Article\"",
        "AttributeError, \"Unable to lookup"
    ],
    [
        "msg = \"Unable to lookup 'site__unknown' on Article\"",
        "msg = \"Unable to lookup 'site__unknown' on"
    ],
    [
        "msg = \"Unable to lookup 'nonexistent' on Article or ArticleForm\"",
        "msg = \"Unable to lookup 'nonexistent'"
    ],
    [
        "flat_all = [\"url\", \"title\", \"content\", \"sites\"]",
        "flat_all = [\"url\", \"title\","
    ],
    [
        "fieldsets = ((None, {\"fields\": (\"url\", \"title\", (\"content\", \"sites\"))}),)",
        "fieldsets = ((None, {\"fields\": (\"url\", \"title\", (\"content\","
    ],
    [
        "fieldsets = ((None, {\"fields\": (\"url\", \"title\", [\"content\", \"sites\"])}),)",
        "fieldsets = ((None, {\"fields\": (\"url\","
    ],
    [
        "TEST_STATIC_ROOT = Path(__file__).parent / \"project\" / \"static\"",
        "TEST_STATIC_ROOT = Path(__file__).parent /"
    ],
    [
        "\"\"\"Helper class to track threads and kwargs when signals are dispatched.\"\"\"",
        "\"\"\"Helper class to track threads and kwargs when"
    ],
    [
        "get_asgi_application() returns a functioning ASGI callable.",
        "get_asgi_application() returns a functioning ASGI"
    ],
    [
        "Makes sure that FileResponse works over ASGI.",
        "Makes sure that FileResponse works"
    ],
    [
        "The request.body object should be available and readable in view",
        "The request.body object should be available and"
    ],
    [
        "code, even if the ASGIHandler cancels processing part way through.",
        "code, even if the ASGIHandler cancels processing part way"
    ],
    [
        "await communicator.send_input({\"type\": \"http.request\", \"body\": b\"Body data!\"})",
        "await communicator.send_input({\"type\": \"http.request\", \"body\":"
    ],
    [
        "await communicator.send_input({\"type\": \"http.request\", \"body\": b\"some body\"})",
        "await communicator.send_input({\"type\": \"http.request\","
    ],
    [
        "await communicator.send_input({\"type\": \"http.request\", \"body\": b\"some body\"})",
        "await communicator.send_input({\"type\": \"http.request\","
    ],
    [
        "msg = \"Invalid ASGI message after request body: http.not_a_real_message\"",
        "msg = \"Invalid ASGI message after"
    ],
    [
        "await communicator.send_input({\"type\": \"http.request\", \"body\": b\"some body\"})",
        "await communicator.send_input({\"type\": \"http.request\", \"body\":"
    ],
    [
        "msg = \"Django can only handle ASGI/HTTP connections, not other.\"",
        "msg = \"Django can only handle ASGI/HTTP connections, not"
    ],
    [
        "from django.http import FileResponse, HttpResponse, StreamingHttpResponse",
        "from django.http import FileResponse, HttpResponse,"
    ],
    [
        "\"From %s\" % request.META.get(\"HTTP_REFERER\") or \"\",",
        "\"From %s\" % request.META.get(\"HTTP_REFERER\")"
    ],
    [
        "Models can have a ``managed`` attribute, which specifies whether the SQL code",
        "Models can have a ``managed`` attribute, which specifies whether the"
    ],
    [
        "is generated for the table on various manage.py operations.",
        "is generated for the table on various"
    ],
    [
        "The main test here is that the all the models can be created without",
        "The main test here is that the all the"
    ],
    [
        "any database errors. We can also do some more simple insertion and",
        "any database errors. We can also do some"
    ],
    [
        "lookup tests while we're here to show that the second of models do",
        "lookup tests while we're here to show that"
    ],
    [
        "refer to the tables from the first set.",
        "refer to the tables from the first"
    ],
    [
        "The intermediary table between two unmanaged models should not be created.",
        "The intermediary table between two unmanaged models should"
    ],
    [
        "table, tables, \"Table '%s' should not exist, but it does.\" % table",
        "table, tables, \"Table '%s' should not"
    ],
    [
        "An intermediary table between a managed and an unmanaged model should",
        "An intermediary table between a managed and an unmanaged"
    ],
    [
        "self.assertIn(table, tables, \"Table '%s' does not exist.\" % table)",
        "self.assertIn(table, tables, \"Table '%s' does not exist.\""
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import TestCase, modify_settings,"
    ],
    [
        "\"The flatpage admin form correctly validates urls\"",
        "\"The flatpage admin form correctly"
    ],
    [
        "self.assertEqual(form.errors[\"url\"], [\"URL is missing a leading slash.\"])",
        "self.assertEqual(form.errors[\"url\"], [\"URL is missing a"
    ],
    [
        "\"Example: “/about/contact/”. Make sure to have leading and \"",
        "\"Example: “/about/contact/”. Make sure to have"
    ],
    [
        "self.assertEqual(form.errors[\"url\"], [\"URL is missing a trailing slash.\"])",
        "self.assertEqual(form.errors[\"url\"], [\"URL is missing a trailing"
    ],
    [
        "\"Example: “/about/contact”. Make sure to have a leading slash.\",",
        "\"Example: “/about/contact”. Make sure to have a leading"
    ],
    [
        "The flatpage admin form correctly enforces url uniqueness among",
        "The flatpage admin form correctly enforces"
    ],
    [
        "Existing flatpages can be edited in the admin form without triggering",
        "Existing flatpages can be edited in"
    ],
    [
        "f.errors, {\"sites\": [translation.gettext(\"This field is required.\")]}",
        "f.errors, {\"sites\": [translation.gettext(\"This field is"
    ],
    [
        "from django.test import Client, TestCase, modify_settings, override_settings",
        "from django.test import Client, TestCase,"
    ],
    [
        "\"A flatpage can be served through a view, even when the middleware is in use\"",
        "\"A flatpage can be served through a view, even when"
    ],
    [
        "\"A flatpage served through a view can require authentication\"",
        "\"A flatpage served through a view can require"
    ],
    [
        "\"A flatpage can be served by the fallback middleware\"",
        "\"A flatpage can be served"
    ],
    [
        "POSTing to a flatpage served through a view will raise a CSRF error if",
        "POSTing to a flatpage served through a"
    ],
    [
        "POSTing to a flatpage served by the middleware will raise a CSRF error",
        "POSTing to a flatpage served by the middleware"
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import TestCase,"
    ],
    [
        "\"A flatpage can be served through a view, even when the middleware is in use\"",
        "\"A flatpage can be served through a view, even"
    ],
    [
        "\"A flatpage served through a view can require authentication\"",
        "\"A flatpage served through a"
    ],
    [
        "\"A flatpage can be served by the fallback middleware\"",
        "\"A flatpage can be served by"
    ],
    [
        "\"A flatpage served by the middleware can require authentication\"",
        "\"A flatpage served by the middleware"
    ],
    [
        "A flatpage with special chars in the URL can be served by the fallback",
        "A flatpage with special chars in the"
    ],
    [
        "\"A flatpage can be served through a view and should add a slash\"",
        "\"A flatpage can be served through a"
    ],
    [
        "\"A flatpage can be served by the fallback middleware and should add a slash\"",
        "\"A flatpage can be served by the"
    ],
    [
        "middleware and should not add a slash.",
        "middleware and should not"
    ],
    [
        "A flatpage with special chars in the URL can be served by the fallback",
        "A flatpage with special chars in the URL can be"
    ],
    [
        "middleware and should add a slash.",
        "middleware and should add a"
    ],
    [
        "\"A flatpage at / should not cause a redirect loop when APPEND_SLASH is set\"",
        "\"A flatpage at / should not cause a"
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import TestCase,"
    ],
    [
        "\"A flatpage can be served through a view\"",
        "\"A flatpage can be served through"
    ],
    [
        "\"A flatpage served through a view can require authentication\"",
        "\"A flatpage served through a view can"
    ],
    [
        "\"A fallback flatpage won't be served if the middleware is disabled\"",
        "\"A fallback flatpage won't be served if the"
    ],
    [
        "A nonexistent flatpage won't be served if the fallback middleware is",
        "A nonexistent flatpage won't be served if"
    ],
    [
        "\"A flatpage with special chars in the URL can be served through a view\"",
        "\"A flatpage with special chars in the"
    ],
    [
        "\"A flatpage can be served through a view and should add a slash\"",
        "\"A flatpage can be served through a view and"
    ],
    [
        "A fallback flatpage won't be served if the middleware is disabled and",
        "A fallback flatpage won't be served if the"
    ],
    [
        "A nonexistent flatpage won't be served if the fallback middleware is",
        "A nonexistent flatpage won't be served"
    ],
    [
        "disabled and should not add a slash.",
        "disabled and should not add"
    ],
    [
        "A flatpage with special chars in the URL can be served through a view",
        "A flatpage with special chars in the URL can be served"
    ],
    [
        "from django.template import Context, Template, TemplateSyntaxError",
        "from django.template import"
    ],
    [
        "\"The flatpage template tag retrieves unregistered prefixed flatpages by default\"",
        "\"The flatpage template tag retrieves unregistered prefixed flatpages by"
    ],
    [
        "\"{% for page in flatpages %}\"",
        "\"{% for page in"
    ],
    [
        "The flatpage template tag retrieves unregistered flatpages for an",
        "The flatpage template tag retrieves"
    ],
    [
        "\"{% get_flatpages for anonuser as flatpages %}\"",
        "\"{% get_flatpages for anonuser as"
    ],
    [
        "\"{% for page in flatpages %}\"",
        "\"{% for page in"
    ],
    [
        "\"The flatpage template tag retrieves all flatpages for an authenticated user\"",
        "\"The flatpage template tag retrieves all"
    ],
    [
        "\"{% get_flatpages for me as flatpages %}\"",
        "\"{% get_flatpages for me as flatpages"
    ],
    [
        "\"{% for page in flatpages %}\"",
        "\"{% for page"
    ],
    [
        "out, \"A Flatpage,A Nested Flatpage,Sekrit Nested Flatpage,Sekrit Flatpage,\"",
        "out, \"A Flatpage,A Nested Flatpage,Sekrit Nested"
    ],
    [
        "\"The flatpage template tag retrieves unregistered prefixed flatpages by default\"",
        "\"The flatpage template tag retrieves unregistered"
    ],
    [
        "\"{% get_flatpages '/location/' as location_flatpages %}\"",
        "\"{% get_flatpages '/location/' as location_flatpages"
    ],
    [
        "\"{% for page in location_flatpages %}\"",
        "\"{% for page"
    ],
    [
        "The flatpage template tag retrieves unregistered prefixed flatpages for",
        "The flatpage template tag retrieves unregistered"
    ],
    [
        "\"{% get_flatpages '/location/' for anonuser as location_flatpages %}\"",
        "\"{% get_flatpages '/location/' for anonuser"
    ],
    [
        "\"{% for page in location_flatpages %}\"",
        "\"{% for page in"
    ],
    [
        "The flatpage template tag retrieve prefixed flatpages for an",
        "The flatpage template tag retrieve prefixed flatpages for"
    ],
    [
        "\"{% get_flatpages '/location/' for me as location_flatpages %}\"",
        "\"{% get_flatpages '/location/' for"
    ],
    [
        "\"{% for page in location_flatpages %}\"",
        "\"{% for page in location_flatpages"
    ],
    [
        "self.assertEqual(out, \"A Nested Flatpage,Sekrit Nested Flatpage,\")",
        "self.assertEqual(out, \"A Nested Flatpage,Sekrit Nested"
    ],
    [
        "\"The prefix for the flatpage template tag can be a template variable\"",
        "\"The prefix for the flatpage template"
    ],
    [
        "\"{% get_flatpages location_prefix as location_flatpages %}\"",
        "\"{% get_flatpages location_prefix"
    ],
    [
        "\"{% for page in location_flatpages %}\"",
        "\"{% for page"
    ],
    [
        "\"There are various ways that the flatpages template tag won't parse\"",
        "\"There are various ways that the flatpages template"
    ],
    [
        "\"get_flatpages expects a syntax of get_flatpages \"",
        "\"get_flatpages expects a syntax of"
    ],
    [
        "render(\"{% load flatpages %}{% get_flatpages %}\")",
        "render(\"{% load flatpages %}{% get_flatpages"
    ],
    [
        "render(\"{% load flatpages %}{% get_flatpages as %}\")",
        "render(\"{% load flatpages %}{% get_flatpages as"
    ],
    [
        "render(\"{% load flatpages %}{% get_flatpages cheesecake flatpages %}\")",
        "render(\"{% load flatpages %}{% get_flatpages cheesecake"
    ],
    [
        "render(\"{% load flatpages %}{% get_flatpages as flatpages asdf %}\")",
        "render(\"{% load flatpages %}{% get_flatpages as"
    ],
    [
        "\"{% load flatpages %}{% get_flatpages cheesecake user as flatpages %}\"",
        "\"{% load flatpages %}{% get_flatpages cheesecake user"
    ],
    [
        "render(\"{% load flatpages %}{% get_flatpages for user as flatpages asdf %}\")",
        "render(\"{% load flatpages %}{% get_flatpages for"
    ],
    [
        "\"{% get_flatpages prefix for user as flatpages asdf %}\"",
        "\"{% get_flatpages prefix for user as"
    ],
    [
        "Tests for the Paginator and Page classes.",
        "Tests for the Paginator and"
    ],
    [
        "Helper method that instantiates a Paginator object from the passed",
        "Helper method that instantiates a Paginator object from the"
    ],
    [
        "params and then checks that its attributes match the passed output.",
        "params and then checks that its attributes match"
    ],
    [
        "def check_attribute(self, name, paginator, expected, params, coerce=None):",
        "def check_attribute(self, name, paginator,"
    ],
    [
        "Helper method that checks a single attribute and gives a nice error",
        "Helper method that checks a single"
    ],
    [
        "\"For '%s', expected %s but got %s.  Paginator parameters were: %s\"",
        "\"For '%s', expected %s but got %s."
    ],
    [
        "Tests the paginator attributes using varying inputs.",
        "Tests the paginator attributes"
    ],
    [
        "Invalid page numbers result in the correct exception being raised.",
        "Invalid page numbers result in the correct exception being"
    ],
    [
        "msg = \"There is nothing here\"",
        "msg = \"There"
    ],
    [
        "msg = \"That page contains no results\"",
        "msg = \"That page"
    ],
    [
        "Helper method that instantiates a Paginator object from the passed",
        "Helper method that instantiates a Paginator object from the"
    ],
    [
        "params and then checks that the start and end indexes of the passed",
        "params and then checks that the start and end indexes of the"
    ],
    [
        "msg = \"For %s of page %s, expected %s but got %s. Paginator parameters were: %s\"",
        "msg = \"For %s of page %s, expected %s but"
    ],
    [
        "msg % (\"start index\", page_num, start, page.start_index(), params),",
        "msg % (\"start index\", page_num,"
    ],
    [
        "msg % (\"end index\", page_num, end, page.end_index(), params),",
        "msg % (\"end index\", page_num, end,"
    ],
    [
        "Paginator pages have the correct start and end indexes.",
        "Paginator pages have the correct start and end"
    ],
    [
        "for params, first, last in tests:",
        "for params, first,"
    ],
    [
        "A paginator page acts like a standard sequence.",
        "A paginator page acts like"
    ],
    [
        "A Paginator subclass can use the ``_get_page`` hook to",
        "A Paginator subclass can use the ``_get_page``"
    ],
    [
        "return an alternative to the standard Page class.",
        "return an alternative to the standard Page"
    ],
    [
        "Paginator.get_page() returns a valid page even with invalid page",
        "Paginator.get_page() returns a valid page even"
    ],
    [
        "for pages, on_each_side, on_ends, elided_after in tests:",
        "for pages, on_each_side, on_ends, elided_after in"
    ],
    [
        "for number, on_each_side, on_ends, expected in tests:",
        "for number, on_each_side, on_ends, expected in"
    ],
    [
        "Test pagination with Django model instances",
        "Test pagination with Django"
    ],
    [
        "Tests proper behavior of a paginator page __getitem__ (queryset",
        "Tests proper behavior of a paginator"
    ],
    [
        "msg = \"Page indices must be integers or slices, not str.\"",
        "msg = \"Page indices must be integers or"
    ],
    [
        "\"Pagination may yield inconsistent results with an unordered \"",
        "\"Pagination may yield inconsistent results"
    ],
    [
        "Unordered object list warning with an object that has an ordered",
        "Unordered object list warning with an object"
    ],
    [
        "attribute but not a model attribute.",
        "attribute but not a"
    ],
    [
        "\"Pagination may yield inconsistent results with an unordered \"",
        "\"Pagination may yield inconsistent results with"
    ],
    [
        "from django.forms.fields import CharField, Field, IntegerField",
        "from django.forms.fields import CharField,"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, TestCase, override_settings",
        "from django.test import RequestFactory, SimpleTestCase,"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "To prevent almost identical usernames, visually identical but differing",
        "To prevent almost identical usernames, visually identical"
    ],
    [
        "by their unicode code points only, Unicode NFKC normalization should",
        "by their unicode code points only, Unicode NFKC"
    ],
    [
        "make appear them equal to Django.",
        "make appear them"
    ],
    [
        "form.errors[\"username\"], [\"A user with that username already exists.\"]",
        "form.errors[\"username\"], [\"A user with that username"
    ],
    [
        "\"Your password can’t be too similar to your other personal information.\"",
        "\"Your password can’t be too similar to your"
    ],
    [
        "errors = {field: [f\"Extra validation for {field}.\"] for field in fields}",
        "errors = {field: [f\"Extra validation for {field}.\"] for field in"
    ],
    [
        "BaseUserCreationForm password validation uses all of the form's data.",
        "BaseUserCreationForm password validation uses all of"
    ],
    [
        "fields = (\"username\", \"email\", \"first_name\", \"last_name\")",
        "fields = (\"username\", \"email\", \"first_name\","
    ],
    [
        "[\"The password is too similar to the first name.\"],",
        "[\"The password is too similar"
    ],
    [
        "[\"A user with that username already exists.\"],",
        "[\"A user with that"
    ],
    [
        "\"username\": {\"unique\": \"This username has already been taken.\"}",
        "\"username\": {\"unique\": \"This username has"
    ],
    [
        "[\"This username has already been taken.\"],",
        "[\"This username has already"
    ],
    [
        "\"\"\"An invalid login doesn't leak the inactive status of a user.\"\"\"",
        "\"\"\"An invalid login doesn't leak the"
    ],
    [
        "\"Please enter a correct %(username)s and password. Note that both \"",
        "\"Please enter a correct %(username)s and password. Note"
    ],
    [
        "\"Votre mot de passe ne peut pas trop ressembler à vos autres informations \"",
        "\"Votre mot de passe ne peut pas trop ressembler à"
    ],
    [
        "errors = {field: [f\"Extra validation for {field}.\"] for field in fields}",
        "errors = {field: [f\"Extra validation for"
    ],
    [
        "\"These groups give users different permissions\"",
        "\"These groups give"
    ],
    [
        "_(\"Invalid password format or unknown hashing algorithm.\"), form.as_table()",
        "_(\"Invalid password format or unknown hashing"
    ],
    [
        "_(\"Invalid password format or unknown hashing algorithm.\"), form.as_table()",
        "_(\"Invalid password format or"
    ],
    [
        "\"The change form does not return the password value\"",
        "\"The change form does not return the password"
    ],
    [
        "\"Raw passwords are not stored, so there is no way to see \"",
        "\"Raw passwords are not stored, so there is no way to see"
    ],
    [
        "\"Enable password-based authentication for this user by setting a \"",
        "\"Enable password-based authentication for this user by setting"
    ],
    [
        "for username, expected_help_text, expected_button_label in cases:",
        "for username, expected_help_text, expected_button_label in"
    ],
    [
        "Create a user and return a tuple (user_object, username, email).",
        "Create a user and return a tuple (user_object, username,"
    ],
    [
        "self.assertEqual(form[\"email\"].errors, [_(\"Enter a valid email address.\")])",
        "self.assertEqual(form[\"email\"].errors, [_(\"Enter a"
    ],
    [
        "Test nonexistent email address. This should not fail because it would",
        "Test nonexistent email address. This should not fail"
    ],
    [
        "\"Sorry to hear you forgot your password.\",",
        "\"Sorry to hear you forgot your"
    ],
    [
        "(\"Really sorry to hear you forgot your password.\", \"text/html\")",
        "(\"Really sorry to hear you forgot your password.\","
    ],
    [
        "Preserve the case of the user name (before the @ in the email address)",
        "Preserve the case of the user name (before"
    ],
    [
        "Inactive user cannot receive password reset email.",
        "Inactive user cannot receive"
    ],
    [
        "Test the PasswordResetForm.save() method with no html_email_template_name",
        "Test the PasswordResetForm.save() method"
    ],
    [
        "Test to ensure original behavior is unchanged after the parameter was added.",
        "Test to ensure original behavior is unchanged after the parameter was"
    ],
    [
        "self.assertEqual(message.get(\"subject\"), \"Custom password reset on example.com\")",
        "self.assertEqual(message.get(\"subject\"), \"Custom password reset"
    ],
    [
        "Test the PasswordResetForm.save() method with html_email_template_name",
        "Test the PasswordResetForm.save() method"
    ],
    [
        "Test to ensure that a multipart email is sent with both text/plain",
        "Test to ensure that a multipart email is"
    ],
    [
        "self.assertEqual(message.get(\"subject\"), \"Custom password reset on example.com\")",
        "self.assertEqual(message.get(\"subject\"), \"Custom password reset on"
    ],
    [
        "f\"ERROR:django.contrib.auth:Failed to send password reset email to {pk}\",",
        "f\"ERROR:django.contrib.auth:Failed to send password"
    ],
    [
        "ReadOnlyPasswordHashWidget doesn't contain a for attribute in the",
        "ReadOnlyPasswordHashWidget doesn't contain a for attribute"
    ],
    [
        "<label> because it doesn't have any labelable elements.",
        "<label> because it doesn't have any"
    ],
    [
        "\"The password is too similar to the username.\",",
        "\"The password is too similar"
    ],
    [
        "errors = {field: [f\"Extra validation for {field}.\"] for field in fields}",
        "errors = {field: [f\"Extra validation for {field}.\"] for field in"
    ],
    [
        "\"If disabled, the current password for this user will be lost.\",",
        "\"If disabled, the current password for"
    ],
    [
        "fields = (\"username\", \"email\", \"first_name\", \"last_name\")",
        "fields = (\"username\", \"email\","
    ],
    [
        "from django.contrib.auth import aget_user, get_user, get_user_model",
        "from django.contrib.auth import aget_user,"
    ],
    [
        "\"Users can be created and can set their password\"",
        "\"Users can be created and can set"
    ],
    [
        "u = await User.objects.acreate_user(\"testuser\", \"test@example.com\", \"testpw\")",
        "u = await"
    ],
    [
        "\"Users can be created without an email\"",
        "\"Users can be created"
    ],
    [
        "\"Check the creation and properties of a superuser\"",
        "\"Check the creation and properties of"
    ],
    [
        "\"Check the creation and properties of a superuser\"",
        "\"Check the creation and"
    ],
    [
        "\"The current user model can be retrieved\"",
        "\"The current user model can"
    ],
    [
        "\"The current user model can be swapped out for another\"",
        "\"The current user model can be swapped"
    ],
    [
        "\"The alternate user setting must point to something in the format app.model\"",
        "\"The alternate user setting must point to something in"
    ],
    [
        "msg = \"AUTH_USER_MODEL must be of the form 'app_label.model_name'\"",
        "msg = \"AUTH_USER_MODEL must be of the form"
    ],
    [
        "\"The current user model must point to an installed model\"",
        "\"The current user model must point to an installed"
    ],
    [
        "\"AUTH_USER_MODEL refers to model 'thismodel.doesntexist' \"",
        "\"AUTH_USER_MODEL refers to model"
    ],
    [
        "login_required is assignable to callable objects.",
        "login_required is assignable to"
    ],
    [
        "login_required is assignable to normal views.",
        "login_required is assignable"
    ],
    [
        "login_required works on a simple view wrapped in a login_required",
        "login_required works on a simple"
    ],
    [
        "login_required works on a simple view wrapped in a login_required",
        "login_required works on a simple view wrapped"
    ],
    [
        "login_not_required is assignable to callable objects.",
        "login_not_required is assignable to callable"
    ],
    [
        "login_not_required is assignable to normal views.",
        "login_not_required is assignable to"
    ],
    [
        "Tests for the mod_wsgi authentication handler",
        "Tests for the"
    ],
    [
        "check_password() returns the correct values as per",
        "check_password() returns the correct values"
    ],
    [
        "check_password() returns the correct values as per",
        "check_password() returns the correct values"
    ],
    [
        "groups_for_user() returns correct values as per",
        "groups_for_user() returns correct"
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import"
    ],
    [
        "\"The Django authentication middleware requires session middleware \"",
        "\"The Django authentication middleware requires session"
    ],
    [
        "\"to be installed. Edit your MIDDLEWARE setting to insert \"",
        "\"to be installed. Edit your MIDDLEWARE setting to insert"
    ],
    [
        "\"No login URL to redirect to. Define settings.LOGIN_URL or provide \"",
        "\"No login URL to redirect to. Define settings.LOGIN_URL or"
    ],
    [
        "\"a login_url via the 'django.contrib.auth.decorators.login_required' \"",
        "\"a login_url via"
    ],
    [
        "\"\"\"Set up the listeners and reset the logged in/logged out counters\"\"\"",
        "\"\"\"Set up the listeners and reset the logged"
    ],
    [
        "\"\"\"Only `last_login` is updated in `update_last_login`\"\"\"",
        "\"\"\"Only `last_login` is updated in"
    ],
    [
        "user.username = \"This username shouldn't get saved\"",
        "user.username = \"This username"
    ],
    [
        "The user_logged_in signal is only registered if the user model has a",
        "The user_logged_in signal is only registered if the user model"
    ],
    [
        "from django.test import RequestFactory, TestCase, override_settings",
        "from django.test import RequestFactory,"
    ],
    [
        "response, \"<title>Password reset | Django site admin</title>\"",
        "response, \"<title>Password reset | Django"
    ],
    [
        "response, \"<title>Error: Password reset | Django site admin</title>\"",
        "response, \"<title>Error: Password reset | Django site"
    ],
    [
        "response, \"<title>Password reset sent | Django site admin</title>\"",
        "response, \"<title>Password reset sent |"
    ],
    [
        "response, \"<title>Password reset unsuccessful | Django site admin</title>\"",
        "response, \"<title>Password reset unsuccessful"
    ],
    [
        "response, \"<title>Enter new password | Django site admin</title>\"",
        "response, \"<title>Enter new password | Django site"
    ],
    [
        "response, \"<title>Error: Enter new password | Django site admin</title>\"",
        "response, \"<title>Error: Enter new password"
    ],
    [
        "\"<title>Enter new password | Django site admin</title>\",",
        "\"<title>Enter new password | Django site"
    ],
    [
        "response, \"<title>Password reset complete | Django site admin</title>\"",
        "response, \"<title>Password reset complete | Django site"
    ],
    [
        "response, \"<title>Password change | Django site admin</title>\"",
        "response, \"<title>Password change |"
    ],
    [
        "response, \"<title>Password change successful | Django site admin</title>\"",
        "response, \"<title>Password change successful | Django"
    ],
    [
        "\"'HttpRequest' object has no attribute 'user'\",",
        "\"'HttpRequest' object has no"
    ],
    [
        "\"Fallback to request.user when user is None will be removed.\",",
        "\"Fallback to request.user when user is None will"
    ],
    [
        "\"'AnonymousUser' object has no attribute '_meta'\",",
        "\"'AnonymousUser' object has no attribute"
    ],
    [
        "\"Fallback to request.user when user is None will be removed.\",",
        "\"Fallback to request.user when user is None"
    ],
    [
        "msg = \"Fallback to request.user when user is None will be removed.\"",
        "msg = \"Fallback to request.user when"
    ],
    [
        "This client eases testing the password reset flow by emulating the",
        "This client eases testing the password reset flow"
    ],
    [
        "PasswordResetConfirmView's redirect and saving of the reset token in the",
        "PasswordResetConfirmView's redirect and saving of the reset token"
    ],
    [
        "user's session. This request puts 'my-token' in the session and redirects",
        "user's session. This request puts 'my-token' in"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import"
    ],
    [
        "Test some details of the PermWrapper implementation.",
        "Test some details of"
    ],
    [
        "This object makes sure __eq__ will not be called endlessly.",
        "This object makes sure __eq__ will not be called"
    ],
    [
        "'something' in PermWrapper works as expected.",
        "'something' in PermWrapper"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"PermWrapper is not iterable.\"):",
        "with self.assertRaisesMessage(TypeError, \"PermWrapper"
    ],
    [
        "The session is not accessed simply by including",
        "The session is not accessed"
    ],
    [
        "The session is accessed if the auth context processor",
        "The session is accessed if the"
    ],
    [
        "is used and relevant attributes accessed.",
        "is used and"
    ],
    [
        "The lazy objects returned behave just like the wrapped objects.",
        "The lazy objects returned behave just like"
    ],
    [
        "from django.contrib.auth.models import Group, Permission, User",
        "from django.contrib.auth.models import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "\"bypass\": [\"Bypass password validation and create user anyway? [y/N]: \"],",
        "\"bypass\": [\"Bypass password validation and create user"
    ],
    [
        "lambda: \"Username (leave blank to use '%s'): \" % get_default_username(),",
        "lambda: \"Username (leave blank to use '%s'):"
    ],
    [
        "Decorator to temporarily replace input/getpass to allow interactive",
        "Decorator to temporarily replace input/getpass to allow"
    ],
    [
        "msg() if callable(msg) else msg for msg in prompt_msgs",
        "msg() if callable(msg) else msg for msg in"
    ],
    [
        "raise ValueError(\"Mock input for %r not found.\" % prompt)",
        "raise ValueError(\"Mock input for %r not found.\""
    ],
    [
        "A fake stdin object that pretends to be a TTY to be used in conjunction",
        "A fake stdin object that pretends to be a TTY to be used"
    ],
    [
        "ValueError, \"Mock input for 'Email address: ' not found.\"",
        "ValueError, \"Mock input for 'Email address:"
    ],
    [
        "for exc in (ImportError, KeyError, OSError):",
        "for exc in (ImportError, KeyError,"
    ],
    [
        "\"\"\"The system username is used if --username isn't provided.\"\"\"",
        "\"\"\"The system username is used if"
    ],
    [
        "with self.assertRaisesMessage(CommandError, \"user 'test' does not exist\"):",
        "with self.assertRaisesMessage(CommandError, \"user 'test' does not"
    ],
    [
        "\"Executing the changepassword management command should change joe's password\"",
        "\"Executing the changepassword management command"
    ],
    [
        "\"Password changed successfully for user 'joe'\",",
        "\"Password changed successfully for user"
    ],
    [
        "A CommandError should be thrown by handle() if the user enters in",
        "A CommandError should be thrown by handle() if the user"
    ],
    [
        "A CommandError should be raised if the user enters in passwords which",
        "A CommandError should be raised if the user"
    ],
    [
        "self.assertIn(\"This password is entirely numeric.\", self.stderr.getvalue())",
        "self.assertIn(\"This password is"
    ],
    [
        "non-ASCII characters from the User object representation.",
        "non-ASCII characters from the User"
    ],
    [
        "changepassword --database should operate on the specified DB.",
        "changepassword --database should operate"
    ],
    [
        "\"Password changed successfully for user 'joe'\",",
        "\"Password changed successfully for"
    ],
    [
        "CommandError, \"You must use --email with --noinput.\"",
        "CommandError, \"You must use --email with"
    ],
    [
        "\"Check the operation of the createsuperuser management command\"",
        "\"Check the operation of the createsuperuser"
    ],
    [
        "\"Enter a valid username. This value may contain only letters, numbers, \"",
        "\"Enter a valid username. This value may contain only letters, numbers,"
    ],
    [
        "\"Uživatel (leave blank to use '%s'): \"",
        "\"Uživatel (leave blank to"
    ],
    [
        "\"A superuser can be created when a custom user model is in use\"",
        "\"A superuser can be created when a custom user model is in"
    ],
    [
        "\"A Custom superuser won't be created when a required field isn't provided\"",
        "\"A Custom superuser won't be created"
    ],
    [
        "CommandError, \"You must use --email with --noinput.\"",
        "CommandError, \"You must use --email with"
    ],
    [
        "If the command is not called from a TTY, it should be skipped and a",
        "If the command is not called from a TTY, it should be"
    ],
    [
        "\"\"\"A fake stdin object that has isatty() return False.\"\"\"",
        "\"\"\"A fake stdin object that has isatty()"
    ],
    [
        "You can pass a stdin object as an option and it should be",
        "You can pass a stdin object as an option and it"
    ],
    [
        "If no such option is passed, it defaults to sys.stdin.",
        "If no such option is"
    ],
    [
        "msg = \"email instance with email %r is not a valid choice.\" % non_existent_email",
        "msg = \"email instance with email %r is not a"
    ],
    [
        "msg = f\"group instance with id {nonexistent_group_id} is not a valid choice.\"",
        "msg = f\"group instance with id {nonexistent_group_id} is not a valid"
    ],
    [
        "msg = f\"group instance with id {nonexistent_group_id} is not a valid choice.\"",
        "msg = f\"group instance with id"
    ],
    [
        "msg = f\"group instance with id {nonexistent_group_id} is not a valid choice.\"",
        "msg = f\"group instance with id {nonexistent_group_id} is not a valid"
    ],
    [
        "\"Error: This field cannot be blank.\\n\"",
        "\"Error: This field cannot"
    ],
    [
        "\"Required field 'orgs' specifies a many-to-many relation through \"",
        "\"Required field 'orgs' specifies a many-to-many"
    ],
    [
        "\"\"\"createsuperuser uses a default username when one isn't provided.\"\"\"",
        "\"\"\"createsuperuser uses a default username when one"
    ],
    [
        "@mock_inputs({\"password\": return_passwords, \"username\": \"\", \"email\": \"\"})",
        "@mock_inputs({\"password\": return_passwords, \"username\": \"\", \"email\":"
    ],
    [
        "Creation should fail if the password fails validation.",
        "Creation should fail if the password"
    ],
    [
        "\"The password is too similar to the username.\\n\"",
        "\"The password is too"
    ],
    [
        "\"The password is too similar to the first name.\\n\"",
        "\"The password is too similar to the"
    ],
    [
        "\"The password is too similar to the first name.\\n\"",
        "\"The password is too similar to the first"
    ],
    [
        "\"\"\"Creation fails if --username is blank.\"\"\"",
        "\"\"\"Creation fails if"
    ],
    [
        "with self.assertRaisesMessage(CommandError, \"Username cannot be blank.\"):",
        "with self.assertRaisesMessage(CommandError, \"Username cannot"
    ],
    [
        "with self.assertRaisesMessage(CommandError, \"Username cannot be blank.\"):",
        "with self.assertRaisesMessage(CommandError, \"Username"
    ],
    [
        "Password validation can be bypassed by entering 'y' at the prompt.",
        "Password validation can be bypassed by entering"
    ],
    [
        "\"\"\"Creation fails if the username fails validation.\"\"\"",
        "\"\"\"Creation fails if the"
    ],
    [
        "invalid_username = (\"x\" * user_field.max_length) + \"y\"",
        "invalid_username = (\"x\" *"
    ],
    [
        "{\"password\": return_passwords, \"username\": return_usernames, \"email\": \"\"}",
        "{\"password\": return_passwords, \"username\":"
    ],
    [
        "\"Error: Ensure this value has at most %s characters (it has %s).\\n\"",
        "\"Error: Ensure this value has at most"
    ],
    [
        "\"\"\"Creation fails if the username already exists.\"\"\"",
        "\"\"\"Creation fails if the username"
    ],
    [
        "{\"password\": return_passwords, \"username\": return_usernames, \"email\": \"\"}",
        "{\"password\": return_passwords, \"username\": return_usernames,"
    ],
    [
        "\"Error: That username is already taken.\\n\"",
        "\"Error: That username is"
    ],
    [
        "Creation fails if the username already exists and a custom user model",
        "Creation fails if the username already exists and"
    ],
    [
        "\"Error: That username is already taken.\\n\"",
        "\"Error: That username"
    ],
    [
        "\"\"\"Creation fails if the username already exists.\"\"\"",
        "\"\"\"Creation fails if the username already"
    ],
    [
        "CommandError, \"Error: That username is already taken.\"",
        "CommandError, \"Error: That username is"
    ],
    [
        "\"Error: That username is already taken.\\n\"",
        "\"Error: That username is"
    ],
    [
        "Creation should fail if the user enters mismatched passwords.",
        "Creation should fail if the user enters"
    ],
    [
        "Creation should fail if the user enters blank passwords.",
        "Creation should fail if the user enters"
    ],
    [
        "createsuperuser --database should operate on the specified DB.",
        "createsuperuser --database should operate on the specified"
    ],
    [
        "@mock_inputs({\"password\": \"nopasswd\", \"username\": \"\", \"email\": \"\"})",
        "@mock_inputs({\"password\": \"nopasswd\", \"username\":"
    ],
    [
        "@mock_inputs({\"password\": \"nopasswd\", \"Username: \": \"other\", \"email\": \"\"})",
        "@mock_inputs({\"password\": \"nopasswd\", \"Username: \": \"other\","
    ],
    [
        "`post_migrate` handler ordering isn't guaranteed. Simulate a case",
        "`post_migrate` handler ordering isn't guaranteed. Simulate"
    ],
    [
        "where create_permissions() is called before create_contenttypes().",
        "where create_permissions() is called before"
    ],
    [
        "A proxy model's permissions use its own content type rather than the",
        "A proxy model's permissions use its own content"
    ],
    [
        "content type of the concrete model.",
        "content type of the"
    ],
    [
        "Create proxy permissions with content_type to the concrete model",
        "Create proxy permissions with content_type to the"
    ],
    [
        "name=\"May use a different app label\",",
        "name=\"May use a different"
    ],
    [
        "Create proxy permissions with content_type to the concrete model",
        "Create proxy permissions with content_type"
    ],
    [
        "- Old workaround was to manually create permissions for proxy models.",
        "- Old workaround was to manually create permissions for"
    ],
    [
        "- Model may have been concrete and then converted to proxy.",
        "- Model may have been concrete and then"
    ],
    [
        "Output a reminder to audit relevant permissions.",
        "Output a reminder to audit"
    ],
    [
        "\"A problem arose migrating proxy model permissions\", stdout.getvalue()",
        "\"A problem arose migrating proxy model"
    ],
    [
        "from django.contrib.auth import BACKEND_SESSION_KEY, REDIRECT_FIELD_NAME, SESSION_KEY",
        "from django.contrib.auth import"
    ],
    [
        "from django.test import Client, TestCase, modify_settings, override_settings",
        "from django.test import Client, TestCase,"
    ],
    [
        "from django.urls import NoReverseMatch, reverse, reverse_lazy",
        "from django.urls import NoReverseMatch, reverse,"
    ],
    [
        "from .models import CustomUser, CustomUserCompositePrimaryKey, UUIDUser",
        "from .models import"
    ],
    [
        "msg = \"No URL to redirect to. Provide a next_page.\"",
        "msg = \"No URL to"
    ],
    [
        "Helper base class for the test classes that follow.",
        "Helper base class for the test"
    ],
    [
        "\"\"\"Assert that error is found in response.context['form'] errors\"\"\"",
        "\"\"\"Assert that error is found in"
    ],
    [
        "for name, args, kwargs in expected_named_urls:",
        "for name, args,"
    ],
    [
        "\"Reversal of url named '%s' failed with NoReverseMatch\" % name",
        "\"Reversal of url named '%s' failed with NoReverseMatch\""
    ],
    [
        "\"\"\"If the provided email is not registered, don't raise any error but",
        "\"\"\"If the provided email is not registered, don't raise any error"
    ],
    [
        "\"Email is sent if a valid email address is provided for password reset\"",
        "\"Email is sent if a valid email address is provided for password"
    ],
    [
        "extra_email_context should be available in the email template context.",
        "extra_email_context should be available in the"
    ],
    [
        "A multipart email with text/plain and text/html is sent",
        "A multipart email with text/plain and text/html is"
    ],
    [
        "if the html_email_template parameter is passed to the view",
        "if the html_email_template parameter is passed"
    ],
    [
        "Email is sent if a valid email address is provided for password reset",
        "Email is sent if a valid email address is provided for password"
    ],
    [
        "when a custom from_email is provided.",
        "when a custom"
    ],
    [
        "\"Poisoned HTTP_HOST headers can't be used for reset emails\"",
        "\"Poisoned HTTP_HOST headers can't be used for reset"
    ],
    [
        "\"Poisoned HTTP_HOST headers can't be used for reset emails on admin views\"",
        "\"Poisoned HTTP_HOST headers can't be used for reset emails on admin"
    ],
    [
        "self.assertIsNotNone(urlmatch, \"No URL found in sent email\")",
        "self.assertIsNotNone(urlmatch, \"No URL found in sent"
    ],
    [
        "self.assertContains(response, \"Please enter your new password\")",
        "self.assertContains(response, \"Please enter"
    ],
    [
        "self.assertContains(response, \"The password reset link was invalid\")",
        "self.assertContains(response, \"The password reset link"
    ],
    [
        "self.assertContains(response, \"The password reset link was invalid\")",
        "self.assertContains(response, \"The password reset link"
    ],
    [
        "self.assertContains(response, \"The password reset link was invalid\")",
        "self.assertContains(response, \"The password reset link"
    ],
    [
        "\"\"\"A POST with an invalid token is rejected.\"\"\"",
        "\"\"\"A POST with an"
    ],
    [
        "self.assertContains(response, \"The password reset link was invalid\")",
        "self.assertContains(response, \"The password reset"
    ],
    [
        "self.assertContains(response, \"The password reset link was invalid\")",
        "self.assertContains(response, \"The password reset link"
    ],
    [
        "self.assertIsNotNone(urlmatch, \"No URL found in sent email\")",
        "self.assertIsNotNone(urlmatch, \"No URL found in sent"
    ],
    [
        "self.assertContains(response, \"Please enter your new password\")",
        "self.assertContains(response, \"Please enter your"
    ],
    [
        "self.assertContains(response, \"The password reset link was invalid\")",
        "self.assertContains(response, \"The password reset link was"
    ],
    [
        "session auth hash after a password change so the session isn't logged out.",
        "session auth hash after a password change so"
    ],
    [
        "bad_url, response.url, \"%s should be blocked\" % bad_url",
        "bad_url, response.url, \"%s should be blocked\""
    ],
    [
        "self.assertIn(good_url, response.url, \"%s should be allowed\" % good_url)",
        "self.assertIn(good_url, response.url, \"%s should"
    ],
    [
        "Makes sure that a login rotates the currently-used CSRF token.",
        "Makes sure that a login rotates the currently-used CSRF"
    ],
    [
        "To avoid reusing another user's session, ensure a new, empty session is",
        "To avoid reusing another user's session, ensure"
    ],
    [
        "created if the existing session corresponds to a different authenticated",
        "created if the existing session corresponds to a different"
    ],
    [
        "As above, but same user logging in after a password change.",
        "As above, but same user logging in"
    ],
    [
        "\"\"\"Stay on the login page by default.\"\"\"",
        "\"\"\"Stay on the login"
    ],
    [
        "\"\"\"If not logged in, stay on the same page.\"\"\"",
        "\"\"\"If not logged in, stay on the"
    ],
    [
        "\"\"\"If logged in, go to default redirected URL.\"\"\"",
        "\"\"\"If logged in, go to"
    ],
    [
        "\"\"\"If logged in, go to custom redirected URL.\"\"\"",
        "\"\"\"If logged in, go to custom"
    ],
    [
        "\"\"\"If next is specified as a GET parameter, go there.\"\"\"",
        "\"\"\"If next is specified as a GET parameter, go"
    ],
    [
        "Detect a redirect loop if LOGIN_REDIRECT_URL is not correctly set,",
        "Detect a redirect loop if LOGIN_REDIRECT_URL is not correctly"
    ],
    [
        "\"Redirection loop for authenticated user detected. Check that \"",
        "\"Redirection loop for authenticated user detected. Check"
    ],
    [
        "\"your LOGIN_REDIRECT_URL doesn't point to a login page.\"",
        "\"your LOGIN_REDIRECT_URL doesn't point"
    ],
    [
        "\"Logout without next_page option renders the default template\"",
        "\"Logout without next_page option renders"
    ],
    [
        "The logout() view should send \"no-cache\" headers for reasons described",
        "The logout() view should send"
    ],
    [
        "\"Logout with next_page option given redirects to specified resource\"",
        "\"Logout with next_page option given"
    ],
    [
        "\"Logout with query string redirects to specified resource\"",
        "\"Logout with query string redirects to specified"
    ],
    [
        "\"Logout with custom query string redirects to specified resource\"",
        "\"Logout with custom query string redirects to specified"
    ],
    [
        "\"Logout resolves names or URLs passed as next_page.\"",
        "\"Logout resolves names or"
    ],
    [
        "bad_url, response.url, \"%s should be blocked\" % bad_url",
        "bad_url, response.url, \"%s should be"
    ],
    [
        "self.assertIn(good_url, response.url, \"%s should be allowed\" % good_url)",
        "self.assertIn(good_url, response.url, \"%s should be allowed\" %"
    ],
    [
        "message=\"Conflicting form data submitted. Please try again.\",",
        "message=\"Conflicting form data submitted. Please"
    ],
    [
        "msg = \"Password must be a string or bytes, got int.\"",
        "msg = \"Password must be a string or bytes, got"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"Unknown password hashing algorithm\"):",
        "with self.assertRaisesMessage(ValueError, \"Unknown"
    ],
    [
        "Makes sure specifying no plain password with a valid encoded password",
        "Makes sure specifying no plain password with a"
    ],
    [
        "\"Unknown password hashing algorithm '%s'. Did you specify it in \"",
        "\"Unknown password hashing algorithm '%s'. Did"
    ],
    [
        "for password, encoded, hasher_side_effect in cases:",
        "for password, encoded,"
    ],
    [
        "for password, encoded, hasher_side_effect in cases:",
        "for password, encoded,"
    ],
    [
        "msg = \"salt must be provided and cannot contain $.\"",
        "msg = \"salt must be provided and"
    ],
    [
        "for salt in [None, \"\", \"sea$salt\"]:",
        "for salt in [None, \"\","
    ],
    [
        "msg = \"password must be provided.\"",
        "msg = \"password"
    ],
    [
        "not_implemented_msg = \"subclasses of BasePasswordHasher must provide %s() method\"",
        "not_implemented_msg = \"subclasses of BasePasswordHasher"
    ],
    [
        "msg = \"Hasher 'BasePasswordHasher' doesn't specify a library attribute\"",
        "msg = \"Hasher 'BasePasswordHasher' doesn't specify a"
    ],
    [
        "msg = \"Couldn't load 'PlainHasher' algorithm library: No module named 'plain'\"",
        "msg = \"Couldn't load 'PlainHasher' algorithm library: No module"
    ],
    [
        "msg = self.not_implemented_msg % \"an encode\"",
        "msg = self.not_implemented_msg % \"an"
    ],
    [
        "msg = self.not_implemented_msg % \"a decode\"",
        "msg = self.not_implemented_msg"
    ],
    [
        "\"subclasses of BasePasswordHasher should provide a harden_runtime() method\"",
        "\"subclasses of BasePasswordHasher should provide a harden_runtime()"
    ],
    [
        "msg = self.not_implemented_msg % \"a safe_summary\"",
        "msg = self.not_implemented_msg %"
    ],
    [
        "msg = self.not_implemented_msg % \"a verify\"",
        "msg = self.not_implemented_msg %"
    ],
    [
        "for attr, summary_key, new_value in tests:",
        "for attr, summary_key,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "\"The module in NAME could not be imported: json.tool. \"",
        "\"The module in NAME could not"
    ],
    [
        "cm.exception.messages, [\"This password is too common.\", msg_too_short]",
        "cm.exception.messages, [\"This password is"
    ],
    [
        "\"This password is too short. It must contain at least %d characters.\"",
        "\"This password is too short. It must contain"
    ],
    [
        "return \"Your password must be %d characters long\" % self.min_length",
        "return \"Your password must be"
    ],
    [
        "expected_error = \"Your password must be %d characters long\"",
        "expected_error = \"Your password must be"
    ],
    [
        "expected_error = \"The password is too similar to the %s.\"",
        "expected_error = \"The password is too"
    ],
    [
        "cm.exception.messages, [\"The password is too similar to the username.\"]",
        "cm.exception.messages, [\"The password is too similar"
    ],
    [
        "\"Your password can’t be too similar to your other personal information.\",",
        "\"Your password can’t be too similar to your other"
    ],
    [
        "return \"The password is too close to the %(verbose_name)s.\"",
        "return \"The password is too"
    ],
    [
        "expected_error = \"The password is too close to the %s.\"",
        "expected_error = \"The password is too close"
    ],
    [
        "return \"The password is too close to a user attribute.\"",
        "return \"The password is too close"
    ],
    [
        "expected_error = \"The password is too close to a user attribute.\"",
        "expected_error = \"The password is too close to a"
    ],
    [
        "expected_error = \"This password is too common.\"",
        "expected_error = \"This password is too"
    ],
    [
        "expected_error = \"This password is too common.\"",
        "expected_error = \"This password is too"
    ],
    [
        "\"Your password can’t be a commonly used password.\",",
        "\"Your password can’t be a"
    ],
    [
        "return \"This password has been used too much.\"",
        "return \"This password has"
    ],
    [
        "expected_error = \"This password has been used too much.\"",
        "expected_error = \"This password has been used"
    ],
    [
        "expected_error = \"This password is entirely numeric.\"",
        "expected_error = \"This password is"
    ],
    [
        "\"Your password can’t be entirely numeric.\",",
        "\"Your password can’t"
    ],
    [
        "return \"This password is all digits.\"",
        "return \"This password is"
    ],
    [
        "expected_error = \"This password is all digits.\"",
        "expected_error = \"This password is"
    ],
    [
        "valid_usernames = [\"joe\", \"René\", \"ᴮᴵᴳᴮᴵᴿᴰ\", \"أحمد\"]",
        "valid_usernames = [\"joe\", \"René\","
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, TestCase",
        "from django.test import"
    ],
    [
        "msg = \"You don't have access here\"",
        "msg = \"You don't have access"
    ],
    [
        "msg = \"You don't have access here\"",
        "msg = \"You don't have access"
    ],
    [
        "login_required works on a simple view wrapped in a login_required",
        "login_required works on a simple view wrapped in"
    ],
    [
        "from django.contrib.auth.models import AnonymousUser, Group, Permission, User",
        "from django.contrib.auth.models import AnonymousUser, Group,"
    ],
    [
        "msg = \"perm_list must be an iterable of permissions.\"",
        "msg = \"perm_list must be an"
    ],
    [
        "msg = \"perm_list must be an iterable of permissions.\"",
        "msg = \"perm_list must be an iterable"
    ],
    [
        "\"\"\"Hasher that counts how many times it computes a hash.\"\"\"",
        "\"\"\"Hasher that counts how many times it computes a"
    ],
    [
        "A base class for tests that need to validate the ModelBackend",
        "A base class for tests that need"
    ],
    [
        "with different User models. Subclasses should define a class",
        "with different User models. Subclasses should define"
    ],
    [
        "level UserModel attribute, and a create_users() method to",
        "level UserModel attribute, and a create_users()"
    ],
    [
        "construct two users for test purposes.",
        "construct two users for test"
    ],
    [
        "Tests for the ModelBackend using the default User model.",
        "Tests for the ModelBackend using the default"
    ],
    [
        "user_credentials = {\"username\": \"test\", \"password\": \"test\"}",
        "user_credentials = {\"username\":"
    ],
    [
        "A custom user without an `is_active` field is allowed to authenticate.",
        "A custom user without an `is_active` field is"
    ],
    [
        "A custom user without an `is_active` field is allowed to authenticate.",
        "A custom user without an `is_active` field"
    ],
    [
        "Tests for the ModelBackend using the custom ExtensionUser model.",
        "Tests for the ModelBackend using the"
    ],
    [
        "This isn't a perfect test, because both the User and ExtensionUser are",
        "This isn't a perfect test, because both the"
    ],
    [
        "synchronized to the database, which wouldn't ordinary happen in",
        "synchronized to the database, which wouldn't ordinary"
    ],
    [
        "production. As a result, it doesn't catch errors caused by the non-",
        "production. As a result, it doesn't catch errors caused"
    ],
    [
        "The specific problem is queries on .filter(groups__user) et al, which",
        "The specific problem is queries on"
    ],
    [
        "makes an implicit assumption that the user model is called 'User'. In",
        "makes an implicit assumption that the user model is called 'User'."
    ],
    [
        "production, the auth.User table won't exist, so the requested join",
        "production, the auth.User table won't exist, so"
    ],
    [
        "won't exist either; in testing, the auth.User *does* exist, and",
        "won't exist either; in testing, the auth.User *does*"
    ],
    [
        "so does the join. However, the join table won't contain any useful",
        "so does the join. However, the join"
    ],
    [
        "data; for testing, we check that the data we expect actually does exist.",
        "data; for testing, we check that the data we expect"
    ],
    [
        "Tests for the ModelBackend using the CustomPermissionsUser model.",
        "Tests for the ModelBackend using"
    ],
    [
        "As with the ExtensionUser test, this isn't a perfect test, because both",
        "As with the ExtensionUser test, this isn't"
    ],
    [
        "the User and CustomPermissionsUser are synchronized to the database,",
        "the User and CustomPermissionsUser are synchronized to the"
    ],
    [
        "which wouldn't ordinary happen in production.",
        "which wouldn't ordinary"
    ],
    [
        "The model backend can accept a credentials kwarg labeled with",
        "The model backend can accept a credentials kwarg labeled"
    ],
    [
        "A custom user with a UUID primary key should be able to login.",
        "A custom user with a UUID primary key should be able"
    ],
    [
        "elif user.is_anonymous and perm == \"anon\":",
        "elif user.is_anonymous and"
    ],
    [
        "elif not user.is_active and perm == \"inactive\":",
        "elif not user.is_active and perm =="
    ],
    [
        "async def ahas_perm(self, user, perm, obj=None):",
        "async def ahas_perm(self, user, perm,"
    ],
    [
        "if \"test_group\" in [group.name for group in user.groups.all()]:",
        "if \"test_group\" in [group.name for group in"
    ],
    [
        "Tests for auth backend that supports object level permissions",
        "Tests for auth backend that"
    ],
    [
        "Tests for AnonymousUser delegating to backend.",
        "Tests for AnonymousUser"
    ],
    [
        "msg = \"perm_list must be an iterable of permissions.\"",
        "msg = \"perm_list must be an iterable"
    ],
    [
        "msg = \"perm_list must be an iterable of permissions.\"",
        "msg = \"perm_list must be"
    ],
    [
        "An appropriate error is raised if no auth backends are provided.",
        "An appropriate error is raised if"
    ],
    [
        "\"No authentication backends have been defined. \"",
        "\"No authentication backends have been defined."
    ],
    [
        "\"No authentication backends have been defined. \"",
        "\"No authentication backends have been defined."
    ],
    [
        "Always raises PermissionDenied in `authenticate`, `has_perm` and `has_module_perms`.",
        "Always raises PermissionDenied in `authenticate`, `has_perm`"
    ],
    [
        "async def aauthenticate(self, request, username=None, password=None):",
        "async def aauthenticate(self,"
    ],
    [
        "async def ahas_perm(self, user_obj, perm, obj=None):",
        "async def ahas_perm(self, user_obj,"
    ],
    [
        "Other backends are not checked once a backend raises PermissionDenied",
        "Other backends are not checked once a backend raises"
    ],
    [
        "Tests for changes in the settings.AUTHENTICATION_BACKENDS",
        "Tests for changes in"
    ],
    [
        "Removing a backend configured in AUTHENTICATION_BACKENDS makes already",
        "Removing a backend configured"
    ],
    [
        "async def aauthenticate(self, request, username=None, password=None):",
        "async def aauthenticate(self, request, username=None,"
    ],
    [
        "A backend (SkippedBackend) is ignored if it doesn't accept the",
        "A backend (SkippedBackend) is ignored if it doesn't accept"
    ],
    [
        "An exception from within get_user_model() is propagated and doesn't",
        "An exception from within get_user_model() is"
    ],
    [
        "\"AUTH_USER_MODEL refers to model 'thismodel.doesntexist' \"",
        "\"AUTH_USER_MODEL refers to model"
    ],
    [
        "as the one defined in AUTHENTICATION_BACKENDS setting.",
        "as the one defined in AUTHENTICATION_BACKENDS"
    ],
    [
        "\"You have multiple authentication backends configured and \"",
        "\"You have multiple authentication backends"
    ],
    [
        "\"therefore must provide the `backend` argument or set the \"",
        "\"therefore must provide the `backend` argument or set the"
    ],
    [
        "\"backend must be a dotted import path string (got \"",
        "\"backend must be a dotted import path string (got"
    ],
    [
        "Inactive users may authenticate with the AllowAllUsersModelBackend.",
        "Inactive users may authenticate with"
    ],
    [
        "user_credentials = {\"username\": \"test\", \"password\": \"test\"}",
        "user_credentials = {\"username\":"
    ],
    [
        "msg = \"get_response must be provided.\"",
        "msg = \"get_response must be"
    ],
    [
        "\"\"\"Users are not created when remote user is not specified.\"\"\"",
        "\"\"\"Users are not created when remote user is not"
    ],
    [
        "response = await self.async_client.get(\"/remote_user/\", **{self.header: \"\"})",
        "response = await"
    ],
    [
        "CSRF check must access the CSRF token from the session or cookie,",
        "CSRF check must access the CSRF token from the session"
    ],
    [
        "rather than the request, as rotate_token() may have been called by an",
        "rather than the request, as rotate_token() may have been"
    ],
    [
        "authentication middleware during the process_request() phase.",
        "authentication middleware during the process_request()"
    ],
    [
        "response = await csrf_client.post(\"/remote_user/\", data, **headers)",
        "response = await"
    ],
    [
        "Tests the case where the username passed in the header does not exist",
        "Tests the case where the username passed in the header does not"
    ],
    [
        "Tests the case where the username passed in the header is a valid User.",
        "Tests the case where the username passed in the header"
    ],
    [
        "A user's last_login is set the first time they make a",
        "A user's last_login is set the"
    ],
    [
        "request but not updated in subsequent requests with the same session.",
        "request but not updated in subsequent"
    ],
    [
        "A logged in user is logged out automatically when",
        "A logged in user is logged"
    ],
    [
        "the REMOTE_USER header disappears during the same browser session.",
        "the REMOTE_USER header disappears during the same browser"
    ],
    [
        "If the username in the header changes between requests",
        "If the username in the"
    ],
    [
        "that the original user is logged out",
        "that the original user is"
    ],
    [
        "\"\"\"Backend that doesn't create unknown users.\"\"\"",
        "\"\"\"Backend that doesn't create unknown"
    ],
    [
        "Contains the same tests as RemoteUserTest, but using a custom auth backend",
        "Contains the same tests as RemoteUserTest,"
    ],
    [
        "class that doesn't create unknown users.",
        "class that doesn't"
    ],
    [
        "Grabs username before the @ character.",
        "Grabs username before the @"
    ],
    [
        "Sets user's email address using the email specified in an HTTP header.",
        "Sets user's email address using the email specified in an"
    ],
    [
        "Sets user's last name for existing users.",
        "Sets user's last name for existing"
    ],
    [
        "Tests a custom RemoteUserBackend subclass that overrides the clean_username",
        "Tests a custom RemoteUserBackend subclass"
    ],
    [
        "The strings passed in REMOTE_USER should be cleaned and the known users",
        "The strings passed in REMOTE_USER should be cleaned and"
    ],
    [
        "should not have been configured with an email address.",
        "should not have been configured with"
    ],
    [
        "The unknown user created should be configured with an email address",
        "The unknown user created should be configured with an email"
    ],
    [
        "Middleware that overrides custom HTTP auth user header.",
        "Middleware that overrides custom HTTP auth"
    ],
    [
        "Tests a custom RemoteUserMiddleware subclass with custom HTTP auth user",
        "Tests a custom RemoteUserMiddleware subclass with custom HTTP auth"
    ],
    [
        "PersistentRemoteUserMiddleware keeps the user logged in even if the",
        "PersistentRemoteUserMiddleware keeps the user logged"
    ],
    [
        "subsequent calls do not contain the header value.",
        "subsequent calls do not"
    ],
    [
        "A logged in user is kept logged in even if the REMOTE_USER header",
        "A logged in user is kept logged in even if the REMOTE_USER"
    ],
    [
        "disappears during the same browser session.",
        "disappears during the"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, TransactionTestCase, override_settings",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"The given username must be set\"):",
        "with self.assertRaisesMessage(ValueError, \"The given"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"Superuser must have is_staff=True.\"):",
        "with self.assertRaisesMessage(ValueError, \"Superuser must"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"Superuser must have is_staff=True.\"):",
        "with self.assertRaisesMessage(ValueError, \"Superuser"
    ],
    [
        "Passwords are usable even if they don't correspond to a hasher in",
        "Passwords are usable even if they"
    ],
    [
        "user = User(**{User.USERNAME_FIELD: ohm_username, \"password\": \"foo\"})",
        "user = User(**{User.USERNAME_FIELD: ohm_username, \"password\":"
    ],
    [
        "Calling user.save() twice should trigger password_changed() once.",
        "Calling user.save() twice should trigger password_changed()"
    ],
    [
        "password_changed() shouldn't be called if User.check_password()",
        "password_changed() shouldn't be called if"
    ],
    [
        "self, perm, is_active=True, include_superusers=True, backend=None, obj=None",
        "self, perm, is_active=True,"
    ],
    [
        "if obj is not None and obj.username == \"charliebrown\":",
        "if obj is not None and obj.username"
    ],
    [
        "msg = \"Permission name should be in the form app_label.permission_codename.\"",
        "msg = \"Permission name should be in"
    ],
    [
        "for perm in (\"nodots\", \"too.many.dots\", \"...\", \"\"):",
        "for perm in (\"nodots\","
    ],
    [
        "msg = \"The `perm` argument must be a string or a permission instance.\"",
        "msg = \"The `perm` argument must be a string or a permission"
    ],
    [
        "for perm in (b\"auth.test\", object(), None):",
        "for perm in (b\"auth.test\", object(),"
    ],
    [
        "msg = \"backend must be a dotted import path string (got %r).\"",
        "msg = \"backend must be a dotted import path string (got"
    ],
    [
        "\"You have multiple authentication backends configured and \"",
        "\"You have multiple authentication backends configured and"
    ],
    [
        "\"therefore must provide the `backend` argument.\"",
        "\"therefore must provide the `backend`"
    ],
    [
        "Tests the behavior of the guaranteed is_active attribute",
        "Tests the behavior of the guaranteed is_active"
    ],
    [
        "tests that the default value for is_active is provided",
        "tests that the default value"
    ],
    [
        "no_repr_msg = \"Django doesn't provide a DB representation for AnonymousUser.\"",
        "no_repr_msg = \"Django doesn't provide a DB representation for"
    ],
    [
        "\"Cannot cast AnonymousUser to int. Are you trying to use it in \"",
        "\"Cannot cast AnonymousUser to int. Are you trying to use it"
    ],
    [
        "str(p), \"Auth_Tests | custom email field | Can view custom email field\"",
        "str(p), \"Auth_Tests | custom email field | Can"
    ],
    [
        "from django.test import SimpleTestCase, override_settings, override_system_checks",
        "from django.test import"
    ],
    [
        "\"'REQUIRED_FIELDS' must be a list or tuple.\",",
        "\"'REQUIRED_FIELDS' must be a"
    ],
    [
        "\"\"\"USERNAME_FIELD should not appear in REQUIRED_FIELDS.\"\"\"",
        "\"\"\"USERNAME_FIELD should not appear"
    ],
    [
        "\"The field named as the 'USERNAME_FIELD' for a custom user model \"",
        "\"The field named as the 'USERNAME_FIELD' for a"
    ],
    [
        "\"must not be included in 'REQUIRED_FIELDS'.\",",
        "\"must not be"
    ],
    [
        "\"The 'USERNAME_FIELD' is currently set to 'username', you \"",
        "\"The 'USERNAME_FIELD' is currently set to 'username', you"
    ],
    [
        "\"should remove 'username' from the 'REQUIRED_FIELDS'.\"",
        "\"should remove 'username' from the"
    ],
    [
        "A non-unique USERNAME_FIELD raises an error only if the default",
        "A non-unique USERNAME_FIELD raises an error only"
    ],
    [
        "authentication backend is used. Otherwise, a warning is raised.",
        "authentication backend is used. Otherwise,"
    ],
    [
        "\"unique because it is named as the 'USERNAME_FIELD'.\",",
        "\"unique because it is named as the"
    ],
    [
        "\"the 'USERNAME_FIELD', but it is not unique.\",",
        "\"the 'USERNAME_FIELD', but it"
    ],
    [
        "\"Ensure that your authentication backend(s) can handle \"",
        "\"Ensure that your authentication backend(s) can handle"
    ],
    [
        "\"'CustomUserPartiallyUnique.username' must be unique because \"",
        "\"'CustomUserPartiallyUnique.username' must be unique"
    ],
    [
        "\"it is named as the 'USERNAME_FIELD'.\",",
        "\"it is named"
    ],
    [
        "\"'CustomUserPartiallyUnique.username' is named as the \"",
        "\"'CustomUserPartiallyUnique.username' is named as"
    ],
    [
        "\"'USERNAME_FIELD', but it is not unique.\",",
        "\"'USERNAME_FIELD', but it"
    ],
    [
        "\"Ensure that your authentication backend(s) can \"",
        "\"Ensure that your authentication"
    ],
    [
        "<User Model>.is_anonymous/is_authenticated must not be methods.",
        "<User Model>.is_anonymous/is_authenticated must"
    ],
    [
        "\"%s.is_anonymous must be an attribute or property rather than \"",
        "\"%s.is_anonymous must be an attribute"
    ],
    [
        "\"a method. Ignoring this is a security issue as anonymous \"",
        "\"a method. Ignoring this is a security issue as anonymous"
    ],
    [
        "\"users will be treated as authenticated!\" % BadUser,",
        "\"users will be treated as authenticated!\""
    ],
    [
        "\"%s.is_authenticated must be an attribute or property rather \"",
        "\"%s.is_authenticated must be an attribute or"
    ],
    [
        "\"than a method. Ignoring this is a security issue as anonymous \"",
        "\"than a method. Ignoring this is"
    ],
    [
        "\"users will be treated as authenticated!\" % BadUser,",
        "\"users will be treated as authenticated!\" %"
    ],
    [
        "permissions = [(\"change_checked\", \"Can edit permission (duplicate)\")]",
        "permissions = [(\"change_checked\", \"Can edit permission"
    ],
    [
        "\"The permission codenamed 'change_checked' clashes with a builtin \"",
        "\"The permission codenamed 'change_checked' clashes with a"
    ],
    [
        "\"Some permission with duplicate permission code\",",
        "\"Some permission with"
    ],
    [
        "\"The permission codenamed 'my_custom_permission' is duplicated for \"",
        "\"The permission codenamed 'my_custom_permission' is"
    ],
    [
        "\"The verbose_name of model 'auth_tests.Checked' must be at most \"",
        "\"The verbose_name of model 'auth_tests.Checked' must be at most"
    ],
    [
        "model = type(model_name, (models.Model,), {\"__module__\": self.__module__})",
        "model = type(model_name,"
    ],
    [
        "\"characters for its builtin permission codenames to be at \"",
        "\"characters for its builtin permission codenames to be at"
    ],
    [
        "\"The permission named '%s' of model 'auth_tests.Checked' is longer \"",
        "\"The permission named '%s' of model"
    ],
    [
        "\"The permission codenamed '%s' of model 'auth_tests.Checked' \"",
        "\"The permission codenamed '%s'"
    ],
    [
        "\"AuthenticationMiddleware must be defined before it in MIDDLEWARE.\",",
        "\"AuthenticationMiddleware must be defined before"
    ],
    [
        "\"AuthenticationMiddleware must be defined before it in MIDDLEWARE.\",",
        "\"AuthenticationMiddleware must be defined"
    ],
    [
        "from django.contrib.auth.urls import urlpatterns as auth_urlpatterns",
        "from django.contrib.auth.urls import urlpatterns"
    ],
    [
        "from django.urls import path, re_path, reverse_lazy",
        "from django.urls import path, re_path,"
    ],
    [
        "\"Dummy view for remote user tests\"",
        "\"Dummy view for remote"
    ],
    [
        "t = Template(\"Username is {{ user }}.\")",
        "t = Template(\"Username is {{"
    ],
    [
        "READ_ONLY_METHODS = {\"get\", \"options\", \"head\", \"trace\"}",
        "READ_ONLY_METHODS = {\"get\","
    ],
    [
        "The token generated for a user created in the same request",
        "The token generated for a user created in the same"
    ],
    [
        "\"\"\"Updating the user email address invalidates the token.\"\"\"",
        "\"\"\"Updating the user email address invalidates"
    ],
    [
        "\"\"\"The token is valid after n seconds, but no greater.\"\"\"",
        "\"\"\"The token is valid after n seconds, but"
    ],
    [
        "A valid token can be created with a secret other than SECRET_KEY by",
        "A valid token can be created with a secret other than SECRET_KEY"
    ],
    [
        "msg = \"The SECRET_KEY setting must not be empty.\"",
        "msg = \"The SECRET_KEY setting"
    ],
    [
        "def create_user(self, email, date_of_birth, password=None, **fields):",
        "def create_user(self, email, date_of_birth,"
    ],
    [
        "Creates and saves a User with the given email and password.",
        "Creates and saves a User with"
    ],
    [
        "raise ValueError(\"Users must have an email address\")",
        "raise ValueError(\"Users must have an email"
    ],
    [
        "async def acreate_user(self, email, date_of_birth, password=None, **fields):",
        "async def acreate_user(self, email, date_of_birth, password=None,"
    ],
    [
        "raise ValueError(\"Users must have an email address\")",
        "raise ValueError(\"Users must have an"
    ],
    [
        "def create_superuser(self, email, password, date_of_birth, **fields):",
        "def create_superuser(self, email, password, date_of_birth,"
    ],
    [
        "fields from the AbstractUser class, so they don't clash with the",
        "fields from the AbstractUser class, so they"
    ],
    [
        "A user with a non-unique username.",
        "A user with"
    ],
    [
        "This model is not invalid if it is used with a custom authentication",
        "This model is not invalid if it is"
    ],
    [
        "permissions = ((\"display_proxys\", \"May display proxys information\"),)",
        "permissions = ((\"display_proxys\", \"May"
    ],
    [
        "permissions = ((\"use_different_app_label\", \"May use a different app label\"),)",
        "permissions = ((\"use_different_app_label\", \"May use a different"
    ],
    [
        "The CustomPermissionsUser users email as the identifier, but uses the normal",
        "The CustomPermissionsUser users email as the identifier, but"
    ],
    [
        "Django permissions model. This allows us to check that the PermissionsMixin",
        "Django permissions model. This allows us to check"
    ],
    [
        "includes everything that is needed to interact with the ModelBackend.",
        "includes everything that is needed"
    ],
    [
        "\"\"\"A user with a UUID as primary key\"\"\"",
        "\"\"\"A user with a UUID as"
    ],
    [
        "This test user class and derivatives test the default is_active behavior",
        "This test user class and derivatives test the default is_active"
    ],
    [
        "from django.contrib.auth.models import AbstractBaseUser, BaseUserManager, Group",
        "from django.contrib.auth.models import AbstractBaseUser, BaseUserManager,"
    ],
    [
        "def create_superuser(self, username, email, group, password):",
        "def create_superuser(self, username, email,"
    ],
    [
        "Creation/checking of database objects in parallel with callback tracking is",
        "Creation/checking of database objects in parallel"
    ],
    [
        "to verify that the behavior of the two match in all tested cases.",
        "to verify that the behavior of the two match in all"
    ],
    [
        "\"\"\"Create a Thing instance and notify about it.\"\"\"",
        "\"\"\"Create a Thing instance"
    ],
    [
        "self.assertEqual(sorted(t.num for t in Thing.objects.all()), sorted(nums))",
        "self.assertEqual(sorted(t.num for t in Thing.objects.all()),"
    ],
    [
        "\"robust_callback in on_commit() during transaction (robust callback).\",",
        "\"robust_callback in on_commit() during transaction"
    ],
    [
        "\"\"\"If outer transaction fails, no hooks from within it run.\"\"\"",
        "\"\"\"If outer transaction fails, no hooks from within"
    ],
    [
        "lambda: [self.notify(t.num) for t in Thing.objects.all()]",
        "lambda: [self.notify(t.num) for t"
    ],
    [
        "raise AssertionError(\"this function should never be called\")",
        "raise AssertionError(\"this function should never"
    ],
    [
        "msg = \"on_commit() cannot be used in manual transaction management\"",
        "msg = \"on_commit() cannot be used"
    ],
    [
        "msg = \"on_commit()'s callback must be a callable.\"",
        "msg = \"on_commit()'s callback"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"app_label must be a str\"):",
        "with self.assertRaisesMessage(TypeError, \"app_label must"
    ],
    [
        "The optimizer does nothing on a single operation,",
        "The optimizer does nothing on a single"
    ],
    [
        "and that it does it in just one pass.",
        "and that it does it in"
    ],
    [
        "CreateModel and DeleteModel should collapse into nothing.",
        "CreateModel and DeleteModel should collapse"
    ],
    [
        "AlterOrderWithRespectTo, and DeleteModel should collapse into nothing.",
        "AlterOrderWithRespectTo, and DeleteModel should collapse"
    ],
    [
        "/AlterField should collapse into the second.",
        "/AlterField should collapse into"
    ],
    [
        "We should be able to optimize away create/delete through a create or",
        "We should be able to optimize away create/delete through a"
    ],
    [
        "delete of a different model, but only if the create operation does not",
        "delete of a different model, but only if the create operation does"
    ],
    [
        "AddField optimizes into CreateModel if it's a FK to a model that's",
        "AddField optimizes into CreateModel if it's a"
    ],
    [
        "between them (and there's no FK in the other direction), by changing",
        "between them (and there's no FK in"
    ],
    [
        "the order of the CreateModel operations.",
        "the order of the CreateModel"
    ],
    [
        "CreateModel reordering behavior doesn't result in an infinite loop if",
        "CreateModel reordering behavior doesn't result in an infinite"
    ],
    [
        "there are FKs in both directions.",
        "there are FKs in both"
    ],
    [
        "CreateModel order remains unchanged if the later AddField operation",
        "CreateModel order remains unchanged if the"
    ],
    [
        "A CreateModel that inherits from another isn't reordered to avoid",
        "A CreateModel that inherits from another isn't reordered to"
    ],
    [
        "moving it earlier than its parent CreateModel operation.",
        "moving it earlier than its parent"
    ],
    [
        "RenameField should optimize to the other side of AlterField,",
        "RenameField should optimize to the other side"
    ],
    [
        "add/alter/rename field should optimize to CreateModel with options.",
        "add/alter/rename field should optimize"
    ],
    [
        "tuple(\"c\" if value == \"b\" else value for value in item)",
        "tuple(\"c\" if value == \"b\" else value for"
    ],
    [
        "tuple(value for value in item if value != \"b\")",
        "tuple(value for value in item"
    ],
    [
        "field-level through checking is working. This should manage to collapse",
        "field-level through checking is working. This should"
    ],
    [
        "model Foo to nonexistence, and model Bar to a single IntegerField",
        "model Foo to nonexistence, and model Bar to"
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import TestCase, modify_settings,"
    ],
    [
        "Tests recording migrations as applied or not.",
        "Tests recording migrations as applied"
    ],
    [
        "{(x, y) for (x, y) in recorder.applied_migrations() if x == \"myapp\"},",
        "{(x, y) for (x, y) in"
    ],
    [
        "{(x, y) for (x, y) in recorder.applied_migrations() if x == \"myapp\"},",
        "{(x, y) for (x, y) in recorder.applied_migrations() if x =="
    ],
    [
        "{(x, y) for (x, y) in recorder_other.applied_migrations() if x == \"myapp\"},",
        "{(x, y) for (x, y) in recorder_other.applied_migrations() if"
    ],
    [
        "{(x, y) for (x, y) in recorder.applied_migrations() if x == \"myapp\"},",
        "{(x, y) for (x, y) in recorder.applied_migrations() if"
    ],
    [
        "The has_table() method caches a positive result and not continually",
        "The has_table() method caches a"
    ],
    [
        "query for the existence of the migrations table.",
        "query for the existence of the migrations"
    ],
    [
        "Tests the disk and database loader, and running through migrations",
        "Tests the disk and database loader, and running through"
    ],
    [
        "for recorder, app, name in self.applied_records:",
        "for recorder, app,"
    ],
    [
        "Makes sure the loader can load the migrations for the test apps,",
        "Makes sure the loader can load the migrations for the test"
    ],
    [
        "and then render them out to a new Apps.",
        "and then render them out to a"
    ],
    [
        "list(author_state.fields), [\"id\", \"name\", \"slug\", \"age\", \"rating\"]",
        "list(author_state.fields), [\"id\", \"name\", \"slug\", \"age\","
    ],
    [
        "The loader can load migrations with a dependency on an unmigrated app.",
        "The loader can load migrations with a dependency on an unmigrated"
    ],
    [
        "Makes sure the loader uses Migration.run_before.",
        "Makes sure the loader uses"
    ],
    [
        "Makes sure the '__first__' migrations build correctly.",
        "Makes sure the '__first__'"
    ],
    [
        "msg = \"There is no migration for 'migrations' with the prefix 'blarg'\"",
        "msg = \"There is no migration"
    ],
    [
        "\"App with migrations module file not in unmigrated apps.\",",
        "\"App with migrations module file"
    ],
    [
        "\"App missing __init__.py in migrations module not in unmigrated apps.\",",
        "\"App missing __init__.py in migrations module not in"
    ],
    [
        "Undefined MIGRATION_MODULES implies default migration module.",
        "Undefined MIGRATION_MODULES implies default"
    ],
    [
        "MIGRATION_MODULES allows disabling of migrations for a particular app.",
        "MIGRATION_MODULES allows disabling of migrations for a"
    ],
    [
        "If a MIGRATION_MODULES override points to a missing module, the error",
        "If a MIGRATION_MODULES override points to a missing module, the"
    ],
    [
        "raised during the importation attempt should be propagated unless",
        "raised during the importation attempt should be"
    ],
    [
        "\"Tests loading a complex set of squashed migrations\"",
        "\"Tests loading a complex"
    ],
    [
        "\"Tests loading a complex but erroneous set of squashed migrations\"",
        "\"Tests loading a complex but"
    ],
    [
        "\"to because some of the replaced migrations are already applied.\"",
        "\"to because some of the replaced"
    ],
    [
        "squashed migrations that have all of their `replaces` applied.",
        "squashed migrations that have all of their `replaces`"
    ],
    [
        "\"Tests loading a squashed migration with a new migration referencing it\"",
        "\"Tests loading a squashed migration with a new"
    ],
    [
        "The sample migrations are structured like this:",
        "The sample migrations are structured like"
    ],
    [
        "=============== \\ ============= / == / ======================",
        "=============== \\ ============= / =="
    ],
    [
        "\"\"\"Files prefixed with underscore, tilde, or dot aren't loaded.\"\"\"",
        "\"\"\"Files prefixed with underscore, tilde,"
    ],
    [
        "name for app, name in loader.disk_migrations if app == \"migrations\"",
        "name for app, name in loader.disk_migrations"
    ],
    [
        "\"\"\"Migration directories without an __init__.py file are ignored.\"\"\"",
        "\"\"\"Migration directories without an __init__.py"
    ],
    [
        "name for app, name in loader.disk_migrations if app == \"migrations\"",
        "name for app, name in loader.disk_migrations if app"
    ],
    [
        "To support frozen environments, MigrationLoader loads migrations from",
        "To support frozen environments, MigrationLoader loads"
    ],
    [
        "regular packages with no __file__ attribute.",
        "regular packages with no"
    ],
    [
        "name for app, name in loader.disk_migrations if app == \"migrations\"",
        "name for app, name in"
    ],
    [
        "To support frozen environments, MigrationLoader loads .pyc migrations.",
        "To support frozen environments, MigrationLoader loads"
    ],
    [
        "MigrationLoader reraises ImportErrors caused by \"bad magic number\" pyc",
        "MigrationLoader reraises ImportErrors caused by \"bad magic"
    ],
    [
        "files with a more helpful message.",
        "files with a"
    ],
    [
        "\"to be a stale .pyc file.\"",
        "\"to be a stale"
    ],
    [
        "An object that migration doesn't know how to serialize.",
        "An object that migration doesn't know"
    ],
    [
        "A model that is in a migration-less app (which this app is",
        "A model that is in a migration-less app (which"
    ],
    [
        "if its migrations directory has not been repointed)",
        "if its migrations directory"
    ],
    [
        "self.args = (a, b, c, d)",
        "self.args = (a, b,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "Tests the migration writer (makes migration files from Migration instances)",
        "Tests the migration writer (makes migration"
    ],
    [
        "\"Could not exec %r (from value %r): %s\" % (string.strip(), value, e)",
        "\"Could not exec %r (from value %r): %s\" % (string.strip(), value,"
    ],
    [
        "self.fail(\"Could not exec %r: %s\" % (string.strip(), e))",
        "self.fail(\"Could not exec %r:"
    ],
    [
        "\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string), value",
        "\"%s\\ntest_value_result = %s\" % (\"\\n\".join(imports), string),"
    ],
    [
        "(\"[list, tuple, dict, set, frozenset]\", set()),",
        "(\"[list, tuple, dict,"
    ],
    [
        "default=TextEnum.B, choices=[(m.value, m) for m in TextEnum]",
        "default=TextEnum.B, choices=[(m.value, m) for"
    ],
    [
        "choices=[(m.value, m) for m in TextTranslatedEnum],",
        "choices=[(m.value, m) for m in"
    ],
    [
        "default=BinaryEnum.B, choices=[(m.value, m) for m in BinaryEnum]",
        "default=BinaryEnum.B, choices=[(m.value, m) for"
    ],
    [
        "default=IntEnum.A, choices=[(m.value, m) for m in IntEnum]",
        "default=IntEnum.A, choices=[(m.value, m) for"
    ],
    [
        "default=IntFlagEnum.A, choices=[(m.value, m) for m in IntFlagEnum]",
        "default=IntFlagEnum.A, choices=[(m.value, m) for"
    ],
    [
        "\"models.CharField(choices=[('A', 'A value'), ('B', 'B value')], \"",
        "\"models.CharField(choices=[('A', 'A value'), ('B',"
    ],
    [
        "choices=((uuid_a, \"UUID A\"), (uuid_b, \"UUID B\")), default=uuid_a",
        "choices=((uuid_a, \"UUID A\"), (uuid_b,"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"Cannot serialize function: lambda\"):",
        "with self.assertRaisesMessage(ValueError, \"Cannot serialize"
    ],
    [
        "Make sure compiled regex can be serialized.",
        "Make sure compiled regex"
    ],
    [
        "with self.assertRaisesMessage(ImportError, \"No module named 'custom'\"):",
        "with self.assertRaisesMessage(ImportError, \"No module named"
    ],
    [
        "\"\"\"An unbound method used within a class body can be serialized.\"\"\"",
        "\"\"\"An unbound method used within a class body can"
    ],
    [
        "\"\"\"A reference in a local scope can't be serialized.\"\"\"",
        "\"\"\"A reference in a local scope can't be"
    ],
    [
        "ValueError, \"Could not find function upload_to in migrations.test_writer\"",
        "ValueError, \"Could not find function"
    ],
    [
        "self.assertSerializedResultEqual({\"c\", \"b\", \"a\"}, (\"{'a', 'b', 'c'}\", set()))",
        "self.assertSerializedResultEqual({\"c\", \"b\", \"a\"}, (\"{'a', 'b', 'c'}\","
    ],
    [
        "(\"('models.Model', {'from django.db import models'})\", set()),",
        "(\"('models.Model', {'from django.db"
    ],
    [
        "\"Could not locate an appropriate location to create \"",
        "\"Could not locate an appropriate location to"
    ],
    [
        "\"migrations package namespace_app.migrations. Make sure the toplevel \"",
        "\"migrations package namespace_app.migrations. Make sure the toplevel"
    ],
    [
        "\"package exists and can be imported.\"",
        "\"package exists and can be"
    ],
    [
        "\"import datetime\\nimport time\\nfrom django.db import migrations, models\\n\",",
        "\"import datetime\\nimport time\\nfrom django.db import"
    ],
    [
        "Test comments at top of file.",
        "Test comments at top"
    ],
    [
        "migration = type(\"Migration\", (migrations.Migration,), {\"operations\": []})",
        "migration = type(\"Migration\", (migrations.Migration,), {\"operations\":"
    ],
    [
        "django.db.models shouldn't be imported if unused.",
        "django.db.models shouldn't be imported"
    ],
    [
        "self.assertIn(\"from django.db import migrations, models\", output)",
        "self.assertIn(\"from django.db import"
    ],
    [
        "from django.db import IntegrityError, connection, migrations, models, transaction",
        "from django.db import IntegrityError, connection,"
    ],
    [
        "from django.db.models.functions import Abs, Concat, Pi",
        "from django.db.models.functions import Abs,"
    ],
    [
        "from .models import FoodManager, FoodQuerySet, UnicodeModel",
        "from .models import FoodManager, FoodQuerySet,"
    ],
    [
        "Tests running the operations and making sure they do what they say they do.",
        "Tests running the operations and making sure they do what"
    ],
    [
        "Each test looks at their state changing, and then their database operation -",
        "Each test looks at their state changing, and then their database operation"
    ],
    [
        "Most other tests use this operation as part of setup, so check failures",
        "Most other tests use this operation as part of setup, so check"
    ],
    [
        "ValueError, \"Found duplicate value pink in CreateModel fields argument.\"",
        "ValueError, \"Found duplicate value pink in"
    ],
    [
        "message = \"Found duplicate value test_crmo.pony in CreateModel bases argument.\"",
        "message = \"Found duplicate value"
    ],
    [
        "\"Found duplicate value migrations.unicodemodel in CreateModel bases \"",
        "\"Found duplicate value migrations.unicodemodel in CreateModel bases"
    ],
    [
        "\"Found duplicate value <class 'django.db.models.base.Model'> in \"",
        "\"Found duplicate value <class 'django.db.models.base.Model'>"
    ],
    [
        "\"Found duplicate value <class 'migrations.test_operations.Mixin'> in \"",
        "\"Found duplicate value <class"
    ],
    [
        "\"Found duplicate value objects in CreateModel managers argument.\",",
        "\"Found duplicate value objects in CreateModel managers"
    ],
    [
        "Tests the CreateModel operation directly followed by an",
        "Tests the CreateModel operation directly followed by"
    ],
    [
        "Test the creation of a model with a ManyToMany field and the",
        "Test the creation of a model with"
    ],
    [
        "\"\"\"Creation of models with a FK to a PK with db_collation.\"\"\"",
        "\"\"\"Creation of models with a FK"
    ],
    [
        "Tests the CreateModel operation on a multi-table inheritance setup.",
        "Tests the CreateModel operation on"
    ],
    [
        "insert_sql = f\"INSERT INTO {app_label}_product (id, price) VALUES (%d, %d)\"",
        "insert_sql = f\"INSERT INTO {app_label}_product"
    ],
    [
        "cursor.execute(\"SET CONSTRAINTS %s IMMEDIATE\" % quoted_name)",
        "cursor.execute(\"SET CONSTRAINTS %s IMMEDIATE\" %"
    ],
    [
        "The managers on a model are set.",
        "The managers on a model"
    ],
    [
        "Tests the DeleteModel operation ignores proxy models.",
        "Tests the DeleteModel operation"
    ],
    [
        "self.assertEqual(operation.describe(), \"Rename model Pony to Horse\")",
        "self.assertEqual(operation.describe(), \"Rename model Pony to"
    ],
    [
        "operation.formatted_description(), \"~ Rename model Pony to Horse\"",
        "operation.formatted_description(), \"~ Rename model Pony"
    ],
    [
        "RenameModel operations shouldn't trigger the caching of rendered apps",
        "RenameModel operations shouldn't trigger the caching"
    ],
    [
        "Tests the RenameModel operation on model with self referential FK.",
        "Tests the RenameModel operation on"
    ],
    [
        "self.assertEqual(operation.describe(), \"Rename model Rider to HorseRider\")",
        "self.assertEqual(operation.describe(), \"Rename model Rider to"
    ],
    [
        "Tests the RenameModel operation on a model which has a superclass that",
        "Tests the RenameModel operation on a model"
    ],
    [
        "operation.describe(), \"Rename model ShetlandPony to LittleHorse\"",
        "operation.describe(), \"Rename model ShetlandPony"
    ],
    [
        "\"\"\"RenameModel renames a many-to-many column after a RenameField.\"\"\"",
        "\"\"\"RenameModel renames a many-to-many"
    ],
    [
        "self.assertEqual(operation.describe(), \"Add field height to Pony\")",
        "self.assertEqual(operation.describe(), \"Add field"
    ],
    [
        "operation.formatted_description(), \"+ Add field height to Pony\"",
        "operation.formatted_description(), \"+ Add field height to"
    ],
    [
        "Tests the AddField operation on TextField.",
        "Tests the AddField operation"
    ],
    [
        "Tests the AddField operation on TextField.",
        "Tests the AddField operation on"
    ],
    [
        "Tests the AddField operation on TextField/BinaryField.",
        "Tests the AddField operation"
    ],
    [
        "Column names that are SQL keywords shouldn't cause problems when used",
        "Column names that are SQL keywords"
    ],
    [
        "Tests the AddField operation's state alteration",
        "Tests the AddField operation's"
    ],
    [
        "\"\"\"The AddField operation can set and unset a database default.\"\"\"",
        "\"\"\"The AddField operation can set"
    ],
    [
        "if connection.vendor != \"oracle\" or db_default != \"'\":",
        "if connection.vendor != \"oracle\" or"
    ],
    [
        "\"\"\"The AddField operation with both default and db_default.\"\"\"",
        "\"\"\"The AddField operation with both"
    ],
    [
        "Tests the AddField operation with a ManyToManyField.",
        "Tests the AddField operation with a"
    ],
    [
        "self.assertEqual(operation.describe(), \"Remove field pink from Pony\")",
        "self.assertEqual(operation.describe(), \"Remove field"
    ],
    [
        "operation.formatted_description(), \"- Remove field pink from Pony\"",
        "operation.formatted_description(), \"- Remove field pink from"
    ],
    [
        "Tests the RemoveField operation on a foreign key.",
        "Tests the RemoveField operation on a"
    ],
    [
        "Tests the AlterModelTable operation if the table name is set to None.",
        "Tests the AlterModelTable operation if the"
    ],
    [
        "self.assertEqual(operation.describe(), \"Rename table for Pony to (default)\")",
        "self.assertEqual(operation.describe(), \"Rename table for Pony to"
    ],
    [
        "Tests the AlterModelTable operation if the table name is not changed.",
        "Tests the AlterModelTable operation if the table"
    ],
    [
        "self.assertEqual(operation.describe(), \"Alter field pink on Pony\")",
        "self.assertEqual(operation.describe(), \"Alter field pink on"
    ],
    [
        "operation.formatted_description(), \"~ Alter field pink on Pony\"",
        "operation.formatted_description(), \"~ Alter field pink"
    ],
    [
        "\"\"\"The AlterField operation changing default to db_default.\"\"\"",
        "\"\"\"The AlterField operation changing default"
    ],
    [
        "The AlterField operation changing a null field to db_default.",
        "The AlterField operation changing a"
    ],
    [
        "AlterField operation is a noop when adding only a db_column and the",
        "AlterField operation is a noop when adding"
    ],
    [
        "any(\"ALTER\" in query[\"sql\"] for query in ctx.captured_queries), False",
        "any(\"ALTER\" in query[\"sql\"] for query"
    ],
    [
        "operation = migrations.AlterModelTableComment(\"Pony\", \"Custom pony comment\")",
        "operation = migrations.AlterModelTableComment(\"Pony\", \"Custom"
    ],
    [
        "operation.formatted_description(), \"~ Alter Pony table comment\"",
        "operation.formatted_description(), \"~ Alter"
    ],
    [
        "The AlterField operation on primary keys (things like PostgreSQL's",
        "The AlterField operation on primary keys (things like"
    ],
    [
        "Tests the AlterField operation on primary keys changes any FKs pointing to it.",
        "Tests the AlterField operation on primary keys changes any FKs pointing to"
    ],
    [
        "AlterField operation of db_collation on primary keys changes any FKs",
        "AlterField operation of db_collation on primary keys changes any"
    ],
    [
        "for c in self.get_table_description(\"%s_rider\" % app_label)",
        "for c in self.get_table_description(\"%s_rider\" %"
    ],
    [
        "for c in self.get_table_description(\"%s_pony\" % app_label)",
        "for c in self.get_table_description(\"%s_pony\""
    ],
    [
        "If AlterField doesn't reload state appropriately, the second AlterField",
        "If AlterField doesn't reload state appropriately, the second"
    ],
    [
        "crashes on MySQL due to not dropping the PonyRider.pony foreign key",
        "crashes on MySQL due to not dropping"
    ],
    [
        "If AlterField doesn't reload state appropriately, the second AlterField",
        "If AlterField doesn't reload state"
    ],
    [
        "crashes on MySQL due to not dropping the PonyRider.pony foreign key",
        "crashes on MySQL due to not dropping the"
    ],
    [
        "If RenameField doesn't reload state appropriately, the AlterField",
        "If RenameField doesn't reload state appropriately, the"
    ],
    [
        "crashes on MySQL due to not dropping the PonyRider.pony foreign key",
        "crashes on MySQL due to not"
    ],
    [
        "self.assertEqual(operation.describe(), \"Rename field pink on Pony to blue\")",
        "self.assertEqual(operation.describe(), \"Rename field pink on Pony to"
    ],
    [
        "operation.formatted_description(), \"~ Rename field pink on Pony to blue\"",
        "operation.formatted_description(), \"~ Rename field pink on Pony to"
    ],
    [
        "{\"model_name\": \"Pony\", \"old_name\": \"pink\", \"new_name\": \"blue\"},",
        "{\"model_name\": \"Pony\", \"old_name\": \"pink\","
    ],
    [
        "FieldDoesNotExist, \"app.model has no field named 'field'\"",
        "FieldDoesNotExist, \"app.model has no"
    ],
    [
        "\"Indexes passed to AddIndex operations require a name argument. \"",
        "\"Indexes passed to AddIndex operations require a name"
    ],
    [
        "\"Create index test_adin_pony_pink_idx on field(s) pink of model Pony\",",
        "\"Create index test_adin_pony_pink_idx on field(s) pink of"
    ],
    [
        "\"+ Create index test_adin_pony_pink_idx on field(s) pink of model Pony\",",
        "\"+ Create index test_adin_pony_pink_idx on field(s) pink of"
    ],
    [
        "self.assertEqual(operation.describe(), \"Remove index pony_test_idx from Pony\")",
        "self.assertEqual(operation.describe(), \"Remove index pony_test_idx from"
    ],
    [
        "operation.formatted_description(), \"- Remove index pony_test_idx from Pony\"",
        "operation.formatted_description(), \"- Remove index pony_test_idx"
    ],
    [
        "\"Rename index pony_pink_idx on Pony to new_pony_test_idx\",",
        "\"Rename index pony_pink_idx on Pony to"
    ],
    [
        "\"~ Rename index pony_pink_idx on Pony to new_pony_test_idx\",",
        "\"~ Rename index pony_pink_idx on Pony to"
    ],
    [
        "msg = \"RenameIndex.old_name and old_fields are mutually exclusive.\"",
        "msg = \"RenameIndex.old_name and old_fields"
    ],
    [
        "msg = \"RenameIndex requires one of old_name and old_fields arguments to be set.\"",
        "msg = \"RenameIndex requires one of old_name and old_fields arguments"
    ],
    [
        "\"Rename unnamed index for ('weight', 'pink') on Pony to new_pony_test_idx\",",
        "\"Rename unnamed index for ('weight',"
    ],
    [
        "\"Create index test_addfuncin_pony_abs_idx on Abs(F(weight)) on model Pony\",",
        "\"Create index test_addfuncin_pony_abs_idx on Abs(F(weight)) on"
    ],
    [
        "Test AlterField operation with an index to ensure indexes created via",
        "Test AlterField operation with an index to ensure"
    ],
    [
        "any(\"CHECK\" in query[\"sql\"] for query in ctx.captured_queries), False",
        "any(\"CHECK\" in query[\"sql\"] for query"
    ],
    [
        "any(\"CHECK\" in query[\"sql\"] for query in ctx.captured_queries), False",
        "any(\"CHECK\" in query[\"sql\"] for query in"
    ],
    [
        "for check, valid, invalid in checks:",
        "for check, valid,"
    ],
    [
        "for check, valid, invalid in checks:",
        "for check, valid, invalid"
    ],
    [
        "\"~ Alter constraint test_alter_constraint_pony_fields_uq on Pony\",",
        "\"~ Alter constraint test_alter_constraint_pony_fields_uq"
    ],
    [
        "\"Create constraint deferred_pink_constraint_add on model Pony\",",
        "\"Create constraint deferred_pink_constraint_add on model"
    ],
    [
        "cursor.execute(\"SET CONSTRAINTS %s IMMEDIATE\" % quoted_name)",
        "cursor.execute(\"SET CONSTRAINTS %s"
    ],
    [
        "\"Remove constraint deferred_pink_constraint_rm from model Pony\",",
        "\"Remove constraint deferred_pink_constraint_rm"
    ],
    [
        "cursor.execute(\"SET CONSTRAINTS %s IMMEDIATE\" % quoted_name)",
        "cursor.execute(\"SET CONSTRAINTS %s"
    ],
    [
        "\"Create constraint covering_pink_constraint_add on model Pony\",",
        "\"Create constraint covering_pink_constraint_add on"
    ],
    [
        "\"Remove constraint covering_pink_constraint_rm from model Pony\",",
        "\"Remove constraint covering_pink_constraint_rm from model"
    ],
    [
        "\"Create constraint test_adfuncuc_pony_abs_uq on model Pony\",",
        "\"Create constraint test_adfuncuc_pony_abs_uq"
    ],
    [
        "\"Remove constraint test_rmfuncuc_pony_abs_uq from model Pony\",",
        "\"Remove constraint test_rmfuncuc_pony_abs_uq from model"
    ],
    [
        "self.assertEqual(operation.describe(), \"Change Meta options on Pony\")",
        "self.assertEqual(operation.describe(), \"Change Meta options on"
    ],
    [
        "operation.formatted_description(), \"~ Change Meta options on Pony\"",
        "operation.formatted_description(), \"~ Change Meta"
    ],
    [
        "{\"name\": \"Pony\", \"options\": {\"permissions\": [(\"can_groom\", \"Can groom\")]}},",
        "{\"name\": \"Pony\", \"options\": {\"permissions\": [(\"can_groom\","
    ],
    [
        "self.assertEqual(operation.describe(), \"Change Meta options on Pony\")",
        "self.assertEqual(operation.describe(), \"Change Meta"
    ],
    [
        "operation.describe(), \"Set order_with_respect_to on Rider to pony\"",
        "operation.describe(), \"Set order_with_respect_to on Rider"
    ],
    [
        "\"~ Set order_with_respect_to on Rider to pony\",",
        "\"~ Set order_with_respect_to on Rider"
    ],
    [
        "The managers on a model are set.",
        "The managers on a model"
    ],
    [
        "self.assertEqual(operation.formatted_description(), \"~ Change managers on Pony\")",
        "self.assertEqual(operation.formatted_description(), \"~ Change managers on"
    ],
    [
        "The managers on a model are set.",
        "The managers on a model"
    ],
    [
        "Creating and then altering an FK works correctly",
        "Creating and then altering"
    ],
    [
        "\"INSERT INTO i_love_ponies (id, special_thing) \"",
        "\"INSERT INTO i_love_ponies (id,"
    ],
    [
        "\"INSERT INTO i_love_ponies (id, special_thing) \"",
        "\"INSERT INTO i_love_ponies (id, special_thing)"
    ],
    [
        "\"UPDATE i_love_ponies SET special_thing = 'Ponies' \"",
        "\"UPDATE i_love_ponies SET special_thing"
    ],
    [
        "\"UPDATE i_love_ponies SET special_thing = 'Django' \"",
        "\"UPDATE i_love_ponies SET special_thing ="
    ],
    [
        "\"DELETE FROM i_love_ponies WHERE special_thing LIKE '%Django%';\"",
        "\"DELETE FROM i_love_ponies WHERE special_thing"
    ],
    [
        "\"DELETE FROM i_love_ponies WHERE special_thing LIKE '%%Ponies%%';\"",
        "\"DELETE FROM i_love_ponies WHERE special_thing LIKE"
    ],
    [
        "\"SELECT COUNT(*) FROM i_love_ponies WHERE special_thing = 'Django'\"",
        "\"SELECT COUNT(*) FROM i_love_ponies WHERE special_thing ="
    ],
    [
        "\"SELECT COUNT(*) FROM i_love_ponies WHERE special_thing = 'Ponies'\"",
        "\"SELECT COUNT(*) FROM i_love_ponies"
    ],
    [
        "\"INSERT INTO i_love_ponies (id, special_thing) VALUES (%s, %s);\",",
        "\"INSERT INTO i_love_ponies (id, special_thing) VALUES"
    ],
    [
        "\"DELETE FROM i_love_ponies WHERE special_thing = 'Django';\",",
        "\"DELETE FROM i_love_ponies WHERE"
    ],
    [
        "[\"DELETE FROM i_love_ponies WHERE special_thing = 'Ponies';\", None],",
        "[\"DELETE FROM i_love_ponies WHERE"
    ],
    [
        "\"DELETE FROM i_love_ponies WHERE id = %s OR special_thing = %s;\",",
        "\"DELETE FROM i_love_ponies WHERE id ="
    ],
    [
        "[[\"INSERT INTO foo (bar) VALUES ('buz');\"]],",
        "[[\"INSERT INTO foo (bar) VALUES"
    ],
    [
        "((\"DELETE FROM foo WHERE bar = 'buz';\", \"invalid\", \"parameter count\"),),",
        "((\"DELETE FROM foo WHERE bar = 'buz';\", \"invalid\", \"parameter"
    ],
    [
        "msg = \"You cannot reverse this operation\"",
        "msg = \"You cannot"
    ],
    [
        "ValueError, \"RunPython must be supplied with a callable\"",
        "ValueError, \"RunPython must be supplied"
    ],
    [
        "msg = \"RunPython must be supplied with callable arguments\"",
        "msg = \"RunPython must be supplied with callable"
    ],
    [
        "Tests the RunPython operation correctly handles the \"atomic\" keyword",
        "Tests the RunPython operation correctly handles the"
    ],
    [
        "on the FK side as well.",
        "on the FK side"
    ],
    [
        "Book.objects.create(title=\"Old Man and The Sea\", author=author)",
        "Book.objects.create(title=\"Old Man and The Sea\","
    ],
    [
        "A model with BigAutoField can be created.",
        "A model with BigAutoField"
    ],
    [
        "A field may be migrated in the following ways:",
        "A field may be migrated"
    ],
    [
        "blog = Blog.objects.create(name=\"web development done right\")",
        "blog = Blog.objects.create(name=\"web development"
    ],
    [
        "\"\"\"A field may be migrated from AutoField to BigAutoField.\"\"\"",
        "\"\"\"A field may be migrated from AutoField"
    ],
    [
        "\"\"\"A field may be migrated from SmallAutoField to AutoField.\"\"\"",
        "\"\"\"A field may be migrated from SmallAutoField to"
    ],
    [
        "\"\"\"A field may be migrated from SmallAutoField to BigAutoField.\"\"\"",
        "\"\"\"A field may be migrated from"
    ],
    [
        "\"CREATE TABLE i_love_ponies (id int, special_thing int);\",",
        "\"CREATE TABLE i_love_ponies (id int, special_thing"
    ],
    [
        "A complex SeparateDatabaseAndState operation: Multiple operations both",
        "A complex SeparateDatabaseAndState operation: Multiple"
    ],
    [
        "for state and database. Verify the state dependencies within each list",
        "for state and database. Verify the state"
    ],
    [
        "and that state ops don't affect the database.",
        "and that state ops don't affect"
    ],
    [
        "for app_label, add_field, alter_field in tests:",
        "for app_label, add_field, alter_field in"
    ],
    [
        "\"Modifying GeneratedFields is not supported - the field \"",
        "\"Modifying GeneratedFields is not supported -"
    ],
    [
        "f\"{app_label}.Pony.modified_pink must be removed and re-added with the \"",
        "f\"{app_label}.Pony.modified_pink must be removed and re-added with"
    ],
    [
        "\"Modifying GeneratedFields is not supported - the field \"",
        "\"Modifying GeneratedFields is not supported - the"
    ],
    [
        "f\"{app_label}.Pony.modified_pink must be removed and re-added with the \"",
        "f\"{app_label}.Pony.modified_pink must be removed and re-added"
    ],
    [
        "\"Modifying GeneratedFields is not supported - the field \"",
        "\"Modifying GeneratedFields is not supported - the field"
    ],
    [
        "f\"{app_label}.Pony.modified_pink must be removed and re-added with the \"",
        "f\"{app_label}.Pony.modified_pink must be removed and re-added with the"
    ],
    [
        "(we don't want to replicate all of them here, as the functionality",
        "(we don't want to replicate all of them here, as the"
    ],
    [
        "is in a common base class anyway)",
        "is in a common base class"
    ],
    [
        "The CreateTable operation ignores swapped models.",
        "The CreateTable operation"
    ],
    [
        "Tests the DeleteModel operation ignores swapped models.",
        "Tests the DeleteModel operation ignores"
    ],
    [
        "from django.db import connection, migrations, models",
        "from django.db import connection,"
    ],
    [
        "A router that doesn't have an opinion regarding migrating.",
        "A router that doesn't have an"
    ],
    [
        "A router that doesn't allow migrating.",
        "A router that doesn't allow"
    ],
    [
        "A router that always allows migrating.",
        "A router that always"
    ],
    [
        "A router that allows migrating depending on a hint.",
        "A router that allows migrating depending on a"
    ],
    [
        "Test when router doesn't have an opinion (i.e. CreateModel should run).",
        "Test when router doesn't have an opinion (i.e. CreateModel"
    ],
    [
        "Test when router returns False (i.e. CreateModel shouldn't run).",
        "Test when router returns False (i.e. CreateModel shouldn't"
    ],
    [
        "Test when router returns True (i.e. CreateModel should run).",
        "Test when router returns True (i.e."
    ],
    [
        "operation = migrations.RunSQL(sql, hints=hints or {})",
        "operation = migrations.RunSQL(sql,"
    ],
    [
        "operation = migrations.RunPython(inner_method, hints=hints or {})",
        "operation = migrations.RunPython(inner_method, hints=hints"
    ],
    [
        "Tests state construction, rendering and modification by operations.",
        "Tests state construction, rendering and modification"
    ],
    [
        "Tests making a ProjectState from an Apps",
        "Tests making a ProjectState from an"
    ],
    [
        "{\"proxy\": True, \"ordering\": [\"name\"], \"indexes\": [], \"constraints\": []},",
        "{\"proxy\": True, \"ordering\": [\"name\"], \"indexes\":"
    ],
    [
        "self.assertEqual([name for name, mgr in food_state.managers], [\"food_mgr\"])",
        "self.assertEqual([name for name, mgr in"
    ],
    [
        "self.assertTrue(all(isinstance(name, str) for name, mgr in food_state.managers))",
        "self.assertTrue(all(isinstance(name, str) for name, mgr"
    ],
    [
        "[name for name, mgr in food_no_default_manager_state.managers],",
        "[name for name,"
    ],
    [
        "[name for name, mgr in food_order_manager_state.managers],",
        "[name for name, mgr in"
    ],
    [
        "isinstance(name, str) for name, mgr in food_order_manager_state.managers",
        "isinstance(name, str) for name, mgr in"
    ],
    [
        "[mgr.args for name, mgr in food_order_manager_state.managers],",
        "[mgr.args for name, mgr in"
    ],
    [
        "When the default manager of the model is a custom manager,",
        "When the default manager of the model is a"
    ],
    [
        "it needs to be added to the model state.",
        "it needs to be added"
    ],
    [
        "When a manager is added with a name of 'objects' but it does not",
        "When a manager is added with a name of 'objects' but it"
    ],
    [
        "have `use_in_migrations = True`, no migration should be added to the",
        "have `use_in_migrations = True`, no migration should be"
    ],
    [
        "When a manager is added with `use_in_migrations = True` and a parent",
        "When a manager is added with"
    ],
    [
        "model had a manager with the same name and `use_in_migrations = True`,",
        "model had a manager with the same name"
    ],
    [
        "StateApps.bulk_update() should update apps.ready to False and reset",
        "StateApps.bulk_update() should update apps.ready to False and"
    ],
    [
        "Tests rendering a ProjectState into an Apps.",
        "Tests rendering a ProjectState into an"
    ],
    [
        "self.assertTrue(all(isinstance(mgr.name, str) for mgr in Food._meta.managers))",
        "self.assertTrue(all(isinstance(mgr.name, str) for mgr"
    ],
    [
        "The ProjectState render method correctly renders models",
        "The ProjectState render method"
    ],
    [
        "to account for inter-model base dependencies.",
        "to account for inter-model base"
    ],
    [
        "The ProjectState render method doesn't raise an",
        "The ProjectState render method doesn't"
    ],
    [
        "ImproperlyConfigured exception about unique labels if two dotted app",
        "ImproperlyConfigured exception about unique labels if"
    ],
    [
        "names have the same last part.",
        "names have the same"
    ],
    [
        "The model is reloaded even on changes that are not involved in",
        "The model is reloaded even on changes that are not involved"
    ],
    [
        "relations. Other models pointing to or from it are also reloaded.",
        "relations. Other models pointing to or from it"
    ],
    [
        "self.assertEqual([r.related_model for r in A._meta.related_objects], [B])",
        "self.assertEqual([r.related_model for r"
    ],
    [
        "self.assertEqual([r.related_model for r in B._meta.related_objects], [C])",
        "self.assertEqual([r.related_model for r in B._meta.related_objects],"
    ],
    [
        "self.assertEqual([r.related_model for r in C._meta.related_objects], [])",
        "self.assertEqual([r.related_model for r"
    ],
    [
        "self.assertEqual([r.related_model for r in A._meta.related_objects], [B])",
        "self.assertEqual([r.related_model for r"
    ],
    [
        "self.assertEqual([r.related_model for r in B._meta.related_objects], [C])",
        "self.assertEqual([r.related_model for r in B._meta.related_objects],"
    ],
    [
        "self.assertEqual([r.related_model for r in C._meta.related_objects], [])",
        "self.assertEqual([r.related_model for r in C._meta.related_objects],"
    ],
    [
        "remaining the relations and references for models of an old state.",
        "remaining the relations and references for models of"
    ],
    [
        "mod for mod in state.apps.get_models() if mod._meta.model_name == \"a\"",
        "mod for mod in state.apps.get_models() if mod._meta.model_name =="
    ],
    [
        "mod for mod in state.apps.get_models() if mod._meta.model_name == \"a\"",
        "mod for mod in state.apps.get_models() if"
    ],
    [
        "== and != are implemented correctly.",
        "== and != are"
    ],
    [
        "\"The field migrations.Book.author was declared with a lazy reference \"",
        "\"The field migrations.Book.author was declared with a"
    ],
    [
        "\"to 'migrations.author', but app 'migrations' doesn't provide model \"",
        "\"to 'migrations.author', but app 'migrations' doesn't provide model"
    ],
    [
        "\"The field migrations.Book.publisher was declared with a lazy reference \"",
        "\"The field migrations.Book.publisher was declared"
    ],
    [
        "\"to 'migrations.publisher', but app 'migrations' doesn't provide model \"",
        "\"to 'migrations.publisher', but app 'migrations' doesn't provide model"
    ],
    [
        "\"The field migrations.Magazine.authors was declared with a lazy reference \"",
        "\"The field migrations.Magazine.authors was declared with a lazy"
    ],
    [
        "\"to 'migrations.author', but app 'migrations' doesn't provide model \"",
        "\"to 'migrations.author', but app 'migrations' doesn't provide"
    ],
    [
        "\"The field migrations.Magazine_authors.author was declared with a lazy \"",
        "\"The field migrations.Magazine_authors.author was declared"
    ],
    [
        "\"reference to 'migrations.author', but app 'migrations' doesn't provide \"",
        "\"reference to 'migrations.author', but app 'migrations' doesn't"
    ],
    [
        "\"The field migrations.Book.author was declared with a lazy reference \"",
        "\"The field migrations.Book.author was declared with a lazy reference"
    ],
    [
        "\"to 'migrations.author', but app 'migrations' doesn't provide model \"",
        "\"to 'migrations.author', but app 'migrations' doesn't provide model"
    ],
    [
        "\"The field migrations.Book.publisher was declared with a lazy reference \"",
        "\"The field migrations.Book.publisher was declared with a"
    ],
    [
        "\"to 'migrations.publisher', but app 'migrations' doesn't provide model \"",
        "\"to 'migrations.publisher', but app 'migrations'"
    ],
    [
        "\"The field migrations.Magazine.authors was declared with a lazy reference \"",
        "\"The field migrations.Magazine.authors was declared"
    ],
    [
        "\"to 'migrations.author', but app 'migrations' doesn't provide model \"",
        "\"to 'migrations.author', but app 'migrations' doesn't"
    ],
    [
        "\"The field migrations.Magazine_authors.author was declared with a lazy \"",
        "\"The field migrations.Magazine_authors.author was declared with"
    ],
    [
        "\"reference to 'migrations.author', but app 'migrations' doesn't provide \"",
        "\"reference to 'migrations.author', but app 'migrations' doesn't provide"
    ],
    [
        "Including real apps can resolve dangling FK errors.",
        "Including real apps can resolve"
    ],
    [
        "This test relies on the fact that contenttypes is always loaded.",
        "This test relies on the fact that contenttypes is always"
    ],
    [
        "Makes sure ProjectState doesn't include OrderWrt fields when",
        "Makes sure ProjectState doesn't include"
    ],
    [
        "choices = [(\"a\", \"A\"), (\"b\", \"B\")]",
        "choices = [(\"a\", \"A\"),"
    ],
    [
        "[(\"tests\", \"comment\"), (\"tests\", \"post\"), (\"tests_other\", \"comment\")],",
        "[(\"tests\", \"comment\"), (\"tests\", \"post\"), (\"tests_other\","
    ],
    [
        "ValueError, 'ModelState.fields cannot be bound to a model - \"field\" is.'",
        "ValueError, 'ModelState.fields cannot be bound to a model"
    ],
    [
        "'Model fields in \"ModelState.fields\" cannot refer to a model class - '",
        "'Model fields in \"ModelState.fields\" cannot refer to"
    ],
    [
        "'\"app.Model.field.to\" does. Use a string reference instead.',",
        "'\"app.Model.field.to\" does. Use a string"
    ],
    [
        "'Model fields in \"ModelState.fields\" cannot refer to a model class - '",
        "'Model fields in \"ModelState.fields\" cannot refer"
    ],
    [
        "'\"app.Model.field.through\" does. Use a string reference instead.',",
        "'\"app.Model.field.through\" does. Use a string reference"
    ],
    [
        "\"Indexes passed to ModelState require a name attribute. <Index: \"",
        "\"Indexes passed to ModelState require a name attribute."
    ],
    [
        "Rendering a model state doesn't alter its internal fields.",
        "Rendering a model state doesn't alter"
    ],
    [
        "state = ModelState(\"app\", \"Model\", [(\"name\", field)])",
        "state = ModelState(\"app\", \"Model\","
    ],
    [
        "\"app\", \"Model\", [(\"name\", field)], bases=[\"app.A\", \"app.B\", \"app.C\"]",
        "\"app\", \"Model\", [(\"name\", field)],"
    ],
    [
        "InvalidBasesError, \"Cannot resolve bases for [<ModelState: 'app.Model'>]\"",
        "InvalidBasesError, \"Cannot resolve bases for"
    ],
    [
        "Tests making a ProjectState from an Apps with a swappable model",
        "Tests making a ProjectState from an Apps"
    ],
    [
        "{\"swappable\": \"TEST_SWAPPABLE_MODEL\", \"indexes\": [], \"constraints\": []},",
        "{\"swappable\": \"TEST_SWAPPABLE_MODEL\", \"indexes\": [], \"constraints\":"
    ],
    [
        "A swappable model inheriting from a hierarchy:",
        "A swappable model inheriting"
    ],
    [
        "Tests making a ProjectState from unused models with custom managers",
        "Tests making a ProjectState from"
    ],
    [
        "self.assertEqual([name for name, mgr in food_state.managers], [\"food_mgr\"])",
        "self.assertEqual([name for name, mgr in food_state.managers],"
    ],
    [
        "index_names = [index.name for index in abstract_state.options[\"indexes\"]]",
        "index_names = [index.name for index in"
    ],
    [
        "index_names = [index.name for index in model_state.options[\"indexes\"]]",
        "index_names = [index.name for index"
    ],
    [
        "self, name, foreign_keys=[], bases=(), abstract=False, proxy=False",
        "self, name, foreign_keys=[], bases=(),"
    ],
    [
        "fname_base = fname = \"%s_%%d\" % name.lower()",
        "fname_base = fname = \"%s_%%d\" %"
    ],
    [
        "{(n._meta.app_label, n._meta.model_name) for n in needle},",
        "{(n._meta.app_label, n._meta.model_name) for n in"
    ],
    [
        "self.assertRelated(A, [B, C, D, E, F])",
        "self.assertRelated(A, [B, C,"
    ],
    [
        "self.assertRelated(B, [A, C, D, E, F])",
        "self.assertRelated(B, [A, C, D,"
    ],
    [
        "self.assertRelated(C, [A, B, D, E, F])",
        "self.assertRelated(C, [A, B,"
    ],
    [
        "self.assertRelated(D, [A, B, C, E, F])",
        "self.assertRelated(D, [A, B, C,"
    ],
    [
        "self.assertRelated(E, [A, B, C, D, F])",
        "self.assertRelated(E, [A, B, C,"
    ],
    [
        "self.assertRelated(F, [A, B, C, D, E])",
        "self.assertRelated(F, [A, B, C,"
    ],
    [
        "Z = self.create_model(\"Z\", bases=(A, M, Q))",
        "Z = self.create_model(\"Z\","
    ],
    [
        "Deprecated model fields should still be usable in historic migrations.",
        "Deprecated model fields should still be usable in"
    ],
    [
        "from django.core.checks import Error, Tags, register",
        "from django.core.checks import Error, Tags,"
    ],
    [
        "from django.core.management.commands.migrate import Command as MigrateCommand",
        "from django.core.management.commands.migrate import Command"
    ],
    [
        "from django.test import TestCase, override_settings, skipUnlessDBFeature",
        "from django.test import TestCase, override_settings,"
    ],
    [
        "from django.test.utils import captured_stdout, extend_sys_path, isolate_apps",
        "from django.test.utils import"
    ],
    [
        "Tests basic usage of the migrate command.",
        "Tests basic usage of the"
    ],
    [
        "self.assertIn(\"Running pre-migrate handlers for application migrations\", stdout)",
        "self.assertIn(\"Running pre-migrate handlers for"
    ],
    [
        "\"Running post-migrate handlers for application migrations\", stdout",
        "\"Running post-migrate handlers for"
    ],
    [
        "self.assertIn(\"Running pre-migrate handlers for application migrations\", stdout)",
        "self.assertIn(\"Running pre-migrate handlers for application"
    ],
    [
        "\"Running post-migrate handlers for application migrations\", stdout",
        "\"Running post-migrate handlers for"
    ],
    [
        "msg = \"App 'unmigrated_app_syncdb' does not have migrations.\"",
        "msg = \"App 'unmigrated_app_syncdb' does not"
    ],
    [
        "\"More than one migration matches 'a' in app 'migrations'. Please \"",
        "\"More than one migration matches 'a' in"
    ],
    [
        "msg = \"Cannot find a migration matching 'nonexistent' from app 'migrations'.\"",
        "msg = \"Cannot find a migration matching 'nonexistent'"
    ],
    [
        "`Migration.initial = False` skips fake-initial detection.",
        "`Migration.initial = False` skips"
    ],
    [
        "--fake-initial only works if all tables created in the initial",
        "--fake-initial only works if all tables"
    ],
    [
        "migration of an app exists. Database routers must be obeyed when doing",
        "migration of an app exists. Database routers must"
    ],
    [
        "Split initial migrations can be faked with --fake-initial.",
        "Split initial migrations can"
    ],
    [
        "migrate exits if it detects a conflict.",
        "migrate exits if it"
    ],
    [
        "\"Conflicting migrations detected; multiple leaf nodes in the \"",
        "\"Conflicting migrations detected; multiple leaf"
    ],
    [
        "\"To fix them run 'python manage.py makemigrations --merge'\"",
        "\"To fix them run"
    ],
    [
        "\"    Raw Python operation -> Grow salamander tail.\\n\",",
        "\" Raw Python operation -> Grow salamander"
    ],
    [
        "showmigrations --list  displays migrations and whether or not they're",
        "showmigrations --list displays migrations and"
    ],
    [
        "\"running pre-migrate handlers for application migrations\\n\"",
        "\"running pre-migrate handlers for"
    ],
    [
        "Tests --plan output of showmigrations command",
        "Tests --plan output"
    ],
    [
        "\"    Raw Python operation -> Grow salamander tail.\\n\"",
        "\" Raw Python operation"
    ],
    [
        "\"    Raw SQL operation -> ['SELECT * FROM migrations_book']\\n\"",
        "\" Raw SQL operation -> ['SELECT * FROM"
    ],
    [
        "\"    Raw SQL operation -> ['SELECT * FROM migrations_author']\\n\",",
        "\" Raw SQL operation -> ['SELECT * FROM"
    ],
    [
        "\"Planned operations:\\n  No planned migration operations.\\n\",",
        "\"Planned operations:\\n No planned"
    ],
    [
        "\"    Raw SQL operation -> ['SELECT * FROM migrations_book']\\n\"",
        "\" Raw SQL operation -> ['SELECT * FROM"
    ],
    [
        "\"    Raw SQL operation -> ['SELECT * FROM migrations_salamand…\\n\",",
        "\" Raw SQL operation -> ['SELECT *"
    ],
    [
        "\"    Raw SQL operation -> SELECT * FROM migrations_author WHE…\\n\",",
        "\" Raw SQL operation -> SELECT *"
    ],
    [
        "\"    Raw SQL operation -> IRREVERSIBLE\\n\",",
        "\" Raw SQL"
    ],
    [
        "\"    Raw Python operation -> Feed salamander.\\n\",",
        "\" Raw Python operation ->"
    ],
    [
        "\"    Raw Python operation -> IRREVERSIBLE\\n\"",
        "\" Raw Python"
    ],
    [
        "\"    Raw Python operation -> IRREVERSIBLE\\n\"",
        "\" Raw Python operation"
    ],
    [
        "Tests --plan output of showmigrations command without migrations",
        "Tests --plan output of"
    ],
    [
        "Tests --plan output of showmigrations command with squashed migrations.",
        "Tests --plan output of showmigrations command"
    ],
    [
        "`showmigrations --plan app_label` output with a single app_label.",
        "`showmigrations --plan app_label` output with a"
    ],
    [
        "`showmigrations --plan app_label` output with multiple app_labels.",
        "`showmigrations --plan app_label` output with"
    ],
    [
        "\"-- Add field bool to tribble\",",
        "\"-- Add field bool"
    ],
    [
        "\"-- Add field bool to tribble\",",
        "\"-- Add field"
    ],
    [
        "Transaction wrappers aren't shown for non-atomic migrations.",
        "Transaction wrappers aren't shown"
    ],
    [
        "queries = [q.strip() for q in output.splitlines()]",
        "queries = [q.strip() for q"
    ],
    [
        "Transaction wrappers aren't shown for databases that don't support",
        "Transaction wrappers aren't shown for databases"
    ],
    [
        "queries = [q.strip() for q in output.splitlines()]",
        "queries = [q.strip() for q in"
    ],
    [
        "\"-- THIS OPERATION CANNOT BE WRITTEN AS SQL\",",
        "\"-- THIS OPERATION CANNOT BE"
    ],
    [
        "* `B` has a migration we want to apply",
        "* `B` has a migration"
    ],
    [
        "* `C` has no migrations, but has an FK to `A`",
        "* `C` has no migrations, but has"
    ],
    [
        "When we try to migrate \"B\", an exception occurs because the",
        "When we try to migrate \"B\", an exception"
    ],
    [
        "\"B\" was not included in the ProjectState that is used to detect",
        "\"B\" was not included in the ProjectState"
    ],
    [
        "For an app without migrations, editor.execute() is used for executing",
        "For an app without migrations,"
    ],
    [
        "[call for call in execute.mock_calls if \"CREATE TABLE\" in str(call)]",
        "[call for call in execute.mock_calls if \"CREATE TABLE\" in"
    ],
    [
        "self.assertIn(\"Creating table %s\" % table_name, stdout)",
        "self.assertIn(\"Creating table %s\""
    ],
    [
        "msg = \"Can't use run_syncdb with app 'migrations' as it has migrations.\"",
        "msg = \"Can't use run_syncdb with"
    ],
    [
        "Running migrate --run-syncdb with an app_label only creates tables for",
        "Running migrate --run-syncdb with an app_label only creates"
    ],
    [
        "[call for call in execute.mock_calls if \"CREATE TABLE\" in str(call)]",
        "[call for call in execute.mock_calls if \"CREATE TABLE\" in"
    ],
    [
        "Running a single squashed migration should record all of the original",
        "Running a single squashed migration should"
    ],
    [
        "Running migrate for a squashed migration should record as run",
        "Running migrate for a squashed migration should record"
    ],
    [
        "\"run 'manage.py migrate' to finish recording.\\n\",",
        "\"run 'manage.py migrate' to"
    ],
    [
        "Migrating to a squashed migration specified by name should succeed",
        "Migrating to a squashed migration specified by name"
    ],
    [
        "even if it is partially applied.",
        "even if it"
    ],
    [
        "Running migrate with some migrations applied before their dependencies",
        "Running migrate with some migrations applied before their"
    ],
    [
        "\"  apply all migrations: migrated_app, migrated_unapplied_app\\n\"",
        "\" apply all migrations:"
    ],
    [
        "\"  your models in app(s): 'migrated_app', \"",
        "\" your models in app(s):"
    ],
    [
        "\"'migrated_unapplied_app' have changes that are not yet \"",
        "\"'migrated_unapplied_app' have changes that"
    ],
    [
        "\"reflected in a migration, and so won't be applied.\\n\"",
        "\"reflected in a migration, and so won't be"
    ],
    [
        "\"  run 'manage.py makemigrations' to make new migrations, and \"",
        "\" run 'manage.py makemigrations' to make new"
    ],
    [
        "\"then re-run 'manage.py migrate' to apply them.\\n\",",
        "\"then re-run 'manage.py migrate' to apply"
    ],
    [
        "With prune=True, references to migration files deleted from the",
        "With prune=True, references to migration"
    ],
    [
        "migrations module (such as after being squashed) are removed from the",
        "migrations module (such as after being squashed) are removed from"
    ],
    [
        "\"  Cannot use --prune because the following squashed \"",
        "\" Cannot use --prune because the"
    ],
    [
        "\"migrations have their 'replaces' attributes and may not \"",
        "\"migrations have their 'replaces' attributes and may"
    ],
    [
        "\"  Re-run 'manage.py migrate' if they are not marked as \"",
        "\" Re-run 'manage.py migrate' if they are"
    ],
    [
        "\"applied, and remove 'replaces' attributes in their \"",
        "\"applied, and remove 'replaces' attributes in their"
    ],
    [
        "\"Pruning migrations:\\n  No migrations to prune.\\n\",",
        "\"Pruning migrations:\\n No migrations to"
    ],
    [
        "msg = \"Migrations can be pruned only when an app is specified.\"",
        "msg = \"Migrations can be pruned only when"
    ],
    [
        "The history consistency checks in makemigrations respect",
        "The history consistency checks in makemigrations"
    ],
    [
        "makemigrations exits if it detects a conflict.",
        "makemigrations exits if it detects a"
    ],
    [
        "\"Conflicting migrations detected; multiple leaf nodes in the \"",
        "\"Conflicting migrations detected; multiple leaf"
    ],
    [
        "\"To fix them run 'python manage.py makemigrations --merge'\",",
        "\"To fix them run"
    ],
    [
        "makemigrations exits if in merge mode with no conflicts.",
        "makemigrations exits if in merge mode"
    ],
    [
        "self.assertIn(\"No conflicts detected to merge.\", out.getvalue())",
        "self.assertIn(\"No conflicts detected"
    ],
    [
        "makemigrations exits if no app is specified with 'empty' mode.",
        "makemigrations exits if no app is specified"
    ],
    [
        "msg = \"You must supply at least one app label when using --empty.\"",
        "msg = \"You must supply at least one app label when using"
    ],
    [
        "makemigrations properly constructs an empty migration.",
        "makemigrations properly constructs an empty"
    ],
    [
        "\"dependencies=[]\" if HAS_BLACK else \"dependencies=[\\n]\", content",
        "\"dependencies=[]\" if HAS_BLACK else \"dependencies=[\\n]\","
    ],
    [
        "\"operations=[]\" if HAS_BLACK else \"operations=[\\n]\", content",
        "\"operations=[]\" if HAS_BLACK"
    ],
    [
        "makemigrations raises a nice error when migrations are disabled for an",
        "makemigrations raises a nice error when migrations"
    ],
    [
        "\"Django can't create migrations for app 'migrations' because migrations \"",
        "\"Django can't create migrations for app 'migrations' because migrations"
    ],
    [
        "\"have been disabled via the MIGRATION_MODULES setting.\"",
        "\"have been disabled via the"
    ],
    [
        "makemigrations exits when there are no changes and no apps are specified.",
        "makemigrations exits when there are no changes and"
    ],
    [
        "makemigrations exits when there are no changes to an app.",
        "makemigrations exits when there are no changes to"
    ],
    [
        "self.assertIn(\"No changes detected in app 'migrations'\", out.getvalue())",
        "self.assertIn(\"No changes detected in"
    ],
    [
        "makemigrations should detect initial is needed on empty migration",
        "makemigrations should detect initial is"
    ],
    [
        "\"\"\"Migration directories without an __init__.py file are allowed.\"\"\"",
        "\"\"\"Migration directories without an __init__.py"
    ],
    [
        "Migration directories without an __init__.py file are not allowed if",
        "Migration directories without an __init__.py file are not allowed"
    ],
    [
        "there are multiple namespace search paths that resolve to them.",
        "there are multiple namespace search paths that resolve"
    ],
    [
        "makemigrations announces the migration at the default verbosity level.",
        "makemigrations announces the migration at the default"
    ],
    [
        "makemigrations fails to merge migrations with no common ancestor.",
        "makemigrations fails to merge migrations with no common"
    ],
    [
        "self.assertIn(\"Could not find common ancestor of\", exception_message)",
        "self.assertIn(\"Could not find common ancestor of\","
    ],
    [
        "makemigrations enters and exits interactive mode properly.",
        "makemigrations enters and exits"
    ],
    [
        "makemigrations enters interactive mode and merges properly.",
        "makemigrations enters interactive mode and"
    ],
    [
        "self.assertIn(\"Created new merge migration %s\" % merge_file, out.getvalue())",
        "self.assertIn(\"Created new merge migration"
    ],
    [
        "Non-interactive makemigrations fails when a default is missing on a",
        "Non-interactive makemigrations fails when a default"
    ],
    [
        "\"Field 'silly_int' on model 'sillymodel' not migrated: it is \"",
        "\"Field 'silly_int' on model 'sillymodel' not migrated: it"
    ],
    [
        "\"impossible to add a non-nullable field without specifying a \"",
        "\"impossible to add a non-nullable"
    ],
    [
        "makemigrations messages when adding a NOT NULL field in interactive",
        "makemigrations messages when adding a NOT NULL field in"
    ],
    [
        "\"It is impossible to add a non-nullable field 'silly_field' to \"",
        "\"It is impossible to add a"
    ],
    [
        "\"author without specifying a default. This is because the \"",
        "\"author without specifying a default. This is because the"
    ],
    [
        "\"database needs something to populate existing rows.\\n\"",
        "\"database needs something to populate"
    ],
    [
        "\"rows with a null value for this column)\\n\"",
        "\"rows with a null value for this"
    ],
    [
        "self.assertIn(\"Please enter the default value as valid Python.\", output)",
        "self.assertIn(\"Please enter the default value as valid Python.\","
    ],
    [
        "\"The datetime and django.utils.timezone modules are \"",
        "\"The datetime and django.utils.timezone"
    ],
    [
        "\"available, so it is possible to provide e.g. timezone.now as \"",
        "\"available, so it is possible to provide"
    ],
    [
        "self.assertIn(\"Type 'exit' to exit this prompt\", output)",
        "self.assertIn(\"Type 'exit' to exit this prompt\","
    ],
    [
        "Non-interactive makemigrations fails when a default is missing on a",
        "Non-interactive makemigrations fails when a"
    ],
    [
        "self.assertIn(\"Alter field slug on author\", out.getvalue())",
        "self.assertIn(\"Alter field slug on author\","
    ],
    [
        "\"Field 'slug' on model 'author' given a default of NOT PROVIDED \"",
        "\"Field 'slug' on model 'author' given a default of"
    ],
    [
        "makemigrations messages when changing a NULL field to NOT NULL in",
        "makemigrations messages when changing a NULL"
    ],
    [
        "\"It is impossible to change a nullable field 'slug' on author to \"",
        "\"It is impossible to change a nullable field 'slug' on"
    ],
    [
        "\"non-nullable without providing a default. This is because the \"",
        "\"non-nullable without providing a default. This is because the"
    ],
    [
        "\"database needs something to populate existing rows.\\n\"",
        "\"database needs something to"
    ],
    [
        "\"rows with a null value for this column)\\n\"",
        "\"rows with a null value for this"
    ],
    [
        "\"have to be handled manually, for example with a RunPython or \"",
        "\"have to be handled manually, for example"
    ],
    [
        "self.assertIn(\"Please enter the default value as valid Python.\", output)",
        "self.assertIn(\"Please enter the default value as valid"
    ],
    [
        "\"The datetime and django.utils.timezone modules are \"",
        "\"The datetime and django.utils.timezone"
    ],
    [
        "\"available, so it is possible to provide e.g. timezone.now as \"",
        "\"available, so it is possible to provide e.g. timezone.now"
    ],
    [
        "self.assertIn(\"Type 'exit' to exit this prompt\", output)",
        "self.assertIn(\"Type 'exit' to exit this"
    ],
    [
        "makemigrations adds and removes a possible model rename in",
        "makemigrations adds and removes a possible model"
    ],
    [
        "makemigrations adds and removes a possible field rename in",
        "makemigrations adds and removes a possible"
    ],
    [
        "self.assertIn(\"Remove field silly_field from sillymodel\", out.getvalue())",
        "self.assertIn(\"Remove field silly_field from"
    ],
    [
        "self.assertIn(\"Add field silly_rename to sillymodel\", out.getvalue())",
        "self.assertIn(\"Add field silly_rename to sillymodel\","
    ],
    [
        "self.assertIn(\"Rename model SillyModel to RenamedModel\", out.getvalue())",
        "self.assertIn(\"Rename model SillyModel to"
    ],
    [
        "\"Rename field silly_field on sillymodel to silly_rename\",",
        "\"Rename field silly_field on"
    ],
    [
        "makemigrations properly merges the conflicting migrations with --noinput.",
        "makemigrations properly merges the conflicting migrations"
    ],
    [
        "makemigrations respects --dry-run option when fixing migration",
        "makemigrations respects --dry-run option when"
    ],
    [
        "`makemigrations --merge --dry-run` writes the merge migration file to",
        "`makemigrations --merge --dry-run` writes the merge"
    ],
    [
        "`makemigrations --dry-run` should not ask for defaults.",
        "`makemigrations --dry-run` should not ask"
    ],
    [
        "self.assertIn(\"Add field silly_date to sillymodel\", out.getvalue())",
        "self.assertIn(\"Add field silly_date to sillymodel\","
    ],
    [
        "Allow `makemigrations --dry-run` to output the migrations file to",
        "Allow `makemigrations --dry-run` to output"
    ],
    [
        "self.assertIn(\"+ Add field silly_char to sillymodel\", out.getvalue())",
        "self.assertIn(\"+ Add field silly_char"
    ],
    [
        "With scriptable=True, log output is diverted to stderr, and only the",
        "With scriptable=True, log output is diverted to stderr,"
    ],
    [
        "paths of generated migration files are written to stdout.",
        "paths of generated migration files"
    ],
    [
        "self.assertIn(\"    + Create model ModelWithCustomBase\\n\", err.getvalue())",
        "self.assertIn(\" + Create model"
    ],
    [
        "self.assertIn(f\"Created new merge migration {merge_file}\", err.getvalue())",
        "self.assertIn(f\"Created new merge migration"
    ],
    [
        "makemigrations creates migrations when specifying a custom location",
        "makemigrations creates migrations when specifying a"
    ],
    [
        "for migration files using MIGRATION_MODULES if the custom path",
        "for migration files using MIGRATION_MODULES"
    ],
    [
        "self.assertIn(\" + Create model SillyModel\", out.getvalue())",
        "self.assertIn(\" + Create model SillyModel\","
    ],
    [
        "\"Could not locate an appropriate location to create migrations \"",
        "\"Could not locate an appropriate"
    ],
    [
        "\"package some.nonexistent.path. Make sure the toplevel package \"",
        "\"package some.nonexistent.path. Make sure the toplevel"
    ],
    [
        "The user is prompted to merge by default if there are conflicts and",
        "The user is prompted to merge by"
    ],
    [
        "merge is True. Answer negative to differentiate it from behavior when",
        "merge is True. Answer negative to"
    ],
    [
        "makemigrations does not raise a CommandError when an unspecified app",
        "makemigrations does not raise a CommandError"
    ],
    [
        "makemigrations does not create a merge for an unspecified app even if",
        "makemigrations does not create a merge for an unspecified app"
    ],
    [
        "self.assertIn(\"No conflicts detected to merge.\", out.getvalue())",
        "self.assertIn(\"No conflicts detected to"
    ],
    [
        "makemigrations --merge does not output any operations from apps that",
        "makemigrations --merge does not output"
    ],
    [
        "don't belong to a given app.",
        "don't belong to a"
    ],
    [
        "\"    - remove field silly_field from author\\n\"",
        "\" - remove field"
    ],
    [
        "\"    + add field rating to author\\n\"",
        "\" + add field"
    ],
    [
        "\"merging will only work if the operations printed above do not \"",
        "\"merging will only work if the operations printed"
    ],
    [
        "\"with each other (working on different fields or models)\\n\"",
        "\"with each other (working on different fields or"
    ],
    [
        "\"should these migration branches be merged? [y/n] \",",
        "\"should these migration branches be merged?"
    ],
    [
        "makemigrations --name generate a custom migration name.",
        "makemigrations --name generate a custom migration"
    ],
    [
        "\"dependencies=[]\" if HAS_BLACK else \"dependencies=[\\n]\", content",
        "\"dependencies=[]\" if HAS_BLACK"
    ],
    [
        "self.assertIn(\"operations=[]\" if HAS_BLACK else \"operations=[\\n]\", content)",
        "self.assertIn(\"operations=[]\" if HAS_BLACK"
    ],
    [
        "msg = \"The migration name must be a valid Python identifier.\"",
        "msg = \"The migration name must be a valid Python"
    ],
    [
        "\"makemigrations\", \"migrations\", \"--name\", \"invalid name\", \"--empty\"",
        "\"makemigrations\", \"migrations\", \"--name\", \"invalid name\","
    ],
    [
        "makemigrations --check should exit with a non-zero status when",
        "makemigrations --check should exit with a"
    ],
    [
        "there are changes to an app requiring migrations.",
        "there are changes to an"
    ],
    [
        "makemigrations --check should exit with a zero status when there are no",
        "makemigrations --check should exit with a zero status when there are"
    ],
    [
        "self.assertEqual(\"No changes detected in app 'migrations'\\n\", out.getvalue())",
        "self.assertEqual(\"No changes detected in app 'migrations'\\n\","
    ],
    [
        "makemigrations should print the relative paths to the migrations unless",
        "makemigrations should print the relative"
    ],
    [
        "they are outside of the current tree, in which case the absolute path",
        "they are outside of the current tree, in"
    ],
    [
        "makemigrations prints the absolute path if os.path.relpath() raises a",
        "makemigrations prints the absolute path if os.path.relpath() raises"
    ],
    [
        "ValueError when it's impossible to obtain a relative path, e.g. on",
        "ValueError when it's impossible to obtain"
    ],
    [
        "Windows if Django is installed on a different drive than where the",
        "Windows if Django is installed on"
    ],
    [
        "makemigrations should raise InconsistentMigrationHistory exception if",
        "makemigrations should raise InconsistentMigrationHistory"
    ],
    [
        "there are some migrations applied before their dependencies.",
        "there are some migrations"
    ],
    [
        "\"Got an error checking a consistent migration history performed \"",
        "\"Got an error checking a consistent"
    ],
    [
        "\"for database connection 'default': could not connect to server\"",
        "\"for database connection 'default': could"
    ],
    [
        "makemigrations prompts the user when adding auto_now_add to an existing",
        "makemigrations prompts the user when adding auto_now_add to"
    ],
    [
        "\"It is impossible to add the field 'creation_date' with \"",
        "\"It is impossible to add the"
    ],
    [
        "\"'auto_now_add=True' to entry without providing a default. This \"",
        "\"'auto_now_add=True' to entry without providing"
    ],
    [
        "\"is because the database needs something to populate existing \"",
        "\"is because the database needs"
    ],
    [
        "self.assertIn(\"Please enter the default value as valid Python.\", prompt_output)",
        "self.assertIn(\"Please enter the default value as"
    ],
    [
        "\"Accept the default 'timezone.now' by pressing 'Enter' or provide \"",
        "\"Accept the default 'timezone.now' by pressing"
    ],
    [
        "self.assertIn(\"Type 'exit' to exit this prompt\", prompt_output)",
        "self.assertIn(\"Type 'exit' to exit this"
    ],
    [
        "self.assertIn(\"Add field creation_date to entry\", prompt_output)",
        "self.assertIn(\"Add field creation_date"
    ],
    [
        "Non-interactive makemigrations fails when a default is missing on a",
        "Non-interactive makemigrations fails when a default is missing on"
    ],
    [
        "\"Field 'creation_date' on model 'entry' not migrated: it is \"",
        "\"Field 'creation_date' on model 'entry' not"
    ],
    [
        "\"impossible to add a field with 'auto_now_add=True' without \"",
        "\"impossible to add a field"
    ],
    [
        "makemigrations prompts the user when adding a unique field with",
        "makemigrations prompts the user when adding a"
    ],
    [
        "f\"Callable default on unique field book.created will not generate \"",
        "f\"Callable default on unique field book.created will not"
    ],
    [
        "f\"a manual migration to generate unique values described here: \"",
        "f\"a manual migration to generate unique values described here:"
    ],
    [
        "self.assertNotIn(\"Add field created to book\", out_value)",
        "self.assertNotIn(\"Add field created to book\","
    ],
    [
        "self.assertIn(\"Add field created to book\", out_value)",
        "self.assertIn(\"Add field created to book\","
    ],
    [
        "self.assertIn(\"Add field created to book\", out_value)",
        "self.assertIn(\"Add field created to book\","
    ],
    [
        "msg = \"App migrations has no migration, cannot update last migration.\"",
        "msg = \"App migrations has no migration, cannot update last"
    ],
    [
        "f\"Updated migration {updated_migration_file} requires manual porting.\\n\"",
        "f\"Updated migration {updated_migration_file}"
    ],
    [
        "f\"Previous migration {previous_migration_file} was kept and must be \"",
        "f\"Previous migration {previous_migration_file} was kept"
    ],
    [
        "\"  You should commit this migration but leave the old ones in place;\\n\"",
        "\" You should commit this migration but leave the"
    ],
    [
        "\"  the new migration will be used for new installs. Once you are sure\\n\"",
        "\" the new migration will be used for new installs. Once you are"
    ],
    [
        "\"  all instances of the codebase have applied the migrations you \"",
        "\" all instances of the codebase have applied the"
    ],
    [
        "\"  you can delete them.\\n\" % squashed_migration_file,",
        "\" you can delete"
    ],
    [
        "r\"Cyclical squash replacement found, starting at\"",
        "r\"Cyclical squash replacement found, starting"
    ],
    [
        "Replacement migrations are partially applied. Then we squash again and",
        "Replacement migrations are partially applied. Then"
    ],
    [
        "verify that only unapplied migrations will be applied by \"migrate\".",
        "verify that only unapplied migrations will be applied"
    ],
    [
        "All recursively replaced migrations should be recorded/unrecorded, when",
        "All recursively replaced migrations should"
    ],
    [
        "migrating an app with double squashed migrations.",
        "migrating an app with"
    ],
    [
        "app_label for app_label, _ in recorder.applied_migrations()",
        "app_label for app_label,"
    ],
    [
        "app_label for app_label, _ in recorder.applied_migrations()",
        "app_label for app_label, _ in"
    ],
    [
        "squashmigrations doesn't accept a starting migration after the ending migration.",
        "squashmigrations doesn't accept a starting migration after the ending"
    ],
    [
        "\"\"\"--squashed-name specifies the new migration's name.\"\"\"",
        "\"\"\"--squashed-name specifies the"
    ],
    [
        "\"\"\"--squashed-name also works if a start migration is omitted.\"\"\"",
        "\"\"\"--squashed-name also works if a start"
    ],
    [
        "\"Squashed migration couldn't be formatted using the \"",
        "\"Squashed migration couldn't be formatted"
    ],
    [
        "'\"black\" command. You can call it manually.\\n'",
        "'\"black\" command. You can"
    ],
    [
        "f\"  You should commit this migration but leave the old ones in place;\\n\"",
        "f\" You should commit this migration but"
    ],
    [
        "f\"  the new migration will be used for new installs. Once you are sure\\n\"",
        "f\" the new migration will be used for new installs. Once you are"
    ],
    [
        "f\"  all instances of the codebase have applied the migrations you \"",
        "f\" all instances of the codebase have applied the migrations you"
    ],
    [
        "f\"  Your migrations contained functions that must be manually copied \"",
        "f\" Your migrations contained functions that"
    ],
    [
        "f\"  as we could not safely copy their implementation.\\n\"",
        "f\" as we could not safely"
    ],
    [
        "f\"  See the comment at the top of the squashed migration for details.\\n\"",
        "f\" See the comment at the top of the"
    ],
    [
        "This class inherits TestCase because MigrationTestBase uses",
        "This class inherits TestCase because"
    ],
    [
        "`available_apps = ['migrations']` which means that it's the only installed",
        "`available_apps = ['migrations']` which means that it's"
    ],
    [
        "app. 'django.contrib.auth' must be in INSTALLED_APPS for some of these",
        "app. 'django.contrib.auth' must be in INSTALLED_APPS for"
    ],
    [
        "nonexistent_app_error = \"No installed app with label 'nonexistent_app'.\"",
        "nonexistent_app_error = \"No installed app with"
    ],
    [
        "\"No installed app with label 'django.contrib.auth'. Did you mean 'auth'?\"",
        "\"No installed app with label 'django.contrib.auth'. Did"
    ],
    [
        "\"Optimized migration couldn't be formatted using the \"",
        "\"Optimized migration couldn't be"
    ],
    [
        "'\"black\" command. You can call it manually.\\n'",
        "'\"black\" command. You can call it"
    ],
    [
        "\"  Your migrations contained functions that must be manually copied over,\\n\"",
        "\" Your migrations contained functions that must be manually"
    ],
    [
        "\"  as we could not safely copy their implementation.\\n\"",
        "\" as we could not safely"
    ],
    [
        "\"  See the comment at the top of the optimized migration for details.\\n\"",
        "\" See the comment at the top of"
    ],
    [
        "f\"Migration will require manual porting but is already a squashed \"",
        "f\"Migration will require manual porting but is"
    ],
    [
        "f\"migration.\\nTransition to a normal migration first: \"",
        "f\"migration.\\nTransition to a normal migration first:"
    ],
    [
        "msg = \"App 'unmigrated_app_simple' does not have migrations.\"",
        "msg = \"App 'unmigrated_app_simple' does"
    ],
    [
        "\"More than one migration matches 'a' in app 'migrations'. Please \"",
        "\"More than one migration matches 'a' in"
    ],
    [
        "msg = \"Cannot find a migration matching 'nonexistent' from app 'migrations'.\"",
        "msg = \"Cannot find a migration matching 'nonexistent'"
    ],
    [
        "from django.db import connection, migrations, models",
        "from django.db import connection, migrations,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "return (self.__module__ + \".\" + self.__class__.__name__, self.args, self.kwargs)",
        "return (self.__module__ + \".\""
    ],
    [
        "output += \"  %s:\\n\" % app_label",
        "output += \" %s:\\n\""
    ],
    [
        "output += \"    %s\\n\" % migration.name",
        "output += \""
    ],
    [
        "output += \"      %s\\n\" % operation",
        "output += \""
    ],
    [
        "output += \"        %s\\n\" % (dep,)",
        "output += \""
    ],
    [
        "\"Incorrect number of migrations (%s) for %s (expected %s)\\n%s\"",
        "\"Incorrect number of migrations (%s) for"
    ],
    [
        "def assertMigrationDependencies(self, changes, app_label, position, dependencies):",
        "def assertMigrationDependencies(self, changes,"
    ],
    [
        "\"No migration at index %s for %s\\n%s\"",
        "\"No migration at index"
    ],
    [
        "\"Migration dependencies mismatch for %s.%s (expected %s):\\n%s\"",
        "\"Migration dependencies mismatch for %s.%s (expected"
    ],
    [
        "def assertOperationTypes(self, changes, app_label, position, types):",
        "def assertOperationTypes(self, changes, app_label,"
    ],
    [
        "\"No migration at index %s for %s\\n%s\"",
        "\"No migration at index %s"
    ],
    [
        "\"Operation type mismatch for %s.%s (expected %s):\\n%s\"",
        "\"Operation type mismatch for %s.%s (expected"
    ],
    [
        "self, changes, app_label, position, operation_position, **attrs",
        "self, changes, app_label, position, operation_position,"
    ],
    [
        "\"No migration at index %s for %s\\n%s\"",
        "\"No migration at index %s for"
    ],
    [
        "\"No operation at index %s for %s.%s\\n%s\"",
        "\"No operation at index %s for"
    ],
    [
        "if getattr(operation, attr, None) != value:",
        "if getattr(operation, attr, None)"
    ],
    [
        "self, changes, app_label, position, operation_position, **attrs",
        "self, changes, app_label, position, operation_position,"
    ],
    [
        "\"No migration at index %s for %s\\n%s\"",
        "\"No migration at index %s for"
    ],
    [
        "\"No operation at index %s for %s.%s\\n%s\"",
        "\"No operation at index"
    ],
    [
        "if getattr(field, attr, None) != value:",
        "if getattr(field, attr, None) !="
    ],
    [
        "\"Shortcut to make ProjectStates from lists of predefined models\"",
        "\"Shortcut to make ProjectStates from lists of predefined"
    ],
    [
        "\"testapp\", \"AuthorProxy\", [], {\"proxy\": True}, (\"testapp.author\",)",
        "\"testapp\", \"AuthorProxy\", [],"
    ],
    [
        "\"thirdapp\", \"AuthorProxy\", [], {\"proxy\": True}, (\"testapp.author\",)",
        "\"thirdapp\", \"AuthorProxy\", [], {\"proxy\":"
    ],
    [
        "\"testapp\", \"AAuthorProxyProxy\", [], {\"proxy\": True}, (\"testapp.authorproxy\",)",
        "\"testapp\", \"AAuthorProxyProxy\", [], {\"proxy\":"
    ],
    [
        "\"testapp\", \"AuthorUnmanaged\", [], {\"managed\": False}, (\"testapp.author\",)",
        "\"testapp\", \"AuthorUnmanaged\", [], {\"managed\": False},"
    ],
    [
        "knight = ModelState(\"eggs\", \"Knight\", [(\"id\", models.AutoField(primary_key=True))])",
        "knight = ModelState(\"eggs\", \"Knight\","
    ],
    [
        "\"\"\"Tests auto-naming of migrations for graph matching.\"\"\"",
        "\"\"\"Tests auto-naming of migrations for graph"
    ],
    [
        "Trim does not remove dependencies but does remove unwanted apps.",
        "Trim does not remove dependencies but"
    ],
    [
        "\"\"\"Tests custom naming of migrations for graph matching.\"\"\"",
        "\"\"\"Tests custom naming of migrations"
    ],
    [
        "side_effect=AssertionError(\"Should not have prompted for not null addition\"),",
        "side_effect=AssertionError(\"Should not have prompted for not null"
    ],
    [
        "side_effect=AssertionError(\"Should not have prompted for not null addition\"),",
        "side_effect=AssertionError(\"Should not have prompted"
    ],
    [
        "side_effect=AssertionError(\"Should not have prompted for not null addition\"),",
        "side_effect=AssertionError(\"Should not have prompted for not null"
    ],
    [
        "side_effect=AssertionError(\"Should not have prompted for not null addition\"),",
        "side_effect=AssertionError(\"Should not have prompted for not"
    ],
    [
        "side_effect=AssertionError(\"Should not have prompted for not null alteration\"),",
        "side_effect=AssertionError(\"Should not have prompted"
    ],
    [
        "RenameField is used if a field is renamed and db_column equal to the",
        "RenameField is used if a field is renamed and db_column equal to"
    ],
    [
        "{\"to\": \"app.foo\", \"on_delete\": models.CASCADE, \"db_column\": \"foo_id\"},",
        "{\"to\": \"app.foo\", \"on_delete\": models.CASCADE,"
    ],
    [
        "Model name is case-insensitive. Changing case doesn't lead to any",
        "Model name is case-insensitive. Changing case"
    ],
    [
        "Tests autodetection of renamed models while simultaneously renaming one",
        "Tests autodetection of renamed models while"
    ],
    [
        "of the fields that relate to the renamed model.",
        "of the fields that relate to the renamed"
    ],
    [
        "The migration to rename a model pointed to by a foreign key in another",
        "The migration to rename a model pointed to by a"
    ],
    [
        "app must run after the other app's migration that adds the foreign key",
        "app must run after the other app's"
    ],
    [
        "with model's original name. Therefore, the renaming migration has a",
        "with model's original name. Therefore, the renaming"
    ],
    [
        "\"\"\"Having a ForeignKey automatically adds a dependency.\"\"\"",
        "\"\"\"Having a ForeignKey automatically adds"
    ],
    [
        "changes = self.get_changes([], [self.author_name, self.book, self.edition])",
        "changes = self.get_changes([], [self.author_name, self.book,"
    ],
    [
        "\"\"\"FK dependencies still work on proxy models.\"\"\"",
        "\"\"\"FK dependencies still work on proxy"
    ],
    [
        "A migration with a FK between two models of the same app",
        "A migration with a FK between two models"
    ],
    [
        "does not have a dependency to itself.",
        "does not have a dependency"
    ],
    [
        "Having a circular ForeignKey dependency automatically",
        "Having a circular"
    ],
    [
        "A migration with a FK between two models of the same app does",
        "A migration with a FK between two models of the"
    ],
    [
        "not have a dependency to itself.",
        "not have a"
    ],
    [
        "to create unique together constraint and indexes before creating all",
        "to create unique together constraint and indexes"
    ],
    [
        "\"\"\"Tests detection for adding db_table in model's options.\"\"\"",
        "\"\"\"Tests detection for adding db_table in"
    ],
    [
        "\"\"\"Tests detection for changing db_table in model's options'.\"\"\"",
        "\"\"\"Tests detection for changing db_table"
    ],
    [
        "\"\"\"Tests detection for removing db_table in model's options.\"\"\"",
        "\"\"\"Tests detection for removing db_table"
    ],
    [
        "Alter_db_table doesn't generate a migration if no changes have been made.",
        "Alter_db_table doesn't generate a migration if no changes have been"
    ],
    [
        "Tests when model changes but db_table stays as-is, autodetector must not",
        "Tests when model changes but db_table stays as-is, autodetector"
    ],
    [
        "Tests when model and db_table changes, autodetector must create two",
        "Tests when model and db_table changes,"
    ],
    [
        "\"Enter a valid “slug” consisting of letters, numbers, \"",
        "\"Enter a valid “slug” consisting"
    ],
    [
        "\"Enter a valid “slug” consisting of letters, numbers, \"",
        "\"Enter a valid “slug” consisting of letters, numbers,"
    ],
    [
        "\"\"\"Empty unique_together shouldn't generate a migration.\"\"\"",
        "\"\"\"Empty unique_together shouldn't"
    ],
    [
        "self.fail(\"Created operation(s) %s from %s\" % (ops, msg))",
        "self.fail(\"Created operation(s) %s from %s\""
    ],
    [
        "(model_state_not_specified, model_state_none, '\"not specified\" to \"None\"'),",
        "(model_state_not_specified, model_state_none, '\"not specified\" to"
    ],
    [
        "(model_state_none, model_state_not_specified, '\"None\" to \"not specified\"'),",
        "(model_state_none, model_state_not_specified, '\"None\" to \"not"
    ],
    [
        "\"\"\"Test creation of new model with indexes already defined.\"\"\"",
        "\"\"\"Test creation of new model with indexes"
    ],
    [
        "\"\"\"Test change detection of new indexes.\"\"\"",
        "\"\"\"Test change detection of new"
    ],
    [
        "\"\"\"Test change detection of removed indexes.\"\"\"",
        "\"\"\"Test change detection of"
    ],
    [
        "\"\"\"Test change detection of reordering of fields in indexes.\"\"\"",
        "\"\"\"Test change detection of reordering of fields"
    ],
    [
        "\"\"\"Test creation of new model with constraints already defined.\"\"\"",
        "\"\"\"Test creation of new model"
    ],
    [
        "\"\"\"Test change detection of new constraints.\"\"\"",
        "\"\"\"Test change detection of"
    ],
    [
        "book_types = {\"F\": \"Fantasy\", \"M\": \"Mystery\"}",
        "book_types = {\"F\":"
    ],
    [
        "\"\"\"Test change detection of removed constraints.\"\"\"",
        "\"\"\"Test change detection of"
    ],
    [
        "\"\"\"Tests unique_together and field removal detection & ordering\"\"\"",
        "\"\"\"Tests unique_together and field removal"
    ],
    [
        "unique_together doesn't generate a migration if no",
        "unique_together doesn't generate a migration if"
    ],
    [
        "unique_together also triggers on ordering changes.",
        "unique_together also triggers"
    ],
    [
        "Added fields will be created before using them in unique_together.",
        "Added fields will be created before using"
    ],
    [
        "Removed fields will be removed after updating unique_together.",
        "Removed fields will be"
    ],
    [
        "\"\"\"Fields are altered after deleting some unique_together.\"\"\"",
        "\"\"\"Fields are altered after"
    ],
    [
        "\"\"\"Fields are renamed before updating unique_together.\"\"\"",
        "\"\"\"Fields are renamed"
    ],
    [
        "\"\"\"The autodetector correctly deals with proxy models.\"\"\"",
        "\"\"\"The autodetector correctly deals"
    ],
    [
        "options={\"proxy\": True, \"indexes\": [], \"constraints\": []},",
        "options={\"proxy\": True, \"indexes\":"
    ],
    [
        "options={\"proxy\": True, \"indexes\": [], \"constraints\": []},",
        "options={\"proxy\": True, \"indexes\": [],"
    ],
    [
        "\"\"\"The autodetector correctly deals with managed models.\"\"\"",
        "\"\"\"The autodetector correctly deals with"
    ],
    [
        "Two instances which deconstruct to the same value aren't considered a",
        "Two instances which deconstruct to the same"
    ],
    [
        "\"\"\"Field instances are handled correctly by nested deconstruction.\"\"\"",
        "\"\"\"Field instances are handled correctly by nested"
    ],
    [
        "\"\"\"Nested deconstruction descends into dict values.\"\"\"",
        "\"\"\"Nested deconstruction descends into"
    ],
    [
        "Nested deconstruction is applied recursively to the args/kwargs of",
        "Nested deconstruction is applied recursively to"
    ],
    [
        "Removing an FK and the model it targets in the same change must remove",
        "Removing an FK and the model it targets"
    ],
    [
        "the FK field before the model to maintain consistency.",
        "the FK field before the model to"
    ],
    [
        "side_effect=AssertionError(\"Should not have prompted for not null addition\"),",
        "side_effect=AssertionError(\"Should not have prompted for not"
    ],
    [
        "Removing a ManyToManyField and the \"through\" model in the same change",
        "Removing a ManyToManyField and the \"through\" model in the same"
    ],
    [
        "must remove the field before the model to maintain consistency.",
        "must remove the field before"
    ],
    [
        "Removing a model that contains a ManyToManyField and the \"through\" model",
        "Removing a model that contains a"
    ],
    [
        "in the same change must remove the field before the model to maintain",
        "in the same change must remove the field before the model to"
    ],
    [
        "removed in the same migration as that through model as the schema will",
        "removed in the same migration as that through model"
    ],
    [
        "pass through an inconsistent state. The autodetector should produce two",
        "pass through an inconsistent state. The autodetector"
    ],
    [
        "If two models with a ForeignKey from one to the other are removed at the",
        "If two models with a ForeignKey from one to the other are removed"
    ],
    [
        "same time, the autodetector should remove them in the correct order.",
        "same time, the autodetector should remove them in"
    ],
    [
        "\"\"\"Changing a model's options should make a change.\"\"\"",
        "\"\"\"Changing a model's options should"
    ],
    [
        "\"\"\"Changing a proxy model's options should also make a change.\"\"\"",
        "\"\"\"Changing a proxy model's options should"
    ],
    [
        "Setting order_with_respect_to when adding the FK too does",
        "Setting order_with_respect_to when adding the FK"
    ],
    [
        "Removing order_with_respect_to when removing the FK too does",
        "Removing order_with_respect_to when removing"
    ],
    [
        "Setting order_with_respect_to when adding the whole model",
        "Setting order_with_respect_to when adding"
    ],
    [
        "does things in the right order.",
        "does things in the right"
    ],
    [
        "Changing the model managers adds a new operation.",
        "Changing the model managers adds a new"
    ],
    [
        "\"\"\"Swappable models get their CreateModel first.\"\"\"",
        "\"\"\"Swappable models get their"
    ],
    [
        "\"\"\"Swappable models get their CreateModel first.\"\"\"",
        "\"\"\"Swappable models get their CreateModel"
    ],
    [
        "\"\"\"Bases of other models come first.\"\"\"",
        "\"\"\"Bases of other"
    ],
    [
        "Inheriting models doesn't move *_ptr fields into AddField operations.",
        "Inheriting models doesn't move *_ptr fields into"
    ],
    [
        "A = ModelState(\"app\", \"A\", [(\"a_id\", models.AutoField(primary_key=True))])",
        "A = ModelState(\"app\","
    ],
    [
        "B = ModelState(\"app\", \"B\", [(\"b_id\", models.AutoField(primary_key=True))])",
        "B = ModelState(\"app\", \"B\","
    ],
    [
        "C = ModelState(\"app\", \"C\", [], bases=(\"app.A\", \"app.B\"))",
        "C = ModelState(\"app\", \"C\", [],"
    ],
    [
        "D = ModelState(\"app\", \"D\", [], bases=(\"app.A\", \"app.B\"))",
        "D = ModelState(\"app\", \"D\","
    ],
    [
        "E = ModelState(\"app\", \"E\", [], bases=(\"app.A\", \"app.B\"))",
        "E = ModelState(\"app\", \"E\", [], bases=(\"app.A\","
    ],
    [
        "changes = self.get_changes([], [A, B, C, D, E])",
        "changes = self.get_changes([], [A,"
    ],
    [
        "A relation used as the primary key is kept as part of CreateModel.",
        "A relation used as the primary key"
    ],
    [
        "A dependency to an app with no migrations uses __first__.",
        "A dependency to an app with no migrations uses"
    ],
    [
        "A dependency to an app with existing migrations uses the",
        "A dependency to an app with existing"
    ],
    [
        "ForeignKeys are altered _before_ the model they used to",
        "ForeignKeys are altered _before_ the model they"
    ],
    [
        "before AddField and not become unsolvable.",
        "before AddField and not"
    ],
    [
        "changes = self.get_changes([], [address, person, apackage, country])",
        "changes = self.get_changes([], [address, person, apackage,"
    ],
    [
        "swappable models but with the swappable not being the first migrated",
        "swappable models but with the swappable"
    ],
    [
        "child = ModelState(\"a\", \"Child\", [], bases=(\"a.Parent\",))",
        "child = ModelState(\"a\", \"Child\","
    ],
    [
        "user = ModelState(\"a\", \"User\", [], bases=(AbstractBaseUser, \"a.Child\"))",
        "user = ModelState(\"a\", \"User\", [],"
    ],
    [
        "changes = self.get_changes([], [parent, child, user])",
        "changes = self.get_changes([], [parent,"
    ],
    [
        "side_effect=AssertionError(\"Should not have prompted for not null addition\"),",
        "side_effect=AssertionError(\"Should not have prompted for not null"
    ],
    [
        "without default should not prompt for a default.",
        "without default should not"
    ],
    [
        "without default should prompt for a default.",
        "without default should prompt for"
    ],
    [
        "Dog = ModelState(\"app\", \"Dog\", [], bases=(\"app.Animal\",))",
        "Dog = ModelState(\"app\","
    ],
    [
        "Removing a base field takes place before adding a new inherited model",
        "Removing a base field takes place before adding"
    ],
    [
        "that has a field with the same name.",
        "that has a field"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "from django.apps.registry import apps as global_apps",
        "from django.apps.registry import"
    ],
    [
        "from django.db import DatabaseError, connection, migrations, models",
        "from django.db import DatabaseError, connection,"
    ],
    [
        "Tests the migration executor (full end-to-end running).",
        "Tests the migration executor (full"
    ],
    [
        "Bear in mind that if these are failing you should fix the other",
        "Bear in mind that if these are failing you should fix the"
    ],
    [
        "test failures first, as they may be propagating into here.",
        "test failures first, as they may be propagating into"
    ],
    [
        "Tests running a simple set of migrations.",
        "Tests running a simple set of"
    ],
    [
        "Tests running a squashed migration from zero (should ignore what it replaces)",
        "Tests running a squashed migration from zero (should ignore"
    ],
    [
        "Applying a non-atomic migration works as expected.",
        "Applying a non-atomic migration"
    ],
    [
        "An atomic operation is properly rolled back inside a non-atomic",
        "An atomic operation is properly rolled back inside"
    ],
    [
        "Re-planning a full migration of a fully-migrated set doesn't",
        "Re-planning a full migration of a fully-migrated"
    ],
    [
        "There was previously a bug where the executor just always performed the",
        "There was previously a bug where the executor just"
    ],
    [
        "backwards plan for applied migrations - which even for the most recent",
        "backwards plan for applied migrations - which even for the most"
    ],
    [
        "migration in an app, might include other, dependent apps, and these",
        "migration in an app, might include other,"
    ],
    [
        "Although the MigrationExecutor interfaces allows for mixed migration",
        "Although the MigrationExecutor interfaces"
    ],
    [
        "plans (combined forwards and backwards migrations) this is not",
        "plans (combined forwards and backwards migrations)"
    ],
    [
        "\"Migration plans with both forwards and backwards migrations are \"",
        "\"Migration plans with both forwards and backwards migrations are"
    ],
    [
        "\"not supported. Please split your migration process into separate \"",
        "\"not supported. Please split your"
    ],
    [
        "\"plans of only forwards OR backwards migrations.\"",
        "\"plans of only forwards OR backwards"
    ],
    [
        "Tests detection of initial migrations already having been applied.",
        "Tests detection of initial migrations already"
    ],
    [
        "same app are not resolved correctly.",
        "same app are not resolved"
    ],
    [
        "x for x in old_table_names(c) if x != \"auth_user\"",
        "x for x in old_table_names(c) if x !="
    ],
    [
        "executor.detect_soft_applied() detects ManyToManyField tables from an",
        "executor.detect_soft_applied() detects ManyToManyField tables"
    ],
    [
        "AddField operation. This checks the case of AddField in a migration",
        "AddField operation. This checks the case of AddField in"
    ],
    [
        "unrelated to the first app being applied are part of the initial model",
        "unrelated to the first app being applied are"
    ],
    [
        "unrelated to the first app being unapplied are part of the initial",
        "unrelated to the first app being unapplied are part"
    ],
    [
        "A new squash migration will be marked as applied even if all its",
        "A new squash migration will be marked as applied even if all"
    ],
    [
        "\"\"\"Migrations are applied and recorded atomically.\"\"\"",
        "\"\"\"Migrations are applied and recorded"
    ],
    [
        "\"\"\"Migrations are not recorded if deferred SQL application fails.\"\"\"",
        "\"\"\"Migrations are not recorded if deferred SQL application"
    ],
    [
        "raise DatabaseError(\"Failed to apply deferred SQL\")",
        "raise DatabaseError(\"Failed to"
    ],
    [
        "with self.assertRaisesMessage(DatabaseError, \"Failed to apply deferred SQL\"):",
        "with self.assertRaisesMessage(DatabaseError, \"Failed to apply deferred"
    ],
    [
        "The django_migrations table is not created if there are no migrations",
        "The django_migrations table is not created if there are"
    ],
    [
        "\"\"\"Really all we need is any object with a debug-useful repr.\"\"\"",
        "\"\"\"Really all we need is any object with"
    ],
    [
        "\"\"\"(More) isolated unit tests for executor methods.\"\"\"",
        "\"\"\"(More) isolated unit tests for"
    ],
    [
        "Minimize unnecessary rollbacks in connected apps.",
        "Minimize unnecessary rollbacks in connected"
    ],
    [
        "Minimize rollbacks when target has multiple in-app children.",
        "Minimize rollbacks when target has multiple"
    ],
    [
        "exp = [(m, True) for m in should_be_rolled_back]",
        "exp = [(m, True) for"
    ],
    [
        "If the current state satisfies the given target, do nothing.",
        "If the current state satisfies the given target,"
    ],
    [
        "\"Please enter some code, or 'exit' (without quotes) to exit.\",",
        "\"Please enter some code, or 'exit' (without"
    ],
    [
        "\"NameError: name 'datetim' is not defined\", self.prompt.getvalue()",
        "\"NameError: name 'datetim' is not defined\","
    ],
    [
        "\"AttributeError: module 'datetime' has no attribute 'dat'\",",
        "\"AttributeError: module 'datetime' has"
    ],
    [
        "from django.db import connection, connections, migrations, models",
        "from django.db import connection,"
    ],
    [
        "Contains an extended set of asserts for testing migrations and schema operations.",
        "Contains an extended set of asserts for testing migrations and schema"
    ],
    [
        "column, [c.name for c in self.get_table_description(table, using=using)]",
        "column, [c.name for c"
    ],
    [
        "column, [c.name for c in self.get_table_description(table, using=using)]",
        "column, [c.name for c in self.get_table_description(table,"
    ],
    [
        "def assertColumnCollation(self, table, column, collation, using=\"default\"):",
        "def assertColumnCollation(self, table, column, collation,"
    ],
    [
        "self, table, columns, value=True, using=\"default\", index_type=None",
        "self, table, columns, value=True, using=\"default\","
    ],
    [
        "and (index_type is None or c[\"type\"] == index_type)",
        "and (index_type is None or c[\"type\"]"
    ],
    [
        "def assertConstraintExists(self, table, name, value=True, using=\"default\"):",
        "def assertConstraintExists(self, table,"
    ],
    [
        "any(c[\"check\"] for n, c in constraints if n == name),",
        "any(c[\"check\"] for n, c in constraints if n"
    ],
    [
        "def assertUniqueConstraintExists(self, table, columns, value=True, using=\"default\"):",
        "def assertUniqueConstraintExists(self, table,"
    ],
    [
        "any(c[\"unique\"] for c in constraints if c[\"columns\"] == list(columns)),",
        "any(c[\"unique\"] for c in constraints if"
    ],
    [
        "def assertFKExists(self, table, columns, to, value=True, using=\"default\"):",
        "def assertFKExists(self, table, columns, to, value=True,"
    ],
    [
        "Allows testing management commands in a temporary migrations module.",
        "Allows testing management commands in a temporary migrations"
    ],
    [
        "Wrap all invocations to makemigrations and squashmigrations with this",
        "Wrap all invocations to makemigrations and squashmigrations"
    ],
    [
        "context manager in order to avoid creating migration files in your",
        "context manager in order to avoid creating migration files"
    ],
    [
        "Takes the application label that will be passed to makemigrations or",
        "Takes the application label that will be passed"
    ],
    [
        "squashmigrations and the Python path to a migrations module.",
        "squashmigrations and the Python path to a"
    ],
    [
        "The migrations module is used as a template for creating the temporary",
        "The migrations module is used as a"
    ],
    [
        "migrations module. If it isn't provided, the application's migrations",
        "migrations module. If it isn't provided,"
    ],
    [
        "module is used, if it exists.",
        "module is used, if it"
    ],
    [
        "Returns the filesystem path to the temporary migrations module.",
        "Returns the filesystem path to"
    ],
    [
        "\"\"\"Common functions to help test operations.\"\"\"",
        "\"\"\"Common functions to help"
    ],
    [
        "def apply_operations(self, app_label, project_state, operations, atomic=True):",
        "def apply_operations(self, app_label,"
    ],
    [
        "def unapply_operations(self, app_label, project_state, operations, atomic=True):",
        "def unapply_operations(self, app_label, project_state,"
    ],
    [
        "Makes a test state using set_up_test_model and returns the",
        "Makes a test state using set_up_test_model and returns"
    ],
    [
        "original state and the state after the migration is applied.",
        "original state and the state"
    ],
    [
        "\"\"\"Creates a test model state and database table.\"\"\"",
        "\"\"\"Creates a test model state and"
    ],
    [
        "\"unique_together\": [[\"pink\", \"weight\"]] if unique_together else [],",
        "\"unique_together\": [[\"pink\", \"weight\"]] if unique_together"
    ],
    [
        "\"\"\"Common functions to help test the optimizer.\"\"\"",
        "\"\"\"Common functions to help"
    ],
    [
        "Handy shortcut for getting results + number of loops",
        "Handy shortcut for getting results"
    ],
    [
        "self, operations, expected, exact=None, less_than=None, app_label=None",
        "self, operations, expected,"
    ],
    [
        "result, iterations = self.optimize(operations, app_label or \"migrations\")",
        "result, iterations = self.optimize(operations, app_label or"
    ],
    [
        "result = [self.serialize(f) for f in result]",
        "result = [self.serialize(f) for f"
    ],
    [
        "expected = [self.serialize(f) for f in expected]",
        "expected = [self.serialize(f) for"
    ],
    [
        "if exact is not None and iterations != exact:",
        "if exact is not None and iterations"
    ],
    [
        "\"Optimization did not take exactly %s iterations (it took %s)\"",
        "\"Optimization did not take exactly %s iterations"
    ],
    [
        "if less_than is not None and iterations >= less_than:",
        "if less_than is not None and"
    ],
    [
        "\"Optimization did not take less than %s iterations (it took %s)\"",
        "\"Optimization did not take less than %s"
    ],
    [
        "from django.db.migrations.graph import DummyNode, MigrationGraph, Node",
        "from django.db.migrations.graph import DummyNode,"
    ],
    [
        "In a graph with merge migrations, iterative_dfs() traverses each node",
        "In a graph with merge migrations, iterative_dfs() traverses each"
    ],
    [
        "only once even if there are multiple paths leading to it.",
        "only once even if there are multiple paths"
    ],
    [
        "Tests for forwards/backwards_plan of nonexistent node.",
        "Tests for forwards/backwards_plan of nonexistent"
    ],
    [
        "validate_consistency() raises an error if there's an isolated dummy",
        "validate_consistency() raises an error if"
    ],
    [
        "Replaced nodes are properly removed and dependencies remapped.",
        "Replaced nodes are properly removed and"
    ],
    [
        "\"either never added to the migration graph, or has been removed.\"",
        "\"either never added to the migration graph,"
    ],
    [
        "A replacement node is properly removed and child dependencies remapped.",
        "A replacement node is properly removed and child dependencies"
    ],
    [
        "We assume parent dependencies are already correct.",
        "We assume parent dependencies"
    ],
    [
        "\" either never added to the migration graph, or has been removed already.\"",
        "\" either never added to the migration graph, or has been"
    ],
    [
        "def allow_migrate(self, db, app_label, model_name=None, **hints):",
        "def allow_migrate(self, db, app_label, model_name=None,"
    ],
    [
        "def allow_migrate(self, db, app_label, model_name=None, **hints):",
        "def allow_migrate(self, db, app_label, model_name=None,"
    ],
    [
        "The Tribble model should be the only one to appear in the 'other' db.",
        "The Tribble model should be the only one to appear in the 'other'"
    ],
    [
        "A model that is in a migration-less app (which this app is",
        "A model that is in a migration-less app (which"
    ],
    [
        "if its migrations directory has not been repointed)",
        "if its migrations directory has not been"
    ],
    [
        "This is a wee bit crazy, but it's just to show that run_before works.",
        "This is a wee bit crazy, but it's just to show that"
    ],
    [
        "[\"SELECT * FROM migrations_book\"], [\"SELECT * FROM migrations_salamander\"]",
        "[\"SELECT * FROM migrations_book\"], [\"SELECT"
    ],
    [
        "[\"SELECT * FROM migrations_author\"], [\"SELECT * FROM migrations_book\"]",
        "[\"SELECT * FROM migrations_author\"],"
    ],
    [
        "Special receiver for handle the fact that test runner calls migrate for",
        "Special receiver for handle the fact that"
    ],
    [
        "several databases and several times for some of them.",
        "several databases and several times"
    ],
    [
        "If all apps have migrations, migration signals should be sent.",
        "If all apps have migrations, migration"
    ],
    [
        "Multiple many-to-many relationships between the same two tables",
        "Multiple many-to-many relationships between the same two"
    ],
    [
        "In this example, an ``Article`` can have many \"primary\" ``Category`` objects",
        "In this example, an ``Article`` can have many"
    ],
    [
        "Set ``related_name`` to designate what the reverse relationship is called.",
        "Set ``related_name`` to designate what the reverse relationship is"
    ],
    [
        "for name in [\"Sports\", \"News\", \"Crime\", \"Life\"]",
        "for name in [\"Sports\","
    ],
    [
        "expected_message = \"Can't bulk create a multi-table inherited model\"",
        "expected_message = \"Can't bulk create"
    ],
    [
        "[State(two_letter_code=s) for s in [\"IL\", \"NY\", \"CA\", \"ME\"]]",
        "[State(two_letter_code=s) for s in"
    ],
    [
        "[State(two_letter_code=s) for s in [\"IL\", \"NY\", \"CA\", \"ME\"]]",
        "[State(two_letter_code=s) for s in"
    ],
    [
        "Zero as id for AutoField should raise exception in MySQL, because MySQL",
        "Zero as id for AutoField should raise"
    ],
    [
        "does not allow zero for automatic primary key if the",
        "does not allow zero for automatic primary"
    ],
    [
        "NO_AUTO_VALUE_ON_ZERO SQL mode is not enabled.",
        "NO_AUTO_VALUE_ON_ZERO SQL mode is"
    ],
    [
        "Test inserting a large batch with objects having primary key set",
        "Test inserting a large batch with"
    ],
    [
        "mixed together with objects without PK set.",
        "mixed together with objects without PK"
    ],
    [
        "Test inserting a large batch with objects having primary key set",
        "Test inserting a large batch with objects having primary"
    ],
    [
        "mixed together with objects without PK set.",
        "mixed together with objects"
    ],
    [
        "field for field in NullableFields._meta.get_fields() if field.name != \"id\"",
        "field for field in NullableFields._meta.get_fields() if field.name !="
    ],
    [
        "field_value = \"\" if isinstance(field, FileField) else None",
        "field_value = \"\" if isinstance(field, FileField)"
    ],
    [
        "message = \"This database backend does not support ignoring conflicts.\"",
        "message = \"This database backend does not support"
    ],
    [
        "\"bulk_create() prohibited to prevent data loss due to unsaved \"",
        "\"bulk_create() prohibited to prevent data"
    ],
    [
        "msg = \"Batch size must be a positive integer.\"",
        "msg = \"Batch size must be a"
    ],
    [
        "msg = \"This database backend does not support updating conflicts.\"",
        "msg = \"This database backend does not support updating"
    ],
    [
        "msg = \"ignore_conflicts and update_conflicts are mutually exclusive\"",
        "msg = \"ignore_conflicts and update_conflicts are mutually"
    ],
    [
        "\"Fields that will be updated when a row insertion fails on \"",
        "\"Fields that will be updated when a row insertion fails"
    ],
    [
        "\"This database backend does not support updating conflicts with \"",
        "\"This database backend does not support updating"
    ],
    [
        "\"specifying unique fields that can trigger the upsert.\"",
        "\"specifying unique fields that"
    ],
    [
        "msg = \"TwoFields has no field named 'nonexistent'\"",
        "msg = \"TwoFields has"
    ],
    [
        "msg = \"Unique fields that can trigger the upsert must be provided.\"",
        "msg = \"Unique fields that can trigger the upsert must"
    ],
    [
        "msg = \"bulk_create() can only be used with concrete fields in update_fields.\"",
        "msg = \"bulk_create() can only be used with concrete"
    ],
    [
        "msg = \"bulk_create() cannot be used with primary keys in update_fields.\"",
        "msg = \"bulk_create() cannot be used with"
    ],
    [
        "msg = \"bulk_create() can only be used with concrete fields in unique_fields.\"",
        "msg = \"bulk_create() can only be used with concrete fields in"
    ],
    [
        "description=(\"Germany is a country in Central Europe.\"),",
        "description=(\"Germany is a country in"
    ],
    [
        "\"The Czech Republic is a landlocked country in Central Europe.\"",
        "\"The Czech Republic is a landlocked"
    ],
    [
        "description=(\"Japan is an island country in East Asia.\"),",
        "description=(\"Japan is an island country in"
    ],
    [
        "\"description\": (\"Germany is a country in Central Europe.\"),",
        "\"description\": (\"Germany is a country in Central"
    ],
    [
        "\"The Czech Republic is a landlocked country in Central Europe.\"",
        "\"The Czech Republic is a landlocked country in"
    ],
    [
        "\"description\": (\"Japan is an island country in East Asia.\"),",
        "\"description\": (\"Japan is an island country in East"
    ],
    [
        "lambda x: (x, x.book_join, x.book_join.editor, x.book_join.author),",
        "lambda x: (x,"
    ],
    [
        "empty = \"\" if connection.features.interprets_empty_strings_as_nulls else None",
        "empty = \"\" if connection.features.interprets_empty_strings_as_nulls"
    ],
    [
        "\"book_title_jane__title\": \"The book by Jane A\",",
        "\"book_title_jane__title\": \"The book by"
    ],
    [
        "\"book_title_jane__title\": \"The book by Jane B\",",
        "\"book_title_jane__title\": \"The book by"
    ],
    [
        "\"book\", condition=Q(book__title__iexact=\"the book by jane a\")",
        "\"book\", condition=Q(book__title__iexact=\"the book"
    ],
    [
        "\"book\", condition=Q(book__title__iexact=\"the book by jane a\")",
        "\"book\", condition=Q(book__title__iexact=\"the book by jane"
    ],
    [
        "\"book\", condition=Q(book__title__iexact=\"the book by jane a\")",
        "\"book\", condition=Q(book__title__iexact=\"the book by jane"
    ],
    [
        "\"book\", condition=Q(book__title__iexact=\"the book by jane a\")",
        "\"book\", condition=Q(book__title__iexact=\"the book by jane"
    ],
    [
        "msg = \"only() is not supported with FilteredRelation.\"",
        "msg = \"only() is not"
    ],
    [
        "(\"Alice\", \"The book by Alice\", None),",
        "(\"Alice\", \"The book by Alice\","
    ],
    [
        "\"FilteredRelation's relation_name cannot contain lookups (got \"",
        "\"FilteredRelation's relation_name cannot contain"
    ],
    [
        "\"FilteredRelation's condition doesn't support relations outside \"",
        "\"FilteredRelation's condition doesn't support relations"
    ],
    [
        "\"FilteredRelation's condition doesn't support nested relations \"",
        "\"FilteredRelation's condition doesn't support nested"
    ],
    [
        "\"deeper than the relation_name (got \"",
        "\"deeper than the relation_name (got"
    ],
    [
        "\"FilteredRelation's condition doesn't support nested relations \"",
        "\"FilteredRelation's condition doesn't support"
    ],
    [
        "\"deeper than the relation_name (got 'book__editor__name' for 'book').\"",
        "\"deeper than the relation_name (got 'book__editor__name' for"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"relation_name cannot be empty.\"):",
        "with self.assertRaisesMessage(ValueError, \"relation_name"
    ],
    [
        "msg = \"condition argument must be a Q() instance.\"",
        "msg = \"condition argument must be"
    ],
    [
        "msg = \"prefetch_related() is not supported with FilteredRelation.\"",
        "msg = \"prefetch_related() is not supported with"
    ],
    [
        "msg = \"Passing a QuerySet within a FilteredRelation is not supported.\"",
        "msg = \"Passing a QuerySet within"
    ],
    [
        "filtered_relation() not only improves performance but also creates",
        "filtered_relation() not only improves performance but also"
    ],
    [
        "correct results when aggregating with multiple LEFT JOINs.",
        "correct results when aggregating with"
    ],
    [
        "Books can be reserved then rented by a borrower. Each reservation and",
        "Books can be reserved then rented by a borrower. Each reservation"
    ],
    [
        "rental session are recorded with Reservation and RentalSession models.",
        "rental session are recorded with"
    ],
    [
        "Every time a reservation or a rental session is over, their state is",
        "Every time a reservation or a rental session is over, their"
    ],
    [
        "Goal: Count number of books that are either currently reserved or",
        "Goal: Count number of books that are either"
    ],
    [
        "return \"pk=%s car=%s driver=%s\" % (str(self.pk), self.car, self.driver)",
        "return \"pk=%s car=%s driver=%s\" % (str(self.pk), self.car,"
    ],
    [
        "from .models import Car, CarDriver, Driver, Group, Membership, Person, UserMembership",
        "from .models import Car, CarDriver,"
    ],
    [
        "Too many copies of the intermediate table aren't involved when doing a",
        "Too many copies of the intermediate table aren't involved"
    ],
    [
        "'\"<Car: None>\" needs to have a value for field \"make\" before this '",
        "'\"<Car: None>\" needs to have a value"
    ],
    [
        "\"'Car' instance needs to have a primary key value before a \"",
        "\"'Car' instance needs to have a primary key value before a"
    ],
    [
        "msg = 'Cannot add \"<Driver: None>\": the value for field \"driver\" is None'",
        "msg = 'Cannot add \"<Driver: None>\": the value for field"
    ],
    [
        "msg = 'Cannot add \"<Car: None>\": the value for field \"car\" is None'",
        "msg = 'Cannot add \"<Car: None>\": the value for field"
    ],
    [
        "'\"<Driver: None>\" needs to have a value for field \"name\" before '",
        "'\"<Driver: None>\" needs to have a value for field"
    ],
    [
        "\"this many-to-many relationship can be used.\"",
        "\"this many-to-many relationship can be"
    ],
    [
        "``select_related()`` follows all relationships and pre-caches any foreign key",
        "``select_related()`` follows all relationships and pre-caches any"
    ],
    [
        "values so that complex trees can be fetched in a single query. However, this",
        "values so that complex trees can be fetched in a single"
    ],
    [
        "isn't always a good idea, so the ``depth`` argument control how many \"levels\"",
        "isn't always a good idea, so the ``depth`` argument control how many"
    ],
    [
        "Helper to create a complete tree.",
        "Helper to create a"
    ],
    [
        "models = [Domain, Kingdom, Phylum, Klass, Order, Family, Genus, Species]",
        "models = [Domain, Kingdom, Phylum, Klass, Order, Family,"
    ],
    [
        "assert len(names) == len(models), (names, models)",
        "assert len(names) =="
    ],
    [
        "for name, model in zip(names, models):",
        "for name, model in zip(names,"
    ],
    [
        "\"Eukaryota Animalia Anthropoda Insecta Diptera Drosophilidae Drosophila \"",
        "\"Eukaryota Animalia Anthropoda Insecta Diptera Drosophilidae"
    ],
    [
        "\"Eukaryota Animalia Chordata Mammalia Primates Hominidae Homo sapiens\"",
        "\"Eukaryota Animalia Chordata Mammalia"
    ],
    [
        "\"Eukaryota Plantae Magnoliophyta Magnoliopsida Fabales Fabaceae Pisum \"",
        "\"Eukaryota Plantae Magnoliophyta Magnoliopsida Fabales Fabaceae Pisum"
    ],
    [
        "\"Eukaryota Fungi Basidiomycota Homobasidiomycatae Agaricales Amanitacae \"",
        "\"Eukaryota Fungi Basidiomycota Homobasidiomycatae"
    ],
    [
        "Normally, accessing FKs doesn't fill in related objects",
        "Normally, accessing FKs doesn't fill in"
    ],
    [
        "A select_related() call will fill in those related objects without any",
        "A select_related() call will fill in those"
    ],
    [
        "families = [o.genus.family.name for o in world]",
        "families = [o.genus.family.name for o"
    ],
    [
        "\"\"\"select_related() applies to entire lists, not just items.\"\"\"",
        "\"\"\"select_related() applies to entire lists, not just"
    ],
    [
        "families = [o.genus.family.name for o in world]",
        "families = [o.genus.family.name for o in"
    ],
    [
        "Passing a relationship field lookup specifier to select_related() will",
        "Passing a relationship field lookup specifier to"
    ],
    [
        "stop the descent at a particular level. This can be used on lists as",
        "stop the descent at a particular level. This can be used"
    ],
    [
        "orders = [o.genus.family.order.name for o in world]",
        "orders = [o.genus.family.order.name for o"
    ],
    [
        "The optional fields passed to select_related() control which related",
        "The optional fields passed to select_related() control"
    ],
    [
        "models we pull in. This allows for smaller queries.",
        "models we pull in. This allows for"
    ],
    [
        "In this case, we explicitly say to select the 'genus' and",
        "In this case, we explicitly say to select"
    ],
    [
        "'genus.family' models, leading to the same number of queries as before.",
        "'genus.family' models, leading to the same"
    ],
    [
        "families = [o.genus.family.name for o in world]",
        "families = [o.genus.family.name for o"
    ],
    [
        "In this case, we explicitly say to select the 'genus' and",
        "In this case, we explicitly say to select"
    ],
    [
        "'genus.family' models, leading to the same number of queries as before.",
        "'genus.family' models, leading to the same"
    ],
    [
        "orders = [o.genus.family.order.name for o in world]",
        "orders = [o.genus.family.order.name for"
    ],
    [
        "Running select_related() after calling values() raises a TypeError",
        "Running select_related() after calling values() raises a"
    ],
    [
        "message = \"Cannot call select_related() after .values() or .values_list()\"",
        "message = \"Cannot call select_related() after .values() or"
    ],
    [
        "Running select_related() after calling values_list() raises a TypeError",
        "Running select_related() after calling"
    ],
    [
        "message = \"Cannot call select_related() after .values() or .values_list()\"",
        "message = \"Cannot call select_related()"
    ],
    [
        "select_related() should thrown an error on fields that do not exist and",
        "select_related() should thrown an error on"
    ],
    [
        "\"Non-relational field given in select_related: '%s'. Choices are: %s\"",
        "\"Non-relational field given in select_related: '%s'. Choices"
    ],
    [
        "\"Invalid field name(s) given in select_related: '%s'. Choices are: %s\"",
        "\"Invalid field name(s) given in select_related: '%s'."
    ],
    [
        "with self.assertRaisesMessage(FieldError, self.invalid_error % (\"tags\", \"\")):",
        "with self.assertRaisesMessage(FieldError, self.invalid_error % (\"tags\","
    ],
    [
        "verbose_name = \"My custom default admin site.\"",
        "verbose_name = \"My custom default"
    ],
    [
        "\"\"\"It's possible to load an app with no models.py file.\"\"\"",
        "\"\"\"It's possible to load an"
    ],
    [
        "from .models import Article, Category, Comment",
        "from .models import Article,"
    ],
    [
        "title=\"Third one, in the first day\",",
        "title=\"Third one, in the"
    ],
    [
        "\"Cannot resolve keyword 'invalid_field' into field. Choices are: \"",
        "\"Cannot resolve keyword 'invalid_field' into field. Choices"
    ],
    [
        "\"categories, comments, id, pub_date, pub_datetime, title\",",
        "\"categories, comments, id,"
    ],
    [
        "msg = \"'kind' must be one of 'year', 'month', 'week', or 'day'.\"",
        "msg = \"'kind' must be one of"
    ],
    [
        "msg = \"'order' must be either 'ASC' or 'DESC'.\"",
        "msg = \"'order' must be either 'ASC' or"
    ],
    [
        "@skipUnless(connection.vendor == \"mysql\", \"Test checks MySQL query syntax\")",
        "@skipUnless(connection.vendor == \"mysql\", \"Test checks MySQL"
    ],
    [
        "for kind in [\"day\", \"month\", \"year\"]:",
        "for kind in [\"day\", \"month\","
    ],
    [
        "return \"%s -> %s\" % (self.tag, self.staff)",
        "return \"%s -> %s\" %"
    ],
    [
        "from django.db.models import CharField, F, Max",
        "from django.db.models import CharField, F,"
    ],
    [
        "from .models import Celebrity, Fan, Staff, StaffTag, Tag",
        "from .models import Celebrity, Fan, Staff,"
    ],
    [
        "msg = \"Cannot combine a unique query with a non-unique query.\"",
        "msg = \"Cannot combine a unique query with a non-unique"
    ],
    [
        "msg = \"Cannot combine queries with different distinct fields.\"",
        "msg = \"Cannot combine queries with different distinct"
    ],
    [
        "msg = \"Cannot create distinct fields once a slice has been taken.\"",
        "msg = \"Cannot create distinct fields once a slice"
    ],
    [
        "msg = \"annotate() + distinct(fields) is not implemented.\"",
        "msg = \"annotate() +"
    ],
    [
        "msg = \"aggregate() + distinct(fields) not implemented.\"",
        "msg = \"aggregate() + distinct(fields) not"
    ],
    [
        "Ordering shouldn't be cleared when distinct on fields are specified.",
        "Ordering shouldn't be cleared when distinct on fields"
    ],
    [
        "Emulates the case when some internal code raises an unexpected",
        "Emulates the case when some"
    ],
    [
        "from .models import Article, Comment, IndexErrorArticle, Person",
        "from .models import Article, Comment, IndexErrorArticle,"
    ],
    [
        "\"\"\"Tests for the earliest() and latest() objects methods\"\"\"",
        "\"\"\"Tests for the earliest() and"
    ],
    [
        "\"earliest() and latest() require either fields as positional \"",
        "\"earliest() and latest() require either fields as"
    ],
    [
        "\"arguments or 'get_latest_by' in the model's Meta.\",",
        "\"arguments or 'get_latest_by' in the model's"
    ],
    [
        "msg = \"Cannot change a query once a slice has been taken.\"",
        "msg = \"Cannot change a query once a"
    ],
    [
        "\"earliest() and latest() require either fields as positional \"",
        "\"earliest() and latest() require either fields as"
    ],
    [
        "\"arguments or 'get_latest_by' in the model's Meta.\",",
        "\"arguments or 'get_latest_by' in the"
    ],
    [
        "msg = \"Cannot change a query once a slice has been taken.\"",
        "msg = \"Cannot change a query once a"
    ],
    [
        "\"earliest() and latest() require either fields as positional arguments \"",
        "\"earliest() and latest() require either"
    ],
    [
        "\"or 'get_latest_by' in the model's Meta.\"",
        "\"or 'get_latest_by' in"
    ],
    [
        "\"Cannot use QuerySet.%s() on an unordered queryset performing aggregation. \"",
        "\"Cannot use QuerySet.%s() on an unordered queryset"
    ],
    [
        "\"\"\"Session store without support for clearing expired sessions.\"\"\"",
        "\"\"\"Session store without support for clearing expired"
    ],
    [
        "This custom Session model adds an extra column to store an account ID. In",
        "This custom Session model adds an extra column"
    ],
    [
        "real-world applications, it gives you the option of querying the database for",
        "real-world applications, it gives you the option of"
    ],
    [
        "all active sessions for a particular account.",
        "all active sessions for a"
    ],
    [
        "from django.contrib.sessions.backends.db import SessionStore as DBStore",
        "from django.contrib.sessions.backends.db import"
    ],
    [
        "A session model with a column for an account ID.",
        "A session model with a column for an account"
    ],
    [
        "A database session store, that handles updating the account ID column",
        "A database session store, that handles updating the account ID"
    ],
    [
        "from django.contrib.sessions.backends.cache import SessionStore as CacheSession",
        "from django.contrib.sessions.backends.cache import SessionStore"
    ],
    [
        "from django.contrib.sessions.backends.cached_db import SessionStore as CacheDBSession",
        "from django.contrib.sessions.backends.cached_db import SessionStore"
    ],
    [
        "from django.contrib.sessions.backends.db import SessionStore as DatabaseSession",
        "from django.contrib.sessions.backends.db import SessionStore"
    ],
    [
        "from django.contrib.sessions.backends.file import SessionStore as FileSession",
        "from django.contrib.sessions.backends.file import"
    ],
    [
        "from .models import SessionStore as CustomDatabaseSession",
        "from .models import"
    ],
    [
        "self.session.pop(\"some key\", \"does not exist\"), \"does not exist\"",
        "self.session.pop(\"some key\", \"does not exist\"), \"does"
    ],
    [
        "await self.session.apop(\"some key\", \"does not exist\"), \"does not exist\"",
        "await self.session.apop(\"some key\", \"does not exist\"), \"does not"
    ],
    [
        "self.session.pop(\"some key\", default=\"does not exist\"), \"does not exist\"",
        "self.session.pop(\"some key\", default=\"does not exist\"),"
    ],
    [
        "await self.session.apop(\"some key\", default=\"does not exist\"),",
        "await self.session.apop(\"some key\", default=\"does"
    ],
    [
        "\"\"\"Falsey values (Such as an empty string) are rejected.\"\"\"",
        "\"\"\"Falsey values (Such as an empty"
    ],
    [
        "data = {\"a test key\": \"a test value\"}",
        "data = {\"a test key\": \"a test"
    ],
    [
        "Loading an unknown session key does not create a session record.",
        "Loading an unknown session key does not create a"
    ],
    [
        "Creating session records on load is a DOS vulnerability.",
        "Creating session records on load is"
    ],
    [
        "Sessions shouldn't be resurrected by a concurrent request.",
        "Sessions shouldn't be resurrected by"
    ],
    [
        "\"\"\"Sessions shouldn't be resurrected by a concurrent request.\"\"\"",
        "\"\"\"Sessions shouldn't be resurrected by"
    ],
    [
        "\"Session repr should be the session key.\"",
        "\"Session repr should be the session"
    ],
    [
        "Test we can use Session.get_decoded to retrieve data stored",
        "Test we can use Session.get_decoded to retrieve data"
    ],
    [
        "Test clearsessions command for clearing expired sessions.",
        "Test clearsessions command for clearing expired"
    ],
    [
        "\"\"\"Failing to write to the cache does not raise errors.\"\"\"",
        "\"\"\"Failing to write to the cache"
    ],
    [
        "self.assertEqual(log.message, f\"Error saving to cache ({session._cache})\")",
        "self.assertEqual(log.message, f\"Error saving to cache"
    ],
    [
        "\"\"\"Failing to write to the cache does not raise errors.\"\"\"",
        "\"\"\"Failing to write to the"
    ],
    [
        "self.assertEqual(log.message, f\"Error saving to cache ({session._cache})\")",
        "self.assertEqual(log.message, f\"Error saving"
    ],
    [
        "Test clearsessions command for clearing expired sessions.",
        "Test clearsessions command for clearing"
    ],
    [
        "\"The request's session was deleted before the request completed. \"",
        "\"The request's session was deleted before the request completed."
    ],
    [
        "\"The user may have logged out in a concurrent request, for example.\"",
        "\"The user may have logged out in a concurrent"
    ],
    [
        "If a session is emptied of data but still has a key, it should still",
        "If a session is emptied of data but still has a key, it should"
    ],
    [
        "This test tested exists() in the other session backends, but that",
        "This test tested exists() in the"
    ],
    [
        "This test tested cycle_key() which would create a new session",
        "This test tested cycle_key() which would create a"
    ],
    [
        "key for the same session data. But we can't invalidate previously",
        "key for the same session data. But we"
    ],
    [
        "signed cookies (other than letting them expire naturally) so",
        "signed cookies (other than letting"
    ],
    [
        "testing for this behavior is meaningless.",
        "testing for this behavior"
    ],
    [
        "\"Cookie backend doesn't have an external store to create records in.\"",
        "\"Cookie backend doesn't have an external store to create"
    ],
    [
        "\"Cookie backend doesn't have an external store to create records in.\"",
        "\"Cookie backend doesn't have an external"
    ],
    [
        "\"CookieSession is stored in the client and there is no way to query it.\"",
        "\"CookieSession is stored in the client and there is no way to"
    ],
    [
        "\"CookieSession is stored in the client and there is no way to query it.\"",
        "\"CookieSession is stored in the client and there is"
    ],
    [
        "not_implemented_msg = \"subclasses of SessionBase must provide %s() method\"",
        "not_implemented_msg = \"subclasses of SessionBase"
    ],
    [
        "msg = self.not_implemented_msg % \"a create\"",
        "msg = self.not_implemented_msg % \"a"
    ],
    [
        "msg = self.not_implemented_msg % \"a create\"",
        "msg = self.not_implemented_msg % \"a"
    ],
    [
        "msg = self.not_implemented_msg % \"a delete\"",
        "msg = self.not_implemented_msg %"
    ],
    [
        "msg = self.not_implemented_msg % \"a delete\"",
        "msg = self.not_implemented_msg"
    ],
    [
        "msg = self.not_implemented_msg % \"an exists\"",
        "msg = self.not_implemented_msg"
    ],
    [
        "msg = self.not_implemented_msg % \"an exists\"",
        "msg = self.not_implemented_msg % \"an"
    ],
    [
        "msg = self.not_implemented_msg % \"a load\"",
        "msg = self.not_implemented_msg % \"a"
    ],
    [
        "msg = self.not_implemented_msg % \"a load\"",
        "msg = self.not_implemented_msg"
    ],
    [
        "msg = self.not_implemented_msg % \"a save\"",
        "msg = self.not_implemented_msg %"
    ],
    [
        "msg = self.not_implemented_msg % \"a save\"",
        "msg = self.not_implemented_msg %"
    ],
    [
        "Proxy model inheritance across apps can result in migrate not creating the table",
        "Proxy model inheritance across apps can result in migrate"
    ],
    [
        "apps and calls migrate, then verifies that the table has been created.",
        "apps and calls migrate, then verifies that the"
    ],
    [
        "Deleting an instance of a model proxying a multi-table inherited",
        "Deleting an instance of a model proxying"
    ],
    [
        "subclass should cascade delete down the whole inheritance chain (see",
        "subclass should cascade delete down the whole inheritance"
    ],
    [
        "rhs = [(c.customer_id, c.company) for c in customers]",
        "rhs = [(c.customer_id, c.company) for"
    ],
    [
        "\"'in' subquery lookup of ('customer_code', 'company_code') \"",
        "\"'in' subquery lookup of"
    ],
    [
        "\"must be a Query object (received 'In')\",",
        "\"must be a Query object"
    ],
    [
        "\"'in' lookup of ('customer_code', 'company_code') \"",
        "\"'in' lookup of ('customer_code', 'company_code')"
    ],
    [
        "\"must be a collection of tuples or lists\",",
        "\"must be a collection"
    ],
    [
        "\"'in' lookup of ('customer_code', 'company_code') \"",
        "\"'in' lookup of"
    ],
    [
        "ValueError, \"'lt' doesn't support multi-column subqueries.\"",
        "ValueError, \"'lt' doesn't"
    ],
    [
        "ValueError, \"'lte' doesn't support multi-column subqueries.\"",
        "ValueError, \"'lte' doesn't"
    ],
    [
        "ValueError, \"'gt' doesn't support multi-column subqueries.\"",
        "ValueError, \"'gt' doesn't support"
    ],
    [
        "ValueError, \"'gte' doesn't support multi-column subqueries.\"",
        "ValueError, \"'gte' doesn't"
    ],
    [
        "ValueError, \"'isnull' doesn't support multi-column subqueries.\"",
        "ValueError, \"'isnull' doesn't support"
    ],
    [
        "f\"'{lookup_name}' lookup of ('customer_code', 'company_code') \"",
        "f\"'{lookup_name}' lookup of ('customer_code', 'company_code')"
    ],
    [
        "\"must be a tuple or a list\",",
        "\"must be a tuple"
    ],
    [
        "f\"'{lookup_name}' lookup of ('customer_code', 'company_code') \"",
        "f\"'{lookup_name}' lookup of"
    ],
    [
        "It's possible to create a working related field that doesn't",
        "It's possible to create a"
    ],
    [
        "use any joining columns, as long as an extra restriction is supplied.",
        "use any joining columns, as long as an extra restriction"
    ],
    [
        "message = \"Join generated an empty ON clause.\"",
        "message = \"Join generated an empty"
    ],
    [
        "from .models import Address, Contact, Customer",
        "from .models import Address, Contact,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase,"
    ],
    [
        "cls.usa = Country.objects.create(name=\"United States of America\")",
        "cls.usa = Country.objects.create(name=\"United"
    ],
    [
        "Recompiling the same subquery doesn't mutate it.",
        "Recompiling the same subquery doesn't"
    ],
    [
        "normal_people = [m.person for m in Membership.objects.order_by(\"pk\")]",
        "normal_people = [m.person for"
    ],
    [
        "normal_people = [m.person for m in Membership.objects.order_by(\"pk\")]",
        "normal_people = [m.person for m in"
    ],
    [
        "normal_members_lists = [list(g.members.all()) for g in Group.objects.all()]",
        "normal_members_lists = [list(g.members.all()) for g"
    ],
    [
        "normal_groups_lists = [list(p.groups.all()) for p in Person.objects.all()]",
        "normal_groups_lists = [list(p.groups.all()) for p"
    ],
    [
        "\"Cannot resolve keyword 'tags' into field. Choices are: \"",
        "\"Cannot resolve keyword 'tags' into field. Choices"
    ],
    [
        "\"Cannot resolve keyword 'ideas' into field. Choices are: \"",
        "\"Cannot resolve keyword 'ideas' into field. Choices are:"
    ],
    [
        "The path_infos and reverse_path_infos attributes are equivalent to",
        "The path_infos and reverse_path_infos attributes are"
    ],
    [
        "calling the get_<method>() with no arguments.",
        "calling the get_<method>() with no"
    ],
    [
        "Shallow copying a ForeignObject (or a ForeignObjectRel) removes the",
        "Shallow copying a ForeignObject (or"
    ],
    [
        "Deep copying a ForeignObject removes the object's cached PathInfo",
        "Deep copying a ForeignObject removes the"
    ],
    [
        "values, including those of the related ForeignObjectRel.",
        "values, including those of the related"
    ],
    [
        "Pickling a ForeignObjectRel removes the path_infos attribute.",
        "Pickling a ForeignObjectRel removes the path_infos"
    ],
    [
        "ForeignObjectRel implements __getstate__(), so copy and pickle modules",
        "ForeignObjectRel implements __getstate__(), so copy and pickle"
    ],
    [
        "both use that, but ForeignObject implements __reduce__() and __copy__()",
        "both use that, but ForeignObject"
    ],
    [
        "separately, so doesn't share the same behaviour.",
        "separately, so doesn't share the same"
    ],
    [
        "Pickling a ForeignObject does not remove the cached PathInfo values.",
        "Pickling a ForeignObject does not remove the"
    ],
    [
        "ForeignObject will always keep the path_infos and reverse_path_infos",
        "ForeignObject will always keep the path_infos"
    ],
    [
        "attributes within the same process, because of the way",
        "attributes within the same process, because"
    ],
    [
        "Field.__reduce__() is used for restoring values.",
        "Field.__reduce__() is used for"
    ],
    [
        "group_name = self.group.name if self.group_id else \"NULL\"",
        "group_name = self.group.name if"
    ],
    [
        "return \"%s is a member of %s\" % (self.person.name, group_name)",
        "return \"%s is a member of %s\" %"
    ],
    [
        "Define some extra Field methods so this Rel acts more like a Field, which",
        "Define some extra Field methods so this Rel acts more like a Field,"
    ],
    [
        "lets us use ReverseManyToOneDescriptor in both directions.",
        "lets us use ReverseManyToOneDescriptor in"
    ],
    [
        "return tuple(lhs_field for lhs_field, rhs_field in self.field.related_fields)",
        "return tuple(lhs_field for lhs_field, rhs_field"
    ],
    [
        "A ForeignObject that uses StartsWith operator in its joins instead of",
        "A ForeignObject that uses StartsWith operator in its joins"
    ],
    [
        "the default equality operator. This is logically a many-to-many relation",
        "the default equality operator. This is logically"
    ],
    [
        "and creates a ReverseManyToOneDescriptor in both directions.",
        "and creates a ReverseManyToOneDescriptor in"
    ],
    [
        "Makes ReverseManyToOneDescriptor work in both directions.",
        "Makes ReverseManyToOneDescriptor work"
    ],
    [
        "This model is designed to yield no join conditions and",
        "This model is designed to"
    ],
    [
        "from .article import Article, ArticleIdea, ArticleTag, ArticleTranslation, NewsArticle",
        "from .article import Article, ArticleIdea, ArticleTag,"
    ],
    [
        "from .customers import Address, Contact, Customer",
        "from .customers import Address, Contact,"
    ],
    [
        "from .person import Country, Friendship, Group, Membership, Person",
        "from .person import Country, Friendship, Group, Membership,"
    ],
    [
        "The set of articletranslation should not set any local fields.",
        "The set of articletranslation should"
    ],
    [
        "raise AttributeError(\"%s must be accessed via instance\" % self.field.name)",
        "raise AttributeError(\"%s must be accessed"
    ],
    [
        "if value is not None and not self.field.remote_field.multiple:",
        "if value is not"
    ],
    [
        "self.alias, self.col, self.value = alias, col, value",
        "self.alias, self.col, self.value ="
    ],
    [
        "return \"%s.%s = %%s\" % (qn(self.alias), qn(self.col)), [self.value]",
        "return \"%s.%s = %%s\" % (qn(self.alias),"
    ],
    [
        "This field will allow querying and fetching the currently active translation",
        "This field will allow querying and"
    ],
    [
        "Media that can associated to any object.",
        "Media that can associated"
    ],
    [
        "category = models.ForeignKey(Category, models.SET_NULL, null=True, blank=True)",
        "category = models.ForeignKey(Category, models.SET_NULL,"
    ],
    [
        "from .models import Category, Contact, Episode, EpisodePermanent, Media, PhoneNumber",
        "from .models import Category, Contact, Episode, EpisodePermanent,"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, TestCase, override_settings",
        "from django.test import RequestFactory,"
    ],
    [
        "from .admin import site as admin_site",
        "from .admin import site as"
    ],
    [
        "from .models import Category, Episode, EpisodePermanent, Media, PhoneNumber",
        "from .models import Category, Episode,"
    ],
    [
        "e = Episode.objects.create(name=\"This Week in Django\")",
        "e = Episode.objects.create(name=\"This"
    ],
    [
        "A smoke test to ensure GET on the add_view works.",
        "A smoke test to ensure GET on the"
    ],
    [
        "A smoke test to ensure GET on the change_view works.",
        "A smoke test to ensure GET on the"
    ],
    [
        "A smoke test to ensure POST on add_view works.",
        "A smoke test to ensure POST on"
    ],
    [
        "A smoke test to ensure POST on edit_view works.",
        "A smoke test to ensure POST"
    ],
    [
        "Create a model with an attached Media object via GFK. We can't",
        "Create a model with an attached Media"
    ],
    [
        "load content via a fixture (since the GenericForeignKey relies on",
        "load content via a fixture (since"
    ],
    [
        "content type IDs, which will vary depending on what other tests",
        "content type IDs, which will vary depending on what"
    ],
    [
        "have been run), thus we do it here.",
        "have been run), thus we do"
    ],
    [
        "e = model.objects.create(name=\"This Week in Django\")",
        "e = model.objects.create(name=\"This Week in"
    ],
    [
        "self.assertContains(response, \"Are you sure you want to delete\")",
        "self.assertContains(response, \"Are you sure you want"
    ],
    [
        "The custom ModelForm's `Meta.exclude` is respected when",
        "The custom ModelForm's `Meta.exclude` is respected"
    ],
    [
        "and when no `ModelAdmin.exclude` is defined.",
        "and when no `ModelAdmin.exclude`"
    ],
    [
        "The custom ModelForm's `Meta.exclude` is respected by",
        "The custom ModelForm's `Meta.exclude` is respected"
    ],
    [
        "for (formset, inline), other_inline in zip(",
        "for (formset, inline),"
    ],
    [
        "Any method you add to a model will be available to instances.",
        "Any method you add to a model will be available"
    ],
    [
        "database query for the sake of demonstration.",
        "database query for the sake"
    ],
    [
        "return [self.__class__(*row) for row in cursor.fetchall()]",
        "return [self.__class__(*row) for"
    ],
    [
        "user = models.ForeignKey(User, models.CASCADE, unique=True, to_field=\"username\")",
        "user = models.ForeignKey(User, models.CASCADE,"
    ],
    [
        "A formset over a ForeignKey with a to_field can be saved.",
        "A formset over a ForeignKey with a to_field can"
    ],
    [
        "self.fail(\"Errors found on form:%s\" % form_set)",
        "self.fail(\"Errors found on form:%s\""
    ],
    [
        "self.fail(\"Errors found on formset:%s\" % form_set.errors)",
        "self.fail(\"Errors found on formset:%s\""
    ],
    [
        "self.fail(\"Errors found on formset:%s\" % form_set.errors)",
        "self.fail(\"Errors found on formset:%s\""
    ],
    [
        "self.fail(\"Errors found on formset:%s\" % form_set.errors)",
        "self.fail(\"Errors found on formset:%s\" %"
    ],
    [
        "A formset over a ForeignKey with a to_field can be saved.",
        "A formset over a ForeignKey with a"
    ],
    [
        "self.fail(\"Errors found on form:%s\" % form_set)",
        "self.fail(\"Errors found on form:%s\" %"
    ],
    [
        "self.fail(\"Errors found on formset:%s\" % form_set.errors)",
        "self.fail(\"Errors found on formset:%s\" %"
    ],
    [
        "self.fail(\"Errors found on formset:%s\" % form_set.errors)",
        "self.fail(\"Errors found on formset:%s\""
    ],
    [
        "self.fail(\"Errors found on formset:%s\" % form_set.errors)",
        "self.fail(\"Errors found on formset:%s\" %"
    ],
    [
        "\"\"\"An inline model with a OneToOneField with to_field & primary key.\"\"\"",
        "\"\"\"An inline model with a OneToOneField with to_field &"
    ],
    [
        "formset with instance has working relations.",
        "formset with instance has working"
    ],
    [
        "No fields passed to modelformset_factory() should result in no fields",
        "No fields passed to modelformset_factory() should"
    ],
    [
        "Existing and new inlines are saved with save_as_new.",
        "Existing and new inlines are saved with"
    ],
    [
        "Test the type of Formset and Form error attributes",
        "Test the type of Formset and Form"
    ],
    [
        "defined in Meta should not raise errors and BaseModelForm should respect",
        "defined in Meta should not raise errors and BaseModelForm should"
    ],
    [
        "A formset mix-in that lets a form decide if it's to be deleted.",
        "A formset mix-in that lets a form decide if it's to"
    ],
    [
        "form.should_delete() is called. The formset delete field is also suppressed.",
        "form.should_delete() is called. The formset delete field"
    ],
    [
        "BaseModelFormSet should use ModelFormSet method _should_delete_form.",
        "BaseModelFormSet should use ModelFormSet"
    ],
    [
        "\"\"\"A model form with a 'should_delete' method\"\"\"",
        "\"\"\"A model form with"
    ],
    [
        "\"\"\"Add test data to database via formset\"\"\"",
        "\"\"\"Add test data to database via"
    ],
    [
        "\"\"\"Verify base formset doesn't modify database\"\"\"",
        "\"\"\"Verify base formset doesn't"
    ],
    [
        "\"\"\"Verify base formset honors DELETE field\"\"\"",
        "\"\"\"Verify base formset honors DELETE"
    ],
    [
        "{\"form-%d-id\" % i: user.pk for i, user in enumerate(User.objects.all())}",
        "{\"form-%d-id\" % i: user.pk for i, user"
    ],
    [
        "\"\"\"Verify DeleteFormset ignores DELETE field and uses form method\"\"\"",
        "\"\"\"Verify DeleteFormset ignores DELETE field and uses"
    ],
    [
        "\"signature() method should generate a signature\"",
        "\"signature() method should generate a"
    ],
    [
        "msg = \"'whatever' is not an algorithm accepted by the hashlib module.\"",
        "msg = \"'whatever' is not an algorithm accepted by the hashlib"
    ],
    [
        "\"jkw osanteuh ,rcuh nthu aou oauh ,ud du\",",
        "\"jkw osanteuh ,rcuh nthu"
    ],
    [
        "\"unsign should raise an exception if the value has been tampered with\"",
        "\"unsign should raise an exception if the value has been tampered"
    ],
    [
        "\"dumps and loads be reversible for any JSON serializable object\"",
        "\"dumps and loads be reversible for any"
    ],
    [
        "\"loads should raise exception for tampered objects\"",
        "\"loads should raise exception for"
    ],
    [
        "\"\"\"The default key is a valid verification key.\"\"\"",
        "\"\"\"The default key is a valid"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import RequestFactory, SimpleTestCase,"
    ],
    [
        "from . import middleware as mw",
        "from . import"
    ],
    [
        "TemplateResponses returned from process_view() must be rendered before",
        "TemplateResponses returned from process_view() must be"
    ],
    [
        "being passed to any middleware that tries to access response.content,",
        "being passed to any middleware that tries to"
    ],
    [
        "TemplateResponses returned from process_view() should be passed to any",
        "TemplateResponses returned from process_view() should"
    ],
    [
        "\"return an HttpResponse object. It returned None instead.\"",
        "\"return an HttpResponse object. It returned None"
    ],
    [
        "\"Asynchronous handler adapted for middleware \"",
        "\"Asynchronous handler adapted"
    ],
    [
        "\"Synchronous handler adapted for middleware \"",
        "\"Synchronous handler adapted"
    ],
    [
        "\"have at least one of sync_capable/async_capable set to True.\"",
        "\"have at least one of sync_capable/async_capable set to"
    ],
    [
        "\"Asynchronous handler adapted for middleware \"",
        "\"Asynchronous handler adapted for middleware"
    ],
    [
        "\"didn't return an HttpResponse object. It returned None instead.\"",
        "\"didn't return an HttpResponse object. It returned"
    ],
    [
        "def process_view(self, request, view_func, view_args, view_kwargs):",
        "def process_view(self, request, view_func, view_args,"
    ],
    [
        "return HttpResponse(\"Processed view %s\" % view_func.__name__)",
        "return HttpResponse(\"Processed view"
    ],
    [
        "async def process_view(self, request, view_func, view_args, view_kwargs):",
        "async def process_view(self, request,"
    ],
    [
        "return HttpResponse(\"Processed view %s\" % view_func.__name__)",
        "return HttpResponse(\"Processed view %s\""
    ],
    [
        "def process_view(self, request, view_func, view_args, view_kwargs):",
        "def process_view(self, request, view_func,"
    ],
    [
        "def process_view(self, request, view_func, view_args, view_kwargs):",
        "def process_view(self, request, view_func,"
    ],
    [
        "\"Processed view {{ view }}{% for m in mw %}\\n{{ m }}{% endfor %}\"",
        "\"Processed view {{ view }}{% for m"
    ],
    [
        "\"\"\"Middleware that is deliberately neither sync or async.\"\"\"",
        "\"\"\"Middleware that is deliberately neither sync or"
    ],
    [
        "\"template_response OK{% for m in mw %}\\n{{ m }}{% endfor %}\"",
        "\"template_response OK{% for m in mw %}\\n{{ m }}{% endfor"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, TestCase, override_settings",
        "from django.test import RequestFactory, SimpleTestCase, TestCase,"
    ],
    [
        "from .models import Book, Bookmark, Department, Employee, ImprovedBook, TaggedItem",
        "from .models import Book, Bookmark, Department, Employee,"
    ],
    [
        "def __init__(self, field, request, params, model, model_admin, field_path):",
        "def __init__(self, field, request, params,"
    ],
    [
        "super().__init__(field, request, params, model, model_admin, field_path)",
        "super().__init__(field, request, params,"
    ],
    [
        "for choice, expected_display in zip(choices, expected_displays, strict=True):",
        "for choice, expected_display in zip(choices, expected_displays,"
    ],
    [
        "The last choice is for the None value.",
        "The last choice is"
    ],
    [
        "choice = select_by(filterspec.choices(changelist), \"display\", \"This month\")",
        "choice = select_by(filterspec.choices(changelist),"
    ],
    [
        "choice = select_by(filterspec.choices(changelist), \"display\", \"This year\")",
        "choice = select_by(filterspec.choices(changelist), \"display\", \"This"
    ],
    [
        "choice = select_by(filterspec.choices(changelist), \"display\", \"No date\")",
        "choice = select_by(filterspec.choices(changelist), \"display\", \"No"
    ],
    [
        "choice = select_by(filterspec.choices(changelist), \"display\", \"Has date\")",
        "choice = select_by(filterspec.choices(changelist), \"display\", \"Has"
    ],
    [
        "\"Windows doesn't support setting a timezone that differs from the \"",
        "\"Windows doesn't support setting a timezone that differs from"
    ],
    [
        "expected = [(self.jack.pk, \"Jack Red\"), (self.john.pk, \"John Blue\")]",
        "expected = [(self.jack.pk, \"Jack Red\"),"
    ],
    [
        "expected = [(self.john.pk, \"John Blue\"), (self.jack.pk, \"Jack Red\")]",
        "expected = [(self.john.pk, \"John Blue\"), (self.jack.pk,"
    ],
    [
        "expected = [(self.jack.pk, \"Jack Red\"), (self.john.pk, \"John Blue\")]",
        "expected = [(self.jack.pk, \"Jack Red\"), (self.john.pk, \"John"
    ],
    [
        "(self.djangonaut_book.pk, \"Djangonaut: an art of living\"),",
        "(self.djangonaut_book.pk, \"Djangonaut: an"
    ],
    [
        "expected = [(self.alfred.pk, \"alfred\"), (self.bob.pk, \"bob\")]",
        "expected = [(self.alfred.pk, \"alfred\"),"
    ],
    [
        "(self.djangonaut_book.pk, \"Djangonaut: an art of living\"),",
        "(self.djangonaut_book.pk, \"Djangonaut: an"
    ],
    [
        "expected = [(albert.pk, \"Albert Green\"), (self.jack.pk, \"Jack Red\")]",
        "expected = [(albert.pk, \"Albert Green\"),"
    ],
    [
        "expected = [(albert.pk, \"Albert Green\"), (self.jack.pk, \"Jack Red\")]",
        "expected = [(albert.pk, \"Albert Green\"), (self.jack.pk,"
    ],
    [
        "expected = [(self.bob.pk, \"bob\"), (self.lisa.pk, \"lisa\")]",
        "expected = [(self.bob.pk, \"bob\"),"
    ],
    [
        "Ensure ('fieldpath', ClassName ) lookups pass lookup_allowed checks",
        "Ensure ('fieldpath', ClassName )"
    ],
    [
        "Any filter must define a title.",
        "Any filter must define a"
    ],
    [
        "\"The list filter 'DecadeListFilterWithoutTitle' does not specify a 'title'.\"",
        "\"The list filter 'DecadeListFilterWithoutTitle' does not"
    ],
    [
        "Any SimpleListFilter must define a parameter_name.",
        "Any SimpleListFilter must define"
    ],
    [
        "\"The list filter 'DecadeListFilterWithoutParameter' does not specify a \"",
        "\"The list filter 'DecadeListFilterWithoutParameter' does not"
    ],
    [
        "A SimpleListFilter lookups method can return None but disables the",
        "A SimpleListFilter lookups method can return"
    ],
    [
        "When a filter's queryset method fails, it fails loudly and",
        "When a filter's queryset method"
    ],
    [
        "for filterspec, expected_displays in zip(filters, tests, strict=True):",
        "for filterspec, expected_displays in"
    ],
    [
        "for filterspec, expected_displays in zip(filters, tests, strict=True):",
        "for filterspec, expected_displays in"
    ],
    [
        "[\"All\", \"Non-Fictional\", \"Fictional\", \"We don't know\", \"Not categorized\"],",
        "[\"All\", \"Non-Fictional\", \"Fictional\", \"We don't"
    ],
    [
        "[\"All\", \"Owned by Dev Department\", \"Other\"],",
        "[\"All\", \"Owned by Dev"
    ],
    [
        "for filterspec, expected_displays in zip(filters, tests, strict=True):",
        "for filterspec, expected_displays in zip(filters, tests,"
    ],
    [
        "for i, (display, selected, query_string) in enumerate(expected_choice_values):",
        "for i, (display, selected, query_string) in"
    ],
    [
        "for i, (display, selected, query_string) in enumerate(expected_choice_values):",
        "for i, (display, selected,"
    ],
    [
        "for i, (display, selected, query_string) in enumerate(expected_choice_values):",
        "for i, (display, selected, query_string) in"
    ],
    [
        "A SimpleListFilter's parameter name is not mistaken for a model field",
        "A SimpleListFilter's parameter name is not mistaken for"
    ],
    [
        "Ensure choices are set the selected class when using non-string values",
        "Ensure choices are set the selected class"
    ],
    [
        "Ensure SimpleListFilter lookups pass lookup_allowed checks when",
        "Ensure SimpleListFilter lookups pass lookup_allowed checks"
    ],
    [
        "Ensure SimpleListFilter can access self.value() inside the lookup.",
        "Ensure SimpleListFilter can access"
    ],
    [
        "choices = tuple(c[\"display\"] for c in filterspec.choices(changelist))",
        "choices = tuple(c[\"display\"] for c in"
    ],
    [
        "A list filter that filters the queryset by default gives the correct",
        "A list filter that filters the queryset by default gives"
    ],
    [
        "for modeladmin, query_string, expected_result in tests:",
        "for modeladmin, query_string, expected_result"
    ],
    [
        "for modeladmin, query_string, expected_result in tests:",
        "for modeladmin, query_string,"
    ],
    [
        "\"The list filter 'EmptyFieldListFilter' cannot be used with field \"",
        "\"The list filter 'EmptyFieldListFilter' cannot be used with"
    ],
    [
        "\"'department' which doesn't allow empty strings and nulls.\"",
        "\"'department' which doesn't allow empty strings and"
    ],
    [
        "Filter __in lookups with a custom divider.",
        "Filter __in lookups with a custom"
    ],
    [
        "\"/\", {\"name__in\": \"|\".join(e.name for e in employees)}",
        "\"/\", {\"name__in\": \"|\".join(e.name for e in"
    ],
    [
        "msg = \"subclasses of FacetsMixin must provide a get_facet_counts() method.\"",
        "msg = \"subclasses of FacetsMixin must provide a get_facet_counts()"
    ],
    [
        "assert k in [f.attname for f in self._meta.fields], (",
        "assert k in [f.attname for f in"
    ],
    [
        "\"Author.__init__ got an unexpected parameter: %s\" % k",
        "\"Author.__init__ got an unexpected"
    ],
    [
        "\"It was a bright cold day in April and the clocks were striking \"",
        "\"It was a bright cold day in April and the clocks were striking"
    ],
    [
        "\"On an evening in the latter part of May a middle-aged man \"",
        "\"On an evening in the latter part of May"
    ],
    [
        "\"was walking homeward from Shaston to the village of Marlott, \"",
        "\"was walking homeward from Shaston to the village of Marlott,"
    ],
    [
        "\"in the adjoining Vale of Blakemore, or Blackmoor.\"",
        "\"in the adjoining Vale"
    ],
    [
        "opening_line=\"A squat gray building of only thirty-four stories.\",",
        "opening_line=\"A squat gray building of only thirty-four"
    ],
    [
        "opening_line=\"It was the day my grandmother exploded.\",",
        "opening_line=\"It was the day my grandmother"
    ],
    [
        "Execute the passed query against the passed model and check the output",
        "Execute the passed query against the passed model"
    ],
    [
        "def assertProcessed(self, model, results, orig, expected_annotations=()):",
        "def assertProcessed(self, model, results, orig,"
    ],
    [
        "Compare the results of a raw query against expected results",
        "Compare the results of a raw query"
    ],
    [
        "The results of a raw query contain no annotations",
        "The results of a raw query"
    ],
    [
        "The passed raw query results contain the expected annotations",
        "The passed raw query results contain the"
    ],
    [
        "queryset = RawQuerySet(raw_query=\"SELECT * FROM raw_query_author\")",
        "queryset = RawQuerySet(raw_query=\"SELECT"
    ],
    [
        "repr(queryset), \"<RawQuerySet: SELECT * FROM raw_query_author>\"",
        "repr(queryset), \"<RawQuerySet: SELECT"
    ],
    [
        "repr(queryset.query), \"<RawQuery: SELECT * FROM raw_query_author>\"",
        "repr(queryset.query), \"<RawQuery: SELECT *"
    ],
    [
        "Basic test of raw query with a simple database query",
        "Basic test of raw query with a simple"
    ],
    [
        "query = \"SELECT * FROM raw_query_author\"",
        "query = \"SELECT"
    ],
    [
        "Raw queries are lazy: they aren't actually executed until they're",
        "Raw queries are lazy: they aren't"
    ],
    [
        "q = Author.objects.raw(\"SELECT * FROM raw_query_author\")",
        "q = Author.objects.raw(\"SELECT"
    ],
    [
        "Test of a simple raw query against a model containing a foreign key",
        "Test of a simple raw query against a model containing a foreign"
    ],
    [
        "query = \"SELECT * FROM raw_query_book\"",
        "query = \"SELECT * FROM"
    ],
    [
        "Test of a simple raw query against a model containing a field with",
        "Test of a simple raw query against a"
    ],
    [
        "query = \"SELECT * FROM raw_query_coffee\"",
        "query = \"SELECT *"
    ],
    [
        "A raw query with a model that has a pk db_column with mixed case.",
        "A raw query with a model that"
    ],
    [
        "query = \"SELECT * FROM raw_query_mixedcaseidcolumn\"",
        "query = \"SELECT * FROM"
    ],
    [
        "\"\"\"Raw query tolerates columns being returned in any order.\"\"\"",
        "\"\"\"Raw query tolerates columns being"
    ],
    [
        "query = \"SELECT %s FROM raw_query_author\" % select",
        "query = \"SELECT %s FROM"
    ],
    [
        "Test of raw query's optional ability to translate unexpected result",
        "Test of raw query's optional ability to translate"
    ],
    [
        "column names to specific model fields",
        "column names to"
    ],
    [
        "\"SELECT first_name AS first, last_name AS last, dob, id \"",
        "\"SELECT first_name AS first, last_name AS last, dob,"
    ],
    [
        "translations = {\"first\": \"first_name\", \"last\": \"last_name\"}",
        "translations = {\"first\": \"first_name\", \"last\":"
    ],
    [
        "query = \"SELECT * FROM raw_query_author WHERE first_name = %s\"",
        "query = \"SELECT * FROM"
    ],
    [
        "query = \"SELECT * FROM raw_query_author WHERE first_name like 'J%'\"",
        "query = \"SELECT * FROM raw_query_author WHERE"
    ],
    [
        "query = \"SELECT * FROM raw_query_author WHERE first_name like 'J%%'\"",
        "query = \"SELECT * FROM raw_query_author WHERE"
    ],
    [
        "query = \"SELECT * FROM raw_query_author WHERE first_name = %(first)s\"",
        "query = \"SELECT * FROM raw_query_author WHERE first_name ="
    ],
    [
        "Test representation of raw query with parameters",
        "Test representation of raw query with"
    ],
    [
        "query = \"SELECT * FROM raw_query_author WHERE last_name = %(last)s\"",
        "query = \"SELECT * FROM raw_query_author WHERE last_name ="
    ],
    [
        "\"<RawQuerySet: SELECT * FROM raw_query_author WHERE last_name = foo>\",",
        "\"<RawQuerySet: SELECT * FROM raw_query_author WHERE"
    ],
    [
        "\"<RawQuery: SELECT * FROM raw_query_author WHERE last_name = foo>\",",
        "\"<RawQuery: SELECT * FROM raw_query_author WHERE last_name ="
    ],
    [
        "query = \"SELECT * FROM raw_query_author WHERE last_name = %s\"",
        "query = \"SELECT * FROM raw_query_author"
    ],
    [
        "\"<RawQuerySet: SELECT * FROM raw_query_author WHERE last_name = foo>\",",
        "\"<RawQuerySet: SELECT * FROM raw_query_author WHERE last_name"
    ],
    [
        "\"<RawQuery: SELECT * FROM raw_query_author WHERE last_name = foo>\",",
        "\"<RawQuery: SELECT * FROM raw_query_author WHERE"
    ],
    [
        "query = \"SELECT * FROM raw_query_reviewer\"",
        "query = \"SELECT"
    ],
    [
        "query = \"SELECT * FROM raw_query_author\"",
        "query = \"SELECT * FROM"
    ],
    [
        "query = \"SELECT id, first_name, dob FROM raw_query_author\"",
        "query = \"SELECT id, first_name, dob FROM"
    ],
    [
        "query = \"SELECT first_name, dob FROM raw_query_author\"",
        "query = \"SELECT first_name, dob"
    ],
    [
        "msg = \"Raw query must include the primary key\"",
        "msg = \"Raw query must include the primary"
    ],
    [
        "\"SELECT a.*, count(b.id) as book_count \"",
        "\"SELECT a.*, count(b.id)"
    ],
    [
        "\"LEFT JOIN raw_query_book b ON a.id = b.author_id \"",
        "\"LEFT JOIN raw_query_book b ON a.id ="
    ],
    [
        "\"GROUP BY a.id, a.first_name, a.last_name, a.dob ORDER BY a.id\"",
        "\"GROUP BY a.id, a.first_name, a.last_name, a.dob ORDER"
    ],
    [
        "query = \"    SELECT * FROM raw_query_author\"",
        "query = \" SELECT"
    ],
    [
        "query = \"SELECT * FROM raw_query_author\"",
        "query = \"SELECT *"
    ],
    [
        "query = \"SELECT * FROM raw_query_author ORDER BY id ASC\"",
        "query = \"SELECT * FROM raw_query_author ORDER"
    ],
    [
        "query = \"SELECT * FROM raw_query_friendlyauthor\"",
        "query = \"SELECT"
    ],
    [
        "self.assertEqual([o.pk for o in FriendlyAuthor.objects.raw(query)], [f.pk])",
        "self.assertEqual([o.pk for o"
    ],
    [
        "\"(SELECT * FROM raw_query_book WHERE paperback IS NOT NULL) sq\"",
        "\"(SELECT * FROM raw_query_book WHERE paperback IS NOT NULL)"
    ],
    [
        "Regression test that ensures the `column` attribute on the field is",
        "Regression test that ensures the `column` attribute on the field"
    ],
    [
        "used to generate the list of fields included in the query, as opposed",
        "used to generate the list of fields included in the"
    ],
    [
        "to the `attname`. This is important when the primary key is a",
        "to the `attname`. This is important when the primary"
    ],
    [
        "ForeignKey field because `attname` and `column` are not necessarily the",
        "ForeignKey field because `attname` and `column` are not necessarily"
    ],
    [
        "books = Book.objects.raw(\"SELECT * FROM raw_query_book\")",
        "books = Book.objects.raw(\"SELECT * FROM"
    ],
    [
        "books = Book.objects.raw(\"SELECT * FROM raw_query_book\")",
        "books = Book.objects.raw(\"SELECT *"
    ],
    [
        "msg = \"Pickled model instance's Django version is not specified.\"",
        "msg = \"Pickled model instance's Django"
    ],
    [
        "unpickled with a different Django version than the current",
        "unpickled with a different Django version than"
    ],
    [
        "A model may override __getstate__() to choose the attributes to pickle.",
        "A model may override __getstate__() to choose"
    ],
    [
        "msg = \"Number of args exceeds number of fields\"",
        "msg = \"Number of args exceeds"
    ],
    [
        "msg = \"get_next/get_previous cannot be used on unsaved objects.\"",
        "msg = \"get_next/get_previous cannot be used"
    ],
    [
        "Chained foreign keys with to_field produce incorrect query.",
        "Chained foreign keys with to_field produce incorrect"
    ],
    [
        "Model metaclasses have access to the class attribute dict in",
        "Model metaclasses have access to"
    ],
    [
        "You can filter by objects that have an 'evaluate' attr",
        "You can filter by objects"
    ],
    [
        "Testing some internals of the template processing.",
        "Testing some internals of the template"
    ],
    [
        "These are *not* examples to be copied in user code.",
        "These are *not* examples to be copied in"
    ],
    [
        "from django.template.defaultfilters import register as filter_library",
        "from django.template.defaultfilters import"
    ],
    [
        "TokenType.BLOCK, 'sometag _(\"Page not found\") value|yesno:_(\"yes,no\")'",
        "TokenType.BLOCK, 'sometag _(\"Page not"
    ],
    [
        "split, [\"sometag\", '_(\"Page not found\")', 'value|yesno:_(\"yes,no\")']",
        "split, [\"sometag\", '_(\"Page not"
    ],
    [
        "fe_test(r'\"Some \\\"Good\\\" News\"', 'Some \"Good\" News')",
        "fe_test(r'\"Some \\\"Good\\\" News\"', 'Some \"Good\""
    ],
    [
        "fe_test(r'\"Some \\\"Good\\\" News\"', 'Some \"Good\" News')",
        "fe_test(r'\"Some \\\"Good\\\" News\"',"
    ],
    [
        "fe_test(r\"'Some \\'Bad\\' News'\", \"Some 'Bad' News\")",
        "fe_test(r\"'Some \\'Bad\\' News'\", \"Some 'Bad'"
    ],
    [
        "fe = FilterExpression(r'\"Some \\\"Good\\\" News\"', p)",
        "fe = FilterExpression(r'\"Some"
    ],
    [
        "\"Variables and attributes may not begin with underscores: 'article._hidden'\"",
        "\"Variables and attributes may not begin with underscores:"
    ],
    [
        "Variable(r'\"Some \\\"Good\\\" News\"').resolve(c), 'Some \"Good\" News'",
        "Variable(r'\"Some \\\"Good\\\" News\"').resolve(c), 'Some"
    ],
    [
        "Variable(r\"'Some \\'Better\\' News'\").resolve(c), \"Some 'Better' News\"",
        "Variable(r\"'Some \\'Better\\' News'\").resolve(c),"
    ],
    [
        "msg = f\"Variables and attributes may not begin with underscores: '{name}'\"",
        "msg = f\"Variables and attributes may"
    ],
    [
        "TypeError, \"Variable must be a string or number, got <class 'dict'>\"",
        "TypeError, \"Variable must be a string"
    ],
    [
        "msg = \"Unsupported arguments to Library.filter: (None, '')\"",
        "msg = \"Unsupported arguments to"
    ],
    [
        "msg = \"Invalid arguments provided to simple_tag\"",
        "msg = \"Invalid arguments provided"
    ],
    [
        "msg = \"Invalid arguments provided to simple_block_tag\"",
        "msg = \"Invalid arguments provided"
    ],
    [
        "msg = \"Unsupported arguments to Library.tag: (None, '')\"",
        "msg = \"Unsupported arguments to Library.tag: (None,"
    ],
    [
        "from django.template import Context, Engine, TemplateDoesNotExist, TemplateSyntaxError",
        "from django.template import Context, Engine,"
    ],
    [
        "'{% extends \"one.html\" %}{% block content %}'",
        "'{% extends \"one.html\" %}{% block content"
    ],
    [
        "\"{{ block.super }} locmem-one{% endblock %}\"",
        "\"{{ block.super }}"
    ],
    [
        "'{% extends \"two.html\" %}{% block content %}'",
        "'{% extends \"two.html\" %}{% block content"
    ],
    [
        "\"{{ block.super }} locmem-two{% endblock %}\"",
        "\"{{ block.super }} locmem-two{% endblock"
    ],
    [
        "'{% extends \"three.html\" %}{% block content %}'",
        "'{% extends \"three.html\" %}{% block content"
    ],
    [
        "\"{{ block.super }} locmem-three{% endblock %}\"",
        "\"{{ block.super }}"
    ],
    [
        "output.strip(), \"three locmem-three two locmem-two one locmem-one\"",
        "output.strip(), \"three locmem-three two locmem-two one"
    ],
    [
        "Catch if a template extends itself and no other matching",
        "Catch if a template extends itself and"
    ],
    [
        "Extending should continue even if two loaders return the same",
        "Extending should continue even if two"
    ],
    [
        "'{% extends \"base.html\" %}{% block content %}'",
        "'{% extends \"base.html\" %}{% block"
    ],
    [
        "\"{% extends 'base.html' %}{% block base %}{{ block.super }}\"",
        "\"{% extends 'base.html' %}{% block base %}{{"
    ],
    [
        "\"{% extends 'included.html' %}{% block included %}\"",
        "\"{% extends 'included.html' %}{% block included"
    ],
    [
        "\"included.html\": \"{% block included %}A{% endblock %}\",",
        "\"included.html\": \"{% block included"
    ],
    [
        "{\"index.html\": \"{% block content %}B{% endblock %}{% extends 'base.html' %}\"}",
        "{\"index.html\": \"{% block content %}B{% endblock %}{% extends"
    ],
    [
        "msg = \"{% extends 'base.html' %} must be the first tag in 'index.html'.\"",
        "msg = \"{% extends 'base.html' %} must be the first"
    ],
    [
        "template_string = \"{% block content %}B{% endblock %}{% extends 'base.html' %}\"",
        "template_string = \"{% block content %}B{% endblock %}{%"
    ],
    [
        "msg = \"{% extends 'base.html' %} must be the first tag in the template.\"",
        "msg = \"{% extends 'base.html' %} must be"
    ],
    [
        "msg = \"No DjangoTemplates backend is configured.\"",
        "msg = \"No DjangoTemplates backend"
    ],
    [
        "msg = \"The response content must be rendered before it can be iterated over.\"",
        "msg = \"The response content must be rendered before it can be iterated"
    ],
    [
        "response = self._response(\"{{ foo }}{{ processors }}\", {\"foo\": \"bar\"})",
        "response = self._response(\"{{ foo }}{{"
    ],
    [
        "\"Rendering a template response triggers the post-render callbacks\"",
        "\"Rendering a template response triggers the post-render"
    ],
    [
        "response = self._response(\"{{ foo }}{{ processors }}\").render()",
        "response = self._response(\"{{ foo }}{{"
    ],
    [
        "response = self._response(\"{{ foo }}{{ processors }}\", {\"foo\": \"bar\"}).render()",
        "response = self._response(\"{{ foo }}{{"
    ],
    [
        "\"{{ foo }}{{ processors }}\", {\"processors\": \"no\"}",
        "\"{{ foo }}{{ processors }}\", {\"processors\":"
    ],
    [
        "self.assertContains(response, \"This is where you can find the snark: /snark/\")",
        "self.assertContains(response, \"This is where you"
    ],
    [
        "from django.template import Engine, Variable, VariableDoesNotExist",
        "from django.template import Engine,"
    ],
    [
        "\"Exception while resolving variable 'article' in template 'template_name'.\",",
        "\"Exception while resolving variable 'article'"
    ],
    [
        "\"Exception while resolving variable 'author' in template 'unknown'.\",",
        "\"Exception while resolving variable 'author' in template"
    ],
    [
        "\"Failed lookup for key [author] in {'section': 'News'}\",",
        "\"Failed lookup for key [author]"
    ],
    [
        "self.assertEqual(\"(or (literal True) (literal False))\", repr(var))",
        "self.assertEqual(\"(or (literal True)"
    ],
    [
        "self.assertCalcEqual(True, [False, \"and\", False, \"or\", True])",
        "self.assertCalcEqual(True, [False, \"and\","
    ],
    [
        "self.assertCalcEqual(True, [True, \"or\", False, \"and\", False])",
        "self.assertCalcEqual(True, [True, \"or\", False, \"and\","
    ],
    [
        "self.assertCalcEqual(True, [True, \"==\", True, \"or\", True, \"==\", False])",
        "self.assertCalcEqual(True, [True, \"==\", True,"
    ],
    [
        "With template debugging disabled, the raw TemplateDoesNotExist class",
        "With template debugging disabled, the raw"
    ],
    [
        "docstrings in the cached loader for details.",
        "docstrings in the cached loader"
    ],
    [
        "With template debugging enabled, a TemplateDoesNotExist instance",
        "With template debugging enabled,"
    ],
    [
        "should be cached when a template is missing.",
        "should be cached when a"
    ],
    [
        "When a TemplateDoesNotExist instance is cached, the cached instance",
        "When a TemplateDoesNotExist instance is"
    ],
    [
        "should not contain the __traceback__, __context__, or __cause__",
        "should not contain the __traceback__,"
    ],
    [
        "attributes that Python sets when raising exceptions.",
        "attributes that Python sets"
    ],
    [
        "error_msg = \"Cached TemplateDoesNotExist must not have been thrown.\"",
        "error_msg = \"Cached TemplateDoesNotExist must not have"
    ],
    [
        "to text before computing its cache key.",
        "to text before computing its cache"
    ],
    [
        "expected_sources = [os.path.abspath(s) for s in expected_sources]",
        "expected_sources = [os.path.abspath(s) for s in"
    ],
    [
        "\"\"\"An empty dirs list in loaders overrides top level dirs.\"\"\"",
        "\"\"\"An empty dirs list in loaders overrides top"
    ],
    [
        "msg = \"Can't mix strings and bytes in path components\"",
        "msg = \"Can't mix strings and bytes in path"
    ],
    [
        "\"This test only runs on case-sensitive file systems.\",",
        "\"This test only runs on case-sensitive file"
    ],
    [
        "\"Python on Windows doesn't have working os.chmod().\",",
        "\"Python on Windows doesn't have"
    ],
    [
        "template_path = Path(__file__).parent / \"templates\" / \"index.html\"",
        "template_path = Path(__file__).parent / \"templates\""
    ],
    [
        "template_path = Path(__file__).parent / \"templates\" / \"index.html\"",
        "template_path = Path(__file__).parent / \"templates\""
    ],
    [
        "template_path = Path(__file__).parent / \"templates\" / \"index.html\"",
        "template_path = Path(__file__).parent / \"templates\""
    ],
    [
        "template_path = Path(__file__).parent / \"templates\" / \"index.html\"",
        "template_path = Path(__file__).parent /"
    ],
    [
        "Runs test method multiple times in the following order:",
        "Runs test method multiple times in the"
    ],
    [
        "Use test_once=True to test deprecation warnings since the message won't be",
        "Use test_once=True to test deprecation warnings"
    ],
    [
        "\"Class whose __str__ returns non-ASCII data\"",
        "\"Class whose __str__ returns"
    ],
    [
        "from django.template import Context, Engine, TemplateSyntaxError",
        "from django.template import"
    ],
    [
        "\"The relative path '\\\"./../two.html\\\"' points outside the file \"",
        "\"The relative path '\\\"./../two.html\\\"' points outside the"
    ],
    [
        "\"hierarchy that template 'error_extends.html' is in.\"",
        "\"hierarchy that template 'error_extends.html'"
    ],
    [
        "\"The relative path '\\\"./../three.html\\\"' points outside the file \"",
        "\"The relative path '\\\"./../three.html\\\"' points outside"
    ],
    [
        "\"hierarchy that template 'error_include.html' is in.\"",
        "\"hierarchy that template 'error_include.html'"
    ],
    [
        "from django.template import Context, Engine, TemplateSyntaxError",
        "from django.template import Context, Engine,"
    ],
    [
        "t = engine.from_string(\"{% load custom %}{{ name|make_data_div }}\")",
        "t = engine.from_string(\"{% load custom"
    ],
    [
        "self.assertEqual(tag.__doc__, \"Expected %s __doc__\" % name)",
        "self.assertEqual(tag.__doc__, \"Expected %s __doc__\" %"
    ],
    [
        "self.assertEqual(tag.__dict__[\"anything\"], \"Expected %s __dict__\" % name)",
        "self.assertEqual(tag.__dict__[\"anything\"], \"Expected %s"
    ],
    [
        "(\"{% load custom %}{% no_params %}\", \"no_params - Expected result\"),",
        "(\"{% load custom %}{% no_params %}\","
    ],
    [
        "\"{% load custom %}{% no_params_with_context %}\",",
        "\"{% load custom %}{% no_params_with_context"
    ],
    [
        "\"{% load custom %}{% simple_keyword_only_default %}\",",
        "\"{% load custom"
    ],
    [
        "\"{% load custom %}{% simple_only_unlimited_args %}\",",
        "\"{% load custom"
    ],
    [
        "\"'simple_one_default' received unexpected keyword argument 'three'\",",
        "\"'simple_one_default' received unexpected keyword argument"
    ],
    [
        "\"'simple_two_params' received too many positional arguments\",",
        "\"'simple_two_params' received too many"
    ],
    [
        "\"'simple_one_default' received too many positional arguments\",",
        "\"'simple_one_default' received too"
    ],
    [
        "\"'simple_keyword_only_param' did not receive value(s) for the \"",
        "\"'simple_keyword_only_param' did not receive value(s)"
    ],
    [
        "\"{% load custom %}{% simple_keyword_only_param %}\",",
        "\"{% load custom %}{%"
    ],
    [
        "\"'simple_keyword_only_param' received multiple values for \"",
        "\"'simple_keyword_only_param' received multiple"
    ],
    [
        "\"'simple_keyword_only_default' received multiple values for \"",
        "\"'simple_keyword_only_default' received multiple values"
    ],
    [
        "\"'simple_unlimited_args_kwargs' received some positional argument(s) \"",
        "\"'simple_unlimited_args_kwargs' received some positional"
    ],
    [
        "\"'simple_unlimited_args_kwargs' received multiple values for keyword \"",
        "\"'simple_unlimited_args_kwargs' received multiple values for keyword"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"}, autoescape=False)",
        "c = Context({\"name\": \"Jack"
    ],
    [
        "t = self.engine.from_string(\"{% load custom %}{% escape_naive %}\")",
        "t = self.engine.from_string(\"{% load custom"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack &"
    ],
    [
        "t = self.engine.from_string(\"{% load custom %}{% escape_naive %}\")",
        "t = self.engine.from_string(\"{% load custom"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\":"
    ],
    [
        "t = self.engine.from_string(\"{% load custom %}{% escape_explicit %}\")",
        "t = self.engine.from_string(\"{% load custom %}{% escape_explicit"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack &"
    ],
    [
        "t = self.engine.from_string(\"{% load custom %}{% escape_format_html %}\")",
        "t = self.engine.from_string(\"{% load custom %}{% escape_format_html"
    ],
    [
        "\"takes_context=True so it must have a first argument of 'context'\"",
        "\"takes_context=True so it must have a first argument of"
    ],
    [
        "\"takes_context=True so it must have a first argument of 'context'\"",
        "\"takes_context=True so it must have"
    ],
    [
        "\"{% load custom %}{% simple_tag_takes_context_without_params %}\"",
        "\"{% load custom %}{% simple_tag_takes_context_without_params"
    ],
    [
        "\"{% load custom %}{% div %}content{% enddiv %}\",",
        "\"{% load custom %}{%"
    ],
    [
        "\"{% load custom %}{% no_params_with_context_block %}inner\"",
        "\"{% load custom %}{% no_params_with_context_block"
    ],
    [
        "\"simple_two_params_block - Expected result (content value: inner): \"",
        "\"simple_two_params_block - Expected result"
    ],
    [
        "\"simple_keyword_only_param_block - Expected result (content value: \"",
        "\"simple_keyword_only_param_block - Expected result (content"
    ],
    [
        "\"{% load custom %}{% simple_keyword_only_default_block %}forty two\"",
        "\"{% load custom %}{% simple_keyword_only_default_block %}forty"
    ],
    [
        "\"simple_keyword_only_default_block - Expected result (content value: \"",
        "\"simple_keyword_only_default_block - Expected result"
    ],
    [
        "\"simple_keyword_only_default_block - Expected result (content value: \"",
        "\"simple_keyword_only_default_block - Expected result (content"
    ],
    [
        "\"simple_one_default_block - Expected result (content value: inner): \"",
        "\"simple_one_default_block - Expected result (content"
    ],
    [
        "\"simple_one_default_block - Expected result (content value: inner): \"",
        "\"simple_one_default_block - Expected result (content value: inner):"
    ],
    [
        "\"simple_one_default_block - Expected result (content value: inner): \"",
        "\"simple_one_default_block - Expected result (content value: inner):"
    ],
    [
        "\"simple_one_default_block - Expected result (content value: inner): \"",
        "\"simple_one_default_block - Expected result (content value:"
    ],
    [
        "\"simple_unlimited_args_block - Expected result (content value: thirty \"",
        "\"simple_unlimited_args_block - Expected result (content value: thirty"
    ],
    [
        "\"{% load custom %}{% simple_only_unlimited_args_block %}inner\"",
        "\"{% load custom"
    ],
    [
        "\"simple_only_unlimited_args_block - Expected result (content value: \"",
        "\"simple_only_unlimited_args_block - Expected result (content value:"
    ],
    [
        "\"simple_unlimited_args_kwargs_block - Expected result (content value: \"",
        "\"simple_unlimited_args_kwargs_block - Expected result (content value:"
    ],
    [
        "\"'simple_one_default_block' received unexpected keyword argument \"",
        "\"'simple_one_default_block' received unexpected keyword"
    ],
    [
        "\"'simple_two_params_block' received too many positional arguments\",",
        "\"'simple_two_params_block' received too"
    ],
    [
        "\"'simple_one_default_block' received too many positional arguments\",",
        "\"'simple_one_default_block' received too"
    ],
    [
        "\"'simple_keyword_only_param_block' did not receive value(s) for the \"",
        "\"'simple_keyword_only_param_block' did not receive value(s)"
    ],
    [
        "\"{% load custom %}{% simple_keyword_only_param_block %}\"",
        "\"{% load custom %}{%"
    ],
    [
        "\"'simple_keyword_only_param_block' received multiple values for \"",
        "\"'simple_keyword_only_param_block' received multiple values for"
    ],
    [
        "\"'simple_keyword_only_default_block' received multiple values for \"",
        "\"'simple_keyword_only_default_block' received multiple values for"
    ],
    [
        "\"'simple_unlimited_args_kwargs_block' received multiple values for \"",
        "\"'simple_unlimited_args_kwargs_block' received multiple values for"
    ],
    [
        "\"{% load custom %}{% div %}Some content\",",
        "\"{% load custom %}{% div"
    ],
    [
        "\"{% load custom %}{% simple_one_default_block %}Some content\",",
        "\"{% load custom %}{%"
    ],
    [
        "\"'simple_tag_without_content_parameter' must have a first argument \"",
        "\"'simple_tag_without_content_parameter' must have a first argument"
    ],
    [
        "\"{% load custom %}{% simple_tag_without_content_parameter %}\",",
        "\"{% load custom %}{% simple_tag_without_content_parameter"
    ],
    [
        "\"takes_context=True so it must have a first argument of 'context' and \"",
        "\"takes_context=True so it must have a first argument of"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"}, autoescape=False)",
        "c = Context({\"name\": \"Jack"
    ],
    [
        "\"{% load custom %}{% escape_naive_block %}{{ name }} again\"",
        "\"{% load custom %}{% escape_naive_block %}{{"
    ],
    [
        "self.assertEqual(t.render(c), \"Hello Jack & Jill: Jack & Jill again!\")",
        "self.assertEqual(t.render(c), \"Hello Jack & Jill: Jack"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\":"
    ],
    [
        "\"{% load custom %}{% escape_naive_block %}{{ name }} again\"",
        "\"{% load custom %}{% escape_naive_block %}{{"
    ],
    [
        "t.render(c), \"Hello Jack &amp; Jill: Jack &amp;amp; Jill again!\"",
        "t.render(c), \"Hello Jack &amp; Jill:"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack &"
    ],
    [
        "\"{% load custom %}{% escape_explicit_block %}again\"",
        "\"{% load custom %}{%"
    ],
    [
        "self.assertEqual(t.render(c), \"Hello Jack &amp; Jill: again!\")",
        "self.assertEqual(t.render(c), \"Hello Jack &amp; Jill:"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack"
    ],
    [
        "\"{% load custom %}{% escape_format_html_block %}again\"",
        "\"{% load custom %}{% escape_format_html_block"
    ],
    [
        "self.assertEqual(t.render(c), \"Hello Jack &amp; Jill: again!\")",
        "self.assertEqual(t.render(c), \"Hello Jack &amp; Jill:"
    ],
    [
        "\"takes_context=True so it must have a first argument of 'context'\"",
        "\"takes_context=True so it must have a first argument"
    ],
    [
        "\"takes_context=True so it must have a first argument of 'context'\"",
        "\"takes_context=True so it must have a"
    ],
    [
        "\"{% load custom %}{% simple_tag_takes_context_without_params_block %}\"",
        "\"{% load custom %}{%"
    ],
    [
        "\"'simple_block_tag_without_content' must have a first argument of 'content'\"",
        "\"'simple_block_tag_without_content' must have a"
    ],
    [
        "\"{% load custom %}{% simple_block_tag_without_content %}\"",
        "\"{% load custom %}{% simple_block_tag_without_content"
    ],
    [
        "msg = \"'simple_block_tag_with_context_without_content' is decorated with \"",
        "msg = \"'simple_block_tag_with_context_without_content' is decorated with"
    ],
    [
        "\"takes_context=True so it must have a first argument of 'context' and a \"",
        "\"takes_context=True so it must have a first"
    ],
    [
        "\"{% load custom %}{% simple_block_tag_with_context_without_content %}\"",
        "\"{% load custom"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack"
    ],
    [
        "t = self.engine.from_string(\"{% load custom %}{% div %}{{ name }}{% enddiv %}\")",
        "t = self.engine.from_string(\"{% load custom %}{% div"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack"
    ],
    [
        "\"{% load custom %}{% div as div_content %}{{ name }}{% enddiv %}\"",
        "\"{% load custom %}{% div as div_content"
    ],
    [
        "\"My div is: {{ div_content }}\"",
        "\"My div is: {{"
    ],
    [
        "self.assertEqual(t.render(c), \"My div is: <div id='test'>Jack &amp; Jill</div>\")",
        "self.assertEqual(t.render(c), \"My div is: <div"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack &"
    ],
    [
        "\"{% load custom %}Start{% div id='outer' %}Before{% div id='inner' %}\"",
        "\"{% load custom %}Start{% div id='outer'"
    ],
    [
        "\"{{ name }}{% enddiv %}After{% enddiv %}End\"",
        "\"{{ name }}{% enddiv %}After{% enddiv"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack"
    ],
    [
        "\"{% load custom %}Start{% div id='outer' %}Before\"",
        "\"{% load custom %}Start{%"
    ],
    [
        "\"simple_keyword_only_default_block - Expected result (content value: \"",
        "\"simple_keyword_only_default_block - Expected result"
    ],
    [
        "c = Context({\"name\": \"Jack & Jill\"})",
        "c = Context({\"name\": \"Jack"
    ],
    [
        "\"{% load custom %}{% div_custom_end %}{{ name }}{% divend %}\"",
        "\"{% load custom %}{% div_custom_end %}{{ name }}{% divend"
    ],
    [
        "\"'enddiv_custom_end', expected 'divend'. Did you forget to register or \"",
        "\"'enddiv_custom_end', expected 'divend'. Did you forget to"
    ],
    [
        "\"{% load custom %}{% div_custom_end %}{{ name }}{% enddiv_custom_end %}\"",
        "\"{% load custom %}{% div_custom_end %}{{ name }}{% enddiv_custom_end"
    ],
    [
        "\"{% load inclusion %}{% inclusion_no_params %}\",",
        "\"{% load inclusion %}{% inclusion_no_params"
    ],
    [
        "\"{% load inclusion %}{% inclusion_no_params_with_context %}\",",
        "\"{% load inclusion %}{%"
    ],
    [
        "\"inclusion_no_params_with_context - Expected result (context value: \"",
        "\"inclusion_no_params_with_context - Expected result"
    ],
    [
        "\"{% load inclusion %}{% inclusion_only_unlimited_args %}\",",
        "\"{% load inclusion %}{% inclusion_only_unlimited_args"
    ],
    [
        "\"'inclusion_one_default' received unexpected keyword argument 'three'\",",
        "\"'inclusion_one_default' received unexpected keyword"
    ],
    [
        "\"'inclusion_two_params' received too many positional arguments\",",
        "\"'inclusion_two_params' received too many"
    ],
    [
        "\"'inclusion_one_default' received too many positional arguments\",",
        "\"'inclusion_one_default' received too"
    ],
    [
        "\"'inclusion_one_default' did not receive value(s) for the argument(s): \"",
        "\"'inclusion_one_default' did not receive value(s) for the argument(s):"
    ],
    [
        "\"{% load inclusion %}{% inclusion_one_default %}\",",
        "\"{% load inclusion"
    ],
    [
        "\"{% load inclusion %}{% inclusion_keyword_only_default \"",
        "\"{% load inclusion %}{% inclusion_keyword_only_default"
    ],
    [
        "\"'inclusion_unlimited_args' did not receive value(s) for the \"",
        "\"'inclusion_unlimited_args' did not receive"
    ],
    [
        "\"{% load inclusion %}{% inclusion_unlimited_args %}\",",
        "\"{% load inclusion %}{% inclusion_unlimited_args"
    ],
    [
        "\"'inclusion_unlimited_args_kwargs' received multiple values for \"",
        "\"'inclusion_unlimited_args_kwargs' received multiple"
    ],
    [
        "\"takes_context=True so it must have a first argument of 'context'\"",
        "\"takes_context=True so it must have a"
    ],
    [
        "\"takes_context=True so it must have a first argument of 'context'\"",
        "\"takes_context=True so it must have a first"
    ],
    [
        "\"{% load inclusion %}{% inclusion_tag_takes_context_without_params %}\"",
        "\"{% load inclusion %}{%"
    ],
    [
        "\"{% load inclusion %}{% inclusion_no_params_from_template %}\",",
        "\"{% load inclusion %}{% inclusion_no_params_from_template"
    ],
    [
        "\"inclusion_params_and_context_from_template - Expected result (context \"",
        "\"inclusion_params_and_context_from_template - Expected result"
    ],
    [
        "\"{% load inclusion %}{% inclusion_only_unlimited_args_from_template %}\",",
        "\"{% load inclusion %}{%"
    ],
    [
        "Context of the included/rendered template as well.",
        "Context of the included/rendered template as"
    ],
    [
        "template = engine.from_string(\"{% load inclusion %}{% inclusion_no_params %}\")",
        "template = engine.from_string(\"{% load inclusion %}{%"
    ],
    [
        "when rendering. Otherwise, leftover values such as blocks from",
        "when rendering. Otherwise, leftover values"
    ],
    [
        "extending can interfere with subsequent rendering.",
        "extending can interfere with subsequent"
    ],
    [
        "\"Invalid template library specified. ImportError raised when \"",
        "\"Invalid template library specified. ImportError"
    ],
    [
        "\"trying to load 'template_tests.broken_tag': cannot import name \"",
        "\"trying to load 'template_tests.broken_tag': cannot import"
    ],
    [
        "\"Invalid template library specified. ImportError raised when \"",
        "\"Invalid template library specified. ImportError raised"
    ],
    [
        "\"trying to load 'tagsegg.templatetags.broken_egg': cannot \"",
        "\"trying to load 'tagsegg.templatetags.broken_egg': cannot"
    ],
    [
        "ttext = \"{% load working_egg %}\"",
        "ttext = \"{%"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import"
    ],
    [
        "{\"False\": False, \"None\": None, \"True\": True},",
        "{\"False\": False, \"None\": None, \"True\":"
    ],
    [
        "{\"False\": False, \"None\": None, \"True\": True},",
        "{\"False\": False, \"None\": None, \"True\":"
    ],
    [
        "Context.push() with a Context argument should work.",
        "Context.push() with a Context"
    ],
    [
        "test_data = {\"x\": \"y\", \"v\": \"z\", \"d\": {\"o\": object, \"a\": \"b\"}}",
        "test_data = {\"x\": \"y\", \"v\": \"z\","
    ],
    [
        "The highest context which has the given key is used.",
        "The highest context which has the given key"
    ],
    [
        "The highest context is used if the given key isn't found.",
        "The highest context is used if"
    ],
    [
        "engine.from_string('{% include \"child\" only %}').render(ctx), \"none\"",
        "engine.from_string('{% include \"child\" only"
    ],
    [
        "test_data = {\"x\": \"y\", \"v\": \"z\", \"d\": {\"o\": object, \"a\": \"b\"}}",
        "test_data = {\"x\": \"y\", \"v\": \"z\","
    ],
    [
        "\"Context processor context_process_returning_none didn't return a \"",
        "\"Context processor context_process_returning_none didn't return"
    ],
    [
        "from django.template import Context, Engine, TemplateDoesNotExist, TemplateSyntaxError",
        "from django.template import Context, Engine, TemplateDoesNotExist,"
    ],
    [
        "t = self._engine().from_string(\"{% url will_not_match %}\")",
        "t = self._engine().from_string(\"{% url will_not_match"
    ],
    [
        "t = self._engine().from_string(\"{% url will_not_match %}\")",
        "t = self._engine().from_string(\"{%"
    ],
    [
        "Error messages should include the unexpected block name and be in all",
        "Error messages should include the unexpected"
    ],
    [
        "\"or 'endif'. Did you forget to register or load this tag?\"",
        "\"or 'endif'. Did you forget to register"
    ],
    [
        "msg = \"Could not parse the remainder: '@bar' from 'foo@bar'\"",
        "msg = \"Could not parse the remainder: '@bar'"
    ],
    [
        "Errors raised while compiling nodes should include the token",
        "Errors raised while compiling nodes should include"
    ],
    [
        "engine.from_string(\"{% load bad_tag %}{% badtag %}\")",
        "engine.from_string(\"{% load bad_tag %}{% badtag"
    ],
    [
        "\"\"\"Errors in a child of {% extends %} are displayed correctly.\"\"\"",
        "\"\"\"Errors in a child of {% extends %} are"
    ],
    [
        "\"\"\"Custom tags can pass extra data back to template.\"\"\"",
        "\"\"\"Custom tags can pass extra data back to"
    ],
    [
        "t = engine.from_string(\"{% load custom %}{% extra_data %}\")",
        "t = engine.from_string(\"{% load custom %}{%"
    ],
    [
        "\"\"\"Errors in extended block are displayed correctly.\"\"\"",
        "\"\"\"Errors in extended block are displayed"
    ],
    [
        "'{% block content %}{% include \"index.html\" %}',",
        "'{% block content %}{% include"
    ],
    [
        "'{% include \"index.html\" %}{% endblock %}\\n',",
        "'{% include \"index.html\" %}{%"
    ],
    [
        "'{% block content %}{% include \"index.html\" %}'",
        "'{% block content %}{% include \"index.html\""
    ],
    [
        "'{% include \"index.html\" %}{% endblock %}\\n',",
        "'{% include \"index.html\" %}{%"
    ],
    [
        "parent = engine.from_string(\"{% block content %}parent{% endblock %}\")",
        "parent = engine.from_string(\"{% block content"
    ],
    [
        "\"{% extends parent %}{% block content %}child{% endblock %}\"",
        "\"{% extends parent %}{% block content"
    ],
    [
        "template the node came from even if extending or including templates.",
        "template the node came from even if"
    ],
    [
        "Templates should not crash when rendering methods for built-in types",
        "Templates should not crash when rendering methods for"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import"
    ],
    [
        "from django.template import Context, Template, Variable, VariableDoesNotExist",
        "from django.template import Context, Template, Variable,"
    ],
    [
        "from django.template.base import DebugLexer, Lexer, TokenType",
        "from django.template.base import"
    ],
    [
        "\"{% if test %}{{ varvalue }}{% endif %}\"",
        "\"{% if test %}{{"
    ],
    [
        "(t.token_type, t.contents, t.lineno, t.position) for t in tokens",
        "(t.token_type, t.contents, t.lineno, t.position) for t"
    ],
    [
        "raise NotImplementedError(\"This method must be implemented by a subclass.\")",
        "raise NotImplementedError(\"This method must be implemented by a"
    ],
    [
        "exc = VariableDoesNotExist(msg=\"Failed lookup in %r\", params=({\"foo\": \"bar\"},))",
        "exc = VariableDoesNotExist(msg=\"Failed lookup in %r\","
    ],
    [
        "self.assertEqual(str(exc), \"Failed lookup in {'foo': 'bar'}\")",
        "self.assertEqual(str(exc), \"Failed lookup in {'foo':"
    ],
    [
        "\"\"\"Variable names that aren't resolved as literals.\"\"\"",
        "\"\"\"Variable names that aren't resolved"
    ],
    [
        "for var in (\"inf\", \"infinity\", \"iNFiniTy\", \"nan\"):",
        "for var in (\"inf\", \"infinity\", \"iNFiniTy\","
    ],
    [
        "var_names.extend((var, \"-\" + var, \"+\" + var))",
        "var_names.extend((var, \"-\" + var, \"+\""
    ],
    [
        "template = self.engine.from_string(\"{% if x %}{{ a }}{% endif %}\")",
        "template = self.engine.from_string(\"{% if x %}{{ a }}{% endif"
    ],
    [
        "template = self.engine.from_string(\"{% ifchanged x %}{{ a }}{% endifchanged %}\")",
        "template = self.engine.from_string(\"{% ifchanged x %}{{ a }}{%"
    ],
    [
        "Checks whether index of error is calculated correctly in",
        "Checks whether index of error is calculated correctly"
    ],
    [
        "\"{% load bad_tag %}{% for i in range %}{% badsimpletag %}{% endfor %}\",",
        "\"{% load bad_tag %}{% for i in range"
    ],
    [
        "\"{% load bad_tag %}{% for i in range %}{% for j in range %}\"",
        "\"{% load bad_tag %}{% for i in range %}{% for j in"
    ],
    [
        "\"{% badsimpletag %}{% endfor %}{% endfor %}\",",
        "\"{% badsimpletag %}{% endfor %}{% endfor"
    ],
    [
        "\"{% load bad_tag %}{% for i in range %}{% badsimpletag %}\"",
        "\"{% load bad_tag %}{% for i in"
    ],
    [
        "\"{% for j in range %}Hello{% endfor %}{% endfor %}\",",
        "\"{% for j in range %}Hello{% endfor %}{% endfor"
    ],
    [
        "\"{% load bad_tag %}{% for i in range %}{% for j in five %}\"",
        "\"{% load bad_tag %}{% for i in"
    ],
    [
        "\"{% badsimpletag %}{% endfor %}{% endfor %}\",",
        "\"{% badsimpletag %}{% endfor %}{% endfor"
    ],
    [
        "\"{% load bad_tag %}{% for j in five %}{% badsimpletag %}{% endfor %}\",",
        "\"{% load bad_tag %}{% for j in five %}{% badsimpletag %}{% endfor"
    ],
    [
        "\"\"\"A filter that uses a decorator (@mark_safe).\"\"\"",
        "\"\"\"A filter that uses a decorator"
    ],
    [
        "\"\"\"A noop filter that always return its first argument and does nothing with",
        "\"\"\"A noop filter that always return its first argument and"
    ],
    [
        "return \"one_param - Expected result: %s\" % arg",
        "return \"one_param - Expected result: %s\""
    ],
    [
        "return f\"one_param_block - Expected result: {arg} with content {content}\"",
        "return f\"one_param_block - Expected result: {arg}"
    ],
    [
        "return \"explicit_no_context - Expected result: %s\" % arg",
        "return \"explicit_no_context - Expected result: %s\" %"
    ],
    [
        "return f\"explicit_no_context_block - Expected result: {arg} with content {content}\"",
        "return f\"explicit_no_context_block - Expected result: {arg}"
    ],
    [
        "\"no_params_with_context - Expected result (context value: %s)\"",
        "\"no_params_with_context - Expected result (context"
    ],
    [
        "\"no_params_with_context_block - Expected result (context value: %s) \"",
        "\"no_params_with_context_block - Expected result"
    ],
    [
        "\"(content value: %s)\" % (context[\"value\"], content)",
        "\"(content value: %s)\" %"
    ],
    [
        "return \"params_and_context - Expected result (context value: %s): %s\" % (",
        "return \"params_and_context - Expected result (context"
    ],
    [
        "\"params_and_context_block - Expected result (context value: %s) \"",
        "\"params_and_context_block - Expected result"
    ],
    [
        "return \"simple_two_params - Expected result: %s, %s\" % (one, two)",
        "return \"simple_two_params - Expected result: %s, %s\" % (one,"
    ],
    [
        "return \"simple_two_params_block - Expected result (content value: %s): %s, %s\" % (",
        "return \"simple_two_params_block - Expected result (content"
    ],
    [
        "return \"simple_keyword_only_param - Expected result: %s\" % kwarg",
        "return \"simple_keyword_only_param - Expected result: %s\" %"
    ],
    [
        "\"simple_keyword_only_param_block - Expected result (content value: %s): %s\"",
        "\"simple_keyword_only_param_block - Expected result (content"
    ],
    [
        "return \"simple_keyword_only_default - Expected result: %s\" % kwarg",
        "return \"simple_keyword_only_default - Expected result:"
    ],
    [
        "\"simple_keyword_only_default_block - Expected result (content value: %s): %s\"",
        "\"simple_keyword_only_default_block - Expected result"
    ],
    [
        "return \"simple_one_default - Expected result: %s, %s\" % (one, two)",
        "return \"simple_one_default - Expected result: %s, %s\" %"
    ],
    [
        "return \"simple_one_default_block - Expected result (content value: %s): %s, %s\" % (",
        "return \"simple_one_default_block - Expected result (content value:"
    ],
    [
        "return \"simple_unlimited_args - Expected result: %s\" % (",
        "return \"simple_unlimited_args - Expected result: %s\" %"
    ],
    [
        "\", \".join(str(arg) for arg in [one, two, *args])",
        "\", \".join(str(arg) for arg in"
    ],
    [
        "return \"simple_unlimited_args_block - Expected result (content value: %s): %s\" % (",
        "return \"simple_unlimited_args_block - Expected result (content value:"
    ],
    [
        "\", \".join(str(arg) for arg in [one, two, *args]),",
        "\", \".join(str(arg) for arg in"
    ],
    [
        "return \"simple_only_unlimited_args - Expected result: %s\" % \", \".join(",
        "return \"simple_only_unlimited_args - Expected result: %s\" %"
    ],
    [
        "\"simple_only_unlimited_args_block - Expected result (content value: %s): %s\"",
        "\"simple_only_unlimited_args_block - Expected result (content value:"
    ],
    [
        "\", \".join(str(arg) for arg in args),",
        "\", \".join(str(arg) for"
    ],
    [
        "return \"simple_unlimited_args_kwargs - Expected result: %s / %s\" % (",
        "return \"simple_unlimited_args_kwargs - Expected result: %s /"
    ],
    [
        "\", \".join(str(arg) for arg in [one, two, *args]),",
        "\", \".join(str(arg) for arg"
    ],
    [
        "\", \".join(\"%s=%s\" % (k, v) for (k, v) in kwargs.items()),",
        "\", \".join(\"%s=%s\" % (k, v) for (k, v) in"
    ],
    [
        "def simple_unlimited_args_kwargs_block(content, one, two=\"hi\", *args, **kwargs):",
        "def simple_unlimited_args_kwargs_block(content, one, two=\"hi\", *args,"
    ],
    [
        "\"simple_unlimited_args_kwargs_block - Expected result (content value: %s): \"",
        "\"simple_unlimited_args_kwargs_block - Expected result (content value: %s):"
    ],
    [
        "\", \".join(str(arg) for arg in [one, two, *args]),",
        "\", \".join(str(arg) for arg in"
    ],
    [
        "\", \".join(\"%s=%s\" % (k, v) for (k, v) in kwargs.items()),",
        "\", \".join(\"%s=%s\" % (k, v) for (k, v) in"
    ],
    [
        "\"\"\"A tag that doesn't even think about escaping issues\"\"\"",
        "\"\"\"A tag that doesn't even think"
    ],
    [
        "\"\"\"A block tag that doesn't even think about escaping issues\"\"\"",
        "\"\"\"A block tag that doesn't"
    ],
    [
        "\"\"\"A tag that uses escape explicitly\"\"\"",
        "\"\"\"A tag that"
    ],
    [
        "\"\"\"A block tag that uses escape explicitly\"\"\"",
        "\"\"\"A block tag that uses"
    ],
    [
        "\"\"\"A block tag that uses format_html\"\"\"",
        "\"\"\"A block tag that uses"
    ],
    [
        "raise RuntimeError(\"I am a bad tag\")",
        "raise RuntimeError(\"I am a bad"
    ],
    [
        "raise RuntimeError(\"I am a bad simpletag\")",
        "raise RuntimeError(\"I am"
    ],
    [
        "return {\"result\": \"inclusion_no_params - Expected result\"}",
        "return {\"result\": \"inclusion_no_params - Expected"
    ],
    [
        "return {\"result\": \"inclusion_no_params_from_template - Expected result\"}",
        "return {\"result\": \"inclusion_no_params_from_template"
    ],
    [
        "return {\"result\": \"inclusion_one_param - Expected result: %s\" % arg}",
        "return {\"result\": \"inclusion_one_param - Expected"
    ],
    [
        "return {\"result\": \"inclusion_one_param_from_template - Expected result: %s\" % arg}",
        "return {\"result\": \"inclusion_one_param_from_template - Expected result: %s\" %"
    ],
    [
        "return {\"result\": \"inclusion_explicit_no_context - Expected result: %s\" % arg}",
        "return {\"result\": \"inclusion_explicit_no_context - Expected"
    ],
    [
        "\"result\": \"inclusion_explicit_no_context_from_template - Expected result: %s\"",
        "\"result\": \"inclusion_explicit_no_context_from_template - Expected result:"
    ],
    [
        "\"inclusion_no_params_with_context - Expected result (context value: %s)\"",
        "\"inclusion_no_params_with_context - Expected result (context"
    ],
    [
        "\"inclusion_no_params_with_context_from_template - Expected result (context \"",
        "\"inclusion_no_params_with_context_from_template - Expected result"
    ],
    [
        "\"inclusion_params_and_context - Expected result (context value: %s): %s\"",
        "\"inclusion_params_and_context - Expected result (context value: %s):"
    ],
    [
        "\"(context value: %s): %s\" % (context[\"value\"], arg)",
        "\"(context value: %s): %s\" % (context[\"value\"],"
    ],
    [
        "return {\"result\": \"inclusion_two_params - Expected result: %s, %s\" % (one, two)}",
        "return {\"result\": \"inclusion_two_params - Expected result: %s, %s\""
    ],
    [
        "\"result\": \"inclusion_two_params_from_template - Expected result: %s, %s\"",
        "\"result\": \"inclusion_two_params_from_template - Expected result:"
    ],
    [
        "return {\"result\": \"inclusion_one_default - Expected result: %s, %s\" % (one, two)}",
        "return {\"result\": \"inclusion_one_default - Expected result: %s,"
    ],
    [
        "\"result\": (\"inclusion_keyword_only_default - Expected result: %s\" % kwarg),",
        "\"result\": (\"inclusion_keyword_only_default - Expected result: %s\" %"
    ],
    [
        "\"result\": \"inclusion_one_default_from_template - Expected result: %s, %s\"",
        "\"result\": \"inclusion_one_default_from_template - Expected result:"
    ],
    [
        "% (\", \".join(str(arg) for arg in [one, two, *args]))",
        "% (\", \".join(str(arg) for arg in"
    ],
    [
        "% (\", \".join(str(arg) for arg in [one, two, *args]))",
        "% (\", \".join(str(arg) for arg in [one, two,"
    ],
    [
        "\"result\": \"inclusion_only_unlimited_args - Expected result: %s\"",
        "\"result\": \"inclusion_only_unlimited_args - Expected"
    ],
    [
        "% (\", \".join(str(arg) for arg in args))",
        "% (\", \".join(str(arg) for arg in"
    ],
    [
        "\"result\": \"inclusion_only_unlimited_args_from_template - Expected result: %s\"",
        "\"result\": \"inclusion_only_unlimited_args_from_template -"
    ],
    [
        "% (\", \".join(str(arg) for arg in args))",
        "% (\", \".join(str(arg) for arg"
    ],
    [
        "\"result\": \"inclusion_unlimited_args_kwargs - Expected result: %s / %s\"",
        "\"result\": \"inclusion_unlimited_args_kwargs - Expected result: %s"
    ],
    [
        "\", \".join(str(arg) for arg in [one, two, *args]),",
        "\", \".join(str(arg) for arg in [one,"
    ],
    [
        "\", \".join(\"%s=%s\" % (k, v) for (k, v) in kwargs.items()),",
        "\", \".join(\"%s=%s\" % (k, v)"
    ],
    [
        "\"{% block first %}a{% endblock %}{% block second %}b{% endblock %}\",",
        "\"{% block first %}a{% endblock %}{% block second"
    ],
    [
        "\"{% for n in numbers %}_{% block opt %}{{ n }}{% endblock %}{% endfor %}_\"",
        "\"{% for n in numbers %}_{% block opt %}{{ n"
    ],
    [
        "\"extends_duplicate\": \"{% extends 'base.html' %}{% extends 'base.html' %}\",",
        "\"extends_duplicate\": \"{% extends 'base.html' %}{% extends"
    ],
    [
        "Three-level with no redefinitions on third level",
        "Three-level with no redefinitions"
    ],
    [
        "Two-level with no redefinitions on second level",
        "Two-level with no redefinitions on"
    ],
    [
        "Two-level with double quotes instead of single quotes",
        "Two-level with double quotes instead of single"
    ],
    [
        "Two-level with one block defined, one block not defined",
        "Two-level with one block defined,"
    ],
    [
        "Three-level with one block defined on this level, two blocks",
        "Three-level with one block defined on this"
    ],
    [
        "Three-level with second and third levels blank",
        "Three-level with second and"
    ],
    [
        "Three-level with space NOT in a block -- should be ignored",
        "Three-level with space NOT in a block -- should"
    ],
    [
        "Three-level with both blocks defined on this level, but none on",
        "Three-level with both blocks defined on this"
    ],
    [
        "Three-level with this level providing one and second level",
        "Three-level with this level providing one and"
    ],
    [
        "Three-level with this level overriding second level",
        "Three-level with this level"
    ],
    [
        "A block defined only in a child template shouldn't be displayed",
        "A block defined only in a child template shouldn't be"
    ],
    [
        "{% load %} tag (standard usage, without inheritance)",
        "{% load %} tag (standard"
    ],
    [
        "{% load %} tag (within a child template)",
        "{% load %} tag (within"
    ],
    [
        "Two-level inheritance with {{ block.super }}",
        "Two-level inheritance with {{ block.super"
    ],
    [
        "Three-level inheritance with {{ block.super }} from parent",
        "Three-level inheritance with {{ block.super }}"
    ],
    [
        "Three-level inheritance with {{ block.super }} from grandparent",
        "Three-level inheritance with {{ block.super }} from"
    ],
    [
        "Three-level inheritance with {{ block.super }} from parent and",
        "Three-level inheritance with {{ block.super }}"
    ],
    [
        "Inheritance from local context without use of template loader",
        "Inheritance from local context without use of"
    ],
    [
        "Inheritance from local context with variable parent template",
        "Inheritance from local context with variable"
    ],
    [
        "Set up a base template to extend",
        "Set up a base template"
    ],
    [
        "Inheritance from a template that doesn't have any blocks",
        "Inheritance from a template that doesn't have"
    ],
    [
        "Set up a base template with a space in it.",
        "Set up a base template with a space"
    ],
    [
        "Inheritance from a template with a space in its name should work.",
        "Inheritance from a template with a space in its name"
    ],
    [
        "Base template, putting block in a conditional {% if %} tag",
        "Base template, putting block in a"
    ],
    [
        "Base template, putting block in a conditional {% if %} tag",
        "Base template, putting block in a conditional {% if %}"
    ],
    [
        "Inherit from a template with block wrapped in an {% if %} tag",
        "Inherit from a template with block wrapped"
    ],
    [
        "Inherit from a template with block wrapped in an {% if %} tag",
        "Inherit from a template with block wrapped in an {% if %}"
    ],
    [
        "Base template, putting block in a {% for %} tag",
        "Base template, putting block in a"
    ],
    [
        "Inherit from a template with block wrapped in an {% for %} tag",
        "Inherit from a template with block wrapped"
    ],
    [
        "Inherit from a template with block wrapped in an {% for %} tag",
        "Inherit from a template with block wrapped in an {%"
    ],
    [
        "Expression starting and ending with a quote",
        "Expression starting and ending with"
    ],
    [
        "msg = \"'extends' cannot appear more than once in the same template\"",
        "msg = \"'extends' cannot appear more than once"
    ],
    [
        "msg = \"'block' tag with name 'content' appears more than once\"",
        "msg = \"'block' tag with name"
    ],
    [
        "@setup({\"t\": \"{% widthratio a b c as variable %}-{{ variable }}-\"})",
        "@setup({\"t\": \"{% widthratio a b c"
    ],
    [
        "from ..utils import SilentAttrClass, SilentGetItemClass, SomeClass, setup",
        "from ..utils import SilentAttrClass,"
    ],
    [
        "Plain text should go through the template parser untouched.",
        "Plain text should go through the template"
    ],
    [
        "Variables should be replaced with their value in the current",
        "Variables should be replaced with their value in the"
    ],
    [
        "More than one replacement variable is allowed in a template",
        "More than one replacement variable is allowed in a"
    ],
    [
        "Fail silently when a variable is not found in the current context",
        "Fail silently when a variable is not found"
    ],
    [
        "A variable may not contain more than one word",
        "A variable may not contain"
    ],
    [
        "Raise TemplateSyntaxError for empty variable tags.",
        "Raise TemplateSyntaxError for empty variable"
    ],
    [
        "Raise TemplateSyntaxError for empty variable tags.",
        "Raise TemplateSyntaxError for"
    ],
    [
        "Attribute syntax allows a template to call an object's attribute",
        "Attribute syntax allows a template to call"
    ],
    [
        "Multiple levels of attribute access are allowed.",
        "Multiple levels of attribute access are"
    ],
    [
        "Fail silently when a variable's attribute isn't found.",
        "Fail silently when a"
    ],
    [
        "Raise TemplateSyntaxError when trying to access a variable",
        "Raise TemplateSyntaxError when trying"
    ],
    [
        "Attribute syntax allows a template to call a dictionary key's",
        "Attribute syntax allows a template"
    ],
    [
        "Fail silently when a variable's dictionary key isn't found.",
        "Fail silently when a variable's dictionary key"
    ],
    [
        "Fail silently when accessing a non-simple method",
        "Fail silently when accessing a"
    ],
    [
        "Don't silence a TypeError if it was raised inside a callable.",
        "Don't silence a TypeError if it was"
    ],
    [
        "self.assertEqual(output, \"a {{ moo %} b\")",
        "self.assertEqual(output, \"a {{ moo"
    ],
    [
        "around, so this triggers an error.",
        "around, so this triggers"
    ],
    [
        "Call methods in the top level of the context.",
        "Call methods in the top level of the"
    ],
    [
        "Call methods returned from dictionary lookups.",
        "Call methods returned"
    ],
    [
        "@setup({\"tpl-str\": \"%s\", \"tpl-percent\": \"%%\", \"tpl-weird-percent\": \"% %s\"})",
        "@setup({\"tpl-str\": \"%s\", \"tpl-percent\": \"%%\","
    ],
    [
        "{\"template\": \"{{ class_var.class_property }} | {{ class_var.class_method }}\"}",
        "{\"template\": \"{{ class_var.class_property }} | {{"
    ],
    [
        "for case in (MyClass, lambda: MyClass):",
        "for case in (MyClass,"
    ],
    [
        "self.assertEqual(output, \"Example property | Example method\")",
        "self.assertEqual(output, \"Example property |"
    ],
    [
        "If the metaclass defines __getitem__, the template system should use",
        "If the metaclass defines __getitem__, the"
    ],
    [
        "it to resolve the dot notation.",
        "it to resolve the"
    ],
    [
        "return getattr(cls, name) + \" is yummy.\"",
        "return getattr(cls, name) + \""
    ],
    [
        "\"{'content': [<Block Node: content. Contents: []>]})>\",",
        "\"{'content': [<Block Node: content. Contents:"
    ],
    [
        "Let's just make sure setup runs cases in the right order.",
        "Let's just make sure setup runs cases in the"
    ],
    [
        "at_least_with_one_msg = \"'with' expected at least one variable assignment\"",
        "at_least_with_one_msg = \"'with' expected at least one variable"
    ],
    [
        "\"{{ key }}-{{ dict.key }}-{{ key }}\"",
        "\"{{ key }}-{{ dict.key"
    ],
    [
        "\"{{ key }}-{{ dict.key }}-{{ key }}\"",
        "\"{{ key }}-{{ dict.key"
    ],
    [
        "List-index syntax allows a template to access a certain item of a",
        "List-index syntax allows a template to access a certain"
    ],
    [
        "Fail silently when the list index is out of range.",
        "Fail silently when the list index"
    ],
    [
        "Fail silently when the list index is out of range.",
        "Fail silently when the list index is out of"
    ],
    [
        "Fail silently when variable is a dict without the specified key.",
        "Fail silently when variable is a dict without"
    ],
    [
        "Dictionary lookup wins out when dict's key is a string.",
        "Dictionary lookup wins out when dict's key is a"
    ],
    [
        "But list-index lookup wins out when dict's key is an int, which",
        "But list-index lookup wins out when dict's key is an"
    ],
    [
        "behind the scenes is really a dictionary lookup (for a dict)",
        "behind the scenes is really a dictionary lookup (for a"
    ],
    [
        "after converting the key to an int.",
        "after converting the key to an"
    ],
    [
        "Dictionary lookup wins out when there is a string and int version",
        "Dictionary lookup wins out when there is a string and"
    ],
    [
        "TemplateSyntaxError, \"'now' statement takes one argument\"",
        "TemplateSyntaxError, \"'now' statement takes one"
    ],
    [
        "from ..utils import SafeClass, UnsafeClass, setup",
        "from ..utils import"
    ],
    [
        "\"{% autoescape off %}{{ first }} {% autoescape on %}{{ first }}\"",
        "\"{% autoescape off %}{{ first }} {% autoescape on %}{{ first"
    ],
    [
        "r'{% autoescape on %}{{ var|default_if_none:\" endquote\\\" hah\" }}'",
        "r'{% autoescape on %}{{ var|default_if_none:\""
    ],
    [
        "Literal string arguments to filters, if used in the result, are safe.",
        "Literal string arguments to filters, if used in"
    ],
    [
        "\"{{ first }}{% filter safe %}{{ first }} x<y{% endfilter %}\"",
        "\"{{ first }}{% filter safe %}{{ first }} x<y{%"
    ],
    [
        "The \"safe\" and \"escape\" filters cannot work due to internal",
        "The \"safe\" and \"escape\" filters cannot work due"
    ],
    [
        "implementation details (fortunately, the (no)autoescape block",
        "implementation details (fortunately,"
    ],
    [
        "tags can be used in those cases)",
        "tags can be used in"
    ],
    [
        "self.assertEqual(output, \"Tom & Dick & Harry\")",
        "self.assertEqual(output, \"Tom & Dick"
    ],
    [
        "Iterating over strings outputs safe characters.",
        "Iterating over strings outputs"
    ],
    [
        "\"{% autoescape true %}{{ var.key }}{% endautoescape %}\"",
        "\"{% autoescape true %}{{ var.key }}{%"
    ],
    [
        "msg = \"'autoescape' argument should be 'on' or 'off'\"",
        "msg = \"'autoescape' argument should"
    ],
    [
        "\"autoescape-incorrect-arg\", {\"var\": {\"key\": \"this & that\"}}",
        "\"autoescape-incorrect-arg\", {\"var\": {\"key\":"
    ],
    [
        "{\"autoescape-incorrect-arg\": \"{% autoescape %}{{ var.key }}{% endautoescape %}\"}",
        "{\"autoescape-incorrect-arg\": \"{% autoescape %}{{ var.key }}{% endautoescape"
    ],
    [
        "msg = \"'autoescape' tag requires exactly one argument.\"",
        "msg = \"'autoescape' tag requires exactly one"
    ],
    [
        "\"autoescape-incorrect-arg\", {\"var\": {\"key\": \"this & that\"}}",
        "\"autoescape-incorrect-arg\", {\"var\": {\"key\": \"this"
    ],
    [
        "\"{% get_static_prefix as static_prefix %}{{ static_prefix }}\"",
        "\"{% get_static_prefix as static_prefix"
    ],
    [
        "\"{% get_media_prefix as media_prefix %}{{ media_prefix }}\"",
        "\"{% get_media_prefix as media_prefix %}{{ media_prefix"
    ],
    [
        "\"{% load static %}{% get_media_prefix ad media_prefix %}\"",
        "\"{% load static %}{% get_media_prefix ad"
    ],
    [
        "msg = \"First argument in 'get_media_prefix' must be 'as'\"",
        "msg = \"First argument in 'get_media_prefix'"
    ],
    [
        "'{% load static %}{% static \"admin/base.css\" as foo %}{{ foo }}'",
        "'{% load static %}{% static \"admin/base.css\" as foo %}{{ foo"
    ],
    [
        "'{% load static %}{% static \"special?chars&quoted.html\" %}'",
        "'{% load static %}{%"
    ],
    [
        "@setup({\"t\": \"{% load static %}{% static %}\"})",
        "@setup({\"t\": \"{% load static %}{%"
    ],
    [
        "msg = \"'static' takes at least one argument (path to file)\"",
        "msg = \"'static' takes at least one argument"
    ],
    [
        "Allow spaces before the filter pipe",
        "Allow spaces before the"
    ],
    [
        "Allow spaces after the filter pipe",
        "Allow spaces after"
    ],
    [
        "Raise TemplateSyntaxError for a nonexistent filter",
        "Raise TemplateSyntaxError for a"
    ],
    [
        "Raise TemplateSyntaxError when trying to access a filter containing",
        "Raise TemplateSyntaxError when trying to"
    ],
    [
        "Raise TemplateSyntaxError for invalid block tags",
        "Raise TemplateSyntaxError for invalid"
    ],
    [
        "\"forget to register or load this tag?\"",
        "\"forget to register or load this"
    ],
    [
        "Raise TemplateSyntaxError for empty block tags",
        "Raise TemplateSyntaxError for empty"
    ],
    [
        "Raise TemplateSyntaxError for empty block tags in templates with",
        "Raise TemplateSyntaxError for empty block tags"
    ],
    [
        "Chained filters, with an argument to the first one",
        "Chained filters, with an argument"
    ],
    [
        "Literal string as argument is always \"safe\" from auto-escaping.",
        "Literal string as argument is"
    ],
    [
        "Fail silently for methods that raise an exception with a",
        "Fail silently for methods that raise an exception with"
    ],
    [
        "In methods that raise an exception without a",
        "In methods that raise an"
    ],
    [
        "`silent_variable_attribute` set to True, the exception propagates",
        "`silent_variable_attribute` set to True, the exception"
    ],
    [
        "Escaped backslash using known escape char",
        "Escaped backslash using known escape"
    ],
    [
        "Empty strings can be passed as arguments to filters",
        "Empty strings can be passed"
    ],
    [
        "Strings are converted to bytestrings in the final output.",
        "Strings are converted to bytestrings"
    ],
    [
        "Numbers as filter arguments should work",
        "Numbers as filter arguments should"
    ],
    [
        "Filters should accept empty string constants",
        "Filters should accept empty"
    ],
    [
        "Fail silently for non-callable attribute and dict lookups which",
        "Fail silently for non-callable attribute and dict lookups"
    ],
    [
        "raise an exception with a \"silent_variable_failure\" attribute",
        "raise an exception with a"
    ],
    [
        "Fail silently for non-callable attribute and dict lookups which",
        "Fail silently for non-callable attribute and"
    ],
    [
        "raise an exception with a `silent_variable_failure` attribute",
        "raise an exception with"
    ],
    [
        "In attribute and dict lookups that raise an unexpected exception",
        "In attribute and dict lookups that raise an"
    ],
    [
        "without a `silent_variable_attribute` set to True, the exception",
        "without a `silent_variable_attribute` set to True,"
    ],
    [
        "In attribute and dict lookups that raise an unexpected exception",
        "In attribute and dict lookups that raise"
    ],
    [
        "without a `silent_variable_attribute` set to True, the exception",
        "without a `silent_variable_attribute` set to"
    ],
    [
        "\"{% for n in num %}{% ifchanged %}{{ n }}{% endifchanged %}{% endfor %}\"",
        "\"{% for n in num %}{% ifchanged %}{{"
    ],
    [
        "\"{% for n in num %}{% ifchanged %}{{ n }}{% endifchanged %}{% endfor %}\"",
        "\"{% for n in num %}{% ifchanged %}{{ n }}{% endifchanged %}{% endfor"
    ],
    [
        "\"{% for n in num %}{% ifchanged %}{{ n }}{% endifchanged %}{% endfor %}\"",
        "\"{% for n in num %}{% ifchanged %}{{ n"
    ],
    [
        "\"{% for x in numx %}{% ifchanged %}{{ x }}{% endifchanged %}\"",
        "\"{% for x in numx %}{% ifchanged %}{{"
    ],
    [
        "\"{% for x in numx %}{% ifchanged %}{{ x }}{% endifchanged %}\"",
        "\"{% for x in numx %}{%"
    ],
    [
        "\"{% for x in numx %}{% ifchanged %}{{ x }}{% endifchanged %}\"",
        "\"{% for x in numx %}{% ifchanged %}{{ x }}{% endifchanged"
    ],
    [
        "\"{% for x in numx %}{% ifchanged %}{{ x }}{% endifchanged %}\"",
        "\"{% for x in numx %}{% ifchanged %}{{"
    ],
    [
        "\"{% for y in numy %}{% ifchanged %}{{ y }}{% endifchanged %}\"",
        "\"{% for y in numy %}{% ifchanged"
    ],
    [
        "\"{% endfor %}{% endfor %}{% endfor %}\"",
        "\"{% endfor %}{% endfor"
    ],
    [
        "\"{% if c %}{% ifchanged %}{{ d }}{% endifchanged %}\"",
        "\"{% if c %}{% ifchanged %}{{"
    ],
    [
        "\"{% endif %}{% endfor %}{% endfor %}\"",
        "\"{% endif %}{% endfor"
    ],
    [
        "\"{% for n in num %}{% ifchanged n %}..{% endifchanged %}\"",
        "\"{% for n in num %}{% ifchanged n %}..{%"
    ],
    [
        "Test one parameter given to ifchanged.",
        "Test one parameter given"
    ],
    [
        "\"{% for n in num %}{% for x in numx %}\"",
        "\"{% for n in num %}{%"
    ],
    [
        "\"{% ifchanged n %}..{% endifchanged %}{{ x }}\"",
        "\"{% ifchanged n %}..{% endifchanged %}{{"
    ],
    [
        "\"{% ifchanged x n %}{{ x }}{% endifchanged %}\"",
        "\"{% ifchanged x n %}{{ x }}{%"
    ],
    [
        "\"{% for d in days %}{% ifchanged %}{{ d.day }}{% endifchanged %}\"",
        "\"{% for d in days %}{% ifchanged %}{{ d.day"
    ],
    [
        "\"{% for h in d.hours %}{% ifchanged d h %}{{ h }}{% endifchanged %}\"",
        "\"{% for h in d.hours %}{% ifchanged d h %}{{ h"
    ],
    [
        "Test a date+hour like construct, where the hour of the last day is",
        "Test a date+hour like construct, where the hour of the last"
    ],
    [
        "the same but the date had changed, so print the hour anyway.",
        "the same but the date had changed, so print the"
    ],
    [
        "\"{% for d in days %}{% ifchanged d.day %}{{ d.day }}{% endifchanged %}\"",
        "\"{% for d in days %}{% ifchanged d.day %}{{ d.day }}{% endifchanged"
    ],
    [
        "\"{% for h in d.hours %}{% ifchanged d.day h %}{{ h }}{% endifchanged %}\"",
        "\"{% for h in d.hours %}{% ifchanged d.day h %}{{"
    ],
    [
        "Logically the same as above, just written with explicit ifchanged",
        "Logically the same as above, just written with explicit"
    ],
    [
        "\"{% ifchanged id %}-first{% else %}-other{% endifchanged %}\"",
        "\"{% ifchanged id %}-first{%"
    ],
    [
        "Test the else clause of ifchanged.",
        "Test the else clause of"
    ],
    [
        "'{% ifchanged id %}{% cycle \"red\" \"blue\" %}{% else %}gray{% endifchanged %}'",
        "'{% ifchanged id %}{% cycle \"red\" \"blue\" %}{% else %}gray{% endifchanged"
    ],
    [
        "'{% ifchanged id %}-{% cycle \"red\" \"blue\" %}{% else %}{% endifchanged %}'",
        "'{% ifchanged id %}-{% cycle \"red\" \"blue\" %}{% else"
    ],
    [
        "\"{% ifchanged %}***{{ id }}*{% else %}...{% endifchanged %}\"",
        "\"{% ifchanged %}***{{ id }}*{% else %}...{%"
    ],
    [
        "\"ifchanged-filter-ws\": \"{% load custom %}{% for n in num %}\"",
        "\"ifchanged-filter-ws\": \"{% load custom %}{% for n in"
    ],
    [
        "'{% ifchanged n|noop:\"x y\" %}..{% endifchanged %}{{ n }}'",
        "'{% ifchanged n|noop:\"x y\" %}..{% endifchanged %}{{ n"
    ],
    [
        "\"{{ var }}{% endifchanged %}{% endwith %}{% endfor %}]\"",
        "\"{{ var }}{% endifchanged %}{%"
    ],
    [
        "isn't used. Hence we don't use the @setup decorator.",
        "isn't used. Hence we don't use the"
    ],
    [
        "'{% for x in vars %}{% include \"include\" %}{% endfor %}'",
        "'{% for x in vars %}{% include \"include\""
    ],
    [
        "\"include\": \"{% ifchanged %}{{ x }}{% endifchanged %}\",",
        "\"include\": \"{% ifchanged %}{{ x"
    ],
    [
        "'{% for x in vars %}{% include \"include\" %}'",
        "'{% for x in vars %}{%"
    ],
    [
        "'{% include \"include\" %}{% endfor %}'",
        "'{% include \"include\""
    ],
    [
        "\"include\": \"{% ifchanged %}{{ x }}{% endifchanged %}\",",
        "\"include\": \"{% ifchanged %}{{"
    ],
    [
        "\"{% spaceless %} <b>    <i> text </i>    </b> {% endspaceless %}\"",
        "\"{% spaceless %} <b> <i> text </i> </b> {%"
    ],
    [
        "\"{% spaceless %} <b> \\n <i> text </i> \\n </b> {% endspaceless %}\"",
        "\"{% spaceless %} <b> \\n <i> text </i> \\n </b> {%"
    ],
    [
        "\"{% spaceless %}<b>   <i>{{ text }}</i>  </b>{% endspaceless %}\"",
        "\"{% spaceless %}<b> <i>{{ text }}</i>"
    ],
    [
        "\"<b>   <i>{{ text }}</i>  </b>{% endspaceless %}\"",
        "\"<b> <i>{{ text }}</i>"
    ],
    [
        "\"{% spaceless %}<b>   <i>{{ text|safe }}</i>  </b>{% endspaceless %}\"",
        "\"{% spaceless %}<b> <i>{{ text|safe }}</i> </b>{%"
    ],
    [
        "msg = \"Incorrect format for 'lorem' tag\"",
        "msg = \"Incorrect format"
    ],
    [
        "@setup({\"lorem_incorrect_count\": \"{% lorem two p %}\"})",
        "@setup({\"lorem_incorrect_count\": \"{% lorem two"
    ],
    [
        "Raise exception for invalid template name",
        "Raise exception for"
    ],
    [
        "Raise exception for invalid variable template name",
        "Raise exception for invalid"
    ],
    [
        "Raise exception for extra {% extends %} tags",
        "Raise exception for extra {% extends"
    ],
    [
        "Raise exception for custom tags used in child with {% load %} tag in",
        "Raise exception for custom tags used in child with"
    ],
    [
        "Raise exception for block.super used in base template",
        "Raise exception for block.super used in base"
    ],
    [
        "\"{% regroup data by bar as grouped %}\"",
        "\"{% regroup data by bar as"
    ],
    [
        "\"{% for group in grouped %}\"",
        "\"{% for group in grouped"
    ],
    [
        "\"{% for item in group.list %}\"",
        "\"{% for item"
    ],
    [
        "\"{% regroup data by bar as grouped %}\"",
        "\"{% regroup data by bar as grouped"
    ],
    [
        "\"{% for group in grouped %}\"",
        "\"{% for group in"
    ],
    [
        "\"{% for item in group.list %}\"",
        "\"{% for item"
    ],
    [
        "Test for silent failure when target variable isn't found",
        "Test for silent failure when target variable"
    ],
    [
        "'{% regroup data by at|date:\"m\" as grouped %}'",
        "'{% regroup data by at|date:\"m\" as"
    ],
    [
        "\"{% for group in grouped %}\"",
        "\"{% for group in"
    ],
    [
        "\"{% for item in group.list %}\"",
        "\"{% for item"
    ],
    [
        "The date template filter has expects_localtime = True",
        "The date template filter has expects_localtime ="
    ],
    [
        "'{% regroup data by bar|join:\"\" as grouped %}'",
        "'{% regroup data by bar|join:\"\""
    ],
    [
        "\"{% for group in grouped %}\"",
        "\"{% for group"
    ],
    [
        "\"{% for item in group.list %}\"",
        "\"{% for item in"
    ],
    [
        "The join template filter has needs_autoescape = True",
        "The join template filter has needs_autoescape"
    ],
    [
        "\"regroup_unpack\": \"{% regroup data by bar as grouped %}\"",
        "\"regroup_unpack\": \"{% regroup data by bar"
    ],
    [
        "\"{% for grouper, group in grouped %}\"",
        "\"{% for grouper, group in grouped"
    ],
    [
        "\"{% for item in group %}\"",
        "\"{% for item in"
    ],
    [
        "with self.assertRaisesMessage(TemplateSyntaxError, \"No cycles in template.\"):",
        "with self.assertRaisesMessage(TemplateSyntaxError, \"No cycles"
    ],
    [
        "TemplateSyntaxError, \"Named cycle 'undefinedcycle' does not exist.\"",
        "TemplateSyntaxError, \"Named cycle 'undefinedcycle'"
    ],
    [
        "TemplateSyntaxError, \"Named cycle 'undefinedcycle' does not exist.\"",
        "TemplateSyntaxError, \"Named cycle 'undefinedcycle' does"
    ],
    [
        "TemplateSyntaxError, \"Named cycle 'undefinedcycle' does not exist.\"",
        "TemplateSyntaxError, \"Named cycle 'undefinedcycle' does"
    ],
    [
        "\"{% for i in test %}{% cycle 'a' 'b' %}{% resetcycle %}{% endfor %}\"",
        "\"{% for i in test %}{% cycle 'a' 'b' %}{% resetcycle %}{% endfor"
    ],
    [
        "\"{% for i in test %}\"",
        "\"{% for i in"
    ],
    [
        "\"{% for i in test %}\"",
        "\"{% for i in"
    ],
    [
        "\"{% for j in inner %}\"",
        "\"{% for j"
    ],
    [
        "\"{% for j in inner %}\"",
        "\"{% for j"
    ],
    [
        "\"{% cycle 'X' 'Y' 'Z' as XYZ %}\"",
        "\"{% cycle 'X' 'Y'"
    ],
    [
        "\"{% cycle 'a' 'b' 'c' as abc %}\"",
        "\"{% cycle 'a' 'b' 'c'"
    ],
    [
        "\"{% cycle 'X' 'Y' 'Z' as XYZ %}\"",
        "\"{% cycle 'X' 'Y' 'Z'"
    ],
    [
        "\"{% cycle 'a' 'b' 'c' as abc %}\"",
        "\"{% cycle 'a' 'b' 'c' as abc"
    ],
    [
        "\"{% for val in values %}{{ forloop.revcounter }}{% endfor %}\"",
        "\"{% for val in values %}{{ forloop.revcounter }}{%"
    ],
    [
        "\"{% if forloop.first %}f{% else %}x{% endif %}{% endfor %}\"",
        "\"{% if forloop.first %}f{% else %}x{% endif"
    ],
    [
        "\"{% if forloop.last %}l{% else %}x{% endif %}{% endfor %}\"",
        "\"{% if forloop.last %}l{% else %}x{% endif %}{% endfor"
    ],
    [
        "\"{% for key,value in items %}{{ key }}:{{ value }}/{% endfor %}\"",
        "\"{% for key,value in items %}{{"
    ],
    [
        "\"{% for key, value in items %}{{ key }}:{{ value }}/{% endfor %}\"",
        "\"{% for key, value in items %}{{ key }}:{{ value }}/{%"
    ],
    [
        "\"{% for key , value in items %}{{ key }}:{{ value }}/{% endfor %}\"",
        "\"{% for key , value in items %}{{ key }}:{{ value }}/{%"
    ],
    [
        "\"{% for key ,value in items %}{{ key }}:{{ value }}/{% endfor %}\"",
        "\"{% for key ,value in items %}{{ key }}:{{ value }}/{% endfor"
    ],
    [
        "\"{% for key value in items %}{{ key }}:{{ value }}/{% endfor %}\"",
        "\"{% for key value in items %}{{ key }}:{{"
    ],
    [
        "msg = \"'for' tag received an invalid argument: for key value in items\"",
        "msg = \"'for' tag received an invalid argument:"
    ],
    [
        "\"{% for key,,value in items %}{{ key }}:{{ value }}/{% endfor %}\"",
        "\"{% for key,,value in items %}{{ key"
    ],
    [
        "msg = \"'for' tag received an invalid argument: for key,,value in items\"",
        "msg = \"'for' tag received an"
    ],
    [
        "\"{% for key,value, in items %}{{ key }}:{{ value }}/{% endfor %}\"",
        "\"{% for key,value, in items %}{{ key }}:{{ value"
    ],
    [
        "msg = \"'for' tag received an invalid argument: for key,value, in items\"",
        "msg = \"'for' tag received an invalid argument:"
    ],
    [
        "@setup({\"double-quote\": '{% for \"k\" in items %}{{ \"k\" }}/{% endfor %}'})",
        "@setup({\"double-quote\": '{% for \"k\" in items %}{{ \"k\" }}/{% endfor"
    ],
    [
        "msg = \"\"\"'for' tag received an invalid argument: for \"k\" in items\"\"\"",
        "msg = \"\"\"'for' tag received an invalid argument: for \"k\""
    ],
    [
        "@setup({\"single-quote\": \"{% for 'k' in items %}{{ k }}/{% endfor %}\"})",
        "@setup({\"single-quote\": \"{% for 'k' in items %}{{ k }}/{% endfor"
    ],
    [
        "msg = \"\"\"'for' tag received an invalid argument: for 'k' in items\"\"\"",
        "msg = \"\"\"'for' tag received an invalid argument: for 'k'"
    ],
    [
        "@setup({\"vertical-bar\": \"{% for k|upper in items %}{{ k|upper }}/{% endfor %}\"})",
        "@setup({\"vertical-bar\": \"{% for k|upper in items"
    ],
    [
        "msg = \"'for' tag received an invalid argument: for k|upper in items\"",
        "msg = \"'for' tag received an"
    ],
    [
        "A single loopvar doesn't truncate the list in val.",
        "A single loopvar doesn't truncate the"
    ],
    [
        "\"{% for x,y,z in items %}{{ x }}:{{ y }},{{ z }}/{% endfor %}\"",
        "\"{% for x,y,z in items %}{{ x"
    ],
    [
        "\"{% for val in values %}{{ val }}{% empty %}empty text{% endfor %}\"",
        "\"{% for val in values %}{{ val }}{% empty %}empty text{% endfor"
    ],
    [
        "\"{% for val in values %}{{ val }}{% empty %}values array empty\"",
        "\"{% for val in values %}{{ val }}{%"
    ],
    [
        "\"{{ val }}{% empty %}values array not found{% endfor %}\"",
        "\"{{ val }}{% empty %}values array not"
    ],
    [
        "\"{% load custom %}{% for x in s|noop:'x y' %}{{ x }}{% endfor %}\"",
        "\"{% load custom %}{% for x in"
    ],
    [
        "{\"for-tag-unpack-strs\": \"{% for x,y in items %}{{ x }}:{{ y }}/{% endfor %}\"}",
        "{\"for-tag-unpack-strs\": \"{% for x,y in items %}{{ x"
    ],
    [
        "\"{% for x,y,z in items %}{{ x }}:{{ y }},{{ z }}/{% endfor %}\"",
        "\"{% for x,y,z in items %}{{ x }}:{{"
    ],
    [
        "\"{% for x,y,z in items %}{{ x }}:{{ y }},{{ z }}/{% endfor %}\"",
        "\"{% for x,y,z in items %}{{ x }}:{{ y }},{{ z }}/{%"
    ],
    [
        "\"main\": '{% with alpha=alpha.values %}{% include \"base\" %}{% endwith %}_'",
        "\"main\": '{% with alpha=alpha.values %}{% include \"base\""
    ],
    [
        "'{% with alpha=alpha.extra %}{% include \"base\" %}{% endwith %}',",
        "'{% with alpha=alpha.extra %}{% include \"base\" %}{%"
    ],
    [
        "\"base\": \"{% for x, y in alpha %}{{ x }}:{{ y }},{% endfor %}\",",
        "\"base\": \"{% for x, y in alpha %}{{ x }}:{{ y }},{% endfor"
    ],
    [
        "@setup({\"invalid_for_loop\": \"{% for x items %}{{ x }}{% endfor %}\"})",
        "@setup({\"invalid_for_loop\": \"{% for x items %}{{"
    ],
    [
        "msg = \"'for' statements should have at least four words: for x items\"",
        "msg = \"'for' statements should have at least four words: for x"
    ],
    [
        "@setup({\"invalid_for_loop\": \"{% for x from items %}{{ x }}{% endfor %}\"})",
        "@setup({\"invalid_for_loop\": \"{% for x from items %}{{ x"
    ],
    [
        "msg = \"'for' statements should use the format 'for x in y': for x from items\"",
        "msg = \"'for' statements should use the format"
    ],
    [
        "self.assertEqual(output, \"It's the {% verbatim %} tag\")",
        "self.assertEqual(output, \"It's the {% verbatim %}"
    ],
    [
        "\"{% verbatim %}{% verbatim %}{% endverbatim %}{% endverbatim %}\"",
        "\"{% verbatim %}{% verbatim %}{% endverbatim %}{% endverbatim"
    ],
    [
        "\"{% verbatim %}{% endverbatim %}{% verbatim %}{% endverbatim %}\"",
        "\"{% verbatim %}{% endverbatim %}{% verbatim"
    ],
    [
        "\"Don't {% endverbatim %} just yet{% endverbatim special %}\"",
        "\"Don't {% endverbatim %} just yet{% endverbatim"
    ],
    [
        "self.assertEqual(output, \"Don't {% endverbatim %} just yet\")",
        "self.assertEqual(output, \"Don't {% endverbatim"
    ],
    [
        "for context, expected in [(non_empty_context, \"?\"), (empty_context, \"\")]:",
        "for context, expected in [(non_empty_context,"
    ],
    [
        "request = self.request_factory.get(\"/\", {\"x\": \"y\", \"a\": \"b\"})",
        "request = self.request_factory.get(\"/\", {\"x\":"
    ],
    [
        "request = self.request_factory.get(\"/\", {\"x\": \"y\", \"a\": \"b\"})",
        "request = self.request_factory.get(\"/\", {\"x\":"
    ],
    [
        "msg = \"'Context' object has no attribute 'request'\"",
        "msg = \"'Context' object has"
    ],
    [
        "\"'include' tag takes at least one argument: the name of the \"",
        "\"'include' tag takes at least one argument: the name of"
    ],
    [
        "The correct template is identified as not existing",
        "The correct template is identified as not"
    ],
    [
        "when {% include %} specifies a template that does not exist.",
        "when {% include %} specifies a"
    ],
    [
        "when {% extends %} specifies a template that does exist, but that",
        "when {% extends %} specifies a template that"
    ],
    [
        "template has an {% include %} of something that does not exist.",
        "template has an {% include %} of something that"
    ],
    [
        "outer_tmpl = engine.from_string(\"{% include tmpl %}\")",
        "outer_tmpl = engine.from_string(\"{%"
    ],
    [
        "outer_temp = engine.from_string(\"{% include var %}\")",
        "outer_temp = engine.from_string(\"{% include"
    ],
    [
        "outer_temp = engine.from_string(\"{% include var %}\")",
        "outer_temp = engine.from_string(\"{% include var"
    ],
    [
        "msg = \"No template names provided\"",
        "msg = \"No"
    ],
    [
        "{% for c in comments %}",
        "{% for c"
    ],
    [
        "{% if c.children %}{% include tmpl with comments=c.children %}{% endif %}",
        "{% if c.children %}{% include tmpl with"
    ],
    [
        "outer_tmpl = engine.from_string(\"{% include tmpl %}\")",
        "outer_tmpl = engine.from_string(\"{% include"
    ],
    [
        "CounterNode object in the {% counter %} template tag is created once",
        "CounterNode object in the {% counter %}"
    ],
    [
        "if caching works properly. Each iteration increases the counter instead",
        "if caching works properly. Each iteration increases the"
    ],
    [
        "This works as a regression test only if the cached loader",
        "This works as a regression test only if the"
    ],
    [
        "isn't used, so the @setup decorator isn't used.",
        "isn't used, so the @setup decorator"
    ],
    [
        "'{% for x in vars %}{% include \"include\" %}{% endfor %}'",
        "'{% for x in vars %}{% include"
    ],
    [
        "\"next\": \"{% load custom %}{% counter %}\",",
        "\"next\": \"{% load custom"
    ],
    [
        "msg = \"No named cycles in template. 'a' is not defined\"",
        "msg = \"No named cycles in template. 'a' is not"
    ],
    [
        "msg = \"'cycle' tag requires at least two arguments\"",
        "msg = \"'cycle' tag requires at least"
    ],
    [
        "msg = \"Could not parse the remainder: ',b,c' from 'a,b,c'\"",
        "msg = \"Could not parse the remainder:"
    ],
    [
        "\"{% cycle 'a' 'b' 'c' as abc %}{% cycle abc %}{% cycle abc %}\"",
        "\"{% cycle 'a' 'b' 'c' as abc %}{% cycle abc"
    ],
    [
        "\"{% cycle abc %}{% cycle abc %}{% cycle abc %}{% cycle abc %}\"",
        "\"{% cycle abc %}{% cycle abc %}{% cycle abc %}{% cycle abc"
    ],
    [
        "msg = \"Only 'silent' flag is allowed after cycle's name, not 'invalid_flag'.\"",
        "msg = \"Only 'silent' flag is allowed after cycle's name, not"
    ],
    [
        "self.assertEqual(output, \"A &amp; B &amp; C &amp; D\")",
        "self.assertEqual(output, \"A &amp; B &amp;"
    ],
    [
        "\"{% cycle one two as foo %} & {% cycle foo %}{% endfilter %}\"",
        "\"{% cycle one two as foo %} &"
    ],
    [
        "self.assertEqual(output, \"A &amp;amp; B &amp; C &amp;amp; D\")",
        "self.assertEqual(output, \"A &amp;amp; B &amp; C &amp;amp;"
    ],
    [
        "\"{% for x in values %}{% cycle 'a' 'b' 'c' as abc silent %}{{ x }}\"",
        "\"{% for x in values %}{% cycle 'a' 'b' 'c' as abc silent %}{{"
    ],
    [
        "\"{% cycle 'a' 'b' 'c' as abc silent %}{{ abc }}{{ x }}{% endfor %}\"",
        "\"{% cycle 'a' 'b' 'c' as abc silent %}{{ abc }}{{ x }}{%"
    ],
    [
        "\"{% for x in values %}\"",
        "\"{% for x"
    ],
    [
        "\"{% cycle 'a' 'b' 'c' as abc silent %}{% include 'included-cycle' %}\"",
        "\"{% cycle 'a' 'b' 'c' as abc"
    ],
    [
        "\"{% autoescape off %}{% cycle a b as ab %}{% cycle ab %}\"",
        "\"{% autoescape off %}{% cycle a b as ab %}{%"
    ],
    [
        "\"{% for x in values %}\"",
        "\"{% for x"
    ],
    [
        "\"{% cycle cycler %}{{ cycler }}\"",
        "\"{% cycle cycler %}{{"
    ],
    [
        "A named {% cycle %} tag works inside an {% ifchanged %} block and a",
        "A named {% cycle %} tag works inside an {% ifchanged %} block"
    ],
    [
        "\"{% for x in values %}\"",
        "\"{% for x in values"
    ],
    [
        "\"{% cycle cycler %}{{ cycler }}\"",
        "\"{% cycle cycler %}{{"
    ],
    [
        "A {% with %} tag shouldn't reset the {% cycle %} variable.",
        "A {% with %} tag shouldn't reset the {%"
    ],
    [
        "\"undefined_cycle\": \"{% cycle 'a' 'b' 'c' as cycler silent %}\"",
        "\"undefined_cycle\": \"{% cycle 'a' 'b'"
    ],
    [
        "\"{% for x in values %}\"",
        "\"{% for x"
    ],
    [
        "\"{% cycle undefined %}{{ cycler }}\"",
        "\"{% cycle undefined"
    ],
    [
        "TemplateSyntaxError, \"Named cycle 'undefined' does not exist\"",
        "TemplateSyntaxError, \"Named cycle 'undefined' does"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import"
    ],
    [
        "'{% url \"client_action\" id=client.id action=\"!$&\\'()*+,;=~:@,\" %}'",
        "'{% url \"client_action\" id=client.id action=\"!$&\\'()*+,;=~:@,\""
    ],
    [
        "url_node = URLNode(view_name=\"named-view\", args=[], kwargs={}, asvar=None)",
        "url_node = URLNode(view_name=\"named-view\","
    ],
    [
        "\"{% if foo %}foo{% elif bar %}bar{% elif baz %}baz{% else %}nothing\"",
        "\"{% if foo %}foo{% elif bar %}bar{% elif baz %}baz{% else"
    ],
    [
        "\"{% if foo %}foo{% elif bar %}bar{% elif baz %}baz{% else %}nothing\"",
        "\"{% if foo %}foo{% elif bar %}bar{% elif"
    ],
    [
        "\"{% if foo %}foo{% elif bar %}bar{% elif baz %}baz{% else %}nothing\"",
        "\"{% if foo %}foo{% elif bar %}bar{% elif baz %}baz{% else"
    ],
    [
        "\"{% if foo %}foo{% elif bar %}bar{% elif baz %}baz{% else %}nothing\"",
        "\"{% if foo %}foo{% elif bar"
    ],
    [
        "\"{% if foo is bar %} yes {% else if foo is not bar %} no {% endif %}\"",
        "\"{% if foo is bar %} yes {% else if foo is not bar %} no"
    ],
    [
        "\"{% if x.is_true or x.is_bad %}yes{% else %}no{% endif %}\"",
        "\"{% if x.is_true or x.is_bad %}yes{% else %}no{%"
    ],
    [
        "If evaluations are shortcircuited where possible",
        "If evaluations are"
    ],
    [
        "\"{% if x.is_false and x.is_bad %}yes{% else %}no{% endif %}\"",
        "\"{% if x.is_false and x.is_bad %}yes{%"
    ],
    [
        "The is_bad() function should not be evaluated. If it is, an",
        "The is_bad() function should not be evaluated. If it is,"
    ],
    [
        "@setup({\"if-tag-single-eq\": \"{% if foo = bar %}yes{% else %}no{% endif %}\"})",
        "@setup({\"if-tag-single-eq\": \"{% if foo = bar %}yes{% else"
    ],
    [
        "@setup({\"template\": \"{% if foo is True %}yes{% else %}no{% endif %}\"})",
        "@setup({\"template\": \"{% if foo is True %}yes{%"
    ],
    [
        "@setup({\"template\": \"{% if foo is True %}yes{% else %}no{% endif %}\"})",
        "@setup({\"template\": \"{% if foo is True %}yes{% else %}no{% endif"
    ],
    [
        "@setup({\"template\": \"{% if foo is bar %}yes{% else %}no{% endif %}\"})",
        "@setup({\"template\": \"{% if foo is bar %}yes{%"
    ],
    [
        "@setup({\"template\": \"{% if foo is bar %}yes{% else %}no{% endif %}\"})",
        "@setup({\"template\": \"{% if foo is bar"
    ],
    [
        "@setup({\"template\": \"{% if foo is not None %}yes{% else %}no{% endif %}\"})",
        "@setup({\"template\": \"{% if foo is not"
    ],
    [
        "@setup({\"template\": \"{% if foo is not None %}yes{% else %}no{% endif %}\"})",
        "@setup({\"template\": \"{% if foo is not None %}yes{% else %}no{% endif"
    ],
    [
        "@setup({\"template\": \"{% if foo is not bar %}yes{% else %}no{% endif %}\"})",
        "@setup({\"template\": \"{% if foo is not"
    ],
    [
        "@setup({\"template\": \"{% if foo is not bar %}yes{% else %}no{% endif %}\"})",
        "@setup({\"template\": \"{% if foo is not bar %}yes{%"
    ],
    [
        "\"{% echo this that theother %} {% other_echo and another thing %}\"",
        "\"{% echo this that theother %}"
    ],
    [
        "self.assertEqual(output, \"this that theother and another thing\")",
        "self.assertEqual(output, \"this that theother and"
    ],
    [
        "\"{% echo this that theother %} {{ statement|upper }}\"",
        "\"{% echo this that theother %} {{"
    ],
    [
        "self.assertEqual(output, \"this that theother NOT SHOUTING\")",
        "self.assertEqual(output, \"this that theother NOT"
    ],
    [
        "msg = \"'bad_tag' is not a valid tag or filter in tag library 'testtags'\"",
        "msg = \"'bad_tag' is not a valid tag or filter in tag"
    ],
    [
        "\"'echo' is not a registered tag library. Must be one of:\\n\"",
        "\"'echo' is not a registered tag library."
    ],
    [
        "\"'from' is not a registered tag library. Must be one of:\\n\"",
        "\"'from' is not a registered tag library."
    ],
    [
        "\"'bad_library' is not a registered tag library. Must be one of:\\n\"",
        "\"'bad_library' is not a registered tag library."
    ],
    [
        "\"'subpackage.missing' is not a registered tag library. Must be one of:\\n\"",
        "\"'subpackage.missing' is not a registered tag"
    ],
    [
        "@skipIf(numpy is False, \"Numpy must be installed to run these tests.\")",
        "@skipIf(numpy is False, \"Numpy must be installed to run"
    ],
    [
        "Numpy's array-index syntax allows a template to access a certain",
        "Numpy's array-index syntax allows a template to access a"
    ],
    [
        "Fail silently when the array index is out of range.",
        "Fail silently when the array"
    ],
    [
        "from django.template import Context, Engine, TemplateSyntaxError",
        "from django.template import"
    ],
    [
        "Allow first argument to be a variable.",
        "Allow first argument to be a"
    ],
    [
        "\"Oh freddled gruntbuggly/Thy micturations are to me/\"",
        "\"Oh freddled gruntbuggly/Thy micturations are"
    ],
    [
        "\"As plurdled gabbleblotchits/On a lurgid bee/\"",
        "\"As plurdled gabbleblotchits/On a"
    ],
    [
        "\"That mordiously hath bitled out/Its earted jurtles/\"",
        "\"That mordiously hath bitled out/Its"
    ],
    [
        "\"Into a rancid festering/Or else I shall rend thee in the \"",
        "\"Into a rancid festering/Or else I shall rend"
    ],
    [
        "\"gobberwarts with my blurglecruncheon/See if I don't.\"",
        "\"gobberwarts with my blurglecruncheon/See if I"
    ],
    [
        "\"\"\"A timeout of None means \"cache forever\".\"\"\"",
        "\"\"\"A timeout of None means"
    ],
    [
        "When a cache called \"template_fragments\" is present, the cache tag",
        "When a cache called \"template_fragments\" is present, the"
    ],
    [
        "will use it in preference to 'default'",
        "will use it in"
    ],
    [
        "When a cache that doesn't exist is specified, the cache tag will",
        "When a cache that doesn't exist is specified, the cache"
    ],
    [
        "from django.template import Context, Template, TemplateSyntaxError",
        "from django.template import Context,"
    ],
    [
        "from ...utils import setup as base_setup",
        "from ...utils import"
    ],
    [
        "from .base import MultipleLocaleActivationTestCase, extended_locale_paths, here",
        "from .base import MultipleLocaleActivationTestCase, extended_locale_paths,"
    ],
    [
        "name: template.replace(\"{% blocktranslate \", \"{% blocktrans \").replace(",
        "name: template.replace(\"{% blocktranslate \", \"{%"
    ],
    [
        "\"{% endblocktranslate %}\", \"{% endblocktrans %}\"",
        "\"{% endblocktranslate %}\", \"{%"
    ],
    [
        "\"\"\"simple translation of a variable and filter\"\"\"",
        "\"\"\"simple translation of a"
    ],
    [
        "\"{% blocktranslate with anton|lower as berta %}{{ berta }}\"",
        "\"{% blocktranslate with anton|lower as berta"
    ],
    [
        "\"\"\"simple translation of a variable and filter\"\"\"",
        "\"\"\"simple translation of a"
    ],
    [
        "\"\"\"simple translation of a string with interpolation\"\"\"",
        "\"\"\"simple translation of a string with"
    ],
    [
        "\"{% blocktranslate count counter=number %}singular{% plural %}\"",
        "\"{% blocktranslate count counter=number %}singular{%"
    ],
    [
        "\"{{ counter }} plural{% endblocktranslate %}\"",
        "\"{{ counter }}"
    ],
    [
        "\"{% blocktranslate count number as counter %}singular{% plural %}\"",
        "\"{% blocktranslate count number as counter %}singular{% plural"
    ],
    [
        "\"{{ counter }} plural{% endblocktranslate %}\"",
        "\"{{ counter }}"
    ],
    [
        "\"{% blocktranslate count number as counter %}singular{% plural %}\"",
        "\"{% blocktranslate count number as counter %}singular{% plural"
    ],
    [
        "\"{{ counter }} plural{% endblocktranslate %}\"",
        "\"{{ counter }} plural{%"
    ],
    [
        "\"{% blocktranslate count counter=number %}singular{% plural %}\"",
        "\"{% blocktranslate count counter=number %}singular{% plural"
    ],
    [
        "\"{{ counter }} plural{% endblocktranslate %}\"",
        "\"{{ counter }} plural{% endblocktranslate"
    ],
    [
        "\"{% blocktranslate with berta=anton|escape %}{{ berta }}\"",
        "\"{% blocktranslate with berta=anton|escape %}{{ berta"
    ],
    [
        "Escaping inside blocktranslate and translate works as if it was",
        "Escaping inside blocktranslate and translate works as if it"
    ],
    [
        "\"{% blocktranslate with berta=anton|force_escape %}{{ berta }}\"",
        "\"{% blocktranslate with berta=anton|force_escape %}{{"
    ],
    [
        "\"{% blocktranslate with anton|escape as berta %}{{ berta }}\"",
        "\"{% blocktranslate with anton|escape as berta %}{{ berta"
    ],
    [
        "\"{% blocktranslate with anton|force_escape as berta %}\"",
        "\"{% blocktranslate with anton|force_escape as berta"
    ],
    [
        "\"{% blocktranslate with extra_field=myextra_field count counter=number %}\"",
        "\"{% blocktranslate with extra_field=myextra_field count counter=number"
    ],
    [
        "\"singular {{ extra_field }}{% plural %}plural{% endblocktranslate %}\"",
        "\"singular {{ extra_field }}{% plural"
    ],
    [
        "\"{% blocktranslate with myextra_field as extra_field \"",
        "\"{% blocktranslate with myextra_field as"
    ],
    [
        "\"count number as counter %}singular {{ extra_field }}{% plural %}plural\"",
        "\"count number as counter %}singular {{"
    ],
    [
        "\"{{ counter }} result{% plural %}{{ counter }} results\"",
        "\"{{ counter }} result{% plural"
    ],
    [
        "\"{% blocktranslate count number as counter %}{{ counter }} result\"",
        "\"{% blocktranslate count number as"
    ],
    [
        "\"{% plural %}{{ counter }} results{% endblocktranslate %}\"",
        "\"{% plural %}{{ counter }}"
    ],
    [
        "\"{% blocktranslate with a=anton b=berta %}{{ a }} + {{ b }}\"",
        "\"{% blocktranslate with a=anton b=berta %}{{ a }} + {{"
    ],
    [
        "\"{% blocktranslate with anton as a and berta as b %}\"",
        "\"{% blocktranslate with anton as a and berta"
    ],
    [
        "\"{{ a }} + {{ b }}{% endblocktranslate %}\"",
        "\"{{ a }} + {{ b }}{%"
    ],
    [
        "'{% translate \"Page not found\" as page_not_found %}'",
        "'{% translate \"Page not"
    ],
    [
        "\"{% blocktranslate %}Error: {{ page_not_found }}{% endblocktranslate %}\"",
        "\"{% blocktranslate %}Error: {{"
    ],
    [
        "\"{% blocktranslate asvar page_not_found %}Page not found\"",
        "\"{% blocktranslate asvar page_not_found %}Page not"
    ],
    [
        "msg = \"No argument provided to the '{}' tag for the asvar option.\".format(",
        "msg = \"No argument provided to the '{}' tag for the"
    ],
    [
        "msg = \"'{}' doesn't allow other block tags (seen 'block b') inside it\".format(",
        "msg = \"'{}' doesn't allow other block tags (seen 'block b')"
    ],
    [
        "TemplateSyntaxError, \"The 'with' option was specified more than once\"",
        "TemplateSyntaxError, \"The 'with' option was specified"
    ],
    [
        "msg = \"\\\"with\\\" in '{}' tag needs at least one keyword argument.\".format(",
        "msg = \"\\\"with\\\" in '{}' tag needs"
    ],
    [
        "msg = \"\\\"count\\\" in '{}' tag expected exactly one keyword argument.\".format(",
        "msg = \"\\\"count\\\" in '{}' tag expected exactly one keyword"
    ],
    [
        "\"{% plural %}{{ counter }}{% endblocktranslate %}\"",
        "\"{% plural %}{{ counter"
    ],
    [
        "msg = \"'counter' argument to '{}' tag must be a number.\".format(tag_name)",
        "msg = \"'counter' argument to '{}' tag"
    ],
    [
        "\"There is {{ count }} object. {% block a %} {% endblock %}\"",
        "\"There is {{ count }} object. {% block a %}"
    ],
    [
        "msg = \"'{}' doesn't allow other block tags inside it\".format(tag_name)",
        "msg = \"'{}' doesn't allow other block"
    ],
    [
        "\"{{% endblocktranslate %}}\", \"{{% end{} %}}\".format(self.tag_name)",
        "\"{{% endblocktranslate %}}\","
    ],
    [
        "'{% blocktranslate context \"month name\" %}May{% endblocktranslate %}'",
        "'{% blocktranslate context \"month name\" %}May{%"
    ],
    [
        "'{% blocktranslate context \"verb\" %}May{% endblocktranslate %}'",
        "'{% blocktranslate context \"verb\" %}May{%"
    ],
    [
        "\" super result{% plural %}{{ number }} super results\"",
        "\" super result{% plural %}{{ number }} super"
    ],
    [
        "\" super result{% plural %}{{ number }} super results\"",
        "\" super result{% plural %}{{ number }}"
    ],
    [
        "\"{{ number }} super result{% plural %}{{ number }} super results\"",
        "\"{{ number }} super result{% plural %}{{ number }}"
    ],
    [
        "\"{{ number }} super result{% plural %}{{ number }} super results\"",
        "\"{{ number }} super result{% plural %}{{ number }}"
    ],
    [
        "\"There are {{ num_comments }} comments{% endblocktranslate %}\"",
        "\"There are {{ num_comments }}"
    ],
    [
        "\"There are {{ num_comments }} comments{% endblocktranslate %}\"",
        "\"There are {{ num_comments }}"
    ],
    [
        "\"There are  \\t\\n  \\t {{ num_comments }} comments\\n\\n\"",
        "\"There are \\t\\n \\t {{ num_comments }}"
    ],
    [
        "\"%}\\n{{ number }} super \\n result{% plural %}{{ number }} super results\"",
        "\"%}\\n{{ number }} super \\n result{% plural %}{{ number }}"
    ],
    [
        "msg = \"Unknown argument for 'blocktranslate' tag: %r.\"",
        "msg = \"Unknown argument"
    ],
    [
        "'\"context\" in %r tag expected exactly one argument.' % \"blocktranslate\"",
        "'\"context\" in %r tag expected"
    ],
    [
        "\"{{ number }} super result{% plural %}{{ number }}\"",
        "\"{{ number }} super result{% plural %}{{ number"
    ],
    [
        "(%(person)s is translated as %(personne)s in fr.po).",
        "(%(person)s is translated as %(personne)s"
    ],
    [
        "(%(person) misses a 's' in fr.po, causing the string formatting to fail)",
        "(%(person) misses a 's' in fr.po,"
    ],
    [
        "self.assertEqual(rendered, \"My other name is James.\")",
        "self.assertEqual(rendered, \"My other"
    ],
    [
        "\"{{% endblocktranslate %}}\", \"{{% end{} %}}\".format(self.tag_name)",
        "\"{{% endblocktranslate %}}\","
    ],
    [
        "\"{{% endblocktranslate %}}\", \"{{% end{} %}}\".format(self.tag_name)",
        "\"{{% endblocktranslate %}}\", \"{{% end{}"
    ],
    [
        "\"{{ percent }}% represents {{ num }} object{% plural %}\"",
        "\"{{ percent }}% represents {{ num }} object{% plural"
    ],
    [
        "\"{{ percent }}% represents {{ num }} objects{% endblocktranslate %}\"",
        "\"{{ percent }}% represents {{ num }} objects{%"
    ],
    [
        "Python's %-formatting is properly escaped in blocktranslate, singular,",
        "Python's %-formatting is properly escaped in blocktranslate,"
    ],
    [
        "\"%(percent)s% represents {{ num }} object{% plural %}\"",
        "\"%(percent)s% represents {{ num }} object{%"
    ],
    [
        "\"%(percent)s% represents {{ num }} objects{% endblocktranslate %}\"",
        "\"%(percent)s% represents {{ num }} objects{%"
    ],
    [
        "'singular=[<Text token: \"content...\">, <Var token: \"variable...\">] '",
        "'singular=[<Text token: \"content...\">, <Var"
    ],
    [
        "\"{% get_available_languages as langs %}{% for lang in langs %}\"",
        "\"{% get_available_languages as langs %}{% for lang in"
    ],
    [
        "\"'get_available_languages' requires 'as variable' (got \"",
        "\"'get_available_languages' requires 'as variable' (got"
    ],
    [
        "'{% get_language_info for \"de\" as l %}'",
        "'{% get_language_info for \"de\" as"
    ],
    [
        "\"{{ l.code }}: {{ l.name }}/{{ l.name_local }} bidi={{ l.bidi }}\"",
        "\"{{ l.code }}: {{ l.name }}/{{ l.name_local }} bidi={{ l.bidi"
    ],
    [
        "\"{% get_language_info for LANGUAGE_CODE as l %}\"",
        "\"{% get_language_info for LANGUAGE_CODE"
    ],
    [
        "\"{{ l.code }}: {{ l.name }}/{{ l.name_local }} bidi={{ l.bidi }}\"",
        "\"{{ l.code }}: {{ l.name }}/{{ l.name_local }}"
    ],
    [
        "'{% get_language_info for \"de\"|noop:\"x y\" as l %}'",
        "'{% get_language_info for \"de\"|noop:\"x y\""
    ],
    [
        "\"{{ l.code }}: {{ l.name }}/{{ l.name_local }}/\"",
        "\"{{ l.code }}: {{ l.name }}/{{ l.name_local"
    ],
    [
        "\"{{ l.name_translated }} bidi={{ l.bidi }}\"",
        "\"{{ l.name_translated }} bidi={{ l.bidi"
    ],
    [
        "msg = \"'get_language_info' requires 'for string as variable' (got [])\"",
        "msg = \"'get_language_info' requires 'for string"
    ],
    [
        "\"'get_current_language' requires 'as variable' (got \"",
        "\"'get_current_language' requires 'as"
    ],
    [
        "from django.template import Context, Template, TemplateSyntaxError",
        "from django.template import Context, Template,"
    ],
    [
        "from ...utils import setup as base_setup",
        "from ...utils import"
    ],
    [
        "name: template.replace(\"{% translate \", \"{% trans \")",
        "name: template.replace(\"{% translate \","
    ],
    [
        "\"\"\"simple translation of a string delimited by '.\"\"\"",
        "\"\"\"simple translation of a string delimited by"
    ],
    [
        "\"\"\"simple translation of a string delimited by \".\"\"\"",
        "\"\"\"simple translation of a string delimited by"
    ],
    [
        "\"\"\"simple translation of a string to German\"\"\"",
        "\"\"\"simple translation of a string"
    ],
    [
        "\"\"\"simple non-translation (only marking) of a string to German\"\"\"",
        "\"\"\"simple non-translation (only marking) of a string"
    ],
    [
        "msg = \"'{}' takes at least one argument\".format(tag_name)",
        "msg = \"'{}' takes at"
    ],
    [
        "msg = \"Unknown argument for '{}' tag: 'badoption'\".format(tag_name)",
        "msg = \"Unknown argument for"
    ],
    [
        "msg = \"No argument provided to the '{}' tag for the as option.\".format(tag_name)",
        "msg = \"No argument provided to the"
    ],
    [
        "msg = \"No argument provided to the '{}' tag for the context option.\".format(",
        "msg = \"No argument provided to the '{}' tag"
    ],
    [
        "f\"Invalid argument 'as' provided to the '{tag_name}' tag for the context \"",
        "f\"Invalid argument 'as' provided to the"
    ],
    [
        "f\"Invalid argument 'noop' provided to the '{tag_name}' tag for the context \"",
        "f\"Invalid argument 'noop' provided to the '{tag_name}' tag for"
    ],
    [
        "msg = \"The 'noop' option was specified more than once.\"",
        "msg = \"The 'noop' option was specified"
    ],
    [
        "\"{% get_language_info_list for langcodes as langs %}\"",
        "\"{% get_language_info_list for langcodes as langs"
    ],
    [
        "\"{% for l in langs %}{{ l.code }}: {{ l.name }}/\"",
        "\"{% for l in langs %}{{ l.code }}: {{"
    ],
    [
        "\"{{ l.name_local }} bidi={{ l.bidi }}; {% endfor %}\"",
        "\"{{ l.name_local }} bidi={{ l.bidi }}; {% endfor"
    ],
    [
        "output, \"it: Italian/italiano bidi=False; no: Norwegian/norsk bidi=False; \"",
        "output, \"it: Italian/italiano bidi=False; no: Norwegian/norsk"
    ],
    [
        "\"{% get_language_info_list for langcodes as langs %}\"",
        "\"{% get_language_info_list for langcodes as"
    ],
    [
        "\"{% for l in langs %}{{ l.code }}: {{ l.name }}/\"",
        "\"{% for l in langs %}{{ l.code }}: {{"
    ],
    [
        "\"{{ l.name_local }} bidi={{ l.bidi }}; {% endfor %}\"",
        "\"{{ l.name_local }} bidi={{ l.bidi }}; {% endfor"
    ],
    [
        "'{% get_language_info_list for langcodes|noop:\"x y\" as langs %}'",
        "'{% get_language_info_list for langcodes|noop:\"x"
    ],
    [
        "\"{% for l in langs %}{{ l.code }}: {{ l.name }}/\"",
        "\"{% for l in langs %}{{ l.code }}: {{"
    ],
    [
        "\"{{ l.name_local }}/{{ l.name_translated }} \"",
        "\"{{ l.name_local }}/{{ l.name_translated }}"
    ],
    [
        "\"bidi={{ l.bidi }}; {% endfor %}\"",
        "\"bidi={{ l.bidi }};"
    ],
    [
        "\"'get_language_info_list' requires 'for sequence as variable' (got \"",
        "\"'get_language_info_list' requires 'for sequence"
    ],
    [
        "\"'get_current_language_bidi' requires 'as variable' (got \"",
        "\"'get_current_language_bidi' requires 'as"
    ],
    [
        "'{{ \"hu\"|language_name_local }} {{ \"hu\"|language_bidi }} '",
        "'{{ \"hu\"|language_name_local }} {{ \"hu\"|language_bidi"
    ],
    [
        "\"{{ langcode|language_name }} {{ langcode|language_name_local }} \"",
        "\"{{ langcode|language_name }} {{ langcode|language_name_local"
    ],
    [
        "\"{{ langcode|language_bidi }} {{ langcode|language_name_translated }}\"",
        "\"{{ langcode|language_bidi }} {{"
    ],
    [
        "'{% get_language_info_list for langcodes|noop:\"x y\" as langs %}'",
        "'{% get_language_info_list for langcodes|noop:\"x y\" as langs"
    ],
    [
        "\"{% for l in langs %}{{ l.code }}: {{ l.name }}/\"",
        "\"{% for l in langs %}{{ l.code }}: {{"
    ],
    [
        "\"{{ l.name_local }}/{{ l.name_translated }} \"",
        "\"{{ l.name_local }}/{{ l.name_translated }}"
    ],
    [
        "\"bidi={{ l.bidi }}; {% endfor %}\"",
        "\"bidi={{ l.bidi }};"
    ],
    [
        "'{% cycle \"foo\" _(\"Password\") _(\\'Password\\') as c %} {% cycle c %} '",
        "'{% cycle \"foo\" _(\"Password\") _(\\'Password\\') as c %} {%"
    ],
    [
        "TemplateSyntaxError, \"'language' takes one argument (language)\"",
        "TemplateSyntaxError, \"'language' takes one"
    ],
    [
        "Tests for template rendering when multiple locales are activated during the",
        "Tests for template rendering when multiple locales are"
    ],
    [
        "\"{% autoescape off %}{{ a|capfirst }} {{ b|capfirst }}\"",
        "\"{% autoescape off %}{{ a|capfirst"
    ],
    [
        "\"{% autoescape off %}{{ a|lower }} {{ b|lower }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|lower }} {{ b|lower }}{% endautoescape"
    ],
    [
        "self.assertEqual(output, \"apple & banana apple &amp; banana\")",
        "self.assertEqual(output, \"apple & banana apple"
    ],
    [
        "self.assertEqual(output, \"apple &amp; banana apple &amp; banana\")",
        "self.assertEqual(output, \"apple &amp; banana apple"
    ],
    [
        "\"{% autoescape off %}{{ a|urlize }} {{ b|urlize }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|urlize }} {{"
    ],
    [
        "teststring is the urlquoted version of 'http://hi.baidu.com/重新开始'",
        "teststring is the urlquoted version"
    ],
    [
        "for wrapping_in, (start_out, end_out) in wrapping_chars:",
        "for wrapping_in, (start_out, end_out)"
    ],
    [
        "'Email us at \"hi@example.com\", or phone us at +xx.yy', autoescape=False",
        "'Email us at \"hi@example.com\", or"
    ],
    [
        "'Email us at \"<a href=\"mailto:hi@example.com\">hi@example.com</a>\", or '",
        "'Email us at \"<a href=\"mailto:hi@example.com\">hi@example.com</a>\", or"
    ],
    [
        "'foo<a href=\" <a href=\"http://google.com\" rel=\"nofollow\">google.com</a> \">'",
        "'foo<a href=\" <a href=\"http://google.com\""
    ],
    [
        "prepend_www = lazy(lambda url: \"www.\" + url, str)",
        "prepend_www = lazy(lambda url:"
    ],
    [
        "\"{% autoescape off %}{{ a|first }} {{ b|first }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|first }}"
    ],
    [
        "Running slugify on a pre-escaped string leads to odd behavior,",
        "Running slugify on a pre-escaped"
    ],
    [
        "but the result is still safe.",
        "but the result"
    ],
    [
        "\"{% autoescape off %}{{ a|slugify }} {{ b|slugify }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|slugify }}"
    ],
    [
        "lazy_str = lazy(lambda string: string, str)",
        "lazy_str = lazy(lambda string: string,"
    ],
    [
        "'{% autoescape off %}{{ a|cut:\"x\" }} {{ b|cut:\"x\" }}{% endautoescape %}'",
        "'{% autoescape off %}{{ a|cut:\"x\" }} {{ b|cut:\"x\" }}{%"
    ],
    [
        "'{% autoescape off %}{{ a|cut:\"&\" }} {{ b|cut:\"&\" }}{% endautoescape %}'",
        "'{% autoescape off %}{{ a|cut:\"&\" }} {{ b|cut:\"&\""
    ],
    [
        "'{% autoescape off %}{{ a|cut:\";\" }} {{ b|cut:\";\" }}{% endautoescape %}'",
        "'{% autoescape off %}{{ a|cut:\";\" }} {{ b|cut:\";\""
    ],
    [
        "self.assertEqual(cut(\"a string to be mangled\", \"a\"), \" string to be mngled\")",
        "self.assertEqual(cut(\"a string to be mangled\", \"a\"),"
    ],
    [
        "self.assertEqual(cut(\"a string to be mangled\", \"ng\"), \"a stri to be maled\")",
        "self.assertEqual(cut(\"a string to be mangled\", \"ng\"), \"a"
    ],
    [
        "cut(\"a string to be mangled\", \"strings\"), \"a string to be mangled\"",
        "cut(\"a string to be mangled\", \"strings\"), \"a string to be"
    ],
    [
        "@setup({\"t\": '{{ var|yesno:\"yup,nup,mup\" }} {{ var|yesno }}'})",
        "@setup({\"t\": '{{ var|yesno:\"yup,nup,mup\" }} {{ var|yesno"
    ],
    [
        "self.assertEqual(yesno(True, \"certainly,get out of town,perhaps\"), \"certainly\")",
        "self.assertEqual(yesno(True, \"certainly,get out of town,perhaps\"),"
    ],
    [
        "yesno(False, \"certainly,get out of town,perhaps\"), \"get out of town\"",
        "yesno(False, \"certainly,get out of town,perhaps\"),"
    ],
    [
        "self.assertEqual(yesno(None, \"certainly,get out of town\"), \"get out of town\")",
        "self.assertEqual(yesno(None, \"certainly,get out of town\"),"
    ],
    [
        "self.assertEqual(yesno(None, \"certainly,get out of town,perhaps\"), \"perhaps\")",
        "self.assertEqual(yesno(None, \"certainly,get out of town,perhaps\"),"
    ],
    [
        "from ..utils import SafeClass, UnsafeClass, setup",
        "from ..utils import"
    ],
    [
        "Filters decorated with stringfilter still respect is_safe.",
        "Filters decorated with stringfilter still respect"
    ],
    [
        "\"{% autoescape off %}{{ unsafe|capfirst }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ unsafe|capfirst }}{%"
    ],
    [
        "\"{% autoescape off %}{{ safe|capfirst }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ safe|capfirst }}{%"
    ],
    [
        "The contents of \"linenumbers\" is escaped according to the current",
        "The contents of \"linenumbers\" is escaped according to the"
    ],
    [
        "\"{% autoescape off %}{{ a|linenumbers }} {{ b|linenumbers }}\"",
        "\"{% autoescape off %}{{ a|linenumbers"
    ],
    [
        "from django.template.defaultfilters import time as time_filter",
        "from django.template.defaultfilters import time"
    ],
    [
        "\"{% autoescape off %}{{ a|addslashes }} {{ b|addslashes }}\"",
        "\"{% autoescape off %}{{ a|addslashes }} {{ b|addslashes"
    ],
    [
        "self.assertEqual(addslashes(r\"\\ : backslashes, too\"), \"\\\\\\\\ : backslashes, too\")",
        "self.assertEqual(addslashes(r\"\\ : backslashes, too\"), \"\\\\\\\\ : backslashes,"
    ],
    [
        "Force_escape is applied immediately. It can be used to provide",
        "Force_escape is applied immediately. It can be used"
    ],
    [
        "\"{% autoescape off %}{{ a|force_escape }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|force_escape"
    ],
    [
        "\"{% autoescape off %}{{ a|force_escape|force_escape }}\"",
        "\"{% autoescape off %}{{"
    ],
    [
        "\"{% autoescape off %}{{ a|force_escape|escape }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|force_escape|escape }}{% endautoescape"
    ],
    [
        "\"{% autoescape off %}{{ a|escape|force_escape }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|escape|force_escape }}{% endautoescape"
    ],
    [
        "escaped = force_escape(\"<some html & special characters > here\")",
        "escaped = force_escape(\"<some html &"
    ],
    [
        "self.assertEqual(escaped, \"&lt;some html &amp; special characters &gt; here\")",
        "self.assertEqual(escaped, \"&lt;some html &amp; special"
    ],
    [
        "force_escape(\"<some html & special characters > here ĐÅ€£\"),",
        "force_escape(\"<some html & special characters > here"
    ],
    [
        "The contents in \"linebreaksbr\" are escaped according to the current",
        "The contents in \"linebreaksbr\" are escaped according to the"
    ],
    [
        "\"{% autoescape off %}{{ a|linebreaksbr }} {{ b|linebreaksbr }}\"",
        "\"{% autoescape off %}{{ a|linebreaksbr }}"
    ],
    [
        "The \"escapeseq\" filter works the same whether autoescape is on or off,",
        "The \"escapeseq\" filter works the same whether autoescape is on or"
    ],
    [
        "and has no effect on strings already marked as safe.",
        "and has no effect on strings already marked as"
    ],
    [
        "'{{ a|escapeseq|join:\", \" }} -- {{ b|escapeseq|join:\", \" }}'",
        "'{{ a|escapeseq|join:\", \" }} --"
    ],
    [
        "{\"a\": [\"x&y\", \"<p>\"], \"b\": [mark_safe(\"x&y\"), mark_safe(\"<p>\")]},",
        "{\"a\": [\"x&y\", \"<p>\"],"
    ],
    [
        "self.assertEqual(output, \"x&amp;y, &lt;p&gt; -- x&y, <p>\")",
        "self.assertEqual(output, \"x&amp;y, &lt;p&gt; --"
    ],
    [
        "'{% autoescape off %}{{ a|escapeseq|join:\", \" }}'",
        "'{% autoescape off %}{{ a|escapeseq|join:\","
    ],
    [
        "{\"a\": [\"x&y\", \"<p>\"], \"b\": [mark_safe(\"x&y\"), mark_safe(\"<p>\")]},",
        "{\"a\": [\"x&y\", \"<p>\"], \"b\": [mark_safe(\"x&y\"),"
    ],
    [
        "self.assertEqual(output, \"x&amp;y, &lt;p&gt; -- x&y, <p>\")",
        "self.assertEqual(output, \"x&amp;y, &lt;p&gt;"
    ],
    [
        "output = self.engine.render_to_string(\"escapeseq_join\", {\"a\": [\"x&y\", \"<p>\"]})",
        "output = self.engine.render_to_string(\"escapeseq_join\", {\"a\":"
    ],
    [
        "'{% autoescape off %}{{ a|escapeseq|join:\"<br/>\" }}{% endautoescape %}'",
        "'{% autoescape off %}{{ a|escapeseq|join:\"<br/>\" }}{% endautoescape"
    ],
    [
        "self.assertEqual(output, \"alpha &amp; beta &amp; me\")",
        "self.assertEqual(output, \"alpha &amp;"
    ],
    [
        "self.assertEqual(output, \"alpha &amp; beta & me\")",
        "self.assertEqual(output, \"alpha &amp;"
    ],
    [
        "self.assertEqual(output, \"alpha &amp; beta &amp; me\")",
        "self.assertEqual(output, \"alpha &amp;"
    ],
    [
        "self.assertEqual(output, \"alpha & beta &amp; me\")",
        "self.assertEqual(output, \"alpha & beta &amp;"
    ],
    [
        "self.assertEqual(output, \"alpha &amp; beta &amp; me\")",
        "self.assertEqual(output, \"alpha &amp; beta &amp;"
    ],
    [
        "self.assertEqual(output, \"alpha & beta &amp; me\")",
        "self.assertEqual(output, \"alpha &"
    ],
    [
        "var_list = [\"<p>Hello World!</p>\", \"beta & me\", \"<script>Hi!</script>\"]",
        "var_list = [\"<p>Hello World!</p>\", \"beta & me\","
    ],
    [
        "context = {\"var_list\": var_list, \"var_joiner\": \"<br/>\"}",
        "context = {\"var_list\": var_list,"
    ],
    [
        "expected_result = \"<p>Hello World!</p><br/>beta & me<br/><script>Hi!</script>\"",
        "expected_result = \"<p>Hello World!</p><br/>beta &"
    ],
    [
        "If dictsortreversed is passed something other than a list of",
        "If dictsortreversed is passed something other than a list"
    ],
    [
        "\"\"\"Fail silently if invalid lookups are passed.\"\"\"",
        "\"\"\"Fail silently if invalid lookups"
    ],
    [
        "self.assertEqual(title(\"a nice title, isn't it?\"), \"A Nice Title, Isn't It?\")",
        "self.assertEqual(title(\"a nice title, isn't it?\"), \"A Nice Title, Isn't"
    ],
    [
        "{\"a\": \"alpha & bravo\", \"b\": mark_safe(\"alpha &amp; bravo\")},",
        "{\"a\": \"alpha & bravo\","
    ],
    [
        "self.assertEqual(output, \"alpha & … alpha &amp; …\")",
        "self.assertEqual(output, \"alpha & … alpha &amp;"
    ],
    [
        "{\"a\": \"alpha & bravo\", \"b\": mark_safe(\"alpha &amp; bravo\")},",
        "{\"a\": \"alpha & bravo\", \"b\": mark_safe(\"alpha &amp;"
    ],
    [
        "self.assertEqual(output, \"alpha &amp; … alpha &amp; …\")",
        "self.assertEqual(output, \"alpha &amp; … alpha &amp;"
    ],
    [
        "\"A sentence with a few …\",",
        "\"A sentence with"
    ],
    [
        "\"A sentence with a few words in it\",",
        "\"A sentence with a"
    ],
    [
        "truncatewords(\"A sentence with a few words in it\", \"not a number\"),",
        "truncatewords(\"A sentence with a few words in it\","
    ],
    [
        "\"A sentence with a few words in it\",",
        "\"A sentence with a few words"
    ],
    [
        "self.assertEqual(output, \"&amp;, &lt; -- &, <\")",
        "self.assertEqual(output, \"&amp;, &lt;"
    ],
    [
        "'{% autoescape off %}{{ a|join:\", \" }} -- {{ a|safeseq|join:\", \" }}'",
        "'{% autoescape off %}{{ a|join:\", \" }}"
    ],
    [
        "self.assertEqual(output, \"&, < -- &, <\")",
        "self.assertEqual(output, \"&, <"
    ],
    [
        "{\"a\": \"How razorback-jumping frogs can level six piqued gymnasts!\"},",
        "{\"a\": \"How razorback-jumping frogs can level"
    ],
    [
        "\"this is a long paragraph of text that really needs to be wrapped I'm \"",
        "\"this is a long paragraph of text that really needs to be wrapped I'm"
    ],
    [
        "\"this is a long\\nparagraph of\\ntext that\\nreally needs\\nto be wrapped\\n\"",
        "\"this is a long\\nparagraph of\\ntext that\\nreally needs\\nto be"
    ],
    [
        "\"this is a short paragraph of text.\\n  But this line should be \"",
        "\"this is a short paragraph of text.\\n But this line"
    ],
    [
        "\"this is a\\nshort\\nparagraph of\\ntext.\\n  But this\\nline should be\\n\"",
        "\"this is a\\nshort\\nparagraph of\\ntext.\\n But"
    ],
    [
        "\"this is a short paragraph of text.\\n  But this line should be \"",
        "\"this is a short paragraph of text.\\n But this line should"
    ],
    [
        "\"this is a short\\nparagraph of\\ntext.\\n  But this line\\nshould be\\n\"",
        "\"this is a short\\nparagraph of\\ntext.\\n"
    ],
    [
        "\"this is a long paragraph of text that really needs to be wrapped \"",
        "\"this is a long paragraph of text that really needs"
    ],
    [
        "\"this is a long\\nparagraph of\\ntext that\\nreally needs\\nto be wrapped\\n\"",
        "\"this is a long\\nparagraph of\\ntext that\\nreally needs\\nto be"
    ],
    [
        "@setup({\"empty_list\": \"{% autoescape off %}{{ a|last }}{% endautoescape %}\"})",
        "@setup({\"empty_list\": \"{% autoescape off %}{{ a|last"
    ],
    [
        "The \"escape\" filter works the same whether autoescape is on or off,",
        "The \"escape\" filter works the same whether"
    ],
    [
        "but it has no effect on strings already marked as safe.",
        "but it has no effect on strings already marked as"
    ],
    [
        "\"{% autoescape off %}{{ a|escape }} {{ b|escape }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|escape }} {{"
    ],
    [
        "add_html = lazy(lambda string: string + \"special characters > here\", str)",
        "add_html = lazy(lambda string: string + \"special characters >"
    ],
    [
        "escaped = escape(add_html(\"<some html & \"))",
        "escaped = escape(add_html(\"<some html &"
    ],
    [
        "self.assertEqual(escaped, \"&lt;some html &amp; special characters &gt; here\")",
        "self.assertEqual(escaped, \"&lt;some html &amp;"
    ],
    [
        "\"{% autoescape off %}{{ a|striptags }} {{ b|striptags }}\"",
        "\"{% autoescape off %}{{ a|striptags }}"
    ],
    [
        "'some <b>html</b> with <script>alert(\"You smell\")</script> disallowed '",
        "'some <b>html</b> with <script>alert(\"You smell\")</script> disallowed"
    ],
    [
        "'some html with alert(\"You smell\") disallowed  tags',",
        "'some html with alert(\"You smell\")"
    ],
    [
        "'some <b>html</b> with <script>alert(\"Hello\")</script> disallowed '",
        "'some <b>html</b> with <script>alert(\"Hello\")</script>"
    ],
    [
        "'some html with alert(\"Hello\") disallowed  tags',",
        "'some html with alert(\"Hello\")"
    ],
    [
        "Literal string arguments to the default filter are always treated as",
        "Literal string arguments to the default filter are always treated"
    ],
    [
        "safe strings, regardless of the auto-escaping state.",
        "safe strings, regardless of the auto-escaping"
    ],
    [
        "Note: we have to use {\"a\": \"\"} here, otherwise the invalid template",
        "Note: we have to use {\"a\":"
    ],
    [
        "variable string interferes with the test result.",
        "variable string interferes with the"
    ],
    [
        "'{% autoescape off %}{{ a|default:\"x<\" }}{% endautoescape %}'",
        "'{% autoescape off %}{{ a|default:\"x<\" }}{% endautoescape"
    ],
    [
        "'foo<a href=\" <a href=\"http://google.com\" rel=\"nofollow\">google.c…</a> \">'",
        "'foo<a href=\" <a href=\"http://google.com\" rel=\"nofollow\">google.c…</a>"
    ],
    [
        "\"{% autoescape off %}{{ a|unordered_list }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|unordered_list"
    ],
    [
        "\"{% autoescape off %}{{ a|unordered_list }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|unordered_list }}{% endautoescape"
    ],
    [
        "\"{% autoescape off %}{{ a|unordered_list }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|unordered_list"
    ],
    [
        "The \"upper\" filter messes up entities (which are case-sensitive),",
        "The \"upper\" filter messes up entities (which are"
    ],
    [
        "so it's not safe for non-escaping purposes.",
        "so it's not safe"
    ],
    [
        "\"{% autoescape off %}{{ a|upper }} {{ b|upper }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|upper }} {{ b|upper }}{%"
    ],
    [
        "self.assertEqual(output, \"A & B A &AMP; B\")",
        "self.assertEqual(output, \"A & B A"
    ],
    [
        "self.assertEqual(output, \"A &amp; B A &amp;AMP; B\")",
        "self.assertEqual(output, \"A &amp; B A &amp;AMP;"
    ],
    [
        "self.assertEqual(upper(\"Mixed case input\"), \"MIXED CASE INPUT\")",
        "self.assertEqual(upper(\"Mixed case input\"), \"MIXED CASE"
    ],
    [
        "\"{% autoescape off %}{{ a|floatformat }} {{ b|floatformat }}\"",
        "\"{% autoescape off %}{{ a|floatformat }} {{ b|floatformat"
    ],
    [
        "for num, decimal_places, expected in tests:",
        "for num, decimal_places, expected in"
    ],
    [
        "Chaining safeness-preserving filters should not alter the safe status.",
        "Chaining safeness-preserving filters should not alter"
    ],
    [
        "self.assertEqual(output, \" A &lt; b . A < b \")",
        "self.assertEqual(output, \" A &lt; b . A < b"
    ],
    [
        "self.assertEqual(output, \" A < b . A < b \")",
        "self.assertEqual(output, \" A < b . A"
    ],
    [
        "self.assertEqual(output, \"A &lt; .A < \")",
        "self.assertEqual(output, \"A &lt; .A"
    ],
    [
        "'{% autoescape off %}{{ a|cut:\"b\"|capfirst }}.{{ b|cut:\"b\"|capfirst }}'",
        "'{% autoescape off %}{{"
    ],
    [
        "self.assertEqual(output, \"A < .A < \")",
        "self.assertEqual(output, \"A <"
    ],
    [
        "'{% autoescape off %}{{ a|force_escape|cut:\";\" }}{% endautoescape %}'",
        "'{% autoescape off %}{{ a|force_escape|cut:\";\" }}{% endautoescape"
    ],
    [
        "'{% autoescape off %}{{ a|cut:\";\"|force_escape }}{% endautoescape %}'",
        "'{% autoescape off %}{{ a|cut:\";\"|force_escape }}{%"
    ],
    [
        "\"{% autoescape off %}{{ a|safe|force_escape }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|safe|force_escape }}{%"
    ],
    [
        "Notice that escaping is applied *after* any filters, so the string",
        "Notice that escaping is applied *after* any filters, so the"
    ],
    [
        "formatting here only needs to deal with pre-escaped characters.",
        "formatting here only needs to deal with pre-escaped"
    ],
    [
        "append_script = lazy(lambda string: r\"<script>this</script>\" + string, str)",
        "append_script = lazy(lambda string: r\"<script>this</script>\" + string,"
    ],
    [
        "\"\"\"Without arg, the active language's DATE_FORMAT is used.\"\"\"",
        "\"\"\"Without arg, the active language's"
    ],
    [
        "self.assertEqual(output, \". a&b . . a&b .\")",
        "self.assertEqual(output, \". a&b . ."
    ],
    [
        "self.assertEqual(output, \". a&amp;b . . a&b .\")",
        "self.assertEqual(output, \". a&amp;b . . a&b"
    ],
    [
        "The contents in \"linebreaks\" are escaped according to the current",
        "The contents in \"linebreaks\" are escaped"
    ],
    [
        "\"{% autoescape off %}{{ a|linebreaks }} {{ b|linebreaks }}\"",
        "\"{% autoescape off %}{{ a|linebreaks }} {{"
    ],
    [
        "add_header = lazy(lambda string: \"Header\\n\\n\" + string, str)",
        "add_header = lazy(lambda string: \"Header\\n\\n\" + string,"
    ],
    [
        "The make_list filter can destroy existing escaping, so the results are",
        "The make_list filter can destroy existing escaping, so the"
    ],
    [
        "'{% autoescape off %}{{ a|make_list|stringformat:\"s\"|safe }}'",
        "'{% autoescape off %}{{"
    ],
    [
        "\"\"\"This is just a test method.\"\"\"",
        "\"\"\"This is just a test"
    ],
    [
        "for arg, data, expected_value in tests:",
        "for arg, data, expected_value"
    ],
    [
        "for arg, data, expected_exception in fail_tests:",
        "for arg, data,"
    ],
    [
        "Since dictsort uses dict.get()/getattr() under the hood, it can sort",
        "Since dictsort uses dict.get()/getattr() under the hood, it"
    ],
    [
        "If dictsort is passed something other than a list of dictionaries,",
        "If dictsort is passed something other than"
    ],
    [
        "\"\"\"Fail silently if invalid lookups are passed.\"\"\"",
        "\"\"\"Fail silently if invalid"
    ],
    [
        "\"{% autoescape off %}{{ a|wordcount }} {{ b|wordcount }}\"",
        "\"{% autoescape off %}{{ a|wordcount }}"
    ],
    [
        "\"{% autoescape off %}{{ a|random }} {{ b|random }}{% endautoescape %}\"",
        "\"{% autoescape off %}{{ a|random }}"
    ],
    [
        "Tests for built in Function expressions.",
        "Tests for built in"
    ],
    [
        "from django.db.models import Value as V",
        "from django.db.models import"
    ],
    [
        "from django.db.models.functions import Coalesce, Length, Upper",
        "from django.db.models.functions import"
    ],
    [
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod",
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do"
    ],
    [
        "tempor incididunt ut labore et dolore magna aliqua.\"\"\"",
        "tempor incididunt ut labore et dolore magna"
    ],
    [
        "from datetime import timezone as datetime_timezone",
        "from datetime import"
    ],
    [
        "from ..models import Author, DTModel, Fan",
        "from ..models import Author,"
    ],
    [
        "Extract year uses a BETWEEN filter to compare the year to allow indexes",
        "Extract year uses a BETWEEN filter to compare the"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"lookup_name must be provided\"):",
        "with self.assertRaisesMessage(ValueError, \"lookup_name"
    ],
    [
        "\"Extract input expression must be DateField, DateTimeField, TimeField, or \"",
        "\"Extract input expression must be DateField, DateTimeField,"
    ],
    [
        "\"Cannot extract time component 'second' from DateField 'start_date'.\",",
        "\"Cannot extract time component 'second' from"
    ],
    [
        "\"Extract input expression must be DateField, DateTimeField, \"",
        "\"Extract input expression must"
    ],
    [
        "msg = \"Extract requires native DurationField database support.\"",
        "msg = \"Extract requires"
    ],
    [
        "msg = \"Cannot extract component '%s' from DurationField 'duration'.\"",
        "msg = \"Cannot extract component '%s'"
    ],
    [
        "date_truncations = [\"year\", \"quarter\", \"month\", \"day\"]",
        "date_truncations = [\"year\", \"quarter\", \"month\","
    ],
    [
        "msg = \"output_field must be either DateField, TimeField, or DateTimeField\"",
        "msg = \"output_field must be either"
    ],
    [
        "msg = \"'name' isn't a DateField, TimeField, or DateTimeField.\"",
        "msg = \"'name' isn't a"
    ],
    [
        "msg = \"Cannot truncate DateField 'start_date' to DateTimeField\"",
        "msg = \"Cannot truncate DateField 'start_date'"
    ],
    [
        "msg = \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "msg = \"Cannot truncate TimeField 'start_time'"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time' to"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time' to"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time'"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time' to"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time' to"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time'"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time'"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time'"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'start_date' to TimeField\"",
        "ValueError, \"Cannot truncate DateField"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'start_date' to TimeField\"",
        "ValueError, \"Cannot truncate DateField 'start_date' to"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField 'start_time' to"
    ],
    [
        "ValueError, \"Cannot truncate TimeField 'start_time' to DateTimeField\"",
        "ValueError, \"Cannot truncate TimeField"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'start_date' to DateTimeField\"",
        "ValueError, \"Cannot truncate DateField 'start_date' to"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'start_date' to DateTimeField\"",
        "ValueError, \"Cannot truncate DateField"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'start_date' to DateTimeField\"",
        "ValueError, \"Cannot truncate DateField"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'start_date' to DateTimeField\"",
        "ValueError, \"Cannot truncate DateField 'start_date' to"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'start_date' to DateTimeField\"",
        "ValueError, \"Cannot truncate DateField 'start_date'"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'start_date' to DateTimeField\"",
        "ValueError, \"Cannot truncate DateField 'start_date'"
    ],
    [
        "tz = datetime_timezone.utc if settings.USE_TZ else None",
        "tz = datetime_timezone.utc if settings.USE_TZ else"
    ],
    [
        "msg = \"tzinfo can only be used with DateTimeField.\"",
        "msg = \"tzinfo can only be used"
    ],
    [
        "If the truncated datetime transitions to a different offset (daylight",
        "If the truncated datetime transitions to a"
    ],
    [
        "saving) then the returned value will have that new timezone/offset.",
        "saving) then the returned value will"
    ],
    [
        "date_truncations = [\"year\", \"quarter\", \"month\", \"week\", \"day\"]",
        "date_truncations = [\"year\", \"quarter\", \"month\", \"week\","
    ],
    [
        "msg = \"tzinfo can only be used with DateTimeField.\"",
        "msg = \"tzinfo can only be used"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel, FloatModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel, FloatModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import"
    ],
    [
        "msg = \"SQLite does not support negative precision.\"",
        "msg = \"SQLite does not support"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel, FloatModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel, FloatModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel, FloatModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import DecimalModel,"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import"
    ],
    [
        "from ..models import DecimalModel, FloatModel, IntegerModel",
        "from ..models import"
    ],
    [
        "msg = \"JSONObject() is not supported on this database backend.\"",
        "msg = \"JSONObject() is not supported on"
    ],
    [
        "from django.db.models import CharField, F, Value",
        "from django.db.models import CharField, F,"
    ],
    [
        "from django.db.models.functions import Cast, JSONArray, JSONObject, Lower",
        "from django.db.models.functions import Cast, JSONArray,"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\","
    ],
    [
        "msg = \"JSONFields are not supported on this database backend.\"",
        "msg = \"JSONFields are not supported on"
    ],
    [
        "from django.db.models.functions import Lag, Lead, NthValue, Ntile",
        "from django.db.models.functions import Lag, Lead,"
    ],
    [
        "msg = \"NthValue requires a positive integer as for nth\"",
        "msg = \"NthValue requires a positive"
    ],
    [
        "msg = \"NthValue requires a non-null source expression\"",
        "msg = \"NthValue requires a"
    ],
    [
        "msg = \"Lag requires a positive integer for the offset\"",
        "msg = \"Lag requires a positive integer"
    ],
    [
        "msg = \"Lead requires a positive integer for the offset\"",
        "msg = \"Lead requires a positive"
    ],
    [
        "msg = \"Lead requires a non-null source expression\"",
        "msg = \"Lead requires a non-null"
    ],
    [
        "msg = \"Lag requires a non-null source expression\"",
        "msg = \"Lag requires a"
    ],
    [
        "self.skipTest(\"This backend does not support case-insensitive collations.\")",
        "self.skipTest(\"This backend does not"
    ],
    [
        "self.skipTest(\"This backend does not support case-sensitive collations.\")",
        "self.skipTest(\"This backend does not support"
    ],
    [
        "self.skipTest(\"This backend does not support language collations.\")",
        "self.skipTest(\"This backend does not support"
    ],
    [
        "msg = \"Invalid collation name: %r.\"",
        "msg = \"Invalid collation name:"
    ],
    [
        "with self.subTest(value), self.assertRaisesMessage(ValueError, msg % value):",
        "with self.subTest(value), self.assertRaisesMessage(ValueError, msg"
    ],
    [
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod",
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed"
    ],
    [
        "tempor incididunt ut labore et dolore magna aliqua.\"\"\"",
        "tempor incididunt ut labore et dolore magna"
    ],
    [
        "authors.order_by(\"name\"), [\"smithj\", \"Rhonda\"], lambda a: a.display_name",
        "authors.order_by(\"name\"), [\"smithj\", \"Rhonda\"],"
    ],
    [
        "ValueError, \"Coalesce must take at least two expressions\"",
        "ValueError, \"Coalesce must take at least two"
    ],
    [
        "self.assertQuerySetEqual(authors, [\"Rhonda\", \"John Smith\"], lambda a: a.name)",
        "self.assertQuerySetEqual(authors, [\"Rhonda\", \"John Smith\"], lambda"
    ],
    [
        "self.assertQuerySetEqual(authors, [\"Rhonda\", \"John Smith\"], lambda a: a.name)",
        "self.assertQuerySetEqual(authors, [\"Rhonda\", \"John Smith\"],"
    ],
    [
        "self.assertQuerySetEqual(authors, [\"John Smith\", \"Rhonda\"], lambda a: a.name)",
        "self.assertQuerySetEqual(authors, [\"John Smith\", \"Rhonda\"], lambda a:"
    ],
    [
        "from django.test import TestCase, ignore_warnings, skipUnlessDBFeature",
        "from django.test import TestCase,"
    ],
    [
        "from ..models import Author, DTModel, Fan, FloatModel",
        "from ..models import Author, DTModel, Fan,"
    ],
    [
        "The SQL for the Cast expression is wrapped with parentheses in case",
        "The SQL for the Cast expression"
    ],
    [
        "@skipUnless(connection.vendor == \"oracle\", \"Oracle specific test for NULL-literal\")",
        "@skipUnless(connection.vendor == \"oracle\", \"Oracle specific test"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TestCase,"
    ],
    [
        "from ..models import Article, Author, DecimalModel, Fan",
        "from ..models import Article,"
    ],
    [
        "past_sql = RawSQL(\"cast(%s as datetime)\", (past,))",
        "past_sql = RawSQL(\"cast(%s as"
    ],
    [
        "ValueError, \"Greatest must take at least two expressions\"",
        "ValueError, \"Greatest must take at"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import"
    ],
    [
        "from ..models import Article, Author, DecimalModel, Fan",
        "from ..models import Article, Author,"
    ],
    [
        "future_sql = RawSQL(\"cast(%s as datetime)\", (future,))",
        "future_sql = RawSQL(\"cast(%s"
    ],
    [
        "ValueError, \"Least must take at least two expressions\"",
        "ValueError, \"Least must take at"
    ],
    [
        "authors.order_by(\"name\"), [\"john smith\", \"rhonda\"], lambda a: a.lower_name",
        "authors.order_by(\"name\"), [\"john smith\", \"rhonda\"], lambda a:"
    ],
    [
        "authors.order_by(\"name\"), [\"John Smith\"], lambda a: a.name",
        "authors.order_by(\"name\"), [\"John Smith\"],"
    ],
    [
        "text=\"This is about How to Django.\",",
        "text=\"This is about"
    ],
    [
        "from django.db.models.functions import Chr, Left, Ord",
        "from django.db.models.functions import Chr,"
    ],
    [
        "authors, [repeated_text], lambda a: a.repeated_text, ordered=False",
        "authors, [repeated_text], lambda"
    ],
    [
        "authors.order_by(\"name\"), [\"John \", \"Rhond\"], lambda a: a.name_part",
        "authors.order_by(\"name\"), [\"John \", \"Rhond\"], lambda"
    ],
    [
        "authors.order_by(\"name\"), [\"smithj\", \"rh\"], lambda a: a.alias",
        "authors.order_by(\"name\"), [\"smithj\", \"rh\"],"
    ],
    [
        "authors.order_by(\"name\"), [\"Joh\", \"Rho\"], lambda a: a.name_part",
        "authors.order_by(\"name\"), [\"Joh\", \"Rho\"],"
    ],
    [
        "from django.db.models.functions import LTrim, RTrim, Trim",
        "from django.db.models.functions import"
    ],
    [
        "self.assertQuerySetEqual(authors, [\" John  \"], lambda a: a.name)",
        "self.assertQuerySetEqual(authors, [\" John \"],"
    ],
    [
        "from django.db.models.functions import Length, Reverse, Trim",
        "from django.db.models.functions import"
    ],
    [
        "(\"John Smith\", \"htimS nhoJ\", \"gnirts citats\"),",
        "(\"John Smith\", \"htimS nhoJ\","
    ],
    [
        "(\"Élena Jordan\", \"nadroJ anelÉ\", \"gnirts citats\"),",
        "(\"Élena Jordan\", \"nadroJ anelÉ\", \"gnirts"
    ],
    [
        "from django.db.models import Value as V",
        "from django.db.models import"
    ],
    [
        "from django.db.models.functions import Concat, ConcatPair, Upper",
        "from django.db.models.functions import"
    ],
    [
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod",
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit,"
    ],
    [
        "tempor incididunt ut labore et dolore magna aliqua.\"\"\"",
        "tempor incididunt ut labore et dolore magna"
    ],
    [
        "ValueError, \"Concat must take at least two expressions\"",
        "ValueError, \"Concat must take at least"
    ],
    [
        "joined=Concat(\"name\", V(\" (\"), \"goes_by\", V(\")\"), output_field=CharField()),",
        "joined=Concat(\"name\", V(\" (\"), \"goes_by\", V(\")\"),"
    ],
    [
        "title_text=Concat(\"title\", V(\" - \"), \"text\", output_field=TextField()),",
        "title_text=Concat(\"title\", V(\" - \"),"
    ],
    [
        "self.assertEqual(article.title + \" - \" + article.text, article.title_text)",
        "self.assertEqual(article.title + \" -"
    ],
    [
        "Concat(\"title\", V(\" - \"), \"text\", output_field=TextField())",
        "Concat(\"title\", V(\" - \"), \"text\","
    ],
    [
        "expected = article.title + \" - \" + article.text",
        "expected = article.title + \" -"
    ],
    [
        "\"SQLite and PostgreSQL specific implementation detail.\",",
        "\"SQLite and PostgreSQL"
    ],
    [
        "qs = Article.objects.annotate(description=Concat(\"title\", V(\": \"), \"summary\"))",
        "qs = Article.objects.annotate(description=Concat(\"title\", V(\": \"),"
    ],
    [
        "\"name\", V(\":\"), \"alias\", V(\":\"), \"age\", output_field=TextField()",
        "\"name\", V(\":\"), \"alias\", V(\":\"),"
    ],
    [
        "authors.order_by(\"name\"), [\"John Smith\"], lambda a: a.name",
        "authors.order_by(\"name\"), [\"John Smith\"],"
    ],
    [
        "from django.db.models.functions import Length, LPad, RPad",
        "from django.db.models.functions import"
    ],
    [
        "authors, [padded_name], lambda a: a.padded_name, ordered=False",
        "authors, [padded_name], lambda a: a.padded_name,"
    ],
    [
        "(\"George R. R. Martin\", \"George Martin\"),",
        "(\"George R. R. Martin\", \"George"
    ],
    [
        "(\"J. R. R. Tolkien\", \"J. Tolkien\"),",
        "(\"J. R. R. Tolkien\","
    ],
    [
        "(\"George R. R. Martin\", \"George R. R. Martin\"),",
        "(\"George R. R. Martin\", \"George"
    ],
    [
        "(\"J. R. R. Tolkien\", \"J. R. R. Tolkien\"),",
        "(\"J. R. R. Tolkien\","
    ],
    [
        "Concat(Value(\"Author: \"), F(\"name\")), Value(\"Author: \"), Value(\"\")",
        "Concat(Value(\"Author: \"), F(\"name\")), Value(\"Author: \"),"
    ],
    [
        "(\"George R. R. Martin\", \"George R. R. Martin\"),",
        "(\"George R. R. Martin\", \"George R."
    ],
    [
        "(\"J. R. R. Tolkien\", \"J. R. R. Tolkien\"),",
        "(\"J. R. R. Tolkien\", \"J. R."
    ],
    [
        "qs = Author.objects.annotate(same_name=Replace(F(\"name\"), Value(\"R. R. \")))",
        "qs = Author.objects.annotate(same_name=Replace(F(\"name\"), Value(\"R."
    ],
    [
        "(\"George R. R. Martin\", \"George Martin\"),",
        "(\"George R. R."
    ],
    [
        "(\"J. R. R. Tolkien\", \"J. Tolkien\"),",
        "(\"J. R. R. Tolkien\","
    ],
    [
        "from django.db.models.functions import Length, Lower, Right",
        "from django.db.models.functions import Length, Lower,"
    ],
    [
        "authors.order_by(\"name\"), [\"Smith\", \"honda\"], lambda a: a.name_part",
        "authors.order_by(\"name\"), [\"Smith\", \"honda\"],"
    ],
    [
        "authors.order_by(\"name\"), [\"smithj\", \"da\"], lambda a: a.alias",
        "authors.order_by(\"name\"), [\"smithj\", \"da\"], lambda a:"
    ],
    [
        "authors.order_by(\"name\"), [\"ith\", \"nda\"], lambda a: a.name_part",
        "authors.order_by(\"name\"), [\"ith\", \"nda\"], lambda"
    ],
    [
        "from django.db.models import Value as V",
        "from django.db.models import Value as"
    ],
    [
        "from django.db.models.functions import Lower, StrIndex, Substr, Upper",
        "from django.db.models.functions import Lower, StrIndex,"
    ],
    [
        "authors.order_by(\"name\"), [\" Sm\", \"da\"], lambda a: a.name_part",
        "authors.order_by(\"name\"), [\" Sm\", \"da\"],"
    ],
    [
        "authors.order_by(\"name\"), [\"ohn Smith\", \"honda\"], lambda a: a.name_part",
        "authors.order_by(\"name\"), [\"ohn Smith\", \"honda\"],"
    ],
    [
        "authors.order_by(\"name\"), [\"smithj\", \"rhond\"], lambda a: a.alias",
        "authors.order_by(\"name\"), [\"smithj\", \"rhond\"],"
    ],
    [
        "authors.order_by(\"name\"), [\"HN SM\", \"HONDA\"], lambda a: a.name_part",
        "authors.order_by(\"name\"), [\"HN SM\", \"HONDA\"], lambda a:"
    ],
    [
        "Many-to-many relationships between the same two tables",
        "Many-to-many relationships between the"
    ],
    [
        "In this example, a ``Person`` can have many friends, who are also ``Person``",
        "In this example, a ``Person`` can have many friends, who"
    ],
    [
        "objects. Friendship is a symmetrical relationship - if I am your friend, you",
        "objects. Friendship is a symmetrical relationship - if I am"
    ],
    [
        "are my friend. Here, ``friends`` is an example of a symmetrical",
        "are my friend. Here, ``friends`` is an"
    ],
    [
        "A ``Person`` can also have many idols - but while I may idolize you, you may",
        "A ``Person`` can also have many idols - but while"
    ],
    [
        "not think the same of me. Here, ``idols`` is an example of a non-symmetrical",
        "not think the same of me. Here, ``idols`` is an example of"
    ],
    [
        "``ManyToManyField``. Only recursive ``ManyToManyField`` fields may be",
        "``ManyToManyField``. Only recursive ``ManyToManyField`` fields"
    ],
    [
        "non-symmetrical, and they are symmetrical by default.",
        "non-symmetrical, and they are"
    ],
    [
        "This test validates that the many-to-many table is created using a mangled name",
        "This test validates that the many-to-many table is created using"
    ],
    [
        "if there is a name clash, and tests that symmetry is preserved where",
        "if there is a name clash, and"
    ],
    [
        "cls.a, cls.b, cls.c, cls.d = [",
        "cls.a, cls.b, cls.c, cls.d ="
    ],
    [
        "for name in [\"Anne\", \"Bill\", \"Chuck\", \"David\"]",
        "for name in [\"Anne\", \"Bill\", \"Chuck\","
    ],
    [
        "cls.a, cls.b, cls.c, cls.d = [",
        "cls.a, cls.b, cls.c, cls.d"
    ],
    [
        "for name in [\"Anne\", \"Bill\", \"Chuck\", \"David\"]",
        "for name in [\"Anne\", \"Bill\","
    ],
    [
        "raise models.ProtectedError(\"Not allowed to delete.\", [instance])",
        "raise models.ProtectedError(\"Not allowed"
    ],
    [
        "from django.db.models import ProtectedError, Q, Sum",
        "from django.db.models import"
    ],
    [
        "GenericRelations on inherited classes use the correct content type.",
        "GenericRelations on inherited classes use the correct"
    ],
    [
        "The correct column name is used for the primary key on the",
        "The correct column name is used"
    ],
    [
        "SQL query parameters for generic relations are properly",
        "SQL query parameters for generic relations"
    ],
    [
        "In this bug the first query (below) works while the second, with the",
        "In this bug the first query (below) works"
    ],
    [
        "query parameters the same but in reverse order, does not.",
        "query parameters the same but"
    ],
    [
        "The issue is that the generic relation conditions do not get properly",
        "The issue is that the generic relation conditions do not get"
    ],
    [
        "Ordering over a generic relation does not include extraneous",
        "Ordering over a generic relation does not include"
    ],
    [
        "duplicate results, nor excludes rows not participating in the relation.",
        "duplicate results, nor excludes rows not participating in the"
    ],
    [
        "return len([p for p in places if p.id == place.id])",
        "return len([p for p in places if p.id"
    ],
    [
        "Saving a model with a GenericForeignKey to a model instance whose",
        "Saving a model with a GenericForeignKey to a model instance"
    ],
    [
        "Saving a model with a GenericForeignKey to a model instance whose",
        "Saving a model with a GenericForeignKey to a model instance"
    ],
    [
        "__bool__ method returns False (Guild.__bool__() here) shouldn't fail",
        "__bool__ method returns False (Guild.__bool__() here)"
    ],
    [
        "Filtering with a reverse generic relation, where the GenericRelation",
        "Filtering with a reverse generic relation,"
    ],
    [
        "The reverse generic relation accessor (targets) is created if the",
        "The reverse generic relation accessor (targets) is created"
    ],
    [
        "GenericRelation comes from an abstract base model (HasLinks).",
        "GenericRelation comes from an abstract base model"
    ],
    [
        "\"\"\"Primary key is not checked if the content type doesn't match.\"\"\"",
        "\"\"\"Primary key is not checked if the content type doesn't"
    ],
    [
        "\"\"\"Dummy cache backend ignores cache set calls.\"\"\"",
        "\"\"\"Dummy cache backend ignores cache"
    ],
    [
        "\"\"\"Add doesn't do anything in dummy cache backend.\"\"\"",
        "\"\"\"Add doesn't do anything"
    ],
    [
        "\"\"\"Nonexistent keys aren't found in the dummy cache backend.\"\"\"",
        "\"\"\"Nonexistent keys aren't found in the"
    ],
    [
        "\"\"\"aget_many() returns nothing for the dummy cache backend.\"\"\"",
        "\"\"\"aget_many() returns nothing for the dummy"
    ],
    [
        "await cache.aset_many({\"a\": \"a\", \"b\": \"b\", \"c\": \"c\", \"d\": \"d\"})",
        "await cache.aset_many({\"a\": \"a\", \"b\": \"b\", \"c\": \"c\", \"d\":"
    ],
    [
        "Cache deletion is transparently ignored on the dummy cache backend.",
        "Cache deletion is transparently ignored on"
    ],
    [
        "\"\"\"ahas_key() doesn't ever return True for the dummy cache backend.\"\"\"",
        "\"\"\"ahas_key() doesn't ever return True for the dummy"
    ],
    [
        "\"\"\"Dummy cache values can't be incremented.\"\"\"",
        "\"\"\"Dummy cache values"
    ],
    [
        "\"\"\"Dummy cache values can't be decremented.\"\"\"",
        "\"\"\"Dummy cache values can't be"
    ],
    [
        "\"\"\"All data types are ignored equally by the dummy cache.\"\"\"",
        "\"\"\"All data types are ignored equally by the"
    ],
    [
        "\"\"\"Expiration has no effect on the dummy cache.\"\"\"",
        "\"\"\"Expiration has no effect on the"
    ],
    [
        "\"\"\"Unicode values are ignored by the dummy cache.\"\"\"",
        "\"\"\"Unicode values are ignored by the dummy"
    ],
    [
        "\"\"\"aset_many() does nothing for the dummy cache backend.\"\"\"",
        "\"\"\"aset_many() does nothing for the"
    ],
    [
        "\"\"\"adelete_many() does nothing for the dummy cache backend.\"\"\"",
        "\"\"\"adelete_many() does nothing for the dummy"
    ],
    [
        "\"\"\"aclear() does nothing for the dummy cache backend.\"\"\"",
        "\"\"\"aclear() does nothing for"
    ],
    [
        "\"\"\"aclose() does nothing for the dummy cache backend.\"\"\"",
        "\"\"\"aclose() does nothing for the dummy cache"
    ],
    [
        "\"\"\"Dummy cache versions can't be incremented.\"\"\"",
        "\"\"\"Dummy cache versions can't"
    ],
    [
        "\"\"\"Dummy cache versions can't be decremented.\"\"\"",
        "\"\"\"Dummy cache versions can't be"
    ],
    [
        "raise Exception(\"Faked exception saving to cache\")",
        "raise Exception(\"Faked exception"
    ],
    [
        "raise Exception(\"Faked exception saving to cache\")",
        "raise Exception(\"Faked exception saving to"
    ],
    [
        "from django.db import close_old_connections, connection, connections",
        "from django.db import"
    ],
    [
        "\"Cache key contains characters that will cause errors if used with memcached: %r\"",
        "\"Cache key contains characters that will cause errors if"
    ],
    [
        "\"Dummy cache backend ignores cache set calls\"",
        "\"Dummy cache backend ignores cache"
    ],
    [
        "\"Add doesn't do anything in dummy cache backend\"",
        "\"Add doesn't do anything in dummy cache"
    ],
    [
        "\"Nonexistent keys aren't found in the dummy cache backend\"",
        "\"Nonexistent keys aren't found in the dummy"
    ],
    [
        "\"get_many returns nothing for the dummy cache backend\"",
        "\"get_many returns nothing for"
    ],
    [
        "cache.set_many({\"a\": \"a\", \"b\": \"b\", \"c\": \"c\", \"d\": \"d\"})",
        "cache.set_many({\"a\": \"a\", \"b\": \"b\","
    ],
    [
        "\"Cache deletion is transparently ignored on the dummy cache backend\"",
        "\"Cache deletion is transparently ignored on"
    ],
    [
        "\"The has_key method doesn't ever return True for the dummy cache backend\"",
        "\"The has_key method doesn't ever return True for the dummy cache"
    ],
    [
        "\"The in operator doesn't ever return True for the dummy cache backend\"",
        "\"The in operator doesn't ever return True for the dummy"
    ],
    [
        "\"Dummy cache values can't be incremented\"",
        "\"Dummy cache values can't"
    ],
    [
        "\"Dummy cache values can't be decremented\"",
        "\"Dummy cache values can't be"
    ],
    [
        "\"All data types are ignored equally by the dummy cache\"",
        "\"All data types are ignored equally by"
    ],
    [
        "\"Expiration has no effect on the dummy cache\"",
        "\"Expiration has no effect on the"
    ],
    [
        "\"Unicode values are ignored by the dummy cache\"",
        "\"Unicode values are ignored by the dummy"
    ],
    [
        "\"set_many does nothing for the dummy cache backend\"",
        "\"set_many does nothing for the dummy cache"
    ],
    [
        "\"delete_many does nothing for the dummy cache backend\"",
        "\"delete_many does nothing for the"
    ],
    [
        "\"clear does nothing for the dummy cache backend\"",
        "\"clear does nothing for"
    ],
    [
        "\"Dummy cache versions can't be incremented\"",
        "\"Dummy cache versions can't"
    ],
    [
        "\"Dummy cache versions can't be decremented\"",
        "\"Dummy cache versions can't"
    ],
    [
        "return \"CUSTOM-\" + \"-\".join([key_prefix, str(version), key])",
        "return \"CUSTOM-\" + \"-\".join([key_prefix,"
    ],
    [
        "setting = {k: base.copy() for k in _caches_setting_base if k not in exclude}",
        "setting = {k: base.copy() for k in _caches_setting_base if k not"
    ],
    [
        "\"\"\"If None is cached, get() returns it instead of the default.\"\"\"",
        "\"\"\"If None is cached, get() returns it instead of the"
    ],
    [
        "\"\"\"Nonexistent cache keys return as None/default.\"\"\"",
        "\"\"\"Nonexistent cache keys return as"
    ],
    [
        "cache.set_many({\"a\": \"a\", \"b\": \"b\", \"c\": \"c\", \"d\": \"d\"})",
        "cache.set_many({\"a\": \"a\", \"b\": \"b\", \"c\": \"c\","
    ],
    [
        "cache.get_many([\"a\", \"c\", \"d\"]), {\"a\": \"a\", \"c\": \"c\", \"d\": \"d\"}",
        "cache.get_many([\"a\", \"c\", \"d\"]), {\"a\": \"a\", \"c\": \"c\", \"d\":"
    ],
    [
        "self.assertEqual(cache.get_many([\"a\", \"b\", \"e\"]), {\"a\": \"a\", \"b\": \"b\"})",
        "self.assertEqual(cache.get_many([\"a\", \"b\", \"e\"]), {\"a\": \"a\","
    ],
    [
        "self.assertEqual(cache.get_many(iter([\"a\", \"b\", \"e\"])), {\"a\": \"a\", \"b\": \"b\"})",
        "self.assertEqual(cache.get_many(iter([\"a\", \"b\", \"e\"])), {\"a\":"
    ],
    [
        "\"\"\"set_many() returns an empty list when all keys are inserted.\"\"\"",
        "\"\"\"set_many() returns an empty list"
    ],
    [
        "treated as an absolute expiration timestamp instead of a relative",
        "treated as an absolute expiration timestamp instead of a"
    ],
    [
        "Passing in None into timeout results in a value that is cached forever",
        "Passing in None into timeout results in a"
    ],
    [
        "Passing in zero into timeout results in a value that is not cached",
        "Passing in zero into timeout results in a value that is"
    ],
    [
        "All the builtin backends should warn (except memcached that should",
        "All the builtin backends should"
    ],
    [
        "error) on keys that would be refused by memcached. This encourages",
        "error) on keys that would be"
    ],
    [
        "portable caching code without making it too difficult to use production",
        "portable caching code without making it too"
    ],
    [
        "key = \"key with spaces and 清\"",
        "key = \"key with spaces and"
    ],
    [
        "\"Cache key will cause errors if used with memcached: \"",
        "\"Cache key will cause errors if used with"
    ],
    [
        "\"Cache key will cause errors if used with memcached: \"",
        "\"Cache key will cause errors if"
    ],
    [
        "num_count_queries = sum(\"COUNT\" in query[\"sql\"] for query in captured_queries)",
        "num_count_queries = sum(\"COUNT\" in query[\"sql\"] for query in"
    ],
    [
        "The rowcount attribute should not be checked on a closed cursor.",
        "The rowcount attribute should not be checked on"
    ],
    [
        "\"Cache table 'test cache table' already exists.\\n\" * len(settings.CACHES),",
        "\"Cache table 'test cache table'"
    ],
    [
        "Delete and recreate cache table with legacy behavior (explicitly",
        "Delete and recreate cache table"
    ],
    [
        "self.assertEqual(out.getvalue(), \"Cache table 'test cache table' created.\\n\")",
        "self.assertEqual(out.getvalue(), \"Cache table 'test"
    ],
    [
        "\"\"\"A router that puts the cache table on the 'other' database.\"\"\"",
        "\"\"\"A router that puts the cache table on the"
    ],
    [
        "self.assertFalse(bad_obj.locked, \"Cache was locked during pickling\")",
        "self.assertFalse(bad_obj.locked, \"Cache was"
    ],
    [
        "self.assertFalse(bad_obj.locked, \"Cache was locked during pickling\")",
        "self.assertFalse(bad_obj.locked, \"Cache was locked"
    ],
    [
        "\"\"\"incr/decr does not modify expiry time (matches memcached behavior)\"\"\"",
        "\"\"\"incr/decr does not modify expiry time (matches"
    ],
    [
        "params = {\"BACKEND\": self.base_params[\"BACKEND\"], \"LOCATION\": location}",
        "params = {\"BACKEND\":"
    ],
    [
        "While other backends merely warn, memcached should raise for an invalid",
        "While other backends merely warn, memcached should raise for an"
    ],
    [
        "\"Cache key will cause errors if used with memcached: \"",
        "\"Cache key will cause errors if used"
    ],
    [
        "self.assertTrue(value is None or value == large_value)",
        "self.assertTrue(value is None or value"
    ],
    [
        "settings = {\"default\": {\"BACKEND\": backend, \"LOCATION\": location}}",
        "settings = {\"default\": {\"BACKEND\":"
    ],
    [
        "Specific test cases for the file-based cache.",
        "Specific test cases for the"
    ],
    [
        "os.path.exists(fname), \"Expected cache.clear to ignore non cache files\"",
        "os.path.exists(fname), \"Expected cache.clear to"
    ],
    [
        "os.path.exists(self.dirname), \"Expected cache.clear to keep the cache dir\"",
        "os.path.exists(self.dirname), \"Expected cache.clear to"
    ],
    [
        "\"Windows only partially supports umasks and chmod.\",",
        "\"Windows only partially supports"
    ],
    [
        "dir_path = Path(self.dirname) / \"nested\" / \"filebasedcache\"",
        "dir_path = Path(self.dirname) / \"nested\" /"
    ],
    [
        "\"\"\"Override to manually advance time since file access can be slow.\"\"\"",
        "\"\"\"Override to manually advance time since file access can"
    ],
    [
        "Tests for the ability to mixin a custom ``validate_key`` method to",
        "Tests for the ability to mixin"
    ],
    [
        "a custom cache backend that otherwise inherits from a builtin",
        "a custom cache backend that otherwise inherits from a"
    ],
    [
        "Settings having Cache arguments with a TIMEOUT=None create Caches that will",
        "Settings having Cache arguments with a"
    ],
    [
        "\"\"\"Caches that have the TIMEOUT parameter undefined in the default",
        "\"\"\"Caches that have the TIMEOUT"
    ],
    [
        "\"\"\"Memory caches that have the TIMEOUT parameter set to `None` in the",
        "\"\"\"Memory caches that have the TIMEOUT parameter set to `None` in"
    ],
    [
        "default settings with have `None` as the default timeout.",
        "default settings with have `None` as the"
    ],
    [
        "\"\"\"Memory caches that have the TIMEOUT parameter unset will set cache",
        "\"\"\"Memory caches that have the TIMEOUT"
    ],
    [
        "\"\"\"Memory caches that have the TIMEOUT parameter set to `None` will set",
        "\"\"\"Memory caches that have the TIMEOUT parameter"
    ],
    [
        "a non expiring key by default.",
        "a non expiring key"
    ],
    [
        "request._cache_update_cache = update_cache if update_cache else True",
        "request._cache_update_cache = update_cache if"
    ],
    [
        "for initial_vary, newheaders, resulting_vary in headers:",
        "for initial_vary, newheaders, resulting_vary in"
    ],
    [
        "get_cache_key keys differ by fully-qualified URL instead of path",
        "get_cache_key keys differ by fully-qualified URL instead of"
    ],
    [
        "for initial_cc, newheaders, expected_cc in tests:",
        "for initial_cc, newheaders,"
    ],
    [
        "\"Cache keys should include the language name when translation is active\",",
        "\"Cache keys should include the language name when"
    ],
    [
        "\"Cache keys should include the language name when translation is active\",",
        "\"Cache keys should include the language name when translation is"
    ],
    [
        "\"ko, en\", \"cookie, accept-encoding, accept-language\", key",
        "\"ko, en\", \"cookie, accept-encoding,"
    ],
    [
        "\"ko-KR, en-US\", \"accept-encoding, accept-language, cookie\", key",
        "\"ko-KR, en-US\", \"accept-encoding, accept-language, cookie\","
    ],
    [
        "\"Cache keys should include the time zone name when time zones are active\",",
        "\"Cache keys should include the time zone name when time zones are"
    ],
    [
        "request = self.factory.get(self.path, {\"foo\": \"bar\", \"other\": \"true\"})",
        "request = self.factory.get(self.path, {\"foo\":"
    ],
    [
        "content = \"Check for cache with QUERY_STRING\"",
        "content = \"Check for cache with"
    ],
    [
        "request = self.factory.get(self.path, {\"foo\": \"bar\", \"somethingelse\": \"true\"})",
        "request = self.factory.get(self.path, {\"foo\": \"bar\", \"somethingelse\":"
    ],
    [
        "return StreamingHttpResponse([\"Check for cache with streaming content.\"])",
        "return StreamingHttpResponse([\"Check for cache with"
    ],
    [
        "return HttpResponse(\"Hello World %s\" % value)",
        "return HttpResponse(\"Hello World %s\""
    ],
    [
        "The constructor is correctly distinguishing between usage of",
        "The constructor is correctly"
    ],
    [
        "CacheMiddleware as Middleware vs. usage of CacheMiddleware as view",
        "CacheMiddleware as Middleware vs. usage of CacheMiddleware as"
    ],
    [
        "\"\"\"Responses with 'Cache-Control: private' are not cached.\"\"\"",
        "\"\"\"Responses with 'Cache-Control: private' are"
    ],
    [
        "Django must prevent caching of responses that set a user-specific (and",
        "Django must prevent caching of responses that set a user-specific"
    ],
    [
        "maybe security sensitive) cookie in response to a cookie-less request.",
        "maybe security sensitive) cookie in response to a cookie-less"
    ],
    [
        "\"\"\"The cache instance is different for each thread.\"\"\"",
        "\"\"\"The cache instance is different"
    ],
    [
        "Most are probably redundant since they manipulate the same object",
        "Most are probably redundant since they manipulate"
    ],
    [
        "anyway but the ETag header is 'special' because it relies on the",
        "anyway but the ETag header is 'special'"
    ],
    [
        "content being complete (which is not necessarily always the case",
        "content being complete (which is"
    ],
    [
        "for initial_vary, newheaders, resulting_vary in headers:",
        "for initial_vary, newheaders, resulting_vary"
    ],
    [
        "template = engines[\"django\"].from_string(\"This is a test\")",
        "template = engines[\"django\"].from_string(\"This"
    ],
    [
        "template = engines[\"django\"].from_string(\"This is a test\")",
        "template = engines[\"django\"].from_string(\"This is"
    ],
    [
        "template = engines[\"django\"].from_string(\"This is a test\")",
        "template = engines[\"django\"].from_string(\"This is"
    ],
    [
        "Attempting to retrieve the same alias should yield the same instance.",
        "Attempting to retrieve the same alias should yield"
    ],
    [
        "Requesting the same alias from separate threads should yield separate",
        "Requesting the same alias from separate threads should yield"
    ],
    [
        "msg = \"The connection 'nonexistent' doesn't exist.\"",
        "msg = \"The connection 'nonexistent' doesn't"
    ],
    [
        "\"Could not find backend 'django.nonexistent.NonexistentBackend': \"",
        "\"Could not find"
    ],
    [
        "count_attr = \"_%s_%s_count\" % (self.field.attname, get_or_set)",
        "count_attr = \"_%s_%s_count\" % (self.field.attname,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "from .models import Article, Author, MySQLUnixTimestamp",
        "from .models import"
    ],
    [
        "lhs_sql, lhs_params = self.process_lhs(compiler, connection, self.lhs.lhs)",
        "lhs_sql, lhs_params = self.process_lhs(compiler,"
    ],
    [
        "params = lhs_params + rhs_params + lhs_params + rhs_params",
        "params = lhs_params + rhs_params + lhs_params +"
    ],
    [
        "The purpose of this lookup is to efficiently compare the year of the field.",
        "The purpose of this lookup is to efficiently compare"
    ],
    [
        "lhs_sql, params = self.process_lhs(compiler, connection, real_lhs)",
        "lhs_sql, params = self.process_lhs(compiler, connection,"
    ],
    [
        "This lookup is used to test lookup registration.",
        "This lookup is used"
    ],
    [
        "InMonth matches if the column's month is the same as value's month.",
        "InMonth matches if the column's month"
    ],
    [
        "params = lhs_params + rhs_params + lhs_params + rhs_params",
        "params = lhs_params + rhs_params + lhs_params +"
    ],
    [
        "\"%s >= date_trunc('month', %s) and \"",
        "\"%s >= date_trunc('month',"
    ],
    [
        "__exact=None is transformed to __isnull=True if a custom lookup class",
        "__exact=None is transformed to __isnull=True if a custom"
    ],
    [
        "with lookup_name != 'exact' is registered as the `exact` lookup.",
        "with lookup_name != 'exact' is registered as the `exact`"
    ],
    [
        "connection.vendor == \"postgresql\", \"PostgreSQL specific SQL used\"",
        "connection.vendor == \"postgresql\", \"PostgreSQL"
    ],
    [
        "msg = \"Bilateral transformations on nested querysets are not implemented.\"",
        "msg = \"Bilateral transformations on nested querysets"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"mysql\", \"MySQL specific SQL used\")",
        "@unittest.skipUnless(connection.vendor == \"mysql\", \"MySQL specific"
    ],
    [
        "connection.vendor == \"postgresql\", \"PostgreSQL specific SQL used\"",
        "connection.vendor == \"postgresql\", \"PostgreSQL"
    ],
    [
        "connection.vendor == \"postgresql\", \"PostgreSQL specific SQL used\"",
        "connection.vendor == \"postgresql\", \"PostgreSQL specific SQL"
    ],
    [
        "params = lhs_params + rhs_params + lhs_params + rhs_params",
        "params = lhs_params + rhs_params + lhs_params +"
    ],
    [
        "params = lhs_params + rhs_params + lhs_params + rhs_params",
        "params = lhs_params + rhs_params +"
    ],
    [
        "\"Unsupported lookup 'junk' for IntegerField or join on the field not \"",
        "\"Unsupported lookup 'junk' for IntegerField or"
    ],
    [
        "\"Unsupported lookup 'junk__more_junk' for IntegerField or join\"",
        "\"Unsupported lookup 'junk__more_junk' for IntegerField"
    ],
    [
        "\" on the field not permitted.\"",
        "\" on the"
    ],
    [
        "These test that things behave sensibly for the rare corner-case of a model with",
        "These test that things behave sensibly for"
    ],
    [
        "ShadowParent declares a scalar, rather than a field. When this is",
        "ShadowParent declares a scalar, rather than a field."
    ],
    [
        "overridden, the field value, rather than the scalar value must still be",
        "overridden, the field value, rather than the scalar value"
    ],
    [
        "used when the field is deferred.",
        "used when the"
    ],
    [
        "Instances with deferred fields look the same as normal instances when",
        "Instances with deferred fields look the same"
    ],
    [
        "we examine attribute values. Therefore, this method returns the number",
        "we examine attribute values. Therefore, this"
    ],
    [
        "of deferred fields on returned instances.",
        "of deferred fields on returned"
    ],
    [
        "msg = \"Cannot pass None as an argument to only().\"",
        "msg = \"Cannot pass None as"
    ],
    [
        "Ensure select_related together with only on a proxy model behaves",
        "Ensure select_related together with only on"
    ],
    [
        "When an inherited model is fetched from the DB, its PK is also fetched.",
        "When an inherited model is fetched from the DB, its PK is"
    ],
    [
        "When getting the PK of the parent model it is useful to use the already",
        "When getting the PK of the parent model it is useful to use"
    ],
    [
        "fetched parent model PK if it happens to be available.",
        "fetched parent model PK if it happens to be"
    ],
    [
        "msg = \"Primary has no field named 'missing'\"",
        "msg = \"Primary has no field named"
    ],
    [
        "msg = \"Secondary has no field named 'missing'\"",
        "msg = \"Secondary has no field"
    ],
    [
        "msg = \"Primary has no field named 'missing'\"",
        "msg = \"Primary has"
    ],
    [
        "msg = \"Secondary has no field named 'missing'\"",
        "msg = \"Secondary has"
    ],
    [
        "\"Field Primary.related cannot be both deferred and traversed using \"",
        "\"Field Primary.related cannot be both deferred and"
    ],
    [
        "\"Field Primary.related cannot be both deferred and traversed using \"",
        "\"Field Primary.related cannot be both deferred and"
    ],
    [
        "Tests for the update() queryset method that allows in-place, multi-object",
        "Tests for the update() queryset method that allows"
    ],
    [
        "from django.db import IntegrityError, connection, transaction",
        "from django.db import IntegrityError, connection,"
    ],
    [
        "from django.db.models import Case, CharField, Count, F, IntegerField, Max, When",
        "from django.db.models import Case, CharField, Count,"
    ],
    [
        "from django.db.models.functions import Abs, Concat, Lower",
        "from django.db.models.functions import Abs, Concat,"
    ],
    [
        "Update changes the right number of rows for a nonempty queryset",
        "Update changes the right number of rows for a nonempty"
    ],
    [
        "Update changes the right number of rows for an empty queryset",
        "Update changes the right number of"
    ],
    [
        "Update changes the right number of rows for an empty queryset",
        "Update changes the right number of rows for an"
    ],
    [
        "when the update affects only a base table",
        "when the update affects only"
    ],
    [
        "Update changes the right number of rows for an empty queryset",
        "Update changes the right number of rows for"
    ],
    [
        "when the update affects only a base table",
        "when the update affects only a"
    ],
    [
        "Update works using <field>_id for foreign keys",
        "Update works using <field>_id"
    ],
    [
        "Objects are updated by first filtering the candidates into a queryset",
        "Objects are updated by first filtering the candidates into"
    ],
    [
        "and then calling the update() method. It executes immediately and",
        "and then calling the update()"
    ],
    [
        "We can update multiple objects at once.",
        "We can update multiple objects at"
    ],
    [
        "Foreign key fields can also be updated, although you can only update",
        "Foreign key fields can also be updated,"
    ],
    [
        "the object referred to, not anything inside the related object.",
        "the object referred to, not"
    ],
    [
        "Multiple fields can be updated at once",
        "Multiple fields can be"
    ],
    [
        "In the rare case you want to update every instance of a model, update()",
        "In the rare case you want to update every instance of a model,"
    ],
    [
        "We do not support update on already sliced query sets.",
        "We do not support update on already sliced"
    ],
    [
        "msg = \"Cannot update a query once a slice has been taken.\"",
        "msg = \"Cannot update a query once a slice has been"
    ],
    [
        "Update of an FK field which specifies a to_field works.",
        "Update of an FK field which specifies a to_field"
    ],
    [
        "\"(only non-relations and foreign keys permitted).\"",
        "\"(only non-relations and"
    ],
    [
        "Update of a queryset that's been annotated.",
        "Update of a queryset"
    ],
    [
        "\"Aggregate functions are not allowed in this query \"",
        "\"Aggregate functions are not allowed in"
    ],
    [
        "Update of a queryset that's been annotated and involves multiple tables.",
        "Update of a queryset that's been"
    ],
    [
        "msg = \"Joined field references are not permitted in this query\"",
        "msg = \"Joined field references are"
    ],
    [
        "msg = \"Joined field references are not permitted in this query\"",
        "msg = \"Joined field references are not permitted"
    ],
    [
        "\"Cannot update when ordering by an aggregate: \"",
        "\"Cannot update when ordering by an"
    ],
    [
        "msg = \"Cannot negate non-conditional expressions.\"",
        "msg = \"Cannot negate"
    ],
    [
        "\"UPDATE...ORDER BY syntax is supported on MySQL/MariaDB\",",
        "\"UPDATE...ORDER BY syntax is supported"
    ],
    [
        "\"\"\"Update field with a unique constraint using an ordered queryset.\"\"\"",
        "\"\"\"Update field with a unique"
    ],
    [
        "from django.db import IntegrityError, connection, models",
        "from django.db import IntegrityError, connection,"
    ],
    [
        "from django.db.models.functions import Abs, Lower, Sqrt, Upper",
        "from django.db.models.functions import Abs, Lower, Sqrt,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import SimpleTestCase, TestCase, skipIfDBFeature,"
    ],
    [
        "msg = \"This method must be implemented by a subclass.\"",
        "msg = \"This method must be implemented by"
    ],
    [
        "msg = \"This method must be implemented by a subclass.\"",
        "msg = \"This method must be"
    ],
    [
        "msg = \"This method must be implemented by a subclass.\"",
        "msg = \"This method must be implemented"
    ],
    [
        "msg = \"This method must be implemented by a subclass.\"",
        "msg = \"This method must be implemented by"
    ],
    [
        "msg = \"CheckConstraint.condition must be a Q instance or boolean expression.\"",
        "msg = \"CheckConstraint.condition must be a"
    ],
    [
        "msg = f\"Constraint “{constraint.name}” is violated.\"",
        "msg = f\"Constraint “{constraint.name}” is"
    ],
    [
        "\"price < %s OR price > %s\",",
        "\"price < %s OR price"
    ],
    [
        "msg = f\"Constraint “{is_null_constraint.name}” is violated.\"",
        "msg = f\"Constraint “{is_null_constraint.name}”"
    ],
    [
        "msg = f\"Constraint “{is_not_null_constraint.name}” is violated.\"",
        "msg = f\"Constraint “{is_not_null_constraint.name}”"
    ],
    [
        "msg = f\"Constraint “{constraint_with_pk.name}” is violated.\"",
        "msg = f\"Constraint"
    ],
    [
        "msg = f\"Constraint “{json_exact_constraint.name}” is violated.\"",
        "msg = f\"Constraint “{json_exact_constraint.name}” is"
    ],
    [
        "msg = f\"Constraint “{constraint.name}” is violated.\"",
        "msg = f\"Constraint “{constraint.name}”"
    ],
    [
        "kwargs, {\"fields\": tuple(fields), \"name\": name, \"condition\": condition}",
        "kwargs, {\"fields\": tuple(fields), \"name\": name, \"condition\":"
    ],
    [
        "msg = \"Unique constraint product with this Name and Color already exists.\"",
        "msg = \"Unique constraint product with this Name and Color"
    ],
    [
        "Partial unique constraints are not ignored by",
        "Partial unique constraints are not"
    ],
    [
        "msg = \"Constraint “name_without_color_uniq” is violated.\"",
        "msg = \"Constraint “name_without_color_uniq”"
    ],
    [
        "msg = \"Unique constraint product with this Name and Color already exists.\"",
        "msg = \"Unique constraint product with this Name and Color already"
    ],
    [
        "msg = \"Product with this Price already exists.\"",
        "msg = \"Product with this Price already"
    ],
    [
        "msg = \"Constraint “name_without_color_uniq” is violated.\"",
        "msg = \"Constraint “name_without_color_uniq” is"
    ],
    [
        "msg = \"Constraint “name_lower_uniq” is violated.\"",
        "msg = \"Constraint"
    ],
    [
        "msg = \"Constraint “name_lower_uniq_desc” is violated.\"",
        "msg = \"Constraint “name_lower_uniq_desc”"
    ],
    [
        "msg = \"Constraint “name_lower_without_color_uniq” is violated.\"",
        "msg = \"Constraint “name_lower_without_color_uniq”"
    ],
    [
        "msg = \"Constraint “name_uniq” is violated.\"",
        "msg = \"Constraint “name_uniq”"
    ],
    [
        "msg = \"Constraint “uniq_prices_no_unit” is violated.\"",
        "msg = \"Constraint “uniq_prices_no_unit” is"
    ],
    [
        "msg = \"Constraint “uniq_prices_unit” is violated.\"",
        "msg = \"Constraint"
    ],
    [
        "msg = \"Product with this Price already exists.\"",
        "msg = \"Product with this Price already"
    ],
    [
        "msg = f\"Constraint “{constraint.name}” is violated.\"",
        "msg = f\"Constraint"
    ],
    [
        "ValueError, \"UniqueConstraint.condition must be a Q instance.\"",
        "ValueError, \"UniqueConstraint.condition must be a"
    ],
    [
        "cursor.execute(\"SET CONSTRAINTS %s IMMEDIATE\" % constraint_name)",
        "cursor.execute(\"SET CONSTRAINTS %s"
    ],
    [
        "cursor.execute(\"SET CONSTRAINTS %s DEFERRED\" % constraint_name)",
        "cursor.execute(\"SET CONSTRAINTS %s DEFERRED\""
    ],
    [
        "message = \"UniqueConstraint with conditions cannot be deferred.\"",
        "message = \"UniqueConstraint with conditions cannot"
    ],
    [
        "message = \"UniqueConstraint with include fields cannot be deferred.\"",
        "message = \"UniqueConstraint with include fields cannot be"
    ],
    [
        "message = \"UniqueConstraint with opclasses cannot be deferred.\"",
        "message = \"UniqueConstraint with opclasses"
    ],
    [
        "message = \"UniqueConstraint with expressions cannot be deferred.\"",
        "message = \"UniqueConstraint with expressions cannot be"
    ],
    [
        "message = \"UniqueConstraint.deferrable must be a Deferrable instance.\"",
        "message = \"UniqueConstraint.deferrable must be"
    ],
    [
        "msg = \"UniqueConstraint.include must be a list or tuple.\"",
        "msg = \"UniqueConstraint.include must be a list"
    ],
    [
        "msg = \"UniqueConstraint.opclasses must be a list or tuple.\"",
        "msg = \"UniqueConstraint.opclasses must be a"
    ],
    [
        "msg = \"UniqueConstraint.nulls_distinct must be a bool.\"",
        "msg = \"UniqueConstraint.nulls_distinct must be"
    ],
    [
        "\"UniqueConstraint.fields and UniqueConstraint.opclasses must have \"",
        "\"UniqueConstraint.fields and UniqueConstraint.opclasses"
    ],
    [
        "\"At least one field or expression is required to define a unique \"",
        "\"At least one field or expression is required to"
    ],
    [
        "msg = \"UniqueConstraint.fields and expressions are mutually exclusive.\"",
        "msg = \"UniqueConstraint.fields and"
    ],
    [
        "\"UniqueConstraint.opclasses cannot be used with expressions. Use \"",
        "\"UniqueConstraint.opclasses cannot be used with expressions."
    ],
    [
        "msg = \"A unique constraint must be named.\"",
        "msg = \"A unique constraint"
    ],
    [
        "\"Model with database default with this Field with db default already \"",
        "\"Model with database default with this Field with db default already"
    ],
    [
        "msg = \"Constraint “unique_field_with_db_default_expression” is violated.\"",
        "msg = \"Constraint “unique_field_with_db_default_expression”"
    ],
    [
        "from django.db.models import ProtectedError, Q, RestrictedError",
        "from django.db.models import"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import"
    ],
    [
        "msg = \"on_delete must be callable.\"",
        "msg = \"on_delete must"
    ],
    [
        "\"Cannot delete some instances of model 'R' because they are \"",
        "\"Cannot delete some instances of model 'R'"
    ],
    [
        "\"referenced through protected foreign keys: 'A.protect'.\"",
        "\"referenced through protected"
    ],
    [
        "\"Cannot delete some instances of model 'R' because they are \"",
        "\"Cannot delete some instances of model 'R' because they are"
    ],
    [
        "\"referenced through protected foreign keys: 'A.protect', \"",
        "\"referenced through protected foreign keys:"
    ],
    [
        "\"Cannot delete some instances of model 'P' because they are \"",
        "\"Cannot delete some instances of model 'P' because they"
    ],
    [
        "\"referenced through protected foreign keys: 'R.p'.\"",
        "\"referenced through protected foreign"
    ],
    [
        "A models.DO_NOTHING relation doesn't trigger a query.",
        "A models.DO_NOTHING relation doesn't"
    ],
    [
        "\"Cannot delete some instances of model 'R' because they are \"",
        "\"Cannot delete some instances of model 'R' because they are"
    ],
    [
        "\"referenced through restricted foreign keys: 'A.restrict'.\"",
        "\"referenced through restricted foreign keys:"
    ],
    [
        "\"Cannot delete some instances of model 'R' because they are \"",
        "\"Cannot delete some instances of model 'R' because"
    ],
    [
        "\"referenced through restricted foreign keys: 'A.restrict', \"",
        "\"referenced through restricted foreign"
    ],
    [
        "\"Cannot delete some instances of model 'P' because they are \"",
        "\"Cannot delete some instances of model 'P'"
    ],
    [
        "\"referenced through restricted foreign keys: 'A.restrict'.\"",
        "\"referenced through restricted"
    ],
    [
        "\"are referenced through restricted foreign keys: \"",
        "\"are referenced through restricted foreign keys:"
    ],
    [
        "msg = \"Cannot use 'limit' or 'offset' with delete().\"",
        "msg = \"Cannot use 'limit' or 'offset'"
    ],
    [
        "msg = \"M object can't be deleted because its id attribute is set to None.\"",
        "msg = \"M object can't be deleted because"
    ],
    [
        "queries = fetches_to_mem + TEST_SIZE // GET_ITERATOR_CHUNK_SIZE",
        "queries = fetches_to_mem + TEST_SIZE"
    ],
    [
        "QuerySet.delete() should return the number of deleted rows and a",
        "QuerySet.delete() should return the number of deleted"
    ],
    [
        "dictionary with the number of deletions for each object type.",
        "dictionary with the number of deletions for each object"
    ],
    [
        "Model.delete() should return the number of deleted rows and a",
        "Model.delete() should return the number of"
    ],
    [
        "dictionary with the number of deletions for each object type.",
        "dictionary with the number of deletions"
    ],
    [
        "classes should not issue multiple queries during cascade",
        "classes should not issue multiple queries during"
    ],
    [
        "Only referenced fields are selected during cascade deletion SELECT",
        "Only referenced fields are selected during cascade"
    ],
    [
        "Fast deleting when DatabaseFeatures.update_can_self_select = False",
        "Fast deleting when"
    ],
    [
        "\"The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.\"",
        "\"The number of GET/POST"
    ],
    [
        "\"The number of files exceeded settings.DATA_UPLOAD_MAX_NUMBER_FILES.\"",
        "\"The number of"
    ],
    [
        "TOO_MUCH_DATA_MSG = \"Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.\"",
        "TOO_MUCH_DATA_MSG = \"Request"
    ],
    [
        "\"\"\"Absence of Accept header defaults to '*/*'.\"\"\"",
        "\"\"\"Absence of Accept header defaults"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import RequestFactory, SimpleTestCase,"
    ],
    [
        "from django.test.client import BOUNDARY, MULTIPART_CONTENT, FakePayload",
        "from django.test.client import"
    ],
    [
        "self, input_data, META, content_length, boundary, encoding=None",
        "self, input_data, META, content_length,"
    ],
    [
        "self, input_data, META, content_length, boundary, encoding=None",
        "self, input_data, META, content_length, boundary,"
    ],
    [
        "The request's path is correctly assembled, regardless of whether or",
        "The request's path is correctly"
    ],
    [
        "WSGI squashes multiple successive slashes in PATH_INFO, WSGIRequest",
        "WSGI squashes multiple successive slashes in"
    ],
    [
        "should take that into account when populating request.path and",
        "should take that into account when populating request.path"
    ],
    [
        "The FORCE_SCRIPT_NAME setting takes precedence over the request's",
        "The FORCE_SCRIPT_NAME setting takes precedence over"
    ],
    [
        "The request's path is correctly assembled, regardless of whether or not",
        "The request's path is correctly assembled,"
    ],
    [
        "request = WSGIRequest({\"REQUEST_METHOD\": \"get\", \"wsgi.input\": BytesIO(b\"\")})",
        "request = WSGIRequest({\"REQUEST_METHOD\":"
    ],
    [
        "request = WSGIRequest({\"REQUEST_METHOD\": \"get\", \"wsgi.input\": BytesIO(b\"\")})",
        "request = WSGIRequest({\"REQUEST_METHOD\": \"get\","
    ],
    [
        "Reading from request is allowed after accessing request contents as",
        "Reading from request is allowed after accessing request"
    ],
    [
        "Construction of POST or body is not allowed after reading",
        "Construction of POST or body"
    ],
    [
        "\"HTTP requests with the 'application/x-www-form-urlencoded' content type \"",
        "\"HTTP requests with the"
    ],
    [
        "Reading body after parsing multipart/form-data is not allowed",
        "Reading body after parsing multipart/form-data is"
    ],
    [
        "Reading body after parsing multipart that isn't form-data is allowed",
        "Reading body after parsing multipart that"
    ],
    [
        "for method in [\"GET\", \"PUT\", \"DELETE\"]:",
        "for method in"
    ],
    [
        "POST should be populated even if body is read first",
        "POST should be populated even if"
    ],
    [
        "POST should be populated even if body is read first, and then",
        "POST should be populated even if body"
    ],
    [
        "POST should be populated even if body is read first, and then",
        "POST should be populated even if body is read first,"
    ],
    [
        "the stream is read second. Using multipart/form-data instead of urlencoded.",
        "the stream is read second. Using"
    ],
    [
        "MultiPartParserError, \"Invalid boundary in multipart: None\"",
        "MultiPartParserError, \"Invalid boundary in multipart:"
    ],
    [
        "\"Invalid non-ASCII Content-Type in multipart: multipart/form-data; \"",
        "\"Invalid non-ASCII Content-Type in multipart:"
    ],
    [
        "msg = \"Request max total header size exceeded.\"",
        "msg = \"Request max total header"
    ],
    [
        "If wsgi.input.read() raises an exception while trying to read() the",
        "If wsgi.input.read() raises an exception while trying to read()"
    ],
    [
        "POST, the exception is identifiable (not a generic OSError).",
        "POST, the exception is identifiable"
    ],
    [
        "If wsgi.input.read() raises an exception while trying to read() the",
        "If wsgi.input.read() raises an exception while"
    ],
    [
        "FILES, the exception is identifiable (not a generic OSError).",
        "FILES, the exception is identifiable (not a"
    ],
    [
        "for host in chain(self.poisoned_hosts, [\"other.com\", \"example.com..\"]):",
        "for host in chain(self.poisoned_hosts, [\"other.com\","
    ],
    [
        "If ALLOWED_HOSTS is empty and DEBUG is True, variants of localhost are",
        "If ALLOWED_HOSTS is empty and DEBUG is True, variants of localhost"
    ],
    [
        "get_host() makes helpful suggestions if a valid-looking host is not in",
        "get_host() makes helpful suggestions if a valid-looking"
    ],
    [
        "msg_invalid_host = \"Invalid HTTP_HOST header: %r.\"",
        "msg_invalid_host = \"Invalid"
    ],
    [
        "msg_suggestion = msg_invalid_host + \" You may need to add %r to ALLOWED_HOSTS.\"",
        "msg_suggestion = msg_invalid_host + \" You may need"
    ],
    [
        "host = \"%s:%s\" % (domain, port)",
        "host = \"%s:%s\" % (domain,"
    ],
    [
        "When using select_related(), we must query the",
        "When using select_related(), we"
    ],
    [
        "Device and Building tables using two different aliases (each) in order to",
        "Device and Building tables using two different aliases (each) in"
    ],
    [
        "differentiate the start and end Connection fields. The net result is that",
        "differentiate the start and end Connection fields. The"
    ],
    [
        "both the \"connections = ...\" queries here should give the same results",
        "both the \"connections = ...\" queries here"
    ],
    [
        "without pulling in more than the absolute minimum number of tables",
        "without pulling in more than the"
    ],
    [
        "(history has shown that it's easy to make a mistake in the implementation",
        "(history has shown that it's easy to"
    ],
    [
        "and include some unnecessary bonus joins).",
        "and include some unnecessary"
    ],
    [
        "[(c.id, str(c.start), str(c.end)) for c in connections],",
        "[(c.id, str(c.start), str(c.end)) for"
    ],
    [
        "[(c.id, str(c.start), str(c.end)) for c in connections],",
        "[(c.id, str(c.start), str(c.end)) for c"
    ],
    [
        "Same sort of problem as the previous test, but this time there are",
        "Same sort of problem as the previous test, but this time"
    ],
    [
        "more extra tables to pull in as part of the select_related() and some",
        "more extra tables to pull in as"
    ],
    [
        "of them could potentially clash (so need to be kept separate).",
        "of them could potentially clash (so need to be"
    ],
    [
        "the first related model in the tests below",
        "the first related model in the"
    ],
    [
        "(\"state\") is empty and we try to select the more remotely related",
        "(\"state\") is empty and we try"
    ],
    [
        "state__country. The regression here was not skipping the empty column results",
        "state__country. The regression here was not skipping the empty"
    ],
    [
        "\"\"\"Exercising select_related() with multi-table model inheritance.\"\"\"",
        "\"\"\"Exercising select_related() with multi-table model"
    ],
    [
        "Deferred fields are used correctly if you select_related a subset",
        "Deferred fields are used correctly"
    ],
    [
        "from .admin import site as custom_site",
        "from .admin import site as"
    ],
    [
        "query = {\"date__%s\" % field: val for field, val in query.items()}",
        "query = {\"date__%s\" % field: val for"
    ],
    [
        "_, _, lookup_params, *_ = changelist.get_filters(request)",
        "_, _, lookup_params, *_"
    ],
    [
        "for query, expected_from_date, expected_to_date in tests:",
        "for query, expected_from_date, expected_to_date in"
    ],
    [
        "parent = models.ForeignKey(Parent, models.SET_NULL, editable=False, null=True)",
        "parent = models.ForeignKey(Parent,"
    ],
    [
        "parent = models.ForeignKey(Child, models.SET_NULL, editable=False, null=True)",
        "parent = models.ForeignKey(Child, models.SET_NULL,"
    ],
    [
        "Model with Manager that defines a default order.",
        "Model with Manager that"
    ],
    [
        "from .models import Band, Child, Event, Genre, GrandChild, Parent, ProxyUser, Swallow",
        "from .models import Band, Child, Event,"
    ],
    [
        "list_display = (\"origin\", \"load\", \"speed\", \"swallowonetoone\")",
        "list_display = (\"origin\", \"load\", \"speed\","
    ],
    [
        "from django.db import DatabaseError, connection, models",
        "from django.db import DatabaseError,"
    ],
    [
        "from django.db.models import F, Field, IntegerField",
        "from django.db.models import F, Field,"
    ],
    [
        "from django.template import Context, Template, TemplateSyntaxError",
        "from django.template import Context,"
    ],
    [
        "from django.test import TestCase, override_settings, skipUnlessDBFeature",
        "from django.test import TestCase,"
    ],
    [
        "from django.test.utils import CaptureQueriesContext, isolate_apps, register_lookup",
        "from django.test.utils import CaptureQueriesContext,"
    ],
    [
        "from .admin import site as custom_site",
        "from .admin import site as"
    ],
    [
        "'class=\"action-select\" aria-label=\"Select this object for an action - {}\"></td>'",
        "'class=\"action-select\" aria-label=\"Select this object for an action -"
    ],
    [
        "overwrite a custom select_related provided by ModelAdmin.get_queryset().",
        "overwrite a custom select_related"
    ],
    [
        "Searches over multi-valued relationships return rows from related",
        "Searches over multi-valued relationships"
    ],
    [
        "models only when all searched fields match that row.",
        "models only when all searched"
    ],
    [
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}\"",
        "\"{% load admin_list %}{% spaceless %}{%"
    ],
    [
        "context = Context({\"cl\": cl, \"opts\": Child._meta})",
        "context = Context({\"cl\": cl, \"opts\":"
    ],
    [
        "new_child, link, \"name\", '<td class=\"field-parent nowrap\">-</td>'",
        "new_child, link, \"name\", '<td"
    ],
    [
        "\"Failed to find expected row element: %s\" % table_output,",
        "\"Failed to find expected row element: %s\" %"
    ],
    [
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}\"",
        "\"{% load admin_list %}{% spaceless %}{% result_list"
    ],
    [
        "context = Context({\"cl\": cl, \"opts\": Child._meta})",
        "context = Context({\"cl\": cl, \"opts\":"
    ],
    [
        "new_child, link, \"-\", '<td class=\"field-parent nowrap\">-</td>'",
        "new_child, link, \"-\", '<td class=\"field-parent"
    ],
    [
        "Empty value display can be set on AdminSite.",
        "Empty value display can"
    ],
    [
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}\"",
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless"
    ],
    [
        "context = Context({\"cl\": cl, \"opts\": Child._meta})",
        "context = Context({\"cl\":"
    ],
    [
        "new_child, link, \"name\", '<td class=\"field-parent nowrap\">???</td>'",
        "new_child, link, \"name\","
    ],
    [
        "\"Failed to find expected row element: %s\" % table_output,",
        "\"Failed to find expected row element: %s\""
    ],
    [
        "Empty value display can be set in ModelAdmin or individual fields.",
        "Empty value display can be set in ModelAdmin or"
    ],
    [
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}\"",
        "\"{% load admin_list %}{% spaceless %}{%"
    ],
    [
        "context = Context({\"cl\": cl, \"opts\": Child._meta})",
        "context = Context({\"cl\": cl, \"opts\":"
    ],
    [
        "\"Failed to find expected row element: %s\" % table_output,",
        "\"Failed to find expected row element: %s\""
    ],
    [
        "Inclusion tag result_list generates a table when with default",
        "Inclusion tag result_list generates a"
    ],
    [
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}\"",
        "\"{% load admin_list %}{% spaceless %}{% result_list"
    ],
    [
        "context = Context({\"cl\": cl, \"opts\": Child._meta})",
        "context = Context({\"cl\": cl,"
    ],
    [
        "\"Failed to find expected row element: %s\" % table_output,",
        "\"Failed to find expected row"
    ],
    [
        "'aria-label=\"Select all objects on this page for an action\">',",
        "'aria-label=\"Select all objects on this"
    ],
    [
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}\"",
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{%"
    ],
    [
        "context = Context({\"cl\": cl, \"opts\": GrandChild._meta})",
        "context = Context({\"cl\": cl, \"opts\":"
    ],
    [
        "\"Failed to find expected row element: %s\" % table_output,",
        "\"Failed to find expected row element: %s\""
    ],
    [
        "table and this checks that the items are nested within the table",
        "table and this checks that the"
    ],
    [
        "when list_editable is enabled are rendered in a div outside the",
        "when list_editable is enabled are rendered in"
    ],
    [
        "\"{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}\"",
        "\"{% load admin_list %}{% spaceless %}{%"
    ],
    [
        "context = Context({\"cl\": cl, \"opts\": Child._meta})",
        "context = Context({\"cl\":"
    ],
    [
        "hiddenfields_div, table_output, msg_prefix=\"Failed to find hidden fields\"",
        "hiddenfields_div, table_output, msg_prefix=\"Failed to"
    ],
    [
        "msg_prefix='Failed to find \"name\" list_editable field',",
        "msg_prefix='Failed to find \"name\" list_editable"
    ],
    [
        "results shouldn't appear more than once. Basic ManyToMany.",
        "results shouldn't appear more than once."
    ],
    [
        "results shouldn't appear more than once. With an intermediate model.",
        "results shouldn't appear more than once. With"
    ],
    [
        "When using a ManyToMany in list_filter at the second level behind a",
        "When using a ManyToMany in list_filter at the second level"
    ],
    [
        "ForeignKey, distinct() must be called and results shouldn't appear more",
        "ForeignKey, distinct() must be called and results shouldn't"
    ],
    [
        "results shouldn't appear more than once. Model managed in the",
        "results shouldn't appear more than"
    ],
    [
        "admin inherits from the one that defines the relationship.",
        "admin inherits from the one that defines"
    ],
    [
        "results shouldn't appear more than once. Target of the relationship",
        "results shouldn't appear more than once. Target"
    ],
    [
        "is a non-unique related object, distinct() must be called.",
        "is a non-unique related object, distinct() must be"
    ],
    [
        "messages = [m.message for m in request._messages]",
        "messages = [m.message for m in"
    ],
    [
        "is a non-unique related object, distinct() must be called.",
        "is a non-unique related object,"
    ],
    [
        "When using a ManyToMany in search_fields at the second level behind a",
        "When using a ManyToMany in search_fields at the second"
    ],
    [
        "ForeignKey, distinct() must be called and results shouldn't appear more",
        "ForeignKey, distinct() must be called and results shouldn't"
    ],
    [
        "All rows containing each of the searched words are returned, where each",
        "All rows containing each of the"
    ],
    [
        "word must be in one of search_fields.",
        "word must be in one"
    ],
    [
        "grandchild = GrandChild.objects.create(name=\"I am a grandchild\", parent=child)",
        "grandchild = GrandChild.objects.create(name=\"I am a"
    ],
    [
        "request = self.factory.get(\"/\", data={SEARCH_VAR: \"'I am a child'\"})",
        "request = self.factory.get(\"/\", data={SEARCH_VAR: \"'I"
    ],
    [
        "If a ManyToManyField is in list_filter but isn't in any lookup params,",
        "If a ManyToManyField is in list_filter but isn't in any"
    ],
    [
        "the changelist's query shouldn't have distinct.",
        "the changelist's query shouldn't"
    ],
    [
        "for lookup_params in ({}, {\"name\": \"test\"}):",
        "for lookup_params in ({}, {\"name\":"
    ],
    [
        "Child.objects.create(id=i, name=\"child %s\" % i, parent=parent, age=i)",
        "Child.objects.create(id=i, name=\"child %s\" %"
    ],
    [
        "self.assertContains(response, '<a href=\"%s\">%s</a>' % (link, i))",
        "self.assertContains(response, '<a href=\"%s\">%s</a>'"
    ],
    [
        "Simultaneous edits of list_editable fields on the changelist by",
        "Simultaneous edits of list_editable fields"
    ],
    [
        "different users must not result in one user's edits creating a new",
        "different users must not result in one user's edits creating"
    ],
    [
        "\"\"\"list_editable edits use a filtered queryset to limit memory usage.\"\"\"",
        "\"\"\"list_editable edits use a filtered queryset to"
    ],
    [
        "self.assertContains(response, \"Error: Select swallow to change\")",
        "self.assertContains(response, \"Error: Select swallow"
    ],
    [
        "The primary key is used in the ordering of the changelist's results to",
        "The primary key is used in the ordering of"
    ],
    [
        "guarantee a deterministic order, even when the model doesn't have any",
        "guarantee a deterministic order, even when the"
    ],
    [
        "The primary key is used in the ordering of the changelist's results to",
        "The primary key is used in the"
    ],
    [
        "guarantee a deterministic order, even when the model has a manager that",
        "guarantee a deterministic order, even when the model has a"
    ],
    [
        "generated for changelist views are correct.",
        "generated for changelist views"
    ],
    [
        "for number, pages, expected in [",
        "for number, pages, expected"
    ],
    [
        "for i in range(pages * cl.list_per_page):",
        "for i in range(pages"
    ],
    [
        "When ModelAdmin.has_add_permission() returns False, the object-tools",
        "When ModelAdmin.has_add_permission() returns"
    ],
    [
        "response, '<div class=\"help\" id=\"searchbar_helptext\">Search help text</div>'",
        "response, '<div class=\"help\""
    ],
    [
        "parent = Parent.objects.create(name=\"I am your father\")",
        "parent = Parent.objects.create(name=\"I"
    ],
    [
        "child = Child.objects.create(name=\"I am your child\", parent=parent)",
        "child = Child.objects.create(name=\"I am your"
    ],
    [
        "{% get_admin_log %} works if the user model's primary key isn't named",
        "{% get_admin_log %} works if the user model's primary key isn't"
    ],
    [
        "\"\"\"{% get_admin_log %} works without specifying a user.\"\"\"",
        "\"\"\"{% get_admin_log %} works without specifying a"
    ],
    [
        "\"{% for entry in admin_log %}\"",
        "\"{% for entry in"
    ],
    [
        "msg = \"'get_admin_log' statements require two arguments\"",
        "msg = \"'get_admin_log' statements require two"
    ],
    [
        "msg = \"First argument to 'get_admin_log' must be an integer\"",
        "msg = \"First argument to 'get_admin_log'"
    ],
    [
        "msg = \"Second argument to 'get_admin_log' must be 'as'\"",
        "msg = \"Second argument to 'get_admin_log'"
    ],
    [
        "msg = \"Fourth argument to 'get_admin_log' must be 'for_user'\"",
        "msg = \"Fourth argument to 'get_admin_log' must be"
    ],
    [
        "Selecting a row and then selecting another row whilst holding shift",
        "Selecting a row and then selecting another"
    ],
    [
        "question = self.selenium.find_element(By.CSS_SELECTOR, \".actions > .question\")",
        "question = self.selenium.find_element(By.CSS_SELECTOR, \".actions"
    ],
    [
        "clear = self.selenium.find_element(By.CSS_SELECTOR, \".actions > .clear\")",
        "clear = self.selenium.find_element(By.CSS_SELECTOR,"
    ],
    [
        "\"You have unsaved changes on individual editable fields. If you \"",
        "\"You have unsaved changes on individual editable fields. If"
    ],
    [
        "\"run an action, your unsaved changes will be lost.\",",
        "\"run an action, your unsaved changes will be"
    ],
    [
        "\"You have selected an action, but you haven’t saved your \"",
        "\"You have selected an action, but you haven’t saved your"
    ],
    [
        "\"changes to individual fields yet. Please click OK to save. \"",
        "\"changes to individual fields yet. Please click"
    ],
    [
        "\"You’ll need to re-run the action.\",",
        "\"You’ll need to"
    ],
    [
        "\"You have selected an action, and you haven’t made any \"",
        "\"You have selected an action, and you haven’t made"
    ],
    [
        "\"changes on individual fields. You’re probably looking for \"",
        "\"changes on individual fields. You’re probably"
    ],
    [
        "\"the Go button rather than the Save button.\",",
        "\"the Go button rather than the"
    ],
    [
        "\" \".join(\"-\" if i is None else i for i in item)",
        "\" \".join(\"-\" if i is None else"
    ],
    [
        "Model inheritance exists in two varieties:",
        "Model inheritance exists"
    ],
    [
        "- abstract base classes which are a way of specifying common",
        "- abstract base classes which are a"
    ],
    [
        "information inherited by the subclasses. They don't exist as a separate",
        "information inherited by the subclasses. They don't exist as a"
    ],
    [
        "- non-abstract base classes (the default), which are models in their own",
        "- non-abstract base classes (the default), which are models in their"
    ],
    [
        "right with their own database tables and everything. Their subclasses",
        "right with their own database tables and everything. Their"
    ],
    [
        "have references back to them, created automatically.",
        "have references back to them, created"
    ],
    [
        "return \"%s %s\" % (self.__class__.__name__, self.name)",
        "return \"%s %s\""
    ],
    [
        "chef = models.ForeignKey(Chef, models.SET_NULL, null=True, blank=True)",
        "chef = models.ForeignKey(Chef, models.SET_NULL, null=True,"
    ],
    [
        "place = models.ForeignKey(Place, models.CASCADE, null=True, related_name=\"+\")",
        "place = models.ForeignKey(Place, models.CASCADE,"
    ],
    [
        "AttributeError, \"'CommonInfo' has no attribute 'objects'\"",
        "AttributeError, \"'CommonInfo' has no attribute"
    ],
    [
        "\"Cannot resolve keyword 'supplier' into field. Choices are: \"",
        "\"Cannot resolve keyword 'supplier' into field. Choices"
    ],
    [
        "\"address, chef, chef_id, id, italianrestaurant, lot, name, \"",
        "\"address, chef, chef_id, id, italianrestaurant,"
    ],
    [
        "\"place_ptr, place_ptr_id, provider, rating, serves_hot_dogs, serves_pizza\"",
        "\"place_ptr, place_ptr_id, provider, rating, serves_hot_dogs,"
    ],
    [
        "content=\"The web framework for perfections with deadlines.\",",
        "content=\"The web framework for perfections"
    ],
    [
        "msg = \"'Post' object has no attribute 'attached_%(class)s_set'\"",
        "msg = \"'Post' object has no"
    ],
    [
        "msg = \"Cannot resolve keyword 'attached_comment_set' into field.\"",
        "msg = \"Cannot resolve keyword 'attached_comment_set' into"
    ],
    [
        "Updating a field of a model subclass doesn't issue an UPDATE",
        "Updating a field of a model subclass"
    ],
    [
        "\"\"\"Creating a child with non-abstract parents only issues INSERTs.\"\"\"",
        "\"\"\"Creating a child with non-abstract parents only"
    ],
    [
        "for i, test in enumerate([a, b]):",
        "for i, test in"
    ],
    [
        "expected_order_by_sql = \"ORDER BY %s.%s DESC\" % (",
        "expected_order_by_sql = \"ORDER BY %s.%s DESC\""
    ],
    [
        "msg = \"Grand parent with this Email already exists.\"",
        "msg = \"Grand parent with this"
    ],
    [
        "msg = \"Grand parent with this First name and Last name already exists.\"",
        "msg = \"Grand parent with this First"
    ],
    [
        "Single layer multiple inheritance is as expected, deriving the",
        "Single layer multiple inheritance is as expected,"
    ],
    [
        "inherited field from the first base.",
        "inherited field from the"
    ],
    [
        "In contrast to standard Python MRO, resolution of inherited fields is",
        "In contrast to standard Python MRO, resolution of inherited fields"
    ],
    [
        "strictly depth-first, rather than breadth-first in diamond-shaped cases.",
        "strictly depth-first, rather than"
    ],
    [
        "This is because a copy of the parent field descriptor is placed onto",
        "This is because a copy of the parent field descriptor"
    ],
    [
        "the model class in ModelBase.__new__(), rather than the attribute",
        "the model class in ModelBase.__new__(),"
    ],
    [
        "lookup going via bases. (It only **looks** like inheritance.)",
        "lookup going via bases. (It"
    ],
    [
        "Here, Child inherits name from Root, rather than ParentB.",
        "Here, Child inherits name from Root, rather than"
    ],
    [
        "Where the Child model needs to inherit a field from a different base",
        "Where the Child model needs to inherit a field from a"
    ],
    [
        "than that given by depth-first resolution, the target field can be",
        "than that given by depth-first resolution, the target"
    ],
    [
        "\"The field 'name' clashes with the field 'name' \"",
        "\"The field 'name' clashes with the field 'name'"
    ],
    [
        "\"Local field 'name' in class 'Descendant' clashes with field of \"",
        "\"Local field 'name' in class 'Descendant' clashes with"
    ],
    [
        "\"the same name from base class 'ConcreteDescendant'.\"",
        "\"the same name from"
    ],
    [
        "msg = \"Descendant has no field named %r\"",
        "msg = \"Descendant has no"
    ],
    [
        "\"The field 'foo_id' clashes with the field 'foo' \"",
        "\"The field 'foo_id' clashes with the field 'foo'"
    ],
    [
        "\"'model_inheritance.Foo.foo' clashes with field name \"",
        "\"'model_inheritance.Foo.foo' clashes with field"
    ],
    [
        "\"add/change a related_name argument to the definition \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"Reverse query name for 'model_inheritance.Foo.foo' \"",
        "\"Reverse query name"
    ],
    [
        "\"add/change a related_name argument to the definition \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"The field 'name' clashes with the field 'name' from \"",
        "\"The field 'name' clashes with the field 'name'"
    ],
    [
        "\"Auto-generated field 'concreteparent_ptr' in class 'Descendant' \"",
        "\"Auto-generated field 'concreteparent_ptr' in"
    ],
    [
        "\"for parent_link to base class 'ConcreteParent' clashes with \"",
        "\"for parent_link to base class 'ConcreteParent' clashes"
    ],
    [
        "\"declared field of the same name.\"",
        "\"declared field of the"
    ],
    [
        "return [(f.name, f.__class__) for f in model._meta.get_fields()]",
        "return [(f.name, f.__class__) for f in"
    ],
    [
        "\"\"\"TaggedItemForm has a widget defined in Meta.\"\"\"",
        "\"\"\"TaggedItemForm has a widget defined in"
    ],
    [
        "\"fk_name 'generic_relations.BadModel.content_type' is not a ForeignKey to \"",
        "\"fk_name 'generic_relations.BadModel.content_type' is not a ForeignKey"
    ],
    [
        "The save_as_new parameter creates new items that are associated with",
        "The save_as_new parameter creates new items that"
    ],
    [
        "formset = GenericFormSet(data, instance=lion, prefix=\"form\", save_as_new=True)",
        "formset = GenericFormSet(data, instance=lion, prefix=\"form\","
    ],
    [
        "self.assertEqual([tag.tag for tag in tags], [\"hunts\", \"roars\"])",
        "self.assertEqual([tag.tag for tag in tags],"
    ],
    [
        "Generic relations let an object have a foreign key to any object through a",
        "Generic relations let an object have a foreign key"
    ],
    [
        "content-type/object-id field. A ``GenericForeignKey`` field can point to any",
        "content-type/object-id field. A ``GenericForeignKey`` field"
    ],
    [
        "object, be it animal, vegetable, or mineral.",
        "object, be it animal, vegetable,"
    ],
    [
        "The canonical example is tags (although this example implementation is *far*",
        "The canonical example is tags (although this example implementation"
    ],
    [
        "A model that tests having multiple GenericForeignKeys. One is defined",
        "A model that tests having multiple"
    ],
    [
        "through an inherited abstract model and one defined directly on this class.",
        "through an inherited abstract model and one defined directly"
    ],
    [
        "return \"%s is %s than %s\" % (self.first_obj, self.comparative, self.other_obj)",
        "return \"%s is %s than %s\" % (self.first_obj, self.comparative,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import"
    ],
    [
        "Should be able to use update_or_create from the generic related manager",
        "Should be able to use update_or_create from the"
    ],
    [
        "Should be able to use update_or_create from the generic related manager",
        "Should be able to use update_or_create from the"
    ],
    [
        "Should be able to use get_or_create from the generic related manager",
        "Should be able to use get_or_create from"
    ],
    [
        "Should be able to use get_or_create from the generic related manager",
        "Should be able to use get_or_create from the"
    ],
    [
        "Objects with declared GenericRelations can be tagged directly -- the",
        "Objects with declared GenericRelations can be"
    ],
    [
        "Test accessing the content object like a foreign key.",
        "Test accessing the content object like"
    ],
    [
        "self.assertQuerySetEqual(qs, [\"hairy\", \"mpk\", \"yellow\"], lambda x: x.tag)",
        "self.assertQuerySetEqual(qs, [\"hairy\", \"mpk\", \"yellow\"],"
    ],
    [
        "Test lookups over an object without GenericRelations.",
        "Test lookups over an object without"
    ],
    [
        "You can set a generic foreign key in the way you'd expect.",
        "You can set a generic foreign key in"
    ],
    [
        "Queries across generic relations respect the content types. Even though",
        "Queries across generic relations respect"
    ],
    [
        "there are two TaggedItems with a tag of \"fatty\", this query only pulls",
        "there are two TaggedItems with a tag of"
    ],
    [
        "out the one with the content type related to Animals.",
        "out the one with the content"
    ],
    [
        "Create another fatty tagged instance with different PK to ensure there",
        "Create another fatty tagged instance with different"
    ],
    [
        "is a content type restriction in the generated queries below.",
        "is a content type restriction in"
    ],
    [
        "If you delete an object with an explicit Generic relation, the related",
        "If you delete an object with an explicit Generic relation, the"
    ],
    [
        "objects are deleted when the source object is deleted.",
        "objects are deleted when the source object"
    ],
    [
        "If Generic Relation is not explicitly defined, any related objects",
        "If Generic Relation is not explicitly defined, any related"
    ],
    [
        "remain after deletion of the source object.",
        "remain after deletion of the"
    ],
    [
        "If you delete a tag, the objects using the tag are unaffected (other",
        "If you delete a tag, the objects using the tag"
    ],
    [
        "\"<TaggedItem: shiny> instance isn't saved. Use bulk=False or save the \"",
        "\"<TaggedItem: shiny> instance isn't saved. Use bulk=False or save"
    ],
    [
        "msg = \"'TaggedItem' instance expected, got <Animal: Lion>\"",
        "msg = \"'TaggedItem' instance"
    ],
    [
        "\"Cannot resolve keyword 'vegetable' into field. Choices are: \"",
        "\"Cannot resolve keyword 'vegetable' into field."
    ],
    [
        "\"animal, content_object, content_type, content_type_id, id, \"",
        "\"animal, content_object, content_type, content_type_id,"
    ],
    [
        "Concrete model subclasses with generic relations work",
        "Concrete model subclasses with generic"
    ],
    [
        "Generic relations on a base class (Vegetable) work correctly in",
        "Generic relations on a base class (Vegetable) work"
    ],
    [
        "msg = \"Field 'content_object' does not generate an automatic reverse relation\"",
        "msg = \"Field 'content_object' does not generate an automatic reverse"
    ],
    [
        "\"save() prohibited to prevent data loss due to unsaved related object \"",
        "\"save() prohibited to prevent data loss due to unsaved"
    ],
    [
        "\"bulk_create() prohibited to prevent data loss due to unsaved related \"",
        "\"bulk_create() prohibited to prevent data loss due to unsaved related"
    ],
    [
        "The default for for_concrete_model should be True",
        "The default for for_concrete_model"
    ],
    [
        "When for_concrete_model is False, we should still be able to get",
        "When for_concrete_model is False, we should still be able"
    ],
    [
        "an instance of the concrete class.",
        "an instance of the"
    ],
    [
        "Instances of the proxy should be returned when",
        "Instances of the proxy should be returned"
    ],
    [
        "Regression tests for the resolve_url function.",
        "Regression tests for the resolve_url"
    ],
    [
        "Passing a URL path to resolve_url() results in the same url.",
        "Passing a URL path to resolve_url() results in the same"
    ],
    [
        "Passing a relative URL path to resolve_url() results in the same url.",
        "Passing a relative URL path to resolve_url() results in the"
    ],
    [
        "Passing a full URL to resolve_url() results in the same url.",
        "Passing a full URL to resolve_url() results in the same"
    ],
    [
        "Passing a model to resolve_url() results in get_absolute_url() being",
        "Passing a model to resolve_url()"
    ],
    [
        "Passing a view function to resolve_url() results in the URL path",
        "Passing a view function to resolve_url()"
    ],
    [
        "Passing the result of reverse_lazy is resolved to a real URL",
        "Passing the result of reverse_lazy is"
    ],
    [
        "Passing a view name to resolve_url() results in the URL path mapping",
        "Passing a view name to resolve_url() results in the"
    ],
    [
        "Passing a domain to resolve_url() returns the same domain.",
        "Passing a domain to resolve_url() returns"
    ],
    [
        "Passing a non-view callable into resolve_url() raises a",
        "Passing a non-view callable into resolve_url()"
    ],
    [
        "from django.http import HttpRequest, HttpResponse, HttpResponseNotAllowed",
        "from django.http import"
    ],
    [
        "from django.utils.functional import keep_lazy, keep_lazy_text, lazy",
        "from django.utils.functional import keep_lazy, keep_lazy_text,"
    ],
    [
        "from django.views.decorators.cache import cache_control, cache_page, never_cache",
        "from django.views.decorators.cache import cache_control,"
    ],
    [
        "condition(lambda r: None, lambda r: None),",
        "condition(lambda r: None,"
    ],
    [
        "Built-in decorators set certain attributes of the wrapped function.",
        "Built-in decorators set certain attributes of the wrapped"
    ],
    [
        "\"\"\"A decorator that sets a new attribute on the method.\"\"\"",
        "\"\"\"A decorator that sets a new"
    ],
    [
        "msg = \"'set' object is not subscriptable\"",
        "msg = \"'set' object is"
    ],
    [
        "@method_decorator can be used to decorate a class and its methods.",
        "@method_decorator can be used to decorate a class and"
    ],
    [
        "@method_decorator can accept a tuple of decorators.",
        "@method_decorator can accept a tuple of"
    ],
    [
        "@method_decorator on a non-callable attribute raises an error.",
        "@method_decorator on a non-callable attribute raises"
    ],
    [
        "\"Cannot decorate 'prop' as it isn't a callable attribute of \"",
        "\"Cannot decorate 'prop' as it isn't a"
    ],
    [
        "@method_decorator on a nonexistent method raises an error.",
        "@method_decorator on a nonexistent method raises"
    ],
    [
        "\"The keyword argument `name` must be the name of a method of the \"",
        "\"The keyword argument `name` must be the name of a method of the"
    ],
    [
        "\"decorated class: <class 'Test'>. Got 'nonexistent_method' instead\"",
        "\"decorated class: <class 'Test'>."
    ],
    [
        "\"\"\"A decorator that sets a new attribute on the method.\"\"\"",
        "\"\"\"A decorator that sets a"
    ],
    [
        "msg = \"'set' object is not subscriptable\"",
        "msg = \"'set' object"
    ],
    [
        "@method_decorator can be used to decorate a class and its methods.",
        "@method_decorator can be used to decorate"
    ],
    [
        "@method_decorator can accept a tuple of decorators.",
        "@method_decorator can accept a"
    ],
    [
        "return await func(*args, **kwargs) + \"?\"",
        "return await func(*args, **kwargs)"
    ],
    [
        "return await func(*args, **kwargs) + \"!\"",
        "return await func(*args, **kwargs)"
    ],
    [
        "expected = {\"func_name\": \"method\", \"func_module\": \"decorators.tests\"}",
        "expected = {\"func_name\": \"method\","
    ],
    [
        "@xframe_options_exempt instructs the XFrameOptionsMiddleware to NOT set",
        "@xframe_options_exempt instructs the XFrameOptionsMiddleware to"
    ],
    [
        "from django.views.decorators.cache import cache_control, cache_page, never_cache",
        "from django.views.decorators.cache import cache_control,"
    ],
    [
        "\"\"\"Proxy to the underlying HttpRequest object.\"\"\"",
        "\"\"\"Proxy to the underlying HttpRequest"
    ],
    [
        "\"cache_control didn't receive an HttpRequest. If you are \"",
        "\"cache_control didn't receive an HttpRequest. If you are"
    ],
    [
        "\"decorating a classmethod, be sure to use @method_decorator.\"",
        "\"decorating a classmethod, be sure to"
    ],
    [
        "\"cache_control didn't receive an HttpRequest. If you are decorating a \"",
        "\"cache_control didn't receive an HttpRequest. If you are"
    ],
    [
        "\"classmethod, be sure to use @method_decorator.\"",
        "\"classmethod, be sure"
    ],
    [
        "\"never_cache didn't receive an HttpRequest. If you are decorating \"",
        "\"never_cache didn't receive an HttpRequest. If you are"
    ],
    [
        "\"a classmethod, be sure to use @method_decorator.\"",
        "\"a classmethod, be sure to use"
    ],
    [
        "\"never_cache didn't receive an HttpRequest. If you are decorating \"",
        "\"never_cache didn't receive an HttpRequest. If you are"
    ],
    [
        "\"a classmethod, be sure to use @method_decorator.\"",
        "\"a classmethod, be sure to use"
    ],
    [
        "Tests for Django's bundled context processors.",
        "Tests for Django's bundled context"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import"
    ],
    [
        "The request object is available in the template and that its",
        "The request object is available in the template"
    ],
    [
        "Test whether sql_queries represents the actual amount",
        "Test whether sql_queries represents the actual"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import include, path,"
    ],
    [
        "Some extra URL patterns that are included at the top level.",
        "Some extra URL patterns that are included at the"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import"
    ],
    [
        "These URL patterns are included in two different ways in the main urls.py, with",
        "These URL patterns are included in two different"
    ],
    [
        "an extra argument present in one case. Thus, there are two different ways for",
        "an extra argument present in one case. Thus,"
    ],
    [
        "each name to resolve and Django must distinguish the possibilities based on the",
        "each name to resolve and Django must distinguish the possibilities based on"
    ],
    [
        "\"tried to compile url regex twice for the same language\"",
        "\"tried to compile url regex"
    ],
    [
        "error = AssertionError(\"tried to compile non-translated url regex twice\")",
        "error = AssertionError(\"tried to compile non-translated url regex"
    ],
    [
        "\"\"\"Regex errors are re-raised as ImproperlyConfigured.\"\"\"",
        "\"\"\"Regex errors are re-raised as"
    ],
    [
        "msg = '\"*\" is not a valid regular expression: nothing to repeat'",
        "msg = '\"*\" is not a valid regular"
    ],
    [
        "'{% url \"outer\" as outer_url %}outer:{{ outer_url }},'",
        "'{% url \"outer\" as outer_url"
    ],
    [
        "'{% url \"inner\" as inner_url %}inner:{{ inner_url }}'",
        "'{% url \"inner\" as inner_url %}inner:{{ inner_url"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import include, path,"
    ],
    [
        "from .views import LazyRedirectView, empty_view, login_required_view",
        "from .views import"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import"
    ],
    [
        "Unit tests for reverse URL lookups.",
        "Unit tests for"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, TestCase, override_settings",
        "from django.test import RequestFactory, SimpleTestCase,"
    ],
    [
        "from . import middleware, urlconf_outer, views",
        "from . import middleware,"
    ],
    [
        "(\"people\", NoReverseMatch, [\"name with spaces\"], {}),",
        "(\"people\", NoReverseMatch, [\"name"
    ],
    [
        "(\"people\", NoReverseMatch, [], {\"name\": \"name with spaces\"}),",
        "(\"people\", NoReverseMatch, [], {\"name\": \"name"
    ],
    [
        "{\"drive_name\": \"C\", \"path\": r\"Documents and Settings\\spam\"},",
        "{\"drive_name\": \"C\", \"path\": r\"Documents"
    ],
    [
        "(\"part\", \"/prefix/xx/part/one/\", [], {\"value\": \"one\", \"prefix\": \"xx\"}),",
        "(\"part\", \"/prefix/xx/part/one/\", [], {\"value\": \"one\","
    ],
    [
        "(\"nested-namedcapture\", NoReverseMatch, [], {\"outer\": \"opt/\", \"inner\": \"opt\"}),",
        "(\"nested-namedcapture\", NoReverseMatch, [], {\"outer\": \"opt/\", \"inner\":"
    ],
    [
        "URLResolver should raise an exception when no urlpatterns exist.",
        "URLResolver should raise an exception when no urlpatterns"
    ],
    [
        "\"The included URLconf 'urlpatterns_reverse.no_urls' does not \"",
        "\"The included URLconf 'urlpatterns_reverse.no_urls' does not"
    ],
    [
        "\"appear to have any patterns in it. If you see the 'urlpatterns' \"",
        "\"appear to have any patterns in it. If you see the"
    ],
    [
        "\"variable with valid patterns in the file then the issue is \"",
        "\"variable with valid patterns in the file then"
    ],
    [
        "\"probably caused by a circular import.\",",
        "\"probably caused by a"
    ],
    [
        "for name, expected, args, kwargs in test_data:",
        "for name, expected, args, kwargs"
    ],
    [
        "msg = \"Don't mix *args and **kwargs in call to reverse()!\"",
        "msg = \"Don't mix *args and"
    ],
    [
        "\"Reverse for 'nonexistent-view' not found. 'nonexistent-view' \"",
        "\"Reverse for 'nonexistent-view' not found."
    ],
    [
        "\"is not a valid view function or pattern name.\"",
        "\"is not a valid view function or"
    ],
    [
        "cases = [None, \"\", {}, [], set(), (), QueryDict()]",
        "cases = [None, \"\", {}, [], set(), (),"
    ],
    [
        "Test repr of URLResolver, especially when urlconf_name is a list",
        "Test repr of URLResolver, especially when urlconf_name is a"
    ],
    [
        "Verifies lazy object returned by reverse_lazy is coerced to",
        "Verifies lazy object returned by reverse_lazy is"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected"
    ],
    [
        "URL pattern name arguments don't need to be unique. The last registered",
        "URL pattern name arguments don't need"
    ],
    [
        "pattern takes precedence for conflicting names.",
        "pattern takes precedence"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs,"
    ],
    [
        "requirements of a path to match - i.e., at the very least, it matches",
        "requirements of a path to match - i.e., at the very least,"
    ],
    [
        "the root pattern '^/'. Never return None from resolve() to prevent a",
        "the root pattern '^/'. Never return None from resolve() to"
    ],
    [
        "test_urls = [\"\", \"a\", \"\\\\\", \".\"]",
        "test_urls = [\"\", \"a\","
    ],
    [
        "both the patterns and URL names, if available.",
        "both the patterns and URL"
    ],
    [
        "[{\"type\": URLResolver}, {\"type\": URLPattern, \"name\": None}],",
        "[{\"type\": URLResolver}, {\"type\": URLPattern,"
    ],
    [
        "\"Wrong number of tried URLs returned.  Expected %s, got %s.\"",
        "\"Wrong number of tried URLs returned. Expected %s,"
    ],
    [
        "for t, e in zip(tried, expected):",
        "for t, e in zip(tried,"
    ],
    [
        "), \"%s is not an instance of %s\" % (t, e[\"type\"])",
        "), \"%s is not an instance of %s\" %"
    ],
    [
        "t.name, \"Expected no URL name but found %s.\" % t.name",
        "t.name, \"Expected no URL name"
    ],
    [
        "'Wrong URL name.  Expected \"%s\", got \"%s\".'",
        "'Wrong URL name. Expected \"%s\","
    ],
    [
        "URLResolver._populate() can be called concurrently, but not more",
        "URLResolver._populate() can be called concurrently, but"
    ],
    [
        "\"Some URL: %s\" % reverse_lazy(\"some-login-page\"), \"Some URL: /login/\"",
        "\"Some URL: %s\" %"
    ],
    [
        "reverse_lazy can be used in settings without causing a circular",
        "reverse_lazy can be used in settings without causing a"
    ],
    [
        "Names deployed via dynamic URL objects that require namespaces can't",
        "Names deployed via dynamic URL objects that require"
    ],
    [
        "for name, args, kwargs in test_urls:",
        "for name, args,"
    ],
    [
        "Names deployed via dynamic URL objects that require namespaces can't",
        "Names deployed via dynamic URL"
    ],
    [
        "for name, args, kwargs in test_urls:",
        "for name, args, kwargs"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected in"
    ],
    [
        "\"\"\"Normal lookups work on names included from other patterns.\"\"\"",
        "\"\"\"Normal lookups work on names included from"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected"
    ],
    [
        "\"\"\"Dynamic URL objects can be found using a namespace.\"\"\"",
        "\"\"\"Dynamic URL objects can be found using a"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected in"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs,"
    ],
    [
        "Namespace defaults to app_name when including a (pattern, app_name)",
        "Namespace defaults to app_name when"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected"
    ],
    [
        "\"\"\"Namespaces can be installed anywhere in the URL pattern tree.\"\"\"",
        "\"\"\"Namespaces can be installed anywhere in the"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs,"
    ],
    [
        "\"\"\"Namespaces can be applied to include()'d urlpatterns.\"\"\"",
        "\"\"\"Namespaces can be applied"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs,"
    ],
    [
        "Namespaces can be applied to include()'d urlpatterns that set an",
        "Namespaces can be applied to"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs,"
    ],
    [
        "Using include() with namespaces when there is a regex variable in front",
        "Using include() with namespaces when there"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs,"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs,"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected in"
    ],
    [
        "\"\"\"A default application namespace can be used for lookup.\"\"\"",
        "\"\"\"A default application namespace can"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected in"
    ],
    [
        "\"\"\"A default application namespace is sensitive to the current app.\"\"\"",
        "\"\"\"A default application namespace is sensitive to the"
    ],
    [
        "for name, args, kwargs, current_app, expected in test_urls:",
        "for name, args, kwargs, current_app, expected"
    ],
    [
        "An application namespace without a default is sensitive to the current",
        "An application namespace without a default is sensitive to the"
    ],
    [
        "for name, args, kwargs, current_app, expected in test_urls:",
        "for name, args, kwargs, current_app, expected in"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected"
    ],
    [
        "for name, args, kwargs, expected in test_urls:",
        "for name, args, kwargs, expected in"
    ],
    [
        "for name, args, kwargs, current_app, expected in test_urls:",
        "for name, args, kwargs,"
    ],
    [
        "\"\"\"current_app shouldn't be used unless it matches the whole path.\"\"\"",
        "\"\"\"current_app shouldn't be used unless it matches the whole"
    ],
    [
        "for name, args, kwargs, current_app, expected in test_urls:",
        "for name, args, kwargs, current_app, expected in"
    ],
    [
        "Overriding request.urlconf with None will fall back to the default",
        "Overriding request.urlconf with None will fall back"
    ],
    [
        "Test reversing an URL from the *overridden* URLconf from inside",
        "Test reversing an URL from the *overridden*"
    ],
    [
        "Test reversing an URL from the *default* URLconf from inside",
        "Test reversing an URL from the *default* URLconf"
    ],
    [
        "\"Reverse for 'outer' not found. 'outer' is not a valid view \"",
        "\"Reverse for 'outer' not found. 'outer' is not a valid"
    ],
    [
        "Test reversing an URL from the *overridden* URLconf from inside",
        "Test reversing an URL from the *overridden* URLconf"
    ],
    [
        "Test reversing an URL from the *default* URLconf from inside",
        "Test reversing an URL from"
    ],
    [
        "message = \"Reverse for 'outer' not found.\"",
        "message = \"Reverse for"
    ],
    [
        "\"\"\"The URLconf is reset after each request.\"\"\"",
        "\"\"\"The URLconf is reset after"
    ],
    [
        "\"If the urls.py doesn't specify handlers, the defaults are used\"",
        "\"If the urls.py doesn't specify"
    ],
    [
        "msg = \"I don't think I'm getting good value for this view\"",
        "msg = \"I don't think I'm getting good value for this"
    ],
    [
        "\"The included URLconf 'None' does not appear to have any patterns \"",
        "\"The included URLconf 'None' does not appear to have"
    ],
    [
        "\"in it. If you see the 'urlpatterns' variable with valid patterns \"",
        "\"in it. If you see the 'urlpatterns' variable with valid patterns"
    ],
    [
        "\"in the file then the issue is probably caused by a circular \"",
        "\"in the file then the issue is probably caused by a circular"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"view must be a callable\"):",
        "with self.assertRaisesMessage(TypeError, \"view must be a"
    ],
    [
        "msg = '(regex_error/$\" is not a valid regular expression'",
        "msg = '(regex_error/$\" is not a valid"
    ],
    [
        "msg = \"View does not exist in module urlpatterns_reverse.views.\"",
        "msg = \"View does not exist"
    ],
    [
        "msg = \"I am here to confuse django.urls.get_callable\"",
        "msg = \"I am here to confuse"
    ],
    [
        "msg = \"Could not import 'test'. The path must be fully qualified.\"",
        "msg = \"Could not import 'test'. The path must"
    ],
    [
        "with self.assertRaisesMessage(ImportError, \"No module named 'foo'\"):",
        "with self.assertRaisesMessage(ImportError, \"No module"
    ],
    [
        "msg = \"Parent module urlpatterns_reverse.foo does not exist.\"",
        "msg = \"Parent module urlpatterns_reverse.foo does"
    ],
    [
        "\"Specifying a namespace in include() without providing an \"",
        "\"Specifying a namespace in include() without"
    ],
    [
        "\"Cannot override the namespace for a dynamic module that provides a \"",
        "\"Cannot override the namespace for a"
    ],
    [
        "for name, kwargs, expected in test_urls:",
        "for name, kwargs, expected in"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import"
    ],
    [
        "raise AttributeError(\"I am here to confuse django.urls.get_callable\")",
        "raise AttributeError(\"I am here to"
    ],
    [
        "raise ValueError(\"I don't think I'm getting good value for this view\")",
        "raise ValueError(\"I don't think I'm getting good value"
    ],
    [
        "raise Exception(\"debug() bubbles up exceptions before cleanup.\")",
        "raise Exception(\"debug() bubbles up"
    ],
    [
        "\"\"\"Simple test run: catches errors and runs cleanup.\"\"\"",
        "\"\"\"Simple test run: catches errors and runs"
    ],
    [
        "\"Exception: debug() bubbles up exceptions before cleanup.\", traceback",
        "\"Exception: debug() bubbles up"
    ],
    [
        "self.fail(\"SkipTest should not be raised at this stage.\")",
        "self.fail(\"SkipTest should not be raised"
    ],
    [
        "\"\"\"debug() bubbles up exceptions before cleanup.\"\"\"",
        "\"\"\"debug() bubbles up exceptions"
    ],
    [
        "msg = \"debug() bubbles up exceptions before cleanup.\"",
        "msg = \"debug() bubbles up"
    ],
    [
        "\"\"\"debug() bubbles up exceptions during _pre_setup.\"\"\"",
        "\"\"\"debug() bubbles up exceptions during"
    ],
    [
        "\"\"\"debug() bubbles up exceptions during _post_teardown.\"\"\"",
        "\"\"\"debug() bubbles up"
    ],
    [
        "from django.test import TestCase, TransactionTestCase, override_settings",
        "from django.test import TestCase, TransactionTestCase,"
    ],
    [
        "so that it's less likely to overflow. An overflow causes",
        "so that it's less likely to overflow. An"
    ],
    [
        "\"Database queries to 'other' are not allowed in this test. \"",
        "\"Database queries to 'other' are not allowed"
    ],
    [
        "\"DisallowedDatabaseQueriesTests.databases to ensure proper test \"",
        "\"DisallowedDatabaseQueriesTests.databases to ensure proper"
    ],
    [
        "\"ExampleTests.lockfile isn't set. Set it to a unique value in the \"",
        "\"ExampleTests.lockfile isn't set. Set it to"
    ],
    [
        "from django.db import IntegrityError, connections, transaction",
        "from django.db import"
    ],
    [
        "from .models import Car, Person, PossessedCar",
        "from .models import"
    ],
    [
        "raise pickle.PickleError(\"cannot be pickled for testing reasons\")",
        "raise pickle.PickleError(\"cannot be pickled for testing"
    ],
    [
        "\"\"\"ParallelTestSuite requires that all TestCases are picklable.\"\"\"",
        "\"\"\"ParallelTestSuite requires that all TestCases are"
    ],
    [
        "\"Database connections to 'other' are not allowed in this test. \"",
        "\"Database connections to 'other' are not allowed"
    ],
    [
        "\"Add 'other' to test_utils.test_testcase.TestTestCase.databases to \"",
        "\"Add 'other' to"
    ],
    [
        "\"ensure proper test isolation and silence this failure.\"",
        "\"ensure proper test isolation"
    ],
    [
        "\"Database queries to 'other' are not allowed in this test. \"",
        "\"Database queries to 'other' are not"
    ],
    [
        "\"Add 'other' to test_utils.test_testcase.TestTestCase.databases to \"",
        "\"Add 'other' to"
    ],
    [
        "\"ensure proper test isolation and silence this failure.\"",
        "\"ensure proper test isolation"
    ],
    [
        "msg = \"reset_sequences cannot be used on TestCase instances\"",
        "msg = \"reset_sequences cannot be"
    ],
    [
        "\"\"\"Class level test data is equal to instance level test data.\"\"\"",
        "\"\"\"Class level test data is equal to instance level test"
    ],
    [
        "Class level test data is not identical to instance level test data.",
        "Class level test data is not identical"
    ],
    [
        "\"\"\"Identity of test data is preserved between accesses.\"\"\"",
        "\"\"\"Identity of test data"
    ],
    [
        "\"\"\"Known related objects identity is preserved.\"\"\"",
        "\"\"\"Known related objects identity"
    ],
    [
        "In-memory data isolation is respected for model instances assigned to class",
        "In-memory data isolation is respected for"
    ],
    [
        "from django.urls import NoReverseMatch, path, reverse, reverse_lazy",
        "from django.urls import NoReverseMatch, path, reverse,"
    ],
    [
        "from .models import Car, Person, PossessedCar",
        "from .models import Car, Person,"
    ],
    [
        "self.fail(\"%s should not result in a skipped test.\" % func.__name__)",
        "self.fail(\"%s should not result in a skipped test.\" %"
    ],
    [
        "\"skipUnlessDBFeature cannot be used on test_foo (test_utils.tests.\"",
        "\"skipUnlessDBFeature cannot be used on test_foo"
    ],
    [
        "\"SkipTestCase doesn't allow queries against the 'default' database.\",",
        "\"SkipTestCase doesn't allow queries"
    ],
    [
        "\"skipIfDBFeature cannot be used on test_foo (test_utils.tests.\"",
        "\"skipIfDBFeature cannot be used"
    ],
    [
        "\"doesn't allow queries against the 'default' database.\",",
        "\"doesn't allow queries against the"
    ],
    [
        "self.fail(\"SkipTest should not be raised here.\")",
        "self.fail(\"SkipTest should not"
    ],
    [
        "self.fail(\"SkipTest should not be raised at this stage\")",
        "self.fail(\"SkipTest should not be raised at"
    ],
    [
        "\"skipIfDBFeature cannot be used on <class 'test_utils.tests.\"",
        "\"skipIfDBFeature cannot be used on <class"
    ],
    [
        "\"MissingDatabases'> as it doesn't allow queries against the \"",
        "\"MissingDatabases'> as it doesn't allow"
    ],
    [
        "\"Trying to compare non-ordered queryset against more than one \"",
        "\"Trying to compare non-ordered queryset against more"
    ],
    [
        "assertQuerySetEqual checks the number of appearance of each item",
        "assertQuerySetEqual checks the number of"
    ],
    [
        "self.assertIn(\"Set self.maxDiff to None to see it.\", str(ctx.exception))",
        "self.assertIn(\"Set self.maxDiff to None to see"
    ],
    [
        "self.assertNotIn(\"Set self.maxDiff to None to see it.\", exception_msg)",
        "self.assertNotIn(\"Set self.maxDiff to None"
    ],
    [
        "msg = \"No templates used to render the response\"",
        "msg = \"No templates used to"
    ],
    [
        "\"Template 'template_used/base.html' was not a template used to render \"",
        "\"Template 'template_used/base.html' was not a template"
    ],
    [
        "\"the response. Actual template(s) used: template_used/alternative.html\"",
        "\"the response. Actual"
    ],
    [
        "msg = \"No templates used to render the response\"",
        "msg = \"No templates used to"
    ],
    [
        "msg = f\"{msg_prefix}: No templates used to render the response\"",
        "msg = f\"{msg_prefix}: No templates used to"
    ],
    [
        "f\"{msg_prefix}: Template 'template_used/base.html' was not a \"",
        "f\"{msg_prefix}: Template 'template_used/base.html' was not"
    ],
    [
        "f\"template used to render the response. Actual template(s) used: \"",
        "f\"template used to render the response. Actual"
    ],
    [
        "\"Template 'template_used/base.html' was expected to be rendered \"",
        "\"Template 'template_used/base.html' was expected to be rendered"
    ],
    [
        "msg = \"response and/or template_name argument must be provided\"",
        "msg = \"response and/or template_name"
    ],
    [
        "msg = \"No templates used to render the response\"",
        "msg = \"No templates used to render the"
    ],
    [
        "\"Template 'template_used/base.html' was not a template used to \"",
        "\"Template 'template_used/base.html' was not a template"
    ],
    [
        "\"render the response. Actual template(s) used: \"",
        "\"render the response. Actual template(s)"
    ],
    [
        "msg = \"%s() is only usable on responses fetched using the Django test Client.\"",
        "msg = \"%s() is only usable on"
    ],
    [
        "parse_html('<script>var a = \"<p\" + \">\";</script>')",
        "parse_html('<script>var a ="
    ],
    [
        "dom = parse_html(\"<p>Hello <%s> world</p>\" % tag)",
        "dom = parse_html(\"<p>Hello <%s> world</p>\" %"
    ],
    [
        "dom = parse_html(\"<p>Hello <%s /> world</p>\" % tag)",
        "dom = parse_html(\"<p>Hello <%s /> world</p>\" %"
    ],
    [
        "\"<div>Hello<!-- this is a comment --> World!</div>\",",
        "\"<div>Hello<!-- this is a comment -->"
    ],
    [
        "'<input type=\"text\" id=\"id_name\" />', '<input id=\"id_name\" type=\"text\" />'",
        "'<input type=\"text\" id=\"id_name\" />', '<input"
    ],
    [
        "('<p class=\"foo bar\"></p>', '<p class=\"bar foo\"></p>'),",
        "('<p class=\"foo bar\"></p>', '<p"
    ],
    [
        "('<p class=\" foo bar \"></p>', '<p class=\"bar foo\"></p>'),",
        "('<p class=\" foo bar \"></p>', '<p class=\"bar"
    ],
    [
        "('<p class=\"   foo    bar    \"></p>', '<p class=\"bar foo\"></p>'),",
        "('<p class=\" foo bar"
    ],
    [
        "('<p class=\"\\t \\nfoo \\t\\nbar\\n\\t \"></p>', '<p class=\"bar foo\"></p>'),",
        "('<p class=\"\\t \\nfoo \\t\\nbar\\n\\t \"></p>', '<p class=\"bar"
    ],
    [
        "<td><input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" /></td></tr>",
        "<td><input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\""
    ],
    [
        "<td><input type=\"text\" id=\"id_last_name\" name=\"last_name\" value=\"Lennon\" /></td></tr>",
        "<td><input type=\"text\" id=\"id_last_name\" name=\"last_name\""
    ],
    [
        "<input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" />",
        "<input type=\"text\" name=\"first_name\" value=\"John\""
    ],
    [
        "<input type=\"text\" name=\"last_name\" value=\"Lennon\" id=\"id_last_name\" />",
        "<input type=\"text\" name=\"last_name\" value=\"Lennon\""
    ],
    [
        "<div> this is a div AFTER the p</div>",
        "<div> this is a div AFTER"
    ],
    [
        "<p> This is a valid paragraph",
        "<p> This is a valid"
    ],
    [
        "<!-- browsers would close the p tag here -->",
        "<!-- browsers would close the"
    ],
    [
        "<div> this is a div AFTER the p</div>",
        "<div> this is a div AFTER the"
    ],
    [
        "</p> <!-- this is invalid HTML parsing, but it should make no",
        "</p> <!-- this is invalid HTML parsing, but it should make"
    ],
    [
        "\"First argument is not valid HTML:\\n\"",
        "\"First argument is not valid"
    ],
    [
        "This is a form: <form method=\"get\">",
        "This is a"
    ],
    [
        "'<p class=\"help\">Some help text for the title (with Unicode ŠĐĆŽćžšđ)</p>'",
        "'<p class=\"help\">Some help text for"
    ],
    [
        "'<p class=\"help\">Some help text for the title (with Unicode ŠĐĆŽćžšđ)</p>',",
        "'<p class=\"help\">Some help text for the title (with Unicode"
    ],
    [
        "\"False is not true : Couldn't find '<b>Hello</b>' in the following \"",
        "\"False is not true : Couldn't find '<b>Hello</b>' in the"
    ],
    [
        "\"False is not true : Prefix: Couldn't find '<b>Hello</b>' in the following \"",
        "\"False is not true : Prefix: Couldn't find '<b>Hello</b>' in the"
    ],
    [
        "haystack = \"<p><b>Hello</b> <span>there</span>! Hi <span>there</span>!</p>\"",
        "haystack = \"<p><b>Hello</b>"
    ],
    [
        "msg = f\"Couldn't find '<p>Howdy</p>' in the following response\\n{haystack!r}\"",
        "msg = f\"Couldn't find '<p>Howdy</p>' in"
    ],
    [
        "\"<p>This is a very very very very very very very very long message which \"",
        "\"<p>This is a very very very very very very very very long message"
    ],
    [
        "\"exceeds the max limit of truncation.</p>\"",
        "\"exceeds the max"
    ],
    [
        "msg = f\"Couldn't find '<b>Hello</b>' in the following response\\n{haystack!r}\"",
        "msg = f\"Couldn't find '<b>Hello</b>' in the following"
    ],
    [
        "haystack = \"<p><b>Hello</b> <span>there</span>! Hi <span>there</span>!</p>\"",
        "haystack = \"<p><b>Hello</b> <span>there</span>!"
    ],
    [
        "\"'<b>Hello</b>' unexpectedly found in the following response\"",
        "\"'<b>Hello</b>' unexpectedly found in the"
    ],
    [
        "@unittest.skip(\"Fixture loading should not be performed for skipped tests.\")",
        "@unittest.skip(\"Fixture loading should not be performed for skipped"
    ],
    [
        "msg = \"'Expected message' not found in 'Unexpected message'\"",
        "msg = \"'Expected message' not found"
    ],
    [
        "\"\"\"assertRaisesMessage shouldn't interpret RE special chars.\"\"\"",
        "\"\"\"assertRaisesMessage shouldn't interpret"
    ],
    [
        "msg = \"Expected message' not found in 'Unexpected message'\"",
        "msg = \"Expected message' not"
    ],
    [
        "error_invalid = [\"Enter a valid email address.\"]",
        "error_invalid = [\"Enter a valid email"
    ],
    [
        "EmailField, {\"a@a.com\": \"Wrong output\"}, {\"aaa\": error_invalid}",
        "EmailField, {\"a@a.com\": \"Wrong output\"},"
    ],
    [
        "{\"aaa\": [\"Come on, gimme some well formatted data, dude.\"]},",
        "{\"aaa\": [\"Come on, gimme some well formatted data,"
    ],
    [
        "return cls._get_cleaned_form(\"invalid_non_field\" if nonfield else \"invalid\")",
        "return cls._get_cleaned_form(\"invalid_non_field\" if"
    ],
    [
        "return cls._get_cleaned_formset(\"invalid_non_field\" if nonfield else \"invalid\")",
        "return cls._get_cleaned_formset(\"invalid_non_field\" if nonfield else"
    ],
    [
        "\"The form <TestForm bound=True, valid=False, fields=(field)> does not \"",
        "\"The form <TestForm bound=True, valid=False, fields=(field)> does not"
    ],
    [
        "\"The errors of field 'field' on form <TestForm bound=True, valid=True, \"",
        "\"The errors of field 'field' on form <TestForm"
    ],
    [
        "\"The errors of field 'field' on form <TestForm bound=True, valid=False, \"",
        "\"The errors of field 'field' on form <TestForm bound=True, valid=False,"
    ],
    [
        "self.assertIn(\"['invalid value'] != ['other error']\", str(ctx.exception))",
        "self.assertIn(\"['invalid value'] != ['other"
    ],
    [
        "\"The form <TestForm bound=False, valid=Unknown, fields=(field)> is not \"",
        "\"The form <TestForm bound=False, valid=Unknown,"
    ],
    [
        "\"bound, it will never have any errors.\"",
        "\"bound, it will never have any"
    ],
    [
        "\"The errors of field 'field' on form <TestForm bound=True, valid=False, \"",
        "\"The errors of field 'field' on form <TestForm bound=True, valid=False,"
    ],
    [
        "\"The non-field errors of form <TestForm bound=True, valid=False, \"",
        "\"The non-field errors of form <TestForm bound=True, valid=False,"
    ],
    [
        "\"['non-field error'] != ['other non-field error']\", str(ctx.exception)",
        "\"['non-field error'] != ['other non-field"
    ],
    [
        "\"does not contain the field 'other_field'.\"",
        "\"does not contain the field"
    ],
    [
        "self.assertIn(\"['invalid value'] != ['other error']\", str(ctx.exception))",
        "self.assertIn(\"['invalid value'] != ['other"
    ],
    [
        "\"bound, it will never have any errors.\"",
        "\"bound, it will never"
    ],
    [
        "\"['non-field error'] != ['other non-field error']\", str(ctx.exception)",
        "\"['non-field error'] != ['other non-field"
    ],
    [
        "\"The non-form errors of formset <TestFormset: bound=True valid=False \"",
        "\"The non-form errors of formset <TestFormset:"
    ],
    [
        "\"The non-form errors of formset <TestFormset: bound=True valid=False \"",
        "\"The non-form errors of formset <TestFormset: bound=True valid=False"
    ],
    [
        "msg = \"You must use field=None with form_index=None.\"",
        "msg = \"You must use field=None with"
    ],
    [
        "Overriding the MEDIA_ROOT setting should be reflected in the",
        "Overriding the MEDIA_ROOT setting should"
    ],
    [
        "Overriding the MEDIA_URL setting should be reflected in the",
        "Overriding the MEDIA_URL setting should be reflected"
    ],
    [
        "Overriding the FILE_UPLOAD_PERMISSIONS setting should be reflected in",
        "Overriding the FILE_UPLOAD_PERMISSIONS setting should be"
    ],
    [
        "Overriding the FILE_UPLOAD_DIRECTORY_PERMISSIONS setting should be",
        "Overriding the FILE_UPLOAD_DIRECTORY_PERMISSIONS setting"
    ],
    [
        "reflected in the directory_permissions_mode attribute of",
        "reflected in the directory_permissions_mode"
    ],
    [
        "Overriding DATABASE_ROUTERS should update the base router.",
        "Overriding DATABASE_ROUTERS should update the base"
    ],
    [
        "Overriding the STATIC_URL setting should be reflected in the",
        "Overriding the STATIC_URL setting should be reflected in"
    ],
    [
        "Overriding the STATIC_ROOT setting should be reflected in the",
        "Overriding the STATIC_ROOT setting should be reflected in"
    ],
    [
        "Overriding the STORAGES setting should be reflected in",
        "Overriding the STORAGES setting"
    ],
    [
        "Overriding the STATICFILES_FINDERS setting should be reflected in",
        "Overriding the STATICFILES_FINDERS setting"
    ],
    [
        "Overriding the STATICFILES_DIRS setting should be reflected in",
        "Overriding the STATICFILES_DIRS setting should be"
    ],
    [
        "An exception in setUpTestData() shouldn't leak a transaction which would",
        "An exception in setUpTestData() shouldn't"
    ],
    [
        "cascade across the rest of the test suite.",
        "cascade across the rest of"
    ],
    [
        "A visualisation of the callback tree tested. Each node is expected to",
        "A visualisation of the callback tree tested."
    ],
    [
        "\"Database connections to 'default' are not allowed in SimpleTestCase \"",
        "\"Database connections to 'default' are not allowed in"
    ],
    [
        "\"subclasses. Either subclass TestCase or TransactionTestCase to \"",
        "\"subclasses. Either subclass TestCase or"
    ],
    [
        "\"ensure proper test isolation or add 'default' to \"",
        "\"ensure proper test isolation or add"
    ],
    [
        "\"Database queries to 'default' are not allowed in SimpleTestCase \"",
        "\"Database queries to 'default' are not allowed"
    ],
    [
        "\"subclasses. Either subclass TestCase or TransactionTestCase to \"",
        "\"subclasses. Either subclass TestCase or TransactionTestCase to"
    ],
    [
        "\"ensure proper test isolation or add 'default' to \"",
        "\"ensure proper test isolation or add 'default' to"
    ],
    [
        "\"Database queries to 'default' are not allowed in SimpleTestCase \"",
        "\"Database queries to 'default' are not allowed in"
    ],
    [
        "\"subclasses. Either subclass TestCase or TransactionTestCase to \"",
        "\"subclasses. Either subclass TestCase"
    ],
    [
        "\"ensure proper test isolation or add 'default' to \"",
        "\"ensure proper test isolation or add 'default'"
    ],
    [
        "\"Database threaded connections to 'default' are not allowed in \"",
        "\"Database threaded connections to 'default'"
    ],
    [
        "\"SimpleTestCase subclasses. Either subclass TestCase or TransactionTestCase\"",
        "\"SimpleTestCase subclasses. Either subclass"
    ],
    [
        "\" to ensure proper test isolation or add 'default' to \"",
        "\" to ensure proper test isolation or add 'default' to"
    ],
    [
        "if conn is not connection and conn.allow_thread_sharing:",
        "if conn is not connection"
    ],
    [
        "\"test_utils.tests.DatabaseAliasTests.databases refers to 'void' which is \"",
        "\"test_utils.tests.DatabaseAliasTests.databases refers to 'void' which"
    ],
    [
        "\"test_utils.tests.DatabaseAliasTests.databases refers to 'defualt' which \"",
        "\"test_utils.tests.DatabaseAliasTests.databases refers to"
    ],
    [
        "\"is not defined in settings.DATABASES. Did you mean 'default'?\"",
        "\"is not defined in settings.DATABASES. Did"
    ],
    [
        "\"\"\"An exception is setUp() is reraised after disable() is called.\"\"\"",
        "\"\"\"An exception is setUp() is reraised"
    ],
    [
        "template = Template(\"This is a string-based template\")",
        "template = Template(\"This is a"
    ],
    [
        "Upload handlers to test the upload API.",
        "Upload handlers to test the"
    ],
    [
        "This test upload handler terminates the connection if more than a quota",
        "This test upload handler terminates the connection if more than"
    ],
    [
        "\"\"\"A handler that raises a StopUpload exception.\"\"\"",
        "\"\"\"A handler that raises"
    ],
    [
        "\"\"\"A handler that raises an exception.\"\"\"",
        "\"\"\"A handler that raises an"
    ],
    [
        "\"\"\"A handler with potential directory-traversal vulnerability.\"\"\"",
        "\"\"\"A handler with potential directory-traversal"
    ],
    [
        "with open(os.path.join(self.upload_dir, self.file_name), \"wb\") as fp:",
        "with open(os.path.join(self.upload_dir, self.file_name),"
    ],
    [
        "from django.core.files import temp as tempfile",
        "from django.core.files import temp as"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, client, override_settings",
        "from django.test import SimpleTestCase, TestCase, client,"
    ],
    [
        "Receiving file upload when filename is blank (before and after",
        "Receiving file upload when filename is blank (before"
    ],
    [
        "\"\"\"Uploaded file names should be sanitized before ever reaching the view.\"\"\"",
        "\"\"\"Uploaded file names should be sanitized"
    ],
    [
        "for name, filename, _ in cases:",
        "for name, filename, _ in"
    ],
    [
        "for name, _, expected in cases:",
        "for name, _,"
    ],
    [
        "\"\"\"Uploaded files may have content type parameters available.\"\"\"",
        "\"\"\"Uploaded files may have content type parameters"
    ],
    [
        "If passed an incomplete multipart message, MultiPartParser does not",
        "If passed an incomplete multipart message, MultiPartParser does"
    ],
    [
        "attempt to read beyond the end of the stream, and simply will handle",
        "attempt to read beyond the end of"
    ],
    [
        "the part that can be parsed gracefully.",
        "the part that can be parsed"
    ],
    [
        "\"file contents\" \"--\" + client.BOUNDARY + \"--\",",
        "\"file contents\" \"--\" +"
    ],
    [
        "If passed an empty multipart message, MultiPartParser will return",
        "If passed an empty multipart"
    ],
    [
        "with file() as smallfile, file() as bigfile:",
        "with file() as smallfile, file()"
    ],
    [
        "\"You cannot alter upload handlers after the upload has been processed.\"",
        "\"You cannot alter upload handlers after"
    ],
    [
        "This can happen if something -- i.e. an exception handler -- tries to",
        "This can happen if something -- i.e. an"
    ],
    [
        "access POST while handling an error in parsing POST. This shouldn't",
        "access POST while handling an error in parsing POST."
    ],
    [
        "\"\"\"A handler that'll access POST during an exception.\"\"\"",
        "\"\"\"A handler that'll access POST during an"
    ],
    [
        "\"Caught a repeated exception that'll cause an infinite loop in \"",
        "\"Caught a repeated exception that'll cause an infinite"
    ],
    [
        "The storage backend shouldn't mess with the case of the filenames",
        "The storage backend shouldn't mess with the"
    ],
    [
        "Tests for error handling during directory creation",
        "Tests for error handling during"
    ],
    [
        "msg = \"%s exists and is not a directory.\" % UPLOAD_TO",
        "msg = \"%s exists and is"
    ],
    [
        "from django.http import HttpResponse, HttpResponseServerError, JsonResponse",
        "from django.http import HttpResponse,"
    ],
    [
        "A file upload can be updated into the POST dictionary.",
        "A file upload can be updated into the POST"
    ],
    [
        "Use the sha digest hash to verify the uploaded contents.",
        "Use the sha digest hash to verify the"
    ],
    [
        "if key + \"_hash\" not in form_data:",
        "if key + \"_hash\""
    ],
    [
        "Simple view to echo back info about uploaded files for tests.",
        "Simple view to echo back info"
    ],
    [
        "r = {k: f.name for k, f in request.FILES.items()}",
        "r = {k: f.name for k, f"
    ],
    [
        "Simple view to echo back the content of uploaded files for tests.",
        "Simple view to echo back the content of"
    ],
    [
        "r = {k: read_and_close(f) for k, f in request.FILES.items()}",
        "r = {k: read_and_close(f) for k, f in"
    ],
    [
        "Dynamically add in an upload handler.",
        "Dynamically add in an"
    ],
    [
        "You can't change handlers after reading FILES; this view shouldn't work.",
        "You can't change handlers after reading FILES;"
    ],
    [
        "Check the .getlist() function to ensure we receive the correct number of files.",
        "Check the .getlist() function to ensure we receive the correct number of"
    ],
    [
        "Check adding the file to the database will preserve the filename case.",
        "Check adding the file to the database will preserve"
    ],
    [
        "Simple view to echo back extra content-type parameters.",
        "Simple view to echo back extra"
    ],
    [
        "k: v.decode() for k, v in uploadedfile.content_type_extra.items()",
        "k: v.decode() for k, v in"
    ],
    [
        "``DoesNotExist`` exception was raised during the ``get()`` call.",
        "``DoesNotExist`` exception was raised during"
    ],
    [
        "``DoesNotExist`` exception was raised during the ``filter()`` call.",
        "``DoesNotExist`` exception was raised during"
    ],
    [
        "\"\"\"AttributeError raised by QuerySet.get() isn't hidden.\"\"\"",
        "\"\"\"AttributeError raised by QuerySet.get() isn't"
    ],
    [
        "\"\"\"AttributeError raised by QuerySet.filter() isn't hidden.\"\"\"",
        "\"\"\"AttributeError raised by"
    ],
    [
        "raise ValueError(\"FailingEmailBackend is doomed to fail.\")",
        "raise ValueError(\"FailingEmailBackend is doomed"
    ],
    [
        "Test the sending of a test email using the `sendtestemail` command.",
        "Test the sending of a test email"
    ],
    [
        "The mail is sent with the correct subject and recipient.",
        "The mail is sent with the correct subject and"
    ],
    [
        "The mail may be sent with multiple recipients.",
        "The mail may be"
    ],
    [
        "The command should complain if no receivers are given (and --admins or",
        "The command should complain if no"
    ],
    [
        "\"You must specify some email recipients, or pass the --managers or \"",
        "\"You must specify some email recipients, or"
    ],
    [
        "The mail should be sent to the email addresses specified in",
        "The mail should be sent to the email"
    ],
    [
        "The mail should be sent to the email addresses specified in",
        "The mail should be sent to the"
    ],
    [
        "The mail should be sent to the email addresses specified in both",
        "The mail should be sent to the email addresses"
    ],
    [
        "from email import message_from_bytes as _message_from_bytes",
        "from email import message_from_bytes"
    ],
    [
        "from email.message import EmailMessage as PyEmailMessage",
        "from email.message import EmailMessage as"
    ],
    [
        "from email.message import Message as PyMessage",
        "from email.message import Message as"
    ],
    [
        "from django.core.mail.backends import console, dummy, filebased, locmem, smtp",
        "from django.core.mail.backends import console,"
    ],
    [
        "Asserts that the `message` has all `headers`.",
        "Asserts that the `message`"
    ],
    [
        "message: can be an instance of an email.Message subclass or bytes",
        "message: can be an instance of an email.Message subclass or"
    ],
    [
        "with the contents of an email message.",
        "with the contents of"
    ],
    [
        "headers: should be a set of (header-name, header-value) tuples.",
        "headers: should be a set of (header-name,"
    ],
    [
        "missing = \"\\n\".join(f\"  {h}: {v}\" for h, v in headers - msg_headers)",
        "missing = \"\\n\".join(f\" {h}: {v}\" for h, v"
    ],
    [
        "actual = \"\\n\".join(f\"  {h}: {v}\" for h, v in msg_headers)",
        "actual = \"\\n\".join(f\" {h}: {v}\" for"
    ],
    [
        "f\"Expected headers not found in message.\\n\"",
        "f\"Expected headers not found"
    ],
    [
        "else first[:max_len] + (\"…\" if isinstance(first, str) else b\"...\")",
        "else first[:max_len] + (\"…\" if isinstance(first, str) else"
    ],
    [
        "\"First string doesn't start with the second.\",",
        "\"First string doesn't start"
    ],
    [
        "else (\"…\" if isinstance(first, str) else b\"...\") + first[-max_len:]",
        "else (\"…\" if isinstance(first, str) else b\"...\")"
    ],
    [
        "\"First string doesn't end with the second.\",",
        "\"First string doesn't end with the"
    ],
    [
        "Return a list of the raw attachment parts in the MIME message generated",
        "Return a list of the raw attachment parts"
    ],
    [
        "by serializing django_message and reparsing the result.",
        "by serializing django_message and reparsing"
    ],
    [
        "This returns only \"top-level\" attachments. It will not descend into",
        "This returns only \"top-level\" attachments. It will"
    ],
    [
        "message/* attached emails to find nested attachments.",
        "message/* attached emails to find"
    ],
    [
        "Return a list of decoded attachments resulting from serializing",
        "Return a list of decoded attachments"
    ],
    [
        "Each attachment is returned as an EmailAttachment named tuple with",
        "Each attachment is returned as"
    ],
    [
        "fields filename, content, and mimetype. The content will be decoded",
        "fields filename, content, and mimetype. The"
    ],
    [
        "to str for mimetype text/*; retained as bytes for other mimetypes.",
        "to str for mimetype text/*; retained as"
    ],
    [
        "Return a multiline indented string representation",
        "Return a multiline"
    ],
    [
        "of the message's MIME content-type structure, e.g.:",
        "of the message's MIME"
    ],
    [
        "\"\"\"Line length check should encode the payload supporting `surrogateescape`.",
        "\"\"\"Line length check should encode"
    ],
    [
        "payload is encoded with the provided charset and `surrogateescape` is",
        "payload is encoded with the provided"
    ],
    [
        "used as the error handling strategy.",
        "used as the error handling"
    ],
    [
        "This test is heavily based on the test from the fix for the bug above.",
        "This test is heavily based on the test from the fix"
    ],
    [
        "Line length checks in SafeMIMEText's set_payload should also use the",
        "Line length checks in SafeMIMEText's"
    ],
    [
        "same error handling strategy to avoid errors such as:",
        "same error handling strategy to avoid errors"
    ],
    [
        "\"Text heavily based in Python's text for non-ascii messages: Föö bär\"",
        "\"Text heavily based in Python's text for"
    ],
    [
        "email = EmailMessage(\"Subject\", body, \"from@example.com\", [\"to@example.com\"])",
        "email = EmailMessage(\"Subject\", body, \"from@example.com\","
    ],
    [
        "Empty strings in various recipient arguments are always stripped",
        "Empty strings in various recipient arguments are"
    ],
    [
        "A bcc address should be in the recipients,",
        "A bcc address should be in the"
    ],
    [
        "but not in the (visible) message headers.",
        "but not in the (visible) message"
    ],
    [
        "TypeError, '\"to\" argument must be a list or tuple'",
        "TypeError, '\"to\" argument must be a list"
    ],
    [
        "TypeError, '\"cc\" argument must be a list or tuple'",
        "TypeError, '\"cc\" argument must be a"
    ],
    [
        "TypeError, '\"bcc\" argument must be a list or tuple'",
        "TypeError, '\"bcc\" argument must be a list"
    ],
    [
        "TypeError, '\"reply_to\" argument must be a list or tuple'",
        "TypeError, '\"reply_to\" argument must be a"
    ],
    [
        "msg = \"Header values can't contain newlines \"",
        "msg = \"Header values can't contain newlines"
    ],
    [
        "\"Long subject lines that get wrapped should contain a space continuation \"",
        "\"Long subject lines that get wrapped should contain a space continuation"
    ],
    [
        "\"character to get expected behavior in Outlook and Thunderbird\",",
        "\"character to get expected behavior in Outlook"
    ],
    [
        "b\"Long subject lines that get wrapped should contain a space continuation\\n\"",
        "b\"Long subject lines that get wrapped should"
    ],
    [
        "b\" character to get expected behavior in Outlook and Thunderbird\",",
        "b\" character to get expected behavior in Outlook"
    ],
    [
        "Specifying dates or message-ids in the extra headers overrides the",
        "Specifying dates or message-ids in the extra headers overrides"
    ],
    [
        "Specifying 'Reply-To' in headers should override reply_to.",
        "Specifying 'Reply-To' in headers"
    ],
    [
        "make sure the email addresses are parsed correctly (especially with",
        "make sure the email addresses are parsed"
    ],
    [
        "text_content = \"This is an important message.\"",
        "text_content = \"This is an"
    ],
    [
        "html_content = \"<p>This is an <strong>important</strong> message.</p>\"",
        "html_content = \"<p>This is an <strong>important</strong>"
    ],
    [
        "EmailMultiAlternatives includes alternatives if the body is empty and",
        "EmailMultiAlternatives includes alternatives if the body is"
    ],
    [
        "msg = EmailMessage(\"subject\", None, \"from@example.com\", [\"to@example.com\"])",
        "msg = EmailMessage(\"subject\","
    ],
    [
        "email = EmailMessage(body=\"Firstname Sürname is a great guy.\")",
        "email = EmailMessage(body=\"Firstname Sürname is a"
    ],
    [
        "self.assertEqual(message.get_payload(), \"Firstname S=FCrname is a great guy.\")",
        "self.assertEqual(message.get_payload(), \"Firstname S=FCrname is"
    ],
    [
        "text_content = \"Firstname Sürname is a great guy.\"",
        "text_content = \"Firstname Sürname is a great"
    ],
    [
        "html_content = \"<p>Firstname Sürname is a <strong>great</strong> guy.</p>\"",
        "html_content = \"<p>Firstname Sürname is a <strong>great</strong>"
    ],
    [
        "b\"\\n\\n<p>Firstname S=FCrname is a <strong>great</strong> guy.</p>\",",
        "b\"\\n\\n<p>Firstname S=FCrname is"
    ],
    [
        "The mimetype can be omitted from an attachment tuple.",
        "The mimetype can be omitted"
    ],
    [
        "text_content = \"This is an important message.\"",
        "text_content = \"This is"
    ],
    [
        "html_content = \"<p>This is an <strong>important</strong> message.</p>\"",
        "html_content = \"<p>This is"
    ],
    [
        "Test attaching a file against different mimetypes and make sure that",
        "Test attaching a file against different mimetypes and"
    ],
    [
        "a file will be attached and sent in some form even if a mismatched",
        "a file will be attached and sent"
    ],
    [
        "file_path = Path(__file__).parent / \"attachments\" / basename",
        "file_path = Path(__file__).parent / \"attachments\""
    ],
    [
        "in a form that can be decoded at the receiving end.",
        "in a form that can be"
    ],
    [
        "EmailMessage.attach() docs: \"You can pass it",
        "EmailMessage.attach() docs: \"You can"
    ],
    [
        "a single argument that is a MIMEBase instance.\"",
        "a single argument that is a"
    ],
    [
        "it will also accept django.core.mail.EmailMessage and email.message.Message.\"",
        "it will also accept django.core.mail.EmailMessage"
    ],
    [
        "django_email = EmailMessage(\"child subject\", \"child body\")",
        "django_email = EmailMessage(\"child"
    ],
    [
        "email = EmailMessage(\"parent message\", \"parent body\")",
        "email = EmailMessage(\"parent message\","
    ],
    [
        "\"content and mimetype must not be given when a MIMEBase instance \"",
        "\"content and mimetype must not be given when a"
    ],
    [
        "msg = \"content must be provided.\"",
        "msg = \"content must be"
    ],
    [
        "Make sure that dummy backends returns correct number of sent messages",
        "Make sure that dummy backends returns correct number"
    ],
    [
        "Make sure that get_connection() accepts arbitrary keyword that might be",
        "Make sure that get_connection() accepts arbitrary keyword"
    ],
    [
        "\"\"\"Test custom backend defined in this suite.\"\"\"",
        "\"\"\"Test custom backend defined in"
    ],
    [
        "\"\"\"Test connection argument to send_mail(), et. al.\"\"\"",
        "\"\"\"Test connection argument to send_mail(),"
    ],
    [
        "msg = EmailMessage(body=\"Body with only ASCII characters.\")",
        "msg = EmailMessage(body=\"Body with"
    ],
    [
        "msg = EmailMessage(body=\"Body with latin characters: àáä.\")",
        "msg = EmailMessage(body=\"Body with"
    ],
    [
        "\"Body with non latin characters: А Б В Г Д Е Ж Ѕ З И І К Л М Н О П.\",",
        "\"Body with non latin characters: А Б В Г Д Е Ж Ѕ З И І К Л М Н"
    ],
    [
        "body = \"Body with latin characters: àáä.\"",
        "body = \"Body with latin characters:"
    ],
    [
        "msg = EmailMessage(\"Subject\", body, \"bounce@example.com\", [\"to@example.com\"])",
        "msg = EmailMessage(\"Subject\", body,"
    ],
    [
        "for email_address, encoding, expected_result in (",
        "for email_address, encoding, expected_result in"
    ],
    [
        "((\"A name\", \"to@example.com\"), \"ascii\", \"A name <to@example.com>\"),",
        "((\"A name\", \"to@example.com\"), \"ascii\","
    ],
    [
        "(\"A name <to@example.com>\", \"ascii\", \"A name <to@example.com>\"),",
        "(\"A name <to@example.com>\", \"ascii\","
    ],
    [
        "('\"A name\" <to@example.com>', \"ascii\", \"A name <to@example.com>\"),",
        "('\"A name\" <to@example.com>', \"ascii\", \"A name"
    ],
    [
        "\"To Example very longTo Example very longTo Example very longT\"",
        "\"To Example very longTo Example"
    ],
    [
        "msg = \"Invalid address; address parts cannot contain newlines.\"",
        "msg = \"Invalid address; address parts cannot contain"
    ],
    [
        "msg = \"Both content and mimetype must be provided.\"",
        "msg = \"Both content and mimetype must"
    ],
    [
        "Check generated messages have the expected MIME parts and nesting.",
        "Check generated messages have the expected MIME parts and"
    ],
    [
        "for name, email, expected in cases:",
        "for name, email, expected in"
    ],
    [
        "EmailMessage class docs: \"All parameters are optional\"",
        "EmailMessage class docs: \"All"
    ],
    [
        "EmailMessage class docs: \"… is initialized with the following parameters",
        "EmailMessage class docs: \"… is initialized with the"
    ],
    [
        "(in the given order, if positional arguments are used).\"",
        "(in the given order, if positional arguments are"
    ],
    [
        "EmailMessage class docs: \"All parameters … can be set at any time",
        "EmailMessage class docs: \"All parameters … can be set"
    ],
    [
        "prior to calling the send() method.\"",
        "prior to calling the"
    ],
    [
        "EMAIL_USE_LOCALTIME=False creates a datetime in UTC.",
        "EMAIL_USE_LOCALTIME=False creates a datetime"
    ],
    [
        "EMAIL_USE_LOCALTIME=True creates a datetime in the local time zone.",
        "EMAIL_USE_LOCALTIME=True creates a datetime in the local time"
    ],
    [
        "parts shouldn't pollute global email Python package charset registry when",
        "parts shouldn't pollute global email Python package charset"
    ],
    [
        "\"Body with non latin characters: А Б В Г Д Е Ж Ѕ З И І К Л М Н О П.\",",
        "\"Body with non latin characters: А Б В Г Д Е Ж Ѕ З"
    ],
    [
        "\"subclasses of BaseEmailBackendTests must provide a get_mailbox_content() \"",
        "\"subclasses of BaseEmailBackendTests must"
    ],
    [
        "\"subclasses of BaseEmailBackendTests may require a flush_mailbox() method\"",
        "\"subclasses of BaseEmailBackendTests may require"
    ],
    [
        "\"Expected exactly one message, got %d.\\n%r\"",
        "\"Expected exactly one"
    ],
    [
        "% (len(mailbox), [m.as_string() for m in mailbox]),",
        "% (len(mailbox), [m.as_string() for"
    ],
    [
        "\"Chère maman\", \"Je t'aime très fort\", \"from@example.com\", [\"to@example.com\"]",
        "\"Chère maman\", \"Je t'aime"
    ],
    [
        "Message body containing longer lines are converted to Quoted-Printable",
        "Message body containing longer lines are converted to"
    ],
    [
        "to avoid having to insert newlines, which could be hairy to do properly.",
        "to avoid having to insert newlines, which"
    ],
    [
        "regression test for adding html_message parameter to send_mail()",
        "regression test for adding html_message"
    ],
    [
        "String prefix + lazy translated subject = bad output",
        "String prefix + lazy translated"
    ],
    [
        "mail_admins/mail_managers doesn't connect to the mail server",
        "mail_admins/mail_managers doesn't connect to the mail"
    ],
    [
        "Connection can be closed (even when not explicitly opened)",
        "Connection can be closed (even when not explicitly"
    ],
    [
        "The connection can be used as a contextmanager.",
        "The connection can be used"
    ],
    [
        "return [message_from_bytes(m.message().as_bytes()) for m in mail.outbox]",
        "return [message_from_bytes(m.message().as_bytes()) for m in"
    ],
    [
        "Make sure that the locmen backend populates the outbox.",
        "Make sure that the locmen backend"
    ],
    [
        "with open(os.path.join(self.tmp_dir, filename), \"rb\") as fp:",
        "with open(os.path.join(self.tmp_dir, filename), \"rb\")"
    ],
    [
        "messages.extend(message_from_bytes(m) for m in session if m)",
        "messages.extend(message_from_bytes(m) for m in session if"
    ],
    [
        "\"\"\"Make sure opening a connection creates a new file\"\"\"",
        "\"\"\"Make sure opening a connection"
    ],
    [
        "return [message_from_bytes(m.encode()) for m in messages if m]",
        "return [message_from_bytes(m.encode()) for m"
    ],
    [
        "The console backend can be pointed at an arbitrary stream.",
        "The console backend can be pointed at an arbitrary"
    ],
    [
        "async def handle_DATA(self, server, session, envelope):",
        "async def handle_DATA(self, server,"
    ],
    [
        "Opening the backend with non empty username/password tries",
        "Opening the backend with non"
    ],
    [
        "to authenticate against the SMTP server.",
        "to authenticate against"
    ],
    [
        "username=\"not empty username\", password=\"not empty password\"",
        "username=\"not empty username\","
    ],
    [
        "SMTPException, \"SMTP AUTH extension not supported by server.\"",
        "SMTPException, \"SMTP AUTH extension not supported by"
    ],
    [
        "open() returns whether it opened a connection.",
        "open() returns whether it opened a"
    ],
    [
        "\"EMAIL_USE_TLS/EMAIL_USE_SSL are mutually exclusive, so only set \"",
        "\"EMAIL_USE_TLS/EMAIL_USE_SSL are mutually exclusive, so only set"
    ],
    [
        "\"one of those settings to True.\"",
        "\"one of those"
    ],
    [
        "SMTPException, \"STARTTLS extension not supported by server.\"",
        "SMTPException, \"STARTTLS extension not supported by"
    ],
    [
        "\"\"\"The connection's timeout value is None by default.\"\"\"",
        "\"\"\"The connection's timeout value is"
    ],
    [
        "\"\"\"The timeout parameter can be customized.\"\"\"",
        "\"\"\"The timeout parameter can be"
    ],
    [
        "send_messages() shouldn't try to send messages if open() raises an",
        "send_messages() shouldn't try to send messages"
    ],
    [
        "\"\"\"A message isn't sent if it doesn't have any recipients.\"\"\"",
        "\"\"\"A message isn't sent if it"
    ],
    [
        "email = EmailMessage(\"Subject\", \"Content\", \"from@example.com\", to=[])",
        "email = EmailMessage(\"Subject\", \"Content\","
    ],
    [
        "Verify invalid addresses can't sneak into SMTP commands through",
        "Verify invalid addresses can't sneak into"
    ],
    [
        "EmailMessage.all_recipients() (which is distinct from message header fields).",
        "EmailMessage.all_recipients() (which is distinct from"
    ],
    [
        "SMTP backend must encode non-ASCII domains for the SMTP envelope",
        "SMTP backend must encode non-ASCII domains"
    ],
    [
        "(which can be distinct from the email headers).",
        "(which can be distinct from the email"
    ],
    [
        "it for addresses that have been pre-encoded.",
        "it for addresses that have been"
    ],
    [
        "Closing the backend while the SMTP server is stopped doesn't raise an",
        "Closing the backend while the SMTP server is"
    ],
    [
        "A socket connection error is silenced with fail_silently=True.",
        "A socket connection error"
    ],
    [
        "from django.contrib.auth.models import Group, Permission, User",
        "from django.contrib.auth.models import Group,"
    ],
    [
        "from django.test.utils import captured_stdin, captured_stdout, override_settings",
        "from django.test.utils import"
    ],
    [
        "script_globals = 'print(\"__name__\" in globals() and \"Phone\" in globals())'",
        "script_globals = 'print(\"__name__\" in globals() and \"Phone\" in"
    ],
    [
        "\"import django; from logging import getLogger; \"",
        "\"import django; from logging"
    ],
    [
        "with captured_stdin() as stdin, captured_stdout() as stdout:",
        "with captured_stdin() as stdin, captured_stdout() as"
    ],
    [
        "\"Windows select() doesn't support file descriptors.\",",
        "\"Windows select() doesn't support"
    ],
    [
        "with captured_stdin() as stdin, captured_stdout() as stdout:",
        "with captured_stdin() as stdin,"
    ],
    [
        "\"Windows select() doesn't support file descriptors.\",",
        "\"Windows select() doesn't support"
    ],
    [
        "with captured_stdin() as stdin, captured_stdout() as stdout:",
        "with captured_stdin() as stdin,"
    ],
    [
        "\"  from shell.models import Phone, Marker\\n\"",
        "\" from shell.models"
    ],
    [
        "\"  from django.urls import reverse, resolve\",",
        "\" from django.urls import reverse,"
    ],
    [
        "\"  from shell.models import Marker, Phone\\n\\n\"",
        "\" from shell.models import Marker,"
    ],
    [
        "Regression tests for proper working of ForeignKey(null=True). Tests these bugs:",
        "Regression tests for proper working of ForeignKey(null=True). Tests"
    ],
    [
        "from .models import Article, Author, Comment, Forum, Post, SystemInfo",
        "from .models import Article, Author, Comment, Forum, Post,"
    ],
    [
        "ordering across nullable Foreign Keys shouldn't exclude results",
        "ordering across nullable Foreign"
    ],
    [
        "\"Test cases can load fixture objects into models defined in packages\"",
        "\"Test cases can load fixture objects"
    ],
    [
        "\"Copyright is fine the way it is\",",
        "\"Copyright is fine the way it"
    ],
    [
        "\"Poker has no place on ESPN\",",
        "\"Poker has no place"
    ],
    [
        "\"Fixtures can load data into models defined in packages\"",
        "\"Fixtures can load data into"
    ],
    [
        "\"Poker has no place on ESPN\",",
        "\"Poker has no"
    ],
    [
        "\"Copyright is fine the way it is\",",
        "\"Copyright is fine the"
    ],
    [
        "\"Poker has no place on ESPN\",",
        "\"Poker has no"
    ],
    [
        "CommandError, \"No fixture named 'unknown' found.\"",
        "CommandError, \"No fixture named"
    ],
    [
        "\"Copyright is fine the way it is\",",
        "\"Copyright is fine the way it"
    ],
    [
        "\"Poker has no place on ESPN\",",
        "\"Poker has no place on"
    ],
    [
        "Can't reuse ChoiceModel because error_message tests require that it have no",
        "Can't reuse ChoiceModel because error_message tests"
    ],
    [
        "\"\"\"Model with ForeignKey to another model, for testing ModelForm",
        "\"\"\"Model with ForeignKey to another"
    ],
    [
        "self.assertWidgetRendersTo(f, '<input type=\"url\" name=\"f\" id=\"id_f\" required>')",
        "self.assertWidgetRendersTo(f, '<input type=\"url\""
    ],
    [
        "msg = \"'Enter a valid URL.'\"",
        "msg = \"'Enter a valid"
    ],
    [
        "msg = \"'This field is required.'\"",
        "msg = \"'This"
    ],
    [
        "msg = \"got multiple values for keyword argument 'strip'\"",
        "msg = \"got multiple values for keyword"
    ],
    [
        "from django.forms import CharField, HiddenInput, PasswordInput, Textarea, TextInput",
        "from django.forms import CharField, HiddenInput, PasswordInput, Textarea,"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "Setting min_length or max_length to something that is not a number",
        "Setting min_length or max_length to something that is not a"
    ],
    [
        "CharField.widget_attrs() always returns a dictionary and includes",
        "CharField.widget_attrs() always returns a dictionary and"
    ],
    [
        "minlength/maxlength if min_length/max_length are defined on the field",
        "minlength/maxlength if min_length/max_length are defined on"
    ],
    [
        "and the widget is not hidden.",
        "and the widget is not"
    ],
    [
        "Values have whitespace stripped but not if strip=False.",
        "Values have whitespace stripped but not"
    ],
    [
        "A whitespace-only value, ' ', is stripped to an empty string and then",
        "A whitespace-only value, ' ', is stripped to an"
    ],
    [
        "converted to the empty value, None.",
        "converted to the empty value,"
    ],
    [
        "\"\"\"CharField.clean() calls str(value) before stripping it.\"\"\"",
        "\"\"\"CharField.clean() calls str(value) before"
    ],
    [
        "f, '<input type=\"text\" name=\"f\" id=\"id_f\" disabled required>'",
        "f, '<input type=\"text\" name=\"f\""
    ],
    [
        "msg = \"Null characters are not allowed.\"",
        "msg = \"Null characters"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a list of values.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a list"
    ],
    [
        "ValidationError, \"'Enter a valid date.', 'Enter a valid time.'\"",
        "ValidationError, \"'Enter a valid date.', 'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid time.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a list of values.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a list of"
    ],
    [
        "ValidationError, \"'Enter a valid date.', 'Enter a valid time.'\"",
        "ValidationError, \"'Enter a valid date.', 'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid time.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid time.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid time.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "f = TypedChoiceField(choices=[(\"A\", \"A\"), (\"B\", \"B\")], coerce=int)",
        "f = TypedChoiceField(choices=[(\"A\", \"A\"), (\"B\", \"B\")],"
    ],
    [
        "msg = \"'Select a valid choice. B is not one of the available choices.'\"",
        "msg = \"'Select a valid choice. B"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "choices=[(\"\", \"---------\"), (\"a\", \"a\"), (\"b\", \"b\")],",
        "choices=[(\"\", \"---------\"), (\"a\","
    ],
    [
        "A coerce function which results in a value not present in choices",
        "A coerce function which results in a value not present"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "ValidationError, \"'Enter a valid email address.'\"",
        "ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"Enter a valid email address.\"):",
        "with self.assertRaisesMessage(ValidationError, \"Enter a valid"
    ],
    [
        "\"example@example.com\", f.clean(\"      example@example.com  \\t   \\t \")",
        "\"example@example.com\", f.clean(\" example@example.com \\t"
    ],
    [
        "ValidationError, \"'Enter a valid email address.'\"",
        "ValidationError, \"'Enter a valid email"
    ],
    [
        "msg = \"got multiple values for keyword argument 'strip'\"",
        "msg = \"got multiple values for keyword argument"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"Enter a valid UUID.\"):",
        "with self.assertRaisesMessage(ValidationError, \"Enter a"
    ],
    [
        "from django.forms import CharField, ComboField, EmailField",
        "from django.forms import"
    ],
    [
        "ValidationError, \"'Enter a valid email address.'\"",
        "ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "ValidationError, \"'Enter a valid email address.'\"",
        "ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a list of values.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a list of values.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a list of"
    ],
    [
        "return [fix_os_paths(y) for y in x]",
        "return [fix_os_paths(y) for"
    ],
    [
        "path = os.path.join(PATH, \"filepathfield_test_dir\") + \"/\"",
        "path = os.path.join(PATH,"
    ],
    [
        "msg = \"'Select a valid choice. a.py is not one of the available choices.'\"",
        "msg = \"'Select a valid choice. a.py is not"
    ],
    [
        "f, '<input step=\"any\" type=\"number\" name=\"f\" id=\"id_f\" required>'",
        "f, '<input step=\"any\" type=\"number\""
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "A localized FloatField's widget renders to a text input without any",
        "A localized FloatField's widget renders to"
    ],
    [
        "self.assertWidgetRendersTo(f, '<input id=\"id_f\" name=\"f\" type=\"text\" required>')",
        "self.assertWidgetRendersTo(f, '<input id=\"id_f\""
    ],
    [
        "Rendered widget allows non-integer value with the client-side",
        "Rendered widget allows non-integer"
    ],
    [
        "beatles = ((\"J\", \"John\"), (\"P\", \"Paul\"), (\"G\", \"George\"), (\"R\", \"Ringo\"))",
        "beatles = ((\"J\", \"John\"), (\"P\", \"Paul\"), (\"G\", \"George\"), (\"R\","
    ],
    [
        "return \",\".join(data_list) if data_list else None",
        "return \",\".join(data_list) if"
    ],
    [
        "msg = \"'Select a valid choice. X is not one of the available choices.'\"",
        "msg = \"'Select a valid choice. X is not one of the"
    ],
    [
        "If insufficient data is provided, None is substituted.",
        "If insufficient data is provided, None"
    ],
    [
        "msg = \"'This field is required.'\"",
        "msg = \"'This field is"
    ],
    [
        "Test when the first widget's data has changed.",
        "Test when the first widget's"
    ],
    [
        "Test when the last widget's data has changed. This ensures that it is",
        "Test when the last widget's data has changed."
    ],
    [
        "not short circuiting while testing the widgets.",
        "not short circuiting while testing the"
    ],
    [
        "f, '<input type=\"number\" name=\"f\" id=\"id_f\" required>'",
        "f, '<input type=\"number\" name=\"f\" id=\"id_f\""
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a whole number.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a whole number.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a whole number.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a whole number.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a whole number.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "A localized IntegerField's widget renders to a text input without any",
        "A localized IntegerField's widget renders to a text"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a whole number.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a whole"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a whole number.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "f = TypedMultipleChoiceField(choices=[(\"A\", \"A\"), (\"B\", \"B\")], coerce=int)",
        "f = TypedMultipleChoiceField(choices=[(\"A\", \"A\"), (\"B\","
    ],
    [
        "msg = \"'Select a valid choice. B is not one of the available choices.'\"",
        "msg = \"'Select a valid choice. B is not one of the available"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "A coerce function which results in a value not present in choices",
        "A coerce function which results in a value not present"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "no_file_msg = \"'No file was submitted. Check the encoding type on the form.'\"",
        "no_file_msg = \"'No file was submitted. Check the encoding type on"
    ],
    [
        "f.clean(\"some content that is not a file\")",
        "f.clean(\"some content that is not a"
    ],
    [
        "ValidationError, \"'The submitted file is empty.'\"",
        "ValidationError, \"'The submitted file"
    ],
    [
        "ValidationError, \"'The submitted file is empty.'\"",
        "ValidationError, \"'The submitted"
    ],
    [
        "\"मेरी मँडराने वाली नाव सर्पमीनों से भरी ह\".encode(),",
        "\"मेरी मँडराने वाली नाव"
    ],
    [
        "The value of data will more than likely come from request.FILES. The",
        "The value of data will more than likely"
    ],
    [
        "value of initial data will likely be a filename stored in the database.",
        "value of initial data will likely be a"
    ],
    [
        "Since its value is of no use to a FileField it is ignored.",
        "Since its value is of no use"
    ],
    [
        "f.has_changed(\"\", {\"filename\": \"resume.txt\", \"content\": \"My resume\"})",
        "f.has_changed(\"\", {\"filename\": \"resume.txt\", \"content\":"
    ],
    [
        "\"resume.txt\", {\"filename\": \"resume.txt\", \"content\": \"My resume\"}",
        "\"resume.txt\", {\"filename\": \"resume.txt\","
    ],
    [
        "result = [single_file_clean(d, initial) for d in data]",
        "result = [single_file_clean(d, initial) for d in"
    ],
    [
        "msg = \"'The submitted file is empty.'\"",
        "msg = \"'The submitted"
    ],
    [
        "msg = \"File extension “sh” is not allowed. Allowed extensions are: \"",
        "msg = \"File extension “sh” is not"
    ],
    [
        "from datetime import date, datetime, timezone",
        "from datetime import date,"
    ],
    [
        "msg = \"'Enter a valid date/time.'\"",
        "msg = \"'Enter"
    ],
    [
        "f = DateTimeField(input_formats=[\"%Y %m %d %I:%M %p\"])",
        "f = DateTimeField(input_formats=[\"%Y %m %d %I:%M"
    ],
    [
        "f = DateTimeField(input_formats=[\"%Y %m %d %I:%M %p\"])",
        "f = DateTimeField(input_formats=[\"%Y %m"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "f = ChoiceField(choices=[(\"J\", \"John\"), (\"P\", \"Paul\")])",
        "f = ChoiceField(choices=[(\"J\", \"John\"),"
    ],
    [
        "msg = \"'Select a valid choice. John is not one of the available choices.'\"",
        "msg = \"'Select a valid choice. John is not one of"
    ],
    [
        "f = ChoiceField(choices={\"J\": \"John\", \"P\": \"Paul\"})",
        "f = ChoiceField(choices={\"J\":"
    ],
    [
        "f = ChoiceField(choices=[(\"J\", \"John\"), (\"P\", \"Paul\")], disabled=True)",
        "f = ChoiceField(choices=[(\"J\", \"John\"),"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"Enter a valid JSON.\"):",
        "with self.assertRaisesMessage(ValidationError, \"Enter a"
    ],
    [
        "\"\"\"The widget can be overridden with an attribute.\"\"\"",
        "\"\"\"The widget can be overridden with an"
    ],
    [
        "form = JSONForm({\"json_field\": '[\"bar\"]'}, initial={\"json_field\": [\"foo\"]})",
        "form = JSONForm({\"json_field\": '[\"bar\"]'},"
    ],
    [
        "Displaying a bound form (typically due to invalid input). The form",
        "Displaying a bound form (typically due to"
    ],
    [
        "form = JSONForm({\"name\": \"xyz\", \"json_field\": '[\"foo\"]'})",
        "form = JSONForm({\"name\":"
    ],
    [
        "form = JSONForm({\"name\": \"xy\", \"json_field\": '{\"foo\"}'})",
        "form = JSONForm({\"name\":"
    ],
    [
        "from django.forms import DateField, Form, HiddenInput, SelectDateWidget",
        "from django.forms import DateField, Form, HiddenInput,"
    ],
    [
        "self.assertEqual(c.errors, {\"mydate\": [\"Enter a valid date.\"]})",
        "self.assertEqual(c.errors, {\"mydate\": [\"Enter"
    ],
    [
        "self.assertEqual(e.errors, {\"mydate\": [\"Enter a valid date.\"]})",
        "self.assertEqual(e.errors, {\"mydate\": [\"Enter a"
    ],
    [
        "DateField.has_changed() with SelectDateWidget works with a localized",
        "DateField.has_changed() with SelectDateWidget works with"
    ],
    [
        "self.assertEqual(a.errors, {\"mydate\": [\"Voer een geldige datum in.\"]})",
        "self.assertEqual(a.errors, {\"mydate\": [\"Voer een geldige"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid date.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "from django.forms import Form, HiddenInput, NullBooleanField, RadioSelect",
        "from django.forms import Form,"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "from django.forms import DecimalField, NumberInput, Widget",
        "from django.forms import DecimalField,"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"Ensure that there are no more\"):",
        "with self.assertRaisesMessage(ValidationError, \"Ensure that there are"
    ],
    [
        "A localized DecimalField's widget renders to a text input without",
        "A localized DecimalField's widget renders"
    ],
    [
        "self.assertWidgetRendersTo(f, '<input id=\"id_f\" name=\"f\" type=\"text\" required>')",
        "self.assertWidgetRendersTo(f, '<input id=\"id_f\""
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "f\"Ensure this value has at most {max_length} characters (it has \"",
        "f\"Ensure this value has at most {max_length}"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid time.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid time.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid time.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid time.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "from django.forms import ClearableFileInput, FileInput, ImageField, Widget",
        "from django.forms import ClearableFileInput, FileInput, ImageField,"
    ],
    [
        "@unittest.skipUnless(Image, \"Pillow is required to test ImageField\")",
        "@unittest.skipUnless(Image, \"Pillow is required"
    ],
    [
        "This also tests the situation when Pillow doesn't detect the MIME type",
        "This also tests the situation when"
    ],
    [
        "ValidationError, \"File extension “txt” is not allowed.\"",
        "ValidationError, \"File extension “txt” is"
    ],
    [
        "img_file = SimpleUploadedFile(\"not_an_image.jpg\", b\"not an image\")",
        "img_file = SimpleUploadedFile(\"not_an_image.jpg\", b\"not"
    ],
    [
        "\"Upload a valid image. The file you uploaded was either not an \"",
        "\"Upload a valid image. The file you uploaded was either not an"
    ],
    [
        "f, '<input type=\"file\" name=\"f\" accept=\"image/*\" required id=\"id_f\" />'",
        "f, '<input type=\"file\" name=\"f\" accept=\"image/*\" required"
    ],
    [
        "f, '<input type=\"file\" name=\"f\" accept=\"image/png\" required id=\"id_f\" />'",
        "f, '<input type=\"file\" name=\"f\" accept=\"image/png\""
    ],
    [
        "f, '<input type=\"file\" name=\"f\" required id=\"id_f\" />'",
        "f, '<input type=\"file\" name=\"f\" required id=\"id_f\""
    ],
    [
        "from django.forms import ChoiceField, Field, Form, Select",
        "from django.forms import ChoiceField, Field, Form,"
    ],
    [
        "msg = \"This field is required.\"",
        "msg = \"This"
    ],
    [
        "msg = \"Enter a valid duration.\"",
        "msg = \"Enter a"
    ],
    [
        "msg = \"The number of days must be between {min_days} and {max_days}.\".format(",
        "msg = \"The number of days must be between {min_days} and"
    ],
    [
        "msg = \"Le nombre de jours doit être entre {min_days} et {max_days}.\".format(",
        "msg = \"Le nombre de jours doit être entre"
    ],
    [
        "language = ChoiceField(choices=[(\"P\", \"Python\"), (\"J\", \"Java\")], widget=RadioSelect)",
        "language = ChoiceField(choices=[(\"P\", \"Python\"),"
    ],
    [
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul McCartney\")],",
        "choices=[(\"J\", \"John Lennon\"),"
    ],
    [
        "'<input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" '",
        "'<input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\""
    ],
    [
        "'<input type=\"text\" name=\"last_name\" value=\"Lennon\" id=\"id_last_name\" '",
        "'<input type=\"text\" name=\"last_name\" value=\"Lennon\" id=\"id_last_name\""
    ],
    [
        "\"Key 'nonexistentfield' not found in 'Person'. Choices are: birthday, \"",
        "\"Key 'nonexistentfield' not found in 'Person'. Choices"
    ],
    [
        "'<input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" '",
        "'<input type=\"text\" name=\"first_name\""
    ],
    [
        "'<input type=\"text\" name=\"last_name\" value=\"Lennon\" id=\"id_last_name\" '",
        "'<input type=\"text\" name=\"last_name\" value=\"Lennon\" id=\"id_last_name\""
    ],
    [
        "'<ul class=\"errorlist\" id=\"id_first_name_error\"><li>This field is required.'",
        "'<ul class=\"errorlist\" id=\"id_first_name_error\"><li>This"
    ],
    [
        "'<ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field is required.'",
        "'<ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field is"
    ],
    [
        "'<ul class=\"errorlist\" id=\"id_birthday_error\"><li>This field is required.'",
        "'<ul class=\"errorlist\" id=\"id_birthday_error\"><li>This"
    ],
    [
        "'</li></ul><input type=\"text\" name=\"birthday\" aria-invalid=\"true\" required '",
        "'</li></ul><input type=\"text\" name=\"birthday\" aria-invalid=\"true\" required"
    ],
    [
        "<ul class=\"errorlist\" id=\"id_first_name_error\"><li>This field is required.</li></ul>",
        "<ul class=\"errorlist\" id=\"id_first_name_error\"><li>This field is"
    ],
    [
        "<input type=\"text\" name=\"first_name\" id=\"id_first_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"first_name\" id=\"id_first_name\""
    ],
    [
        "<td><ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field is required.</li></ul>",
        "<td><ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field"
    ],
    [
        "<input type=\"text\" name=\"last_name\" id=\"id_last_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"last_name\" id=\"id_last_name\""
    ],
    [
        "<td><ul class=\"errorlist\" id=\"id_birthday_error\"><li>This field is required.</li></ul>",
        "<td><ul class=\"errorlist\" id=\"id_birthday_error\"><li>This field is"
    ],
    [
        "<input type=\"text\" name=\"birthday\" id=\"id_birthday\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"birthday\" id=\"id_birthday\""
    ],
    [
        "<input type=\"text\" name=\"first_name\" id=\"id_first_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"first_name\" id=\"id_first_name\""
    ],
    [
        "</li><li><ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field is required.</li>",
        "</li><li><ul class=\"errorlist\" id=\"id_last_name_error\"><li>This"
    ],
    [
        "<input type=\"text\" name=\"last_name\" id=\"id_last_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"last_name\""
    ],
    [
        "</li><li><ul class=\"errorlist\" id=\"id_birthday_error\"><li>This field is required.</li>",
        "</li><li><ul class=\"errorlist\" id=\"id_birthday_error\"><li>This field"
    ],
    [
        "<input type=\"text\" name=\"birthday\" id=\"id_birthday\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"birthday\""
    ],
    [
        "<input type=\"text\" name=\"first_name\" id=\"id_first_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"first_name\""
    ],
    [
        "</p><ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field is required.</li></ul>",
        "</p><ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field"
    ],
    [
        "<input type=\"text\" name=\"last_name\" id=\"id_last_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"last_name\" id=\"id_last_name\""
    ],
    [
        "</p><ul class=\"errorlist\" id=\"id_birthday_error\"><li>This field is required.</li></ul>",
        "</p><ul class=\"errorlist\" id=\"id_birthday_error\"><li>This"
    ],
    [
        "<input type=\"text\" name=\"birthday\" id=\"id_birthday\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"birthday\""
    ],
    [
        "'<ul class=\"errorlist\" id=\"id_first_name_error\"><li>This field is required.'",
        "'<ul class=\"errorlist\" id=\"id_first_name_error\"><li>This field"
    ],
    [
        "'<ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field is required.'",
        "'<ul class=\"errorlist\" id=\"id_last_name_error\"><li>This field"
    ],
    [
        "'<ul class=\"errorlist\" id=\"id_birthday_error\"><li>This field is required.'",
        "'<ul class=\"errorlist\" id=\"id_birthday_error\"><li>This field is"
    ],
    [
        "'</li></ul><input type=\"text\" name=\"birthday\" aria-invalid=\"true\" required '",
        "'</li></ul><input type=\"text\" name=\"birthday\" aria-invalid=\"true\""
    ],
    [
        "'<input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" '",
        "'<input type=\"text\" name=\"first_name\" value=\"John\""
    ],
    [
        "'<input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" '",
        "'<input type=\"text\" name=\"first_name\""
    ],
    [
        "'<input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" '",
        "'<input type=\"text\" name=\"first_name\" value=\"John\""
    ],
    [
        "'<input type=\"text\" name=\"first_name\" value=\"John\" id=\"id_first_name\" '",
        "'<input type=\"text\" name=\"first_name\" value=\"John\""
    ],
    [
        "self.assertEqual(p[\"first_name\"].errors.as_text(), \"* This field is required.\")",
        "self.assertEqual(p[\"first_name\"].errors.as_text(), \"* This field"
    ],
    [
        "data = {\"first_name\": \"John\", \"last_name\": \"Lennon\"}",
        "data = {\"first_name\":"
    ],
    [
        "data = {\"first_name\": \"John\", \"last_name\": \"Lennon\"}",
        "data = {\"first_name\":"
    ],
    [
        "\"\"\"<li>First name: <input type=\"text\" name=\"first_name\" required></li>",
        "\"\"\"<li>First name: <input type=\"text\" name=\"first_name\""
    ],
    [
        "<li>Last name: <input type=\"text\" name=\"last_name\" required></li>",
        "<li>Last name: <input type=\"text\" name=\"last_name\""
    ],
    [
        "<li>Last name: <input type=\"text\" name=\"last_name\" required></li>",
        "<li>Last name: <input type=\"text\" name=\"last_name\""
    ],
    [
        "f = SignupForm({\"email\": \"test@example.com\", \"get_spam\": True}, auto_id=False)",
        "f = SignupForm({\"email\": \"test@example.com\","
    ],
    [
        "f = SignupForm({\"email\": \"test@example.com\", \"get_spam\": \"True\"}, auto_id=False)",
        "f = SignupForm({\"email\": \"test@example.com\","
    ],
    [
        "f = SignupForm({\"email\": \"test@example.com\", \"get_spam\": \"true\"}, auto_id=False)",
        "f = SignupForm({\"email\": \"test@example.com\","
    ],
    [
        "f = ContactForm({\"subject\": \"Hello\", \"message\": \"I love you.\"}, auto_id=False)",
        "f = ContactForm({\"subject\": \"Hello\", \"message\": \"I"
    ],
    [
        "'<input type=\"text\" name=\"message\" value=\"I love you.\" required>',",
        "'<input type=\"text\" name=\"message\" value=\"I"
    ],
    [
        "'<input type=\"hidden\" name=\"message\" value=\"I love you.\">',",
        "'<input type=\"hidden\" name=\"message\" value=\"I"
    ],
    [
        "language = ChoiceField(choices=[(\"P\", \"Python\"), (\"J\", \"Java\")])",
        "language = ChoiceField(choices=[(\"P\", \"Python\"), (\"J\","
    ],
    [
        "f = FrameworkForm({\"name\": \"Django\", \"language\": \"P\"}, auto_id=False)",
        "f = FrameworkForm({\"name\": \"Django\","
    ],
    [
        "choices=[(\"\", \"------\"), (\"P\", \"Python\"), (\"J\", \"Java\")]",
        "choices=[(\"\", \"------\"), (\"P\","
    ],
    [
        "f = FrameworkForm({\"name\": \"Django\", \"language\": \"P\"}, auto_id=False)",
        "f = FrameworkForm({\"name\": \"Django\","
    ],
    [
        "choices=[(\"R\", \"Ruby\"), (\"P\", \"Perl\")], attrs={\"class\": \"foo\"}",
        "choices=[(\"R\", \"Ruby\"), (\"P\", \"Perl\")], attrs={\"class\":"
    ],
    [
        "f = FrameworkForm({\"name\": \"Django\", \"language\": \"P\"}, auto_id=False)",
        "f = FrameworkForm({\"name\": \"Django\", \"language\": \"P\"},"
    ],
    [
        "f.fields[\"language\"].choices = [(\"P\", \"Python\"), (\"J\", \"Java\")]",
        "f.fields[\"language\"].choices = [(\"P\", \"Python\"), (\"J\","
    ],
    [
        "<div><label><input type=\"radio\" name=\"language\" value=\"P\" required> Python</label></div>",
        "<div><label><input type=\"radio\" name=\"language\""
    ],
    [
        "<div><label><input type=\"radio\" name=\"language\" value=\"J\" required> Java</label></div>",
        "<div><label><input type=\"radio\" name=\"language\" value=\"J\""
    ],
    [
        "<div><label><input type=\"radio\" name=\"language\" value=\"P\" required> Python</label></div>",
        "<div><label><input type=\"radio\" name=\"language\" value=\"P\""
    ],
    [
        "<div><label><input type=\"radio\" name=\"language\" value=\"J\" required> Java</label></div>",
        "<div><label><input type=\"radio\" name=\"language\" value=\"J\""
    ],
    [
        "<div><label><input type=\"radio\" name=\"language\" value=\"P\" required> Python</label></div>",
        "<div><label><input type=\"radio\" name=\"language\" value=\"P\""
    ],
    [
        "<div><label><input type=\"radio\" name=\"language\" value=\"J\" required> Java</label></div>",
        "<div><label><input type=\"radio\" name=\"language\" value=\"J\""
    ],
    [
        "'<div> Name: <input type=\"text\" name=\"name\" required></div><div><fieldset>'",
        "'<div> Name: <input type=\"text\" name=\"name\""
    ],
    [
        "'<label><input type=\"radio\" name=\"name\" value=\"john\" required> John</label>'",
        "'<label><input type=\"radio\" name=\"name\" value=\"john\""
    ],
    [
        "'<label><input type=\"radio\" name=\"name\" value=\"paul\" required> Paul</label>'",
        "'<label><input type=\"radio\" name=\"name\" value=\"paul\""
    ],
    [
        "'<label><input type=\"radio\" name=\"name\" value=\"george\" required> George'",
        "'<label><input type=\"radio\" name=\"name\" value=\"george\""
    ],
    [
        "'<label><input type=\"radio\" name=\"name\" value=\"ringo\" required> Ringo'",
        "'<label><input type=\"radio\" name=\"name\" value=\"ringo\""
    ],
    [
        "\"\\n\".join(\"<div>%s</div>\" % bf for bf in f[\"name\"]),",
        "\"\\n\".join(\"<div>%s</div>\" % bf for"
    ],
    [
        "<input type=\"radio\" name=\"name\" value=\"john\" required> John</label></div>",
        "<input type=\"radio\" name=\"name\" value=\"john\" required>"
    ],
    [
        "<input type=\"radio\" name=\"name\" value=\"paul\" required> Paul</label></div>",
        "<input type=\"radio\" name=\"name\" value=\"paul\""
    ],
    [
        "<input type=\"radio\" name=\"name\" value=\"george\" required> George",
        "<input type=\"radio\" name=\"name\" value=\"george\""
    ],
    [
        "<input type=\"radio\" name=\"name\" value=\"ringo\" required> Ringo</label></div>",
        "<input type=\"radio\" name=\"name\""
    ],
    [
        "msg = \"BoundField indices must be integers or slices, not str.\"",
        "msg = \"BoundField indices must be"
    ],
    [
        "\"\"\"BoundField without any choices (subwidgets) evaluates to True.\"\"\"",
        "\"\"\"BoundField without any choices (subwidgets) evaluates"
    ],
    [
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul McCartney\")]",
        "choices=[(\"J\", \"John Lennon\"), (\"P\","
    ],
    [
        "f = SongForm({\"name\": \"Yesterday\", \"composers\": [\"P\"]}, auto_id=False)",
        "f = SongForm({\"name\": \"Yesterday\", \"composers\":"
    ],
    [
        "str(f[\"name\"]), '<input type=\"text\" name=\"name\" value=\"Yesterday\" required>'",
        "str(f[\"name\"]), '<input type=\"text\" name=\"name\""
    ],
    [
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul McCartney\")]",
        "choices=[(\"J\", \"John Lennon\"), (\"P\","
    ],
    [
        "f = SongForm({\"name\": \"Yesterday\", \"composers\": [\"P\"]}, auto_id=False)",
        "f = SongForm({\"name\": \"Yesterday\", \"composers\":"
    ],
    [
        "f = SongForm({\"name\": \"From Me To You\", \"composers\": [\"P\", \"J\"]}, auto_id=False)",
        "f = SongForm({\"name\": \"From Me To You\", \"composers\": [\"P\", \"J\"]},"
    ],
    [
        "f = SongForm({\"composers\": [\"J\", \"P\"]}, auto_id=False)",
        "f = SongForm({\"composers\": [\"J\","
    ],
    [
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul McCartney\")],",
        "choices=[(\"J\", \"John Lennon\"), (\"P\","
    ],
    [
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul McCartney\")],",
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul"
    ],
    [
        "data = {\"name\": \"Yesterday\", \"composers\": [\"J\", \"P\"]}",
        "data = {\"name\": \"Yesterday\", \"composers\":"
    ],
    [
        "data = MultiValueDict({\"name\": [\"Yesterday\"], \"composers\": [\"J\", \"P\"]})",
        "data = MultiValueDict({\"name\": [\"Yesterday\"], \"composers\":"
    ],
    [
        "f = SongForm(MultiValueDictLike({\"name\": \"Yesterday\", \"composers\": \"J\"}))",
        "f = SongForm(MultiValueDictLike({\"name\": \"Yesterday\","
    ],
    [
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul McCartney\")],",
        "choices=[(\"J\", \"John Lennon\"),"
    ],
    [
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul McCartney\")],",
        "choices=[(\"J\", \"John Lennon\"),"
    ],
    [
        "\"\"\"<li>Name: <input type=\"text\" name=\"name\" value=\"Yesterday\" required>",
        "\"\"\"<li>Name: <input type=\"text\" name=\"name\""
    ],
    [
        "f = SongForm({\"name\": \"Yesterday\", \"composers\": [\"J\"]}, auto_id=False)",
        "f = SongForm({\"name\": \"Yesterday\","
    ],
    [
        "f = SongForm({\"name\": \"Yesterday\", \"composers\": [\"J\", \"P\"]}, auto_id=False)",
        "f = SongForm({\"name\": \"Yesterday\", \"composers\": [\"J\","
    ],
    [
        "f = SongForm(MultiValueDictLike({\"name\": \"Yesterday\", \"composers\": \"J\"}))",
        "f = SongForm(MultiValueDictLike({\"name\":"
    ],
    [
        "\"Something's wrong with '%s'\" % self.cleaned_data[\"special_name\"]",
        "\"Something's wrong with '%s'\" %"
    ],
    [
        "<input type=\"text\" name=\"special_name\" value=\"Nothing to escape\"",
        "<input type=\"text\" name=\"special_name\" value=\"Nothing to"
    ],
    [
        "<li>'<b>Nothing to escape</b>' is a safe string</li></ul>",
        "<li>'<b>Nothing to escape</b>' is a"
    ],
    [
        "<input type=\"text\" name=\"special_safe_name\" value=\"Nothing to escape\"",
        "<input type=\"text\" name=\"special_safe_name\" value=\"Nothing"
    ],
    [
        "\"special_name\": \"Should escape < & > and <script>alert('xss')</script>\",",
        "\"special_name\": \"Should escape < & > and"
    ],
    [
        "'<input type=\"text\" name=\"special_name\" value=\"Should escape &lt; &amp; '",
        "'<input type=\"text\" name=\"special_name\" value=\"Should escape &lt;"
    ],
    [
        "\"<li>'<b><i>Do not escape</i></b>' is a safe string</li></ul>\"",
        "\"<li>'<b><i>Do not escape</i></b>' is a"
    ],
    [
        "raise ValidationError(\"Please make sure your passwords match.\")",
        "raise ValidationError(\"Please make sure"
    ],
    [
        "raise ValidationError(\"Please make sure your passwords match.\")",
        "raise ValidationError(\"Please make sure your"
    ],
    [
        "f.errors[\"__all__\"], [\"Please make sure your passwords match.\"]",
        "f.errors[\"__all__\"], [\"Please make sure"
    ],
    [
        "<li>Please make sure your passwords match.</li></ul></td></tr>",
        "<li>Please make sure your passwords"
    ],
    [
        "<li>Please make sure your passwords match.</li></ul></li>",
        "<li>Please make sure your"
    ],
    [
        "'<ul class=\"errorlist nonfield\"><li>Please make sure your passwords match.'",
        "'<ul class=\"errorlist nonfield\"><li>Please make sure your"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"has no field named\"):",
        "with self.assertRaisesMessage(ValueError, \"has no"
    ],
    [
        "\"Please make sure your passwords match.\",",
        "\"Please make sure your"
    ],
    [
        "\"<li>(Hidden field hidden_input) This field is required.</li></ul>\"",
        "\"<li>(Hidden field hidden_input) This field is"
    ],
    [
        "\"<li>(Hidden field hidden_input) This field is required.</li></ul>\"",
        "\"<li>(Hidden field hidden_input) This"
    ],
    [
        "\"<li>(Hidden field hidden_input) This field is required.</li></ul>\"",
        "\"<li>(Hidden field hidden_input) This field"
    ],
    [
        "\"<li>(Hidden field hidden_input) This field is required.</li></ul>\"",
        "\"<li>(Hidden field hidden_input) This"
    ],
    [
        "gender = ChoiceField(choices=((\"f\", \"Female\"), (\"m\", \"Male\")))",
        "gender = ChoiceField(choices=((\"f\", \"Female\"),"
    ],
    [
        "[(\"f\", \"Female\"), (\"m\", \"Male\"), (\"u\", \"Unspecified\")],",
        "[(\"f\", \"Female\"), (\"m\","
    ],
    [
        "The list of form field validators can be modified without polluting",
        "The list of form field validators can be"
    ],
    [
        "<li>First name: <input type=\"text\" name=\"first_name\" required></li>",
        "<li>First name: <input"
    ],
    [
        "<li>Last name: <input type=\"text\" name=\"last_name\" required></li>",
        "<li>Last name: <input"
    ],
    [
        "<p>First name: <input type=\"text\" name=\"first_name\" required></p>",
        "<p>First name: <input"
    ],
    [
        "<p>Last name: <input type=\"text\" name=\"last_name\" required></p>",
        "<p>Last name: <input type=\"text\" name=\"last_name\""
    ],
    [
        "'<div>First name: <input type=\"text\" name=\"first_name\" required></div>'",
        "'<div>First name: <input type=\"text\""
    ],
    [
        "'<div>Last name: <input type=\"text\" name=\"last_name\" required></div><div>'",
        "'<div>Last name: <input type=\"text\" name=\"last_name\""
    ],
    [
        "'Birthday: <input type=\"text\" name=\"birthday\" required><input '",
        "'Birthday: <input type=\"text\" name=\"birthday\" required><input"
    ],
    [
        "(Hidden field hidden_text) This field is required.</li></ul></td></tr>",
        "(Hidden field hidden_text) This"
    ],
    [
        "(Hidden field hidden_text) This field is required.</li></ul></li>",
        "(Hidden field hidden_text) This field is"
    ],
    [
        "<li>First name: <input type=\"text\" name=\"first_name\" value=\"John\" required>",
        "<li>First name: <input type=\"text\""
    ],
    [
        "<li>Last name: <input type=\"text\" name=\"last_name\" value=\"Lennon\" required>",
        "<li>Last name: <input type=\"text\" name=\"last_name\""
    ],
    [
        "(Hidden field hidden_text) This field is required.</li></ul>",
        "(Hidden field hidden_text) This field is"
    ],
    [
        "<p>First name: <input type=\"text\" name=\"first_name\" value=\"John\" required>",
        "<p>First name: <input type=\"text\" name=\"first_name\" value=\"John\""
    ],
    [
        "<p>Last name: <input type=\"text\" name=\"last_name\" value=\"Lennon\" required>",
        "<p>Last name: <input type=\"text\""
    ],
    [
        "'<ul class=\"errorlist nonfield\"><li>(Hidden field hidden_text) This field '",
        "'<ul class=\"errorlist nonfield\"><li>(Hidden field hidden_text) This"
    ],
    [
        "'is required.</li></ul><div>First name: <input type=\"text\" '",
        "'is required.</li></ul><div>First name: <input"
    ],
    [
        "'name=\"first_name\" value=\"John\" required></div><div>Last name: <input '",
        "'name=\"first_name\" value=\"John\" required></div><div>Last name: <input"
    ],
    [
        "p.as_p(), '<input type=\"hidden\" name=\"foo\"><input type=\"hidden\" name=\"bar\">'",
        "p.as_p(), '<input type=\"hidden\" name=\"foo\"><input type=\"hidden\""
    ],
    [
        "answer = CharField(label=\"Secret answer\", label_suffix=\" =\")",
        "answer = CharField(label=\"Secret"
    ],
    [
        "\"\"\"<li>Favorite color? <input type=\"text\" name=\"color\" required></li>",
        "\"\"\"<li>Favorite color? <input type=\"text\""
    ],
    [
        "<li>Favorite animal: <input type=\"text\" name=\"animal\" required></li>",
        "<li>Favorite animal: <input"
    ],
    [
        "<li>Secret answer = <input type=\"text\" name=\"answer\" required></li>\"\"\",",
        "<li>Secret answer = <input type=\"text\" name=\"answer\""
    ],
    [
        "\"\"\"<li>Favorite color? <input type=\"text\" name=\"color\" required></li>",
        "\"\"\"<li>Favorite color? <input"
    ],
    [
        "<li>Favorite animal? <input type=\"text\" name=\"animal\" required></li>",
        "<li>Favorite animal? <input"
    ],
    [
        "<li>Secret answer = <input type=\"text\" name=\"answer\" required></li>\"\"\",",
        "<li>Secret answer = <input type=\"text\" name=\"answer\""
    ],
    [
        "\"\"\"<li>Favorite color? <input type=\"text\" name=\"color\" required></li>",
        "\"\"\"<li>Favorite color? <input type=\"text\""
    ],
    [
        "<li>Favorite animal <input type=\"text\" name=\"animal\" required></li>",
        "<li>Favorite animal <input"
    ],
    [
        "<li>Secret answer = <input type=\"text\" name=\"answer\" required></li>\"\"\",",
        "<li>Secret answer = <input type=\"text\" name=\"answer\""
    ],
    [
        "'<li>Favorite color? <input type=\"text\" name=\"color\" required></li>\\n'",
        "'<li>Favorite color? <input"
    ],
    [
        "'<li>Secret answer = <input type=\"text\" name=\"answer\" required></li>',",
        "'<li>Secret answer = <input"
    ],
    [
        "Password: <input type=\"password\" name=\"password\" aria-invalid=\"true\" required></li>\"\"\",",
        "Password: <input type=\"password\" name=\"password\""
    ],
    [
        "Password: <input type=\"password\" name=\"password\" aria-invalid=\"true\" required></li>\"\"\",",
        "Password: <input type=\"password\""
    ],
    [
        "p = UserRegistration({}, initial={\"username\": \"django\"}, auto_id=False)",
        "p = UserRegistration({}, initial={\"username\": \"django\"},"
    ],
    [
        "Password: <input type=\"password\" name=\"password\" aria-invalid=\"true\" required></li>\"\"\",",
        "Password: <input type=\"password\" name=\"password\""
    ],
    [
        "Password: <input type=\"password\" name=\"password\" aria-invalid=\"true\" required></li>\"\"\",",
        "Password: <input type=\"password\""
    ],
    [
        "p = UserRegistration({\"password\": \"secret\"}, initial={\"username\": \"django\"})",
        "p = UserRegistration({\"password\": \"secret\"},"
    ],
    [
        "choices=[(\"f\", \"foo\"), (\"b\", \"bar\"), (\"w\", \"whiz\")]",
        "choices=[(\"f\", \"foo\"), (\"b\","
    ],
    [
        "Options: <select multiple name=\"options\" aria-invalid=\"true\" required>",
        "Options: <select multiple name=\"options\""
    ],
    [
        "Password: <input type=\"password\" name=\"password\" aria-invalid=\"true\" required></li>",
        "Password: <input type=\"password\" name=\"password\""
    ],
    [
        "Options: <select multiple name=\"options\" aria-invalid=\"true\" required>",
        "Options: <select multiple name=\"options\""
    ],
    [
        "choices=[(\"f\", \"foo\"), (\"b\", \"bar\"), (\"w\", \"whiz\")],",
        "choices=[(\"f\", \"foo\"), (\"b\", \"bar\"), (\"w\","
    ],
    [
        "Multiple calls to BoundField().value() in an unbound form should return",
        "Multiple calls to BoundField().value() in"
    ],
    [
        "name = CharField(initial=lambda: \"John Doe\", disabled=True)",
        "name = CharField(initial=lambda: \"John"
    ],
    [
        "Cleaning a form with a disabled DateTimeField and callable initial",
        "Cleaning a form with a disabled DateTimeField and"
    ],
    [
        "The cleaned value for a form with a disabled DateTimeField and callable",
        "The cleaned value for a form with a"
    ],
    [
        "initial matches the bound field's cached initial value.",
        "initial matches the bound field's cached initial"
    ],
    [
        "'<div>Password: <div class=\"helptext\">Wählen Sie mit Bedacht.</div>'",
        "'<div>Password: <div class=\"helptext\">Wählen Sie"
    ],
    [
        "'<li>Username: <input type=\"text\" name=\"username\" value=\"foo\" '",
        "'<li>Username: <input type=\"text\" name=\"username\" value=\"foo\""
    ],
    [
        "'Password: <input type=\"password\" name=\"password\" aria-invalid=\"true\" '",
        "'Password: <input type=\"password\" name=\"password\" aria-invalid=\"true\""
    ],
    [
        "'<div class=\"helptext\" id=\"id_password_helptext\">Wählen Sie mit Bedacht.'",
        "'<div class=\"helptext\" id=\"id_password_helptext\">Wählen Sie mit"
    ],
    [
        "'<span class=\"helptext\" id=\"id_password_helptext\">Wählen Sie mit Bedacht.'",
        "'<span class=\"helptext\" id=\"id_password_helptext\">Wählen"
    ],
    [
        "'<span class=\"helptext\" id=\"id_password_helptext\">Wählen Sie mit Bedacht.'",
        "'<span class=\"helptext\" id=\"id_password_helptext\">Wählen Sie mit"
    ],
    [
        "'<span class=\"helptext\" id=\"id_password_helptext\">Wählen Sie mit Bedacht.'",
        "'<span class=\"helptext\" id=\"id_password_helptext\">Wählen Sie mit"
    ],
    [
        "'<ul class=\"errorlist\" id=\"id_color_error\"><li>Enter a list of values.'",
        "'<ul class=\"errorlist\" id=\"id_color_error\"><li>Enter a"
    ],
    [
        "datetime = SplitDateTimeField(help_text=\"Enter Date and Time\")",
        "datetime = SplitDateTimeField(help_text=\"Enter Date"
    ],
    [
        "'<div class=\"helptext\" id=\"id_datetime_helptext\">Enter Date and Time</div>'",
        "'<div class=\"helptext\" id=\"id_datetime_helptext\">Enter Date"
    ],
    [
        "'id=\"id_checkbox_helptext\">Checkbox help text</div> <ul class=\"errorlist\" '",
        "'id=\"id_checkbox_helptext\">Checkbox help text</div> <ul"
    ],
    [
        "'id=\"id_checkbox_error\"> <li>This field is required.</li> </ul> '",
        "'id=\"id_checkbox_error\"> <li>This field is"
    ],
    [
        "'<input type=\"checkbox\" name=\"checkbox\" value=\"b\" aria-invalid=\"true\" '",
        "'<input type=\"checkbox\" name=\"checkbox\" value=\"b\""
    ],
    [
        "'Radio help text</div> <ul class=\"errorlist\" id=\"id_radio_error\"><li>'",
        "'Radio help text</div> <ul class=\"errorlist\""
    ],
    [
        "'This field is required.</li> </ul> <div id=\"id_radio\"><div><label '",
        "'This field is required.</li> </ul> <div id=\"id_radio\"><div><label"
    ],
    [
        "'id=\"id_datetime_helptext\">Enter Date and Time</div><ul class=\"errorlist\" '",
        "'id=\"id_datetime_helptext\">Enter Date and Time</div><ul"
    ],
    [
        "intl_name = CharField(help_text=\"The food's international name.\")",
        "intl_name = CharField(help_text=\"The food's"
    ],
    [
        "\"\"\"<li>First name: <input type=\"text\" name=\"first_name\" required></li>",
        "\"\"\"<li>First name: <input type=\"text\""
    ],
    [
        "<li>Last name: <input type=\"text\" name=\"last_name\" required></li>",
        "<li>Last name: <input"
    ],
    [
        "\"\"\"<li>First name: <input type=\"text\" name=\"first_name\" required></li>",
        "\"\"\"<li>First name: <input"
    ],
    [
        "<li>Last name: <input type=\"text\" name=\"last_name\" required></li>",
        "<li>Last name: <input type=\"text\" name=\"last_name\""
    ],
    [
        "<li>First name: <input type=\"text\" name=\"first_name\" required></li>",
        "<li>First name: <input type=\"text\" name=\"first_name\""
    ],
    [
        "<li>Last name: <input type=\"text\" name=\"last_name\" required></li>",
        "<li>Last name: <input type=\"text\" name=\"last_name\""
    ],
    [
        "<li>Haircut type: <input type=\"text\" name=\"haircut_type\" required></li>\"\"\",",
        "<li>Haircut type: <input"
    ],
    [
        "p = Person({\"name\": \"Joe\", \"is_cool\": True}, auto_id=False)",
        "p = Person({\"name\": \"Joe\","
    ],
    [
        "p = Person({\"name\": \"Joe\", \"is_cool\": False}, auto_id=False)",
        "p = Person({\"name\": \"Joe\", \"is_cool\": False},"
    ],
    [
        "p = Person({\"name\": \"Joe\", \"is_cool\": \"unknown\"}, auto_id=False)",
        "p = Person({\"name\": \"Joe\","
    ],
    [
        "p = Person({\"name\": \"Joe\", \"is_cool\": \"true\"}, auto_id=False)",
        "p = Person({\"name\": \"Joe\","
    ],
    [
        "p = Person({\"name\": \"Joe\", \"is_cool\": \"false\"}, auto_id=False)",
        "p = Person({\"name\": \"Joe\","
    ],
    [
        "'<ul class=\"errorlist\"><li>The submitted file is empty.</li></ul>'",
        "'<ul class=\"errorlist\"><li>The submitted"
    ],
    [
        "'<ul class=\"errorlist\"><li>No file was submitted. Check the '",
        "'<ul class=\"errorlist\"><li>No file was submitted."
    ],
    [
        "\"我隻氣墊船裝滿晒鱔.txt\", \"मेरी मँडराने वाली नाव सर्पमीनों से भरी ह\".encode()",
        "\"我隻氣墊船裝滿晒鱔.txt\", \"मेरी मँडराने वाली नाव सर्पमीनों से"
    ],
    [
        "data = {\"artist\": \"\", \"song\": \"\"}",
        "data = {\"artist\": \"\","
    ],
    [
        "data = {\"artist\": \"The Doors\", \"song\": \"\"}",
        "data = {\"artist\": \"The Doors\","
    ],
    [
        "self.assertEqual(form.errors, {\"name\": [\"This field is required.\"]})",
        "self.assertEqual(form.errors, {\"name\": [\"This field"
    ],
    [
        "data = {\"artist\": None, \"song\": \"\"}",
        "data = {\"artist\": None, \"song\":"
    ],
    [
        "\"The empty_permitted and use_required_attribute arguments may not \"",
        "\"The empty_permitted and use_required_attribute arguments may"
    ],
    [
        "self.assertEqual([f.name for f in form.hidden_fields()], [\"token\"])",
        "self.assertEqual([f.name for f in form.hidden_fields()],"
    ],
    [
        "self.assertEqual([f.name for f in form.visible_fields()], [\"artist\", \"name\"])",
        "self.assertEqual([f.name for f in form.visible_fields()], [\"artist\","
    ],
    [
        "<input type=\"text\" name=\"name\" id=\"id_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"name\" id=\"id_name\" aria-invalid=\"true\""
    ],
    [
        "<input type=\"number\" name=\"age\" id=\"id_age\" aria-invalid=\"true\" required",
        "<input type=\"number\" name=\"age\" id=\"id_age\""
    ],
    [
        "<ul class=\"errorlist\" id=\"id_name_error\"><li>This field is required.</li>",
        "<ul class=\"errorlist\" id=\"id_name_error\"><li>This field is"
    ],
    [
        "<input type=\"text\" name=\"name\" id=\"id_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"name\""
    ],
    [
        "<ul class=\"errorlist\" id=\"id_age_error\"><li>This field is required.</li>",
        "<ul class=\"errorlist\" id=\"id_age_error\"><li>This field is"
    ],
    [
        "<td><ul class=\"errorlist\" id=\"id_name_error\"><li>This field is required.</li></ul>",
        "<td><ul class=\"errorlist\" id=\"id_name_error\"><li>This"
    ],
    [
        "<input type=\"text\" name=\"name\" id=\"id_name\" aria-invalid=\"true\" required",
        "<input type=\"text\" name=\"name\" id=\"id_name\" aria-invalid=\"true\""
    ],
    [
        "<td><ul class=\"errorlist\" id=\"id_age_error\"><li>This field is required.</li></ul>",
        "<td><ul class=\"errorlist\" id=\"id_age_error\"><li>This field is"
    ],
    [
        "<input type=\"number\" name=\"age\" id=\"id_age\" aria-invalid=\"true\" required",
        "<input type=\"number\" name=\"age\" id=\"id_age\" aria-invalid=\"true\""
    ],
    [
        "'</label><ul class=\"errorlist\" id=\"id_name_error\"><li>This field is '",
        "'</label><ul class=\"errorlist\" id=\"id_name_error\"><li>This field is"
    ],
    [
        "'required.</li></ul><input type=\"text\" name=\"name\" required id=\"id_name\" '",
        "'required.</li></ul><input type=\"text\" name=\"name\""
    ],
    [
        "'</label><ul class=\"errorlist\" id=\"id_age_error\"><li>This field is '",
        "'</label><ul class=\"errorlist\" id=\"id_age_error\"><li>This field is"
    ],
    [
        "'required.</li></ul><input type=\"number\" name=\"age\" required id=\"id_age\" '",
        "'required.</li></ul><input type=\"number\" name=\"age\" required"
    ],
    [
        "required_css_class is added to label_tag() and legend_tag() of required",
        "required_css_class is added to label_tag() and legend_tag() of"
    ],
    [
        "self.assertEqual(form.errors, {\"name\": [\"bad value not allowed\"]})",
        "self.assertEqual(form.errors, {\"name\": [\"bad"
    ],
    [
        "form = NameForm(data={\"name\": [\"should be overly\", \"long for the field names\"]})",
        "form = NameForm(data={\"name\": [\"should be overly\", \"long for"
    ],
    [
        "return \"%s.%s ext. %s (label: %s)\" % tuple(data_list)",
        "return \"%s.%s ext. %s (label: %s)\""
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field is"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid country code.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid country code.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'This field"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a complete value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter"
    ],
    [
        "ValidationError, \"'Enter a complete value.', 'Enter an extension.'\"",
        "ValidationError, \"'Enter a complete value.',"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid country code.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a complete value.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a"
    ],
    [
        "ValidationError, \"'Enter a complete value.', 'Enter an extension.'\"",
        "ValidationError, \"'Enter a complete value.',"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid country code.'\"):",
        "with self.assertRaisesMessage(ValidationError, \"'Enter a valid"
    ],
    [
        "Form fields can customize what is considered as an empty value",
        "Form fields can customize what is considered"
    ],
    [
        "for args, kwargs, expected in testcases:",
        "for args, kwargs,"
    ],
    [
        "If a widget has no id, label_tag() and legend_tag() return the text",
        "If a widget has no id, label_tag()"
    ],
    [
        "If an id is provided in `Widget.attrs`, it overrides the generated ID,",
        "If an id is provided in `Widget.attrs`, it overrides the generated"
    ],
    [
        "If auto_id is provided when initializing the form, the generated ID in",
        "If auto_id is provided when initializing the form, the"
    ],
    [
        "BoundField label_suffix (if provided) overrides Form label_suffix",
        "BoundField label_suffix (if provided)"
    ],
    [
        "\"* foo\\n  * This field is required.\",",
        "\"* foo\\n * This field is"
    ],
    [
        "\"* bar\\n  * This field is required.\",",
        "\"* bar\\n * This field"
    ],
    [
        "'<li>foo<ul class=\"errorlist\" id=\"id_foo_error\"><li>This field is required.'",
        "'<li>foo<ul class=\"errorlist\" id=\"id_foo_error\"><li>This"
    ],
    [
        "'<li>bar<ul class=\"errorlist\" id=\"id_bar_error\"><li>This field is required.'",
        "'<li>bar<ul class=\"errorlist\" id=\"id_bar_error\"><li>This field"
    ],
    [
        "\"foo\": [{\"code\": \"required\", \"message\": \"This field is required.\"}],",
        "\"foo\": [{\"code\": \"required\", \"message\": \"This field is"
    ],
    [
        "\"bar\": [{\"code\": \"required\", \"message\": \"This field is required.\"}],",
        "\"bar\": [{\"code\": \"required\", \"message\": \"This field is"
    ],
    [
        "\"__all__\": [{\"code\": \"secret\", \"message\": \"Non-field error.\"}],",
        "\"__all__\": [{\"code\": \"secret\", \"message\": \"Non-field"
    ],
    [
        "\"foo\": [{\"code\": \"required\", \"message\": \"This field is required.\"}],",
        "\"foo\": [{\"code\": \"required\", \"message\": \"This"
    ],
    [
        "\"bar\": [{\"code\": \"required\", \"message\": \"This field is required.\"}],",
        "\"bar\": [{\"code\": \"required\", \"message\": \"This field"
    ],
    [
        "\"__all__\": [{\"code\": \"secret\", \"message\": \"<p>Non-field error.</p>\"}],",
        "\"__all__\": [{\"code\": \"secret\", \"message\":"
    ],
    [
        "[{\"message\": \"Foo\", \"code\": \"\"}, {\"message\": \"Foobar\", \"code\": \"foobar\"}],",
        "[{\"message\": \"Foo\", \"code\": \"\"}, {\"message\":"
    ],
    [
        "<li>(Hidden field last_name) This field is required.</li></ul></li><li>",
        "<li>(Hidden field last_name) This"
    ],
    [
        "<input id=\"id_first_name\" name=\"first_name\" type=\"text\" value=\"John\" required>",
        "<input id=\"id_first_name\" name=\"first_name\" type=\"text\""
    ],
    [
        "<li>(Hidden field last_name) This field is required.</li></ul>",
        "<li>(Hidden field last_name) This"
    ],
    [
        "<li>(Hidden field last_name) This field is required.</li></ul></td></tr>",
        "<li>(Hidden field last_name) This field is"
    ],
    [
        "<input id=\"id_first_name\" name=\"first_name\" type=\"text\" value=\"John\" required>",
        "<input id=\"id_first_name\" name=\"first_name\" type=\"text\" value=\"John\""
    ],
    [
        "'<ul class=\"errorlist nonfield\"><li>(Hidden field last_name) This field '",
        "'<ul class=\"errorlist nonfield\"><li>(Hidden field last_name)"
    ],
    [
        "'<input id=\"id_first_name\" name=\"first_name\" type=\"text\" value=\"John\" '",
        "'<input id=\"id_first_name\" name=\"first_name\" type=\"text\""
    ],
    [
        "p = Person({\"first_name\": \"John\", \"last_name\": \"Lennon\"})",
        "p = Person({\"first_name\":"
    ],
    [
        "<input id=\"id_first_name\" name=\"first_name\" type=\"text\" value=\"John\" required></li>",
        "<input id=\"id_first_name\" name=\"first_name\" type=\"text\" value=\"John\""
    ],
    [
        "<input id=\"id_last_name\" name=\"last_name\" type=\"text\" value=\"Lennon\" required></li>\"\"\",",
        "<input id=\"id_last_name\" name=\"last_name\" type=\"text\""
    ],
    [
        "<input id=\"id_first_name\" name=\"first_name\" type=\"text\" value=\"John\" required></p>",
        "<input id=\"id_first_name\" name=\"first_name\" type=\"text\""
    ],
    [
        "<input id=\"id_last_name\" name=\"last_name\" type=\"text\" value=\"Lennon\" required></p>\"\"\",",
        "<input id=\"id_last_name\" name=\"last_name\" type=\"text\" value=\"Lennon\""
    ],
    [
        "form = TestForm({\"hidden\": \"a\", \"visible\": \"b\"})",
        "form = TestForm({\"hidden\": \"a\", \"visible\":"
    ],
    [
        "\"<li>(Hidden field hidden) Foo &amp; &quot;bar&quot;!</li></ul></li>\"",
        "\"<li>(Hidden field hidden) Foo"
    ],
    [
        "'<input type=\"text\" name=\"visible\" aria-invalid=\"true\" value=\"b\" '",
        "'<input type=\"text\" name=\"visible\" aria-invalid=\"true\""
    ],
    [
        "BaseForm.__repr__() should contain some basic information about the",
        "BaseForm.__repr__() should contain some"
    ],
    [
        "{\"first_name\": \"John\", \"last_name\": \"Lennon\", \"birthday\": \"fakedate\"}",
        "{\"first_name\": \"John\", \"last_name\": \"Lennon\","
    ],
    [
        "BaseForm.__repr__() shouldn't trigger the form validation.",
        "BaseForm.__repr__() shouldn't trigger the form"
    ],
    [
        "{\"first_name\": \"John\", \"last_name\": \"Lennon\", \"birthday\": \"fakedate\"}",
        "{\"first_name\": \"John\", \"last_name\": \"Lennon\","
    ],
    [
        "f = UserForm({\"username\": \"SirRobin\", \"password\": \"blue\"})",
        "f = UserForm({\"username\": \"SirRobin\", \"password\":"
    ],
    [
        "f = UserForm({\"username\": \"SirRobin\", \"password\": \"blue\"})",
        "f = UserForm({\"username\": \"SirRobin\","
    ],
    [
        "f = UserForm({\"username\": \"SirRobin\", \"password\": \"blue\"})",
        "f = UserForm({\"username\":"
    ],
    [
        "\"<li>(Hidden field data) This field is required.</li></ul>\\n<p> \"",
        "\"<li>(Hidden field data) This field is required.</li></ul>\\n<p>"
    ],
    [
        "\"<li>(Hidden field data) This field is required.</li></ul>\"",
        "\"<li>(Hidden field data) This"
    ],
    [
        "kwargs[\"error_messages\"] = {\"invalid\": \"Form custom error message.\"}",
        "kwargs[\"error_messages\"] = {\"invalid\": \"Form"
    ],
    [
        "name = CharField(help_text=\"Some help text\", widget=HiddenInput)",
        "name = CharField(help_text=\"Some"
    ],
    [
        "\"{% for radio in form.language %}\"",
        "\"{% for radio in form.language"
    ],
    [
        "f = SongForm({\"composers\": [\"J\", \"P\"]}, auto_id=False)",
        "f = SongForm({\"composers\": [\"J\", \"P\"]},"
    ],
    [
        "\"{% for checkbox in form.composers %}\"",
        "\"{% for checkbox in form.composers"
    ],
    [
        "'<input checked name=\"composers\" type=\"checkbox\" value=\"J\"> '",
        "'<input checked name=\"composers\""
    ],
    [
        "'<input checked name=\"composers\" type=\"checkbox\" value=\"P\"> '",
        "'<input checked name=\"composers\""
    ],
    [
        "help_text=(\"Good luck picking a username that doesn't already exist.\"),",
        "help_text=(\"Good luck picking a username that"
    ],
    [
        "raise ValidationError(\"Please make sure your passwords match.\")",
        "raise ValidationError(\"Please make sure your passwords"
    ],
    [
        "\"<p><label>{{ form.username.label }}: {{ form.username }}</label></p>\"",
        "\"<p><label>{{ form.username.label }}: {{ form.username"
    ],
    [
        "\"<p>{{ form.username.label_tag }} {{ form.username }}\"",
        "\"<p>{{ form.username.label_tag }} {{ form.username"
    ],
    [
        "\"<span>Good luck picking a username that doesn't already exist.</span></p>\"",
        "\"<span>Good luck picking a username that"
    ],
    [
        "\"Good luck picking a username that doesn't already exist.</span></p>\"",
        "\"Good luck picking a username that"
    ],
    [
        "\"<p>{{ form.username.legend_tag }} {{ form.username }}</p>\"",
        "\"<p>{{ form.username.legend_tag }} {{ form.username"
    ],
    [
        "\"<p>{{ form.username.label_tag }} {{ form.username }}<br>\"",
        "\"<p>{{ form.username.label_tag }} {{"
    ],
    [
        "\"<li>Please make sure your passwords match.</li></ul>\"",
        "\"<li>Please make sure your passwords"
    ],
    [
        "raise ValidationError(\"Please make sure your passwords match.\")",
        "raise ValidationError(\"Please make sure your"
    ],
    [
        "\"<li>Please make sure your passwords match.</li></ul>\"",
        "\"<li>Please make sure"
    ],
    [
        "'<div class=\"error\">Enter a valid email address.</div></div>'",
        "'<div class=\"error\">Enter a valid"
    ],
    [
        "'<p>Comment: <input type=\"text\" name=\"comment\" aria-invalid=\"true\" '",
        "'<p>Comment: <input type=\"text\" name=\"comment\""
    ],
    [
        "def label_tag(self, contents=None, attrs=None, label_suffix=None, tag=None):",
        "def label_tag(self, contents=None, attrs=None,"
    ],
    [
        "def label_tag(self, contents=None, attrs=None, label_suffix=None, tag=None):",
        "def label_tag(self, contents=None,"
    ],
    [
        "def label_tag(self, contents=None, attrs=None, label_suffix=None, tag=None):",
        "def label_tag(self, contents=None,"
    ],
    [
        "with self.subTest(\"form's BoundField takes over renderer's BoundField\"):",
        "with self.subTest(\"form's BoundField takes"
    ],
    [
        "with self.subTest(\"Constructor argument takes over class property\"):",
        "with self.subTest(\"Constructor argument takes"
    ],
    [
        "with self.subTest(\"Overriding css_classes works as expected\"):",
        "with self.subTest(\"Overriding css_classes works as"
    ],
    [
        "flatatt({\"class\": \"news\", \"title\": \"Read this\", \"required\": \"required\"}),",
        "flatatt({\"class\": \"news\", \"title\": \"Read"
    ],
    [
        "flatatt({\"class\": \"news\", \"title\": \"Read this\", \"required\": True}),",
        "flatatt({\"class\": \"news\", \"title\": \"Read"
    ],
    [
        "flatatt({\"class\": \"news\", \"title\": \"Read this\", \"required\": False}),",
        "flatatt({\"class\": \"news\", \"title\": \"Read this\","
    ],
    [
        "flatatt() does not modify the dict passed in.",
        "flatatt() does not modify"
    ],
    [
        "attrs = {\"foo\": \"bar\", \"true\": True, \"false\": False}",
        "attrs = {\"foo\": \"bar\","
    ],
    [
        "example = 'Example of link: <a href=\"http://www.example.com/\">example</a>'",
        "example = 'Example of link: <a"
    ],
    [
        "[ValidationError(\"Sorry this form only works on leap days.\")]",
        "[ValidationError(\"Sorry this form only works on"
    ],
    [
        "\"Select a valid choice. That choice is not one of the \"",
        "\"Select a valid choice. That choice is not one of"
    ],
    [
        "\"__all__\": [\"Sorry this form only works on leap days.\"],",
        "\"__all__\": [\"Sorry this form only works"
    ],
    [
        "\"Select a valid choice. That choice is not one of the \"",
        "\"Select a valid choice. That choice is"
    ],
    [
        "msg = \"Subclasses of RenderableMixin must provide a get_context() method.\"",
        "msg = \"Subclasses of RenderableMixin must"
    ],
    [
        "msg = \"Subclasses of RenderableFieldMixin must provide an as_hidden() method.\"",
        "msg = \"Subclasses of RenderableFieldMixin must provide"
    ],
    [
        "msg = \"Subclasses of RenderableFieldMixin must provide an as_widget() method.\"",
        "msg = \"Subclasses of RenderableFieldMixin"
    ],
    [
        "from datetime import date, datetime, time",
        "from datetime import date,"
    ],
    [
        "\"TimeFields can parse dates in the default format\"",
        "\"TimeFields can parse dates in"
    ],
    [
        "\"Localized TimeFields act as unlocalized widgets\"",
        "\"Localized TimeFields act"
    ],
    [
        "\"TimeFields with manually specified input formats can accept those formats\"",
        "\"TimeFields with manually specified input formats can accept"
    ],
    [
        "Localized TimeFields with manually specified input formats can accept",
        "Localized TimeFields with manually specified input formats"
    ],
    [
        "\"TimeFields can parse dates in the default format\"",
        "\"TimeFields can parse dates in the"
    ],
    [
        "\"Localized TimeFields act as unlocalized widgets\"",
        "\"Localized TimeFields act"
    ],
    [
        "\"TimeFields with manually specified input formats can accept those formats\"",
        "\"TimeFields with manually specified input formats can accept"
    ],
    [
        "Localized TimeFields with manually specified input formats can accept",
        "Localized TimeFields with manually specified input formats"
    ],
    [
        "\"TimeFields can parse dates in the default format\"",
        "\"TimeFields can parse dates"
    ],
    [
        "\"Localized TimeFields in a non-localized environment act as unlocalized widgets\"",
        "\"Localized TimeFields in a non-localized environment"
    ],
    [
        "\"TimeFields with manually specified input formats can accept those formats\"",
        "\"TimeFields with manually specified input formats"
    ],
    [
        "f = forms.TimeField(input_formats=[\"%I:%M:%S %p\", \"%I:%M %p\"])",
        "f = forms.TimeField(input_formats=[\"%I:%M:%S %p\", \"%I:%M"
    ],
    [
        "Localized TimeFields with manually specified input formats can accept",
        "Localized TimeFields with manually specified input formats can"
    ],
    [
        "f = forms.TimeField(input_formats=[\"%I:%M:%S %p\", \"%I:%M %p\"], localize=True)",
        "f = forms.TimeField(input_formats=[\"%I:%M:%S %p\","
    ],
    [
        "\"DateFields can parse dates in the default format\"",
        "\"DateFields can parse dates"
    ],
    [
        "\"Localized DateFields act as unlocalized widgets\"",
        "\"Localized DateFields act as unlocalized"
    ],
    [
        "\"DateFields with manually specified input formats can accept those formats\"",
        "\"DateFields with manually specified input formats can accept"
    ],
    [
        "Localized DateFields with manually specified input formats can accept",
        "Localized DateFields with manually specified input formats"
    ],
    [
        "\"DateFields can parse dates in the default format\"",
        "\"DateFields can parse dates in the default"
    ],
    [
        "\"Localized DateFields act as unlocalized widgets\"",
        "\"Localized DateFields act"
    ],
    [
        "\"DateFields with manually specified input formats can accept those formats\"",
        "\"DateFields with manually specified input formats"
    ],
    [
        "Localized DateFields with manually specified input formats can accept",
        "Localized DateFields with manually specified input"
    ],
    [
        "\"DateFields can parse dates in the default format\"",
        "\"DateFields can parse dates in"
    ],
    [
        "\"Localized DateFields in a non-localized environment act as unlocalized widgets\"",
        "\"Localized DateFields in a non-localized environment act as"
    ],
    [
        "\"DateFields with manually specified input formats can accept those formats\"",
        "\"DateFields with manually specified input formats"
    ],
    [
        "Localized DateFields with manually specified input formats can accept",
        "Localized DateFields with manually specified input formats"
    ],
    [
        "\"DateTimeFields can parse dates in the default format\"",
        "\"DateTimeFields can parse dates in"
    ],
    [
        "\"Localized DateTimeFields act as unlocalized widgets\"",
        "\"Localized DateTimeFields act as"
    ],
    [
        "\"DateTimeFields with manually specified input formats can accept those formats\"",
        "\"DateTimeFields with manually specified input formats can"
    ],
    [
        "f = forms.DateTimeField(input_formats=[\"%H.%M.%S %m.%d.%Y\", \"%H.%M %m-%d-%Y\"])",
        "f = forms.DateTimeField(input_formats=[\"%H.%M.%S"
    ],
    [
        "Localized DateTimeFields with manually specified input formats can",
        "Localized DateTimeFields with manually specified input formats"
    ],
    [
        "@override_settings(DATETIME_INPUT_FORMATS=[\"%I:%M:%S %p %d/%m/%Y\", \"%I:%M %p %d-%m-%Y\"])",
        "@override_settings(DATETIME_INPUT_FORMATS=[\"%I:%M:%S %p %d/%m/%Y\", \"%I:%M %p"
    ],
    [
        "\"DateTimeFields can parse dates in the default format\"",
        "\"DateTimeFields can parse dates in the"
    ],
    [
        "\"Localized DateTimeFields act as unlocalized widgets\"",
        "\"Localized DateTimeFields act"
    ],
    [
        "\"DateTimeFields with manually specified input formats can accept those formats\"",
        "\"DateTimeFields with manually specified input formats"
    ],
    [
        "f = forms.DateTimeField(input_formats=[\"%m.%d.%Y %H:%M:%S\", \"%m-%d-%Y %H:%M\"])",
        "f = forms.DateTimeField(input_formats=[\"%m.%d.%Y %H:%M:%S\","
    ],
    [
        "Localized DateTimeFields with manually specified input formats can",
        "Localized DateTimeFields with manually specified input"
    ],
    [
        "\"DateTimeFields can parse dates in the default format\"",
        "\"DateTimeFields can parse dates in"
    ],
    [
        "Localized DateTimeFields in a non-localized environment act as",
        "Localized DateTimeFields in a non-localized environment"
    ],
    [
        "\"DateTimeFields with manually specified input formats can accept those formats\"",
        "\"DateTimeFields with manually specified input formats can accept those"
    ],
    [
        "input_formats=[\"%I:%M:%S %p %d.%m.%Y\", \"%I:%M %p %d-%m-%Y\"]",
        "input_formats=[\"%I:%M:%S %p %d.%m.%Y\", \"%I:%M %p"
    ],
    [
        "Localized DateTimeFields with manually specified input formats can",
        "Localized DateTimeFields with manually specified input"
    ],
    [
        "input_formats=[\"%I:%M:%S %p %d.%m.%Y\", \"%I:%M %p %d-%m-%Y\"], localize=True",
        "input_formats=[\"%I:%M:%S %p %d.%m.%Y\", \"%I:%M"
    ],
    [
        "form = UserForm({\"full_name\": \"not int nor mail\"})",
        "form = UserForm({\"full_name\": \"not int"
    ],
    [
        "[\"Enter a valid integer.\", \"Enter a valid email address.\"],",
        "[\"Enter a valid integer.\", \"Enter a"
    ],
    [
        "for validator, value, code in cases:",
        "for validator, value,"
    ],
    [
        "for validator, value, code in cases:",
        "for validator, value,"
    ],
    [
        "from django.forms import CharField, Form, Media, MultiWidget, TextInput",
        "from django.forms import CharField,"
    ],
    [
        "attributes = {\"media\": \"all\", \"is\": \"magic-css\"}",
        "attributes = {\"media\": \"all\","
    ],
    [
        "\"\"\"Tests for the media handling on widgets and forms\"\"\"",
        "\"\"\"Tests for the media handling on widgets and"
    ],
    [
        "The relative order of scripts is preserved in a three-way merge.",
        "The relative order of scripts is preserved in a three-way"
    ],
    [
        "self.assertEqual(merged._js, [\"a\", \"b\", \"c\", \"f\", \"g\", \"h\", \"k\"])",
        "self.assertEqual(merged._js, [\"a\", \"b\", \"c\","
    ],
    [
        "merged._css, {\"screen\": [\"c.css\", \"a.css\"], \"all\": [\"d.css\", \"e.css\"]}",
        "merged._css, {\"screen\": [\"c.css\", \"a.css\"],"
    ],
    [
        "{\"screen\": [\"a.css\", \"b.css\", \"c.css\"], \"all\": [\"d.css\", \"e.css\"]},",
        "{\"screen\": [\"a.css\", \"b.css\", \"c.css\"],"
    ],
    [
        "self.assertEqual(merged._css, {\"screen\": [\"c.css\"], \"all\": [\"d.css\", \"e.css\"]})",
        "self.assertEqual(merged._css, {\"screen\": [\"c.css\"], \"all\": [\"d.css\","
    ],
    [
        "self.assertEqual(merged._js_lists, [[\"a\", \"b\", \"c\"], [\"a\", \"b\"]])",
        "self.assertEqual(merged._js_lists, [[\"a\", \"b\", \"c\"],"
    ],
    [
        "self.assertEqual(merged._js_lists, [[\"a\", \"b\", \"c\"], [\"a\", \"c\", \"b\"]])",
        "self.assertEqual(merged._js_lists, [[\"a\", \"b\", \"c\"],"
    ],
    [
        "\"Detected duplicate Media files in an opposite order: \"",
        "\"Detected duplicate Media files in an"
    ],
    [
        "\"['a', 'b', 'c'], ['a', 'c', 'b']\"",
        "\"['a', 'b', 'c'], ['a',"
    ],
    [
        "self.assertEqual(merged._css, {\"screen\": [\"a.css\", \"c.css\"], \"all\": [\"b.css\"]})",
        "self.assertEqual(merged._css, {\"screen\": [\"a.css\", \"c.css\"],"
    ],
    [
        "\"Detected duplicate Media files in an opposite order: \"",
        "\"Detected duplicate Media files in an opposite"
    ],
    [
        "\"\"\"Media handling when media are objects instead of raw strings.\"\"\"",
        "\"\"\"Media handling when media are"
    ],
    [
        "A roundtrip on a ModelForm doesn't alter the TextField value",
        "A roundtrip on a ModelForm doesn't alter the"
    ],
    [
        "def assertFormErrors(self, expected, the_callable, *args, **kwargs):",
        "def assertFormErrors(self, expected, the_callable,"
    ],
    [
        "\"min_length\": \"LENGTH %(show_value)s, MIN LENGTH %(limit_value)s\",",
        "\"min_length\": \"LENGTH %(show_value)s,"
    ],
    [
        "\"max_length\": \"LENGTH %(show_value)s, MAX LENGTH %(limit_value)s\",",
        "\"max_length\": \"LENGTH %(show_value)s, MAX"
    ],
    [
        "\"max_whole_digits\": \"MAX DIGITS BEFORE DP IS %(max)s\",",
        "\"max_whole_digits\": \"MAX DIGITS BEFORE DP IS"
    ],
    [
        "\"min_length\": \"LENGTH %(show_value)s, MIN LENGTH %(limit_value)s\",",
        "\"min_length\": \"LENGTH %(show_value)s,"
    ],
    [
        "\"max_length\": \"LENGTH %(show_value)s, MAX LENGTH %(limit_value)s\",",
        "\"max_length\": \"LENGTH %(show_value)s, MAX LENGTH"
    ],
    [
        "\"min_length\": \"LENGTH %(show_value)s, MIN LENGTH %(limit_value)s\",",
        "\"min_length\": \"LENGTH %(show_value)s,"
    ],
    [
        "\"max_length\": \"LENGTH %(show_value)s, MAX LENGTH %(limit_value)s\",",
        "\"max_length\": \"LENGTH %(show_value)s, MAX"
    ],
    [
        "\"max_length\": '\"%(value)s\" has more than %(limit_value)d characters.',",
        "\"max_length\": '\"%(value)s\" has more than %(limit_value)d"
    ],
    [
        "self.assertFormErrors([\"b IS INVALID CHOICE\"], f.clean, \"b\")",
        "self.assertFormErrors([\"b IS INVALID CHOICE\"], f.clean,"
    ],
    [
        "self.assertFormErrors([\"b IS INVALID CHOICE\"], f.clean, [\"b\"])",
        "self.assertFormErrors([\"b IS INVALID"
    ],
    [
        "self.assertFormErrors([\"INVALID DATE\", \"INVALID TIME\"], f.clean, [\"a\", \"b\"])",
        "self.assertFormErrors([\"INVALID DATE\", \"INVALID TIME\"],"
    ],
    [
        "raise ValidationError(\"I like to be awkward.\")",
        "raise ValidationError(\"I like to be"
    ],
    [
        "% \"\".join(\"<p>%s</p>\" % e for e in self)",
        "% \"\".join(\"<p>%s</p>\" % e for"
    ],
    [
        "'<ul class=\"errorlist nonfield\"><li>I like to be awkward.</li></ul>',",
        "'<ul class=\"errorlist nonfield\"><li>I like"
    ],
    [
        "'<div class=\"error\"><p>I like to be awkward.</p></div>',",
        "'<div class=\"error\"><p>I like"
    ],
    [
        "\"<li>Select a valid choice. &lt;script&gt; is not one of the \"",
        "\"<li>Select a valid choice. &lt;script&gt; is not"
    ],
    [
        "\"<li>Select a valid choice. &lt;script&gt; is not one of the \"",
        "\"<li>Select a valid choice. &lt;script&gt; is not"
    ],
    [
        "\"<li>“&lt;script&gt;” is not a valid value.</li>\"",
        "\"<li>“&lt;script&gt;” is not a valid"
    ],
    [
        "\"invalid_list\": \"NOT A LIST OF VALUES\",",
        "\"invalid_list\": \"NOT A LIST OF"
    ],
    [
        "\"invalid_choice\": '\"%(value)s\" is not one of the available choices.',",
        "\"invalid_choice\": '\"%(value)s\" is not one of the"
    ],
    [
        "['\"invalid\" is not one of the available choices.'],",
        "['\"invalid\" is not one of the available"
    ],
    [
        "\"\"\"Can find a custom template in INSTALLED_APPS.\"\"\"",
        "\"\"\"Can find a custom"
    ],
    [
        "raise ValidationError(\"You may only specify a drink once.\")",
        "raise ValidationError(\"You may only specify"
    ],
    [
        "Make a ChoiceFormset from the given formset_data.",
        "Make a ChoiceFormset from"
    ],
    [
        "The data should be given as a list of (choice, votes) tuples.",
        "The data should be given as a list of (choice, votes)"
    ],
    [
        "for i, (choice, votes) in enumerate(formset_data):",
        "for i, (choice, votes)"
    ],
    [
        "A FormSet constructor takes the same arguments as Form. Create a",
        "A FormSet constructor takes the same arguments as Form."
    ],
    [
        "Custom kwargs set on the formset instance are passed to the",
        "Custom kwargs set on the formset instance are passed"
    ],
    [
        "\"\"\"Form kwargs can be passed dynamically in a formset.\"\"\"",
        "\"\"\"Form kwargs can be passed dynamically in"
    ],
    [
        "self.assertEqual(formset.errors, [{\"votes\": [\"This field is required.\"]}])",
        "self.assertEqual(formset.errors, [{\"votes\": [\"This field is"
    ],
    [
        "A formset's ManagementForm is validated once per FormSet.is_valid()",
        "A formset's ManagementForm is validated"
    ],
    [
        "call and each form of the formset is cleaned once.",
        "call and each form of the formset"
    ],
    [
        "\"\"\"Add a counter to func for the number of times it's called.\"\"\"",
        "\"\"\"Add a counter to func for the number of"
    ],
    [
        "FormSet.has_changed() is True if any data is passed to its forms, even",
        "FormSet.has_changed() is True if any data is passed to its"
    ],
    [
        "A FormSet can be prefilled with existing data by providing a list of",
        "A FormSet can be prefilled with existing data by"
    ],
    [
        "dicts to the `initial` argument. By default, an extra blank form is",
        "dicts to the `initial` argument. By default, an"
    ],
    [
        "\"\"\"A form that's displayed as blank may be submitted as blank.\"\"\"",
        "\"\"\"A form that's displayed as blank may be submitted as"
    ],
    [
        "If at least one field is filled out on a blank form, it will be",
        "If at least one field is filled out on a blank"
    ],
    [
        "self.assertEqual(formset.errors, [{}, {\"votes\": [\"This field is required.\"]}])",
        "self.assertEqual(formset.errors, [{}, {\"votes\": [\"This"
    ],
    [
        "Deleting prefilled data is an error. Removing data from form fields",
        "Deleting prefilled data is an error. Removing data from"
    ],
    [
        "isn't the proper way to delete it.",
        "isn't the proper way to"
    ],
    [
        "self.assertEqual([form.cleaned_data for form in formset.forms], [{}, {}, {}])",
        "self.assertEqual([form.cleaned_data for form in formset.forms],"
    ],
    [
        "min_num argument. It will (essentially) increment the extra argument.",
        "min_num argument. It will (essentially)"
    ],
    [
        "\"\"\"Just one form may be completed.\"\"\"",
        "\"\"\"Just one form may be"
    ],
    [
        "If validate_max is set and max_num is less than TOTAL_FORMS in the",
        "If validate_max is set and max_num is less"
    ],
    [
        "data, a ValidationError is raised. MAX_NUM_FORMS in the data is",
        "data, a ValidationError is raised."
    ],
    [
        "irrelevant here (it's output as a hint for the client but its value",
        "irrelevant here (it's output as a hint for the client but"
    ],
    [
        "in the returned data is not checked).",
        "in the returned data is not"
    ],
    [
        "\"too_many_forms\": \"Number of submitted forms should be at most %(num)d.\"",
        "\"too_many_forms\": \"Number of submitted forms"
    ],
    [
        "If validate_min is set and min_num is more than TOTAL_FORMS in the",
        "If validate_min is set and min_num is more than TOTAL_FORMS in"
    ],
    [
        "data, a ValidationError is raised. MIN_NUM_FORMS in the data is",
        "data, a ValidationError is raised."
    ],
    [
        "irrelevant here (it's output as a hint for the client but its value",
        "irrelevant here (it's output as a hint for the client"
    ],
    [
        "in the returned data is not checked).",
        "in the returned data is"
    ],
    [
        "\"too_few_forms\": \"Number of submitted forms should be at least %(num)d.\"",
        "\"too_few_forms\": \"Number of submitted forms should"
    ],
    [
        "min_num validation doesn't consider unchanged forms with initial data",
        "min_num validation doesn't consider unchanged forms with initial"
    ],
    [
        "formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\", initial=initial)",
        "formset = ChoiceFormSet(data,"
    ],
    [
        "\"\"\"A partially completed form is invalid.\"\"\"",
        "\"\"\"A partially completed"
    ],
    [
        "formset.errors, [{}, {\"votes\": [\"This field is required.\"]}, {}]",
        "formset.errors, [{}, {\"votes\": [\"This"
    ],
    [
        "The extra argument works when the formset is pre-filled with initial",
        "The extra argument works when the formset is pre-filled with"
    ],
    [
        "formset_factory's can_delete argument adds a boolean \"delete\" field to",
        "formset_factory's can_delete argument adds a boolean \"delete\" field"
    ],
    [
        "each form. When that boolean field is True, the form will be in",
        "each form. When that boolean field is True, the form"
    ],
    [
        "If a form is filled with something and can_delete is also checked, that",
        "If a form is filled with something and"
    ],
    [
        "form's errors shouldn't make the entire formset invalid since it's",
        "form's errors shouldn't make the entire formset"
    ],
    [
        "deleted_forms works on a valid formset even if a deleted form would",
        "deleted_forms works on a valid formset even if a deleted form"
    ],
    [
        "formset_factory's can_order argument adds an integer field to each",
        "formset_factory's can_order argument adds an integer"
    ],
    [
        "will have the data in the correct order specified by the ordering",
        "will have the data in the correct"
    ],
    [
        "fields. If a number is duplicated in the set of ordering fields, for",
        "fields. If a number is duplicated in the set"
    ],
    [
        "used as a secondary ordering criteria. In order to put something at the",
        "used as a secondary ordering criteria. In order to put something"
    ],
    [
        "Ordering fields are allowed to be left blank. If they are left blank,",
        "Ordering fields are allowed to be left blank. If they are"
    ],
    [
        "they'll be sorted below everything else.",
        "they'll be sorted"
    ],
    [
        "Can get ordered_forms from a valid formset even if a deleted form",
        "Can get ordered_forms from a valid formset even if a deleted"
    ],
    [
        "FormSets have a clean() hook for doing extra validation that isn't tied",
        "FormSets have a clean() hook for doing extra validation"
    ],
    [
        "to any form. It follows the same pattern as the clean() hook on Forms.",
        "to any form. It follows the same pattern as the clean() hook"
    ],
    [
        "self.assertEqual(str(error), \"You may only specify a drink once.\")",
        "self.assertEqual(str(error), \"You may only"
    ],
    [
        "\"\"\"Limiting the maximum number of forms with max_num.\"\"\"",
        "\"\"\"Limiting the maximum number of forms with"
    ],
    [
        "\"\"\"max_num has no effect when extra is less than max_num.\"\"\"",
        "\"\"\"max_num has no effect when extra is less than"
    ],
    [
        "formset = LimitedFavoriteDrinkFormSet(initial=[{\"name\": \"Fernet and Coke\"}])",
        "formset = LimitedFavoriteDrinkFormSet(initial=[{\"name\": \"Fernet and"
    ],
    [
        "More initial forms than max_num results in all initial forms being",
        "More initial forms than max_num results in all initial forms"
    ],
    [
        "msg = \"'absolute_max' must be greater or equal to 'max_num'.\"",
        "msg = \"'absolute_max' must be greater or equal"
    ],
    [
        "\"\"\"The management form class has field names matching the constants.\"\"\"",
        "\"\"\"The management form class has field names"
    ],
    [
        "\"\"\"The management form has the correct prefix.\"\"\"",
        "\"\"\"The management form has"
    ],
    [
        "formset.non_form_errors(), [\"You may only specify a drink once.\"]",
        "formset.non_form_errors(), [\"You may only specify a"
    ],
    [
        "\"You may only specify a drink once.</li></ul>\",",
        "\"You may only specify a"
    ],
    [
        "\"\"\"A formsets without any forms evaluates as True.\"\"\"",
        "\"\"\"A formsets without any"
    ],
    [
        "\"\"\"Formset's forms use the formset's error_class.\"\"\"",
        "\"\"\"Formset's forms use the"
    ],
    [
        "\"\"\"Formsets call is_valid() on each form.\"\"\"",
        "\"\"\"Formsets call is_valid()"
    ],
    [
        "\"\"\"A formset has a hard limit on the number of forms instantiated.\"\"\"",
        "\"\"\"A formset has a hard limit on the number of"
    ],
    [
        "\"\"\"Can increase the built-in forms limit via a higher max_num.\"\"\"",
        "\"\"\"Can increase the built-in forms limit"
    ],
    [
        "If non_form_errors() is called without calling is_valid() first,",
        "If non_form_errors() is called without calling"
    ],
    [
        "it should ensure that full_clean() is called.",
        "it should ensure that full_clean() is"
    ],
    [
        "raise ValidationError(\"This is a non-form error\")",
        "raise ValidationError(\"This is"
    ],
    [
        "self.assertEqual(list(formset.non_form_errors()), [\"This is a non-form error\"])",
        "self.assertEqual(list(formset.non_form_errors()), [\"This is a"
    ],
    [
        "A custom renderer passed to a formset_factory() is passed to all forms",
        "A custom renderer passed to a formset_factory()"
    ],
    [
        "In the absence of a renderer passed to the formset_factory(),",
        "In the absence of a renderer passed"
    ],
    [
        "In the absence of a renderer passed to the formset_factory(),",
        "In the absence of a renderer passed to the"
    ],
    [
        "\"ManagementForm data is missing or has been tampered with. \"",
        "\"ManagementForm data is missing or has been"
    ],
    [
        "\"You may need to file a bug report if the issue persists.\",",
        "\"You may need to file a bug report if"
    ],
    [
        "\"<li>(Hidden field TOTAL_FORMS) This field is required.</li>\"",
        "\"<li>(Hidden field TOTAL_FORMS) This field"
    ],
    [
        "\"<li>(Hidden field INITIAL_FORMS) This field is required.</li>\"",
        "\"<li>(Hidden field INITIAL_FORMS) This field is"
    ],
    [
        "\"ManagementForm data is missing or has been tampered with. \"",
        "\"ManagementForm data is missing or has been"
    ],
    [
        "\"You may need to file a bug report if the issue persists.\",",
        "\"You may need to file a bug"
    ],
    [
        "\"<li>(Hidden field TOTAL_FORMS) Enter a whole number.</li>\"",
        "\"<li>(Hidden field TOTAL_FORMS) Enter"
    ],
    [
        "\"<li>(Hidden field INITIAL_FORMS) Enter a whole number.</li>\"",
        "\"<li>(Hidden field INITIAL_FORMS) Enter"
    ],
    [
        "[{}, {\"pub_date\": [\"This field is required.\"]}], formset.errors",
        "[{}, {\"pub_date\": [\"This field"
    ],
    [
        "\"\"\"An empty formset still calls clean()\"\"\"",
        "\"\"\"An empty formset still"
    ],
    [
        "\"\"\"Media is available on empty formset.\"\"\"",
        "\"\"\"Media is available"
    ],
    [
        "\"\"\"is_multipart() works with an empty formset.\"\"\"",
        "\"\"\"is_multipart() works with"
    ],
    [
        "\"\"\"all_valid() validates all forms, even when some are invalid.\"\"\"",
        "\"\"\"all_valid() validates all forms, even when"
    ],
    [
        "from django.forms import CharField, FileField, Form, ModelForm",
        "from django.forms import CharField,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase,"
    ],
    [
        "The return values of ModelMultipleChoiceFields are QuerySets",
        "The return values of ModelMultipleChoiceFields are"
    ],
    [
        "If a model's ManyToManyField has blank=True and is saved with no data,",
        "If a model's ManyToManyField has blank=True and"
    ],
    [
        "If a model's ForeignKey has blank=False and a default, no empty option",
        "If a model's ForeignKey has blank=False and a"
    ],
    [
        "The initial value for a callable default returning a queryset is the",
        "The initial value for a callable default"
    ],
    [
        "\"我隻氣墊船裝滿晒鱔.txt\", \"मेरी मँडराने वाली नाव सर्पमीनों से भरी ह\".encode()",
        "\"我隻氣墊船裝滿晒鱔.txt\", \"मेरी मँडराने वाली नाव सर्पमीनों से भरी"
    ],
    [
        "\"Cannot create form field for 'ref' yet, because \"",
        "\"Cannot create form field for"
    ],
    [
        "\"its related model 'B' has not been loaded yet\"",
        "\"its related model 'B' has"
    ],
    [
        "for form, key, expected in tests:",
        "for form, key, expected in"
    ],
    [
        "f = form({\"name\": \"some-key\", key: \"\"})",
        "f = form({\"name\":"
    ],
    [
        "from django.forms import DateField, Form, SelectDateWidget",
        "from django.forms import"
    ],
    [
        "Rendering the None or '' values should yield the same output.",
        "Rendering the None or '' values should"
    ],
    [
        "Invalid dates should still render the failed date.",
        "Invalid dates should still"
    ],
    [
        "for field, value in zip((\"year\", \"month\", \"day\"), values)",
        "for field, value in"
    ],
    [
        "for field, value in zip((\"year\", \"month\", \"day\"), values)",
        "for field, value in zip((\"year\", \"month\", \"day\"),"
    ],
    [
        "year, month, day = (int(x) or \"\" for x in value.split(\"-\"))",
        "year, month, day = (int(x) or \"\""
    ],
    [
        "{\"day\": day, \"month\": month, \"year\": year},",
        "{\"day\": day, \"month\": month, \"year\":"
    ],
    [
        "{\"day\": None, \"month\": None, \"year\": None},",
        "{\"day\": None, \"month\": None, \"year\":"
    ],
    [
        "for field_name, value in zip((\"year\", \"month\", \"day\"), values):",
        "for field_name, value in zip((\"year\","
    ],
    [
        "from django.forms import CharField, Form, HiddenInput",
        "from django.forms import CharField, Form,"
    ],
    [
        "self.widget, \"email\", \"\", html='<input type=\"hidden\" name=\"email\">'",
        "self.widget, \"email\", \"\","
    ],
    [
        "from django.forms import CheckboxSelectMultiple, ChoiceField, Form",
        "from django.forms import"
    ],
    [
        "<div><label><input checked type=\"checkbox\" name=\"beatles\" value=\"J\"> John",
        "<div><label><input checked type=\"checkbox\""
    ],
    [
        "<div><label><input checked type=\"checkbox\" name=\"beatles\" value=\"J\"> John",
        "<div><label><input checked type=\"checkbox\""
    ],
    [
        "<div><label><input checked type=\"checkbox\" name=\"beatles\" value=\"P\"> Paul",
        "<div><label><input checked type=\"checkbox\""
    ],
    [
        "If the value is None, none of the options are selected, even if the",
        "If the value is None, none of the options are selected, even"
    ],
    [
        "<input checked type=\"checkbox\" name=\"nestchoice\" value=\"vinyl\"> Vinyl",
        "<input checked type=\"checkbox\""
    ],
    [
        "Each input gets a separate ID.",
        "Each input gets a separate"
    ],
    [
        "choices = [(\"a\", \"A\"), (\"b\", \"B\"), (\"c\", \"C\")]",
        "choices = [(\"a\", \"A\"), (\"b\","
    ],
    [
        "Each input gets a separate ID when the ID is passed to the constructor.",
        "Each input gets a separate ID when the ID is passed"
    ],
    [
        "attrs={\"id\": \"abc\"}, choices=[(\"a\", \"A\"), (\"b\", \"B\"), (\"c\", \"C\")]",
        "attrs={\"id\": \"abc\"}, choices=[(\"a\", \"A\"), (\"b\", \"B\"), (\"c\","
    ],
    [
        "because clicking that would toggle the first checkbox.",
        "because clicking that would toggle the first"
    ],
    [
        "widget, \"name\", \"value\", '<input type=\"date\" name=\"name\" value=\"value\">'",
        "widget, \"name\", \"value\", '<input type=\"date\""
    ],
    [
        "widget, \"name\", \"value\", '<input type=\"date\" name=\"name\" value=\"value\">'",
        "widget, \"name\", \"value\", '<input type=\"date\" name=\"name\""
    ],
    [
        "from django.forms import CharField, DateInput, Form",
        "from django.forms import CharField,"
    ],
    [
        "self.widget, \"date\", None, html='<input type=\"text\" name=\"date\">'",
        "self.widget, \"date\", None, html='<input"
    ],
    [
        "Should be able to initialize from a string value.",
        "Should be able to initialize from"
    ],
    [
        "Use 'format' to change the way a value is displayed.",
        "Use 'format' to change the way a"
    ],
    [
        "from django.forms import ChoiceField, Form, MultiWidget, Select, TextInput",
        "from django.forms import ChoiceField, Form, MultiWidget, Select,"
    ],
    [
        "If the value is None, none of the options are selected.",
        "If the value is None, none of"
    ],
    [
        "If the value corresponds to a label (but not to an option value), none",
        "If the value corresponds to a label (but not to an"
    ],
    [
        "Select options shouldn't inherit the parent widget attrs.",
        "Select options shouldn't inherit the parent"
    ],
    [
        "The value is compared to its str().",
        "The value is compared to its"
    ],
    [
        "If choices is passed to the constructor and is a generator, it can be",
        "If choices is passed to the constructor and"
    ],
    [
        "iterated over multiple times without getting consumed.",
        "iterated over multiple times"
    ],
    [
        "choices = ((\"bad\", \"you & me\"), (\"good\", mark_safe(\"you &gt; me\")))",
        "choices = ((\"bad\", \"you &"
    ],
    [
        "Choices can be nested one level in order to create HTML optgroups.",
        "Choices can be nested one level"
    ],
    [
        "k: dict(v) if isinstance(v, list) else v for k, v in choices_dict.items()",
        "k: dict(v) if isinstance(v, list) else v for"
    ],
    [
        "for choices in (choices_dict, choices_list, choices_nested_dict):",
        "for choices in (choices_dict,"
    ],
    [
        "widget = self.widget(choices=[(\"J\", \"John\"), (\"P\", \"Paul\")])",
        "widget = self.widget(choices=[(\"J\", \"John\"), (\"P\","
    ],
    [
        "\"\"\"A RadioSelect as a subwidget of MultiWidget.\"\"\"",
        "\"\"\"A RadioSelect as a subwidget"
    ],
    [
        "choices = ((\"\", \"------\"),) + self.beatles",
        "choices = ((\"\", \"------\"),) +"
    ],
    [
        "from django.forms import Form, SplitDateTimeField, SplitHiddenDateTimeWidget",
        "from django.forms import Form,"
    ],
    [
        "from django.forms import CharField, Form, Textarea",
        "from django.forms import CharField, Form,"
    ],
    [
        "from django.forms import ClearableFileInput, FileField, Form, MultiWidget",
        "from django.forms import ClearableFileInput,"
    ],
    [
        "Quacks like a FieldFile (has a .url and string representation), but",
        "Quacks like a FieldFile (has a .url and string representation),"
    ],
    [
        "doesn't require us to care about storages etc.",
        "doesn't require us to care"
    ],
    [
        "A ClearableFileInput with is_required False and rendered with an",
        "A ClearableFileInput with is_required False"
    ],
    [
        "initial value that is a file renders a clear checkbox.",
        "initial value that is a file renders"
    ],
    [
        "A ClearableFileInput should escape name, filename, and URL",
        "A ClearableFileInput should escape name,"
    ],
    [
        "A ClearableFileInput with is_required=True does not render a clear",
        "A ClearableFileInput with is_required=True does not render"
    ],
    [
        "A ClearableFileInput instantiated with no initial value does not render",
        "A ClearableFileInput instantiated with no initial value does not"
    ],
    [
        "self.widget, \"myfile\", None, html='<input type=\"file\" name=\"myfile\">'",
        "self.widget, \"myfile\", None, html='<input type=\"file\""
    ],
    [
        "\"\"\"A ClearableFileInput as a subwidget of MultiWidget.\"\"\"",
        "\"\"\"A ClearableFileInput as a subwidget"
    ],
    [
        "ClearableFileInput.value_from_datadict returns False if the clear",
        "ClearableFileInput.value_from_datadict returns False"
    ],
    [
        "checkbox is checked, if not required.",
        "checkbox is checked, if not"
    ],
    [
        "ClearableFileInput.value_from_datadict never returns False if the field",
        "ClearableFileInput.value_from_datadict never returns False"
    ],
    [
        "A ClearableFileInput should not mask exceptions produced while",
        "A ClearableFileInput should not mask exceptions produced"
    ],
    [
        "checking that it has a value.",
        "checking that it"
    ],
    [
        "msg = \"ClearableFileInput doesn't support uploading multiple files.\"",
        "msg = \"ClearableFileInput doesn't"
    ],
    [
        "from django.forms import BooleanField, CheckboxInput, Form",
        "from django.forms import BooleanField,"
    ],
    [
        "self.widget, \"is_cool\", \"\", html='<input type=\"checkbox\" name=\"is_cool\">'",
        "self.widget, \"is_cool\", \"\", html='<input"
    ],
    [
        "self.widget, \"is_cool\", None, html='<input type=\"checkbox\" name=\"is_cool\">'",
        "self.widget, \"is_cool\", None, html='<input"
    ],
    [
        "self.widget, \"is_cool\", False, html='<input type=\"checkbox\" name=\"is_cool\">'",
        "self.widget, \"is_cool\", False, html='<input"
    ],
    [
        "Using any value that's not in ('', None, False, True) will check the",
        "Using any value that's not in ('', None, False,"
    ],
    [
        "checkbox and set the 'value' attribute.",
        "checkbox and set the"
    ],
    [
        "You can pass 'check_test' to the constructor. This is a callable that",
        "You can pass 'check_test' to the constructor. This"
    ],
    [
        "takes the value and returns True if the box should be checked.",
        "takes the value and returns True if the box should be"
    ],
    [
        "widget, \"greeting\", \"\", html=('<input type=\"checkbox\" name=\"greeting\">')",
        "widget, \"greeting\", \"\","
    ],
    [
        "'<input checked type=\"checkbox\" name=\"greeting\" value=\"hello there\">'",
        "'<input checked type=\"checkbox\" name=\"greeting\" value=\"hello"
    ],
    [
        "The CheckboxInput widget will return False if the key is not found in",
        "The CheckboxInput widget will return False if the key is not"
    ],
    [
        "the data dictionary (because HTML form submission doesn't send any",
        "the data dictionary (because HTML"
    ],
    [
        "from django.forms import ChoiceField, Form, MultiWidget, RadioSelect, TextInput",
        "from django.forms import ChoiceField,"
    ],
    [
        "If value is None, none of the options are selected.",
        "If value is None, none"
    ],
    [
        "If the value corresponds to a label (but not to an option value), none",
        "If the value corresponds to a label (but not"
    ],
    [
        "Only one option can be selected.",
        "Only one option"
    ],
    [
        "Attributes provided at instantiation are passed to the constituent",
        "Attributes provided at instantiation are passed"
    ],
    [
        "The value is compared to its str().",
        "The value is compared to"
    ],
    [
        "If choices is passed to the constructor and is a generator, it can be",
        "If choices is passed to the constructor and is a"
    ],
    [
        "iterated over multiple times without getting consumed.",
        "iterated over multiple times without getting"
    ],
    [
        "choices = ((\"bad\", \"you & me\"), (\"good\", mark_safe(\"you &gt; me\")))",
        "choices = ((\"bad\", \"you & me\"),"
    ],
    [
        "<label><input type=\"radio\" name=\"escape\" value=\"bad\">you & me</label>",
        "<label><input type=\"radio\" name=\"escape\" value=\"bad\">you &"
    ],
    [
        "<label><input type=\"radio\" name=\"escape\" value=\"good\">you &gt; me</label>",
        "<label><input type=\"radio\" name=\"escape\" value=\"good\">you &gt;"
    ],
    [
        "Choices can be nested one level in order to create HTML optgroups.",
        "Choices can be nested one level in order to create HTML"
    ],
    [
        "Attributes provided at render-time are passed to the constituent",
        "Attributes provided at render-time are passed to the"
    ],
    [
        "The <div> in the multiple_input.html widget template include the class",
        "The <div> in the multiple_input.html widget template include the"
    ],
    [
        "<input checked type=\"radio\" class=\"bar\" value=\"J\" name=\"beatle\">John</label>",
        "<input checked type=\"radio\" class=\"bar\""
    ],
    [
        "\"\"\"A RadioSelect as a subwidget of MultiWidget.\"\"\"",
        "\"\"\"A RadioSelect as a subwidget"
    ],
    [
        "from django.forms import CharField, Form, TimeInput",
        "from django.forms import CharField,"
    ],
    [
        "self.widget, \"time\", None, html='<input type=\"text\" name=\"time\">'",
        "self.widget, \"time\", None, html='<input type=\"text\""
    ],
    [
        "The microseconds are trimmed on display, by default.",
        "The microseconds are trimmed on display,"
    ],
    [
        "Use 'format' to change the way a value is displayed.",
        "Use 'format' to change the way a value"
    ],
    [
        "self.widget, \"telephone\", \"\", html='<input type=\"tel\" name=\"telephone\">'",
        "self.widget, \"telephone\", \"\","
    ],
    [
        "from datetime import date, datetime, time",
        "from datetime import date, datetime,"
    ],
    [
        "from django.forms import Form, SplitDateTimeField, SplitDateTimeWidget",
        "from django.forms import Form, SplitDateTimeField,"
    ],
    [
        "Use 'date_format' and 'time_format' to change the way a value is",
        "Use 'date_format' and 'time_format' to change the"
    ],
    [
        "from django.forms import Form, NullBooleanField, NullBooleanSelect",
        "from django.forms import Form,"
    ],
    [
        "html = '<input type=\"None\" name=\"name\" value=\"value\">'",
        "html = '<input type=\"None\" name=\"name\""
    ],
    [
        "self.check_html(Input(), \"name\", \"value\", html=html, attrs={\"readonly\": False})",
        "self.check_html(Input(), \"name\", \"value\", html=html,"
    ],
    [
        "from django.forms import ChoiceField, Form, SelectMultiple",
        "from django.forms import ChoiceField, Form,"
    ],
    [
        "If the value is None, none of the options are selected, even if the",
        "If the value is None, none of the options are selected, even"
    ],
    [
        "If the value corresponds to a label (but not to an option value), none",
        "If the value corresponds to a label (but not"
    ],
    [
        "If multiple values are given, but some of them are not valid, the valid",
        "If multiple values are given, but some of them are not valid,"
    ],
    [
        "from django.forms import Form, MultipleChoiceField, MultipleHiddenInput",
        "from django.forms import Form, MultipleChoiceField,"
    ],
    [
        "Each input should get a separate ID.",
        "Each input should get"
    ],
    [
        "choices=[(\"J\", \"John Lennon\"), (\"P\", \"Paul McCartney\")],",
        "choices=[(\"J\", \"John Lennon\"),"
    ],
    [
        "__deepcopy__() should copy all attributes properly.",
        "__deepcopy__() should copy"
    ],
    [
        "\"\"\"The option 'value' is the same type as what's in `choices`.\"\"\"",
        "\"\"\"The option 'value' is the same type as what's in"
    ],
    [
        "widget = self.widget(choices=[(None, \"select please\"), (\"P\", \"Paul\")])",
        "widget = self.widget(choices=[(None, \"select please\"),"
    ],
    [
        "widget = self.widget(choices=[[\"\", \"select please\"], [\"P\", \"Paul\"]])",
        "widget = self.widget(choices=[[\"\", \"select please\"], [\"P\","
    ],
    [
        "widget = self.widget(choices=[(\"\", \"select please\"), (\"P\", \"Paul\")])",
        "widget = self.widget(choices=[(\"\", \"select please\"),"
    ],
    [
        "self.widget, \"search\", \"\", html='<input type=\"search\" name=\"search\">'",
        "self.widget, \"search\", \"\", html='<input type=\"search\""
    ],
    [
        "from django.forms import FileField, FileInput, Form",
        "from django.forms import FileField,"
    ],
    [
        "FileInput widgets never render the value attribute. The old value",
        "FileInput widgets never render the value attribute. The"
    ],
    [
        "isn't useful if a form is updated or an error occurred.",
        "isn't useful if a form is"
    ],
    [
        "self.widget, \"email\", \"\", html='<input type=\"file\" name=\"email\">'",
        "self.widget, \"email\", \"\","
    ],
    [
        "self.widget, \"email\", None, html='<input type=\"file\" name=\"email\">'",
        "self.widget, \"email\", None, html='<input"
    ],
    [
        "msg = \"FileInput doesn't support uploading multiple files.\"",
        "msg = \"FileInput doesn't support uploading"
    ],
    [
        "from django.forms import CharField, DateTimeInput, Form",
        "from django.forms import"
    ],
    [
        "self.check_html(self.widget, \"date\", None, '<input type=\"text\" name=\"date\">')",
        "self.check_html(self.widget, \"date\", None,"
    ],
    [
        "The microseconds are trimmed on display, by default.",
        "The microseconds are trimmed"
    ],
    [
        "Use 'format' to change the way a value is displayed.",
        "Use 'format' to change the way a value"
    ],
    [
        "from django.forms import CharField, Form, TextInput",
        "from django.forms import"
    ],
    [
        "self.widget, \"email\", \"\", html='<input type=\"text\" name=\"email\">'",
        "self.widget, \"email\", \"\", html='<input type=\"text\""
    ],
    [
        "self.widget, \"email\", None, html='<input type=\"text\" name=\"email\">'",
        "self.widget, \"email\", None, html='<input"
    ],
    [
        "Boolean values are rendered to their string forms (\"True\" and",
        "Boolean values are rendered to"
    ],
    [
        "widget = TextInput(attrs={\"class\": \"fun\", \"type\": \"email\"})",
        "widget = TextInput(attrs={\"class\": \"fun\","
    ],
    [
        "widget, \"email\", \"\", html='<input type=\"email\" class=\"fun\" name=\"email\">'",
        "widget, \"email\", \"\", html='<input type=\"email\" class=\"fun\""
    ],
    [
        "`attrs` passed to render() get precedence over those passed to the",
        "`attrs` passed to render() get precedence over those passed"
    ],
    [
        "beatles = ((\"J\", \"John\"), (\"P\", \"Paul\"), (\"G\", \"George\"), (\"R\", \"Ringo\"))",
        "beatles = ((\"J\", \"John\"), (\"P\", \"Paul\"), (\"G\", \"George\"), (\"R\","
    ],
    [
        "self, widget, name, value, html=\"\", attrs=None, strict=False, **kwargs",
        "self, widget, name, value, html=\"\","
    ],
    [
        "assertEqual = self.assertEqual if strict else self.assertHTMLEqual",
        "assertEqual = self.assertEqual if"
    ],
    [
        "from django.forms import CharField, Form, NumberInput",
        "from django.forms import CharField,"
    ],
    [
        "from django.forms import CharField, Form, PasswordInput",
        "from django.forms import"
    ],
    [
        "self.widget, \"password\", \"\", html='<input type=\"password\" name=\"password\">'",
        "self.widget, \"password\", \"\", html='<input"
    ],
    [
        "The render_value argument lets you specify whether the widget should",
        "The render_value argument lets you specify"
    ],
    [
        "render its value. For security reasons, this is off by default.",
        "render its value. For security reasons, this"
    ],
    [
        "widget, \"password\", \"\", html='<input type=\"password\" name=\"password\">'",
        "widget, \"password\", \"\", html='<input"
    ],
    [
        "widget, \"password\", None, html='<input type=\"password\" name=\"password\">'",
        "widget, \"password\", None,"
    ],
    [
        "def __init__(self, required=True, widget=None, label=None, initial=None):",
        "def __init__(self, required=True, widget=None,"
    ],
    [
        "When choices are set for this widget, we want to pass those along to",
        "When choices are set for this widget,"
    ],
    [
        "The choices for this widget are the Select widget's choices.",
        "The choices for this widget are the Select widget's"
    ],
    [
        "widget = MultiWidget(widgets={\"x\": TextInput(), \"\": TextInput()})",
        "widget = MultiWidget(widgets={\"x\": TextInput(), \"\":"
    ],
    [
        "({\"field\": \"x\", \"field_x\": \"y\"}, [\"y\", \"x\"]),",
        "({\"field\": \"x\", \"field_x\": \"y\"}, [\"y\","
    ],
    [
        "widget = MultiWidget(widgets={\"x\": TextInput(), \"\": TextInput()})",
        "widget = MultiWidget(widgets={\"x\": TextInput(),"
    ],
    [
        "needs_multipart_form should be True if any widgets need it.",
        "needs_multipart_form should be True if any widgets"
    ],
    [
        "needs_multipart_form should be False if no widgets need it.",
        "needs_multipart_form should be False if no widgets need"
    ],
    [
        "MultiWidgets can be composed of other MultiWidgets.",
        "MultiWidgets can be composed of"
    ],
    [
        "from django.db.models import F, Max, Min",
        "from django.db.models import F, Max,"
    ],
    [
        "msg = \"backend does not support timezone-aware datetimes when USE_TZ is False.\"",
        "msg = \"backend does not support timezone-aware"
    ],
    [
        "Event.objects.raw(\"SELECT * FROM timezones_event WHERE dt = %s\", [dt])",
        "Event.objects.raw(\"SELECT * FROM timezones_event WHERE dt ="
    ],
    [
        "cursor.execute(\"INSERT INTO timezones_event (dt) VALUES (%s)\", [dt])",
        "cursor.execute(\"INSERT INTO timezones_event (dt) VALUES"
    ],
    [
        "cursor.execute(\"SELECT dt FROM timezones_event WHERE dt = %s\", [dt])",
        "cursor.execute(\"SELECT dt FROM timezones_event WHERE dt"
    ],
    [
        "naive_warning = \"DateTimeField Event.dt received a naive datetime\"",
        "naive_warning = \"DateTimeField Event.dt received a naive"
    ],
    [
        "msg = \"backend does not support timezone-aware times.\"",
        "msg = \"backend does not support"
    ],
    [
        "msg = \"DateTimeField (unbound) received a naive datetime\"",
        "msg = \"DateTimeField (unbound)"
    ],
    [
        "Event.objects.raw(\"SELECT * FROM timezones_event WHERE dt = %s\", [dt])",
        "Event.objects.raw(\"SELECT * FROM timezones_event WHERE dt ="
    ],
    [
        "cursor.execute(\"INSERT INTO timezones_event (dt) VALUES (%s)\", [dt])",
        "cursor.execute(\"INSERT INTO timezones_event (dt)"
    ],
    [
        "\"INSERT INTO timezones_event (dt) VALUES (%s)\", [utc_naive_dt]",
        "\"INSERT INTO timezones_event (dt) VALUES"
    ],
    [
        "cursor.execute(\"SELECT dt FROM timezones_event WHERE dt = %s\", [dt])",
        "cursor.execute(\"SELECT dt FROM timezones_event WHERE dt = %s\","
    ],
    [
        "\"SELECT dt FROM timezones_event WHERE dt = %s\", [utc_naive_dt]",
        "\"SELECT dt FROM timezones_event WHERE dt"
    ],
    [
        "Test the TIME_ZONE database configuration parameter.",
        "Test the TIME_ZONE database configuration"
    ],
    [
        "Since this involves reading and writing to the same database through two",
        "Since this involves reading and writing to the same"
    ],
    [
        "self.assertIn('\"fields\": {\"dt\": \"%s\"}' % dt, json)",
        "self.assertIn('\"fields\": {\"dt\": \"%s\"}' %"
    ],
    [
        "self.assertRegex(yaml, r\"\\n  fields: {dt: !(!timestamp)? '%s'}\" % re.escape(dt))",
        "self.assertRegex(yaml, r\"\\n fields: {dt: !(!timestamp)?"
    ],
    [
        "Test the {% localtime %} templatetag and related filters.",
        "Test the {% localtime %}"
    ],
    [
        "\"{{ dt }}|{{ dt|localtime }}|{{ dt|utc }}|{{ dt|timezone:ICT }}\"",
        "\"{{ dt }}|{{ dt|localtime }}|{{ dt|utc"
    ],
    [
        "\"{% load tz %}{% localtime %}{{ dt }}|{{ dt|localtime }}|\"",
        "\"{% load tz %}{% localtime %}{{ dt }}|{{"
    ],
    [
        "\"{{ dt|utc }}|{{ dt|timezone:ICT }}{% endlocaltime %}\"",
        "\"{{ dt|utc }}|{{ dt|timezone:ICT }}{%"
    ],
    [
        "\"{% load tz %}{% localtime on %}{{ dt }}|{{ dt|localtime }}|\"",
        "\"{% load tz %}{% localtime on %}{{ dt }}|{{"
    ],
    [
        "\"{{ dt|utc }}|{{ dt|timezone:ICT }}{% endlocaltime %}\"",
        "\"{{ dt|utc }}|{{ dt|timezone:ICT"
    ],
    [
        "\"{% load tz %}{% localtime off %}{{ dt }}|{{ dt|localtime }}|\"",
        "\"{% load tz %}{% localtime off %}{{ dt }}|{{"
    ],
    [
        "\"{{ dt|utc }}|{{ dt|timezone:ICT }}{% endlocaltime %}\"",
        "\"{{ dt|utc }}|{{ dt|timezone:ICT }}{%"
    ],
    [
        "return \"|\".join(datetimes[key].isoformat() for key in result)",
        "return \"|\".join(datetimes[key].isoformat() for key in"
    ],
    [
        "ctx = Context({\"dt\": dt, \"ICT\": ICT})",
        "ctx = Context({\"dt\": dt, \"ICT\":"
    ],
    [
        "results[\"utc\"][\"notag\"] = t(\"utc\", \"eat\", \"utc\", \"ict\")",
        "results[\"utc\"][\"notag\"] = t(\"utc\", \"eat\", \"utc\","
    ],
    [
        "results[\"ict\"][\"notag\"] = t(\"ict\", \"eat\", \"utc\", \"ict\")",
        "results[\"ict\"][\"notag\"] = t(\"ict\", \"eat\", \"utc\","
    ],
    [
        "ctx = Context({\"dt\": dt, \"ICT\": ICT})",
        "ctx = Context({\"dt\":"
    ],
    [
        "Test the |localtime, |utc, and |timezone filters with iana zones.",
        "Test the |localtime, |utc, and |timezone filters"
    ],
    [
        "tpl = Template(\"{% load tz %}{{ dt|localtime }}|{{ dt|utc }}\")",
        "tpl = Template(\"{% load tz %}{{ dt|localtime }}|{{"
    ],
    [
        "tpl = Template(\"{% load tz %}{{ dt|timezone:tz }}\")",
        "tpl = Template(\"{% load tz %}{{ dt|timezone:tz"
    ],
    [
        "Template(\"{% load tz %}{% localtime foo %}{% endlocaltime %}\").render()",
        "Template(\"{% load tz %}{% localtime foo %}{%"
    ],
    [
        "Test the |localtime, |utc, and |timezone filters on bad inputs.",
        "Test the |localtime, |utc, and"
    ],
    [
        "\"{% load tz %}{{ dt }}|{{ dt|localtime }}|{{ dt|utc }}|{{ dt|timezone:tz }}\"",
        "\"{% load tz %}{{ dt }}|{{ dt|localtime }}|{{ dt|utc }}|{{"
    ],
    [
        "ctx = Context({\"dt\": None, \"tz\": ICT})",
        "ctx = Context({\"dt\":"
    ],
    [
        "ctx = Context({\"dt\": \"not a date\", \"tz\": ICT})",
        "ctx = Context({\"dt\": \"not a date\","
    ],
    [
        "tpl = Template(\"{% load tz %}{{ dt|timezone:tz }}\")",
        "tpl = Template(\"{% load"
    ],
    [
        "Test the {% timezone %} templatetag.",
        "Test the {% timezone %}"
    ],
    [
        "Test the {% timezone %} templatetag with IANA time zone providers.",
        "Test the {% timezone %} templatetag with"
    ],
    [
        "tpl = Template(\"{% load tz %}{% timezone tz %}{{ dt }}{% endtimezone %}\")",
        "tpl = Template(\"{% load tz %}{% timezone"
    ],
    [
        "Test the {% get_current_timezone %} templatetag.",
        "Test the {%"
    ],
    [
        "\"{% load tz %}{% get_current_timezone as time_zone %}{{ time_zone }}\"",
        "\"{% load tz %}{% get_current_timezone as time_zone"
    ],
    [
        "\"{% load tz %}{% timezone tz %}{% get_current_timezone as time_zone %}\"",
        "\"{% load tz %}{% timezone tz %}{%"
    ],
    [
        "\"{% load tz %}{% get_current_timezone as time_zone %}{{ time_zone }}\"",
        "\"{% load tz %}{% get_current_timezone"
    ],
    [
        "\"{% load tz %}{% timezone 'Europe/Paris' %}\"",
        "\"{% load tz %}{% timezone 'Europe/Paris'"
    ],
    [
        "\"{% get_current_timezone as time_zone %}{% endtimezone %}\"",
        "\"{% get_current_timezone as time_zone %}{% endtimezone"
    ],
    [
        "\"'get_current_timezone' requires 'as variable' (got \"",
        "\"'get_current_timezone' requires 'as variable'"
    ],
    [
        "Template(\"{% load tz %}{% get_current_timezone %}\").render()",
        "Template(\"{% load tz %}{%"
    ],
    [
        "Test the django.template.context_processors.tz template context processor.",
        "Test the django.template.context_processors.tz template context"
    ],
    [
        "tpl = Template(\"{{ dt|date:'Y-m-d' }} at {{ dt|time:'H:i:s' }}\")",
        "tpl = Template(\"{{ dt|date:'Y-m-d' }} at"
    ],
    [
        "\"{% load tz %}{% localtime off %}{{ dt|date:'Y-m-d' }} at \"",
        "\"{% load tz %}{% localtime off"
    ],
    [
        "tpl = Template('{% now \"O\" %}')",
        "tpl = Template('{% now \"O\""
    ],
    [
        "\"Europe/Paris; it may be ambiguous or it may not exist.\"",
        "\"Europe/Paris; it may be ambiguous"
    ],
    [
        "\"Europe/Paris; it may be ambiguous or it may not exist.\"",
        "\"Europe/Paris; it may be ambiguous or"
    ],
    [
        "\"\"\"Assert that everything has been cleaned up automatically\"\"\"",
        "\"\"\"Assert that everything has been cleaned"
    ],
    [
        "msg = \"Signal receivers must accept keyword arguments (**kwargs).\"",
        "msg = \"Signal receivers must accept keyword"
    ],
    [
        "msg = \"Signal receivers must be callable.\"",
        "msg = \"Signal receivers must be"
    ],
    [
        "Make sure signal caching sender receivers don't prevent garbage",
        "Make sure signal caching sender receivers don't prevent"
    ],
    [
        "from .models import Child, Parent, Poem, Poet, School",
        "from .models import Child, Parent,"
    ],
    [
        "Make sure that an add form that is filled out, but marked for deletion",
        "Make sure that an add form that"
    ],
    [
        "Make sure that a change form that is filled out, but marked for deletion",
        "Make sure that a change form that is filled out, but marked for"
    ],
    [
        "These should both work without a problem.",
        "These should both work without"
    ],
    [
        "Child has two ForeignKeys to Parent, so if we don't specify which one",
        "Child has two ForeignKeys to Parent, so"
    ],
    [
        "to use for the inline formset, we should get an exception.",
        "to use for the inline formset, we should get an"
    ],
    [
        "\"'inline_formsets.Child' has more than one ForeignKey to \"",
        "\"'inline_formsets.Child' has more than one ForeignKey"
    ],
    [
        "If we specify fk_name, but it isn't a ForeignKey from the child model",
        "If we specify fk_name, but it isn't a ForeignKey from"
    ],
    [
        "to the parent model, we should get an exception.",
        "to the parent model, we should get an"
    ],
    [
        "msg = \"fk_name 'school' is not a ForeignKey to 'inline_formsets.Parent'.\"",
        "msg = \"fk_name 'school' is not a ForeignKey"
    ],
    [
        "If the field specified in fk_name is not a ForeignKey, we should get an",
        "If the field specified in fk_name is not a ForeignKey, we should"
    ],
    [
        "ValueError, \"'inline_formsets.Child' has no field named 'test'.\"",
        "ValueError, \"'inline_formsets.Child' has no field"
    ],
    [
        "formset.non_form_errors(), [\"Please correct the duplicate data for name.\"]",
        "formset.non_form_errors(), [\"Please correct the duplicate"
    ],
    [
        "This is a basic model to test saving and loading boolean and date-related",
        "This is a basic model to test saving and loading"
    ],
    [
        "types, which in the past were problematic for some database backends.",
        "types, which in the past were problematic for some database"
    ],
    [
        "\"\"\"TextField values returned from the database should be str.\"\"\"",
        "\"\"\"TextField values returned from the database"
    ],
    [
        "an error if given a timezone-aware datetime object.\"\"\"",
        "an error if given"
    ],
    [
        "a Python datetime.date, not a datetime.datetime\"\"\"",
        "a Python datetime.date,"
    ],
    [
        "def _test_procedure(self, procedure_sql, params, param_types, kparams=None):",
        "def _test_procedure(self, procedure_sql, params,"
    ],
    [
        "\"Keyword parameters for callproc are not supported on this database \"",
        "\"Keyword parameters for callproc are not supported"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\" % (self.first_name,"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\" % (self.first_name,"
    ],
    [
        "self.reference = Table(\"table\", lambda table: table.upper())",
        "self.reference = Table(\"table\","
    ],
    [
        "\"table\", [\"first_column\", \"second_column\"], lambda column: column.upper()",
        "\"table\", [\"first_column\", \"second_column\"], lambda"
    ],
    [
        "\"\", reference=MockReference(\"\", {\"table\"}, {}, {}), non_reference=\"\"",
        "\"\", reference=MockReference(\"\", {\"table\"}, {}, {}),"
    ],
    [
        "reference = MockReference(\"\", {\"table\"}, {}, {})",
        "reference = MockReference(\"\","
    ],
    [
        "reference = MockReference(\"\", {}, {(\"table\", \"column\")}, {})",
        "reference = MockReference(\"\", {}, {(\"table\","
    ],
    [
        "reference = MockReference(\"reference\", {}, {}, {})",
        "reference = MockReference(\"reference\","
    ],
    [
        "reference = MockReference(\"reference\", {}, {}, {})",
        "reference = MockReference(\"reference\", {}, {},"
    ],
    [
        "expected_str = \"(UPPER(%s)), %s\" % (",
        "expected_str = \"(UPPER(%s)),"
    ],
    [
        "expected_str = \"%s.%s, %s.%s DESC, (UPPER(%s.%s))\" % (",
        "expected_str = \"%s.%s, %s.%s DESC,"
    ],
    [
        "\"\"\"Tests related to django.db.backends that haven't been organized.\"\"\"",
        "\"\"\"Tests related to django.db.backends"
    ],
    [
        "Test the custom ``django_date_trunc method``, in particular against",
        "Test the custom ``django_date_trunc"
    ],
    [
        "Test the custom ``django_date_extract method``, in particular against fields",
        "Test the custom ``django_date_extract method``, in particular against"
    ],
    [
        "last_executed_query should not raise an exception even if no previous",
        "last_executed_query should not raise an exception even"
    ],
    [
        "sql = \"INSERT INTO %s (%s, %s) VALUES (%%(root)s, %%(square)s)\" % (",
        "sql = \"INSERT INTO %s (%s,"
    ],
    [
        "sql = f\"UPDATE {table} SET {root_column} = %s + %s WHERE {id_column} = %s\"",
        "sql = f\"UPDATE {table} SET {root_column} = %s + %s WHERE {id_column} ="
    ],
    [
        "An executemany call with too many/not enough parameters will raise an",
        "An executemany call with too many/not enough parameters"
    ],
    [
        "query = \"INSERT INTO %s (%s, %s) VALUES (%%s, %%s)\" % (",
        "query = \"INSERT INTO %s (%s, %s) VALUES (%%s, %%s)\""
    ],
    [
        "\"\"\"Long primary keys and model names can result in a sequence name",
        "\"\"\"Long primary keys and model names can result in a"
    ],
    [
        "that exceeds the database limits, which will result in truncation",
        "that exceeds the database limits,"
    ],
    [
        "on certain databases (e.g., Postgres). The backend needs to use",
        "on certain databases (e.g., Postgres). The"
    ],
    [
        "the correct sequence name in last_insert_id and other places, so",
        "the correct sequence name in last_insert_id and other places,"
    ],
    [
        "\"\"\"Creation of model with long name and long pk name doesn't error.\"\"\"",
        "\"\"\"Creation of model with long name and long"
    ],
    [
        "Sequence resetting as part of a flush with model with long name and",
        "Sequence resetting as part of a flush with model with long"
    ],
    [
        "obj = Post.objects.create(name=\"New post\", text=\"goodbye world\")",
        "obj = Post.objects.create(name=\"New"
    ],
    [
        "All tests in this test case are also run with settings.DEBUG=True in",
        "All tests in this test case are also run with"
    ],
    [
        "EscapingChecksDebug test case, to also test CursorDebugWrapper.",
        "EscapingChecksDebug test case, to"
    ],
    [
        "cursor.execute(\"SELECT '%%', %s\" + self.bare_select_suffix, (\"%d\",))",
        "cursor.execute(\"SELECT '%%', %s\""
    ],
    [
        "query = \"INSERT INTO %s (%s, %s) VALUES (%%(root)s, %%(square)s)\" % (",
        "query = \"INSERT INTO %s (%s, %s) VALUES (%%(root)s, %%(square)s)\""
    ],
    [
        "\"SELECT %s, %s FROM %s ORDER BY %s\"",
        "\"SELECT %s, %s FROM %s ORDER"
    ],
    [
        "self.fail(\"Unexpected error raised with Unicode password: %s\" % e)",
        "self.fail(\"Unexpected error raised with Unicode password: %s\""
    ],
    [
        "DatabaseOperations initialization doesn't query the database.",
        "DatabaseOperations initialization doesn't query the"
    ],
    [
        "\"\"\"Creating an existing table returns a DatabaseError\"\"\"",
        "\"\"\"Creating an existing table returns"
    ],
    [
        "query = \"CREATE TABLE %s (id INTEGER);\" % Article._meta.db_table",
        "query = \"CREATE TABLE %s (id INTEGER);\""
    ],
    [
        "Cursors can be used as a context manager",
        "Cursors can be used"
    ],
    [
        "Test the documented API of connection.queries.",
        "Test the documented API of"
    ],
    [
        "sql = \"INSERT INTO %s (%s, %s) VALUES (%%s, %%s)\" % (",
        "sql = \"INSERT INTO %s (%s, %s) VALUES (%%s, %%s)\""
    ],
    [
        "Try to create a model instance that violates a FK constraint. If it",
        "Try to create a model instance that violates a FK"
    ],
    [
        "fails it should fail with IntegrityError.",
        "fails it should fail with"
    ],
    [
        "self.skipTest(\"This backend does not support integrity checks.\")",
        "self.skipTest(\"This backend does not"
    ],
    [
        "Try to update a model instance introducing a FK constraint violation.",
        "Try to update a model instance introducing a FK constraint"
    ],
    [
        "If it fails it should fail with IntegrityError.",
        "If it fails it should"
    ],
    [
        "self.skipTest(\"This backend does not support integrity checks.\")",
        "self.skipTest(\"This backend does not support integrity"
    ],
    [
        "When constraint checks are disabled, should be able to write bad data",
        "When constraint checks are disabled, should be"
    ],
    [
        "When constraint checks are disabled (using context manager), should be",
        "When constraint checks are disabled (using"
    ],
    [
        "able to write bad data without IntegrityErrors.",
        "able to write bad data"
    ],
    [
        "Constraint checks should raise an IntegrityError when bad data is in the DB.",
        "Constraint checks should raise an IntegrityError when bad data"
    ],
    [
        "self.skipTest(\"This backend does not support integrity checks.\")",
        "self.skipTest(\"This backend does not"
    ],
    [
        "self.skipTest(\"This backend does not support integrity checks.\")",
        "self.skipTest(\"This backend does not support"
    ],
    [
        "The default connection (i.e. django.db.connection) is different for",
        "The default connection (i.e. django.db.connection)"
    ],
    [
        "if conn is not connection and conn.allow_thread_sharing:",
        "if conn is not connection and"
    ],
    [
        "if conn is not connection and conn.allow_thread_sharing:",
        "if conn is not connection and"
    ],
    [
        "A connection that is not explicitly shareable cannot be closed by",
        "A connection that is not explicitly"
    ],
    [
        "msg = \"Cannot decrement the thread sharing count below zero.\"",
        "msg = \"Cannot decrement the thread"
    ],
    [
        "Zero as id for AutoField should raise exception in MySQL, because MySQL",
        "Zero as id for AutoField should raise exception in MySQL,"
    ],
    [
        "does not allow zero for autoincrement primary key if the",
        "does not allow zero for autoincrement primary"
    ],
    [
        "NO_AUTO_VALUE_ON_ZERO SQL mode is not enabled.",
        "NO_AUTO_VALUE_ON_ZERO SQL mode is"
    ],
    [
        "\"name, statement, is_holdable, is_binary, is_scrollable, creation_time\"",
        "\"name, statement, is_holdable, is_binary,"
    ],
    [
        "return [self.PostgresCursor._make(cursor) for cursor in cursors]",
        "return [self.PostgresCursor._make(cursor) for cursor"
    ],
    [
        "reason=\"Cursor not closed properly due to differences in garbage collection.\",",
        "reason=\"Cursor not closed properly due to differences in"
    ],
    [
        "The ORM still generates SQL that is not suitable for usage as prepared",
        "The ORM still generates SQL that is"
    ],
    [
        "server-side cursors which requires some specialized logic when the",
        "server-side cursors which requires some"
    ],
    [
        "from ..models import Author, Book, Person, Tag",
        "from ..models import Author,"
    ],
    [
        "['TRUNCATE \"backends_person\", \"backends_tag\" RESTART IDENTITY CASCADE;'],",
        "['TRUNCATE \"backends_person\", \"backends_tag\""
    ],
    [
        "settings = {\"CHARSET\": None, \"TEMPLATE\": None}",
        "settings = {\"CHARSET\": None,"
    ],
    [
        "\"PostgreSQL does not support collation setting at database \"",
        "\"PostgreSQL does not support collation"
    ],
    [
        "\"database %s already exists\" % parameters[\"dbname\"]",
        "\"database %s already"
    ],
    [
        "error = errors.InsufficientPrivilege(\"permission denied to create database\")",
        "error = errors.InsufficientPrivilege(\"permission denied to"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"Test only for PostgreSQL\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"Test only for"
    ],
    [
        "cursor.execute(\"ALTER SEQUENCE backends_person_id_seq RENAME TO pers_seq\")",
        "cursor.execute(\"ALTER SEQUENCE backends_person_id_seq"
    ],
    [
        "[{\"table\": Person._meta.db_table, \"column\": \"id\", \"name\": \"pers_seq\"}],",
        "[{\"table\": Person._meta.db_table, \"column\": \"id\","
    ],
    [
        "The _nodb_cursor() fallbacks to the default connection database when",
        "The _nodb_cursor() fallbacks to the default connection"
    ],
    [
        "access to the 'postgres' database is not granted.",
        "access to the 'postgres' database"
    ],
    [
        "\"Normally Django will use a connection to the 'postgres' database \"",
        "\"Normally Django will use a connection to the 'postgres' database"
    ],
    [
        "\"to avoid running initialization queries against the production \"",
        "\"to avoid running initialization queries against the production"
    ],
    [
        "\"database when it's not needed (for example, when running tests). \"",
        "\"database when it's not needed (for example,"
    ],
    [
        "\"Django was unable to create a connection to the 'postgres' \"",
        "\"Django was unable to create a connection to"
    ],
    [
        "\"database and will use the first PostgreSQL database instead.\"",
        "\"database and will use the"
    ],
    [
        "_nodb_cursor() re-raises authentication failure to the 'postgres' db",
        "_nodb_cursor() re-raises authentication failure to the"
    ],
    [
        "when other connection to the PostgreSQL database isn't available.",
        "when other connection to the"
    ],
    [
        "\"Normally Django will use a connection to the 'postgres' database \"",
        "\"Normally Django will use a connection to the"
    ],
    [
        "\"to avoid running initialization queries against the production \"",
        "\"to avoid running initialization queries against the"
    ],
    [
        "\"database when it's not needed (for example, when running tests). \"",
        "\"database when it's not needed (for example, when running tests)."
    ],
    [
        "\"Django was unable to create a connection to the 'postgres' \"",
        "\"Django was unable to create a connection to the"
    ],
    [
        "\"database and will use the first PostgreSQL database instead.\"",
        "\"database and will use the"
    ],
    [
        "settings[\"NAME\"] = \"a\" + (max_name_length * \"a\")",
        "settings[\"NAME\"] = \"a\" + (max_name_length"
    ],
    [
        "\"The database name '%s' (%d characters) is longer than \"",
        "\"The database name '%s' (%d"
    ],
    [
        "\"PostgreSQL's limit of %s characters. Supply a shorter NAME in \"",
        "\"PostgreSQL's limit of %s characters. Supply a shorter NAME"
    ],
    [
        "\"settings.DATABASES is improperly configured. Please supply the \"",
        "\"settings.DATABASES is improperly configured. Please supply the"
    ],
    [
        "PostgreSQL shouldn't roll back SET TIME ZONE, even if the first",
        "PostgreSQL shouldn't roll back SET TIME ZONE, even if"
    ],
    [
        "new_tz = \"Europe/Paris\" if db_default_tz == \"UTC\" else \"UTC\"",
        "new_tz = \"Europe/Paris\" if db_default_tz == \"UTC\""
    ],
    [
        "The connection wrapper shouldn't believe that autocommit is enabled",
        "The connection wrapper shouldn't believe"
    ],
    [
        "msg = \"Cannot open a new connection in an atomic block.\"",
        "msg = \"Cannot open a new connection in"
    ],
    [
        "msg = \"Pooling doesn't support persistent connections.\"",
        "msg = \"Pooling doesn't support persistent"
    ],
    [
        "The transaction level can be configured with",
        "The transaction level can"
    ],
    [
        "The session role can be configured with DATABASES",
        "The session role can be configured"
    ],
    [
        "msg = f'role \"{custom_role}\" does not exist'",
        "msg = f'role \"{custom_role}\" does"
    ],
    [
        "The server-side parameters binding role can be enabled with DATABASES",
        "The server-side parameters binding role can be enabled with"
    ],
    [
        "A custom cursor factory can be configured with DATABASES[\"options\"]",
        "A custom cursor factory can"
    ],
    [
        "copy_expert_sql = \"COPY django_session TO STDOUT (FORMAT CSV, HEADER)\"",
        "copy_expert_sql = \"COPY django_session TO STDOUT"
    ],
    [
        "copy_sql = \"COPY django_session TO STDOUT (FORMAT CSV, HEADER)\"",
        "copy_sql = \"COPY django_session TO STDOUT (FORMAT"
    ],
    [
        "self.assertEqual([q[\"sql\"] for q in connection.queries], [copy_sql])",
        "self.assertEqual([q[\"sql\"] for q in"
    ],
    [
        "new_tz = \"Europe/Paris\" if db_default_tz == \"UTC\" else \"UTC\"",
        "new_tz = \"Europe/Paris\" if db_default_tz =="
    ],
    [
        "'ALTER TABLE \"BACKENDS_TAG\" DISABLE CONSTRAINT '",
        "'ALTER TABLE \"BACKENDS_TAG\""
    ],
    [
        "'ALTER TABLE \"BACKENDS_TAG\" ENABLE CONSTRAINT '",
        "'ALTER TABLE \"BACKENDS_TAG\" ENABLE"
    ],
    [
        "'ALTER TABLE \"BACKENDS_TAG\" DISABLE CONSTRAINT '",
        "'ALTER TABLE \"BACKENDS_TAG\""
    ],
    [
        "'ALTER TABLE \"BACKENDS_TAG\" ENABLE CONSTRAINT '",
        "'ALTER TABLE \"BACKENDS_TAG\""
    ],
    [
        "self, cursor, statements, parameters, verbosity, allow_quiet_fail=False",
        "self, cursor, statements, parameters, verbosity,"
    ],
    [
        "self, cursor, statements, parameters, verbosity, allow_quiet_fail=False",
        "self, cursor, statements,"
    ],
    [
        "self, cursor, statements, parameters, verbosity, allow_quiet_fail=False",
        "self, cursor, statements,"
    ],
    [
        "self, cursor, statements, parameters, verbosity, allow_quiet_fail=False",
        "self, cursor, statements,"
    ],
    [
        "from django.db import NotSupportedError, ProgrammingError, connection",
        "from django.db import NotSupportedError,"
    ],
    [
        "\"\"\"'%' chars are escaped for query execution.\"\"\"",
        "\"\"\"'%' chars are escaped for"
    ],
    [
        "\"\"\"A stored procedure can be called through a cursor wrapper.\"\"\"",
        "\"\"\"A stored procedure can be called through a cursor"
    ],
    [
        "\"\"\"Cursor variables can be passed as query parameters.\"\"\"",
        "\"\"\"Cursor variables can be passed"
    ],
    [
        "cursor.execute(\"BEGIN %s := 'X'; END; \", [var])",
        "cursor.execute(\"BEGIN %s := 'X'; END;"
    ],
    [
        "An 'almost right' datetime works with configured NLS parameters",
        "An 'almost right' datetime works with"
    ],
    [
        "\"\"\"Boolean fields have check constraints on their values.\"\"\"",
        "\"\"\"Boolean fields have check constraints on their"
    ],
    [
        "sql = \"select sys_context('userenv', 'sid') from dual\"",
        "sql = \"select sys_context('userenv', 'sid') from"
    ],
    [
        "msg = \"Cannot open a new connection in an atomic block.\"",
        "msg = \"Cannot open a new connection in an atomic"
    ],
    [
        "msg = \"Pooling doesn't support persistent connections.\"",
        "msg = \"Pooling doesn't"
    ],
    [
        "msg = \"unable to open database file\"",
        "msg = \"unable to open database"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connection, connections",
        "from django.db import DEFAULT_DB_ALIAS, NotSupportedError,"
    ],
    [
        "msg = \"Cloning with start method 'forkserver' is not supported.\"",
        "msg = \"Cloning with start method 'forkserver'"
    ],
    [
        "Get the primary key column regardless of whether or not it has",
        "Get the primary key column regardless of whether or not it"
    ],
    [
        "sql = \"CREATE TABLE test_primary (%s int PRIMARY KEY NOT NULL)\" % column",
        "sql = \"CREATE TABLE test_primary (%s int PRIMARY"
    ],
    [
        "\"\"\"Parse a column or constraint definition.\"\"\"",
        "\"\"\"Parse a column"
    ],
    [
        "tokens = (token for token in statement.flatten() if not token.is_whitespace)",
        "tokens = (token for token"
    ],
    [
        "def assertConstraint(self, constraint_details, cols, unique=False, check=False):",
        "def assertConstraint(self, constraint_details, cols,"
    ],
    [
        "constraint, details, check, _ = self.parse_definition(sql, columns)",
        "constraint, details, check, _ = self.parse_definition(sql,"
    ],
    [
        "('CONSTRAINT \"ref\" UNIQUE (\"ref\"),', \"ref\", [\"ref\"]),",
        "('CONSTRAINT \"ref\" UNIQUE (\"ref\"),', \"ref\","
    ],
    [
        "(\"CONSTRAINT ref UNIQUE (ref),\", \"ref\", [\"ref\"]),",
        "(\"CONSTRAINT ref UNIQUE"
    ],
    [
        "for sql, constraint_name, columns in tests:",
        "for sql, constraint_name, columns"
    ],
    [
        "constraint, details, check, _ = self.parse_definition(sql, columns)",
        "constraint, details, check, _ = self.parse_definition(sql,"
    ],
    [
        "(\"CONSTRAINT ref UNIQUE (ref, customname),\", \"ref\", [\"ref\", \"customname\"]),",
        "(\"CONSTRAINT ref UNIQUE (ref,"
    ],
    [
        "for sql, constraint_name, columns in tests:",
        "for sql, constraint_name, columns"
    ],
    [
        "constraint, details, check, _ = self.parse_definition(sql, columns)",
        "constraint, details, check, _"
    ],
    [
        "constraint, details, check, _ = self.parse_definition(sql, columns)",
        "constraint, details, check, _ ="
    ],
    [
        "('CONSTRAINT \"ref\" CHECK (\"ref\" != \\'test\\'),', \"ref\", [\"ref\"]),",
        "('CONSTRAINT \"ref\" CHECK (\"ref\" != \\'test\\'),', \"ref\","
    ],
    [
        "(\"CONSTRAINT ref CHECK (ref != 'test'),\", \"ref\", [\"ref\"]),",
        "(\"CONSTRAINT ref CHECK (ref != 'test'),\","
    ],
    [
        "for sql, constraint_name, columns in tests:",
        "for sql, constraint_name, columns in"
    ],
    [
        "constraint, details, check, _ = self.parse_definition(sql, columns)",
        "constraint, details, check, _ ="
    ],
    [
        "constraint, details, check, _ = self.parse_definition(sql, columns)",
        "constraint, details, check, _"
    ],
    [
        "constraint, details, check, _ = self.parse_definition(sql, columns)",
        "constraint, details, check, _ = self.parse_definition(sql,"
    ],
    [
        "msg = \"Unsupported lookup type: 'unknown-lookup'\"",
        "msg = \"Unsupported lookup type:"
    ],
    [
        "msg = \"Unsupported lookup type: 'unknown-lookup'\"",
        "msg = \"Unsupported lookup"
    ],
    [
        "msg = \"Unsupported lookup type: 'unknown-lookup'\"",
        "msg = \"Unsupported lookup"
    ],
    [
        "from django.db.models import Aggregate, Avg, StdDev, Sum, Variance",
        "from django.db.models import Aggregate, Avg, StdDev, Sum,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, TransactionTestCase, override_settings",
        "from django.test import SimpleTestCase,"
    ],
    [
        "from ..models import Item, Object, Square",
        "from ..models import Item, Object,"
    ],
    [
        "\"\"\"Raise NotSupportedError when aggregating on date/time fields.\"\"\"",
        "\"\"\"Raise NotSupportedError when aggregating on"
    ],
    [
        "for aggregate in (Sum, Avg, Variance, StdDev):",
        "for aggregate in (Sum,"
    ],
    [
        "\"SQLite doesn't support DISTINCT on aggregate functions accepting \"",
        "\"SQLite doesn't support DISTINCT on aggregate"
    ],
    [
        "\"\"\"A named in-memory db should be allowed where supported.\"\"\"",
        "\"\"\"A named in-memory db should be allowed"
    ],
    [
        "for string, pattern, expected in tests:",
        "for string, pattern, expected in"
    ],
    [
        "cursor.execute(\"SELECT %s REGEXP %s\", [string, pattern])",
        "cursor.execute(\"SELECT %s REGEXP %s\","
    ],
    [
        "auto_increment fields are created with the AUTOINCREMENT keyword",
        "auto_increment fields are created with the"
    ],
    [
        "\"integer NOT NULL PRIMARY KEY AUTOINCREMENT\",",
        "\"integer NOT NULL"
    ],
    [
        "\"Wrong SQL used to create an auto-increment column on SQLite\",",
        "\"Wrong SQL used to create an"
    ],
    [
        "SQLite schema editor is not usable within an outer transaction if",
        "SQLite schema editor is not usable within"
    ],
    [
        "foreign key constraint checks are not disabled beforehand.",
        "foreign key constraint checks are not disabled"
    ],
    [
        "\"SQLite schema editor cannot be used while foreign key \"",
        "\"SQLite schema editor cannot be"
    ],
    [
        "\"constraint checks are enabled. Make sure to disable them \"",
        "\"constraint checks are enabled. Make sure"
    ],
    [
        "\"before entering a transaction.atomic() context because \"",
        "\"before entering a transaction.atomic() context"
    ],
    [
        "\"SQLite does not support disabling them in the middle of \"",
        "\"SQLite does not support disabling them in the middle"
    ],
    [
        "SQLite schema editor is usable within an outer transaction as long as",
        "SQLite schema editor is usable within an outer"
    ],
    [
        "foreign key constraints checks are disabled beforehand.",
        "foreign key constraints checks are disabled"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"sqlite\", \"Test only for SQLite\")",
        "@unittest.skipUnless(connection.vendor == \"sqlite\", \"Test only for"
    ],
    [
        "All tests in this test case are also run with settings.DEBUG=True in",
        "All tests in this test case"
    ],
    [
        "EscapingChecksDebug test case, to also test CursorDebugWrapper.",
        "EscapingChecksDebug test case, to"
    ],
    [
        "\"improperly configured to 'invalid'. Use one of 'DEFERRED', 'EXCLUSIVE', \"",
        "\"improperly configured to 'invalid'. Use one"
    ],
    [
        "All storage engines except MyISAM support transactions.",
        "All storage engines except MyISAM"
    ],
    [
        "(\"¿Tú hablas inglés?\", \"'¿Tú hablas inglés?'\"),",
        "(\"¿Tú hablas inglés?\","
    ],
    [
        "\"`start` IS NULL OR `end` IS NULL OR `start` < `end`\",",
        "\"`start` IS NULL OR `end` IS NULL"
    ],
    [
        "for check_clause, table_columns, expected_columns in tests:",
        "for check_clause, table_columns, expected_columns in"
    ],
    [
        "create_sql = \"CREATE TABLE %s (id INTEGER) ENGINE = %%s\" % table_name",
        "create_sql = \"CREATE TABLE %s (id INTEGER) ENGINE = %%s\""
    ],
    [
        "drop_sql = \"DROP TABLE %s\" % table_name",
        "drop_sql = \"DROP TABLE %s\""
    ],
    [
        "@skipUnless(connection.vendor == \"mysql\", \"MySQL specific SQL\")",
        "@skipUnless(connection.vendor == \"mysql\","
    ],
    [
        "if spec[\"columns\"] == [rel_column] and spec[\"foreign_key\"] is not None",
        "if spec[\"columns\"] == [rel_column] and spec[\"foreign_key\"] is"
    ],
    [
        "level: level.upper() for level in (read_committed, repeatable_read)",
        "level: level.upper() for level in"
    ],
    [
        "\"Invalid transaction isolation level 'xxx' specified.\\n\"",
        "\"Invalid transaction isolation level 'xxx'"
    ],
    [
        "\"Use one of 'read committed', 'read uncommitted', \"",
        "\"Use one of 'read committed',"
    ],
    [
        "from django.db import NotSupportedError, connection, transaction",
        "from django.db import NotSupportedError, connection,"
    ],
    [
        "may_require_msg = \"subclasses of BaseDatabaseOperations may require a %s() method\"",
        "may_require_msg = \"subclasses of BaseDatabaseOperations may require a"
    ],
    [
        "msg = \"subclasses of BaseDatabaseOperations must provide an sql_flush() method\"",
        "msg = \"subclasses of BaseDatabaseOperations must provide"
    ],
    [
        "msg = \"Django does not support timezone-aware times.\"",
        "msg = \"Django does not support"
    ],
    [
        "msg = \"DISTINCT ON fields is not supported by this database backend\"",
        "msg = \"DISTINCT ON fields is not supported"
    ],
    [
        "\"This backend does not support %s subtraction.\"",
        "\"This backend does not support %s"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connection, connections",
        "from django.db import DEFAULT_DB_ALIAS, connection,"
    ],
    [
        "\"subclasses of BaseDatabaseIntrospection may require a %s() method\"",
        "\"subclasses of BaseDatabaseIntrospection may"
    ],
    [
        "\"subclasses of BaseDatabaseClient must provide a \"",
        "\"subclasses of BaseDatabaseClient must"
    ],
    [
        "\"settings_to_cmd_args_env() method or override a runshell().\"",
        "\"settings_to_cmd_args_env() method or"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connection, connections, transaction",
        "from django.db import DEFAULT_DB_ALIAS, connection,"
    ],
    [
        "The \"initialization\" class attributes like client_class and",
        "The \"initialization\" class attributes"
    ],
    [
        "creation_class should be set on the class and reflected in the",
        "creation_class should be set on the class and reflected"
    ],
    [
        "corresponding instance attributes of the instantiated backend.",
        "corresponding instance attributes of"
    ],
    [
        "\"subclasses of BaseDatabaseWrapper may require a \"",
        "\"subclasses of BaseDatabaseWrapper may require"
    ],
    [
        "sql = \"SELECT \" + ret_val + connection.features.bare_select_suffix",
        "sql = \"SELECT \" +"
    ],
    [
        "(_, sql, params, many, context), _ = wrapper.call_args",
        "(_, sql, params, many, context),"
    ],
    [
        "(_, sql, param_list, many, context), _ = wrapper.call_args",
        "(_, sql, param_list, many,"
    ],
    [
        "cursor.executemany(\"The database never sees this %s\", [(\"either\",)])",
        "cursor.executemany(\"The database never sees this"
    ],
    [
        "sql = \"SELECT 'aloha'\" + connection.features.bare_select_suffix",
        "sql = \"SELECT"
    ],
    [
        "(_, reported_sql, _, _, _), _ = wrapper.call_args",
        "(_, reported_sql, _, _, _),"
    ],
    [
        "def wrap_with_comment(execute, sql, params, many, context):",
        "def wrap_with_comment(execute, sql, params, many,"
    ],
    [
        "return execute(f\"/* My comment */ {sql}\", params, many, context)",
        "return execute(f\"/* My comment */ {sql}\", params, many,"
    ],
    [
        "message = models.ForeignKey(Message, models.CASCADE, blank=True, null=True)",
        "message = models.ForeignKey(Message,"
    ],
    [
        "from django.test import TestCase, TransactionTestCase, skipUnlessDBFeature",
        "from django.test import TestCase, TransactionTestCase,"
    ],
    [
        "Limit introspection to tables created for models of this app.",
        "Limit introspection to tables created"
    ],
    [
        "Some databases such as Oracle are extremely slow at introspection.",
        "Some databases such as Oracle are extremely"
    ],
    [
        "\"inspectdb has examined a table that should have been filtered out.\"",
        "\"inspectdb has examined a table that should have"
    ],
    [
        "inspectdb can inspect a subset of tables by passing the table names as",
        "inspectdb can inspect a subset of tables by"
    ],
    [
        "Call inspectdb and return a function to validate a field type in its",
        "Call inspectdb and return a function to validate a field"
    ],
    [
        "\"\"\"Test introspection of various Django field types\"\"\"",
        "\"\"\"Test introspection of various Django"
    ],
    [
        "\"        db_table_comment = 'Custom table comment'\",",
        "\" db_table_comment = 'Custom"
    ],
    [
        "@skipUnless(test_collation, \"Language collations are not supported.\")",
        "@skipUnless(test_collation, \"Language collations"
    ],
    [
        "@skipUnless(test_collation, \"Language collations are not supported.\")",
        "@skipUnless(test_collation, \"Language collations"
    ],
    [
        "\"\"\"Test introspection of various Django field types\"\"\"",
        "\"\"\"Test introspection of various Django"
    ],
    [
        "\"as this database handles decimal fields as float\",",
        "\"as this database handles decimal fields as"
    ],
    [
        "\"inspectdb generated an attribute name which is a Python keyword\"",
        "\"inspectdb generated an attribute name"
    ],
    [
        "error_message = \"inspectdb generated a model field name which is a number\"",
        "error_message = \"inspectdb generated a model field"
    ],
    [
        "\"inspectdb generated a model field name which starts with a digit\"",
        "\"inspectdb generated a model field name"
    ],
    [
        "Introspection of column names containing special characters,",
        "Introspection of column names"
    ],
    [
        "self.assertIn(\"field = models.%s()\" % integer_field_type, output)",
        "self.assertIn(\"field = models.%s()\" % integer_field_type,"
    ],
    [
        "self.assertIn(\"tamaño = models.%s()\" % integer_field_type, output)",
        "self.assertIn(\"tamaño = models.%s()\" %"
    ],
    [
        "Introspection of table names containing special characters,",
        "Introspection of table names containing"
    ],
    [
        "By default the command generates models with `Meta.managed = False`.",
        "By default the command generates models with `Meta.managed ="
    ],
    [
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific SQL\")",
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "\"\"\"Unsupported index types (COALESCE here) are skipped.\"\"\"",
        "\"\"\"Unsupported index types (COALESCE here) are"
    ],
    [
        "\"CREATE UNIQUE INDEX Findex ON %s \"",
        "\"CREATE UNIQUE INDEX Findex ON"
    ],
    [
        "\"Only patched sqlite's DatabaseIntrospection.data_types_reverse for this test\",",
        "\"Only patched sqlite's DatabaseIntrospection.data_types_reverse for this"
    ],
    [
        "Introspection errors should not crash the command, and the error should",
        "Introspection errors should not crash the"
    ],
    [
        "\"\"\"inspectdb --include-views creates models for database views.\"\"\"",
        "\"\"\"inspectdb --include-views creates models for"
    ],
    [
        "\"\"\"inspectdb --include-views creates models for materialized views.\"\"\"",
        "\"\"\"inspectdb --include-views creates models for materialized"
    ],
    [
        "\"CREATE MATERIALIZED VIEW inspectdb_people_materialized AS \"",
        "\"CREATE MATERIALIZED VIEW inspectdb_people_materialized AS"
    ],
    [
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific SQL\")",
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL"
    ],
    [
        "\"\"\"inspectdb --include-partitions creates models for partitions.\"\"\"",
        "\"\"\"inspectdb --include-partitions creates"
    ],
    [
        "CREATE TABLE inspectdb_partition_parent (name text not null)",
        "CREATE TABLE inspectdb_partition_parent (name"
    ],
    [
        "FOR VALUES IN ('A', 'B', 'C')",
        "FOR VALUES IN"
    ],
    [
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific SQL\")",
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL"
    ],
    [
        "cursor.execute(\"CREATE EXTENSION IF NOT EXISTS file_fdw\")",
        "cursor.execute(\"CREATE EXTENSION IF NOT EXISTS"
    ],
    [
        "\"CREATE SERVER inspectdb_server FOREIGN DATA WRAPPER file_fdw\"",
        "\"CREATE SERVER inspectdb_server FOREIGN"
    ],
    [
        "\"DROP FOREIGN TABLE IF EXISTS inspectdb_iris_foreign_table\"",
        "\"DROP FOREIGN TABLE"
    ],
    [
        "FULL_RESPONSE = \"Test conditional get response\"",
        "FULL_RESPONSE = \"Test conditional"
    ],
    [
        "self.client.defaults[\"HTTP_IF_NONE_MATCH\"] = \"%s, %s\" % (ETAG, EXPIRED_ETAG)",
        "self.client.defaults[\"HTTP_IF_NONE_MATCH\"] = \"%s, %s\" %"
    ],
    [
        "If-None-Match comparisons use weak matching, so weak and strong ETags",
        "If-None-Match comparisons use weak matching, so"
    ],
    [
        "If-Match comparisons use strong matching, so any comparison involving",
        "If-Match comparisons use strong matching,"
    ],
    [
        "The same quoted ETag should be set on the header regardless of whether",
        "The same quoted ETag should be set"
    ],
    [
        "etag_func() in condition() returns a quoted or an unquoted ETag.",
        "etag_func() in condition() returns a quoted or"
    ],
    [
        "from django.views.decorators.http import condition, etag, last_modified",
        "from django.views.decorators.http import condition,"
    ],
    [
        "from .tests import ETAG, FULL_RESPONSE, LAST_MODIFIED, WEAK_ETAG",
        "from .tests import ETAG, FULL_RESPONSE,"
    ],
    [
        "@condition(lambda r: ETAG, lambda r: LAST_MODIFIED)",
        "@condition(lambda r: ETAG, lambda r:"
    ],
    [
        "Use an etag_func() that returns an unquoted ETag.",
        "Use an etag_func() that returns an"
    ],
    [
        "Use an etag_func() that returns a weak ETag.",
        "Use an etag_func() that returns a weak"
    ],
    [
        "Use an etag_func() that returns None, as opposed to setting etag_func=None.",
        "Use an etag_func() that returns None, as"
    ],
    [
        "Testing signals before/after saving and deleting.",
        "Testing signals before/after saving and"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\" %"
    ],
    [
        "from .models import Author, Book, Car, Page, Person",
        "from .models import Author, Book,"
    ],
    [
        "def pre_delete_handler(signal, sender, instance, origin, **kwargs):",
        "def pre_delete_handler(signal, sender, instance,"
    ],
    [
        "data.append((instance, sender, instance.id is None, origin))",
        "data.append((instance, sender, instance.id"
    ],
    [
        "def __call__(self, signal, sender, instance, origin, **kwargs):",
        "def __call__(self, signal, sender,"
    ],
    [
        "self.data.append((instance, sender, instance.id is None, origin))",
        "self.data.append((instance, sender, instance.id is"
    ],
    [
        "def pre_delete_handler(signal, sender, instance, origin, **kwargs):",
        "def pre_delete_handler(signal, sender, instance,"
    ],
    [
        "def post_delete_handler(signal, sender, instance, origin, **kwargs):",
        "def post_delete_handler(signal, sender, instance, origin,"
    ],
    [
        "def pre_delete_handler(signal, sender, instance, origin, **kwargs):",
        "def pre_delete_handler(signal, sender,"
    ],
    [
        "def post_delete_handler(signal, sender, instance, origin, **kwargs):",
        "def post_delete_handler(signal, sender,"
    ],
    [
        "data.append(\"instance.id is not None: %s\" % (instance.id is not None))",
        "data.append(\"instance.id is not None: %s\" % (instance.id is not"
    ],
    [
        "data.append(\"instance.id is not None: %s\" % (instance.id is not None))",
        "data.append(\"instance.id is not None: %s\" % (instance.id is not"
    ],
    [
        "Signals that disconnect when being called don't mess future",
        "Signals that disconnect when being called don't"
    ],
    [
        "\"Invalid model reference 'invalid'. String model references must be of the \"",
        "\"Invalid model reference 'invalid'. String model references must be of"
    ],
    [
        "[{\"signal\": signals.post_init, \"sender\": Book, \"instance\": instance}],",
        "[{\"signal\": signals.post_init, \"sender\": Book, \"instance\":"
    ],
    [
        "Model signals registered with model classes as senders don't use the",
        "Model signals registered with model classes as"
    ],
    [
        "get_wsgi_application() returns a functioning WSGI callable.",
        "get_wsgi_application() returns a functioning WSGI"
    ],
    [
        "If ``WSGI_APPLICATION`` is a dotted path, the referenced object is",
        "If ``WSGI_APPLICATION`` is a dotted path, the referenced object"
    ],
    [
        "If ``WSGI_APPLICATION`` is ``None``, the return value of",
        "If ``WSGI_APPLICATION`` is ``None``, the return"
    ],
    [
        "msg = \"WSGI application 'wsgi.noexist.app' could not be loaded; Error importing\"",
        "msg = \"WSGI application 'wsgi.noexist.app' could not be loaded; Error"
    ],
    [
        "\"WSGI application 'wsgi.wsgi.noexist' could not be loaded; Error importing\"",
        "\"WSGI application 'wsgi.wsgi.noexist' could not be loaded; Error"
    ],
    [
        "\"\"\"InMemoryStorage handles conversion from str to bytes and back.\"\"\"",
        "\"\"\"InMemoryStorage handles conversion from str to"
    ],
    [
        "\"\"\"A temporary file is removed when saved into storage.\"\"\"",
        "\"\"\"A temporary file is removed"
    ],
    [
        "File size is equal to the size of bytes-encoded version of the saved",
        "File size is equal to the size of bytes-encoded version of"
    ],
    [
        "\"\"\"Deletion handles both files and directory trees.\"\"\"",
        "\"\"\"Deletion handles both files and directory"
    ],
    [
        "\"\"\"Navigate to children of a file node raises FileExistsError.\"\"\"",
        "\"\"\"Navigate to children of a file node raises"
    ],
    [
        "File modified time should change after file changing",
        "File modified time should"
    ],
    [
        "\"\"\"File accessed time should change after consecutive opening.\"\"\"",
        "\"\"\"File accessed time should"
    ],
    [
        "\"\"\"File creation time should not change after I/O operations.\"\"\"",
        "\"\"\"File creation time should not change"
    ],
    [
        "Directory modified and accessed time should change when a new file is",
        "Directory modified and accessed time should change when"
    ],
    [
        "Directory modified and accessed time should change when a new file is",
        "Directory modified and accessed time should change"
    ],
    [
        "Properties using settings values as defaults should be updated on",
        "Properties using settings values as defaults should be"
    ],
    [
        "referenced settings change while specified values should be unchanged.",
        "referenced settings change while specified values should"
    ],
    [
        "characters in file names but where there aren't actual folders but just",
        "characters in file names but where there aren't"
    ],
    [
        "This method is important to test that Storage.save() doesn't replace",
        "This method is important to test"
    ],
    [
        "'\\' with '/' (rather FileSystemStorage.save() does).",
        "'\\' with '/' (rather FileSystemStorage.save()"
    ],
    [
        "\"\"\"Tests for base Storage's generate_filename method.\"\"\"",
        "\"\"\"Tests for base Storage's generate_filename"
    ],
    [
        "msg = \"Could not derive file name from '%s'\"",
        "msg = \"Could not derive file"
    ],
    [
        "msg = \"Detected path traversal attempt in '%s'\" % path",
        "msg = \"Detected path traversal"
    ],
    [
        "msg = f\"Could not derive file name from '{msg_file_name}'\"",
        "msg = f\"Could not derive file name"
    ],
    [
        "msg = \"Detected path traversal attempt in 'some/folder/../path'\"",
        "msg = \"Detected path traversal attempt"
    ],
    [
        "msg = f\"Detected path traversal attempt in '{file_name}'\"",
        "msg = f\"Detected path"
    ],
    [
        "msg = f\"Detected path traversal attempt in '/tmp/{file_name}'\"",
        "msg = f\"Detected path"
    ],
    [
        "msg = f\"Could not derive file name from '/tmp/{file_name}'\"",
        "msg = f\"Could not derive file name"
    ],
    [
        "folders and names. FileField and Storage shouldn't have any os.path()",
        "folders and names. FileField and Storage"
    ],
    [
        "Storing files according to a custom storage system",
        "Storing files according to a"
    ],
    [
        "``FileField`` and its variations can take a ``storage`` argument to specify how",
        "``FileField`` and its variations can take a ``storage`` argument"
    ],
    [
        "and where files should be stored.",
        "and where files should"
    ],
    [
        "from datetime import timezone as datetime_timezone",
        "from datetime import"
    ],
    [
        "from django.core.files.storage import Storage as BaseStorage",
        "from django.core.files.storage import"
    ],
    [
        "from django.core.files.storage import StorageHandler, default_storage, storages",
        "from django.core.files.storage import StorageHandler,"
    ],
    [
        "from django.test import LiveServerTestCase, SimpleTestCase, TestCase, override_settings",
        "from django.test import LiveServerTestCase,"
    ],
    [
        "Makes sure an exception is raised if the location is empty",
        "Makes sure an exception is raised"
    ],
    [
        "Standard file access options are available, and work as expected.",
        "Standard file access options are available, and work"
    ],
    [
        "File storage returns a Datetime object for the last accessed time of",
        "File storage returns a Datetime object for the last accessed time"
    ],
    [
        "File storage returns a datetime for the creation time of a file.",
        "File storage returns a datetime for the"
    ],
    [
        "File storage returns a datetime for the last modified time of a file.",
        "File storage returns a datetime for the last modified time of"
    ],
    [
        "File storage extracts the filename from the content object if no",
        "File storage extracts the filename from the"
    ],
    [
        "Saving a pathname should create intermediate directories as necessary.",
        "Saving a pathname should create intermediate directories"
    ],
    [
        "symlinks_supported(), \"Must be able to symlink to run this test.\"",
        "symlinks_supported(), \"Must be able to symlink to run this"
    ],
    [
        "\"\"\"A new path is created on save when a broken symlink is supplied.\"\"\"",
        "\"\"\"A new path is created on save when a"
    ],
    [
        "File storage returns the full path of a file",
        "File storage returns the full path"
    ],
    [
        "File storage returns a url to access a given file from the web.",
        "File storage returns a url to access a"
    ],
    [
        "File storage returns a url even when its base_url is unset or modified.",
        "File storage returns a url even when its base_url is unset or"
    ],
    [
        "File storage returns a tuple containing directories and files.",
        "File storage returns a tuple containing"
    ],
    [
        "File storage prevents directory traversal (files can only be accessed if",
        "File storage prevents directory traversal (files"
    ],
    [
        "\"\"\"The storage backend should preserve case of filenames.\"\"\"",
        "\"\"\"The storage backend should"
    ],
    [
        "File storage should be robust against directory creation race conditions.",
        "File storage should be robust against directory"
    ],
    [
        "File storage should be robust against file removal race conditions.",
        "File storage should be robust against file"
    ],
    [
        "Test behavior when file.chunks() is raising an error",
        "Test behavior when file.chunks() is raising"
    ],
    [
        "Calling delete with an empty name should not try to remove the base",
        "Calling delete with an empty name should"
    ],
    [
        "msg = \"The name must be given to delete().\"",
        "msg = \"The name must be given"
    ],
    [
        "Properties using settings values as defaults should be updated on",
        "Properties using settings values as defaults should be updated"
    ],
    [
        "referenced settings change while specified values should be unchanged.",
        "referenced settings change while specified"
    ],
    [
        "Append numbers to duplicate files rather than underscores, like Trac.",
        "Append numbers to duplicate files rather than underscores,"
    ],
    [
        "name = \"\".join([basename, \".\", str(number)] + ext)",
        "name = \"\".join([basename, \".\","
    ],
    [
        "\"\"\"Saving to same file name twice overwrites the first file.\"\"\"",
        "\"\"\"Saving to same file name twice overwrites the"
    ],
    [
        "\"\"\"Saving to same file name twice overwrites the first file.\"\"\"",
        "\"\"\"Saving to same file name twice overwrites"
    ],
    [
        "SuspiciousFileOperation, \"Storage can not find an available filename\"",
        "SuspiciousFileOperation, \"Storage can not find"
    ],
    [
        "When Storage.save() wraps a file-like object in File, it should include",
        "When Storage.save() wraps a file-like object in File, it"
    ],
    [
        "names = [o.normal.name for o in objs]",
        "names = [o.normal.name for"
    ],
    [
        "names = [o.limited_length.name for o in objs]",
        "names = [o.limited_length.name for"
    ],
    [
        "SuspiciousFileOperation, \"Storage can not find an available filename\"",
        "SuspiciousFileOperation, \"Storage can not find an available"
    ],
    [
        "Storage.get_valid_name() should be called when upload_to is a callable.",
        "Storage.get_valid_name() should be called when upload_to is"
    ],
    [
        "\"FileField.storage must be a subclass/instance of \"",
        "\"FileField.storage must be a"
    ],
    [
        "for invalid_type in (NotStorage, str, list, set, tuple):",
        "for invalid_type in (NotStorage, str, list, set,"
    ],
    [
        "Deconstructing gives the original callable, not the evaluated value.",
        "Deconstructing gives the original callable, not the evaluated"
    ],
    [
        "A callable that returns default_storage is not omitted when",
        "A callable that returns default_storage is not omitted"
    ],
    [
        "If the directory name contains a dot and the file name doesn't, make",
        "If the directory name contains a dot and the"
    ],
    [
        "sure we still mangle the file name instead of the directory name.",
        "sure we still mangle the file name instead of the"
    ],
    [
        "File names with a dot as their first character don't have an extension,",
        "File names with a dot as their first character"
    ],
    [
        "and the underscore should get added to the end.",
        "and the underscore should get"
    ],
    [
        "ContentFile can be saved correctly with the filesystem storage,",
        "ContentFile can be saved correctly with the"
    ],
    [
        "if it was initialized with either bytes or unicode content.",
        "if it was initialized with either bytes or"
    ],
    [
        "Test the File storage API with a file-like object coming from",
        "Test the File storage API with a file-like object coming"
    ],
    [
        "msg = \"Could not find config for 'nonexistent' in settings.STORAGES.\"",
        "msg = \"Could not find config for"
    ],
    [
        "\"Could not find backend 'django.nonexistent.NonexistentBackend': \"",
        "\"Could not find backend 'django.nonexistent.NonexistentBackend':"
    ],
    [
        "\"\"\"Simple Storage subclass implementing the bare minimum for testing.\"\"\"",
        "\"\"\"Simple Storage subclass implementing the bare minimum for"
    ],
    [
        "error_msg = \"Detected path traversal attempt in '%s'\"",
        "error_msg = \"Detected path traversal attempt"
    ],
    [
        "from django.contrib.auth import views as auth_views",
        "from django.contrib.auth import views"
    ],
    [
        "Regression tests for Django built-in views.",
        "Regression tests for Django built-in"
    ],
    [
        "An abstract article Model so that we can create article models with and",
        "An abstract article Model so that we can"
    ],
    [
        "without a get_absolute_url method (for create_update generic views tests).",
        "without a get_absolute_url method (for create_update"
    ],
    [
        "An Article class with a get_absolute_url defined.",
        "An Article class with a get_absolute_url"
    ],
    [
        "An article Model with a DateField instead of DateTimeField,",
        "An article Model with a DateField instead"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import include, path,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "from django.core.exceptions import BadRequest, PermissionDenied, SuspiciousOperation",
        "from django.core.exceptions import BadRequest,"
    ],
    [
        "from django.template import Context, Template, TemplateDoesNotExist",
        "from django.template import"
    ],
    [
        "Trigger an exception in the template machinery which causes a SafeString",
        "Trigger an exception in the template"
    ],
    [
        "h for h in logger.handlers if h.__class__.__name__ == \"AdminEmailHandler\"",
        "h for h in logger.handlers"
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\","
    ],
    [
        "Ignores all the filtering done by its parent class.",
        "Ignores all the filtering done by"
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\","
    ],
    [
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\", \"e\", \"r\", \"s\", \"h\", \"i\", \"r\", \"e\"]",
        "[\"w\", \"o\", \"r\", \"c\", \"e\", \"s\", \"t\","
    ],
    [
        "from django.test import Client, RequestFactory, SimpleTestCase, override_settings",
        "from django.test import Client, RequestFactory,"
    ],
    [
        "\"\"\"An invalid request is rejected with a localized error message.\"\"\"",
        "\"\"\"An invalid request is rejected"
    ],
    [
        "Referer header is strictly checked for POST over HTTPS. Trigger the",
        "Referer header is strictly checked for POST"
    ],
    [
        "exception by sending an incorrect referer.",
        "exception by sending an incorrect"
    ],
    [
        "\"You are seeing this message because this HTTPS site requires a \"",
        "\"You are seeing this message because this HTTPS"
    ],
    [
        "\"“Referer header” to be sent by your web browser, but \"",
        "\"“Referer header” to be sent by your web browser, but"
    ],
    [
        "\"If you have configured your browser to disable “Referer” \"",
        "\"If you have configured your"
    ],
    [
        "\"headers, please re-enable them, at least for this site, or for \"",
        "\"headers, please re-enable them, at least for this site,"
    ],
    [
        "\"HTTPS connections, or for “same-origin” requests.\",",
        "\"HTTPS connections, or for “same-origin”"
    ],
    [
        "\"If you are using the &lt;meta name=&quot;referrer&quot; \"",
        "\"If you are using"
    ],
    [
        "\"content=&quot;no-referrer&quot;&gt; tag or including the \"",
        "\"content=&quot;no-referrer&quot;&gt; tag or including the"
    ],
    [
        "\"“Referrer-Policy: no-referrer” header, please remove them.\",",
        "\"“Referrer-Policy: no-referrer” header,"
    ],
    [
        "The CSRF cookie is checked for POST. Failure to send this cookie should",
        "The CSRF cookie is checked for POST. Failure to"
    ],
    [
        "\"You are seeing this message because this site requires a CSRF \"",
        "\"You are seeing this message because this site requires a"
    ],
    [
        "\"cookie when submitting forms. This cookie is required for \"",
        "\"cookie when submitting forms. This cookie is"
    ],
    [
        "\"security reasons, to ensure that your browser is not being \"",
        "\"security reasons, to ensure that your browser"
    ],
    [
        "\"\"\"An exception is raised if a nonexistent template is supplied.\"\"\"",
        "\"\"\"An exception is raised if a nonexistent"
    ],
    [
        "The template is loaded directly, not via a template loader, and should",
        "The template is loaded directly, not via"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import RequestFactory, SimpleTestCase,"
    ],
    [
        "from django.views.debug import Path as DebugPath",
        "from django.views.debug import"
    ],
    [
        "return \"repr from the wrapped callable\"",
        "return \"repr from the wrapped"
    ],
    [
        "self.assertEqual(actual, \"repr from the wrapped callable\")",
        "self.assertEqual(actual, \"repr from the wrapped"
    ],
    [
        "\"<p>The current path, <code>not-in-urls</code>, didn’t match any \"",
        "\"<p>The current path, <code>not-in-urls</code>, didn’t match any"
    ],
    [
        "\"<p>The current path, <code>not-in-urls</code>, didn’t match any \"",
        "\"<p>The current path, <code>not-in-urls</code>, didn’t match any"
    ],
    [
        "\"<p>The empty path didn’t match any of these.</p>\",",
        "\"<p>The empty path didn’t match any of"
    ],
    [
        "Numeric IDs and fancy traceback context blocks line numbers shouldn't",
        "Numeric IDs and fancy traceback context blocks line"
    ],
    [
        "\"Numeric IDs in debug response HTML page shouldn't be localized \"",
        "\"Numeric IDs in debug response HTML page shouldn't be"
    ],
    [
        "\"Failed to find 'raise Exception' in last frame of \"",
        "\"Failed to find 'raise Exception' in"
    ],
    [
        "\"traceback, instead found: %s\" % raising_loc,",
        "\"traceback, instead found:"
    ],
    [
        "\"Raises OSError instead of TemplateDoesNotExist on Windows.\",",
        "\"Raises OSError instead of TemplateDoesNotExist"
    ],
    [
        "\"%s (Source does not exist)\" % template_path,",
        "\"%s (Source does not"
    ],
    [
        "Make sure if you don't specify a template, the debug view doesn't blow up.",
        "Make sure if you don't specify a template, the debug view doesn't"
    ],
    [
        "Make sure that the default URLconf template is shown instead of the",
        "Make sure that the default URLconf template is shown instead"
    ],
    [
        "If the admin app include is replaced with exactly one url",
        "If the admin app include is replaced with exactly one"
    ],
    [
        "The templates are loaded directly, not via a template loader, and",
        "The templates are loaded directly, not via a"
    ],
    [
        "Ensure the debug view works when a database exception is raised by",
        "Ensure the debug view works when a database exception"
    ],
    [
        "performing an invalid query and passing the exception to the debug view.",
        "performing an invalid query and passing the"
    ],
    [
        "\"A simple exception report can be generated\"",
        "\"A simple exception report can be"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request, exc_type, exc_value,"
    ],
    [
        "\"An exception report can be generated without request\"",
        "\"An exception report can be generated"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None, exc_type, exc_value,"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None,"
    ],
    [
        "\"\"\"The ExceptionReporter supports Unix, Windows and Macintosh EOL markers\"\"\"",
        "\"\"\"The ExceptionReporter supports Unix, Windows and Macintosh"
    ],
    [
        "reporter = ExceptionReporter(None, None, None, None)",
        "reporter = ExceptionReporter(None,"
    ],
    [
        "for newline in [\"\\n\", \"\\r\\n\", \"\\r\"]:",
        "for newline in [\"\\n\", \"\\r\\n\","
    ],
    [
        "\"An exception report can be generated for just a request\"",
        "\"An exception report can be generated for"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None,"
    ],
    [
        "'<pre class=\"exception_value\">No exception message supplied</pre>', html",
        "'<pre class=\"exception_value\">No exception message supplied</pre>',"
    ],
    [
        "raise ValueError(\"Can't find my keys\") from None",
        "raise ValueError(\"Can't find my"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None,"
    ],
    [
        "self.assertNotIn(\"During handling of the above exception\", html)",
        "self.assertNotIn(\"During handling of the above"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None, exc_type,"
    ],
    [
        "\"During handling of the above exception (My context), another \"",
        "\"During handling of the above exception (My context), another"
    ],
    [
        "self.assertIn(\"Traceback (most recent call last):\\n  None\", html)",
        "self.assertIn(\"Traceback (most recent call last):\\n None\","
    ],
    [
        "self.assertIn(\"Traceback (most recent call last):\\n  None\", text)",
        "self.assertIn(\"Traceback (most recent call last):\\n None\","
    ],
    [
        "\"During handling of the above exception (My context), another \"",
        "\"During handling of the above exception (My context), another"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request, exc_type,"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None, exc_type,"
    ],
    [
        "\"During handling of the above exception (Inner Oops), another \"",
        "\"During handling of the above exception (Inner Oops), another"
    ],
    [
        "self.assertIn(\"Traceback (most recent call last):\", text)",
        "self.assertIn(\"Traceback (most recent call"
    ],
    [
        "\"During handling of the above exception (Inner Oops), another \"",
        "\"During handling of the above"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request, exc_type, exc_value,"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request,"
    ],
    [
        "source = \"def funcName():\\n    raise Error('Whoops')\\nfuncName()\"",
        "source = \"def"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request, exc_type,"
    ],
    [
        "source = \"def funcName():\\n    raise Error('Whoops')\\nfuncName()\"",
        "source = \"def"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request, exc_type,"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request,"
    ],
    [
        "\"Cycle in the exception chain detected: exception 'inner' \"",
        "\"Cycle in the exception chain detected: exception"
    ],
    [
        "exc_value.__traceback__ = exc_value.__context__ = exc_value.__cause__ = None",
        "exc_value.__traceback__ = exc_value.__context__ = exc_value.__cause__"
    ],
    [
        "\"A message can be provided in addition to a request\"",
        "\"A message can be provided in addition"
    ],
    [
        "reporter = ExceptionReporter(request, None, \"I'm a little teapot\", None)",
        "reporter = ExceptionReporter(request, None, \"I'm a little teapot\","
    ],
    [
        "reporter = ExceptionReporter(None, None, \"I'm a little teapot\", None)",
        "reporter = ExceptionReporter(None, None, \"I'm a little"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None, exc_type, exc_value,"
    ],
    [
        "\"\"\"Safe strings in local variables are escaped.\"\"\"",
        "\"\"\"Safe strings in local"
    ],
    [
        "html = ExceptionReporter(None, exc_type, exc_value, tb).get_traceback_html()",
        "html = ExceptionReporter(None, exc_type, exc_value,"
    ],
    [
        "\"Unprintable values should not make the output generation choke.\"",
        "\"Unprintable values should not make the"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None, exc_type, exc_value,"
    ],
    [
        "\"Large values should not create a large HTML.\"",
        "\"Large values should not create a large"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None, exc_type,"
    ],
    [
        "\"&lt;trimmed %d bytes string&gt;\" % (large + repr_of_str_adds,), html",
        "\"&lt;trimmed %d bytes string&gt;\" % (large +"
    ],
    [
        "A UnicodeError displays a portion of the problematic string. HTML in",
        "A UnicodeError displays a portion of the problematic"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None, exc_type,"
    ],
    [
        "self.assertIn(\"The string that could not be encoded/decoded was: \", html)",
        "self.assertIn(\"The string that could not be encoded/decoded was: \","
    ],
    [
        "importlib is not a frozen app, but its loader thinks it's frozen which",
        "importlib is not a frozen app, but its loader thinks"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request, exc_type, exc_value,"
    ],
    [
        "Don't trip over exceptions generated by crafted objects when",
        "Don't trip over exceptions generated by"
    ],
    [
        "\"Evaluation exception reason not mentioned in traceback\",",
        "\"Evaluation exception reason not mentioned in"
    ],
    [
        "\"An exception report can be generated even for a disallowed host.\"",
        "\"An exception report can be generated even for a disallowed"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None,"
    ],
    [
        "An exception report can be generated for requests with 'items' in",
        "An exception report can be generated for requests with"
    ],
    [
        "request GET, POST, FILES, or COOKIES QueryDicts.",
        "request GET, POST, FILES, or"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request,"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None, None,"
    ],
    [
        "request = self.rf.post(\"/test_view/\", data={\"name\": \"filename\", \"items\": fp})",
        "request = self.rf.post(\"/test_view/\", data={\"name\": \"filename\","
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None,"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None,"
    ],
    [
        "The error page can be rendered if the current user can't be retrieved",
        "The error page can be rendered if"
    ],
    [
        "(such as when the database is unavailable).",
        "(such as when the database is"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request, exc_type, exc_value,"
    ],
    [
        "self.assertIn(\"<p>[unable to retrieve the current user]</p>\", html)",
        "self.assertIn(\"<p>[unable to retrieve the"
    ],
    [
        "self.assertIn(\"USER: [unable to retrieve the current user]\", text)",
        "self.assertIn(\"USER: [unable to retrieve the"
    ],
    [
        "The templates are loaded directly, not via a template loader, and",
        "The templates are loaded directly, not via a"
    ],
    [
        "reporter = ExceptionReporter(None, None, None, None)",
        "reporter = ExceptionReporter(None, None, None,"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request,"
    ],
    [
        "\"A simple exception report can be generated\"",
        "\"A simple exception report can be"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request,"
    ],
    [
        "self.assertIn(\"Traceback (most recent call last):\", text)",
        "self.assertIn(\"Traceback (most recent"
    ],
    [
        "\"An exception report can be generated without request\"",
        "\"An exception report can"
    ],
    [
        "reporter = ExceptionReporter(None, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(None, exc_type, exc_value,"
    ],
    [
        "self.assertIn(\"Traceback (most recent call last):\", text)",
        "self.assertIn(\"Traceback (most recent"
    ],
    [
        "\"An exception report can be generated for just a request\"",
        "\"An exception report can be generated for"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None, None,"
    ],
    [
        "\"A message can be provided in addition to a request\"",
        "\"A message can be provided"
    ],
    [
        "reporter = ExceptionReporter(request, None, \"I'm a little teapot\", None)",
        "reporter = ExceptionReporter(request, None, \"I'm a little"
    ],
    [
        "reporter = ExceptionReporter(request, exc_type, exc_value, tb)",
        "reporter = ExceptionReporter(request, exc_type,"
    ],
    [
        "\"   'cycle' tag requires at least two arguments\\n\"",
        "\" 'cycle' tag requires at"
    ],
    [
        "An exception report can be generated for requests with 'items' in",
        "An exception report can be generated"
    ],
    [
        "request GET, POST, FILES, or COOKIES QueryDicts.",
        "request GET, POST, FILES, or COOKIES"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None, None,"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None,"
    ],
    [
        "request = self.rf.post(\"/test_view/\", data={\"name\": \"filename\", \"items\": fp})",
        "request = self.rf.post(\"/test_view/\", data={\"name\": \"filename\","
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None, None,"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request,"
    ],
    [
        "reporter = ExceptionReporter(None, None, \"I'm a little teapot\", None)",
        "reporter = ExceptionReporter(None, None, \"I'm a"
    ],
    [
        "\"An exception report can be generated even for a disallowed host.\"",
        "\"An exception report can be generated"
    ],
    [
        "reporter = ExceptionReporter(request, None, None, None)",
        "reporter = ExceptionReporter(request, None, None,"
    ],
    [
        "Asserts that potentially sensitive info are displayed in the response.",
        "Asserts that potentially sensitive info are displayed"
    ],
    [
        "Asserts that certain sensitive info are not displayed in the response.",
        "Asserts that certain sensitive info are"
    ],
    [
        "Asserts that no variables or POST parameters are displayed in the response.",
        "Asserts that no variables or POST parameters are displayed in"
    ],
    [
        "Asserts that potentially sensitive info are displayed in the email report.",
        "Asserts that potentially sensitive info are displayed"
    ],
    [
        "Asserts that certain sensitive info are not displayed in the email report.",
        "Asserts that certain sensitive info are not displayed in the email"
    ],
    [
        "Asserts that no variables or POST parameters are displayed in the email report.",
        "Asserts that no variables or POST parameters"
    ],
    [
        "Everything (request info and frame variables) can bee seen",
        "Everything (request info and frame variables) can"
    ],
    [
        "in the default error reports for non-sensitive requests.",
        "in the default error reports"
    ],
    [
        "Sensitive POST parameters and frame variables cannot be",
        "Sensitive POST parameters and frame variables"
    ],
    [
        "seen in the default error reports for sensitive requests.",
        "seen in the default error reports"
    ],
    [
        "No POST parameters and frame variables can be seen in the",
        "No POST parameters and frame variables"
    ],
    [
        "default error reports for \"paranoid\" requests.",
        "default error reports for \"paranoid\""
    ],
    [
        "error reports for if request.POST['nonexistent_key'] throws an error.",
        "error reports for if request.POST['nonexistent_key'] throws"
    ],
    [
        "It's possible to assign an exception reporter filter to",
        "It's possible to assign an exception"
    ],
    [
        "the request to bypass the one set in DEFAULT_EXCEPTION_REPORTER_FILTER.",
        "the request to bypass the"
    ],
    [
        "The sensitive_variables decorator works with object methods.",
        "The sensitive_variables decorator works"
    ],
    [
        "The sensitive_variables decorator works with async object methods.",
        "The sensitive_variables decorator works with"
    ],
    [
        "The sensitive_variables decorator works with async object methods.",
        "The sensitive_variables decorator works with"
    ],
    [
        "Sensitive variables don't leak in the sensitive_variables decorator's",
        "Sensitive variables don't leak"
    ],
    [
        "frame, when those variables are passed as arguments to the decorated",
        "frame, when those variables are passed as arguments to the"
    ],
    [
        "Sensitive variables don't leak in the sensitive_variables decorator's",
        "Sensitive variables don't leak in the sensitive_variables"
    ],
    [
        "frame, when those variables are passed as keyword arguments to the",
        "frame, when those variables are passed as keyword arguments to"
    ],
    [
        "return \"This should not be displayed\"",
        "return \"This should not"
    ],
    [
        "Callable settings which forbid to set attributes should not break",
        "Callable settings which forbid to set"
    ],
    [
        "return \"This should not be displayed\"",
        "return \"This should not"
    ],
    [
        "A dict setting containing a non-string key should not break the",
        "A dict setting containing a non-string key"
    ],
    [
        "The debug page should not show some sensitive settings",
        "The debug page should not show some sensitive"
    ],
    [
        "with self.settings(DEBUG=True, **{setting: \"should not be displayed\"}):",
        "with self.settings(DEBUG=True, **{setting: \"should"
    ],
    [
        "The debug page should filter out some sensitive information found in",
        "The debug page should filter out some"
    ],
    [
        "\"recursive\": {setting: \"should not be displayed\"},",
        "\"recursive\": {setting: \"should"
    ],
    [
        "initial = {\"login\": \"cooper\", \"password\": \"secret\"}",
        "initial = {\"login\": \"cooper\", \"password\":"
    ],
    [
        "Sensitive information can be filtered out of error reports.",
        "Sensitive information can be filtered out of error"
    ],
    [
        "detected the request doesn't accept HTML content. Don't check for",
        "detected the request doesn't accept HTML content. Don't"
    ],
    [
        "(non)existence of frames vars in the traceback information section of the",
        "(non)existence of frames vars in the"
    ],
    [
        "response content because they're not included in these error pages.",
        "response content because they're not"
    ],
    [
        "Request info can bee seen in the default error reports for",
        "Request info can bee seen in the default error"
    ],
    [
        "Sensitive POST parameters cannot be seen in the default",
        "Sensitive POST parameters cannot be seen in"
    ],
    [
        "Sensitive POST parameters cannot be seen in the default",
        "Sensitive POST parameters cannot be seen"
    ],
    [
        "Sensitive POST parameters cannot be seen in the default",
        "Sensitive POST parameters cannot be seen"
    ],
    [
        "No POST parameters can be seen in the default error reports",
        "No POST parameters can be seen in the default error"
    ],
    [
        "It's possible to assign an exception reporter filter to",
        "It's possible to assign an exception reporter"
    ],
    [
        "the request to bypass the one set in DEFAULT_EXCEPTION_REPORTER_FILTER.",
        "the request to bypass the one set"
    ],
    [
        "\"sensitive_variables() must be called to use it as a decorator, \"",
        "\"sensitive_variables() must be called to use it"
    ],
    [
        "\"sensitive_post_parameters() must be called to use it as a \"",
        "\"sensitive_post_parameters() must be called to use it as"
    ],
    [
        "\"decorator, e.g., use @sensitive_post_parameters(), not \"",
        "\"decorator, e.g., use @sensitive_post_parameters(), not"
    ],
    [
        "\"sensitive_post_parameters didn't receive an HttpRequest object. \"",
        "\"sensitive_post_parameters didn't receive an HttpRequest"
    ],
    [
        "\"If you are decorating a classmethod, make sure to use \"",
        "\"If you are decorating a classmethod, make sure to"
    ],
    [
        "\"The static view can serve static media\"",
        "\"The static view can serve"
    ],
    [
        "response = self.client.get(\"/%s/%s\" % (self.prefix, quote(filename)))",
        "response = self.client.get(\"/%s/%s\""
    ],
    [
        "\"The static view should stream files in chunks to avoid large memory usage\"",
        "\"The static view should stream files in"
    ],
    [
        "response = self.client.get(\"/%s/%s\" % (self.prefix, \"long-line.txt\"))",
        "response = self.client.get(\"/%s/%s\" % (self.prefix,"
    ],
    [
        "response = self.client.get(\"/%s//%s\" % (self.prefix, file_name))",
        "response = self.client.get(\"/%s//%s\""
    ],
    [
        "with open(path.join(media_dir, file_name), \"rb\") as fp:",
        "with open(path.join(media_dir, file_name), \"rb\")"
    ],
    [
        "with open(path.join(media_dir, file_name), \"rb\") as fp:",
        "with open(path.join(media_dir, file_name), \"rb\")"
    ],
    [
        "Assume that a file is modified since an invalid timestamp as per RFC",
        "Assume that a file is modified since an invalid"
    ],
    [
        "with open(path.join(media_dir, file_name), \"rb\") as fp:",
        "with open(path.join(media_dir, file_name),"
    ],
    [
        "\"\"\"Handle even more bogus If-Modified-Since values gracefully",
        "\"\"\"Handle even more bogus If-Modified-Since"
    ],
    [
        "Assume that a file is modified since an invalid timestamp as per RFC",
        "Assume that a file is modified since an invalid timestamp as per"
    ],
    [
        "with open(path.join(media_dir, file_name), \"rb\") as fp:",
        "with open(path.join(media_dir, file_name), \"rb\") as"
    ],
    [
        "The template is loaded directly, not via a template loader, and should",
        "The template is loaded directly, not via a template loader, and"
    ],
    [
        "Test case to make sure the static URL pattern helper works as expected",
        "Test case to make sure the static URL pattern helper works as"
    ],
    [
        "\"\"\"No URLs are served if DEBUG=False.\"\"\"",
        "\"\"\"No URLs are served if"
    ],
    [
        "ImproperlyConfigured, \"Empty static prefix not permitted\"",
        "ImproperlyConfigured, \"Empty static prefix"
    ],
    [
        "\"\"\"No URLs are served if prefix contains a netloc part.\"\"\"",
        "\"\"\"No URLs are served if prefix"
    ],
    [
        "Tests for URL handling in views and responses.",
        "Tests for URL handling in views"
    ],
    [
        "A non-ASCII argument to HttpRedirect is handled properly.",
        "A non-ASCII argument to"
    ],
    [
        "A non-ASCII argument to HttpPermanentRedirect is handled properly.",
        "A non-ASCII argument to HttpPermanentRedirect is handled"
    ],
    [
        "\"\"\"Return language code for a language which is not activated.\"\"\"",
        "\"\"\"Return language code for a language which"
    ],
    [
        "return [code for code, name in settings.LANGUAGES if code != current_language][",
        "return [code for code, name in settings.LANGUAGES if"
    ],
    [
        "The set_language view can be used to change the session language.",
        "The set_language view can be used to change the session"
    ],
    [
        "The user is redirected to the 'next' argument if provided.",
        "The user is redirected to the"
    ],
    [
        "post_data = {\"language\": lang_code, \"next\": \"/\"}",
        "post_data = {\"language\": lang_code,"
    ],
    [
        "The set_language view only redirects to the 'next' argument if it is",
        "The set_language view only redirects to"
    ],
    [
        "post_data = {\"language\": lang_code, \"next\": \"//unsafe/redirection/\"}",
        "post_data = {\"language\":"
    ],
    [
        "The set_language view only redirects to the 'next' argument if it is",
        "The set_language view only redirects to"
    ],
    [
        "\"safe\" and its scheme is HTTPS if the request was sent over HTTPS.",
        "\"safe\" and its scheme is HTTPS if the request was"
    ],
    [
        "post_data = {\"language\": lang_code, \"next\": non_https_next_url}",
        "post_data = {\"language\": lang_code, \"next\":"
    ],
    [
        "The set_language view redirects to the URL in the referer header when",
        "The set_language view redirects to the URL in the"
    ],
    [
        "The set_language view redirects to '/' when there isn't a referer or",
        "The set_language view redirects to '/' when there"
    ],
    [
        "The set_language view redirects to the \"next\" parameter for requests",
        "The set_language view redirects to the \"next\" parameter"
    ],
    [
        "post_data = {\"language\": lang_code, \"next\": \"/\"}",
        "post_data = {\"language\": lang_code,"
    ],
    [
        "The set_language view doesn't redirect to the HTTP referer header if",
        "The set_language view doesn't redirect to the"
    ],
    [
        "the request doesn't accept HTML response content.",
        "the request doesn't accept HTML"
    ],
    [
        "headers = {\"HTTP_REFERER\": \"/\", \"HTTP_ACCEPT\": \"application/json\"}",
        "headers = {\"HTTP_REFERER\":"
    ],
    [
        "The fallback to root URL for the set_language view works for requests",
        "The fallback to root URL for the set_language"
    ],
    [
        "post_data = {\"language\": lang_code, \"next\": \"//unsafe/redirection/\"}",
        "post_data = {\"language\": lang_code, \"next\":"
    ],
    [
        "post_data = {\"language\": \"pl\", \"next\": \"/views/\"}",
        "post_data = {\"language\": \"pl\", \"next\":"
    ],
    [
        "The set_language view decodes the HTTP_REFERER URL and preserves an",
        "The set_language view decodes the HTTP_REFERER URL and preserves"
    ],
    [
        "\"\"\"The javascript_catalog can be deployed with language settings\"\"\"",
        "\"\"\"The javascript_catalog can be deployed with"
    ],
    [
        "for lang_code in [\"es\", \"fr\", \"ru\"]:",
        "for lang_code in [\"es\","
    ],
    [
        "trans_txt = catalog.gettext(\"this is to be translated\")",
        "trans_txt = catalog.gettext(\"this is to be"
    ],
    [
        "The json_catalog returns the language catalog and settings as JSON.",
        "The json_catalog returns the language catalog"
    ],
    [
        "The javascript_catalog shouldn't load the fallback language in the",
        "The javascript_catalog shouldn't load the fallback"
    ],
    [
        "case that the current selected language is actually the one translated",
        "case that the current selected language is actually"
    ],
    [
        "from, and hence missing translation files completely.",
        "from, and hence missing"
    ],
    [
        "This happens easily when you're translating from English to other",
        "This happens easily when you're translating from English"
    ],
    [
        "languages and you've set settings.LANGUAGE_CODE to some other language",
        "languages and you've set settings.LANGUAGE_CODE"
    ],
    [
        "self.assertNotContains(response, \"esto tiene que ser traducido\")",
        "self.assertNotContains(response, \"esto tiene que"
    ],
    [
        "Same as above for the json_catalog view. Here we also check for the",
        "Same as above for the json_catalog view. Here we"
    ],
    [
        "Let's make sure that the fallback language is still working properly",
        "Let's make sure that the fallback language"
    ],
    [
        "in cases where the selected language cannot be found.",
        "in cases where the selected language"
    ],
    [
        "The fallback language works when there are several levels of fallback",
        "The fallback language works when there are several"
    ],
    [
        "response, \"custom_locale_path: esto tiene que ser traducido\"",
        "response, \"custom_locale_path: esto tiene"
    ],
    [
        "response, \"custom_locale_path: esto tiene que ser traducido\"",
        "response, \"custom_locale_path: esto tiene que ser"
    ],
    [
        "The fallback to a language with less plural forms maintains the real",
        "The fallback to a language with less"
    ],
    [
        "language's number of plural forms and correct translations.",
        "language's number of plural forms and"
    ],
    [
        "'\"this color is to be translated\": \"this colour is to be translated\"',",
        "'\"this color is to be translated\": \"this colour is to"
    ],
    [
        "if the default language is non-English, the selected language",
        "if the default language is"
    ],
    [
        "Same as above with the difference that there IS an 'en' translation",
        "Same as above with the difference that there IS an"
    ],
    [
        "Makes sure that the fallback language is still working properly",
        "Makes sure that the fallback"
    ],
    [
        "in cases where the selected language cannot be found.",
        "in cases where the selected language"
    ],
    [
        "if the default language is en-us, the selected language has a",
        "if the default language is en-us,"
    ],
    [
        "translation available and a catalog composed by djangojs domain",
        "translation available and a catalog composed by"
    ],
    [
        "Similar to above but with neither default or requested language being",
        "Similar to above but with neither default or requested"
    ],
    [
        "msg = \"Invalid package(s) provided to JavaScriptCatalog: unknown_package\"",
        "msg = \"Invalid package(s)"
    ],
    [
        "The template is loaded directly, not via a template loader, and should",
        "The template is loaded directly, not via a template"
    ],
    [
        "\"DATE_INPUT_FORMATS is an object; DECIMAL_SEPARATOR is a string; \"",
        "\"DATE_INPUT_FORMATS is an object; DECIMAL_SEPARATOR is a string;"
    ],
    [
        "from ..models import Article, Author, UrlArticle",
        "from ..models import Article,"
    ],
    [
        "b\"<p>The requested resource was not found on this server.</p>\",",
        "b\"<p>The requested resource was not found on this"
    ],
    [
        "\"A model can set attributes on the get_absolute_url method\"",
        "\"A model can set attributes"
    ],
    [
        "\"The attributes of the original get_absolute_url must be added.\",",
        "\"The attributes of the original get_absolute_url must be"
    ],
    [
        "\"The attributes of the original get_absolute_url must be added.\",",
        "\"The attributes of the original get_absolute_url"
    ],
    [
        "Default error views should raise TemplateDoesNotExist when passed a",
        "Default error views should raise TemplateDoesNotExist"
    ],
    [
        "from django.template.loader import get_template, render_to_string, select_template",
        "from django.template.loader import"
    ],
    [
        "\"select_template() takes an iterable of template names but got a \"",
        "\"select_template() takes an iterable of template names"
    ],
    [
        "\"string: 'template_loader/hello.html'. Use get_template() if you \"",
        "\"string: 'template_loader/hello.html'. Use get_template() if"
    ],
    [
        "\"want to load a single template by name.\",",
        "\"want to load a single template by"
    ],
    [
        "Adding hooks before/after saving and deleting",
        "Adding hooks before/after saving and"
    ],
    [
        "To execute arbitrary code around ``save()`` and ``delete()``, just subclass",
        "To execute arbitrary code around ``save()`` and ``delete()``,"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\" % (self.first_name,"
    ],
    [
        "Set ``request.COOKIES`` with the encoded data and remove the storage",
        "Set ``request.COOKIES`` with the encoded data and"
    ],
    [
        "Return an integer containing the number of messages stored.",
        "Return an integer containing the number of messages"
    ],
    [
        "If the data exceeds what is allowed in a cookie, older messages are",
        "If the data exceeds what is allowed"
    ],
    [
        "removed before saving (and returned by the ``update`` method).",
        "removed before saving (and returned"
    ],
    [
        "non_compliant_chars = [\"\\\\\", \",\", \";\", '\"']",
        "non_compliant_chars = [\"\\\\\","
    ],
    [
        "A complex nested data structure containing Message",
        "A complex nested data structure"
    ],
    [
        "instances is properly encoded/decoded by the custom JSON",
        "instances is properly encoded/decoded by"
    ],
    [
        "A message containing SafeData is keeping its safe status when",
        "A message containing SafeData is keeping its safe"
    ],
    [
        "A message's extra_tags attribute is correctly preserved when retrieved",
        "A message's extra_tags attribute is correctly preserved"
    ],
    [
        "for extra_tags in [\"\", None, \"some tags\"]:",
        "for extra_tags in [\"\", None,"
    ],
    [
        "MessageMiddleware is tolerant of messages not existing on request.",
        "MessageMiddleware is tolerant of messages not existing"
    ],
    [
        "Sets the messages into the backend request's session and remove the",
        "Sets the messages into the backend request's"
    ],
    [
        "\"The session-based temporary message storage requires session \"",
        "\"The session-based temporary message storage requires session"
    ],
    [
        "\"middleware to be installed, and come before the message \"",
        "\"middleware to be installed, and come before"
    ],
    [
        "A message containing SafeData keeps its safe status when retrieved from",
        "A message containing SafeData keeps its safe status"
    ],
    [
        "author = {\"name\": \"John Doe\", \"slug\": \"success-msg\"}",
        "author = {\"name\": \"John Doe\","
    ],
    [
        "\"\"\"Dummy message-store to test the API methods.\"\"\"",
        "\"\"\"Dummy message-store to test"
    ],
    [
        "Return the storage totals from both cookie and session backends.",
        "Return the storage totals from both"
    ],
    [
        "allowed in a cookie will all be stored in the CookieBackend.",
        "allowed in a cookie will all"
    ],
    [
        "won't be written to at all.",
        "won't be written to at"
    ],
    [
        "If the data exceeds what is allowed in a cookie, messages which did",
        "If the data exceeds what is allowed in a cookie, messages"
    ],
    [
        "not fit are stored in the SessionBackend.",
        "not fit are stored"
    ],
    [
        "Large messages, none of which fit in a cookie, are stored in the",
        "Large messages, none of which fit in a cookie, are"
    ],
    [
        "SessionBackend (and nothing is stored in the CookieBackend).",
        "SessionBackend (and nothing is stored in the"
    ],
    [
        "msg = \"add_message() argument must be an HttpRequest object, not 'NoneType'.\"",
        "msg = \"add_message() argument must be"
    ],
    [
        "\"You cannot add messages without installing \"",
        "\"You cannot add messages"
    ],
    [
        "add_message() should use ducktyping to allow request wrappers such as the",
        "add_message() should use ducktyping to allow request wrappers such as"
    ],
    [
        "from django.contrib.messages import Message, add_message, constants",
        "from django.contrib.messages import Message, add_message,"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import"
    ],
    [
        "for level, message, extra_tags, expected in tests:",
        "for level, message, extra_tags, expected in"
    ],
    [
        "from django.urls import path, re_path, reverse",
        "from django.urls import"
    ],
    [
        "TEMPLATE = \"\"\"{% if messages %}",
        "TEMPLATE = \"\"\"{% if"
    ],
    [
        "{% for message in messages %}",
        "{% for message in messages"
    ],
    [
        "<li{% if message.tags %} class=\"{{ message.tags }}\"{% endif %}>",
        "<li{% if message.tags %} class=\"{{ message.tags }}\"{%"
    ],
    [
        "success_message = \"%(name)s was created successfully\"",
        "success_message = \"%(name)s was created"
    ],
    [
        "success_message = \"Object was deleted successfully\"",
        "success_message = \"Object was"
    ],
    [
        "from django.contrib.messages import Message, constants, get_level, set_level",
        "from django.contrib.messages import Message,"
    ],
    [
        "Return the storage backend, setting its loaded data to the ``data``",
        "Return the storage backend, setting its"
    ],
    [
        "This method avoids the storage ``_get`` method from getting called so",
        "This method avoids the storage ``_get`` method from getting called"
    ],
    [
        "that other parts of the storage backend can be tested independent of",
        "that other parts of the storage backend can be"
    ],
    [
        "With the message middleware enabled, messages are properly stored and",
        "With the message middleware enabled,"
    ],
    [
        "retrieved across the full request/redirect/response cycle.",
        "retrieved across the full request/redirect/response"
    ],
    [
        "for level in (\"debug\", \"info\", \"success\", \"warning\", \"error\"):",
        "for level in (\"debug\", \"info\", \"success\", \"warning\","
    ],
    [
        "messages = [Message(self.levels[level], msg) for msg in data[\"messages\"]]",
        "messages = [Message(self.levels[level], msg) for"
    ],
    [
        "Messages persist properly when multiple POSTs are made before a GET.",
        "Messages persist properly when multiple POSTs are made before"
    ],
    [
        "for level in (\"debug\", \"info\", \"success\", \"warning\", \"error\"):",
        "for level in (\"debug\", \"info\", \"success\","
    ],
    [
        "Message(self.levels[level], msg) for msg in data[\"messages\"]",
        "Message(self.levels[level], msg) for msg in"
    ],
    [
        "When the middleware is disabled, an exception is raised when one",
        "When the middleware is disabled, an exception"
    ],
    [
        "for level in (\"debug\", \"info\", \"success\", \"warning\", \"error\"):",
        "for level in (\"debug\", \"info\","
    ],
    [
        "When the middleware is disabled, an exception is not raised",
        "When the middleware is disabled, an exception is"
    ],
    [
        "for level in (\"debug\", \"info\", \"success\", \"warning\", \"error\"):",
        "for level in (\"debug\", \"info\", \"success\","
    ],
    [
        "Return the number of messages being stored after a",
        "Return the number of messages"
    ],
    [
        "raise NotImplementedError(\"This method must be set by a subclass.\")",
        "raise NotImplementedError(\"This method must be"
    ],
    [
        "raise NotImplementedError(\"This method must be set by a subclass.\")",
        "raise NotImplementedError(\"This method must be set by a"
    ],
    [
        "Reading the existing storage doesn't cause the data to be lost.",
        "Reading the existing storage doesn't cause the data to be"
    ],
    [
        "storage.add(constants.INFO, \"A generic info message\", extra_tags=None)",
        "storage.add(constants.INFO, \"A generic info message\","
    ],
    [
        "tags = [msg.tags for msg in storage]",
        "tags = [msg.tags for"
    ],
    [
        "tags, [\"info\", \"\", \"extra-tag debug\", \"warning\", \"error\", \"success\", \"info\"]",
        "tags, [\"info\", \"\", \"extra-tag debug\", \"warning\", \"error\", \"success\","
    ],
    [
        "tags = [msg.level_tag for msg in storage]",
        "tags = [msg.level_tag for msg in"
    ],
    [
        "self.assertEqual(tags, [\"info\", \"\", \"debug\", \"warning\", \"error\", \"success\"])",
        "self.assertEqual(tags, [\"info\", \"\", \"debug\", \"warning\","
    ],
    [
        "tags = [msg.tags for msg in storage]",
        "tags = [msg.tags for"
    ],
    [
        "self.assertEqual(tags, [\"info\", \"custom\", \"extra-tag\", \"\", \"bad\", \"success\"])",
        "self.assertEqual(tags, [\"info\", \"custom\", \"extra-tag\", \"\", \"bad\","
    ],
    [
        "This __doc__ output is required for testing. I copied this example from",
        "This __doc__ output is required for testing. I copied this"
    ],
    [
        "\"This __doc__ output is required for testing. I copied this example from\\n\"",
        "\"This __doc__ output is required for testing. I copied"
    ],
    [
        "\"<p>This __doc__ output is required for testing. I copied this \"",
        "\"<p>This __doc__ output is required for testing. I"
    ],
    [
        "'<p>Display an individual <a class=\"reference external\" '",
        "'<p>Display an individual <a class=\"reference external\""
    ],
    [
        "'docutils literal\">mymodel</tt></dt>\\n<dd>An instance of <a class=\"'",
        "'docutils literal\">mymodel</tt></dt>\\n<dd>An instance"
    ],
    [
        "parse_rst() should use `cmsreference` as the default role.",
        "parse_rst() should use `cmsreference`"
    ],
    [
        "markup = '<p><a class=\"reference external\" href=\"/admindocs/%s\">title</a></p>\\n'",
        "markup = '<p><a"
    ],
    [
        "title, body, _ = parse_docstring(\"firstline\\n\\n    second line\")",
        "title, body, _ = parse_docstring(\"firstline\\n\\n second"
    ],
    [
        "Django shouldn't break the default role for interpreted text",
        "Django shouldn't break the default"
    ],
    [
        "when ``publish_parts`` is used directly, by setting it to",
        "when ``publish_parts`` is used directly, by setting it"
    ],
    [
        "source = \"reST, `interpreted text`, default role.\"",
        "source = \"reST, `interpreted text`,"
    ],
    [
        "markup = \"<p>reST, <cite>interpreted text</cite>, default role.</p>\\n\"",
        "markup = \"<p>reST, <cite>interpreted text</cite>,"
    ],
    [
        "\"The XView middleware requires authentication middleware to be \"",
        "\"The XView middleware requires authentication middleware"
    ],
    [
        "\"installed. Edit your MIDDLEWARE setting to insert \"",
        "\"installed. Edit your MIDDLEWARE setting to"
    ],
    [
        "Models for testing various aspects of the django.contrib.admindocs app.",
        "Models for testing various aspects of the"
    ],
    [
        "This is a line with tag :tag:`extends <built_in-extends>`",
        "This is a line with tag :tag:`extends"
    ],
    [
        "This is a line with model :model:`Family <myapp.Family>`",
        "This is a line with"
    ],
    [
        "This is a line with view :view:`Index <myapp.views.Index>`",
        "This is a line"
    ],
    [
        "This is a line with template :template:`index template <Index.html>`",
        "This is a line with template :template:`index"
    ],
    [
        "This is a line with filter :filter:`example filter <filtername>`",
        "This is a line with"
    ],
    [
        "Stores information about a person, related to :model:`myapp.Company`.",
        "Stores information about a"
    ],
    [
        "Use ``save_changes()`` when saving this object.",
        "Use ``save_changes()`` when saving this"
    ],
    [
        "Field storing :model:`myapp.Company` where the person works.",
        "Field storing :model:`myapp.Company` where"
    ],
    [
        "company = models.ForeignKey(Company, models.CASCADE, help_text=\"place of work\")",
        "company = models.ForeignKey(Company, models.CASCADE,"
    ],
    [
        "family = models.ForeignKey(Family, models.SET_NULL, related_name=\"+\", null=True)",
        "family = models.ForeignKey(Family,"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\" %"
    ],
    [
        "def dummy_function(self, baz, rox, *some_args, **some_kwargs):",
        "def dummy_function(self, baz,"
    ],
    [
        "def all_kinds_arg_function(self, position_only_arg, /, arg, *, kwarg):",
        "def all_kinds_arg_function(self, position_only_arg, /,"
    ],
    [
        "Get the full name of the person",
        "Get the full name of"
    ],
    [
        "from django.test import SimpleTestCase, modify_settings, override_settings",
        "from django.test import"
    ],
    [
        "from django.urls import include, path, reverse",
        "from django.urls import"
    ],
    [
        "response, '<input type=\"hidden\" name=\"next\" value=\"/admindocs/\">', html=True",
        "response, '<input type=\"hidden\" name=\"next\""
    ],
    [
        "Views that are methods are listed correctly.",
        "Views that are methods"
    ],
    [
        "self.assertContains(response, \"Base view for admindocs views.\")",
        "self.assertContains(response, \"Base view for admindocs"
    ],
    [
        "Views that are methods can be displayed.",
        "Views that are methods can be"
    ],
    [
        "\"<p>Please ask your administrators to install \"",
        "\"<p>Please ask your administrators"
    ],
    [
        "Without the sites framework, should not access SITE_ID or Site",
        "Without the sites framework, should not access SITE_ID or"
    ],
    [
        "objects. Deleting settings is fine here as UserSettingsHolder is used.",
        "objects. Deleting settings is fine here as UserSettingsHolder"
    ],
    [
        "Index view should correctly resolve view patterns when ROOT_URLCONF is",
        "Index view should correctly resolve view patterns when ROOT_URLCONF"
    ],
    [
        "Methods that begin with strings defined in",
        "Methods that begin with strings defined"
    ],
    [
        "shouldn't be displayed in the admin docs.",
        "shouldn't be displayed in the"
    ],
    [
        "Methods that take arguments should also displayed.",
        "Methods that take arguments should also"
    ],
    [
        "Methods with arguments should have their arguments displayed.",
        "Methods with arguments should have their"
    ],
    [
        "Methods with keyword arguments should have their arguments displayed.",
        "Methods with keyword arguments should have their"
    ],
    [
        "Methods with multiple arguments should have all their arguments",
        "Methods with multiple arguments should have"
    ],
    [
        "\"\"\"Model properties are displayed as fields.\"\"\"",
        "\"\"\"Model properties are"
    ],
    [
        "\"\"\"Model cached properties are displayed as fields.\"\"\"",
        "\"\"\"Model cached properties are displayed"
    ],
    [
        "The ``description`` field should render correctly for each field type.",
        "The ``description`` field should render correctly"
    ],
    [
        "self.response, \"<td>first name - The person's first name</td>\"",
        "self.response, \"<td>first name -"
    ],
    [
        "self.response, \"<td>last name - The person's last name</td>\"",
        "self.response, \"<td>last name - The person's"
    ],
    [
        "self.assertContains(self.response, \"<p>Get the full name of the person</p>\")",
        "self.assertContains(self.response, \"<p>Get the full name of the"
    ],
    [
        "link = '<a class=\"reference external\" href=\"/admindocs/models/%s/\">%s</a>'",
        "link = '<a class=\"reference"
    ],
    [
        "markup = \"<p>the related %s object</p>\"",
        "markup = \"<p>the related"
    ],
    [
        "company_markup = markup % (link % (\"admin_docs.company\", \"admin_docs.Company\"))",
        "company_markup = markup % (link"
    ],
    [
        "self.assertContains(self.response, \"%s\\n - place of work\" % company_markup)",
        "self.assertContains(self.response, \"%s\\n - place of"
    ],
    [
        "self.response, \".. raw:: html\\n    :file: admin_docs/evilfile.txt\"",
        "self.response, \".. raw::"
    ],
    [
        "link = '<a class=\"reference external\" href=\"/admindocs/models/%s/\">%s</a>'",
        "link = '<a class=\"reference external\""
    ],
    [
        "A model with ``related_name`` of `+` shouldn't show backward",
        "A model with ``related_name`` of `+` shouldn't show"
    ],
    [
        "'<p>Use <tt class=\"docutils literal\">save_changes()</tt> when saving this '",
        "'<p>Use <tt class=\"docutils literal\">save_changes()</tt>"
    ],
    [
        "summary = \"Links with different link text.\"",
        "summary = \"Links with different link"
    ],
    [
        "'<p>This is a line with tag <a class=\"reference external\" '",
        "'<p>This is a line with tag <a class=\"reference external\""
    ],
    [
        "'This is a line with model <a class=\"reference external\" '",
        "'This is a line with"
    ],
    [
        "'This is a line with view <a class=\"reference external\" '",
        "'This is a line with view <a"
    ],
    [
        "'This is a line with template <a class=\"reference external\" '",
        "'This is a line with template <a class=\"reference external\""
    ],
    [
        "'This is a line with filter <a class=\"reference external\" '",
        "'This is a line with filter <a"
    ],
    [
        "\"Model 'doesnotexist' not found in app 'admin_docs'\",",
        "\"Model 'doesnotexist' not found"
    ],
    [
        "description = \"A custom field type\"",
        "description = \"A custom"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, modify_settings, override_settings",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "This is a view for :model:`myapp.Company`",
        "This is a view for"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TestCase, skipIfDBFeature,"
    ],
    [
        "msg = \"Chunk size must be strictly positive.\"",
        "msg = \"Chunk size must be strictly"
    ],
    [
        "[x async for x in qs]",
        "[x async for x"
    ],
    [
        "\"This database backend does not support updating conflicts with specifying \"",
        "\"This database backend does not support updating conflicts"
    ],
    [
        "\"unique fields that can trigger the upsert.\"",
        "\"unique fields that can trigger the"
    ],
    [
        "qs = [(o.pk, o.field) async for o in SimpleModel.objects.all()]",
        "qs = [(o.pk, o.field) async for o in"
    ],
    [
        "qs = [o async for o in SimpleModel.objects.all()]",
        "qs = [o async"
    ],
    [
        "values = [instance.field for instance in qs]",
        "values = [instance.field for instance"
    ],
    [
        "qs = [o async for o in SimpleModel.objects.all()]",
        "qs = [o async for o in"
    ],
    [
        "self.fail(f\"QuerySet.aexplain() result is not valid XML: {e}\")",
        "self.fail(f\"QuerySet.aexplain() result is not valid"
    ],
    [
        "self.fail(f\"QuerySet.aexplain() result is not valid JSON: {e}\")",
        "self.fail(f\"QuerySet.aexplain() result is not valid"
    ],
    [
        "sql = \"SELECT id, field FROM async_simplemodel WHERE created=%s\"",
        "sql = \"SELECT id, field FROM async_simplemodel"
    ],
    [
        "msg = \"No SimpleModel matches the given query.\"",
        "msg = \"No SimpleModel"
    ],
    [
        "msg = \"No SimpleModel matches the given query.\"",
        "msg = \"No SimpleModel matches the given"
    ],
    [
        "\"'HttpRequest' object has no attribute 'auser'\",",
        "\"'HttpRequest' object has no attribute"
    ],
    [
        "\"Fallback to request.user when user is None will be removed.\",",
        "\"Fallback to request.user when user is None"
    ],
    [
        "\"'AnonymousUser' object has no attribute '_meta'\",",
        "\"'AnonymousUser' object has no attribute"
    ],
    [
        "\"Fallback to request.user when user is None will be removed.\",",
        "\"Fallback to request.user when user is"
    ],
    [
        "\"Fallback to request.user when user is None will be removed.\",",
        "\"Fallback to request.user when user is None will be"
    ],
    [
        "\"\"\"A database connection cannot be used in an async context.\"\"\"",
        "\"\"\"A database connection cannot be used in an async"
    ],
    [
        "async_unsafe decorator should work correctly and returns the correct",
        "async_unsafe decorator should work correctly and returns the"
    ],
    [
        "\"You cannot call this from an async context - use a thread or \"",
        "\"You cannot call this from an async context - use a thread or"
    ],
    [
        "async def get(self, request, *args, **kwargs):",
        "async def get(self, request, *args,"
    ],
    [
        "async def post(self, request, *args, **kwargs):",
        "async def post(self,"
    ],
    [
        "f\"{MixedView.__qualname__} HTTP handlers must either be all sync or all \"",
        "f\"{MixedView.__qualname__} HTTP handlers must either be all"
    ],
    [
        "View and by extension any subclasses that don't define handlers are",
        "View and by extension any subclasses that don't define"
    ],
    [
        "from .models import ManyToManyModel, RelatedModel, SimpleModel",
        "from .models import ManyToManyModel,"
    ],
    [
        "from django.core.checks.security import base, csrf, sessions",
        "from django.core.checks.security import base,"
    ],
    [
        "Warn if SESSION_COOKIE_SECURE is off and \"django.contrib.sessions\" is",
        "Warn if SESSION_COOKIE_SECURE is"
    ],
    [
        "Warn if SESSION_COOKIE_SECURE is off and",
        "Warn if SESSION_COOKIE_SECURE"
    ],
    [
        "If SESSION_COOKIE_SECURE is off and we find both the session app and",
        "If SESSION_COOKIE_SECURE is off and we find both the session app"
    ],
    [
        "the middleware, provide one common warning.",
        "the middleware, provide"
    ],
    [
        "If SESSION_COOKIE_SECURE is on, there's no warning about it.",
        "If SESSION_COOKIE_SECURE is on, there's no warning"
    ],
    [
        "Warn if SESSION_COOKIE_HTTPONLY is off and \"django.contrib.sessions\"",
        "Warn if SESSION_COOKIE_HTTPONLY is off"
    ],
    [
        "Warn if SESSION_COOKIE_HTTPONLY is off and",
        "Warn if SESSION_COOKIE_HTTPONLY is off"
    ],
    [
        "If SESSION_COOKIE_HTTPONLY is off and we find both the session app and",
        "If SESSION_COOKIE_HTTPONLY is off and we find both the"
    ],
    [
        "the middleware, provide one common warning.",
        "the middleware, provide one common"
    ],
    [
        "If SESSION_COOKIE_HTTPONLY is on, there's no warning about it.",
        "If SESSION_COOKIE_HTTPONLY is on, there's no warning"
    ],
    [
        "Warn if CsrfViewMiddleware isn't in MIDDLEWARE.",
        "Warn if CsrfViewMiddleware"
    ],
    [
        "Warn if CsrfViewMiddleware is in MIDDLEWARE but",
        "Warn if CsrfViewMiddleware is in"
    ],
    [
        "No warning if CSRF_COOKIE_SECURE isn't True while CSRF_USE_SESSIONS",
        "No warning if CSRF_COOKIE_SECURE isn't"
    ],
    [
        "No warning if CsrfViewMiddleware isn't in MIDDLEWARE, even if",
        "No warning if CsrfViewMiddleware isn't in"
    ],
    [
        "Warn if SecurityMiddleware isn't in MIDDLEWARE.",
        "Warn if SecurityMiddleware isn't in"
    ],
    [
        "Don't warn if SecurityMiddleware isn't installed.",
        "Don't warn if SecurityMiddleware"
    ],
    [
        "Don't warn if SECURE_HSTS_SECONDS isn't set.",
        "Don't warn if"
    ],
    [
        "Don't warn if SecurityMiddleware isn't installed.",
        "Don't warn if"
    ],
    [
        "Don't warn if SECURE_HSTS_SECONDS isn't set.",
        "Don't warn if SECURE_HSTS_SECONDS isn't"
    ],
    [
        "Warn if XFrameOptionsMiddleware isn't in MIDDLEWARE.",
        "Warn if XFrameOptionsMiddleware"
    ],
    [
        "Warn if XFrameOptionsMiddleware is in MIDDLEWARE but",
        "Warn if XFrameOptionsMiddleware is in"
    ],
    [
        "No error if XFrameOptionsMiddleware isn't in MIDDLEWARE even if",
        "No error if XFrameOptionsMiddleware isn't in MIDDLEWARE even"
    ],
    [
        "Don't warn if SECURE_CONTENT_TYPE_NOSNIFF isn't True and",
        "Don't warn if SECURE_CONTENT_TYPE_NOSNIFF"
    ],
    [
        "Don't warn if SECURE_SSL_REDIRECT is False and SecurityMiddleware isn't",
        "Don't warn if SECURE_SSL_REDIRECT is False"
    ],
    [
        "Don't warn if SECURE_REFERRER_POLICY is None and SecurityMiddleware",
        "Don't warn if SECURE_REFERRER_POLICY is None and"
    ],
    [
        "\"The CSRF failure view '' could not be imported.\",",
        "\"The CSRF failure view '' could"
    ],
    [
        "\"does not take the correct number of arguments.\"",
        "\"does not take the"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"mysql\", \"Test only for MySQL\")",
        "@unittest.skipUnless(connection.vendor == \"mysql\", \"Test only"
    ],
    [
        "Routes to the 'other' database if the model name starts with 'Other'.",
        "Routes to the 'other' database if the model name starts with"
    ],
    [
        "def allow_migrate(self, db, app_label, model_name=None, **hints):",
        "def allow_migrate(self, db, app_label, model_name=None,"
    ],
    [
        "return db == (\"other\" if model_name.startswith(\"other\") else \"default\")",
        "return db == (\"other\" if model_name.startswith(\"other\")"
    ],
    [
        "\"'string_if_invalid' in TEMPLATES OPTIONS must be a string but got: %r \"",
        "\"'string_if_invalid' in TEMPLATES OPTIONS must be a string but got: %r"
    ],
    [
        "f\"'same_tags' is used for multiple template tag modules: {modules}\",",
        "f\"'same_tags' is used for multiple template tag modules:"
    ],
    [
        "\"msg\": \"This field is deprecated and will be removed soon.\",",
        "\"msg\": \"This field is deprecated"
    ],
    [
        "msg=\"This field is deprecated and will be removed soon.\",",
        "msg=\"This field is deprecated and will be"
    ],
    [
        "\"MyField has been removed except for support in historical \"",
        "\"MyField has been removed except for"
    ],
    [
        "\"msg\": \"Support for this field is gone.\",",
        "\"msg\": \"Support for this"
    ],
    [
        "msg=\"Support for this field is gone.\",",
        "msg=\"Support for this field"
    ],
    [
        "Don't error if 'default' is present in CACHES setting.",
        "Don't error if 'default' is present"
    ],
    [
        "Error if 'default' not present in CACHES setting.",
        "Error if 'default' not present in"
    ],
    [
        "\"Your 'default' cache configuration might expose your cache or lead \"",
        "\"Your 'default' cache configuration might expose your"
    ],
    [
        "\"to corruption of your data because its LOCATION %s %s.\"",
        "\"to corruption of your data because"
    ],
    [
        "setting: [setting_path] if setting == \"STATICFILES_DIRS\" else setting_path,",
        "setting: [setting_path] if setting == \"STATICFILES_DIRS\""
    ],
    [
        "for setting in (\"MEDIA_ROOT\", \"STATIC_ROOT\", \"STATICFILES_DIRS\"):",
        "for setting in (\"MEDIA_ROOT\", \"STATIC_ROOT\","
    ],
    [
        "msg = self.warning_message % (\"matches\", setting)",
        "msg = self.warning_message %"
    ],
    [
        "for setting in (\"MEDIA_ROOT\", \"STATIC_ROOT\", \"STATICFILES_DIRS\"):",
        "for setting in (\"MEDIA_ROOT\","
    ],
    [
        "settings = self.get_settings(setting, root / \"cache\", root)",
        "settings = self.get_settings(setting, root /"
    ],
    [
        "msg = self.warning_message % (\"is inside\", setting)",
        "msg = self.warning_message % (\"is inside\","
    ],
    [
        "for setting in (\"MEDIA_ROOT\", \"STATIC_ROOT\", \"STATICFILES_DIRS\"):",
        "for setting in (\"MEDIA_ROOT\", \"STATIC_ROOT\","
    ],
    [
        "settings = self.get_settings(setting, root, root / \"other\")",
        "settings = self.get_settings(setting, root,"
    ],
    [
        "msg = self.warning_message % (\"contains\", setting)",
        "msg = self.warning_message %"
    ],
    [
        "for setting in (\"MEDIA_ROOT\", \"STATIC_ROOT\", \"STATICFILES_DIRS\"):",
        "for setting in (\"MEDIA_ROOT\", \"STATIC_ROOT\","
    ],
    [
        "settings = self.get_settings(setting, root / \"cache\", root / \"other\")",
        "settings = self.get_settings(setting, root / \"cache\", root"
    ],
    [
        "(root / \"cache\", root, \"is inside\"),",
        "(root / \"cache\", root,"
    ],
    [
        "for cache_path, setting_path, msg in tests:",
        "for cache_path, setting_path, msg in"
    ],
    [
        "msg = self.warning_message % (msg, \"STATICFILES_DIRS\")",
        "msg = self.warning_message %"
    ],
    [
        "\"Your 'default' cache LOCATION path is relative. Use an \"",
        "\"Your 'default' cache LOCATION path"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase,"
    ],
    [
        "\"db_table 'test_table' is used by multiple models: \"",
        "\"db_table 'test_table' is used by"
    ],
    [
        "\"db_table 'test_table' is used by multiple models: \"",
        "\"db_table 'test_table' is used by multiple models:"
    ],
    [
        "\"You have configured settings.DATABASE_ROUTERS. Verify \"",
        "\"You have configured settings.DATABASE_ROUTERS. Verify"
    ],
    [
        "\"db_table 'test_table' is used by multiple models: \"",
        "\"db_table 'test_table' is used"
    ],
    [
        "\"db_table 'test_table' is used by multiple models: \"",
        "\"db_table 'test_table' is used"
    ],
    [
        "\"You have configured settings.DATABASE_ROUTERS. Verify \"",
        "\"You have configured settings.DATABASE_ROUTERS."
    ],
    [
        "\"index name 'foo' is not unique for model check_framework.Model.\",",
        "\"index name 'foo' is not unique for"
    ],
    [
        "\"index name 'foo' is not unique among models: \"",
        "\"index name 'foo' is not"
    ],
    [
        "\"index name 'foo' is not unique among models: \"",
        "\"index name 'foo' is not unique"
    ],
    [
        "\"constraint name 'foo' is not unique for model \"",
        "\"constraint name 'foo' is not unique for"
    ],
    [
        "\"constraint name 'foo' is not unique among models: \"",
        "\"constraint name 'foo' is not unique among"
    ],
    [
        "\"constraint name 'foo' is not unique among models: \"",
        "\"constraint name 'foo' is not"
    ],
    [
        "\"constraint name 'foo' is not unique among models: \"",
        "\"constraint name 'foo' is not"
    ],
    [
        "\"Auto-created primary key used when not defining a primary key type, \"",
        "\"Auto-created primary key used when not defining"
    ],
    [
        "\"Configure the DEFAULT_AUTO_FIELD setting or the \"",
        "\"Configure the DEFAULT_AUTO_FIELD setting or"
    ],
    [
        "\"CheckDefaultPKConfig.default_auto_field attribute to point to a \"",
        "\"CheckDefaultPKConfig.default_auto_field attribute to point to"
    ],
    [
        "\"The FILE_UPLOAD_TEMP_DIR setting refers to the \"",
        "\"The FILE_UPLOAD_TEMP_DIR setting refers to the"
    ],
    [
        "\"setting must start with a scheme (usually http:// or \"",
        "\"setting must start with a scheme"
    ],
    [
        "\"https://) but found example.com. See the release notes for \"",
        "\"https://) but found example.com. See"
    ],
    [
        "from django.test.utils import isolate_apps, override_settings, override_system_checks",
        "from django.test.utils import"
    ],
    [
        "\"The migrate and makemigrations commands must have the same \"",
        "\"The migrate and makemigrations commands must have the same"
    ],
    [
        "from django.test.utils import isolate_apps, override_settings, override_system_checks",
        "from django.test.utils import"
    ],
    [
        "msg = \"Check functions must accept keyword arguments (**kwargs).\"",
        "msg = \"Check functions must accept"
    ],
    [
        "\"The function %r did not return a list. All functions registered \"",
        "\"The function %r did not return"
    ],
    [
        "\"with the checks registry must return a list.\" % return_non_iterable",
        "\"with the checks registry must return a list.\""
    ],
    [
        "e = Error(\"Message\", hint=\"Hint\", obj=DummyObj(), id=\"ID\")",
        "e = Error(\"Message\", hint=\"Hint\","
    ],
    [
        "expected = \"obj: (ID) Message\\n\\tHINT: Hint\"",
        "expected = \"obj: (ID)"
    ],
    [
        "msg = \"The first argument should be level.\"",
        "msg = \"The first"
    ],
    [
        "msg = 'There is no system check with the \"missingtag\" tag.'",
        "msg = 'There is no system check with the \"missingtag\""
    ],
    [
        "msg = 'There is no system check with the \"deploymenttag\" tag.'",
        "msg = 'There is no system check with"
    ],
    [
        "\"The 'ModelWithAttributeCalledCheck.check()' class method is \"",
        "\"The 'ModelWithAttributeCalledCheck.check()' class method is"
    ],
    [
        "\"The 'ModelWithFieldCalledCheck.check()' class method is \"",
        "\"The 'ModelWithFieldCalledCheck.check()' class"
    ],
    [
        "\"currently overridden by %r.\" % ModelWithFieldCalledCheck.check,",
        "\"currently overridden by"
    ],
    [
        "\"The 'ModelWithRelatedManagerCalledCheck.check()' class method is \"",
        "\"The 'ModelWithRelatedManagerCalledCheck.check()' class"
    ],
    [
        "\"The 'ModelWithDescriptorCalledCheck.check()' class method is \"",
        "\"The 'ModelWithDescriptorCalledCheck.check()' class"
    ],
    [
        "\"currently overridden by %r.\" % ModelWithDescriptorCalledCheck.check,",
        "\"currently overridden by %r.\" %"
    ],
    [
        "\"Spawning reimports modules, overwriting my_check.did_run to False, making this \"",
        "\"Spawning reimports modules, overwriting my_check.did_run to False, making this"
    ],
    [
        "msg = \"You have provided an invalid value for the LANGUAGE_CODE setting: %r.\"",
        "msg = \"You have provided an invalid value"
    ],
    [
        "msg = \"You have provided an invalid language code in the LANGUAGES setting: %r.\"",
        "msg = \"You have provided an invalid"
    ],
    [
        "\"You have provided an invalid language code in the LANGUAGES_BIDI setting: \"",
        "\"You have provided an invalid language code in the LANGUAGES_BIDI"
    ],
    [
        "\"You have provided a value for the LANGUAGE_CODE setting that is \"",
        "\"You have provided a value for the LANGUAGE_CODE setting"
    ],
    [
        "\"Your URL pattern '^include-with-dollar$' uses include with a \"",
        "\"Your URL pattern '^include-with-dollar$' uses"
    ],
    [
        "\"route ending with a '$'. Remove the dollar from the route to \"",
        "\"route ending with a '$'. Remove the dollar from the route to"
    ],
    [
        "r\"is invalid. Ensure that urlpatterns is a list of path\\(\\) and/or \"",
        "r\"is invalid. Ensure that urlpatterns is a"
    ],
    [
        "r\"is invalid. Ensure that urlpatterns is a list of path\\(\\) and/or \"",
        "r\"is invalid. Ensure that urlpatterns is a list of path\\(\\) and/or"
    ],
    [
        "\"Your URL pattern '%s' has a route beginning with a '/'. Remove \"",
        "\"Your URL pattern '%s' has a route"
    ],
    [
        "\"this slash as it is unnecessary. If this pattern is targeted in \"",
        "\"this slash as it is unnecessary. If this pattern is targeted"
    ],
    [
        "\"an include(), ensure the include() pattern has a trailing '/'.\"",
        "\"an include(), ensure the include() pattern"
    ],
    [
        "\"Your URL pattern '^$' [name='name_with:colon'] has a name including a ':'.\"",
        "\"Your URL pattern '^$' [name='name_with:colon'] has"
    ],
    [
        "\"Try removing the string ''. The list of urlpatterns should \"",
        "\"Try removing the string ''. The list of urlpatterns should"
    ],
    [
        "\"not have a prefix string as the first element.\",",
        "\"not have a prefix string as the"
    ],
    [
        "self.assertEqual(warning.hint, \"Try using path() instead of a tuple.\")",
        "self.assertEqual(warning.hint, \"Try using path() instead of a"
    ],
    [
        "\"URL namespace '{}' isn't unique. You may not be able to reverse \"",
        "\"URL namespace '{}' isn't unique. You may not be able"
    ],
    [
        "\"Your URL pattern 'missing_as_view' has an invalid view, pass \"",
        "\"Your URL pattern 'missing_as_view' has"
    ],
    [
        "\"Your URL pattern 'beginning-with/<angle_bracket' has an unmatched \"",
        "\"Your URL pattern 'beginning-with/<angle_bracket' has"
    ],
    [
        "\"Your URL pattern 'ending-with/angle_bracket>' has an unmatched \"",
        "\"Your URL pattern 'ending-with/angle_bracket>' has"
    ],
    [
        "\"Your URL pattern 'closed_angle>/x/<opened_angle' has an unmatched \"",
        "\"Your URL pattern 'closed_angle>/x/<opened_angle'"
    ],
    [
        "\"Your URL pattern 'closed_angle>/x/<opened_angle' has an unmatched \"",
        "\"Your URL pattern 'closed_angle>/x/<opened_angle'"
    ],
    [
        "\"Your URL pattern '<mixed>angle_bracket>' has an unmatched '>' \"",
        "\"Your URL pattern '<mixed>angle_bracket>' has an unmatched '>'"
    ],
    [
        "expected_msg = \"Your URL pattern '(?P<named_group>\\\\d+)' has a route\"",
        "expected_msg = \"Your URL pattern"
    ],
    [
        "expected_msg = \"Your URL pattern '^beginning-with-caret' has a route\"",
        "expected_msg = \"Your URL pattern '^beginning-with-caret' has"
    ],
    [
        "expected_msg = \"Your URL pattern 'ending-with-dollar$' has a route\"",
        "expected_msg = \"Your URL pattern 'ending-with-dollar$' has a"
    ],
    [
        "\"does not take the correct number of arguments \"",
        "\"does not take the correct number"
    ],
    [
        "\"<locals>.view' does not take the correct number of \"",
        "\"<locals>.view' does not take the"
    ],
    [
        "\"Could not import '{}'. View does not exist in module django.views.\",",
        "\"Could not import '{}'. View does not exist"
    ],
    [
        "\"Could not import '{}'. Parent module django.invalid_module does not \"",
        "\"Could not import '{}'. Parent"
    ],
    [
        "\"Could not import '{}'. The path must be fully qualified.\",",
        "\"Could not import '{}'. The path must"
    ],
    [
        "\"The custom handler{} view '{}' could not be imported.\".format(",
        "\"The custom handler{} view '{}' could not"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import include, path,"
    ],
    [
        "from datetime import date, datetime, timedelta, timezone",
        "from datetime import date,"
    ],
    [
        "\"\"\"Cookie will expire when a near expiration time is provided.\"\"\"",
        "\"\"\"Cookie will expire when a near expiration time"
    ],
    [
        "\"\"\"set_cookie() accepts an aware datetime as expiration time.\"\"\"",
        "\"\"\"set_cookie() accepts an aware datetime as"
    ],
    [
        "\"\"\"Setting a cookie after deletion clears the expiry date.\"\"\"",
        "\"\"\"Setting a cookie after deletion clears the"
    ],
    [
        "\"\"\"Cookie will expire when a distant expiration time is provided.\"\"\"",
        "\"\"\"Cookie will expire when a distant"
    ],
    [
        "\"\"\"Cookie will expire if max_age is provided.\"\"\"",
        "\"\"\"Cookie will expire if"
    ],
    [
        "msg = \"'expires' and 'max_age' can't be used together.\"",
        "msg = \"'expires' and 'max_age'"
    ],
    [
        "msg = 'samesite must be \"lax\", \"none\", or \"strict\".'",
        "msg = 'samesite must be"
    ],
    [
        "delete_cookie() sets the secure flag if the cookie name starts with",
        "delete_cookie() sets the secure flag if the cookie name starts"
    ],
    [
        "__Host- or __Secure- (without that, browsers ignore cookies with those",
        "__Host- or __Secure- (without that,"
    ],
    [
        "Headers are set correctly with a buffer when an absolute filename is",
        "Headers are set correctly with a"
    ],
    [
        "pipe_for_read = os.open(pipe_file, os.O_RDONLY | os.O_NONBLOCK)",
        "pipe_for_read = os.open(pipe_file, os.O_RDONLY"
    ],
    [
        "If compressed responses are served with the uncompressed Content-Type",
        "If compressed responses are served with the uncompressed"
    ],
    [
        "and a compression Content-Encoding, browsers might automatically",
        "and a compression Content-Encoding,"
    ],
    [
        "uncompress the file, which is most probably not wanted.",
        "uncompress the file, which is most"
    ],
    [
        "OSError, \"This HttpResponseBase instance is not writable\"",
        "OSError, \"This HttpResponseBase instance is"
    ],
    [
        "OSError, \"This HttpResponseBase instance is not writable\"",
        "OSError, \"This HttpResponseBase instance"
    ],
    [
        "OSError, \"This HttpResponseBase instance cannot tell its position\"",
        "OSError, \"This HttpResponseBase instance"
    ],
    [
        "HttpResponseBase.setdefault() should not change an existing header",
        "HttpResponseBase.setdefault() should not change"
    ],
    [
        "must_be_integer = \"HTTP status code must be an integer.\"",
        "must_be_integer = \"HTTP status code must be an"
    ],
    [
        "reason = \"I'm an anarchist coffee pot on crack.\"",
        "reason = \"I'm an anarchist"
    ],
    [
        "\"\"\"HttpResponse should parse charset from content_type.\"\"\"",
        "\"\"\"HttpResponse should parse charset from"
    ],
    [
        "\"\"\"HttpResponse should encode based on charset.\"\"\"",
        "\"\"\"HttpResponse should encode based on"
    ],
    [
        "sql = \"SELECT * FROM %(db_table)s %(for_update)s;\" % {",
        "sql = \"SELECT * FROM %(db_table)s %(for_update)s;\" %"
    ],
    [
        "return any(for_update_sql in query[\"sql\"] for query in queries)",
        "return any(for_update_sql in query[\"sql\"] for query"
    ],
    [
        "The backend's FOR UPDATE variant appears in",
        "The backend's FOR UPDATE"
    ],
    [
        "generated SQL when select_for_update is invoked.",
        "generated SQL when select_for_update"
    ],
    [
        "The backend's FOR UPDATE NOWAIT variant appears in",
        "The backend's FOR UPDATE NOWAIT variant"
    ],
    [
        "generated SQL when select_for_update is invoked.",
        "generated SQL when select_for_update is"
    ],
    [
        "The backend's FOR UPDATE SKIP LOCKED variant appears in",
        "The backend's FOR UPDATE SKIP LOCKED variant"
    ],
    [
        "generated SQL when select_for_update is invoked.",
        "generated SQL when"
    ],
    [
        "The backend's FOR NO KEY UPDATE variant appears in generated SQL when",
        "The backend's FOR NO KEY UPDATE variant appears in generated"
    ],
    [
        "The backend's FOR UPDATE OF variant appears in the generated SQL when",
        "The backend's FOR UPDATE OF variant appears"
    ],
    [
        "expected = [connection.ops.quote_name(value) for value in expected]",
        "expected = [connection.ops.quote_name(value) for"
    ],
    [
        "expected = [connection.ops.quote_name(value) for value in expected]",
        "expected = [connection.ops.quote_name(value) for"
    ],
    [
        "expected = [connection.ops.quote_name(value) for value in expected]",
        "expected = [connection.ops.quote_name(value) for value in"
    ],
    [
        "expected = [connection.ops.quote_name(value) for value in expected]",
        "expected = [connection.ops.quote_name(value) for"
    ],
    [
        "expected = [connection.ops.quote_name(value) for value in expected]",
        "expected = [connection.ops.quote_name(value) for value"
    ],
    [
        "expected = [connection.ops.quote_name(value) for value in expected]",
        "expected = [connection.ops.quote_name(value) for value"
    ],
    [
        "expected = [connection.ops.quote_name(value) for value in expected]",
        "expected = [connection.ops.quote_name(value) for"
    ],
    [
        "select_for_update(of=['self']) when the only columns selected are from",
        "select_for_update(of=['self']) when the only"
    ],
    [
        "If nowait is specified, we expect an error to be raised rather",
        "If nowait is specified, we expect an error"
    ],
    [
        "If skip_locked is specified, the locked row is skipped resulting in",
        "If skip_locked is specified, the locked row"
    ],
    [
        "NotSupportedError is raised if a SELECT...FOR UPDATE NOWAIT is run on",
        "NotSupportedError is raised if a SELECT...FOR UPDATE"
    ],
    [
        "a database backend that supports FOR UPDATE but not NOWAIT.",
        "a database backend that supports FOR UPDATE but"
    ],
    [
        "NotSupportedError, \"NOWAIT is not supported on this database backend.\"",
        "NotSupportedError, \"NOWAIT is not supported on this"
    ],
    [
        "NotSupportedError is raised if a SELECT...FOR UPDATE SKIP LOCKED is run",
        "NotSupportedError is raised if a SELECT...FOR UPDATE"
    ],
    [
        "on a database backend that supports FOR UPDATE but not SKIP LOCKED.",
        "on a database backend that supports FOR UPDATE"
    ],
    [
        "NotSupportedError, \"SKIP LOCKED is not supported on this database backend.\"",
        "NotSupportedError, \"SKIP LOCKED is not supported on this"
    ],
    [
        "NotSupportedError is raised if a SELECT...FOR UPDATE OF... is run on",
        "NotSupportedError is raised if a SELECT...FOR UPDATE OF... is run"
    ],
    [
        "a database backend that supports FOR UPDATE but not OF.",
        "a database backend that supports"
    ],
    [
        "msg = \"FOR UPDATE OF is not supported on this database backend.\"",
        "msg = \"FOR UPDATE OF is not"
    ],
    [
        "NotSupportedError is raised if a SELECT...FOR NO KEY UPDATE... is run",
        "NotSupportedError is raised if a SELECT...FOR NO KEY"
    ],
    [
        "on a database backend that supports FOR UPDATE but not NO KEY.",
        "on a database backend that supports FOR UPDATE but"
    ],
    [
        "msg = \"FOR NO KEY UPDATE is not supported on this database backend.\"",
        "msg = \"FOR NO KEY UPDATE is not supported on this"
    ],
    [
        "FieldError is raised if a non-relation field is specified in of=(...).",
        "FieldError is raised if a non-relation field is"
    ],
    [
        "\"Invalid field name(s) given in select_for_update(of=(...)): %s. \"",
        "\"Invalid field name(s) given in select_for_update(of=(...)): %s."
    ],
    [
        "\"Only relational fields followed in the query are allowed. \"",
        "\"Only relational fields followed in the query are"
    ],
    [
        "\"Choices are: self, born, born__country, \"",
        "\"Choices are: self,"
    ],
    [
        "with self.assertRaisesMessage(FieldError, msg % \", \".join(of)):",
        "with self.assertRaisesMessage(FieldError, msg %"
    ],
    [
        "FieldError is raised if a relation field that is not followed in the",
        "FieldError is raised if a relation field that"
    ],
    [
        "\"Invalid field name(s) given in select_for_update(of=(...)): %s. \"",
        "\"Invalid field name(s) given"
    ],
    [
        "\"Only relational fields followed in the query are allowed. \"",
        "\"Only relational fields followed in the"
    ],
    [
        "for name in [\"born__country\", \"died\", \"died__country\"]:",
        "for name in"
    ],
    [
        "\"Invalid field name(s) given in select_for_update(of=(...)): \"",
        "\"Invalid field name(s) given"
    ],
    [
        "\"name. Only relational fields followed in the query are allowed. \"",
        "\"name. Only relational fields followed in the"
    ],
    [
        "\"Invalid field name(s) given in select_for_update(of=(...)): \"",
        "\"Invalid field name(s) given in"
    ],
    [
        "\"name. Only relational fields followed in the query are allowed. \"",
        "\"name. Only relational fields followed in the query are allowed."
    ],
    [
        "Reverse OneToOneFields may be included in of=(...) as long as NULLs",
        "Reverse OneToOneFields may be included in of=(...)"
    ],
    [
        "are excluded because LEFT JOIN isn't allowed in SELECT FOR UPDATE.",
        "are excluded because LEFT JOIN isn't allowed in"
    ],
    [
        "when a select_for_update query is executed outside of a transaction.",
        "when a select_for_update query is executed outside"
    ],
    [
        "msg = \"select_for_update cannot be used outside of a transaction.\"",
        "msg = \"select_for_update cannot be used"
    ],
    [
        "when select_for_update is invoked outside of a transaction -",
        "when select_for_update is invoked outside of"
    ],
    [
        "only when the query is executed.",
        "only when the query is"
    ],
    [
        "msg = \"select_for_update cannot be used outside of a transaction.\"",
        "msg = \"select_for_update cannot be"
    ],
    [
        "\"LIMIT/OFFSET is not supported with select_for_update on this database \"",
        "\"LIMIT/OFFSET is not supported with select_for_update"
    ],
    [
        "Utility method that runs a SELECT FOR UPDATE against all",
        "Utility method that runs a SELECT FOR UPDATE"
    ],
    [
        "Person instances. After the select_for_update, it attempts",
        "Person instances. After the"
    ],
    [
        "to update the name of the only record, save, and commit.",
        "to update the name of the only"
    ],
    [
        "This function expects to run in a separate thread.",
        "This function expects to run in a separate"
    ],
    [
        "A thread running a select_for_update that accesses rows being touched",
        "A thread running a select_for_update"
    ],
    [
        "by a similar operation on another connection blocks correctly.",
        "by a similar operation on"
    ],
    [
        "raise ValueError(\"Thread did not run and block\")",
        "raise ValueError(\"Thread did not run"
    ],
    [
        "Running a raw query which can't obtain a FOR UPDATE lock raises",
        "Running a raw query which can't obtain"
    ],
    [
        "ValueError, \"The nowait option cannot be used with skip_locked.\"",
        "ValueError, \"The nowait option cannot"
    ],
    [
        "Subqueries should respect ordering as an ORDER BY clause may be useful",
        "Subqueries should respect ordering as an ORDER BY clause may"
    ],
    [
        "Data loaded in migrations is available if",
        "Data loaded in migrations is"
    ],
    [
        "Data loaded in migrations is available during class setup if",
        "Data loaded in migrations is available during class setup"
    ],
    [
        "Data loaded in migrations is available on TestCase",
        "Data loaded in migrations is available"
    ],
    [
        "Various complex queries that have been problematic in the past.",
        "Various complex queries that have been"
    ],
    [
        "tag = models.ForeignKey(Tag, models.SET_NULL, blank=True, null=True)",
        "tag = models.ForeignKey(Tag, models.SET_NULL, blank=True,"
    ],
    [
        "creator = models.ForeignKey(Author, models.SET_NULL, to_field=\"num\", null=True)",
        "creator = models.ForeignKey(Author, models.SET_NULL,"
    ],
    [
        "return \"%d: %s\" % (self.rank, self.author.name)",
        "return \"%d: %s\" % (self.rank,"
    ],
    [
        "greatest_fan = models.ForeignKey(\"Fan\", models.SET_NULL, null=True, unique=True)",
        "greatest_fan = models.ForeignKey(\"Fan\", models.SET_NULL,"
    ],
    [
        "food = models.ForeignKey(Food, models.SET_NULL, to_field=\"name\", null=True)",
        "food = models.ForeignKey(Food, models.SET_NULL,"
    ],
    [
        "return \"%s at %s\" % (self.food, self.meal)",
        "return \"%s at %s\" % (self.food,"
    ],
    [
        "parent = models.ForeignKey(\"self\", models.SET_NULL, to_field=\"num\", null=True)",
        "parent = models.ForeignKey(\"self\", models.SET_NULL, to_field=\"num\","
    ],
    [
        "assert False, \"type checking should happen without calling model __iter__\"",
        "assert False, \"type checking should"
    ],
    [
        "return self.name + \" \" + self.special_name",
        "return self.name + \""
    ],
    [
        "return \"category item: \" + str(self.category)",
        "return \"category item:"
    ],
    [
        "annotation = models.ForeignKey(Annotation, models.CASCADE, null=True, blank=True)",
        "annotation = models.ForeignKey(Annotation,"
    ],
    [
        "note = models.ForeignKey(Note, on_delete=models.CASCADE, null=True, blank=True)",
        "note = models.ForeignKey(Note,"
    ],
    [
        "for connector in [Q.AND, Q.OR, Q.XOR]:",
        "for connector in [Q.AND,"
    ],
    [
        "msg = \"Cannot resolve keyword 'description' into field.\"",
        "msg = \"Cannot resolve"
    ],
    [
        "RawSQL expressions cause a database error because \"price\" cannot be",
        "RawSQL expressions cause a database error"
    ],
    [
        "replaced by its value. In this case, Q.check() logs a warning and",
        "replaced by its value. In this case, Q.check()"
    ],
    [
        "f\"Got a database error calling check() on {q!r}: \",",
        "f\"Got a database error calling check() on"
    ],
    [
        "from django.db import DatabaseError, NotSupportedError, connection",
        "from django.db import"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TestCase,"
    ],
    [
        "msg = \"Ordering combined queries by transforms is not implemented.\"",
        "msg = \"Ordering combined queries by transforms is not"
    ],
    [
        "msg = \"LIMIT/OFFSET not allowed in subqueries of compound statements\"",
        "msg = \"LIMIT/OFFSET not allowed in subqueries of"
    ],
    [
        "msg = \"ORDER BY not allowed in subqueries of compound statements\"",
        "msg = \"ORDER BY not allowed"
    ],
    [
        "msg = \"intersection is not supported on this database backend\"",
        "msg = \"intersection is not supported on this database"
    ],
    [
        "msg = \"ORDER BY term does not match any column in the result set\"",
        "msg = \"ORDER BY term does not match any"
    ],
    [
        "msg = \"Calling QuerySet.%s() after %s() is not supported.\"",
        "msg = \"Calling QuerySet.%s() after"
    ],
    [
        "msg = \"Calling QuerySet.get(...) with filters after %s() is not supported.\"",
        "msg = \"Calling QuerySet.get(...) with filters after %s()"
    ],
    [
        "msg = \"Cannot use %s operator with combined queryset.\"",
        "msg = \"Cannot use %s operator with combined"
    ],
    [
        "from django.db.models import BooleanField, CharField, F, Q",
        "from django.db.models import BooleanField, CharField, F,"
    ],
    [
        "from django.db.models.lookups import Exact, GreaterThan, IsNull, LessThan",
        "from django.db.models.lookups import Exact,"
    ],
    [
        "from django.db.models.sql.query import JoinPromoter, Query, get_field_names_from_opts",
        "from django.db.models.sql.query import JoinPromoter, Query,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase,"
    ],
    [
        "from .models import Author, Item, ObjectC, Ranking",
        "from .models import Author,"
    ],
    [
        "msg = \"Joined field references are not permitted in this query\"",
        "msg = \"Joined field references are not permitted in this"
    ],
    [
        "msg = \"Joined field references are not permitted in this query\"",
        "msg = \"Joined field references are not permitted in"
    ],
    [
        "msg = \"Cannot filter against a non-conditional expression.\"",
        "msg = \"Cannot filter against a"
    ],
    [
        "path, final_field, targets, names = query.names_to_path([\"value\"], opts=None)",
        "path, final_field, targets, names ="
    ],
    [
        "msg = \"Cannot resolve keyword 'nonexistent' into field.\"",
        "msg = \"Cannot resolve"
    ],
    [
        "from django.db import NotSupportedError, connection, transaction",
        "from django.db import NotSupportedError,"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TestCase,"
    ],
    [
        "+ tuple(f.lower() for f in supported_formats)",
        "+ tuple(f.lower() for"
    ],
    [
        "f\"QuerySet.explain() result is not valid XML: {e}\"",
        "f\"QuerySet.explain() result is not valid XML:"
    ],
    [
        "f\"QuerySet.explain() result is not valid JSON: {e}\"",
        "f\"QuerySet.explain() result is not valid JSON:"
    ],
    [
        "msg = \"DOES NOT EXIST is not a recognized format.\"",
        "msg = \"DOES NOT EXIST is not a"
    ],
    [
        "msg += \" Allowed formats: %s\" % \", \".join(",
        "msg += \" Allowed formats: %s\" % \","
    ],
    [
        "msg += f\" {connection.display_name} does not support any formats.\"",
        "msg += f\" {connection.display_name} does not support"
    ],
    [
        "{\"COSTS\": False, \"BUFFERS\": True, \"ANALYZE\": True},",
        "{\"COSTS\": False, \"BUFFERS\": True,"
    ],
    [
        "{\"costs\": False, \"buffers\": True, \"analyze\": True},",
        "{\"costs\": False, \"buffers\": True,"
    ],
    [
        "{\"verbose\": True, \"timing\": True, \"analyze\": True},",
        "{\"verbose\": True, \"timing\":"
    ],
    [
        "{\"verbose\": False, \"timing\": False, \"analyze\": True},",
        "{\"verbose\": False, \"timing\": False,"
    ],
    [
        "name.upper(), \"true\" if value else \"false\"",
        "name.upper(), \"true\" if"
    ],
    [
        "self.skipTest(\"This backend does not support TEXT format.\")",
        "self.skipTest(\"This backend does not support"
    ],
    [
        "msg = f\"Invalid option name: {invalid_option!r}\"",
        "msg = f\"Invalid option"
    ],
    [
        "prefix = \"ANALYZE \" if connection.mysql_is_mariadb else \"EXPLAIN ANALYZE \"",
        "prefix = \"ANALYZE \" if"
    ],
    [
        "msg = \"This backend does not support explaining query execution.\"",
        "msg = \"This backend does not support"
    ],
    [
        "from django.core.exceptions import EmptyResultSet, FieldError, FullResultSet",
        "from django.core.exceptions import EmptyResultSet, FieldError,"
    ],
    [
        "from django.db.models import CharField, Count, Exists, F, Max, OuterRef, Q",
        "from django.db.models import CharField, Count, Exists, F, Max, OuterRef,"
    ],
    [
        "from django.db.models.functions import ExtractYear, Length, LTrim",
        "from django.db.models.functions import ExtractYear, Length,"
    ],
    [
        "from django.db.models.sql.where import AND, OR, NothingNode, WhereNode",
        "from django.db.models.sql.where import AND,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "self.assertNotIn(LOUTER, [x.join_type for x in query.alias_map.values()])",
        "self.assertNotIn(LOUTER, [x.join_type for"
    ],
    [
        "This test is related to the above one, testing that there aren't",
        "This test is related to the above one, testing that there"
    ],
    [
        "get() should clear ordering for optimization purposes.",
        "get() should clear ordering for"
    ],
    [
        "self.assertNotIn(LOUTER, [x.join_type for x in query.alias_map.values()])",
        "self.assertNotIn(LOUTER, [x.join_type for x in"
    ],
    [
        "if x.join_type == LOUTER and qs.query.alias_refcount[x.table_alias]",
        "if x.join_type =="
    ],
    [
        "msg = \"Maximum recursion depth exceeded: too many subqueries.\"",
        "msg = \"Maximum recursion depth exceeded:"
    ],
    [
        "msg = \"Cannot combine queries on two different base models.\"",
        "msg = \"Cannot combine queries on"
    ],
    [
        "with self.assertRaisesMessage(FieldError, \"Cannot parse keyword query as dict\"):",
        "with self.assertRaisesMessage(FieldError, \"Cannot parse"
    ],
    [
        "[{\"misc\": \"foo\"}, {\"misc\": \"bar\"}, {\"misc\": \"foo\"}],",
        "[{\"misc\": \"foo\"}, {\"misc\":"
    ],
    [
        "msg = \"Cannot change a query once a slice has been taken.\"",
        "msg = \"Cannot change a query"
    ],
    [
        "if x.join_type == LOUTER and q.alias_refcount[x.table_alias]",
        "if x.join_type == LOUTER"
    ],
    [
        "Meta.ordering=None works the same as Meta.ordering=[]",
        "Meta.ordering=None works the"
    ],
    [
        "\"Cannot resolve keyword 'unknown_field' into field. Choices are: \"",
        "\"Cannot resolve keyword 'unknown_field' into field."
    ],
    [
        "\"annotation, category, category_id, children, id, item, \"",
        "\"annotation, category, category_id, children,"
    ],
    [
        "Valid query should be generated when fields fetched from joined tables",
        "Valid query should be generated when fields"
    ],
    [
        "include FKs whose names only differ by case.",
        "include FKs whose names only"
    ],
    [
        "msg = \"'name' isn't a DateField, TimeField, or DateTimeField.\"",
        "msg = \"'name' isn't a"
    ],
    [
        "TypeError, \"Cannot call only() after .values() or .values_list()\"",
        "TypeError, \"Cannot call only()"
    ],
    [
        "TypeError, \"Cannot call defer() after .values() or .values_list()\"",
        "TypeError, \"Cannot call defer() after .values() or"
    ],
    [
        "\"Unsaved model instance <NamedCategory: Other> cannot be used in an ORM \"",
        "\"Unsaved model instance <NamedCategory: Other> cannot be used in"
    ],
    [
        "[o.good for o in qs.extra(order_by=(\"-good\",))], [True, False, False]",
        "[o.good for o in qs.extra(order_by=(\"-good\",))], [True, False,"
    ],
    [
        "crafted_alias = \"\"\"injected_name\" from \"queries_note\"; --\"\"\"",
        "crafted_alias = \"\"\"injected_name\" from \"queries_note\";"
    ],
    [
        "\"Column aliases cannot contain whitespace characters, quotation marks, \"",
        "\"Column aliases cannot contain whitespace"
    ],
    [
        "msg = \"Model instances passed to related filters must be saved.\"",
        "msg = \"Model instances passed to related"
    ],
    [
        "query = \"SELECT * FROM queries_note WHERE note = %s\"",
        "query = \"SELECT * FROM queries_note WHERE note ="
    ],
    [
        "query = \"SELECT * FROM queries_note WHERE note = %s and misc = %s\"",
        "query = \"SELECT * FROM queries_note WHERE note = %s and misc ="
    ],
    [
        "Slice a query that has a sliced subquery",
        "Slice a query that"
    ],
    [
        "Related objects constraints can safely contain sliced subqueries.",
        "Related objects constraints can safely contain sliced"
    ],
    [
        "\"Delete queries can safely contain sliced subqueries\"",
        "\"Delete queries can safely contain sliced"
    ],
    [
        "If a queryset is already evaluated, it can still be used as a query arg.",
        "If a queryset is already evaluated, it can still"
    ],
    [
        "Cloning a queryset does not get out of hand. While complete",
        "Cloning a queryset does not get out of"
    ],
    [
        "testing is impossible, this is a sanity check against invalid use of",
        "testing is impossible, this is a sanity"
    ],
    [
        "opts_class.__deepcopy__ = lambda obj, memo: self.fail(",
        "opts_class.__deepcopy__ = lambda"
    ],
    [
        "Cloning a queryset does not get out of hand. While complete",
        "Cloning a queryset does not get"
    ],
    [
        "testing is impossible, this is a sanity check against invalid use of",
        "testing is impossible, this is a sanity check against invalid"
    ],
    [
        "opts_class.__deepcopy__ = lambda obj, memo: self.fail(",
        "opts_class.__deepcopy__ = lambda"
    ],
    [
        "\"Cannot resolve keyword %r into field. Join on 'name' not permitted.\"",
        "\"Cannot resolve keyword %r into field. Join on 'name'"
    ],
    [
        "msg = \"'flat' and 'named' can't be used together.\"",
        "msg = \"'flat' and 'named'"
    ],
    [
        "msg = \"Cannot filter a query once a slice has been taken.\"",
        "msg = \"Cannot filter a query once a slice"
    ],
    [
        "msg = \"Cannot reorder a query once a slice has been taken.\"",
        "msg = \"Cannot reorder a query"
    ],
    [
        "msg = \"Cannot combine queries once a slice has been taken.\"",
        "msg = \"Cannot combine queries once"
    ],
    [
        "\"\"\"hint: inverting your ordering might do what you need\"\"\"",
        "\"\"\"hint: inverting your ordering might do what you"
    ],
    [
        "msg = \"Negative indexing is not supported.\"",
        "msg = \"Negative indexing is not"
    ],
    [
        "\"\"\"hint: inverting your ordering might do what you need\"\"\"",
        "\"\"\"hint: inverting your ordering might do"
    ],
    [
        "msg = \"Negative indexing is not supported.\"",
        "msg = \"Negative indexing is not"
    ],
    [
        "msg = \"QuerySet indices must be integers or slices, not str.\"",
        "msg = \"QuerySet indices must be integers or slices, not"
    ],
    [
        "msg = \"Cannot change a query once a slice has been taken.\"",
        "msg = \"Cannot change a query"
    ],
    [
        "\"\"\"Tests whose execution depend on different environment conditions like",
        "\"\"\"Tests whose execution depend on"
    ],
    [
        "Python version or DB backend features\"\"\"",
        "Python version or DB backend"
    ],
    [
        "with self.assertRaisesMessage(FieldError, \"Infinite loop caused by ordering.\"):",
        "with self.assertRaisesMessage(FieldError, \"Infinite loop"
    ],
    [
        "with self.assertRaisesMessage(FieldError, \"Infinite loop caused by ordering.\"):",
        "with self.assertRaisesMessage(FieldError, \"Infinite loop caused by"
    ],
    [
        "self.assertEqual(sql.find(\"NULL\", pos + len(fragment)), pos + len(fragment))",
        "self.assertEqual(sql.find(\"NULL\", pos + len(fragment)),"
    ],
    [
        "if max_query_params is None or max_query_params >= len(numbers):",
        "if max_query_params is None or max_query_params >="
    ],
    [
        "for name, number, objecta in b_info:",
        "for name, number, objecta"
    ],
    [
        "for name, objecta, objectb in c_info:",
        "for name, objecta, objectb"
    ],
    [
        "msg = \"Model instances passed to related filters must be saved.\"",
        "msg = \"Model instances passed to related"
    ],
    [
        "those items not having any orders at all. The correct way to write",
        "those items not having any orders at all. The correct way"
    ],
    [
        "this query in SQL seems to be using two nested subqueries.",
        "this query in SQL seems to be using two"
    ],
    [
        "none_val = \"\" if connection.features.interprets_empty_strings_as_nulls else None",
        "none_val = \"\" if connection.features.interprets_empty_strings_as_nulls"
    ],
    [
        "The following case is not handled properly because",
        "The following case is not handled properly"
    ],
    [
        "SQL's COL NOT IN (list containing null) handling is too weird to",
        "SQL's COL NOT IN (list containing null) handling is"
    ],
    [
        "Filtering on non-null character fields works as expected.",
        "Filtering on non-null character fields"
    ],
    [
        "The reason for these tests is that Oracle treats '' as NULL, and this",
        "The reason for these tests is that Oracle treats '' as NULL,"
    ],
    [
        "Generating the query string doesn't alter the query's state",
        "Generating the query string doesn't alter the query's"
    ],
    [
        "self.assertEqual(w.as_sql(compiler, connection), (\"(dummy AND dummy)\", []))",
        "self.assertEqual(w.as_sql(compiler, connection), (\"(dummy AND dummy)\","
    ],
    [
        "self.assertEqual(w.as_sql(compiler, connection), (\"NOT (dummy AND dummy)\", []))",
        "self.assertEqual(w.as_sql(compiler, connection), (\"NOT (dummy AND dummy)\","
    ],
    [
        "self.assertEqual(w.as_sql(compiler, connection), (\"(dummy OR dummy)\", []))",
        "self.assertEqual(w.as_sql(compiler, connection), (\"(dummy"
    ],
    [
        "self.assertEqual(w.as_sql(compiler, connection), (\"NOT (dummy OR dummy)\", []))",
        "self.assertEqual(w.as_sql(compiler, connection), (\"NOT (dummy OR"
    ],
    [
        "msg = \"Cannot resolve keyword '*' into field. Choices are: created, id, name\"",
        "msg = \"Cannot resolve keyword '*' into"
    ],
    [
        "\"Cannot resolve keyword 'queries_author.name' into field. Choices \"",
        "\"Cannot resolve keyword 'queries_author.name' into field. Choices"
    ],
    [
        "\"are: cover, created, creator, creator_id, id, modified, name, \"",
        "\"are: cover, created, creator, creator_id, id,"
    ],
    [
        "msg = 'Cannot use QuerySet for \"Article\": Use a QuerySet for \"ExtraInfo\".'",
        "msg = 'Cannot use QuerySet for \"Article\": Use a QuerySet for"
    ],
    [
        "q_obj = Q(d__name=\"foo\") | Q(b__name=\"foo\") | Q(b__c__name=\"foo\")",
        "q_obj = Q(d__name=\"foo\") | Q(b__name=\"foo\")"
    ],
    [
        "self.assertIn(\" LEFT OUTER JOIN \", str(qs.query))",
        "self.assertIn(\" LEFT OUTER JOIN \","
    ],
    [
        "self.assertIn(\" LEFT OUTER JOIN \", str(qs.query))",
        "self.assertIn(\" LEFT OUTER"
    ],
    [
        "The queries reuse joins sensibly (for example, direct joins",
        "The queries reuse joins sensibly (for example, direct"
    ],
    [
        "When a trimmable join is specified in the query (here school__), the",
        "When a trimmable join is specified in the"
    ],
    [
        "ORM detects it and removes unnecessary joins. The set of reusable joins",
        "ORM detects it and removes unnecessary joins."
    ],
    [
        "are updated after trimming the query so that other lookups don't",
        "are updated after trimming the query so that other"
    ],
    [
        "consider that the outer query's filters are in effect for the subquery",
        "consider that the outer query's filters are in"
    ],
    [
        "Tests QuerySet ORed combining in exclude subquery case.",
        "Tests QuerySet ORed combining in"
    ],
    [
        "error = 'Cannot query \"%s\": Must be \"%s\" instance.'",
        "error = 'Cannot query \"%s\": Must be \"%s\""
    ],
    [
        "A ValueError is raised when the incorrect object type is passed to a",
        "A ValueError is raised when the incorrect object type is passed"
    ],
    [
        "A ValueError is raised when the incorrect object type is passed to a",
        "A ValueError is raised when the incorrect object"
    ],
    [
        "When passing proxy model objects, child objects, or parent objects,",
        "When passing proxy model objects,"
    ],
    [
        "ValueQuerySets are not checked for compatibility with the lookup field.",
        "ValueQuerySets are not checked for compatibility with the"
    ],
    [
        "self.assertIn(\" LEFT OUTER JOIN \", str(qs.query))",
        "self.assertIn(\" LEFT OUTER JOIN \","
    ],
    [
        "self.assertIn(\" LEFT OUTER JOIN %s\" % tblname, str(qs.query))",
        "self.assertIn(\" LEFT OUTER JOIN %s\""
    ],
    [
        "msg = \"Field 'id' expected a number but got 'abc'.\"",
        "msg = \"Field 'id' expected"
    ],
    [
        "Subquery table names should be quoted.",
        "Subquery table names should"
    ],
    [
        "Make sure __pk__in and __in work the same for related fields when",
        "Make sure __pk__in and __in work the same for related"
    ],
    [
        "ValueError, \"Chunk size must be strictly positive.\"",
        "ValueError, \"Chunk size must be strictly"
    ],
    [
        "If the database backend doesn't support chunked reads, then the",
        "If the database backend doesn't support"
    ],
    [
        "result of SQLCompiler.execute_sql() is a list.",
        "result of SQLCompiler.execute_sql() is"
    ],
    [
        "from .models import DumbCategory, NamedCategory, ProxyCategory",
        "from .models import DumbCategory, NamedCategory,"
    ],
    [
        "msg = \"QuerySet.contains() cannot be used on unsaved objects.\"",
        "msg = \"QuerySet.contains() cannot be"
    ],
    [
        "msg = \"'obj' must be a model instance.\"",
        "msg = \"'obj' must be"
    ],
    [
        "msg = \"Cannot call QuerySet.contains() after .values() or .values_list().\"",
        "msg = \"Cannot call QuerySet.contains() after .values() or"
    ],
    [
        "from django.test import TestCase, override_settings, skipUnlessDBFeature",
        "from django.test import TestCase,"
    ],
    [
        "objs = self.notes + [Note(note=\"test\", misc=\"test\")]",
        "objs = self.notes"
    ],
    [
        "msg = \"All bulk_update() objects must have a primary key set.\"",
        "msg = \"All bulk_update() objects must have a primary"
    ],
    [
        "for note, tag in zip(self.notes, self.tags):",
        "for note, tag"
    ],
    [
        "msg = \"Field names must be given to bulk_update().\"",
        "msg = \"Field names must be"
    ],
    [
        "msg = \"Batch size must be a positive integer.\"",
        "msg = \"Batch size must"
    ],
    [
        "FieldDoesNotExist, \"Note has no field named 'nonexistent'\"",
        "FieldDoesNotExist, \"Note has no field"
    ],
    [
        "pk_fields_error = \"bulk_update() cannot be used with primary key fields.\"",
        "pk_fields_error = \"bulk_update() cannot be used with"
    ],
    [
        "msg = \"bulk_update() can only be used with concrete fields.\"",
        "msg = \"bulk_update() can only"
    ],
    [
        "\"bulk_update() prohibited to prevent data loss due to unsaved \"",
        "\"bulk_update() prohibited to prevent data"
    ],
    [
        "from .models import DumbCategory, NonIntegerPKReturningModel, ReturningModel",
        "from .models import DumbCategory, NonIntegerPKReturningModel,"
    ],
    [
        "Many-to-many relationships via an intermediary table",
        "Many-to-many relationships via"
    ],
    [
        "For many-to-many relationships that need extra fields on the intermediary",
        "For many-to-many relationships that need extra fields"
    ],
    [
        "In this example, an ``Article`` can have multiple ``Reporter`` objects, and",
        "In this example, an ``Article`` can have multiple ``Reporter`` objects,"
    ],
    [
        "each ``Article``-``Reporter`` combination (a ``Writer``) has a ``position``",
        "each ``Article``-``Reporter`` combination (a ``Writer``)"
    ],
    [
        "field, which specifies the ``Reporter``'s position for the given article",
        "field, which specifies the ``Reporter``'s position"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\""
    ],
    [
        "from .models import Article, Reporter, Writer",
        "from .models import"
    ],
    [
        "This is a basic model with only two non-primary-key fields.",
        "This is a basic model with only two non-primary-key"
    ],
    [
        "article = models.ForeignKey(Article, models.SET_NULL, null=True, blank=True)",
        "article = models.ForeignKey(Article, models.SET_NULL, null=True,"
    ],
    [
        "You can initialize a model instance using positional arguments,",
        "You can initialize a model instance using"
    ],
    [
        "which should match the field order as defined in the model.",
        "which should match the field order as"
    ],
    [
        "msg = \"Article() got both positional and keyword arguments for field '%s'.\"",
        "msg = \"Article() got both positional"
    ],
    [
        "msg = \"Article() got unexpected keyword arguments: 'foo'\"",
        "msg = \"Article() got unexpected keyword"
    ],
    [
        "msg = \"Article() got unexpected keyword arguments: 'foo', 'bar'\"",
        "msg = \"Article() got unexpected keyword arguments:"
    ],
    [
        "You can leave off the value for an AutoField when creating an",
        "You can leave off the value for an AutoField"
    ],
    [
        "object, because it'll get filled in automatically when you save().",
        "object, because it'll get filled in automatically when"
    ],
    [
        "headlines = [\"Parrot programs in Python\", \"Second article\", \"Third article\"]",
        "headlines = [\"Parrot programs in Python\", \"Second article\","
    ],
    [
        "AttributeError, \"Manager isn't accessible via Article instances\"",
        "AttributeError, \"Manager isn't accessible"
    ],
    [
        "headlines = [\"An article\", \"Article One\", \"Amazing article\", \"Boring article\"]",
        "headlines = [\"An article\", \"Article One\", \"Amazing article\","
    ],
    [
        "gettext_lazy objects work when saving model instances",
        "gettext_lazy objects work when saving"
    ],
    [
        "msg = \"EmptyQuerySet can't be instantiated\"",
        "msg = \"EmptyQuerySet can't"
    ],
    [
        "msg = \"Model instances without primary key value are unhashable\"",
        "msg = \"Model instances without primary key"
    ],
    [
        "\"get() returned more than one Article -- it returned %d!\" % max_results,",
        "\"get() returned more than one Article -- it returned %d!\""
    ],
    [
        "\"get() returned more than one Article -- it returned more than %d!\"",
        "\"get() returned more than one Article -- it returned more"
    ],
    [
        "self.a.headline = \"Parrot programs in Python\"",
        "self.a.headline = \"Parrot programs in"
    ],
    [
        "ObjectDoesNotExist, \"Article matching query does not exist.\"",
        "ObjectDoesNotExist, \"Article matching query does not"
    ],
    [
        "ObjectDoesNotExist, \"Article matching query does not exist.\"",
        "ObjectDoesNotExist, \"Article matching query does not"
    ],
    [
        "Test fetching, deleting and finally saving an object - we should get",
        "Test fetching, deleting and finally saving an object - we should"
    ],
    [
        "This test ensures that the correct set of methods from `QuerySet`",
        "This test ensures that the correct set"
    ],
    [
        "It's particularly useful to prevent accidentally leaking new methods",
        "It's particularly useful to prevent accidentally"
    ],
    [
        "into `Manager`. New `QuerySet` methods that should also be copied onto",
        "into `Manager`. New `QuerySet` methods that should also be"
    ],
    [
        "`Manager` will need to be added to `ManagerTest.QUERYSET_PROXY_METHODS`.",
        "`Manager` will need to"
    ],
    [
        "DatabaseError, \"Forced update did not affect any rows.\"",
        "DatabaseError, \"Forced update did not affect"
    ],
    [
        "select_on_save works correctly if the database doesn't return correct",
        "select_on_save works correctly if the database doesn't return"
    ],
    [
        "information about matched rows from UPDATE.",
        "information about matched rows"
    ],
    [
        "DatabaseError, \"Forced update did not affect any rows.\"",
        "DatabaseError, \"Forced update did"
    ],
    [
        "\"An error occurred in the current transaction. You can't \"",
        "\"An error occurred in the current transaction. You can't"
    ],
    [
        "\"execute queries until the end of the 'atomic' block.\"",
        "\"execute queries until the end of the"
    ],
    [
        "msg = \"refresh_from_db() got an unexpected keyword argument 'unknown_kwarg'\"",
        "msg = \"refresh_from_db() got an unexpected keyword"
    ],
    [
        "'Found \"__\" in fields argument. Relations and transforms are not allowed '",
        "'Found \"__\" in fields argument. Relations and transforms are not allowed"
    ],
    [
        "any(for_update_sql in query[\"sql\"] for query in ctx.captured_queries)",
        "any(for_update_sql in query[\"sql\"] for"
    ],
    [
        "from .models.default_related_name import Author, Book, Editor",
        "from .models.default_related_name import Author, Book,"
    ],
    [
        "msg = \"Cannot resolve keyword 'book' into field.\"",
        "msg = \"Cannot resolve keyword 'book'"
    ],
    [
        "\"DEFAULT_AUTO_FIELD refers to the module \"",
        "\"DEFAULT_AUTO_FIELD refers to the module"
    ],
    [
        "\"'django.db.models.NonexistentAutoField' that could not be \"",
        "\"'django.db.models.NonexistentAutoField' that could not be"
    ],
    [
        "\"refers to the module 'django.db.models.NonexistentAutoField' \"",
        "\"refers to the module 'django.db.models.NonexistentAutoField'"
    ],
    [
        "\"Primary key 'django.db.models.TextField' referred by \"",
        "\"Primary key 'django.db.models.TextField' referred by"
    ],
    [
        "\"Primary key 'django.db.models.TextField' referred by \"",
        "\"Primary key 'django.db.models.TextField'"
    ],
    [
        "msg = \"DEFAULT_AUTO_FIELD must not be empty.\"",
        "msg = \"DEFAULT_AUTO_FIELD must not be"
    ],
    [
        "from django.test import TransactionTestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TransactionTestCase, skipIfDBFeature,"
    ],
    [
        "for model in Article, Authors, Reviewers, Scientist:",
        "for model in Article, Authors, Reviewers,"
    ],
    [
        "for model in Article, Authors, Reviewers, Scientist:",
        "for model in Article, Authors, Reviewers,"
    ],
    [
        "\"Found %d instances of '%s', expected %d\" % (real_count, needle, count),",
        "\"Found %d instances of '%s', expected %d\" % (real_count,"
    ],
    [
        "cls.director = Person.objects.create(name=\"Terry Gilliam / Terry Jones\")",
        "cls.director = Person.objects.create(name=\"Terry Gilliam"
    ],
    [
        "title=\"Monty Python and the Holy Grail\", director=cls.director",
        "title=\"Monty Python and the Holy"
    ],
    [
        "cls.director = Person.objects.create(name=\"Terry Gilliam / Terry Jones\")",
        "cls.director = Person.objects.create(name=\"Terry Gilliam /"
    ],
    [
        "title=\"Monty Python and the Holy Grail\", director=cls.director",
        "title=\"Monty Python and the Holy"
    ],
    [
        "\"\"\"Models module can be loaded from an app in an egg\"\"\"",
        "\"\"\"Models module can be loaded from an"
    ],
    [
        "Loading an app from an egg that has no models returns no models (and no",
        "Loading an app from an egg that has no models returns"
    ],
    [
        "Models module can be loaded from an app located under an egg's",
        "Models module can be loaded from an"
    ],
    [
        "Loading an app with no models from under the top-level egg package",
        "Loading an app with no models from under"
    ],
    [
        "Loading an app from an egg that has an import error in its models",
        "Loading an app from an egg that has an import error in its"
    ],
    [
        "self.assertNotIn(\"NotInstalledModel\", [m.__name__ for m in apps.get_models()])",
        "self.assertNotIn(\"NotInstalledModel\", [m.__name__ for"
    ],
    [
        "This demonstrates features of the database API.",
        "This demonstrates features of the database"
    ],
    [
        "return \"%s (%s)\" % (self.time, self.desc)",
        "return \"%s (%s)\""
    ],
    [
        "author = models.ForeignKey(Author, models.SET_NULL, blank=True, null=True)",
        "author = models.ForeignKey(Author, models.SET_NULL,"
    ],
    [
        "return None if value == \"\" else value",
        "return None if value =="
    ],
    [
        "msg = \"subclasses of YearLookup must provide a get_bound_params() method\"",
        "msg = \"subclasses of YearLookup must provide a"
    ],
    [
        "from django.db.models.functions import Abs, Cast, Length, Substr",
        "from django.db.models.functions import Abs, Cast, Length,"
    ],
    [
        "[Author() for i in range(test_range - Author.objects.count())]",
        "[Author() for i in range(test_range"
    ],
    [
        "authors = {author.pk: author for author in Author.objects.all()}",
        "authors = {author.pk: author for author"
    ],
    [
        "msg = \"in_bulk()'s field_name must be a unique field but 'author' isn't.\"",
        "msg = \"in_bulk()'s field_name must be a unique field but"
    ],
    [
        "msg = \"in_bulk()'s field_name must be a unique field but 'pub_date' isn't.\"",
        "msg = \"in_bulk()'s field_name must be a unique field but 'pub_date'"
    ],
    [
        "msg = \"in_bulk()'s field_name must be a unique field but '%s' isn't.\"",
        "msg = \"in_bulk()'s field_name must be a unique"
    ],
    [
        "msg = \"Cannot use 'limit' or 'offset' with in_bulk().\"",
        "msg = \"Cannot use 'limit' or"
    ],
    [
        "msg = \"in_bulk() cannot be used with values() or values_list().\"",
        "msg = \"in_bulk() cannot be used with"
    ],
    [
        "\"Cannot resolve keyword 'id_plus_two' into field. Choices are: \"",
        "\"Cannot resolve keyword 'id_plus_two' into field. Choices"
    ],
    [
        "\"author, author_id, headline, id, id_plus_one, pub_date, slug, tag\"",
        "\"author, author_id, headline, id,"
    ],
    [
        "\"Subqueries aren't allowed across different databases. Force the \"",
        "\"Subqueries aren't allowed across different databases. Force"
    ],
    [
        "\"inner query to be evaluated using `list(inner_query)`.\",",
        "\"inner query to be"
    ],
    [
        "\"Cannot resolve keyword 'pub_date_year' into field. Choices are: \"",
        "\"Cannot resolve keyword 'pub_date_year' into field. Choices are:"
    ],
    [
        "\"author, author_id, headline, id, pub_date, slug, tag\",",
        "\"author, author_id, headline, id, pub_date, slug,"
    ],
    [
        "\"Unsupported lookup 'starts' for CharField or join on the field \"",
        "\"Unsupported lookup 'starts' for CharField or join"
    ],
    [
        "\"not permitted, perhaps you meant startswith or istartswith?\",",
        "\"not permitted, perhaps you"
    ],
    [
        "\"Unsupported lookup 'is_null' for DateTimeField or join on the field \"",
        "\"Unsupported lookup 'is_null' for DateTimeField or join on the field"
    ],
    [
        "\"not permitted, perhaps you meant isnull?\",",
        "\"not permitted, perhaps you meant"
    ],
    [
        "\"Unsupported lookup 'gobbledygook' for DateTimeField or join on the field \"",
        "\"Unsupported lookup 'gobbledygook' for DateTimeField or join"
    ],
    [
        "\"Unsupported lookup 'gt__foo' for DateTimeField or join on the field \"",
        "\"Unsupported lookup 'gt__foo' for DateTimeField or join on"
    ],
    [
        "\"not permitted, perhaps you meant gt or gte?\",",
        "\"not permitted, perhaps you meant gt or"
    ],
    [
        "\"Unsupported lookup 'gt__' for DateTimeField or join on the field \"",
        "\"Unsupported lookup 'gt__' for DateTimeField or join"
    ],
    [
        "\"not permitted, perhaps you meant gt or gte?\",",
        "\"not permitted, perhaps you"
    ],
    [
        "\"Unsupported lookup 'gt__lt' for DateTimeField or join on the field \"",
        "\"Unsupported lookup 'gt__lt' for DateTimeField or join on the field"
    ],
    [
        "\"not permitted, perhaps you meant gt or gte?\",",
        "\"not permitted, perhaps you meant"
    ],
    [
        "\"Unsupported lookup 'gt__lt__foo' for DateTimeField or join\"",
        "\"Unsupported lookup 'gt__lt__foo' for"
    ],
    [
        "\" on the field not permitted, perhaps you meant gt or gte?\",",
        "\" on the field not permitted,"
    ],
    [
        "\"Unsupported lookup 'lengtp' for SlugField or join on the field not \"",
        "\"Unsupported lookup 'lengtp' for SlugField or join"
    ],
    [
        "\"Unsupported lookup 'editor__name' for ForeignKey or join on the field not \"",
        "\"Unsupported lookup 'editor__name' for ForeignKey or join on the field"
    ],
    [
        "\"Unsupported lookup 'foo' for ForeignKey or join on the field not \"",
        "\"Unsupported lookup 'foo' for ForeignKey or join on the"
    ],
    [
        "\"Unsupported lookup 'title' for ManyToOneRel or join on the field not \"",
        "\"Unsupported lookup 'title' for ManyToOneRel or join on the field not"
    ],
    [
        "\"Unsupported lookup 'abspl' for ManyToOneRel or join on the field not \"",
        "\"Unsupported lookup 'abspl' for ManyToOneRel or"
    ],
    [
        "A regex lookup does not fail on null/None values",
        "A regex lookup does not fail"
    ],
    [
        "A regex lookup does not fail on non-string fields",
        "A regex lookup does not fail on non-string"
    ],
    [
        "A regex lookup does not trip on non-ASCII characters.",
        "A regex lookup does not trip on non-ASCII"
    ],
    [
        "A lookup query containing non-fields raises the proper exception.",
        "A lookup query containing non-fields raises the proper"
    ],
    [
        "\"Unsupported lookup 'blahblah' for CharField or join on the field not \"",
        "\"Unsupported lookup 'blahblah' for CharField or join on"
    ],
    [
        "\"Unsupported lookup 'blahblah__exact' for CharField or join \"",
        "\"Unsupported lookup 'blahblah__exact' for CharField or"
    ],
    [
        "\"Cannot resolve keyword 'blahblah' into field. Choices are: \"",
        "\"Cannot resolve keyword 'blahblah' into field. Choices are:"
    ],
    [
        "\"author, author_id, headline, id, pub_date, slug, tag\"",
        "\"author, author_id, headline, id,"
    ],
    [
        "Genuine field names don't collide with built-in lookup types",
        "Genuine field names don't collide"
    ],
    [
        "\"The QuerySet value for an exact lookup must be limited to one \"",
        "\"The QuerySet value for an exact lookup must be limited to"
    ],
    [
        "__exact=value is transformed to __isnull=True if Field.get_prep_value()",
        "__exact=value is transformed to"
    ],
    [
        "\"\"\"Lookup.can_use_none_as_rhs=True allows None as a lookup value.\"\"\"",
        "\"\"\"Lookup.can_use_none_as_rhs=True allows None as a lookup"
    ],
    [
        "msg = \"The QuerySet value for an isnull lookup must be True or False.\"",
        "msg = \"The QuerySet value for an isnull lookup must"
    ],
    [
        "This demonstrates the reverse lookup features of the database API.",
        "This demonstrates the reverse lookup features"
    ],
    [
        "from .models import Choice, Poll, User",
        "from .models import"
    ],
    [
        "poll=first_poll, related_poll=second_poll, name=\"This is the answer.\"",
        "poll=first_poll, related_poll=second_poll, name=\"This is"
    ],
    [
        "If a related_name is given you can't use the field name instead",
        "If a related_name is given you can't"
    ],
    [
        "\"Cannot resolve keyword 'choice' into field. Choices are: \"",
        "\"Cannot resolve keyword 'choice' into"
    ],
    [
        "\"creator, creator_id, id, poll_choice, question, related_choice\"",
        "\"creator, creator_id, id,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "Place = models.IntegerChoices(\"Place\", \"FIRST SECOND THIRD\")",
        "Place = models.IntegerChoices(\"Place\","
    ],
    [
        "self.assertEqual(YearInSchool.values, [\"FR\", \"SO\", \"JR\", \"SR\", \"GR\"])",
        "self.assertEqual(YearInSchool.values, [\"FR\", \"SO\","
    ],
    [
        "Medal = models.TextChoices(\"Medal\", \"GOLD SILVER BRONZE\")",
        "Medal = models.TextChoices(\"Medal\", \"GOLD SILVER"
    ],
    [
        "msg = \"'str' object cannot be interpreted as an integer\"",
        "msg = \"'str' object cannot be"
    ],
    [
        "msg = \"duplicate values found in <enum 'Fruit'>: PINEAPPLE -> APPLE\"",
        "msg = \"duplicate values found in <enum"
    ],
    [
        "for test in [Gender, Suit, YearInSchool, Vehicle]:",
        "for test in [Gender, Suit, YearInSchool,"
    ],
    [
        "template = Template(\"{{ Suit.DIAMOND.label }}|{{ Suit.DIAMOND.value }}\")",
        "template = Template(\"{{ Suit.DIAMOND.label }}|{{ Suit.DIAMOND.value"
    ],
    [
        "Stationery = models.TextChoices(\"Stationery\", \"label stamp sticker\")",
        "Stationery = models.TextChoices(\"Stationery\", \"label"
    ],
    [
        "msg = \"type 'bool' is not an acceptable base type\"",
        "msg = \"type 'bool' is"
    ],
    [
        "from django.core.exceptions import DisallowedHost, PermissionDenied, SuspiciousOperation",
        "from django.core.exceptions import DisallowedHost, PermissionDenied,"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, override_settings",
        "from django.test import"
    ],
    [
        "The 'django' base logger only output anything when DEBUG=True.",
        "The 'django' base logger only"
    ],
    [
        "self.assertEqual(self.logger_output.getvalue(), \"Hey, this is an error.\\n\")",
        "self.assertEqual(self.logger_output.getvalue(), \"Hey, this"
    ],
    [
        "self, url, level, msg, status_code, logger=\"django.request\", exc_class=None",
        "self, url, level, msg,"
    ],
    [
        "\"Wrong number of calls for logger %r in %r level.\" % (logger, level),",
        "\"Wrong number of calls for logger %r in %r level.\" % (logger,"
    ],
    [
        "msg=\"Bad request (Unable to parse request body): /multi_part_parser_error/\",",
        "msg=\"Bad request (Unable to parse request"
    ],
    [
        "h for h in logger.handlers if h.__class__.__name__ == \"AdminEmailHandler\"",
        "h for h in logger.handlers if"
    ],
    [
        "User-supplied arguments and the EMAIL_SUBJECT_PREFIX setting are used",
        "User-supplied arguments and the EMAIL_SUBJECT_PREFIX setting are"
    ],
    [
        "message = \"Custom message that says '%s' and '%s'\"",
        "message = \"Custom message that says '%s' and"
    ],
    [
        "\"Custom message that says 'ping' and 'pong'\",",
        "\"Custom message that says 'ping'"
    ],
    [
        "The subject is also handled if being passed a request object.",
        "The subject is also handled if being passed a"
    ],
    [
        "message = \"Custom message that says '%s' and '%s'\"",
        "message = \"Custom message that says '%s' and"
    ],
    [
        "\"Custom message that says 'ping' and 'pong'\",",
        "\"Custom message that says 'ping'"
    ],
    [
        "Newlines in email reports' subjects are escaped to prevent",
        "Newlines in email reports' subjects are escaped to"
    ],
    [
        "message = \"Message \\r\\n with newlines\"",
        "message = \"Message"
    ],
    [
        "expected_subject = \"ERROR: Message \\\\r\\\\n with newlines\"",
        "expected_subject = \"ERROR: Message \\\\r\\\\n with"
    ],
    [
        "message = \"All work and no play makes Jack a dull boy\"",
        "message = \"All work and no play makes"
    ],
    [
        "\"name\", logging.ERROR, \"function\", \"lno\", \"message\", None, None",
        "\"name\", logging.ERROR, \"function\", \"lno\", \"message\","
    ],
    [
        "self.assertEqual(msg.subject, \"[Django] ERROR (EXTERNAL IP): message\")",
        "self.assertEqual(msg.subject, \"[Django] ERROR (EXTERNAL IP):"
    ],
    [
        "self.assertIn(\"Report at %s\" % url_path, msg.body)",
        "self.assertIn(\"Report at %s\""
    ],
    [
        "def send_mail(self, subject, message, *args, **kwargs):",
        "def send_mail(self, subject, message, *args,"
    ],
    [
        "\"name\", logging.ERROR, \"function\", \"lno\", \"message\", None, None",
        "\"name\", logging.ERROR, \"function\", \"lno\","
    ],
    [
        "\"name\", logging.ERROR, \"function\", \"lno\", \"message\", None, None",
        "\"name\", logging.ERROR, \"function\", \"lno\", \"message\","
    ],
    [
        "Accessing settings in a custom logging handler does not trigger",
        "Accessing settings in a custom logging handler does"
    ],
    [
        "Calling django.setup() initializes the logging configuration.",
        "Calling django.setup() initializes the"
    ],
    [
        "Using a logging defaults are still applied when using a custom",
        "Using a logging defaults are still applied when"
    ],
    [
        "record = logging.makeLogRecord({\"msg\": log_msg, \"status_code\": status_code})",
        "record = logging.makeLogRecord({\"msg\":"
    ],
    [
        "\"[%s] %s\\n\" % (server_time, log_msg), logger_output.getvalue()",
        "\"[%s] %s\\n\" % (server_time,"
    ],
    [
        "from django.core.exceptions import DisallowedHost, PermissionDenied, SuspiciousOperation",
        "from django.core.exceptions import"
    ],
    [
        "from django.core.checks import Warning as DjangoWarning",
        "from django.core.checks import"
    ],
    [
        "from django.test.utils import isolate_apps, modify_settings, override_settings",
        "from django.test.utils import isolate_apps,"
    ],
    [
        "\"which is either not installed, or is abstract.\",",
        "\"which is either not installed, or is"
    ],
    [
        "\"which is either not installed, or is abstract.\",",
        "\"which is either not installed, or"
    ],
    [
        "Model, null=True, validators=[lambda x: x], db_comment=\"Column comment\"",
        "Model, null=True, validators=[lambda x: x], db_comment=\"Column"
    ],
    [
        "\"null has no effect on ManyToManyField.\",",
        "\"null has no effect on"
    ],
    [
        "\"db_comment has no effect on ManyToManyField.\",",
        "\"db_comment has no effect on"
    ],
    [
        "\"related_name has no effect on ManyToManyField with \"",
        "\"related_name has no effect on"
    ],
    [
        "'a symmetrical relationship, e.g. to \"self\".',",
        "'a symmetrical relationship, e.g."
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an intermediate"
    ],
    [
        "\"'invalid_models_tests.Group.field', but it has more than one \"",
        "\"'invalid_models_tests.Group.field', but it has more than one"
    ],
    [
        "\"foreign key from 'Group', which is ambiguous. You must \"",
        "\"foreign key from 'Group', which"
    ],
    [
        "\"specify which foreign key Django should use via the \"",
        "\"specify which foreign key Django should use"
    ],
    [
        "\"If you want to create a recursive relationship, use \"",
        "\"If you want to create a"
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an intermediate model by"
    ],
    [
        "\"'invalid_models_tests.Group.field', but it has more than one \"",
        "\"'invalid_models_tests.Group.field', but it has more"
    ],
    [
        "\"foreign key to 'Person', which is ambiguous. You must specify \"",
        "\"foreign key to 'Person', which is"
    ],
    [
        "\"which foreign key Django should use via the through_fields \"",
        "\"which foreign key Django should"
    ],
    [
        "\"If you want to create a recursive relationship, use \"",
        "\"If you want to create a recursive relationship, use"
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an intermediate model"
    ],
    [
        "\"'invalid_models_tests.Group.members', but it does not \"",
        "\"'invalid_models_tests.Group.members', but it does not"
    ],
    [
        "\"have a foreign key to 'Group' or 'Person'.\",",
        "\"have a foreign key"
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an intermediate"
    ],
    [
        "\"'invalid_models_tests.Group.members', but it does not have \"",
        "\"'invalid_models_tests.Group.members', but it does not have"
    ],
    [
        "\"a foreign key to 'Group' or 'Person'.\",",
        "\"a foreign key to 'Group'"
    ],
    [
        "\"Field specifies a many-to-many relation through model \"",
        "\"Field specifies a many-to-many"
    ],
    [
        "\"Field specifies a many-to-many relation through model \"",
        "\"Field specifies a many-to-many"
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an intermediate"
    ],
    [
        "\"'invalid_models_tests.Person.friends', but it has more than two \"",
        "\"'invalid_models_tests.Person.friends', but it has"
    ],
    [
        "\"foreign keys to 'Person', which is ambiguous. You must specify \"",
        "\"foreign keys to 'Person', which is"
    ],
    [
        "\"which two foreign keys Django should use via the through_fields \"",
        "\"which two foreign keys Django should use via the through_fields"
    ],
    [
        "\"Use through_fields to specify which two foreign keys Django \"",
        "\"Use through_fields to specify which two"
    ],
    [
        "\"Field defines a relation with model 'AbstractModel', \"",
        "\"Field defines a relation with model"
    ],
    [
        "\"which is either not installed, or is abstract.\",",
        "\"which is either not"
    ],
    [
        "\"Field defines a relation with model 'AbstractModel', \"",
        "\"Field defines a relation with"
    ],
    [
        "\"which is either not installed, or is abstract.\",",
        "\"which is either not installed, or"
    ],
    [
        "\"Field defines a relation to the CompositePrimaryKey of model \"",
        "\"Field defines a relation to the CompositePrimaryKey of"
    ],
    [
        "\"Field defines a relation to the CompositePrimaryKey of model \"",
        "\"Field defines a relation to the CompositePrimaryKey of model"
    ],
    [
        "\"Field defines a relation to the CompositePrimaryKey of model \"",
        "\"Field defines a relation to"
    ],
    [
        "\"Field defines a relation to the CompositePrimaryKey of model \"",
        "\"Field defines a relation to"
    ],
    [
        "\"'Target.bad' must be unique because it is referenced by a foreign \"",
        "\"'Target.bad' must be unique because it is referenced"
    ],
    [
        "\"Add unique=True to this field or add a UniqueConstraint \"",
        "\"Add unique=True to this field"
    ],
    [
        "\"(without condition) in the model Meta.constraints.\"",
        "\"(without condition) in the model"
    ],
    [
        "\"'Target.bad' must be unique because it is referenced by a foreign \"",
        "\"'Target.bad' must be unique because it is referenced"
    ],
    [
        "\"Add unique=True to this field or add a UniqueConstraint \"",
        "\"Add unique=True to this field"
    ],
    [
        "\"(without condition) in the model Meta.constraints.\"",
        "\"(without condition) in"
    ],
    [
        "\"'Target.source' must be unique because it is referenced by a \"",
        "\"'Target.source' must be unique because it is referenced by a"
    ],
    [
        "\"Add unique=True to this field or add a UniqueConstraint \"",
        "\"Add unique=True to this field or add a UniqueConstraint"
    ],
    [
        "\"(without condition) in the model Meta.constraints.\"",
        "\"(without condition) in the model"
    ],
    [
        "\"No subset of the fields 'country_id', 'city_id' on model 'Person' \"",
        "\"No subset of the fields 'country_id', 'city_id'"
    ],
    [
        "\"Mark a single field as unique=True or add a set of \"",
        "\"Mark a single field as unique=True or"
    ],
    [
        "\"fields to a unique constraint (via unique_together or a \"",
        "\"fields to a unique constraint (via unique_together or"
    ],
    [
        "\"UniqueConstraint (without condition) in the model \"",
        "\"UniqueConstraint (without condition) in the model"
    ],
    [
        "\"No subset of the fields 'country_id', 'city_id' on model \"",
        "\"No subset of the fields 'country_id', 'city_id'"
    ],
    [
        "\"Mark a single field as unique=True or add a set of \"",
        "\"Mark a single field as unique=True or"
    ],
    [
        "\"fields to a unique constraint (via unique_together or a \"",
        "\"fields to a unique constraint (via"
    ],
    [
        "\"UniqueConstraint (without condition) in the model \"",
        "\"UniqueConstraint (without condition) in the model"
    ],
    [
        "\"Field specifies on_delete=SET_NULL, but cannot be null.\",",
        "\"Field specifies on_delete=SET_NULL, but cannot"
    ],
    [
        "\"Set null=True argument on the field, or change the on_delete \"",
        "\"Set null=True argument on the field, or change"
    ],
    [
        "\"Field specifies on_delete=SET_DEFAULT, but has no default value.\",",
        "\"Field specifies on_delete=SET_DEFAULT, but has"
    ],
    [
        "hint=\"Set a default value, or change the on_delete rule.\",",
        "hint=\"Set a default value, or"
    ],
    [
        "\"Primary keys must not have null=True.\",",
        "\"Primary keys must"
    ],
    [
        "\"Set null=False on the field, or remove primary_key=True \"",
        "\"Set null=False on the field, or"
    ],
    [
        "\"Field defines a relation with the model \"",
        "\"Field defines a relation with"
    ],
    [
        "\"'invalid_models_tests.SwappedModel', which has been swapped out.\"",
        "\"'invalid_models_tests.SwappedModel', which has been"
    ],
    [
        "hint=\"Update the relation to point at 'settings.TEST_SWAPPED_MODEL'.\",",
        "hint=\"Update the relation to"
    ],
    [
        "\"The name '%s' is invalid related_name for field Child%s.parent\"",
        "\"The name '%s' is invalid related_name for"
    ],
    [
        "\"Related name must be a valid Python identifier or end \"",
        "\"Related name must be a valid Python identifier or end"
    ],
    [
        "\"The to_field 'a' doesn't exist on the related model \"",
        "\"The to_field 'a' doesn't exist on the related"
    ],
    [
        "\"The to_field 'b' doesn't exist on the related model \"",
        "\"The to_field 'b' doesn't exist on"
    ],
    [
        "\"Field defines a relation with model \"",
        "\"Field defines a relation with model"
    ],
    [
        "\"'invalid_models_tests.Parent', which is either not installed, or \"",
        "\"'invalid_models_tests.Parent', which is either not installed,"
    ],
    [
        "\"Field defines a relation to the CompositePrimaryKey of model \"",
        "\"Field defines a relation to the CompositePrimaryKey of"
    ],
    [
        "\"Field defines a relation to the CompositePrimaryKey of model \"",
        "\"Field defines a relation to the CompositePrimaryKey"
    ],
    [
        "\"Reverse query name 'contains__double' must not contain '__'.\",",
        "\"Reverse query name 'contains__double' must not contain"
    ],
    [
        "\"Add or change a related_name or related_query_name \"",
        "\"Add or change a"
    ],
    [
        "\"Reverse query name 'ends_underscore_' must not end with an \"",
        "\"Reverse query name 'ends_underscore_' must"
    ],
    [
        "\"Add or change a related_name or related_query_name \"",
        "\"Add or change a related_name or related_query_name"
    ],
    [
        "\"'invalid_models_tests.Model.rel' clashes with field name \"",
        "\"'invalid_models_tests.Model.rel' clashes with field"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the definition"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the definition"
    ],
    [
        "\"Reverse query name for 'invalid_models_tests.Model.rel' \"",
        "\"Reverse query name for"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to"
    ],
    [
        "\"'invalid_models_tests.Model.rel' clashes with field name \"",
        "\"'invalid_models_tests.Model.rel' clashes with field"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"Reverse query name for 'invalid_models_tests.Model.rel' \"",
        "\"Reverse query name"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the definition for"
    ],
    [
        "\"Reverse query name for 'invalid_models_tests.Model.rel' \"",
        "\"Reverse query name for"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"Reverse query name for 'invalid_models_tests.Model.model' \"",
        "\"Reverse query name"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the definition"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to"
    ],
    [
        "\"Reverse query name for 'invalid_models_tests.Model.model' \"",
        "\"Reverse query name for"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"'invalid_models_tests.Model.foreign' clashes with field name \"",
        "\"'invalid_models_tests.Model.foreign' clashes with field name"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"Reverse query name for 'invalid_models_tests.Model.foreign' \"",
        "\"Reverse query name"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the definition"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the definition"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument to the"
    ],
    [
        "\"clashes with reverse query name for \"",
        "\"clashes with reverse query"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument to the"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument"
    ],
    [
        "\"clashes with reverse query name for \"",
        "\"clashes with reverse query name for"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to the"
    ],
    [
        "\"add/change a related_name argument to the definition for \"",
        "\"add/change a related_name argument to"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument to"
    ],
    [
        "\"clashes with reverse query name for \"",
        "\"clashes with reverse query name"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument to"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument"
    ],
    [
        "\"clashes with reverse query name for \"",
        "\"clashes with reverse query name for"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name argument to"
    ],
    [
        "\"Reverse %s%s for 'invalid_models_tests.Child.%s' clashes with \"",
        "\"Reverse %s%s for 'invalid_models_tests.Child.%s'"
    ],
    [
        "% (attr, rel_name, field_name, attr, clash_name),",
        "% (attr, rel_name, field_name,"
    ],
    [
        "\"Add or change a related_name argument to the definition \"",
        "\"Add or change a related_name"
    ],
    [
        "for error_id, attr, rel_name, field_name, clash_name in errors",
        "for error_id, attr, rel_name, field_name, clash_name in"
    ],
    [
        "only if an intermediary table is specified.",
        "only if an intermediary table is"
    ],
    [
        "ValueError, \"Cannot specify through_fields without a through model\"",
        "ValueError, \"Cannot specify through_fields without a through"
    ],
    [
        "Mixing up the order of link fields to ManyToManyField.through_fields",
        "Mixing up the order of"
    ],
    [
        "\"'Invitation.invitee' is not a foreign key to 'Event'.\",",
        "\"'Invitation.invitee' is not a foreign key to"
    ],
    [
        "\"Did you mean one of the following foreign keys to 'Event': \"",
        "\"Did you mean one of the following foreign keys to"
    ],
    [
        "\"'Invitation.event' is not a foreign key to 'Fan'.\",",
        "\"'Invitation.event' is not a foreign key"
    ],
    [
        "\"Did you mean one of the following foreign keys to 'Fan': \"",
        "\"Did you mean one of the"
    ],
    [
        "Providing invalid field names to ManyToManyField.through_fields",
        "Providing invalid field names"
    ],
    [
        "\"The intermediary model 'invalid_models_tests.Invitation' has no \"",
        "\"The intermediary model 'invalid_models_tests.Invitation' has no"
    ],
    [
        "\"Did you mean one of the following foreign keys to 'Event': \"",
        "\"Did you mean one of the following foreign keys to 'Event':"
    ],
    [
        "\"The intermediary model 'invalid_models_tests.Invitation' has no \"",
        "\"The intermediary model 'invalid_models_tests.Invitation' has"
    ],
    [
        "\"Did you mean one of the following foreign keys to 'Fan': \"",
        "\"Did you mean one of the following foreign"
    ],
    [
        "If ``through_fields`` kwarg is given, it must specify both",
        "If ``through_fields`` kwarg is given, it must"
    ],
    [
        "link fields of the intermediary table.",
        "link fields of the"
    ],
    [
        "\"Field specifies 'through_fields' but does not provide the names \"",
        "\"Field specifies 'through_fields' but does"
    ],
    [
        "\"of the two link fields that should be used for the relation \"",
        "\"of the two link fields that should be used"
    ],
    [
        "\"Make sure you specify 'through_fields' as \"",
        "\"Make sure you specify"
    ],
    [
        "\"No subset of the fields 'a', 'b' on model 'Parent' is unique.\",",
        "\"No subset of the fields 'a', 'b'"
    ],
    [
        "\"Mark a single field as unique=True or add a set of \"",
        "\"Mark a single field as unique=True or"
    ],
    [
        "\"fields to a unique constraint (via unique_together or a \"",
        "\"fields to a unique constraint (via unique_together or a"
    ],
    [
        "\"UniqueConstraint (without condition) in the model \"",
        "\"UniqueConstraint (without condition) in the model"
    ],
    [
        "\"No subset of the fields 'a', 'b', 'd' on model 'Parent' is \"",
        "\"No subset of the fields 'a', 'b', 'd' on model 'Parent'"
    ],
    [
        "\"Mark a single field as unique=True or add a set of \"",
        "\"Mark a single field as unique=True or add"
    ],
    [
        "\"fields to a unique constraint (via unique_together or a \"",
        "\"fields to a unique constraint (via"
    ],
    [
        "\"UniqueConstraint (without condition) in the model \"",
        "\"UniqueConstraint (without condition) in"
    ],
    [
        "\"\"\"Test if backend specific checks are performed.\"\"\"",
        "\"\"\"Test if backend specific checks"
    ],
    [
        "\"IPAddressField has been removed except for support in \"",
        "\"IPAddressField has been removed except for"
    ],
    [
        "\"CommaSeparatedIntegerField is removed except for support in \"",
        "\"CommaSeparatedIntegerField is removed except"
    ],
    [
        "\"NullBooleanField is removed except for support in historical \"",
        "\"NullBooleanField is removed except for support"
    ],
    [
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific SQL\")",
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL"
    ],
    [
        "@skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific SQL\")",
        "@skipUnless(connection.vendor == \"postgresql\","
    ],
    [
        "\"django.contrib.postgres.fields.CICharField is removed except for \"",
        "\"django.contrib.postgres.fields.CICharField is removed except"
    ],
    [
        "'Use CharField(db_collation=\"…\") with a case-insensitive '",
        "'Use CharField(db_collation=\"…\") with a"
    ],
    [
        "\"django.contrib.postgres.fields.CIEmailField is removed except for \"",
        "\"django.contrib.postgres.fields.CIEmailField is removed"
    ],
    [
        "'Use EmailField(db_collation=\"…\") with a case-insensitive '",
        "'Use EmailField(db_collation=\"…\") with"
    ],
    [
        "\"django.contrib.postgres.fields.CITextField is removed except for \"",
        "\"django.contrib.postgres.fields.CITextField is removed except"
    ],
    [
        "'Use TextField(db_collation=\"…\") with a case-insensitive '",
        "'Use TextField(db_collation=\"…\") with"
    ],
    [
        "\"Base field for array has errors:\\n\"",
        "\"Base field for array has"
    ],
    [
        "\"    django.contrib.postgres.fields.CITextField is removed except \"",
        "\" django.contrib.postgres.fields.CITextField is removed"
    ],
    [
        "from django.core.checks import Warning as DjangoWarning",
        "from django.core.checks import"
    ],
    [
        "from django.db.models.functions import Coalesce, LPad, Pi",
        "from django.db.models.functions import"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"'max_length' is ignored when used with %s.\"",
        "\"'max_length' is ignored when used with"
    ],
    [
        "\"BinaryField's default cannot be a string. Use bytes content \"",
        "\"BinaryField's default cannot be a string. Use"
    ],
    [
        "\"CharFields must define a 'max_length' attribute.\",",
        "\"CharFields must define a"
    ],
    [
        "\"'max_length' must be a positive integer.\",",
        "\"'max_length' must be a positive"
    ],
    [
        "\"'max_length' must be a positive integer.\",",
        "\"'max_length' must be a positive"
    ],
    [
        "\"'max_length' must be a positive integer.\",",
        "\"'max_length' must be a"
    ],
    [
        "\"'max_length' must be a positive integer.\",",
        "\"'max_length' must be"
    ],
    [
        "\"'choices' must be a mapping (e.g. a dictionary) or an iterable \"",
        "\"'choices' must be a mapping (e.g. a dictionary) or an"
    ],
    [
        "\"\"\"Two letters isn't a valid choice pair.\"\"\"",
        "\"\"\"Two letters isn't a valid"
    ],
    [
        "\"'choices' must be a mapping of actual values to human readable \"",
        "\"'choices' must be a mapping of actual values to human"
    ],
    [
        "\"names or an iterable containing (actual value, human readable \"",
        "\"names or an iterable containing (actual value, human"
    ],
    [
        "\"'choices' must be a mapping of actual values to human \"",
        "\"'choices' must be a mapping of actual values to"
    ],
    [
        "\"readable names or an iterable containing (actual value, \"",
        "\"readable names or an iterable containing (actual value,"
    ],
    [
        "\"'choices' must be a mapping of actual values to human readable \"",
        "\"'choices' must be a mapping of actual values to human readable"
    ],
    [
        "\"names or an iterable containing (actual value, human readable \"",
        "\"names or an iterable containing (actual value, human"
    ],
    [
        "\"'choices' must be a mapping of actual values to human readable \"",
        "\"'choices' must be a mapping of actual values to human readable"
    ],
    [
        "\"names or an iterable containing (actual value, human readable \"",
        "\"names or an iterable containing (actual"
    ],
    [
        "choices=[(\"ABC\", \"Value Too Long!\"), (\"OK\", \"Good\")],",
        "choices=[(\"ABC\", \"Value Too Long!\"),"
    ],
    [
        "\"'max_length' is too small to fit the longest value \"",
        "\"'max_length' is too small to"
    ],
    [
        "\"in 'choices' (%d characters).\" % choice_max_length,",
        "\"in 'choices' (%d characters).\" %"
    ],
    [
        "\"'db_index' must be None, True or False.\",",
        "\"'db_index' must be None, True"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"mysql\", \"Test valid only for MySQL\")",
        "@unittest.skipUnless(connection.vendor == \"mysql\", \"Test valid only"
    ],
    [
        "\"%s may not allow unique CharFields to have a max_length > \"",
        "\"%s may not allow unique CharFields to"
    ],
    [
        "\"%s does not support a database collation on CharFields.\"",
        "\"%s does not support a"
    ],
    [
        "\"The options auto_now, auto_now_add, and default \"",
        "\"The options auto_now, auto_now_add,"
    ],
    [
        "\"are mutually exclusive. Only one of these options \"",
        "\"are mutually exclusive. Only one of these options"
    ],
    [
        "hint=\"It seems you set a fixed date / time / datetime \"",
        "hint=\"It seems you set a fixed date / time /"
    ],
    [
        "\"value as default for this field. This may not be \"",
        "\"value as default for this field. This may"
    ],
    [
        "\"what you want. If you want to have the current date \"",
        "\"what you want. If you want to have"
    ],
    [
        "hint=\"It seems you set a fixed date / time / datetime \"",
        "hint=\"It seems you set a fixed date"
    ],
    [
        "\"value as default for this field. This may not be \"",
        "\"value as default for this field. This"
    ],
    [
        "\"what you want. If you want to have the current date \"",
        "\"what you want. If you want to have the"
    ],
    [
        "hint=\"It seems you set a fixed date / time / datetime \"",
        "hint=\"It seems you set a fixed date /"
    ],
    [
        "\"value as default for this field. This may not be \"",
        "\"value as default for this field. This"
    ],
    [
        "\"what you want. If you want to have the current date \"",
        "\"what you want. If you want to have the"
    ],
    [
        "hint=\"It seems you set a fixed date / time / datetime \"",
        "hint=\"It seems you set a fixed date / time /"
    ],
    [
        "\"value as default for this field. This may not be \"",
        "\"value as default for this field. This"
    ],
    [
        "\"what you want. If you want to have the current date \"",
        "\"what you want. If you want"
    ],
    [
        "\"DecimalFields must define a 'decimal_places' attribute.\",",
        "\"DecimalFields must define a"
    ],
    [
        "\"DecimalFields must define a 'max_digits' attribute.\",",
        "\"DecimalFields must define"
    ],
    [
        "\"'decimal_places' must be a non-negative integer.\",",
        "\"'decimal_places' must be a"
    ],
    [
        "\"'max_digits' must be a positive integer.\",",
        "\"'max_digits' must be"
    ],
    [
        "\"'decimal_places' must be a non-negative integer.\",",
        "\"'decimal_places' must be a non-negative"
    ],
    [
        "\"'max_digits' must be a positive integer.\",",
        "\"'max_digits' must be a positive"
    ],
    [
        "\"'max_digits' must be greater or equal to 'decimal_places'.\",",
        "\"'max_digits' must be greater or"
    ],
    [
        "\"'primary_key' is not a valid argument for a FileField.\",",
        "\"'primary_key' is not a valid argument for a"
    ],
    [
        "\"FileField's 'upload_to' argument must be a relative path, not \"",
        "\"FileField's 'upload_to' argument must be a relative path, not"
    ],
    [
        "\"FilePathFields must have either 'allow_files' or 'allow_folders' \"",
        "\"FilePathFields must have either 'allow_files' or"
    ],
    [
        "\"GenericIPAddressFields cannot have blank=True if null=False, \"",
        "\"GenericIPAddressFields cannot have blank=True if null=False,"
    ],
    [
        "\"as blank values are stored as nulls.\"",
        "\"as blank values are stored"
    ],
    [
        "\"Cannot use ImageField because Pillow is not installed.\",",
        "\"Cannot use ImageField because"
    ],
    [
        "'or run command \"python -m pip install Pillow\".'",
        "'or run command \"python"
    ],
    [
        "\"'max_length' is ignored when used with %s.\"",
        "\"'max_length' is ignored when"
    ],
    [
        "\"'choices' must be a mapping (e.g. a dictionary) or an iterable \"",
        "\"'choices' must be a mapping (e.g. a dictionary) or"
    ],
    [
        "\"\"\"An integer isn't a valid choice pair.\"\"\"",
        "\"\"\"An integer isn't a valid choice"
    ],
    [
        "\"'choices' must be a mapping of actual values to human readable \"",
        "\"'choices' must be a mapping of actual values"
    ],
    [
        "\"names or an iterable containing (actual value, human readable \"",
        "\"names or an iterable containing (actual value, human readable"
    ],
    [
        "names = [\"field_dt\", \"field_t\", \"field_tz\", \"field_now\"]",
        "names = [\"field_dt\","
    ],
    [
        "fields = [Model._meta.get_field(name) for name in names]",
        "fields = [Model._meta.get_field(name) for name in"
    ],
    [
        "hint=\"It seems you set a fixed date / time / datetime \"",
        "hint=\"It seems you set a fixed"
    ],
    [
        "\"value as default for this field. This may not be \"",
        "\"value as default for this field. This may not"
    ],
    [
        "\"what you want. If you want to have the current date \"",
        "\"what you want. If you want to have the current date"
    ],
    [
        "hint=\"It seems you set a fixed date / time / datetime \"",
        "hint=\"It seems you set a fixed date"
    ],
    [
        "\"value as default for this field. This may not be \"",
        "\"value as default for this field. This"
    ],
    [
        "\"what you want. If you want to have the current date \"",
        "\"what you want. If you want to have the current date"
    ],
    [
        "\"It seems you set a fixed date / time / datetime value as \"",
        "\"It seems you set a fixed date /"
    ],
    [
        "\"default for this field. This may not be what you want. \"",
        "\"default for this field. This may not be what you"
    ],
    [
        "\"If you want to have the current date as default, use \"",
        "\"If you want to have the current date"
    ],
    [
        "\"%s does not support a database index on %s columns.\"",
        "\"%s does not support a database index on"
    ],
    [
        "\"An index won't be created. Silence this warning if you \"",
        "\"An index won't be created. Silence"
    ],
    [
        "\"%s does not support a database collation on TextFields.\"",
        "\"%s does not support a database collation"
    ],
    [
        "\"JSONField default should be a callable instead of an \"",
        "\"JSONField default should be a callable instead"
    ],
    [
        "\"instance so that it's not shared between all field \"",
        "\"instance so that it's not shared between all field"
    ],
    [
        "hint=(\"Use a callable instead, e.g., use `dict` instead of `{}`.\"),",
        "hint=(\"Use a callable instead, e.g.,"
    ],
    [
        "f\"{connection.display_name} does not support comments on columns \"",
        "f\"{connection.display_name} does not support"
    ],
    [
        "f\"{connection.display_name} does not support default database values \"",
        "f\"{connection.display_name} does not support default"
    ],
    [
        "msg = f\"{expression} cannot be used in db_default.\"",
        "msg = f\"{expression} cannot be used"
    ],
    [
        "f\"{connection.display_name} does not support default database values \"",
        "f\"{connection.display_name} does not support default database"
    ],
    [
        "msg = f\"{expression} cannot be used in db_default.\"",
        "msg = f\"{expression} cannot be used in"
    ],
    [
        "msg = f\"{expression} cannot be used in db_default.\"",
        "msg = f\"{expression} cannot"
    ],
    [
        "msg = f\"{expression} cannot be used in db_default.\"",
        "msg = f\"{expression} cannot be"
    ],
    [
        "prevent non-expression literals (integer, float, boolean, etc.) from",
        "prevent non-expression literals (integer,"
    ],
    [
        "f\"{connection.display_name} does not support non-persisted \"",
        "f\"{connection.display_name} does not support non-persisted"
    ],
    [
        "f\"{connection.display_name} does not support non-persisted \"",
        "f\"{connection.display_name} does not support"
    ],
    [
        "f\"{connection.display_name} does not support persisted \"",
        "f\"{connection.display_name} does not support"
    ],
    [
        "\"\\n    CharFields must define a 'max_length' attribute. \"",
        "\"\\n CharFields must define a"
    ],
    [
        "\"\\n    'max_length' is ignored when used with IntegerField. \"",
        "\"\\n 'max_length' is ignored when"
    ],
    [
        "from django.db import connection, connections, models",
        "from django.db import connection, connections,"
    ],
    [
        "from django.db.models.functions import Abs, Lower, Round",
        "from django.db.models.functions import Abs,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "from django.test.utils import isolate_apps, override_settings, register_lookup",
        "from django.test.utils import isolate_apps,"
    ],
    [
        "if max_name_length is not None and not connection.features.truncates_names:",
        "if max_name_length is not None and"
    ],
    [
        "if allowed_len is None or max_name_length < allowed_len:",
        "if allowed_len is None or max_name_length <"
    ],
    [
        "\"'unique_together' must be a list or tuple.\",",
        "\"'unique_together' must be a"
    ],
    [
        "\"All 'unique_together' elements must be lists or tuples.\",",
        "\"All 'unique_together' elements must be lists or"
    ],
    [
        "\"'unique_together' must be a list or tuple.\",",
        "\"'unique_together' must be a list"
    ],
    [
        "\"'unique_together' refers to the nonexistent field \"",
        "\"'unique_together' refers to the"
    ],
    [
        "\"ManyToManyFields are not permitted in 'unique_together'.\",",
        "\"ManyToManyFields are not"
    ],
    [
        "\"'unique_together' refers to a CompositePrimaryKey 'pk', but \"",
        "\"'unique_together' refers to a CompositePrimaryKey 'pk', but"
    ],
    [
        "\"CompositePrimaryKeys are not permitted in 'unique_together'.\",",
        "\"CompositePrimaryKeys are not"
    ],
    [
        "\"'indexes' refers to the nonexistent field 'missing_field'.\",",
        "\"'indexes' refers to the nonexistent field"
    ],
    [
        "\"ManyToManyFields are not permitted in 'indexes'.\",",
        "\"ManyToManyFields are not permitted in"
    ],
    [
        "hint=\"This issue may be caused by multi-table inheritance.\",",
        "hint=\"This issue may be caused by"
    ],
    [
        "\"'indexes' refers to a CompositePrimaryKey 'pk', but \"",
        "\"'indexes' refers to a CompositePrimaryKey 'pk', but"
    ],
    [
        "\"CompositePrimaryKeys are not permitted in 'indexes'.\",",
        "\"CompositePrimaryKeys are not permitted in"
    ],
    [
        "\"The index name '%sindex_name' cannot start with an \"",
        "\"The index name '%sindex_name' cannot"
    ],
    [
        "\"underscore or a number.\" % prefix,",
        "\"underscore or a"
    ],
    [
        "\"%s does not support indexes with conditions.\"",
        "\"%s does not support indexes with"
    ],
    [
        "\"Conditions will be ignored. Silence this warning if you \"",
        "\"Conditions will be ignored. Silence this warning if"
    ],
    [
        "\"%s does not support indexes with non-key columns.\"",
        "\"%s does not support indexes with non-key"
    ],
    [
        "\"Non-key columns will be ignored. Silence this warning if \"",
        "\"Non-key columns will be ignored. Silence this"
    ],
    [
        "\"'indexes' refers to the nonexistent field 'missing_field'.\",",
        "\"'indexes' refers to the nonexistent"
    ],
    [
        "\"ManyToManyFields are not permitted in 'indexes'.\",",
        "\"ManyToManyFields are not permitted in"
    ],
    [
        "hint=\"This issue may be caused by multi-table inheritance.\",",
        "hint=\"This issue may be caused by multi-table"
    ],
    [
        "\"'indexes' refers to a CompositePrimaryKey 'pk', but \"",
        "\"'indexes' refers to a CompositePrimaryKey 'pk',"
    ],
    [
        "\"CompositePrimaryKeys are not permitted in 'indexes'.\",",
        "\"CompositePrimaryKeys are not permitted"
    ],
    [
        "\"%s does not support indexes on expressions.\" % connection.display_name,",
        "\"%s does not support indexes on expressions.\""
    ],
    [
        "\"An index won't be created. Silence this warning if you don't \"",
        "\"An index won't be created. Silence this warning if"
    ],
    [
        "expected = [] if connection.features.supports_expression_indexes else [warn]",
        "expected = [] if connection.features.supports_expression_indexes else"
    ],
    [
        "\"'indexes' refers to the nonexistent field 'missing_field'.\",",
        "\"'indexes' refers to the"
    ],
    [
        "\"'indexes' refers to the nonexistent field 'missing_field'.\",",
        "\"'indexes' refers to the"
    ],
    [
        "\"ManyToManyFields are not permitted in 'indexes'.\",",
        "\"ManyToManyFields are not"
    ],
    [
        "hint=\"This issue may be caused by multi-table inheritance.\",",
        "hint=\"This issue may be"
    ],
    [
        "\"'indexes' refers to a CompositePrimaryKey 'pk', but \"",
        "\"'indexes' refers to a CompositePrimaryKey 'pk', but"
    ],
    [
        "\"CompositePrimaryKeys are not permitted in 'indexes'.\",",
        "\"CompositePrimaryKeys are not permitted in"
    ],
    [
        "\"Field names must not end with an underscore.\",",
        "\"Field names must not end with an"
    ],
    [
        "\"Field names must not end with an underscore.\",",
        "\"Field names must not end with an"
    ],
    [
        "\"The database doesn't have a column name length limit.\",",
        "\"The database doesn't have a column"
    ],
    [
        "'Maximum length is \"%s\" for database \"%s\".'",
        "'Maximum length is \"%s\""
    ],
    [
        "hint=\"Use 'through' to create a separate model for \"",
        "hint=\"Use 'through' to create a separate model for"
    ],
    [
        "'Maximum length is \"%s\" for database \"%s\".'",
        "'Maximum length is \"%s\" for database"
    ],
    [
        "hint=\"Use 'through' to create a separate model for \"",
        "hint=\"Use 'through' to create a separate model for"
    ],
    [
        "\"The database doesn't have a column name length limit.\",",
        "\"The database doesn't have a column name"
    ],
    [
        "when database does not support long names.",
        "when database does not support"
    ],
    [
        "'Autogenerated column name too long for field \"%s\". '",
        "'Autogenerated column name too long for"
    ],
    [
        "'Maximum length is \"%s\" for database \"%s\".'",
        "'Maximum length is \"%s\" for database"
    ],
    [
        "hint=\"Set the column name manually using 'db_column'.\",",
        "hint=\"Set the column name"
    ],
    [
        "'Field names must not contain \"__\".',",
        "'Field names must not contain"
    ],
    [
        "\"'pk' is a reserved word that cannot be used as a field name.\",",
        "\"'pk' is a reserved word that cannot be used as a field"
    ],
    [
        "\"Field 'bar' has column name 'foo' that is used by \"",
        "\"Field 'bar' has column name 'foo' that is used"
    ],
    [
        "hint=\"Specify a 'db_column' for the field.\",",
        "hint=\"Specify a 'db_column' for"
    ],
    [
        "\"The field 'child' clashes with the field \"",
        "\"The field 'child' clashes with the"
    ],
    [
        "\"The field 'clash' clashes with the field 'clash_id' from \"",
        "\"The field 'clash' clashes with"
    ],
    [
        "\"The field 'id' from parent model \"",
        "\"The field 'id' from parent"
    ],
    [
        "\"'invalid_models_tests.mother' clashes with the field 'id' \"",
        "\"'invalid_models_tests.mother' clashes with the"
    ],
    [
        "\"The field 'clash' from parent model \"",
        "\"The field 'clash' from parent"
    ],
    [
        "\"'invalid_models_tests.mother' clashes with the field 'clash' \"",
        "\"'invalid_models_tests.mother' clashes with the field"
    ],
    [
        "\"The field 'f' clashes with the field 'f_id' \"",
        "\"The field 'f' clashes with the field 'f_id'"
    ],
    [
        "\"The field 'clash' clashes with the field 'clash' \"",
        "\"The field 'clash' clashes with the field"
    ],
    [
        "\"The field 'grandparent_ptr' clashes with the field \"",
        "\"The field 'grandparent_ptr' clashes"
    ],
    [
        "\"The field 'fk_id' clashes with the field 'fk' from model \"",
        "\"The field 'fk_id' clashes with the field"
    ],
    [
        "\"'id' can only be used as a field name if the field also sets \"",
        "\"'id' can only be used as a field name if"
    ],
    [
        "\"'ordering' must be a tuple or list \"",
        "\"'ordering' must be a tuple"
    ],
    [
        "\"(even if you want to order by only one field).\",",
        "\"(even if you want to order by only"
    ],
    [
        "\"'ordering' and 'order_with_respect_to' cannot be used together.\",",
        "\"'ordering' and 'order_with_respect_to' cannot be used"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related field, \"",
        "\"'ordering' refers to the nonexistent field,"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related field, \"",
        "\"'ordering' refers to the nonexistent field, related"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related field, \"",
        "\"'ordering' refers to the nonexistent field, related"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related field, \"",
        "\"'ordering' refers to the nonexistent field, related field,"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related field, \"",
        "\"'ordering' refers to the nonexistent field, related field,"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related field, \"",
        "\"'ordering' refers to the nonexistent field, related"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related field, \"",
        "\"'ordering' refers to the nonexistent"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related field, \"",
        "\"'ordering' refers to the nonexistent"
    ],
    [
        "\"The model name '_Model' cannot start or end with an underscore \"",
        "\"The model name '_Model' cannot start or end with"
    ],
    [
        "\"as it collides with the query lookup syntax.\",",
        "\"as it collides with the query lookup"
    ],
    [
        "\"The model name 'Model_' cannot start or end with an underscore \"",
        "\"The model name 'Model_' cannot start or end"
    ],
    [
        "\"as it collides with the query lookup syntax.\",",
        "\"as it collides with the"
    ],
    [
        "\"The model name 'Test__Model' cannot contain double underscores \"",
        "\"The model name 'Test__Model' cannot contain double underscores"
    ],
    [
        "\"as it collides with the query lookup syntax.\",",
        "\"as it collides with"
    ],
    [
        "\"The property 'fk_id' clashes with a related field accessor.\",",
        "\"The property 'fk_id' clashes with a related field"
    ],
    [
        "\"The model cannot have more than one field with \"",
        "\"The model cannot have more"
    ],
    [
        "\"'TEST_SWAPPED_MODEL_BAD_VALUE' is not of the form \"",
        "\"'TEST_SWAPPED_MODEL_BAD_VALUE' is not of"
    ],
    [
        "\"which has not been installed, or is abstract.\",",
        "\"which has not been installed, or is"
    ],
    [
        "\"The model has two identical many-to-many relations through \"",
        "\"The model has two identical many-to-many relations through"
    ],
    [
        "\"The field's intermediary table 'myapp_bar' clashes with the \"",
        "\"The field's intermediary table 'myapp_bar' clashes with the"
    ],
    [
        "\"The field's intermediary table 'myapp_bar' clashes with the \"",
        "\"The field's intermediary table 'myapp_bar' clashes with the"
    ],
    [
        "\"You have configured settings.DATABASE_ROUTERS. Verify \"",
        "\"You have configured"
    ],
    [
        "\"that the table of 'invalid_models_tests.Bar' is \"",
        "\"that the table of"
    ],
    [
        "\"correctly routed to a separate database.\"",
        "\"correctly routed to a separate"
    ],
    [
        "\"The field's intermediary table 'clash' clashes with the \"",
        "\"The field's intermediary table 'clash' clashes with the"
    ],
    [
        "\"The field's intermediary table 'clash' clashes with the \"",
        "\"The field's intermediary table 'clash' clashes with"
    ],
    [
        "\"The field's intermediary table 'clash' clashes with the \"",
        "\"The field's intermediary table 'clash' clashes"
    ],
    [
        "\"table name of 'invalid_models_tests.%s.foos'.\" % clashing_model,",
        "\"table name of 'invalid_models_tests.%s.foos'.\" %"
    ],
    [
        "\"You have configured settings.DATABASE_ROUTERS. Verify \"",
        "\"You have configured settings.DATABASE_ROUTERS. Verify"
    ],
    [
        "\"that the table of 'invalid_models_tests.%s.foos' is \"",
        "\"that the table of 'invalid_models_tests.%s.foos' is"
    ],
    [
        "\"correctly routed to a separate database.\" % clashing_model",
        "\"correctly routed to a separate"
    ],
    [
        "for model_cls, clashing_model in [(Bar, \"Baz\"), (Baz, \"Bar\")]",
        "for model_cls, clashing_model in [(Bar, \"Baz\"),"
    ],
    [
        "\"The field's intermediary table 'bar_foos' clashes with the \"",
        "\"The field's intermediary table 'bar_foos' clashes with"
    ],
    [
        "\"The field's intermediary table 'bar_foos' clashes with the \"",
        "\"The field's intermediary table 'bar_foos'"
    ],
    [
        "\"You have configured settings.DATABASE_ROUTERS. Verify \"",
        "\"You have configured settings.DATABASE_ROUTERS."
    ],
    [
        "\"that the table of 'invalid_models_tests.Foo' is \"",
        "\"that the table of 'invalid_models_tests.Foo' is"
    ],
    [
        "\"correctly routed to a separate database.\"",
        "\"correctly routed to a"
    ],
    [
        "\"%r contains a lazy reference to auth.imaginarymodel, \"",
        "\"%r contains a lazy reference to"
    ],
    [
        "\"but app 'auth' doesn't provide model 'imaginarymodel'.\"",
        "\"but app 'auth' doesn't"
    ],
    [
        "\"%r contains a lazy reference to fanciful_app.imaginarymodel, \"",
        "\"%r contains a lazy reference"
    ],
    [
        "\"but app 'fanciful_app' isn't installed.\" % dummy_function,",
        "\"but app 'fanciful_app' isn't"
    ],
    [
        "\"An instance of class 'DummyClass' was connected to \"",
        "\"An instance of class 'DummyClass'"
    ],
    [
        "\"the 'post_init' signal with a lazy reference to the sender \"",
        "\"the 'post_init' signal with a lazy"
    ],
    [
        "\"'missing-app.model', but app 'missing-app' isn't installed.\",",
        "\"'missing-app.model', but app"
    ],
    [
        "\"Bound method 'DummyClass.dummy_method' was connected to the \"",
        "\"Bound method 'DummyClass.dummy_method' was"
    ],
    [
        "\"'post_init' signal with a lazy reference to the sender \"",
        "\"'post_init' signal with a lazy"
    ],
    [
        "\"'missing-app.model', but app 'missing-app' isn't installed.\",",
        "\"'missing-app.model', but app"
    ],
    [
        "\"The field invalid_models_tests.DummyModel.author was declared \"",
        "\"The field invalid_models_tests.DummyModel.author was"
    ],
    [
        "\"with a lazy reference to 'invalid_models_tests.author', but app \"",
        "\"with a lazy reference to 'invalid_models_tests.author',"
    ],
    [
        "\"The function 'dummy_function' was connected to the 'post_init' \"",
        "\"The function 'dummy_function' was connected to"
    ],
    [
        "\"signal with a lazy reference to the sender \"",
        "\"signal with a lazy reference to the"
    ],
    [
        "\"'missing-app.model', but app 'missing-app' isn't installed.\",",
        "\"'missing-app.model', but app 'missing-app'"
    ],
    [
        "f\"{connection.display_name} does not support comments on tables \"",
        "f\"{connection.display_name} does not support comments on"
    ],
    [
        "\"Model invalid_models_tests.MultipleAutoFields can't have more \"",
        "\"Model invalid_models_tests.MultipleAutoFields can't have more"
    ],
    [
        "\"%s does not support JSONFields.\" % connection.display_name,",
        "\"%s does not support"
    ],
    [
        "expected = [] if connection.features.supports_json_field else [error]",
        "expected = [] if connection.features.supports_json_field else"
    ],
    [
        "\"%s does not support check constraints.\" % connection.display_name,",
        "\"%s does not support check constraints.\""
    ],
    [
        "\"A constraint won't be created. Silence this warning if you \"",
        "\"A constraint won't be created. Silence this warning if you"
    ],
    [
        "\"'constraints' refers to the nonexistent field \"",
        "\"'constraints' refers to the nonexistent field"
    ],
    [
        "\"'constraints' refers to the nonexistent field 'parents'.\",",
        "\"'constraints' refers to the"
    ],
    [
        "\"'constraints' refers to the nonexistent field 'model'.\",",
        "\"'constraints' refers to the nonexistent field"
    ],
    [
        "\"ManyToManyFields are not permitted in 'constraints'.\",",
        "\"ManyToManyFields are not"
    ],
    [
        "hint=\"This issue may be caused by multi-table inheritance.\",",
        "hint=\"This issue may be caused by multi-table"
    ],
    [
        "\"'constraints' refers to the joined field '%s'.\" % field_name,",
        "\"'constraints' refers to the joined"
    ],
    [
        "\"'constraints' refers to the joined field '%s'.\" % field_name,",
        "\"'constraints' refers to the joined"
    ],
    [
        "\"Check constraint 'raw_sql_check' contains RawSQL() expression and \"",
        "\"Check constraint 'raw_sql_check' contains RawSQL() expression"
    ],
    [
        "\"won't be validated during the model full_clean().\",",
        "\"won't be validated during the"
    ],
    [
        "hint=\"Silence this warning if you don't care about it.\",",
        "hint=\"Silence this warning if you don't care about"
    ],
    [
        "\"Check constraint 'nested_raw_sql_check' contains RawSQL() \"",
        "\"Check constraint 'nested_raw_sql_check' contains RawSQL()"
    ],
    [
        "\"expression and won't be validated during the model full_clean().\",",
        "\"expression and won't be validated during the model"
    ],
    [
        "hint=\"Silence this warning if you don't care about it.\",",
        "hint=\"Silence this warning if you don't care about"
    ],
    [
        "\"'constraints' refers to a CompositePrimaryKey 'pk', but \"",
        "\"'constraints' refers to a CompositePrimaryKey 'pk', but"
    ],
    [
        "\"CompositePrimaryKeys are not permitted in 'constraints'.\",",
        "\"CompositePrimaryKeys are not"
    ],
    [
        "\"%s does not support unique constraints with conditions.\"",
        "\"%s does not support unique constraints"
    ],
    [
        "\"A constraint won't be created. Silence this warning if \"",
        "\"A constraint won't be created."
    ],
    [
        "\"'constraints' refers to the nonexistent field \"",
        "\"'constraints' refers to the"
    ],
    [
        "\"'constraints' refers to the joined field 'parent__age__lt'.\",",
        "\"'constraints' refers to the joined"
    ],
    [
        "\"'constraints' refers to the nonexistent field 'model'.\",",
        "\"'constraints' refers to the"
    ],
    [
        "\"%s does not support deferrable unique constraints.\"",
        "\"%s does not support"
    ],
    [
        "\"A constraint won't be created. Silence this warning if \"",
        "\"A constraint won't be created. Silence"
    ],
    [
        "\"'constraints' refers to the nonexistent field 'missing_field'.\",",
        "\"'constraints' refers to the nonexistent field"
    ],
    [
        "\"ManyToManyFields are not permitted in 'constraints'.\",",
        "\"ManyToManyFields are not permitted"
    ],
    [
        "hint=\"This issue may be caused by multi-table inheritance.\",",
        "hint=\"This issue may be caused"
    ],
    [
        "\"'constraints' refers to a CompositePrimaryKey 'pk', but \"",
        "\"'constraints' refers to a CompositePrimaryKey 'pk',"
    ],
    [
        "\"CompositePrimaryKeys are not permitted in 'constraints'.\",",
        "\"CompositePrimaryKeys are not permitted in"
    ],
    [
        "\"%s does not support unique constraints with non-key columns.\"",
        "\"%s does not support unique constraints with"
    ],
    [
        "\"A constraint won't be created. Silence this warning if \"",
        "\"A constraint won't be created. Silence this warning"
    ],
    [
        "\"'constraints' refers to the nonexistent field 'missing_field'.\",",
        "\"'constraints' refers to the nonexistent"
    ],
    [
        "\"ManyToManyFields are not permitted in 'constraints'.\",",
        "\"ManyToManyFields are not permitted"
    ],
    [
        "hint=\"This issue may be caused by multi-table inheritance.\",",
        "hint=\"This issue may be caused by"
    ],
    [
        "\"'constraints' refers to a CompositePrimaryKey 'pk', but \"",
        "\"'constraints' refers to a"
    ],
    [
        "\"CompositePrimaryKeys are not permitted in 'constraints'.\",",
        "\"CompositePrimaryKeys are not permitted"
    ],
    [
        "\"%s does not support unique constraints on expressions.\"",
        "\"%s does not support unique constraints"
    ],
    [
        "\"A constraint won't be created. Silence this warning if you \"",
        "\"A constraint won't be created. Silence this warning if"
    ],
    [
        "expected = [] if connection.features.supports_expression_indexes else [warn]",
        "expected = [] if connection.features.supports_expression_indexes"
    ],
    [
        "f\"{connection.display_name} does not support unique constraints with nulls \"",
        "f\"{connection.display_name} does not support unique constraints with nulls"
    ],
    [
        "\"A constraint won't be created. Silence this warning if you don't care \"",
        "\"A constraint won't be created. Silence this warning if you don't care"
    ],
    [
        "\"'constraints' refers to the nonexistent field 'missing_field'.\",",
        "\"'constraints' refers to the nonexistent"
    ],
    [
        "\"'constraints' refers to the nonexistent field 'missing_field'.\",",
        "\"'constraints' refers to the"
    ],
    [
        "\"ManyToManyFields are not permitted in 'constraints'.\",",
        "\"ManyToManyFields are not"
    ],
    [
        "hint=\"This issue may be caused by multi-table inheritance.\",",
        "hint=\"This issue may be caused by multi-table"
    ],
    [
        "\"'constraints' refers to a CompositePrimaryKey 'pk', but \"",
        "\"'constraints' refers to a CompositePrimaryKey 'pk',"
    ],
    [
        "\"CompositePrimaryKeys are not permitted in 'constraints'.\",",
        "\"CompositePrimaryKeys are not permitted in"
    ],
    [
        "\"'%s' isn't in table_list().\" % Reporter._meta.db_table,",
        "\"'%s' isn't in table_list().\" %"
    ],
    [
        "\"'%s' isn't in table_list().\" % Article._meta.db_table,",
        "\"'%s' isn't in table_list().\" %"
    ],
    [
        "\"CREATE VIEW introspection_article_view AS SELECT headline \"",
        "\"CREATE VIEW introspection_article_view AS SELECT headline"
    ],
    [
        "self.fail(\"The test user has no CREATE VIEW privileges\")",
        "self.fail(\"The test user has no CREATE VIEW"
    ],
    [
        "seq for seq in sequences if seq[\"table\"] == Reporter._meta.db_table",
        "seq for seq in sequences if"
    ],
    [
        "[field.comment for field in desc if field.name == \"name\"],",
        "[field.comment for field in desc if field.name =="
    ],
    [
        "Indexes have the 'orders' key with a list of 'ASC'/'DESC' values.",
        "Indexes have the 'orders' key with a list"
    ],
    [
        "if val[\"index\"] and not (val[\"primary_key\"] or val[\"unique\"]):",
        "if val[\"index\"] and not"
    ],
    [
        "elif details[\"columns\"] == [\"up_votes\"] and details[\"check\"]:",
        "elif details[\"columns\"] =="
    ],
    [
        "elif details[\"columns\"] == [\"voting_number\"] and details[\"check\"]:",
        "elif details[\"columns\"] =="
    ],
    [
        "elif details[\"columns\"] == [\"ref\"] and details[\"unique\"]:",
        "elif details[\"columns\"] == [\"ref\"] and"
    ],
    [
        "elif details[\"columns\"] == [\"voting_number\"] and details[\"unique\"]:",
        "elif details[\"columns\"] == [\"voting_number\"] and"
    ],
    [
        "elif details[\"columns\"] == [\"article_id\"] and details[\"index\"]:",
        "elif details[\"columns\"] == [\"article_id\"]"
    ],
    [
        "elif details[\"columns\"] == [\"id\"] and details[\"primary_key\"]:",
        "elif details[\"columns\"] == [\"id\"]"
    ],
    [
        "elif details[\"columns\"] == [\"article_id\"] and details[\"foreign_key\"]:",
        "elif details[\"columns\"] == [\"article_id\"] and"
    ],
    [
        "constraints.keys() ^ (custom_constraints | field_constraints), set()",
        "constraints.keys() ^ (custom_constraints"
    ],
    [
        "for name in (\"int\", \"path\", \"slug\", \"str\", \"uuid\")",
        "for name in (\"int\","
    ],
    [
        "from django.urls import include, path, register_converter",
        "from django.urls import include,"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import include,"
    ],
    [
        "from django.urls import path, re_path, register_converter",
        "from django.urls import"
    ],
    [
        "raise Exception(\"You can't modify the regular expression.\")",
        "raise Exception(\"You can't modify the"
    ],
    [
        "included_kwargs = {\"base\": b\"hello\", \"value\": b\"world\"}",
        "included_kwargs = {\"base\": b\"hello\", \"value\":"
    ],
    [
        "for url, (url_name, app_name, kwargs) in converter_test_data:",
        "for url, (url_name, app_name, kwargs)"
    ],
    [
        "for expected, (url_name, app_name, kwargs) in converter_test_data:",
        "for expected, (url_name, app_name, kwargs) in"
    ],
    [
        "url_name = \"%s:%s\" % (app_name, url_name)",
        "url_name = \"%s:%s\" % (app_name,"
    ],
    [
        "msg = \"kwargs argument must be a dict, but got str.\"",
        "msg = \"kwargs argument must be"
    ],
    [
        "msg = \"URL route 'foo/<nonexistent:var>/' uses invalid converter 'nonexistent'.\"",
        "msg = \"URL route 'foo/<nonexistent:var>/' uses invalid converter"
    ],
    [
        "msg = \"Converter 'int' is already registered.\"",
        "msg = \"Converter 'int' is already"
    ],
    [
        "msg = \"view must be a callable or a list/tuple in the case of include().\"",
        "msg = \"view must be a callable or a list/tuple in"
    ],
    [
        "msg = \"view must be a callable, pass EmptyCBV.as_view(), not EmptyCBV().\"",
        "msg = \"view must be a callable, pass"
    ],
    [
        "msg = \"URL route %r cannot contain whitespace in angle brackets <…>\"",
        "msg = \"URL route %r cannot contain whitespace in angle"
    ],
    [
        "p = path(\"space%s/<int:num>/\" % string.whitespace, empty_view)",
        "p = path(\"space%s/<int:num>/\""
    ],
    [
        "for url_name, url_suffixes, converter in test_data:",
        "for url_name, url_suffixes,"
    ],
    [
        "url = \"/%s/%s/\" % (url_name, url_suffix)",
        "url = \"/%s/%s/\" % (url_name,"
    ],
    [
        "converted_url = \"/%s/%s/\" % (url_name, converted_value)",
        "converted_url = \"/%s/%s/\" %"
    ],
    [
        "url = \"/%s/%s/\" % (url_name, url_suffix)",
        "url = \"/%s/%s/\" % (url_name,"
    ],
    [
        "for args, kwargs, url_suffix in cases:",
        "for args, kwargs, url_suffix"
    ],
    [
        "expected_url = \"/%s/%s\" % (url_name, url_suffix)",
        "expected_url = \"/%s/%s\" % (url_name,"
    ],
    [
        "\"URL route 'b/<int:book.id>/' uses parameter name 'book.id' which \"",
        "\"URL route 'b/<int:book.id>/' uses parameter name 'book.id' which"
    ],
    [
        "\"\"\"How are errors in Converter.to_python() and to_url() handled?\"\"\"",
        "\"\"\"How are errors in Converter.to_python() and to_url()"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"This type error propagates.\"):",
        "with self.assertRaisesMessage(TypeError, \"This"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"This type error propagates.\"):",
        "with self.assertRaisesMessage(TypeError, \"This"
    ],
    [
        "from django.urls.resolvers import RegexPattern, RoutePattern, get_resolver",
        "from django.urls.resolvers import RegexPattern,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "A ModelAdmin for the Action model that changes the URL of the add_view",
        "A ModelAdmin for the Action model that changes the"
    ],
    [
        "The Action model has a CharField PK.",
        "The Action model has a"
    ],
    [
        "Remove all entries named 'name' from the ModelAdmin instance URL",
        "Remove all entries named 'name' from the ModelAdmin instance"
    ],
    [
        "return [url for url in super().get_urls() if url.name != name]",
        "return [url for url in super().get_urls() if url.name !="
    ],
    [
        "from .models import Action, Car, Person",
        "from .models import Action, Car,"
    ],
    [
        "* The Action model has a CharField PK.",
        "* The Action model has"
    ],
    [
        "* The ModelAdmin for Action customizes the add_view URL, it's",
        "* The ModelAdmin for Action"
    ],
    [
        "name=\"path/to/file/\", description=\"An action with '/' in its name.\"",
        "name=\"path/to/file/\", description=\"An action with '/' in"
    ],
    [
        "description=\"An action with a name similar to a HTML doc path.\",",
        "description=\"An action with a name similar to a HTML doc"
    ],
    [
        "description=\"An action with a name suspected of being a XSS attempt\",",
        "description=\"An action with a name suspected of"
    ],
    [
        "Ensure GET on the add_view works.",
        "Ensure GET on the add_view"
    ],
    [
        "Ensure GET on the add_view plus specifying a field value in the query",
        "Ensure GET on the add_view plus specifying a field"
    ],
    [
        "\"name\": \"Action added through a popup\",",
        "\"name\": \"Action added through"
    ],
    [
        "self.assertContains(response, \"Action added through a popup\")",
        "self.assertContains(response, \"Action added"
    ],
    [
        "the 'Save' button has been pressed when adding a new object.",
        "the 'Save' button has been pressed when adding"
    ],
    [
        "the 'Save' button has been pressed when editing an existing object.",
        "the 'Save' button has been pressed when"
    ],
    [
        "response = self.client.post(post_url, {\"name\": \"Jack Doe\"})",
        "response = self.client.post(post_url,"
    ],
    [
        "the redirection after an object has been created.",
        "the redirection after an object"
    ],
    [
        "\"Permissions and content types are not created for a swapped model\"",
        "\"Permissions and content types are not created for a"
    ],
    [
        "apps_models = [(ct.app_label, ct.model) for ct in ContentType.objects.all()]",
        "apps_models = [(ct.app_label, ct.model) for ct"
    ],
    [
        "\"Model names are case insensitive. Model swapping honors this.\"",
        "\"Model names are case insensitive. Model"
    ],
    [
        "Many-to-one relationships that can be null",
        "Many-to-one relationships that"
    ],
    [
        "To define a many-to-one relationship that can have a null foreign key, use",
        "To define a many-to-one relationship that can have a null"
    ],
    [
        "from .models import Article, Car, Driver, Reporter",
        "from .models import Article, Car,"
    ],
    [
        "\"'Car' instance needs to have a primary key value before this relationship \"",
        "\"'Car' instance needs to have a primary key value before this relationship"
    ],
    [
        "f'\"{car!r}\" needs to have a value for field \"make\" before this '",
        "f'\"{car!r}\" needs to have a value for field \"make\""
    ],
    [
        "The ``manage.py`` utility provides a number of useful commands for managing a",
        "The ``manage.py`` utility provides a number of useful commands for"
    ],
    [
        "Django project. If you want to add a utility command of your own, you can.",
        "Django project. If you want to add a utility"
    ],
    [
        "The user-defined command ``dance`` is defined in the management/commands",
        "The user-defined command ``dance`` is defined in the"
    ],
    [
        "subdirectory of this test application. It is a simple command that responds",
        "subdirectory of this test application. It is a simple"
    ],
    [
        "with a printed message when invoked.",
        "with a printed"
    ],
    [
        "For more details on how to define your own ``manage.py`` commands, look at the",
        "For more details on how to define your"
    ],
    [
        "``django.core.management.commands`` directory. This directory contains the",
        "``django.core.management.commands`` directory. This directory"
    ],
    [
        "definitions for the base Django ``manage.py`` commands.",
        "definitions for the base Django"
    ],
    [
        "from io import BytesIO, StringIO, TextIOWrapper",
        "from io import BytesIO,"
    ],
    [
        "from django.core.management import BaseCommand, CommandError, find_commands",
        "from django.core.management import"
    ],
    [
        "self.assertIn(\"I don't feel like dancing Rock'n'Roll.\\n\", out.getvalue())",
        "self.assertIn(\"I don't feel like"
    ],
    [
        "self.assertIn(\"I don't feel like dancing Jive.\\n\", out.getvalue())",
        "self.assertIn(\"I don't feel like dancing Jive.\\n\","
    ],
    [
        "self.assertIn(\"I don't feel like dancing Jive.\\n\", out.getvalue())",
        "self.assertIn(\"I don't feel like dancing Jive.\\n\","
    ],
    [
        "\"\"\"Exception raised in a command should raise CommandError with",
        "\"\"\"Exception raised in a command should"
    ],
    [
        "call_command, but SystemExit when run from command line",
        "call_command, but SystemExit when"
    ],
    [
        "with captured_stderr() as stderr, self.assertRaises(SystemExit) as cm:",
        "with captured_stderr() as stderr,"
    ],
    [
        "When the Command handle method is decorated with @no_translations,",
        "When the Command handle method is decorated with"
    ],
    [
        "translations are deactivated inside the command.",
        "translations are deactivated inside the"
    ],
    [
        "find_command should still work when the PATH environment variable",
        "find_command should still work when the"
    ],
    [
        "Management commands can also be loaded from Python eggs.",
        "Management commands can also be loaded from Python"
    ],
    [
        "When passing the long option name to call_command, the available option",
        "When passing the long option name to call_command, the available"
    ],
    [
        "It should be possible to pass non-string arguments to call_command.",
        "It should be possible to"
    ],
    [
        "self.assertEqual(out.getvalue(), \"\\nDave, I can't do that.\\n\")",
        "self.assertEqual(out.getvalue(), \"\\nDave, I can't"
    ],
    [
        "\"Dave, my mind is going. I can feel it. I can feel it.\\n\", out.getvalue()",
        "\"Dave, my mind is going. I can feel"
    ],
    [
        "\"Dave, my mind is going. I can feel it. I can feel it.\\n\", out.getvalue()",
        "\"Dave, my mind is going. I can"
    ],
    [
        "By default, call_command should not trigger the check framework, unless",
        "By default, call_command should not trigger the check framework,"
    ],
    [
        "msg = \"requires_system_checks must be a list or tuple.\"",
        "msg = \"requires_system_checks must be a list or"
    ],
    [
        "\"Unknown option(s) for dance command: unrecognized. Valid options \"",
        "\"Unknown option(s) for dance command:"
    ],
    [
        "\"Valid options are: example, force_color, help, integer, no_color, \"",
        "\"Valid options are: example, force_color, help,"
    ],
    [
        "self.assertIn(\"Detected that --version already exists\", out.getvalue())",
        "self.assertIn(\"Detected that --version already exists\","
    ],
    [
        "\"Error: one of the arguments --foo-id --foo-name --foo-list \"",
        "\"Error: one of the arguments"
    ],
    [
        "\"--append_const --const --count --flag_false --flag_true is \"",
        "\"--append_const --const --count --flag_false"
    ],
    [
        "expected_output = \"%s=%s\" % (arg, value)",
        "expected_output = \"%s=%s\""
    ],
    [
        "\"Cannot pass the dest 'until' that matches multiple arguments via \"",
        "\"Cannot pass the dest 'until' that matches"
    ],
    [
        "\"%s=%s\" % (arg, value) for arg, value in args.items()",
        "\"%s=%s\" % (arg, value) for arg, value in"
    ],
    [
        "msg = r\"invalid choice: 'test' \\(choose from '?foo'?\\)\"",
        "msg = r\"invalid choice: 'test' \\(choose"
    ],
    [
        "msg = \"Error: the following arguments are required: subcommand\"",
        "msg = \"Error: the following arguments are"
    ],
    [
        "Tests that need to run by simulating the command line, not by call_command.",
        "Tests that need to run by simulating the"
    ],
    [
        "To avoid conflicts with custom options, commands don't allow",
        "To avoid conflicts with custom options, commands don't"
    ],
    [
        "abbreviated forms of the --setting and --pythonpath options.",
        "abbreviated forms of the --setting and --pythonpath"
    ],
    [
        "out, err = self.run_manage([\"set_option\", \"--set\", \"foo\"])",
        "out, err = self.run_manage([\"set_option\", \"--set\","
    ],
    [
        "out, err = self.run_manage([\"set_option\", \"--skip-checks\", \"--set\", \"foo\"])",
        "out, err = self.run_manage([\"set_option\", \"--skip-checks\","
    ],
    [
        "out, err = self.run_manage([\"subparser\", \"foo\", \"twelve\"])",
        "out, err = self.run_manage([\"subparser\", \"foo\","
    ],
    [
        "\"manage.py subparser foo: error: argument bar: invalid int value: 'twelve'\",",
        "\"manage.py subparser foo: error: argument bar: invalid int"
    ],
    [
        "out, err = self.run_manage([\"subparser_vanilla\", \"foo\", \"seven\"])",
        "out, err ="
    ],
    [
        "\"manage.py subparser_vanilla foo: error: argument bar: invalid int value: \"",
        "\"manage.py subparser_vanilla foo: error: argument"
    ],
    [
        "expected = [os.path.normcase(p) for p in [\"foo/bar\", \"bar/*/\"]]",
        "expected = [os.path.normcase(p) for p"
    ],
    [
        "help=\"Specify the app label(s) to works on.\",",
        "help=\"Specify the app label(s) to"
    ],
    [
        "raise CommandError(\"I'm sorry Dave, I'm afraid I can't do that.\")",
        "raise CommandError(\"I'm sorry Dave, I'm afraid I can't do"
    ],
    [
        "raise CommandError(\"Sorry, Dave, I can't let you do that.\")",
        "raise CommandError(\"Sorry, Dave, I can't let you"
    ],
    [
        "self.stdout.write(\"Dave, my mind is going. I can feel it. I can feel it.\")",
        "self.stdout.write(\"Dave, my mind is going. I can feel it."
    ],
    [
        "help = \"Dance around like a madman.\"",
        "help = \"Dance around like"
    ],
    [
        "self.stdout.write(\"I don't feel like dancing %s.\" % options[\"style\"])",
        "self.stdout.write(\"I don't feel like dancing %s.\""
    ],
    [
        "\"You passed %d as a positional argument.\" % options[\"integer\"]",
        "\"You passed %d as a positional argument.\""
    ],
    [
        "raise CommandError(\"--version argument does no yet exist\")",
        "raise CommandError(\"--version argument does no"
    ],
    [
        "return \"Detected that --version already exists\"",
        "return \"Detected that"
    ],
    [
        "This command returns a URL from a reverse() call.",
        "This command returns a URL from a"
    ],
    [
        "Fake model not defining ``get_absolute_url`` for",
        "Fake model not defining ``get_absolute_url``"
    ],
    [
        "Fake model defining a ``get_absolute_url`` method containing an error",
        "Fake model defining a ``get_absolute_url``"
    ],
    [
        "\"\"\"An ordered tag on an item.\"\"\"",
        "\"\"\"An ordered tag on"
    ],
    [
        "from .models import Answer, Post, Question",
        "from .models import"
    ],
    [
        "from django.contrib.contenttypes import management as contenttypes_management",
        "from django.contrib.contenttypes import management as"
    ],
    [
        "from django.contrib.contenttypes import management as contenttypes_management",
        "from django.contrib.contenttypes import"
    ],
    [
        "interactive mode (the default) deletes stale content types and warns of",
        "interactive mode (the default) deletes stale content types and"
    ],
    [
        "self.assertIn(\"- Content type for contenttypes_tests.Fake\", output)",
        "self.assertIn(\"- Content type for"
    ],
    [
        "interactive mode deletes stale content types even if there aren't any",
        "interactive mode deletes stale content types even"
    ],
    [
        "\"\"\"non-interactive mode deletes stale content types.\"\"\"",
        "\"\"\"non-interactive mode deletes stale content"
    ],
    [
        "\"\"\"A ContentType isn't created if the model isn't available.\"\"\"",
        "\"\"\"A ContentType isn't created if the model"
    ],
    [
        "from .models import Site as MockSite",
        "from .models import"
    ],
    [
        "\"Can view a shortcut for an Author object that has a get_absolute_url method\"",
        "\"Can view a shortcut for an Author object that has a get_absolute_url"
    ],
    [
        "Can view a shortcut when object's get_absolute_url returns a full URL",
        "Can view a shortcut when object's get_absolute_url"
    ],
    [
        "the tested URLs are: \"http://...\", \"https://...\" and \"//...\"",
        "the tested URLs are: \"http://...\", \"https://...\""
    ],
    [
        "Shortcuts for an object that has no get_absolute_url() method raise",
        "Shortcuts for an object that has"
    ],
    [
        "short_url = \"/shortcut/%s/%s/\" % (\"spam\", an_author.pk)",
        "short_url = \"/shortcut/%s/%s/\" % (\"spam\","
    ],
    [
        "The shortcut view works if a model's ForeignKey to site is None.",
        "The shortcut view works if a model's ForeignKey to site"
    ],
    [
        "get_model.side_effect = lambda *args, **kwargs: (",
        "get_model.side_effect = lambda"
    ],
    [
        "When the object has a ManyToManyField to Site, redirect to the current",
        "When the object has a ManyToManyField to"
    ],
    [
        "site if it's attached to the object or to the domain of the first site",
        "site if it's attached to the object or to the domain"
    ],
    [
        "get_model.side_effect = lambda *args, **kwargs: (",
        "get_model.side_effect = lambda *args,"
    ],
    [
        "shortcut_url = \"/shortcut/%s/%s/\" % (ct.pk, obj_with_sites.pk)",
        "shortcut_url = \"/shortcut/%s/%s/\" % (ct.pk,"
    ],
    [
        "The view returns a complete URL regardless of whether the sites",
        "The view returns a complete URL regardless of whether the"
    ],
    [
        "The view doesn't catch an AttributeError raised by",
        "The view doesn't catch an"
    ],
    [
        "from .models import Answer, Post, Question",
        "from .models import Answer,"
    ],
    [
        "question = Question.objects.create(text=\"What is your name?\")",
        "question = Question.objects.create(text=\"What"
    ],
    [
        "question = Question.objects.create(text=\"What is your name?\")",
        "question = Question.objects.create(text=\"What is"
    ],
    [
        "msg = \"Only one queryset is allowed for each content type.\"",
        "msg = \"Only one queryset is allowed for"
    ],
    [
        "from .models import Author, ConcreteModel, FooWithUrl, ProxyModel",
        "from .models import Author, ConcreteModel, FooWithUrl,"
    ],
    [
        "The content type cache (see ContentTypeManager) works correctly.",
        "The content type cache (see ContentTypeManager)"
    ],
    [
        "Lookups for a particular content type -- by model, ID, or natural key",
        "Lookups for a particular content type -- by"
    ],
    [
        "-- should hit the database only on the first lookup.",
        "-- should hit the database only"
    ],
    [
        "type if it doesn't exist in the database.",
        "type if it doesn't exist in the"
    ],
    [
        "Make sure the `for_concrete_model` kwarg correctly works",
        "Make sure the `for_concrete_model` kwarg correctly"
    ],
    [
        "with concrete, proxy and deferred models",
        "with concrete, proxy and"
    ],
    [
        "Make sure the `for_concrete_models` kwarg correctly works",
        "Make sure the `for_concrete_models` kwarg"
    ],
    [
        "with concrete, proxy and deferred models.",
        "with concrete, proxy"
    ],
    [
        "Displaying content types in admin (or anywhere) doesn't break on",
        "Displaying content types in admin (or anywhere) doesn't break"
    ],
    [
        "leftover content type records in the DB for which no model is defined",
        "leftover content type records in the DB for which no model"
    ],
    [
        "Displaying content types in admin (or anywhere) doesn't break on",
        "Displaying content types in admin (or anywhere)"
    ],
    [
        "leftover content type records in the DB for which no model is defined",
        "leftover content type records in the DB for which no model is"
    ],
    [
        "anymore, even if a model with the same name exists in another app.",
        "anymore, even if a model with the same name exists in"
    ],
    [
        "self.assertEqual(str(ct), \"Authentication and Authorization | group\")",
        "self.assertEqual(str(ct), \"Authentication and Authorization |"
    ],
    [
        "When using multiple databases, ContentType.objects.get_for_model() uses",
        "When using multiple"
    ],
    [
        "msg = \"Prefetch querysets cannot use raw(), values(), and values_list().\"",
        "msg = \"Prefetch querysets cannot use"
    ],
    [
        "msg = \"Prefetch querysets cannot use raw(), values(), and values_list().\"",
        "msg = \"Prefetch querysets cannot use raw(), values(),"
    ],
    [
        "\"The GenericForeignKey content type references the nonexistent \"",
        "\"The GenericForeignKey content type"
    ],
    [
        "\"GenericForeignKeys must use a ForeignKey to \"",
        "\"GenericForeignKeys must use a ForeignKey to"
    ],
    [
        "\"'Model.content_type' is not a ForeignKey to \"",
        "\"'Model.content_type' is not a"
    ],
    [
        "\"GenericForeignKeys must use a ForeignKey to \"",
        "\"GenericForeignKeys must use a ForeignKey"
    ],
    [
        "\"The GenericForeignKey object ID references the nonexistent \"",
        "\"The GenericForeignKey object ID references the nonexistent"
    ],
    [
        "\"Field names must not end with an underscore.\",",
        "\"Field names must not"
    ],
    [
        "\"Field defines a relation with model 'MissingModel', \"",
        "\"Field defines a relation with model 'MissingModel',"
    ],
    [
        "\"which is either not installed, or is abstract.\",",
        "\"which is either not installed, or"
    ],
    [
        "\"The GenericRelation defines a relation with the model \"",
        "\"The GenericRelation defines a relation"
    ],
    [
        "\"'contenttypes_tests.TaggedItem', but that model does not have a \"",
        "\"'contenttypes_tests.TaggedItem', but that model does not have"
    ],
    [
        "\"Field defines a relation with the model \"",
        "\"Field defines a relation with the"
    ],
    [
        "\"Update the relation to point at 'settings.TEST_SWAPPED_MODEL'.\"",
        "\"Update the relation to"
    ],
    [
        "\"Field names must not end with an underscore.\",",
        "\"Field names must not end"
    ],
    [
        "\"The contenttypes_tests.Foo ContentType should not be cached.\"",
        "\"The contenttypes_tests.Foo ContentType should not be"
    ],
    [
        "\"The cached contenttypes_tests.Foo ContentType should have \"",
        "\"The cached contenttypes_tests.Foo ContentType"
    ],
    [
        "The tests are shared with contenttypes_tests and so shouldn't import or",
        "The tests are shared with contenttypes_tests and"
    ],
    [
        "reference any models directly. Subclasses should inherit django.test.TestCase.",
        "reference any models directly."
    ],
    [
        "text=\"Which Beatle starts with the letter 'R'?\"",
        "text=\"Which Beatle starts with the letter"
    ],
    [
        "\"\"\"An answer that's not related isn't updated.\"\"\"",
        "\"\"\"An answer that's not related"
    ],
    [
        "[\"John\", \"Paul\", \"George\", \"Number five\", \"Ringo\"],",
        "[\"John\", \"Paul\", \"George\", \"Number five\","
    ],
    [
        "Tests for the order_with_respect_to Meta attribute.",
        "Tests for the"
    ],
    [
        "from .models import Answer, Dimension, Entity, Post, Question",
        "from .models import Answer, Dimension, Entity,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import"
    ],
    [
        "Check each_context contains the documented variables and that available_apps context",
        "Check each_context contains the documented variables and that"
    ],
    [
        "variable structure is the expected one.",
        "variable structure is the expected"
    ],
    [
        "\"\"\"AdminSite.get_action() returns an action even if it's disabled.\"\"\"",
        "\"\"\"AdminSite.get_action() returns an action"
    ],
    [
        "\"\"\"A user with no password can be added.",
        "\"\"\"A user with no password can be"
    ],
    [
        "Enabling/disabling the usable password field shows/hides the password",
        "Enabling/disabling the usable password field"
    ],
    [
        "\"\"\"A user can have their password changed or unset.",
        "\"\"\"A user can have their password changed"
    ],
    [
        "Enabling/disabling the usable password field shows/hides the password",
        "Enabling/disabling the usable password field shows/hides the"
    ],
    [
        "fields and the warning about password lost.",
        "fields and the warning"
    ],
    [
        "A simple section that links to articles, to test linking to related items",
        "A simple section that links to articles, to test linking to related"
    ],
    [
        "A simple article to test admin views. Test backwards compatibility.",
        "A simple article to test"
    ],
    [
        "section = models.ForeignKey(Section, models.CASCADE, null=True, blank=True)",
        "section = models.ForeignKey(Section, models.CASCADE, null=True,"
    ],
    [
        "A simple book that has chapters.",
        "A simple book that has"
    ],
    [
        "author = models.ForeignKey(User, models.SET_NULL, blank=True, null=True)",
        "author = models.ForeignKey(User,"
    ],
    [
        "guest_author = models.ForeignKey(User, models.SET_NULL, blank=True, null=True)",
        "guest_author = models.ForeignKey(User, models.SET_NULL, blank=True,"
    ],
    [
        "color = models.ForeignKey(Color, models.CASCADE, limit_choices_to={\"warm\": True})",
        "color = models.ForeignKey(Color, models.CASCADE, limit_choices_to={\"warm\":"
    ],
    [
        "return \"by %s from %s\" % (self.leader, self.country)",
        "return \"by %s from %s\""
    ],
    [
        "A simple persona associated with accounts, to test inlining of related",
        "A simple persona associated with accounts, to test inlining"
    ],
    [
        "accounts which inherit from a common accounts class.",
        "accounts which inherit from"
    ],
    [
        "A simple, generic account encapsulating the information shared by all",
        "A simple, generic account encapsulating the"
    ],
    [
        "return \"%s: %s\" % (self.servicename, self.username)",
        "return \"%s: %s\" %"
    ],
    [
        "\"\"\"A service-specific account of type Foo.\"\"\"",
        "\"\"\"A service-specific account"
    ],
    [
        "\"\"\"A service-specific account of type Bar.\"\"\"",
        "\"\"\"A service-specific account of type"
    ],
    [
        "return \"%s (%s)\" % (self.name, self.email)",
        "return \"%s (%s)\" %"
    ],
    [
        "Used to check autocomplete to_field resolution when ForeignKey is PK.",
        "Used to check autocomplete to_field resolution when ForeignKey"
    ],
    [
        "return \"Primary key = %s\" % self.id",
        "return \"Primary key ="
    ],
    [
        "help_text=\"Some help text for the content (with Unicode ŠĐĆŽćžšđ)\"",
        "help_text=\"Some help text for the content (with Unicode"
    ],
    [
        "help_text=\"Some help text for the date (with Unicode ŠĐĆŽćžšđ)\",",
        "help_text=\"Some help text for the date"
    ],
    [
        "\"Because we all know there's only one real use case for GFKs.\"",
        "\"Because we all know there's only one"
    ],
    [
        "plot = models.OneToOneField(Plot, models.CASCADE, null=True, blank=True)",
        "plot = models.OneToOneField(Plot, models.CASCADE,"
    ],
    [
        "\"\"\"Secret! Not registered with the admin!\"\"\"",
        "\"\"\"Secret! Not registered with the"
    ],
    [
        "\"\"\"Secret! Not registered with the admin!\"\"\"",
        "\"\"\"Secret! Not registered with the"
    ],
    [
        "owner = models.ForeignKey(User, models.SET_NULL, null=True, blank=True)",
        "owner = models.ForeignKey(User,"
    ],
    [
        "be localized in prepopulated_fields_js.html or it might end up breaking",
        "be localized in prepopulated_fields_js.html or it might end"
    ],
    [
        "choices=((\"option one\", \"Option One\"), (\"option two\", \"Option Two\")),",
        "choices=((\"option one\", \"Option One\"),"
    ],
    [
        "fk = models.ForeignKey(\"self\", models.CASCADE, blank=True, null=True)",
        "fk = models.ForeignKey(\"self\", models.CASCADE,"
    ],
    [
        "choices=((\"option one\", \"Option One\"), (\"option two\", \"Option Two\")),",
        "choices=((\"option one\", \"Option One\"), (\"option"
    ],
    [
        "Model whose show_delete in admin change_view has been disabled",
        "Model whose show_delete in admin change_view has been"
    ],
    [
        "Model whose change_view is disabled in admin",
        "Model whose change_view is disabled"
    ],
    [
        "Dummy class for testing message_user functions on ModelAdmin",
        "Dummy class for testing message_user functions"
    ],
    [
        "Simple model with nothing on it for use in testing",
        "Simple model with nothing on"
    ],
    [
        "Model where the validation of child foreign-key relationships depends",
        "Model where the validation of child foreign-key"
    ],
    [
        "Model that depends on validation of the parent class for one of its",
        "Model that depends on validation of the parent class for one"
    ],
    [
        "\"\"\"Proxy a model with a different app_label.\"\"\"",
        "\"\"\"Proxy a model with"
    ],
    [
        "\"\"\"A custom action defined in a ModelAdmin method.\"\"\"",
        "\"\"\"A custom action defined"
    ],
    [
        "confirmation, \"Are you sure you want to delete the selected subscribers?\"",
        "confirmation, \"Are you sure you want to delete the selected"
    ],
    [
        "response, \"Are you sure you want to delete the selected subscribers?\"",
        "response, \"Are you sure you want to"
    ],
    [
        "If USE_THOUSAND_SEPARATOR is set, the ids for the objects selected for",
        "If USE_THOUSAND_SEPARATOR is set, the ids"
    ],
    [
        "The default delete action where some related objects are protected",
        "The default delete action where some"
    ],
    [
        "response, \"would require deleting the following protected related objects\"",
        "response, \"would require deleting the following protected related"
    ],
    [
        "response, \"would require deleting the following protected related objects\"",
        "response, \"would require deleting the following"
    ],
    [
        "The default delete action doesn't break if a ModelAdmin removes the",
        "The default delete action doesn't break if a"
    ],
    [
        "\"\"\"A custom action may be defined in a function.\"\"\"",
        "\"\"\"A custom action may be defined in"
    ],
    [
        "\"\"\"Another custom action defined in a function.\"\"\"",
        "\"\"\"Another custom action defined"
    ],
    [
        "Actions which don't return an HttpResponse are redirected to the same",
        "Actions which don't return an HttpResponse"
    ],
    [
        "page, retaining the querystring (which may contain changelist info).",
        "page, retaining the querystring (which"
    ],
    [
        "\"\"\"A custom action may return a StreamingHttpResponse.\"\"\"",
        "\"\"\"A custom action may return a"
    ],
    [
        "self.assertEqual(content, b\"This is the content of the file\")",
        "self.assertEqual(content, b\"This is the"
    ],
    [
        "self.assertEqual(response.content, b\"No permission to perform this action\")",
        "self.assertEqual(response.content, b\"No permission to perform"
    ],
    [
        "\"\"\"A ModelAdmin might not have any actions.\"\"\"",
        "\"\"\"A ModelAdmin might not"
    ],
    [
        "msg_prefix=\"Found an unexpected action toggle checkboxbox in response\",",
        "msg_prefix=\"Found an unexpected action toggle"
    ],
    [
        "A ModelAdmin without any actions still has jQuery included on the page.",
        "A ModelAdmin without any actions still has jQuery included on"
    ],
    [
        "\"jQuery missing from admin pages for model with no admin actions\"",
        "\"jQuery missing from admin pages for model with"
    ],
    [
        "\"\"\"The checkbox column class is present in the response.\"\"\"",
        "\"\"\"The checkbox column class is"
    ],
    [
        "The action form's media is included in the changelist view's media.",
        "The action form's media is included in the changelist"
    ],
    [
        "User sees a warning when 'Go' is pressed and no items are selected.",
        "User sees a warning when 'Go' is pressed and no items are"
    ],
    [
        "\"Items must be selected in order to perform actions on them. No items have \"",
        "\"Items must be selected in order to perform actions on them. No items"
    ],
    [
        "User sees a warning when 'Go' is pressed and no action is selected.",
        "User sees a warning when 'Go' is pressed"
    ],
    [
        "response = self.client.get(changelist_url + \"?%s\" % IS_POPUP_VAR)",
        "response = self.client.get(changelist_url +"
    ],
    [
        "Success on popups shall be rendered from template in order to allow",
        "Success on popups shall be rendered from template in order to"
    ],
    [
        "Permission is denied if the user doesn't have delete permission for the",
        "Permission is denied if the user doesn't have delete permission for"
    ],
    [
        "Permission is denied if the user doesn't have delete permission for a",
        "Permission is denied if the user doesn't have"
    ],
    [
        "Admin's model history change messages use form labels instead of",
        "Admin's model history change messages"
    ],
    [
        "city = City.objects.create(name=\"My City Name\", state=state)",
        "city = City.objects.create(name=\"My City Name\","
    ],
    [
        "\"Changed State name (from form’s Meta.labels), \"",
        "\"Changed State name (from form’s"
    ],
    [
        "\"Changed City verbose_name for city “%s”.\" % city,",
        "\"Changed City verbose_name for"
    ],
    [
        "from . import admin as base_admin",
        "from . import"
    ],
    [
        "if not user.is_active or not (user.is_staff or user.has_perm(PERMISSION_NAME)):",
        "if not user.is_active or not (user.is_staff or"
    ],
    [
        "READ_ONLY_METHODS = {\"get\", \"options\", \"head\", \"trace\"}",
        "READ_ONLY_METHODS = {\"get\", \"options\", \"head\","
    ],
    [
        "if model._meta.app_label in {\"auth\", \"sessions\", \"contenttypes\"}:",
        "if model._meta.app_label in"
    ],
    [
        "if model._meta.app_label in {\"auth\", \"sessions\", \"contenttypes\"}:",
        "if model._meta.app_label in {\"auth\", \"sessions\","
    ],
    [
        "A second, custom AdminSite -- see tests.CustomAdminSiteTests.",
        "A second, custom AdminSite"
    ],
    [
        "from . import admin as base_admin",
        "from . import admin as"
    ],
    [
        "return HttpResponse(\"Django is a magical pony!\")",
        "return HttpResponse(\"Django is"
    ],
    [
        "self.fields[\"old_password\"].label = \"Custom old password label\"",
        "self.fields[\"old_password\"].label = \"Custom old password"
    ],
    [
        "from django.http import HttpResponse, JsonResponse, StreamingHttpResponse",
        "from django.http import HttpResponse, JsonResponse,"
    ],
    [
        "(\"Some fields\", {\"classes\": (\"collapse\",), \"fields\": (\"title\", \"content\")}),",
        "(\"Some fields\", {\"classes\": (\"collapse\",), \"fields\": (\"title\","
    ],
    [
        "(\"Some other fields\", {\"classes\": (\"wide\",), \"fields\": (\"date\", \"section\")}),",
        "(\"Some other fields\", {\"classes\": (\"wide\",),"
    ],
    [
        "{\"classes\": (\"wide\",), \"fields\": (\"date\", \"section\", \"sub_section\")},",
        "{\"classes\": (\"wide\",), \"fields\":"
    ],
    [
        "\"I hereby inform you that some user deleted me\",",
        "\"I hereby inform you that some"
    ],
    [
        "def save_model(self, request, obj, form, change=True):",
        "def save_model(self, request, obj,"
    ],
    [
        "\"I hereby inform you that some user created me\",",
        "\"I hereby inform you that some user"
    ],
    [
        "\"\"\"Only allow changing objects with even id number\"\"\"",
        "\"\"\"Only allow changing objects with even id"
    ],
    [
        "Tests various hooks for using custom templates and contexts.",
        "Tests various hooks for using custom templates and"
    ],
    [
        "list_filter = (\"color\", \"color__warm\", \"color__value\", \"pub_date\")",
        "list_filter = (\"color\", \"color__warm\", \"color__value\","
    ],
    [
        "list_display = (\"leader\", \"country\", \"expected\", \"sketch\")",
        "list_display = (\"leader\","
    ],
    [
        "if person and alive and person.name == \"Grace Hopper\":",
        "if person and alive and person.name =="
    ],
    [
        "raise ValidationError(\"Grace is not a Zombie\")",
        "raise ValidationError(\"Grace is not a"
    ],
    [
        "\"This is the test email from an admin action\",",
        "\"This is the test email from"
    ],
    [
        "\"This is the test email from a function action\",",
        "\"This is the test email from"
    ],
    [
        "buf = StringIO(\"This is the content of the file\")",
        "buf = StringIO(\"This is the content of the"
    ],
    [
        "actions = [redirect_to, external_mail, download, no_perm]",
        "actions = [redirect_to, external_mail, download,"
    ],
    [
        "def save_related(self, request, form, formsets, change):",
        "def save_related(self, request,"
    ],
    [
        "child.name = child.name + \" \" + last_name",
        "child.name = child.name + \""
    ],
    [
        "list_display = [\"iso\", \"shortlist\", \"english_name\", \"name\"]",
        "list_display = [\"iso\","
    ],
    [
        "return \"%d amount of cool.\" % instance.pk",
        "return \"%d amount of cool.\" %"
    ],
    [
        "\"posted\": \"Overridden help text for the date\",",
        "\"posted\": \"Overridden help text"
    ],
    [
        "A ModelAdmin with a custom get_queryset() method that uses defer(), to test",
        "A ModelAdmin with a custom get_queryset()"
    ],
    [
        "verbose_name display in messages shown after adding/editing CoverLetter",
        "verbose_name display in messages shown after adding/editing"
    ],
    [
        "instances. Note that the CoverLetter model defines a __str__ method.",
        "instances. Note that the CoverLetter model defines a"
    ],
    [
        "A ModelAdmin with a custom get_queryset() method that uses only(), to test",
        "A ModelAdmin with a custom get_queryset()"
    ],
    [
        "verbose_name display in messages shown after adding/editing Paper",
        "verbose_name display in messages shown after adding/editing"
    ],
    [
        "A ModelAdmin with a custom get_queryset() method that uses defer(), to test",
        "A ModelAdmin with a custom get_queryset() method that uses defer(),"
    ],
    [
        "verbose_name display in messages shown after adding/editing ShortMessage",
        "verbose_name display in messages shown after adding/editing"
    ],
    [
        "A ModelAdmin with a custom get_queryset() method that uses only(), to test",
        "A ModelAdmin with a custom get_queryset() method that uses only(),"
    ],
    [
        "verbose_name display in messages shown after adding/editing Telegram",
        "verbose_name display in messages shown"
    ],
    [
        "instances. Note that the Telegram model defines a __str__ method.",
        "instances. Note that the Telegram"
    ],
    [
        "list_display = (\"name\", \"age\", \"is_employee\", \"colored_name\")",
        "list_display = (\"name\", \"age\","
    ],
    [
        "return [p for p in urlpatterns if p.name and not p.name.endswith(\"_change\")]",
        "return [p for p in urlpatterns if p.name and"
    ],
    [
        "Form to test child dependency on parent object's validation",
        "Form to test child dependency on"
    ],
    [
        "if parent.family_name and parent.family_name != self.cleaned_data.get(",
        "if parent.family_name and parent.family_name"
    ],
    [
        "\"Children must share a family name with their parents \"",
        "\"Children must share a family name with their"
    ],
    [
        "+ \"in this contrived test case\"",
        "+ \"in this contrived"
    ],
    [
        "labels = {\"name\": \"State name (from form’s Meta.labels)\"}",
        "labels = {\"name\": \"State"
    ],
    [
        "def get_formset_kwargs(self, request, obj, inline, prefix):",
        "def get_formset_kwargs(self, request, obj, inline,"
    ],
    [
        "if request.is_add_view and obj is not None:",
        "if request.is_add_view and obj is"
    ],
    [
        "\"'obj' passed to get_formsets_with_inlines wasn't None during add_view\"",
        "\"'obj' passed to get_formsets_with_inlines wasn't None during"
    ],
    [
        "if not request.is_add_view and obj is None:",
        "if not request.is_add_view and obj"
    ],
    [
        "\"'obj' passed to get_formsets_with_inlines was None during change_view\"",
        "\"'obj' passed to get_formsets_with_inlines was"
    ],
    [
        "response, '<a href=\"%s\" aria-current=\"page\">Users</a>' % url",
        "response, '<a href=\"%s\" aria-current=\"page\">Users</a>' %"
    ],
    [
        "from urllib.parse import parse_qsl, urljoin, urlsplit",
        "from urllib.parse import parse_qsl,"
    ],
    [
        "from django.contrib.admin.models import ADDITION, DELETION, LogEntry",
        "from django.contrib.admin.models import ADDITION, DELETION,"
    ],
    [
        "from django.contrib.auth.models import Group, Permission, User",
        "from django.contrib.auth.models import"
    ],
    [
        "from django.core.files import temp as tempfile",
        "from django.core.files import temp"
    ],
    [
        "from django.urls import NoReverseMatch, resolve, reverse",
        "from django.urls import"
    ],
    [
        "ERROR_MESSAGE = \"Please enter the correct username and password \\",
        "ERROR_MESSAGE = \"Please enter the correct username and"
    ],
    [
        "for a staff account. Note that both fields may be case-sensitive.\"",
        "for a staff account. Note that both"
    ],
    [
        "\"\"\"Makes one aware datetime for each supported time zone provider.\"\"\"",
        "\"\"\"Makes one aware datetime for each supported"
    ],
    [
        "Helper methods for extracting data from AdminForm.",
        "Helper methods for extracting data from"
    ],
    [
        "Return a list of AdminFields for the AdminForm in the response.",
        "Return a list of AdminFields for the AdminForm in"
    ],
    [
        "Return the readonly fields for the response's AdminForm.",
        "Return the readonly fields for the"
    ],
    [
        "return [f for f in self.get_admin_form_fields(response) if f.is_readonly]",
        "return [f for f in"
    ],
    [
        "Return the readonly field for the given field_name.",
        "Return the readonly field for"
    ],
    [
        "(failing_msg or \"\") + \"\\nResponse:\\n\" + response.text,",
        "(failing_msg or \"\") + \"\\nResponse:\\n\""
    ],
    [
        "If you leave off the trailing slash, app should redirect and add it.",
        "If you leave off the trailing slash, app should"
    ],
    [
        "A smoke test to ensure GET on the add_view works.",
        "A smoke test to ensure GET on"
    ],
    [
        "msg_prefix=\"Couldn't find an input with the right value in the response\",",
        "msg_prefix=\"Couldn't find an input with the"
    ],
    [
        "A smoke test to ensure GET on the change_view works.",
        "A smoke test to ensure GET on the change_view"
    ],
    [
        "GET on the change_view (when passing a string as the PK argument for a",
        "GET on the change_view (when passing a string"
    ],
    [
        "model with an integer PK field) redirects to the index page with a",
        "model with an integer PK field) redirects"
    ],
    [
        "message saying the object doesn't exist.",
        "message saying the"
    ],
    [
        "[\"section with ID “abc/<b>” doesn’t exist. Perhaps it was deleted?\"],",
        "[\"section with ID “abc/<b>” doesn’t exist. Perhaps"
    ],
    [
        "GET on the change_view (for inherited models) redirects to the index",
        "GET on the change_view (for inherited"
    ],
    [
        "page with a message saying the object doesn't exist.",
        "page with a message saying"
    ],
    [
        "[\"super villain with ID “abc” doesn’t exist. Perhaps it was deleted?\"],",
        "[\"super villain with ID “abc” doesn’t exist. Perhaps it was"
    ],
    [
        "A smoke test to ensure POST on add_view works.",
        "A smoke test to ensure POST on add_view"
    ],
    [
        "\"\"\"HTTP response from a popup is properly escaped.\"\"\"",
        "\"\"\"HTTP response from a popup is"
    ],
    [
        "A smoke test to ensure POST on edit_view works.",
        "A smoke test to ensure POST on edit_view"
    ],
    [
        "Should be able to \"Save as new\" while also deleting an inline.",
        "Should be able to \"Save as new\" while also deleting"
    ],
    [
        "Ensure we can sort on a list_display field that is a callable",
        "Ensure we can sort on a list_display field that is a"
    ],
    [
        "\"Results of sorting on callable are out of order.\",",
        "\"Results of sorting on callable are"
    ],
    [
        "\"Results of sorting on callable are out of order.\",",
        "\"Results of sorting on callable are out of"
    ],
    [
        "\"Results of sorting on property are out of order.\",",
        "\"Results of sorting on property are"
    ],
    [
        "\"Results of sorting on property are out of order.\",",
        "\"Results of sorting on property"
    ],
    [
        "\"\"\"Query expressions may be used for admin_order_field.\"\"\"",
        "\"\"\"Query expressions may be used for"
    ],
    [
        "\"Results of sorting on callable are out of order.\",",
        "\"Results of sorting on callable are"
    ],
    [
        "\"Results of sorting on callable are out of order.\",",
        "\"Results of sorting on callable are out of"
    ],
    [
        "\"Results of sorting on callable are out of order.\",",
        "\"Results of sorting on callable are"
    ],
    [
        "\"Results of sorting on callable are out of order.\",",
        "\"Results of sorting on callable are"
    ],
    [
        "Ensure we can sort on a list_display field that is a Model method",
        "Ensure we can sort on a list_display"
    ],
    [
        "\"Results of sorting on Model method are out of order.\",",
        "\"Results of sorting on Model method are"
    ],
    [
        "\"Results of sorting on Model method are out of order.\",",
        "\"Results of sorting on Model method"
    ],
    [
        "Ensure we can sort on a list_display field that is a ModelAdmin method",
        "Ensure we can sort on a list_display field"
    ],
    [
        "\"Results of sorting on ModelAdmin method are out of order.\",",
        "\"Results of sorting on ModelAdmin method are out of"
    ],
    [
        "\"Results of sorting on ModelAdmin method are out of order.\",",
        "\"Results of sorting on ModelAdmin method are out"
    ],
    [
        "Ensure we can sort on a list_display field that is a ModelAdmin",
        "Ensure we can sort on a list_display"
    ],
    [
        "method in reverse order (i.e. admin_order_field uses the '-' prefix)",
        "method in reverse order (i.e. admin_order_field uses the"
    ],
    [
        "\"Results of sorting on ModelAdmin method are out of order.\",",
        "\"Results of sorting on ModelAdmin"
    ],
    [
        "\"Results of sorting on ModelAdmin method are out of order.\",",
        "\"Results of sorting on ModelAdmin method are out of"
    ],
    [
        "\"Results of sorting on ModelAdmin method are out of order.\",",
        "\"Results of sorting on ModelAdmin method"
    ],
    [
        "\"Results of sorting on ModelAdmin method are out of order.\",",
        "\"Results of sorting on ModelAdmin method"
    ],
    [
        "If no ordering is defined in `ModelAdmin.ordering` or in the query",
        "If no ordering is defined in `ModelAdmin.ordering` or in"
    ],
    [
        "string, then the underlying order of the queryset should not be",
        "string, then the underlying order of the"
    ],
    [
        "changed, even if it is defined in `Modeladmin.get_queryset()`.",
        "changed, even if it is"
    ],
    [
        "The admin shows default sort indicators for all kinds of 'ordering'",
        "The admin shows default sort indicators"
    ],
    [
        "fields: field names, method on the model admin and model itself, and",
        "fields: field names, method on the model admin and"
    ],
    [
        "self.assertContentBefore(response, \"The First Item\", \"The Middle Item\")",
        "self.assertContentBefore(response, \"The First Item\", \"The Middle"
    ],
    [
        "self.assertContentBefore(response, \"The Middle Item\", \"The Last Item\")",
        "self.assertContentBefore(response, \"The Middle Item\", \"The"
    ],
    [
        "\"\"\"Joins shouldn't be performed for <FK>_id fields in list display.\"\"\"",
        "\"\"\"Joins shouldn't be performed for <FK>_id fields"
    ],
    [
        "Admin changelist filters do not contain objects excluded via",
        "Admin changelist filters do not contain"
    ],
    [
        "msg_prefix=\"Expected filter not found in changelist view\",",
        "msg_prefix=\"Expected filter not found in"
    ],
    [
        "msg_prefix=\"Changelist filter not correctly limited by limit_choices_to\",",
        "msg_prefix=\"Changelist filter not correctly"
    ],
    [
        "msg_prefix=\"Expected facet filter toggle not found in changelist view\",",
        "msg_prefix=\"Expected facet filter toggle not found in changelist"
    ],
    [
        "msg_prefix=\"Expected facet filter toggle not found in changelist view\",",
        "msg_prefix=\"Expected facet filter toggle not found in"
    ],
    [
        "msg_prefix=\"Expected not to find facet filter toggle in changelist view\",",
        "msg_prefix=\"Expected not to find facet filter"
    ],
    [
        "msg_prefix=\"Expected not to find facet filter toggle in changelist view\",",
        "msg_prefix=\"Expected not to find facet filter toggle in"
    ],
    [
        "msg_prefix=\"Expected not to find facet filter toggle in changelist view\",",
        "msg_prefix=\"Expected not to find facet"
    ],
    [
        "msg_prefix=\"Expected not to find facet filter toggle in changelist view\",",
        "msg_prefix=\"Expected not to find facet"
    ],
    [
        "\"values\": [c.id for c in Chapter.objects.all()],",
        "\"values\": [c.id for"
    ],
    [
        "\"test\": lambda obj, value: obj.chap.id == value,",
        "\"test\": lambda obj, value:"
    ],
    [
        "\"values\": [c.title for c in Chapter.objects.all()],",
        "\"values\": [c.title for c"
    ],
    [
        "\"test\": lambda obj, value: obj.chap.title == value,",
        "\"test\": lambda obj, value: obj.chap.title =="
    ],
    [
        "\"values\": [b.id for b in Book.objects.all()],",
        "\"values\": [b.id for b"
    ],
    [
        "\"test\": lambda obj, value: obj.chap.book.id == value,",
        "\"test\": lambda obj, value:"
    ],
    [
        "\"values\": [b.name for b in Book.objects.all()],",
        "\"values\": [b.name for b in"
    ],
    [
        "\"test\": lambda obj, value: obj.chap.book.name == value,",
        "\"test\": lambda obj, value:"
    ],
    [
        "\"values\": [p.id for p in Promo.objects.all()],",
        "\"values\": [p.id for"
    ],
    [
        "\"values\": [p.name for p in Promo.objects.all()],",
        "\"values\": [p.name for p in"
    ],
    [
        "\"values\": [p.id for p in Book.objects.all()],",
        "\"values\": [p.id for p"
    ],
    [
        "\"\"\"Ensure incorrect lookup parameters are handled gracefully.\"\"\"",
        "\"\"\"Ensure incorrect lookup parameters are"
    ],
    [
        "Ensures the admin changelist shows correct values in the relevant column",
        "Ensures the admin changelist shows correct values in the relevant"
    ],
    [
        "for rows corresponding to instances of a model in which a named group",
        "for rows corresponding to instances of a model in which"
    ],
    [
        "has been used in the choices option of a field.",
        "has been used in the choices option of"
    ],
    [
        "\"Changelist table isn't showing the right human-readable values \"",
        "\"Changelist table isn't showing the right"
    ],
    [
        "\"set by a model field 'choices' option named group.\"",
        "\"set by a model field 'choices' option"
    ],
    [
        "Ensures the filter UI shows correctly when at least one named group has",
        "Ensures the filter UI shows correctly when at least one named"
    ],
    [
        "been used in the choices option of a model field.",
        "been used in the choices option of a"
    ],
    [
        "\"Changelist filter isn't showing options contained inside a model \"",
        "\"Changelist filter isn't showing options contained inside a model"
    ],
    [
        "\"The boolean and empty_value arguments to the @display decorator \"",
        "\"The boolean and empty_value arguments to the"
    ],
    [
        "if the default language is non-English but the selected language",
        "if the default language is non-English but the"
    ],
    [
        "Makes sure that the fallback language is still working properly",
        "Makes sure that the fallback language is still"
    ],
    [
        "in cases where the selected language cannot be found.",
        "in cases where the selected"
    ],
    [
        "when the selected language cannot be found.",
        "when the selected language cannot"
    ],
    [
        "ForeignKey 'limit_choices_to' should be allowed, otherwise raw_id_fields",
        "ForeignKey 'limit_choices_to' should be allowed, otherwise"
    ],
    [
        "Tests if the \"change password\" link in the admin is hidden if the User",
        "Tests if the \"change password\" link in"
    ],
    [
        "does not have a usable password set.",
        "does not have a usable"
    ],
    [
        "'The \"change password\" link should not be displayed if a user does not '",
        "'The \"change password\" link should not be displayed if a user"
    ],
    [
        "The 'show_delete' context variable in the admin's change view controls",
        "The 'show_delete' context variable in the admin's change view"
    ],
    [
        "the display of the delete button.",
        "the display of the delete"
    ],
    [
        "\"\"\"Changes to ManyToManyFields are included in the object's history.\"\"\"",
        "\"\"\"Changes to ManyToManyFields are included in"
    ],
    [
        "post_data = {\"name\": pizza.name, \"toppings\": [cheese.pk]}",
        "post_data = {\"name\":"
    ],
    [
        "AttributeErrors are allowed to bubble when raised inside a change list",
        "AttributeErrors are allowed to bubble when"
    ],
    [
        "view. Requires a model to be created so there's something to display.",
        "view. Requires a model to be created so there's something"
    ],
    [
        "ModelAdmin.changelist_view shouldn't result in a NoReverseMatch if url",
        "ModelAdmin.changelist_view shouldn't result in a NoReverseMatch if"
    ],
    [
        "response, '<th class=\"field-__str__\">%s</th>' % o, html=True",
        "response, '<th class=\"field-__str__\">%s</th>' % o,"
    ],
    [
        "response, '<th scope=\"col\" class=\"sortable column-%s\">' % field_name",
        "response, '<th scope=\"col\" class=\"sortable"
    ],
    [
        "response, '<th scope=\"col\" class=\"column-%s\">' % field_name",
        "response, '<th scope=\"col\""
    ],
    [
        "response, '<th scope=\"col\" class=\"column-%s\">' % field_name",
        "response, '<th scope=\"col\" class=\"column-%s\">'"
    ],
    [
        "\"<title>Admin_Views administration | Django site admin</title>\",",
        "\"<title>Admin_Views administration | Django"
    ],
    [
        "\"<title>Admin_Views administration | Django site admin</title>\",",
        "\"<title>Admin_Views administration |"
    ],
    [
        "The admin/change_form.html template uses block.super in the",
        "The admin/change_form.html template uses"
    ],
    [
        "response, '<input type=\"text\" name=\"username\" value=\"super\" class=\"hidden\">'",
        "response, '<input type=\"text\" name=\"username\" value=\"super\""
    ],
    [
        "\"Your password can’t be too similar to your other personal information.\"",
        "\"Your password can’t be too similar to"
    ],
    [
        "\"</li><li>Your password can’t be entirely numeric.</li></ul></div>\",",
        "\"</li><li>Your password can’t be"
    ],
    [
        "\"Enter the same password as before, for verification.</div>\",",
        "\"Enter the same password"
    ],
    [
        "The admin/index.html template uses block.super in the bodyclass block.",
        "The admin/index.html template uses block.super in"
    ],
    [
        "The admin/login.html template uses block.super in the",
        "The admin/login.html template uses block.super"
    ],
    [
        "A custom template can be used to render an admin filter.",
        "A custom template can be used"
    ],
    [
        "\"form_url\", response.context, msg=\"form_url not present in response.context\"",
        "\"form_url\", response.context, msg=\"form_url not present"
    ],
    [
        "The behavior for setting initial form data can be overridden in the",
        "The behavior for setting initial form data can be overridden in"
    ],
    [
        "ModelAdmin class. Usually, the initial value is set via the GET params.",
        "ModelAdmin class. Usually, the initial value is"
    ],
    [
        "The minified versions of the JS files are only used when DEBUG is False.",
        "The minified versions of the JS files are only"
    ],
    [
        "\"\"\"'save as' creates a new person\"\"\"",
        "\"\"\"'save as' creates"
    ],
    [
        "Saving a new object using \"Save as new\" redirects to the changelist",
        "Saving a new object using \"Save as new\""
    ],
    [
        "instead of the change view when ModelAdmin.save_as_continue=False.",
        "instead of the change"
    ],
    [
        "When you click \"Save as new\" and have a validation error,",
        "When you click \"Save as new\" and have a validation"
    ],
    [
        "you only see the \"Save as new\" button and not the other save buttons,",
        "you only see the \"Save as new\" button and not the other save"
    ],
    [
        "and that only the \"Save as\" button is visible.",
        "and that only the \"Save as\""
    ],
    [
        "self.assertContains(response, \"Please correct the errors below.\")",
        "self.assertContains(response, \"Please correct"
    ],
    [
        "self.assertContains(response, \"Please correct the error below.\")",
        "self.assertContains(response, \"Please correct"
    ],
    [
        "self.assertContains(response, \"Please correct the error below.\")",
        "self.assertContains(response, \"Please correct"
    ],
    [
        "self.assertContains(response, \"Hello from a custom login template\")",
        "self.assertContains(response, \"Hello from a custom"
    ],
    [
        "self.assertContains(response, \"Hello from a custom logout template\")",
        "self.assertContains(response, \"Hello from a"
    ],
    [
        "self.assertContains(response, \"Hello from a custom index template *bar*\")",
        "self.assertContains(response, \"Hello from a custom"
    ],
    [
        "self.assertContains(response, \"Hello from a custom app_index template\")",
        "self.assertContains(response, \"Hello from a custom app_index"
    ],
    [
        "response, \"Hello from a custom password change form template\"",
        "response, \"Hello from a custom password change"
    ],
    [
        "response, \"Hello from a custom password change done template\"",
        "response, \"Hello from a custom"
    ],
    [
        "self.assertEqual(response.content, b\"Django is a magical pony!\")",
        "self.assertEqual(response.content, b\"Django is"
    ],
    [
        "\"\"\"Return the permission object, for the Model\"\"\"",
        "\"\"\"Return the permission object,"
    ],
    [
        "Make sure only staff members can log in.",
        "Make sure only staff members can"
    ],
    [
        "Successful posts to the login page will redirect to the original url.",
        "Successful posts to the login page will"
    ],
    [
        "Unsuccessful attempts will continue to render the login page with",
        "Unsuccessful attempts will continue to render the login page"
    ],
    [
        "login_url = \"%s?next=%s\" % (reverse(\"admin:login\"), reverse(\"admin:index\"))",
        "login_url = \"%s?next=%s\" % (reverse(\"admin:login\"),"
    ],
    [
        "login.context[\"form\"], \"username\", [\"This field is required.\"]",
        "login.context[\"form\"], \"username\", [\"This field"
    ],
    [
        "Login redirect should be to the admin index page when going directly to",
        "Login redirect should be to the admin index page when"
    ],
    [
        "redirect_url = \"%s?%s\" % (self.index_url, query_string)",
        "redirect_url = \"%s?%s\" % (self.index_url,"
    ],
    [
        "login_url = \"%s?next=%s\" % (reverse(\"admin:login\"), reverse(\"admin:index\"))",
        "login_url = \"%s?next=%s\" % (reverse(\"admin:login\"),"
    ],
    [
        "A logged-in non-staff user trying to access the admin index should be",
        "A logged-in non-staff user trying to access the admin"
    ],
    [
        "presented with the login page and a hint indicating that the current",
        "presented with the login page and a hint indicating"
    ],
    [
        "user doesn't have access to it.",
        "user doesn't have access to"
    ],
    [
        "hint_template = \"You are authenticated as {}\"",
        "hint_template = \"You are authenticated as"
    ],
    [
        "\"\"\"Test add view restricts access and actually adds items.\"\"\"",
        "\"\"\"Test add view restricts access and"
    ],
    [
        "self.assertContains(response, \"<title>Add article | Django site admin</title>\")",
        "self.assertContains(response, \"<title>Add article |"
    ],
    [
        "response, '<input type=\"submit\" value=\"Save and view\" name=\"_continue\">'",
        "response, '<input type=\"submit\" value=\"Save and view\""
    ],
    [
        "'<li class=\"success\">The article “Døm ikke” was added successfully.</li>',",
        "'<li class=\"success\">The article “Døm"
    ],
    [
        "change_list_link = '&rsaquo; <a href=\"%s\">Articles</a>' % reverse(",
        "change_list_link = '&rsaquo; <a href=\"%s\">Articles</a>'"
    ],
    [
        "\"User restricted to add permission is given link to change list view \"",
        "\"User restricted to add permission is given link to change list view"
    ],
    [
        "\"Unrestricted user is not given link to change list view in \"",
        "\"Unrestricted user is not given link to change list view in"
    ],
    [
        "\"\"\"User with add permission to a section but view-only for inlines.\"\"\"",
        "\"\"\"User with add permission to a"
    ],
    [
        "[obj for (request, obj), _ in has_change_permission.call_args_list],",
        "[obj for (request, obj), _"
    ],
    [
        "\"\"\"Change view should restrict access and allow users to edit items.\"\"\"",
        "\"\"\"Change view should restrict access and"
    ],
    [
        "\"<title>Select article to view | Django site admin</title>\",",
        "\"<title>Select article to view | Django"
    ],
    [
        "self.assertContains(response, \"<title>View article | Django site admin</title>\")",
        "self.assertContains(response, \"<title>View article | Django site"
    ],
    [
        "\"<title>Select article to change | Django site admin</title>\",",
        "\"<title>Select article to change"
    ],
    [
        "\"<title>Change article | Django site admin</title>\",",
        "\"<title>Change article | Django"
    ],
    [
        "\"Singular error message not found in response to post with one error\"",
        "\"Singular error message not found in response to post with one"
    ],
    [
        "\"Plural error message not found in response to post with multiple \"",
        "\"Plural error message not found in"
    ],
    [
        "The object should be read-only if the user has permission to view it",
        "The object should be read-only if the"
    ],
    [
        "and change objects of that type but not to change the current object.",
        "and change objects of that type but"
    ],
    [
        "self.assertContains(response, \"<title>View article | Django site admin</title>\")",
        "self.assertContains(response, \"<title>View article | Django"
    ],
    [
        "'Save as new' should raise PermissionDenied for users without the 'add'",
        "'Save as new' should raise PermissionDenied for users without the"
    ],
    [
        "User with change permission to a section but view-only for inlines.",
        "User with change permission to a section but view-only"
    ],
    [
        "\"name\": \"Can edit name with view-only inlines\",",
        "\"name\": \"Can edit name with view-only"
    ],
    [
        "\"\"\"User has view and add permissions on the inline model.\"\"\"",
        "\"\"\"User has view and add permissions on the inline"
    ],
    [
        "\"name\": \"Can edit name with view-only inlines\",",
        "\"name\": \"Can edit name with view-only"
    ],
    [
        "\"\"\"User has view and delete permissions on the inline model.\"\"\"",
        "\"\"\"User has view and delete"
    ],
    [
        "\"\"\"Delete view should restrict access and actually delete items.\"\"\"",
        "\"\"\"Delete view should restrict access and actually delete"
    ],
    [
        "The delete view allows users to delete collected objects without a",
        "The delete view allows users to delete collected"
    ],
    [
        "[\"article with ID “nonexistent” doesn’t exist. Perhaps it was deleted?\"],",
        "[\"article with ID “nonexistent” doesn’t exist. Perhaps"
    ],
    [
        "[\"article with ID “foo” doesn’t exist. Perhaps it was deleted?\"],",
        "[\"article with ID “foo” doesn’t exist. Perhaps"
    ],
    [
        "The foreign key widget should only show the \"add related\" button if the",
        "The foreign key widget should only show the"
    ],
    [
        "user has permission to add that related item.",
        "user has permission to add that related"
    ],
    [
        "The foreign key widget should only show the \"change related\" button if",
        "The foreign key widget should only show the"
    ],
    [
        "the user has permission to change that related item.",
        "the user has permission to"
    ],
    [
        "The foreign key widget should only show the \"delete related\" button if",
        "The foreign key widget should only show"
    ],
    [
        "the user has permission to delete that related item.",
        "the user has permission to delete"
    ],
    [
        "Only admin users should be able to use the admin shortcut view.",
        "Only admin users should be able to"
    ],
    [
        "has_module_permission() returns True for all users who",
        "has_module_permission() returns True for all"
    ],
    [
        "have any permission for that module (add, change, or delete), so that",
        "have any permission for that module (add, change,"
    ],
    [
        "the module is displayed on the admin index page.",
        "the module is displayed on the admin"
    ],
    [
        "If has_module_permission() always returns False, the module shouldn't",
        "If has_module_permission() always returns"
    ],
    [
        "be displayed on the admin index page for any users.",
        "be displayed on the admin index page"
    ],
    [
        "Post-save message shouldn't contain a link to the change form if the",
        "Post-save message shouldn't contain a link to the change form if"
    ],
    [
        "user doesn't have the change permission.",
        "user doesn't have the"
    ],
    [
        "'<li class=\"success\">The article “Fun &amp; games” was added successfully.'",
        "'<li class=\"success\">The article “Fun &amp; games” was"
    ],
    [
        "\"\"\"Tests for proxy models permissions in the admin.\"\"\"",
        "\"\"\"Tests for proxy models permissions in the"
    ],
    [
        "response = self.client.post(url, {\"post\": \"yes\"}, follow=True)",
        "response = self.client.post(url,"
    ],
    [
        "\"\"\"Admin index views don't break when user's ModelAdmin removes standard urls\"\"\"",
        "\"\"\"Admin index views don't break when user's ModelAdmin"
    ],
    [
        "Objects should be nested to display the relationships that",
        "Objects should be nested to display"
    ],
    [
        "cause them to be scheduled for deletion.",
        "cause them to be scheduled"
    ],
    [
        "Cyclic relationships should still cause each object to only be",
        "Cyclic relationships should still cause"
    ],
    [
        "one = '<li>Cyclic one: <a href=\"%s\">I am recursive</a>' % (",
        "one = '<li>Cyclic one: <a href=\"%s\">I am recursive</a>'"
    ],
    [
        "two = '<li>Cyclic two: <a href=\"%s\">I am recursive too</a>' % (",
        "two = '<li>Cyclic two: <a href=\"%s\">I am"
    ],
    [
        "\"your account doesn't have permission to delete the following types of \"",
        "\"your account doesn't have permission to delete"
    ],
    [
        "response, \"would require deleting the following protected related objects\"",
        "response, \"would require deleting the following protected related"
    ],
    [
        "A POST request to delete protected objects should display the page",
        "A POST request to delete protected"
    ],
    [
        "which says the deletion is prohibited.",
        "which says the deletion"
    ],
    [
        "response, \"would require deleting the following protected related objects\"",
        "response, \"would require deleting the following protected"
    ],
    [
        "\"would require deleting the following protected related objects\",",
        "\"would require deleting the following protected"
    ],
    [
        "\"would require deleting the following protected related objects\",",
        "\"would require deleting the following"
    ],
    [
        "should_contain = \"\"\"<li>Secret hideout: underground bunker\"\"\"",
        "should_contain = \"\"\"<li>Secret hideout:"
    ],
    [
        "If a deleted object has two relationships from another model,",
        "If a deleted object has"
    ],
    [
        "both of those should be followed in looking for related",
        "both of those should be followed in looking for"
    ],
    [
        "should_contain = '<li>Plot: <a href=\"%s\">World Domination</a>' % reverse(",
        "should_contain = '<li>Plot: <a"
    ],
    [
        "If a deleted object has two relationships pointing to it from",
        "If a deleted object has two"
    ],
    [
        "another object, the other object should still only be listed",
        "another object, the other object should still only be"
    ],
    [
        "should_contain = '<li>Plot: <a href=\"%s\">World Peace</a></li>' % reverse(",
        "should_contain = '<li>Plot: <a href=\"%s\">World Peace</a></li>'"
    ],
    [
        "In the case of an inherited model, if either the child or",
        "In the case of an inherited model, if"
    ],
    [
        "parent-model instance is deleted, both instances are listed",
        "parent-model instance is deleted, both instances"
    ],
    [
        "for deletion, as well as any relationships they have.",
        "for deletion, as well as"
    ],
    [
        "\"<li>Super secret hideout: super floating castle!\",",
        "\"<li>Super secret hideout: super"
    ],
    [
        "If a deleted object has GenericForeignKeys pointing to it,",
        "If a deleted object has GenericForeignKeys"
    ],
    [
        "those objects should be listed for deletion.",
        "those objects should be listed"
    ],
    [
        "should_contain = '<li>Funky tag: <a href=\"%s\">hott' % reverse(",
        "should_contain = '<li>Funky tag:"
    ],
    [
        "If a deleted object has GenericForeignKey with",
        "If a deleted object has"
    ],
    [
        "GenericRelation(related_query_name='...') pointing to it, those objects",
        "GenericRelation(related_query_name='...') pointing to it, those"
    ],
    [
        "should_contain = '<li>Funky tag: <a href=\"%s\">django' % tag_url",
        "should_contain = '<li>Funky tag: <a"
    ],
    [
        "Retrieving the history for an object using urlencoded form of primary",
        "Retrieving the history for an object using urlencoded"
    ],
    [
        "\"Retrieving the object using urlencoded form of primary key should work\"",
        "\"Retrieving the object using urlencoded form of primary key"
    ],
    [
        "Link to the changeform of the object in changelist should use reverse()",
        "Link to the changeform of the object"
    ],
    [
        "should_contain = '<th class=\"field-__str__\"><a href=\"%s\">%s</a></th>' % (",
        "should_contain = '<th class=\"field-__str__\"><a href=\"%s\">%s</a></th>' %"
    ],
    [
        "The link from the recent actions list referring to the changeform of",
        "The link from the recent actions list referring to the"
    ],
    [
        "should_contain = \"\"\"<a href=\"%s\">%s</a>\"\"\" % (escape(link), escape(self.pk))",
        "should_contain = \"\"\"<a href=\"%s\">%s</a>\"\"\" % (escape(link),"
    ],
    [
        "for operation in [\"Added\", \"Changed\", \"Deleted\"]:",
        "for operation in [\"Added\", \"Changed\","
    ],
    [
        "The link from the delete confirmation page referring back to the",
        "The link from the delete confirmation page referring back"
    ],
    [
        "changeform of the object should be quoted.",
        "changeform of the object should be"
    ],
    [
        "should_contain = '<a href=\"%s\">%s</a>' % (change_url, escape(self.pk))",
        "should_contain = '<a href=\"%s\">%s</a>' %"
    ],
    [
        "\"A model with a primary key that ends with add or is `add` should be visible\"",
        "\"A model with a primary key that ends with add or"
    ],
    [
        "\"A model with a primary key that ends with delete should be visible\"",
        "\"A model with a primary key that ends"
    ],
    [
        "\"A model with a primary key that ends with history should be visible\"",
        "\"A model with a primary key that ends with history should"
    ],
    [
        "\"'View on site should' work properly with char fields\"",
        "\"'View on site should' work properly"
    ],
    [
        "should_contain = '/%s/\" class=\"viewsitelink\">' % model.pk",
        "should_contain = '/%s/\" class=\"viewsitelink\">'"
    ],
    [
        "\"\"\"Object history button link should work and contain the pk value quoted.\"\"\"",
        "\"\"\"Object history button link should work and contain the pk"
    ],
    [
        "response, '<a href=\"%s\" class=\"historylink\"' % escape(expected_link)",
        "response, '<a href=\"%s\" class=\"historylink\"'"
    ],
    [
        "\"\"\"As soon as an object is added using \"Save and continue editing\"",
        "\"\"\"As soon as an object is added using \"Save and continue"
    ],
    [
        "button, the user should be redirected to the object's change_view.",
        "button, the user should be"
    ],
    [
        "In case primary key is a string containing some special characters",
        "In case primary key is a"
    ],
    [
        "Test behavior of a view protected by the staff_member_required decorator.",
        "Test behavior of a view protected by the staff_member_required"
    ],
    [
        "Staff_member_required decorator works with an argument",
        "Staff_member_required decorator works with an"
    ],
    [
        "content=\"<p>La kjærligheten til de lidende seire.</p>\",",
        "content=\"<p>La kjærligheten til de"
    ],
    [
        "A test to ensure that POST on edit_view handles non-ASCII characters.",
        "A test to ensure that POST"
    ],
    [
        "\"&lt;p&gt;La kjærligheten til de lidende seire.&lt;/p&gt;\"",
        "\"&lt;p&gt;La kjærligheten til de"
    ],
    [
        "Non-field errors are displayed for each of the forms in the",
        "Non-field errors are displayed for each of the forms"
    ],
    [
        "\"with this Driver and Restaurant already exists.</li></ul></td></tr>\",",
        "\"with this Driver and Restaurant already"
    ],
    [
        "\"with this Driver and Restaurant already exists.</li></ul></td></tr>\",",
        "\"with this Driver and Restaurant"
    ],
    [
        "self.assertContains(response, \"Grace is not a Zombie\")",
        "self.assertContains(response, \"Grace is not"
    ],
    [
        "str(ErrorList([\"Grace is not a Zombie\"], error_class=\"nonform\")),",
        "str(ErrorList([\"Grace is not a Zombie\"],"
    ],
    [
        "Fields should not be list-editable in popups.",
        "Fields should not be list-editable in"
    ],
    [
        "hidden pk fields aren't displayed in the table body and their",
        "hidden pk fields aren't displayed in the table body"
    ],
    [
        "corresponding human-readable value is displayed instead. The hidden pk",
        "corresponding human-readable value is displayed instead. The"
    ],
    [
        "fields are displayed but separately (not in the table) and only once.",
        "fields are displayed but separately (not in the table) and"
    ],
    [
        "title=\"The adventures of Guido\", content=\"Once upon a time in Djangoland...\"",
        "title=\"The adventures of Guido\", content=\"Once"
    ],
    [
        "\"\"\"Similarly as test_pk_hidden_fields, but when the hidden pk fields are",
        "\"\"\"Similarly as test_pk_hidden_fields, but when the hidden pk"
    ],
    [
        "content=\"Once upon a time in Djangoland...\",",
        "content=\"Once upon a"
    ],
    [
        "\"A search that mentions sibling models\"",
        "\"A search that mentions sibling"
    ],
    [
        "The to_field GET parameter is preserved when a search is performed.",
        "The to_field GET parameter is preserved"
    ],
    [
        "'<input type=\"hidden\" name=\"%s\" value=\"id\">' % TO_FIELD_VAR,",
        "'<input type=\"hidden\" name=\"%s\" value=\"id\">'"
    ],
    [
        "Inline models which inherit from a common parent are correctly handled.",
        "Inline models which inherit from a"
    ],
    [
        "self.assertContains(response, \"Primary key = %s\" % i)",
        "self.assertContains(response, \"Primary key = %s\""
    ],
    [
        "self.assertNotContains(response, \"Primary key = %s\" % i)",
        "self.assertNotContains(response, \"Primary key ="
    ],
    [
        "'<li class=\"success\">The cover letter “<a href=\"%s\">'",
        "'<li class=\"success\">The cover letter “<a"
    ],
    [
        "'<li class=\"success\">The short message “<a href=\"%s\">'",
        "'<li class=\"success\">The short message “<a"
    ],
    [
        "'<li class=\"success\">The cover letter “<a href=\"%s\">'",
        "'<li class=\"success\">The cover letter “<a"
    ],
    [
        "\"John Doe II</a>” was changed successfully.</li>\"",
        "\"John Doe II</a>” was changed"
    ],
    [
        "'<li class=\"success\">The short message “<a href=\"%s\">'",
        "'<li class=\"success\">The short message “<a"
    ],
    [
        "\"Telegram without typo</a>” was changed successfully.</li>\"",
        "\"Telegram without typo</a>”"
    ],
    [
        "Custom querysets are considered for the admin history view.",
        "Custom querysets are considered for the admin history"
    ],
    [
        "\"A simple model can be saved as inlines\"",
        "\"A simple model can be"
    ],
    [
        "A model with an explicit autofield primary key can be saved as inlines.",
        "A model with an explicit autofield primary key can be"
    ],
    [
        "An inline with an editable ordering fields is updated correctly.",
        "An inline with an editable ordering fields"
    ],
    [
        "\"Check the never-cache status of the main index\"",
        "\"Check the never-cache status"
    ],
    [
        "\"Check the never-cache status of an application index\"",
        "\"Check the never-cache status of an application"
    ],
    [
        "\"Check the never-cache status of a model index\"",
        "\"Check the never-cache status"
    ],
    [
        "\"Check the never-cache status of a model add page\"",
        "\"Check the never-cache status of"
    ],
    [
        "\"Check the never-cache status of a model edit page\"",
        "\"Check the never-cache status of a model edit"
    ],
    [
        "\"Check the never-cache status of a model history page\"",
        "\"Check the never-cache status of a model"
    ],
    [
        "\"Check the never-cache status of a model delete page\"",
        "\"Check the never-cache status of a model delete"
    ],
    [
        "\"Check the never-cache status of login views\"",
        "\"Check the never-cache status of login"
    ],
    [
        "\"Check the never-cache status of logout view\"",
        "\"Check the never-cache status of"
    ],
    [
        "\"Check the never-cache status of the password change view\"",
        "\"Check the never-cache status of the password change"
    ],
    [
        "\"Check the never-cache status of the password change done view\"",
        "\"Check the never-cache status of the password"
    ],
    [
        "that maxLength (in the JavaScript) is rendered without separators.",
        "that maxLength (in the JavaScript)"
    ],
    [
        "which is present in the add view, even if the",
        "which is present in the add view, even if"
    ],
    [
        "doesn't break a view-only change view.",
        "doesn't break a view-only change"
    ],
    [
        "The JavaScript-automated prepopulated fields work with the main form",
        "The JavaScript-automated prepopulated fields work with"
    ],
    [
        "and with stacked and tabular inlines.",
        "and with stacked and"
    ],
    [
        "\" the mAin nÀMë and it's awεšomeıııİ\"",
        "\" the mAin nÀMë and"
    ],
    [
        ").send_keys(\" here is a sŤāÇkeð   inline !  \")",
        ").send_keys(\" here is a"
    ],
    [
        "\" now you haVe anöther   sŤāÇkeð  inline with a very ... \"",
        "\" now you haVe anöther sŤāÇkeð"
    ],
    [
        ").send_keys(\"And now, with a tÃbűlaŘ inline !!!\")",
        ").send_keys(\"And now, with a tÃbűlaŘ inline"
    ],
    [
        "\" now you haVe anöther   sŤāÇkeð  inline with a very loooong \"",
        "\" now you haVe anöther sŤāÇkeð inline"
    ],
    [
        "name=\" the mAin nÀMë and it's awεšomeıııİ\",",
        "name=\" the mAin nÀMë and it's"
    ],
    [
        "name=\" here is a sŤāÇkeð   inline !  \",",
        "name=\" here is a sŤāÇkeð inline"
    ],
    [
        "\" now you haVe anöther   sŤāÇkeð  inline with a very ... \"",
        "\" now you haVe anöther sŤāÇkeð inline with a very"
    ],
    [
        "name=\"And now, with a tÃbűlaŘ inline !!!\",",
        "name=\"And now, with a tÃbűlaŘ"
    ],
    [
        "The prepopulation works for existing objects too, as long as",
        "The prepopulation works for existing objects"
    ],
    [
        "name=\" this is the mAin nÀMë\",",
        "name=\" this is"
    ],
    [
        "The 'collapse' class in fieldsets definition allows to",
        "The 'collapse' class in fieldsets definition allows"
    ],
    [
        "url = self.live_server_url + reverse(\"admin:auth_user_change\", args=[user.id])",
        "url = self.live_server_url +"
    ],
    [
        "\"\"\"JavaScript-assisted auto-focus on first usable form field.\"\"\"",
        "\"\"\"JavaScript-assisted auto-focus on first"
    ],
    [
        "\"Cancelling the deletion of an object takes the user back one page.\"",
        "\"Cancelling the deletion of an object takes the user"
    ],
    [
        "Cancelling the deletion of an object with relations takes the user back",
        "Cancelling the deletion of an object with relations takes"
    ],
    [
        "list_editable foreign keys have add/change popups.",
        "list_editable foreign keys"
    ],
    [
        "\"\"\"Clicking \"\"No, take me back\" on a delete popup closes the window.\"\"\"",
        "\"\"\"Clicking \"\"No, take me back\" on"
    ],
    [
        "Browsers' default stylesheets override the font of inputs. The admin",
        "Browsers' default stylesheets override the font"
    ],
    [
        "adds additional CSS to handle this.",
        "adds additional CSS"
    ],
    [
        "Create a chain of 'self' related objects via popups.",
        "Create a chain of 'self' related objects via"
    ],
    [
        "Cleanup child popups when closing a parent popup.",
        "Cleanup child popups when"
    ],
    [
        "'<div class=\"help\" id=\"id_title_helptext\"><div>Some help text for the '",
        "'<div class=\"help\" id=\"id_title_helptext\"><div>Some help text for"
    ],
    [
        "'<div class=\"help\" id=\"id_content_helptext\"><div>Some help text for the '",
        "'<div class=\"help\" id=\"id_content_helptext\"><div>Some help"
    ],
    [
        "'<div class=\"help\"><div>Some help text for the date (with Unicode ŠĐĆŽćžšđ)'",
        "'<div class=\"help\"><div>Some help text for the"
    ],
    [
        "title=\"I worked on readonly_fields\", content=\"Its good stuff\"",
        "title=\"I worked on readonly_fields\", content=\"Its"
    ],
    [
        "self.assertContains(response, \"%d amount of cool\" % p.pk)",
        "self.assertContains(response, \"%d amount of cool\" %"
    ],
    [
        "\"content\": \"This is an incredible development.\",",
        "\"content\": \"This is"
    ],
    [
        "ForeignKey readonly fields render as links if the target model is",
        "ForeignKey readonly fields render as links if"
    ],
    [
        "broke if the related field is read-only due to the help_text attribute",
        "broke if the related field is read-only due to"
    ],
    [
        "Can reference a reverse OneToOneField in ModelAdmin.readonly_fields.",
        "Can reference a reverse OneToOneField in"
    ],
    [
        "pd = PlotDetails.objects.create(details=\"Brand New Plot\", plot=pl)",
        "pd = PlotDetails.objects.create(details=\"Brand New"
    ],
    [
        "self.assertEqual(field.contents(), '<a href=\"%s\">Brand New Plot</a>' % pd_url)",
        "self.assertEqual(field.contents(), '<a href=\"%s\">Brand New Plot</a>'"
    ],
    [
        "p = FieldOverridePost.objects.create(title=\"Test Post\", content=\"Test Content\")",
        "p = FieldOverridePost.objects.create(title=\"Test Post\", content=\"Test"
    ],
    [
        "'<div class=\"help\"><div>Overridden help text for the date</div></div>',",
        "'<div class=\"help\"><div>Overridden help text"
    ],
    [
        "response, \"Some help text for the date (with Unicode ŠĐĆŽćžšđ)\"",
        "response, \"Some help text for"
    ],
    [
        "Should be able to use a ModelAdmin method in list_display that has the",
        "Should be able to use a ModelAdmin method in list_display that has"
    ],
    [
        "same name as a reverse model field (\"sketch\" in this case).",
        "same name as a reverse model field"
    ],
    [
        "\"%s</a>” was added successfully. You may edit it again below.</li>\"",
        "\"%s</a>” was added successfully. You may edit it again"
    ],
    [
        "[\"The two password fields didn’t match.\"],",
        "[\"The two password fields"
    ],
    [
        "User addition through a FK popup should return the appropriate",
        "User addition through a FK popup"
    ],
    [
        "User change through a FK popup should return the appropriate JavaScript",
        "User change through a FK popup should return the"
    ],
    [
        "User deletion through a FK popup should return the appropriate",
        "User deletion through a FK popup should"
    ],
    [
        "Fields have a CSS class name with a 'field-' prefix.",
        "Fields have a CSS class name"
    ],
    [
        "CSS class names are used for each app and model on the admin index",
        "CSS class names are used for each app and model"
    ],
    [
        "'<th scope=\"col\">Add link</th><th scope=\"col\">Change or view list link</th>'",
        "'<th scope=\"col\">Add link</th><th scope=\"col\">Change"
    ],
    [
        "'<th scope=\"col\">Add link</th><th scope=\"col\">Change or view list link</th>'",
        "'<th scope=\"col\">Add link</th><th scope=\"col\">Change or"
    ],
    [
        "Ensure app and model tag are correctly read by change_form template",
        "Ensure app and model tag are correctly read"
    ],
    [
        "self.assertContains(response, '<body class=\" app-admin_views model-section ')",
        "self.assertContains(response, '<body class=\""
    ],
    [
        "Ensure app and model tag are correctly read by change_list template",
        "Ensure app and model tag are correctly read by change_list"
    ],
    [
        "self.assertContains(response, '<body class=\" app-admin_views model-section ')",
        "self.assertContains(response, '<body class=\""
    ],
    [
        "Ensure app and model tag are correctly read by delete_confirmation",
        "Ensure app and model tag"
    ],
    [
        "self.assertContains(response, '<body class=\" app-admin_views model-section ')",
        "self.assertContains(response, '<body class=\""
    ],
    [
        "Ensure app and model tag are correctly read by app_index template",
        "Ensure app and model tag are correctly read"
    ],
    [
        "Ensure app and model tag are correctly read by",
        "Ensure app and model tag are correctly"
    ],
    [
        "self.assertContains(response, '<body class=\" app-admin_views model-section ')",
        "self.assertContains(response, '<body class=\" app-admin_views model-section"
    ],
    [
        "Cells of the change list table should contain the field name in their",
        "Cells of the change list table should contain"
    ],
    [
        "No date hierarchy links display with empty changelist.",
        "No date hierarchy links display with"
    ],
    [
        "Single day-level date hierarchy appears for single object.",
        "Single day-level date hierarchy appears for single"
    ],
    [
        "day-level links appear for changelist within single month.",
        "day-level links appear for"
    ],
    [
        "month-level links appear for changelist within single year.",
        "month-level links appear for changelist within"
    ],
    [
        "year-level links appear for year-spanning changelist.",
        "year-level links appear for"
    ],
    [
        "One can easily customize the way related objects are saved.",
        "One can easily customize the way related objects"
    ],
    [
        "'<input type=\"hidden\" name=\"next\" value=\"%s\">' % reverse(\"admin:index\"),",
        "'<input type=\"hidden\" name=\"next\" value=\"%s\">' %"
    ],
    [
        "Helper that sends a post to the dummy test methods and asserts that a",
        "Helper that sends a post to the dummy test methods"
    ],
    [
        "message with the level has appeared in the response.",
        "message with the level has appeared"
    ],
    [
        "response, '<li class=\"%s\">Test %s</li>' % (level, level), html=True",
        "response, '<li class=\"%s\">Test %s</li>' %"
    ],
    [
        "response, '<li class=\"extra_tag info\">Test tags</li>', html=True",
        "response, '<li class=\"extra_tag"
    ],
    [
        "Assert that two URLs are equal despite the ordering",
        "Assert that two URLs are equal"
    ],
    [
        "url = \"%s?%s\" % (url, self.get_preserved_filters_querystring())",
        "url = \"%s?%s\" % (url,"
    ],
    [
        "url = \"%s?%s\" % (url, self.get_preserved_filters_querystring())",
        "url = \"%s?%s\" % (url,"
    ],
    [
        "response, f'<div class=\"flex-container fieldBox field-{field_name} hidden\">'",
        "response, f'<div class=\"flex-container fieldBox"
    ],
    [
        "Verifying that if the parent form fails validation, the inlines also",
        "Verifying that if the parent form fails"
    ],
    [
        "run validation even if validation is contingent on parent form data.",
        "run validation even if validation is contingent on"
    ],
    [
        "Also, assertFormError() and assertFormSetError() is usable for admin",
        "Also, assertFormError() and assertFormSetError() is usable for"
    ],
    [
        "\"Children must share a family name with their parents in this \"",
        "\"Children must share a family name with their parents in this"
    ],
    [
        "Verifying that if the parent form fails validation, the inlines also",
        "Verifying that if the parent form fails validation,"
    ],
    [
        "run validation even if validation is contingent on parent form data",
        "run validation even if validation is"
    ],
    [
        "\"Children must share a family name with their parents in this \"",
        "\"Children must share a family name"
    ],
    [
        "\"The view_on_site value is either a boolean or a callable\"",
        "\"The view_on_site value is either a boolean or"
    ],
    [
        "\"The value of 'view_on_site' must be a callable or a boolean \"",
        "\"The value of 'view_on_site' must be a callable or"
    ],
    [
        "\"The 'View on site' button is not displayed if view_on_site is False\"",
        "\"The 'View on site' button is not displayed"
    ],
    [
        "\"The default behavior is followed if view_on_site is True\"",
        "\"The default behavior is followed if view_on_site"
    ],
    [
        "\"The right link is displayed if view_on_site is a callable\"",
        "\"The right link is displayed if view_on_site"
    ],
    [
        "\"None is returned if model doesn't have get_absolute_url\"",
        "\"None is returned if model"
    ],
    [
        "\"\"\"The view_on_site URL accepts non-integer ids.\"\"\"",
        "\"\"\"The view_on_site URL"
    ],
    [
        "\"The 'View on site' button is not displayed if view_on_site is False\"",
        "\"The 'View on site' button is"
    ],
    [
        "\"The 'View on site' button is displayed if view_on_site is True\"",
        "\"The 'View on site' button is displayed if"
    ],
    [
        "\"The right link is displayed if view_on_site is a callable\"",
        "\"The right link is displayed if view_on_site is"
    ],
    [
        "of get_formsets_with_inlines() should be None. When changing, it should be",
        "of get_formsets_with_inlines() should be None. When changing, it should"
    ],
    [
        "equal to the existing model instance.",
        "equal to the existing model"
    ],
    [
        "The GetFormsetsArgumentCheckingAdmin ModelAdmin throws an exception",
        "The GetFormsetsArgumentCheckingAdmin ModelAdmin throws an"
    ],
    [
        "if obj is not None during add_view or obj is None during change_view.",
        "if obj is not None during add_view or obj is"
    ],
    [
        "Verifies the behaviour of the admin catch-all view.",
        "Verifies the behaviour of the"
    ],
    [
        "* Anonynous/non-staff users are redirected to login for all URLs, whether",
        "* Anonynous/non-staff users are redirected to"
    ],
    [
        "* APPEND_SLASH is applied for staff if needed.",
        "* APPEND_SLASH is applied for"
    ],
    [
        "* Catch-all view disabled via AdminSite.final_catch_all_view.",
        "* Catch-all view disabled via"
    ],
    [
        "from . import admin, custom_has_permission_admin, customadmin, views",
        "from . import admin, custom_has_permission_admin,"
    ],
    [
        "from .test_autocomplete_view import site as autocomplete_site",
        "from .test_autocomplete_view import"
    ],
    [
        "q = Question.objects.create(question=\"Is this a question?\")",
        "q = Question.objects.create(question=\"Is this"
    ],
    [
        "request = self.factory.get(self.url, {\"term\": \"is\", **self.opts})",
        "request = self.factory.get(self.url,"
    ],
    [
        "q = Question.objects.create(question=\"Is this a question?\")",
        "q = Question.objects.create(question=\"Is this a"
    ],
    [
        "q = Question.objects.create(question=\"Is this a question?\")",
        "q = Question.objects.create(question=\"Is this"
    ],
    [
        "request = self.factory.get(self.url, {\"term\": \"is\", **opts})",
        "request = self.factory.get(self.url, {\"term\":"
    ],
    [
        "to_field resolution should correctly resolve for target models using",
        "to_field resolution should correctly resolve"
    ],
    [
        "MTI. Tests for single and multi-level cases.",
        "MTI. Tests for single and"
    ],
    [
        "for Target, Remote, related_name in tests:",
        "for Target, Remote, related_name"
    ],
    [
        "request = self.factory.get(self.url, {\"term\": \"frida\", **opts})",
        "request = self.factory.get(self.url, {\"term\":"
    ],
    [
        "request = self.factory.get(self.url, {\"term\": \"anna\", **opts})",
        "request = self.factory.get(self.url, {\"term\":"
    ],
    [
        "self.url, {\"term\": \"is\", **self.opts, \"field_name\": \"does_not_exist\"}",
        "self.url, {\"term\": \"is\", **self.opts,"
    ],
    [
        "self.url, {\"term\": \"is\", **self.opts, \"field_name\": \"answer\"}",
        "self.url, {\"term\": \"is\","
    ],
    [
        "self.url, {\"term\": \"is\", **self.opts, \"field_name\": \"related_questions\"}",
        "self.url, {\"term\": \"is\", **self.opts,"
    ],
    [
        "q = Question.objects.create(question=\"Is this a question?\")",
        "q = Question.objects.create(question=\"Is"
    ],
    [
        "response = self.client.get(self.url, {\"term\": \"\", **self.opts})",
        "response = self.client.get(self.url,"
    ],
    [
        "response = self.client.get(self.url, {\"term\": \"\", **self.opts})",
        "response = self.client.get(self.url,"
    ],
    [
        "Users require the change permission for the related model to the",
        "Users require the change permission for the"
    ],
    [
        "request = self.factory.get(self.url, {\"term\": \"is\", **self.opts})",
        "request = self.factory.get(self.url,"
    ],
    [
        "Searching across model relations use QuerySet.distinct() to avoid",
        "Searching across model relations use"
    ],
    [
        "request = self.factory.get(self.url, {\"term\": \"question\", **self.opts})",
        "request = self.factory.get(self.url,"
    ],
    [
        "msg = \"EmptySearchAdmin must have search_fields for the autocomplete_view.\"",
        "msg = \"EmptySearchAdmin must have search_fields for the"
    ],
    [
        "request = self.factory.get(self.url, {\"term\": \"\", **self.opts})",
        "request = self.factory.get(self.url, {\"term\":"
    ],
    [
        "request = self.factory.get(self.url, {\"term\": \"question\", **self.opts})",
        "request = self.factory.get(self.url, {\"term\": \"question\","
    ],
    [
        "{\"id\": str(q.pk), \"text\": q.question, \"posted\": str(q.posted)}",
        "{\"id\": str(q.pk), \"text\":"
    ],
    [
        "from selenium.webdriver.support import expected_conditions as ec",
        "from selenium.webdriver.support import expected_conditions as"
    ],
    [
        "submit_row template tag should pass whole context.",
        "submit_row template tag should pass whole"
    ],
    [
        "admin_modify template tags follow the standard search pattern",
        "admin_modify template tags follow the standard search"
    ],
    [
        "extra_context = {\"show_publish\": True, \"extra\": True}",
        "extra_context = {\"show_publish\":"
    ],
    [
        "admin_list template tags follow the standard search pattern",
        "admin_list template tags follow the standard search"
    ],
    [
        "Question(question=\"q\", posted=posted) for posted in posted_dates",
        "Question(question=\"q\", posted=posted) for posted in"
    ],
    [
        "query = {\"posted__%s\" % q: val for q, val in query.items()}",
        "query = {\"posted__%s\" % q: val for"
    ],
    [
        "choices = [choice[\"link\"] for choice in spec[\"choices\"]]",
        "choices = [choice[\"link\"] for choice"
    ],
    [
        "\"&\".join(\"posted__%s\" % c for c in choice)",
        "\"&\".join(\"posted__%s\" % c for c"
    ],
    [
        "(\"?\" + choice) if choice else \"\" for choice in expected_choices",
        "(\"?\" + choice) if choice else \"\""
    ],
    [
        "query = {\"expires__%s\" % q: val for q, val in query.items()}",
        "query = {\"expires__%s\" % q: val"
    ],
    [
        "choices = [choice[\"link\"] for choice in spec[\"choices\"]]",
        "choices = [choice[\"link\"] for choice"
    ],
    [
        "\"?\" + \"&\".join(\"expires__%s\" % c for c in choice)",
        "\"?\" + \"&\".join(\"expires__%s\" % c"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import SimpleTestCase,"
    ],
    [
        "Tests for various ways of registering models with the admin site.",
        "Tests for various ways of registering models with"
    ],
    [
        "from .models import Guest, Location, Person, Place, Traveler",
        "from .models import Guest, Location, Person,"
    ],
    [
        "msg = \"The model Person is already registered in app 'admin_registration'.\"",
        "msg = \"The model Person is already registered in app"
    ],
    [
        "\"The model Person is already registered with \"",
        "\"The model Person is"
    ],
    [
        "msg = \"The model Person is not registered\"",
        "msg = \"The model"
    ],
    [
        "msg = \"The model Person is not registered.\"",
        "msg = \"The model"
    ],
    [
        "Exception is raised when trying to register an abstract model.",
        "Exception is raised when trying"
    ],
    [
        "msg = \"The model Location is abstract, so it cannot be registered with admin.\"",
        "msg = \"The model Location is abstract, so it cannot be registered"
    ],
    [
        "\"The model Guest has a composite primary key, so it cannot be registered \"",
        "\"The model Guest has a composite primary key, so it cannot be registered"
    ],
    [
        "\"Checks for registered models should return true.\"",
        "\"Checks for registered models"
    ],
    [
        "\"Checks for unregistered models should return false.\"",
        "\"Checks for unregistered models should return"
    ],
    [
        "Tests the register decorator in admin.decorators",
        "Tests the register decorator"
    ],
    [
        "is functionally equal to (the way it is written in these tests):",
        "is functionally equal to (the way it is"
    ],
    [
        "ValueError, \"Wrapped class must subclass ModelAdmin.\"",
        "ValueError, \"Wrapped class must"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"site must subclass AdminSite\"):",
        "with self.assertRaisesMessage(ValueError, \"site must"
    ],
    [
        "ValueError, \"At least one model must be passed to register.\"",
        "ValueError, \"At least one model must be passed"
    ],
    [
        "Failing to import a backend keeps raising the original import error",
        "Failing to import a backend keeps raising"
    ],
    [
        "with self.assertRaisesMessage(ImportError, \"No module named 'raise\"):",
        "with self.assertRaisesMessage(ImportError, \"No module named"
    ],
    [
        "with self.assertRaisesMessage(ImportError, \"No module named 'raise\"):",
        "with self.assertRaisesMessage(ImportError, \"No module"
    ],
    [
        "Failing to initialize a backend keeps raising the original exception",
        "Failing to initialize a backend keeps raising the original"
    ],
    [
        "msg = \"app_dirs must not be set when loaders is defined.\"",
        "msg = \"app_dirs must not be"
    ],
    [
        "\"Template engine aliases aren't unique, duplicates: django. Set \"",
        "\"Template engine aliases aren't unique, duplicates: django."
    ],
    [
        "\"a unique NAME for each engine in settings.TEMPLATES.\"",
        "\"a unique NAME for each"
    ],
    [
        "from django.forms import CharField, Form, Media",
        "from django.forms import CharField,"
    ],
    [
        "self.skipTest(\"test doesn't apply to dummy backend\")",
        "self.skipTest(\"test doesn't apply to"
    ],
    [
        "self.skipTest(\"test doesn't apply to dummy backend\")",
        "self.skipTest(\"test doesn't apply to dummy"
    ],
    [
        "content = template.render({\"media\": media, \"test_form\": form})",
        "content = template.render({\"media\": media, \"test_form\":"
    ],
    [
        "request, lambda r: None, (), {}",
        "request, lambda r:"
    ],
    [
        "expected = '<input type=\"hidden\" name=\"csrfmiddlewaretoken\" value=\"([^\"]+)\">'",
        "expected = '<input type=\"hidden\""
    ],
    [
        "match = re.match(expected, content) or re.match(",
        "match = re.match(expected, content)"
    ],
    [
        "self.assertTrue(match, \"hidden csrftoken field not found in output\")",
        "self.assertTrue(match, \"hidden csrftoken field"
    ],
    [
        "from django.template import Context, EngineHandler, RequestContext",
        "from django.template import Context, EngineHandler,"
    ],
    [
        "msg = \"context must be a dict rather than Context.\"",
        "msg = \"context must be a dict"
    ],
    [
        "msg = \"context must be a dict rather than RequestContext.\"",
        "msg = \"context must be a"
    ],
    [
        "Import errors in tag modules should be reraised with a helpful message.",
        "Import errors in tag modules should"
    ],
    [
        "\"ImportError raised when trying to load \"",
        "\"ImportError raised when trying to"
    ],
    [
        "\"\"\"The cached template loader is always enabled by default.\"\"\"",
        "\"\"\"The cached template loader is always enabled by"
    ],
    [
        "{\"DIRS\": [], \"APP_DIRS\": True, \"NAME\": \"django\", \"OPTIONS\": {}}",
        "{\"DIRS\": [], \"APP_DIRS\": True, \"NAME\":"
    ],
    [
        "\"DIRS\": [Path(__file__).parent / \"templates\" / \"template_backends\"],",
        "\"DIRS\": [Path(__file__).parent /"
    ],
    [
        "template = self.engine.from_string(\"hello {{ foo }}!\")",
        "template = self.engine.from_string(\"hello {{ foo"
    ],
    [
        "content = template.render(context={\"self\": \"self\", \"foo\": \"world\"})",
        "content = template.render(context={\"self\": \"self\", \"foo\":"
    ],
    [
        "template = self.engine.from_string(\"Static URL: {{ STATIC_URL }}\")",
        "template = self.engine.from_string(\"Static URL: {{ STATIC_URL"
    ],
    [
        "\"DIRS\": [Path(__file__).parent / \"templates\" / \"template_backends\"],",
        "\"DIRS\": [Path(__file__).parent / \"templates\" /"
    ],
    [
        "name=\"The Definitive Guide to Django: Web Development Done Right\",",
        "name=\"The Definitive Guide to Django:"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming: Case"
    ],
    [
        "self.assertTrue(all(not book.selected for book in books))",
        "self.assertTrue(all(not book.selected for"
    ],
    [
        "self.assertTrue(all(not book.selected for book in books))",
        "self.assertTrue(all(not book.selected for book"
    ],
    [
        "self.assertEqual({p.last_name for p in people}, {\"Stark\", \"Roosevelt\"})",
        "self.assertEqual({p.last_name for p in people},"
    ],
    [
        "FieldError, \"Cannot resolve keyword 'nope' into field.\"",
        "FieldError, \"Cannot resolve keyword 'nope'"
    ],
    [
        "\"Cannot resolve keyword 'annotation_typo' into field. Choices are: %s\"",
        "\"Cannot resolve keyword 'annotation_typo' into"
    ],
    [
        "[\"Amazon.com\", \"Books.com\", \"Mamma and Pappa's Books\"],",
        "[\"Amazon.com\", \"Books.com\", \"Mamma and Pappa's"
    ],
    [
        "Annotations can reference fields in a values clause,",
        "Annotations can reference fields"
    ],
    [
        "and contribute to an existing values clause.",
        "and contribute to an"
    ],
    [
        "Deferred attributes can be referenced by an annotation,",
        "Deferred attributes can be"
    ],
    [
        "but they are not themselves deferred, and cannot be deferred.",
        "but they are not themselves deferred,"
    ],
    [
        "FieldDoesNotExist, \"Book has no field named 'other_rating'\"",
        "FieldDoesNotExist, \"Book has no field"
    ],
    [
        "Fields on an inherited model can be referenced by an",
        "Fields on an inherited model can"
    ],
    [
        "lambda d: (d.other_name, d.other_chain, d.is_open, d.book_isbn),",
        "lambda d: (d.other_name,"
    ],
    [
        "Annotating None onto a model round-trips",
        "Annotating None onto"
    ],
    [
        "(\"case when name='Angus & Robinson' then chain else name end\", \"Westfield\"),",
        "(\"case when name='Angus & Robinson' then chain else"
    ],
    [
        "Columns are aligned in the correct order for resolve_columns. This test",
        "Columns are aligned in the correct order for resolve_columns. This"
    ],
    [
        "will fail on MySQL if column ordering is out. Column fields should be",
        "will fail on MySQL if column ordering is out."
    ],
    [
        "msg = \"QuerySet.annotate() received non-expression(s): %s.\"",
        "msg = \"QuerySet.annotate() received non-expression(s):"
    ],
    [
        "TypeError, msg % \", \".join([str(BooleanField()), \"True\"])",
        "TypeError, msg %"
    ],
    [
        "msg = \"Complex annotations require an alias\"",
        "msg = \"Complex annotations require"
    ],
    [
        "[{\"jacob_name\": \"Jacob Kaplan-Moss\", \"james_name\": \"James Bennett\"}],",
        "[{\"jacob_name\": \"Jacob Kaplan-Moss\", \"james_name\": \"James"
    ],
    [
        "publisher_books_qs, [{\"name\": \"Sams\"}, {\"name\": \"Morgan Kaufmann\"}]",
        "publisher_books_qs, [{\"name\": \"Sams\"}, {\"name\": \"Morgan"
    ],
    [
        "crafted_alias = \"\"\"injected_name\" from \"annotations_book\"; --\"\"\"",
        "crafted_alias = \"\"\"injected_name\" from"
    ],
    [
        "\"Column aliases cannot contain whitespace characters, quotation marks, \"",
        "\"Column aliases cannot contain whitespace characters, quotation"
    ],
    [
        "\"Column aliases cannot contain whitespace characters, quotation marks, \"",
        "\"Column aliases cannot contain whitespace characters, quotation marks,"
    ],
    [
        "name=\"The Definitive Guide to Django: Web Development Done Right\",",
        "name=\"The Definitive Guide to Django: Web"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in"
    ],
    [
        "\"Cannot aggregate over the 'other_age' alias. Use annotate() to promote it.\"",
        "\"Cannot aggregate over the 'other_age' alias. Use annotate() to"
    ],
    [
        "msg = \"Book has no field named 'rating_alias'\"",
        "msg = \"Book has no field"
    ],
    [
        "msg = \"Cannot resolve keyword 'rating_alias' into field.\"",
        "msg = \"Cannot resolve"
    ],
    [
        "msg = \"Cannot select the 'rating_alias' alias. Use annotate() to promote it.\"",
        "msg = \"Cannot select the 'rating_alias' alias."
    ],
    [
        "crafted_alias = \"\"\"injected_name\" from \"annotations_book\"; --\"\"\"",
        "crafted_alias = \"\"\"injected_name\" from"
    ],
    [
        "\"Column aliases cannot contain whitespace characters, quotation marks, \"",
        "\"Column aliases cannot contain whitespace characters,"
    ],
    [
        "sql = \"SELECT * FROM foo WHERE id in (%s, %s)\"",
        "sql = \"SELECT * FROM foo"
    ],
    [
        "parent = models.ForeignKey(\"self\", models.CASCADE, null=True, blank=True)",
        "parent = models.ForeignKey(\"self\","
    ],
    [
        "which is not an inheritor of ManyToManyField.",
        "which is not an"
    ],
    [
        "if kwargs[\"rel\"].through is not None and self.db_table is not None:",
        "if kwargs[\"rel\"].through is not None and self.db_table is not"
    ],
    [
        "\"Cannot specify a db_table if an intermediary model is used.\"",
        "\"Cannot specify a db_table if an intermediary model is"
    ],
    [
        "A MySQL BinaryField that uses a different blob size.",
        "A MySQL BinaryField that uses a different"
    ],
    [
        "from django.test import TransactionTestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import"
    ],
    [
        "from django.test.utils import CaptureQueriesContext, isolate_apps, register_lookup",
        "from django.test.utils import"
    ],
    [
        "from .fields import CustomManyToManyField, InheritedManyToManyField, MediumBlobField",
        "from .fields import"
    ],
    [
        "Be aware that these tests are more liable than most to false results,",
        "Be aware that these tests are more"
    ],
    [
        "as sometimes the code to check if a test has worked is almost as complex",
        "as sometimes the code to check if a test has worked is almost as"
    ],
    [
        "as the code it is testing.",
        "as the code it"
    ],
    [
        "\"Deletes all model tables for our models for a clean test environment\"",
        "\"Deletes all model tables for our models for a clean test"
    ],
    [
        "table_names = [table_name.lower() for table_name in table_names]",
        "table_names = [table_name.lower() for table_name in"
    ],
    [
        "for name, (type, desc) in columns.items():",
        "for name, (type, desc) in"
    ],
    [
        "Get the indexes on the table using a new cursor.",
        "Get the indexes on the table using a"
    ],
    [
        "Get the constraints on a table using a new cursor.",
        "Get the constraints on a table using"
    ],
    [
        "JOIN pg_index as i on oc.oid = ANY(i.indclass)",
        "JOIN pg_index as i on oc.oid"
    ],
    [
        "JOIN pg_class as c on c.oid = i.indexrelid",
        "JOIN pg_class as c on c.oid"
    ],
    [
        "if cast_function and type(database_default) is not type(expected_default):",
        "if cast_function and type(database_default)"
    ],
    [
        "Return a dict with keys 'fks', 'uniques, and 'indexes' indicating the",
        "Return a dict with keys 'fks', 'uniques, and"
    ],
    [
        "number of foreign keys, unique constraints, and indexes on",
        "number of foreign keys, unique constraints, and indexes"
    ],
    [
        "expected foreign key relationship's (table, column).",
        "expected foreign key relationship's"
    ],
    [
        "self.assertFalse(any([c.name == column and c.comment for c in columns]))",
        "self.assertFalse(any([c.name == column and c.comment"
    ],
    [
        "all(val == expected for val, expected in zip(index_orders, order))",
        "all(val == expected for val,"
    ],
    [
        "def assertForeignKeyExists(self, model, column, expected_fk_table, field=\"id\"):",
        "def assertForeignKeyExists(self, model, column, expected_fk_table,"
    ],
    [
        "Fail if the FK constraint on `model.Meta.db_table`.`column` to",
        "Fail if the FK constraint"
    ],
    [
        "if details[\"columns\"] == [column] and details[\"foreign_key\"]:",
        "if details[\"columns\"] == [column]"
    ],
    [
        "Tries creating a model's table, and then deleting it.",
        "Tries creating a model's table,"
    ],
    [
        "\"Creating tables out of FK order, then repointing, works\"",
        "\"Creating tables out of FK"
    ],
    [
        "for sql in (str(statement) for statement in editor.deferred_sql)",
        "for sql in (str(statement) for"
    ],
    [
        "if sql.startswith(\"ALTER TABLE\") and \"ADD CONSTRAINT\" in sql",
        "if sql.startswith(\"ALTER TABLE\") and \"ADD"
    ],
    [
        "new_field = ForeignKey(Node, CASCADE, related_name=\"new_fk\", null=True)",
        "new_field = ForeignKey(Node,"
    ],
    [
        "editor.execute(\"UPDATE schema_node SET new_parent_fk_id = %s;\", [parent.pk])",
        "editor.execute(\"UPDATE schema_node SET new_parent_fk_id = %s;\","
    ],
    [
        "new_field = ForeignKey(Node, CASCADE, related_name=\"new_fk\", null=True)",
        "new_field = ForeignKey(Node, CASCADE,"
    ],
    [
        "editor.execute(\"UPDATE schema_node SET new_parent_fk_id = %s;\", [parent.pk])",
        "editor.execute(\"UPDATE schema_node SET new_parent_fk_id"
    ],
    [
        "\"Creating a FK to a proxy model creates database constraints.\"",
        "\"Creating a FK to a proxy"
    ],
    [
        "When a primary key that's pointed to by a ForeignKey with",
        "When a primary key that's pointed to"
    ],
    [
        "db_constraint=False is altered, a foreign key constraint isn't added.",
        "db_constraint=False is altered, a foreign key"
    ],
    [
        "any(drop_default_sql in query[\"sql\"] for query in ctx.captured_queries)",
        "any(drop_default_sql in query[\"sql\"] for query in"
    ],
    [
        "any(\"CREATE TABLE\" in query[\"sql\"] for query in ctx.captured_queries), False",
        "any(\"CREATE TABLE\" in query[\"sql\"] for"
    ],
    [
        "any(\"DROP TABLE\" in query[\"sql\"] for query in ctx.captured_queries), False",
        "any(\"DROP TABLE\" in query[\"sql\"] for query in ctx.captured_queries),"
    ],
    [
        "Adding a field and removing it removes all deferred sql referring to it.",
        "Adding a field and removing it removes all deferred sql"
    ],
    [
        "Tests adding fields to models with a temporary default",
        "Tests adding fields to models with a"
    ],
    [
        "Tests adding fields to models with a temporary default where",
        "Tests adding fields to models with a temporary"
    ],
    [
        "Tests adding fields to models with a default that is not directly",
        "Tests adding fields to models with a"
    ],
    [
        "any(\"None\" in query[\"sql\"] for query in ctx.captured_queries),",
        "any(\"None\" in query[\"sql\"] for query in"
    ],
    [
        "any(\"CREATE TABLE\" in query[\"sql\"] for query in ctx.captured_queries),",
        "any(\"CREATE TABLE\" in query[\"sql\"] for query in"
    ],
    [
        "any(\"DROP TABLE\" in query[\"sql\"] for query in ctx.captured_queries),",
        "any(\"DROP TABLE\" in query[\"sql\"]"
    ],
    [
        "Changing a field type shouldn't affect the not null status.",
        "Changing a field type shouldn't affect the"
    ],
    [
        "Nullability for textual fields is preserved on databases that",
        "Nullability for textual fields is preserved"
    ],
    [
        "Changing a field type shouldn't affect the not null status.",
        "Changing a field type shouldn't affect the"
    ],
    [
        "interprets_empty_strings_as_nulls when changing a CharField to null.",
        "interprets_empty_strings_as_nulls when changing a CharField"
    ],
    [
        "f\"CREATE COLLATION IF NOT EXISTS {ci_collation} (provider=icu, \"",
        "f\"CREATE COLLATION IF NOT EXISTS {ci_collation}"
    ],
    [
        "self.skipTest(\"This backend does not support deterministic collations.\")",
        "self.skipTest(\"This backend does not support deterministic"
    ],
    [
        "self.skipTest(\"This backend does not support deterministic collations.\")",
        "self.skipTest(\"This backend does not support deterministic"
    ],
    [
        "interprets_empty_strings_as_nulls when changing a TextField to null.",
        "interprets_empty_strings_as_nulls when changing a TextField to"
    ],
    [
        "\"Found an unexpected FK constraint to %s\" % details[\"columns\"]",
        "\"Found an unexpected FK constraint to %s\""
    ],
    [
        "Should be able to convert an implicit \"id\" field to an explicit \"id\"",
        "Should be able to convert an implicit \"id\""
    ],
    [
        "Should be able to rename an IntegerField(primary_key=True) to",
        "Should be able to"
    ],
    [
        "Should be able to rename an IntegerField(primary_key=True) to",
        "Should be able to rename an"
    ],
    [
        "Should be able to rename an SmallIntegerField(primary_key=True) to",
        "Should be able to rename an SmallIntegerField(primary_key=True)"
    ],
    [
        "f'(\"{column}\" smallserial NOT NULL PRIMARY KEY)'",
        "f'(\"{column}\" smallserial NOT NULL"
    ],
    [
        "\"SELECT data_type FROM pg_sequences WHERE sequencename = %s\",",
        "\"SELECT data_type FROM pg_sequences WHERE sequencename ="
    ],
    [
        "\"SELECT data_type FROM pg_sequences WHERE sequencename = %s\",",
        "\"SELECT data_type FROM pg_sequences"
    ],
    [
        "Should be able to rename an IntegerField(primary_key=True) to",
        "Should be able to rename"
    ],
    [
        "Renaming a field shouldn't affect the not null status.",
        "Renaming a field shouldn't affect the"
    ],
    [
        "\"\"\"Renaming a field shouldn't affect a database default.\"\"\"",
        "\"\"\"Renaming a field shouldn't"
    ],
    [
        "if details[\"columns\"] == [new_field_name] and details[\"check\"]",
        "if details[\"columns\"] == [new_field_name]"
    ],
    [
        "f\"Cannot alter field {old_field} into {new_field} - they are not \"",
        "f\"Cannot alter field {old_field} into {new_field} - they are"
    ],
    [
        "any(\"DROP TABLE\" in query[\"sql\"] for query in ctx.captured_queries),",
        "any(\"DROP TABLE\" in query[\"sql\"] for query"
    ],
    [
        "self.fail(\"No check constraint for height found\")",
        "self.fail(\"No check constraint"
    ],
    [
        "if details[\"columns\"] == [\"height\"] and details[\"check\"]:",
        "if details[\"columns\"] =="
    ],
    [
        "self.fail(\"No check constraint for height found\")",
        "self.fail(\"No check constraint"
    ],
    [
        "Tests removing and adding unique constraints to a single column.",
        "Tests removing and adding unique constraints"
    ],
    [
        "If AlterField isn't selective about dropping foreign key constraints",
        "If AlterField isn't selective about dropping foreign key"
    ],
    [
        "when modifying a field with a unique constraint, the AlterField",
        "when modifying a field with a unique constraint, the"
    ],
    [
        "incorrectly drops and recreates the Book.author foreign key even though",
        "incorrectly drops and recreates the Book.author foreign key"
    ],
    [
        "Tests removing and adding unique_together constraints on a model.",
        "Tests removing and adding unique_together constraints"
    ],
    [
        "Tests removing and adding unique_together constraints that include",
        "Tests removing and adding unique_together constraints"
    ],
    [
        "Tests removing and adding unique_together constraints that include",
        "Tests removing and adding unique_together"
    ],
    [
        "a foreign key, where the foreign key is added after the model is",
        "a foreign key, where the foreign key is"
    ],
    [
        "\"WHERE %s IS NOT NULL\" % editor.quote_name(\"weight\"),",
        "\"WHERE %s IS NOT NULL\" %"
    ],
    [
        "self.skipTest(\"This backend does not support case-insensitive collations.\")",
        "self.skipTest(\"This backend does not support case-insensitive"
    ],
    [
        "\"Cannot resolve keyword 'nonexistent' into field. Choices are: \"",
        "\"Cannot resolve keyword 'nonexistent' into"
    ],
    [
        "Tests removing and adding index_together constraints on a model.",
        "Tests removing and adding index_together constraints on a"
    ],
    [
        "Changing db_index to False doesn't remove indexes from Meta.indexes.",
        "Changing db_index to False doesn't remove indexes"
    ],
    [
        "Indexes defined with ordering (ASC/DESC) defined on column",
        "Indexes defined with ordering (ASC/DESC)"
    ],
    [
        "\"Multiple references to %s can't be used in an indexed expression.\"",
        "\"Multiple references to %s can't be used in"
    ],
    [
        "\"%s must be topmost expressions in an indexed expression.\"",
        "\"%s must be topmost expressions in an"
    ],
    [
        "self.skipTest(\"This backend does not support case-insensitive collations.\")",
        "self.skipTest(\"This backend does not support"
    ],
    [
        "self.skipTest(\"This backend does not support case-insensitive collations.\")",
        "self.skipTest(\"This backend does not support case-insensitive"
    ],
    [
        "\"Cannot resolve keyword 'nonexistent' into field. Choices are: \"",
        "\"Cannot resolve keyword 'nonexistent' into field. Choices"
    ],
    [
        "Tests altering of the primary key",
        "Tests altering of"
    ],
    [
        "Ensures transaction is correctly closed when an error occurs",
        "Ensures transaction is correctly closed"
    ],
    [
        "\"Executing DDL statements while in a transaction on databases \"",
        "\"Executing DDL statements while in a transaction"
    ],
    [
        "\"that can't perform a rollback is prohibited.\"",
        "\"that can't perform a rollback is"
    ],
    [
        "editor.sql_create_table % {\"table\": \"foo\", \"definition\": \"\"}",
        "editor.sql_create_table % {\"table\": \"foo\","
    ],
    [
        "Only affects databases that supports foreign keys.",
        "Only affects databases that"
    ],
    [
        "Only affects databases that supports foreign keys.",
        "Only affects databases that supports foreign"
    ],
    [
        "Tries creating a model's table, and then deleting it when it has a",
        "Tries creating a model's table, and then deleting it when it"
    ],
    [
        "\"Errors when applying initial migration for a model \"",
        "\"Errors when applying initial migration for a model"
    ],
    [
        "\"with a table named after an SQL reserved word: %s\" % e",
        "\"with a table named after an SQL reserved word: %s\""
    ],
    [
        "No queries are performed if a field default changes and the field's",
        "No queries are performed if a field default changes and the"
    ],
    [
        "not changing from null to non-null.",
        "not changing from null to"
    ],
    [
        "No queries are performed when changing field attributes that don't",
        "No queries are performed when changing field attributes"
    ],
    [
        "comment = \"Custom comment with default\"",
        "comment = \"Custom"
    ],
    [
        "comment = \"This is the name.\"",
        "comment = \"This is the"
    ],
    [
        "ModelWithDbTableComment, \"Custom table comment\", \"New table comment\"",
        "ModelWithDbTableComment, \"Custom table comment\", \"New"
    ],
    [
        "Changing the primary key field name of a model with a self-referential",
        "Changing the primary key field name"
    ],
    [
        "effective_default() should be used for DateField, DateTimeField, and",
        "effective_default() should be used for DateField, DateTimeField,"
    ],
    [
        "Table names are stripped of their namespace/schema before being used to",
        "Table names are stripped of their"
    ],
    [
        "namespaced_table_name = '\"%s\".\"%s\"' % (namespace, table_name)",
        "namespaced_table_name = '\"%s\".\"%s\"'"
    ],
    [
        "connection.vendor == \"oracle\", \"Oracle specific db_table syntax\"",
        "connection.vendor == \"oracle\", \"Oracle"
    ],
    [
        "connection.vendor == \"postgresql\", \"PostgreSQL specific db_table syntax.\"",
        "connection.vendor == \"postgresql\", \"PostgreSQL"
    ],
    [
        "Foreign keys without database level constraint don't prevent the field",
        "Foreign keys without database level constraint don't prevent"
    ],
    [
        "they reference from being renamed in an atomic block.",
        "they reference from being renamed in"
    ],
    [
        "foo = ForeignKey(Foo, CASCADE, to_field=\"field\", db_constraint=False)",
        "foo = ForeignKey(Foo, CASCADE,"
    ],
    [
        "Foreign keys without database level constraint don't prevent the table",
        "Foreign keys without database level constraint"
    ],
    [
        "they reference from being renamed in an atomic block.",
        "they reference from being renamed"
    ],
    [
        "foo = ForeignKey(Foo, CASCADE, to_field=\"field\", db_constraint=False)",
        "foo = ForeignKey(Foo,"
    ],
    [
        "\"CREATE COLLATION IF NOT EXISTS case_insensitive \"",
        "\"CREATE COLLATION IF NOT EXISTS"
    ],
    [
        "return super().__dir__() + dir(global_settings) + [\"FOO\"]",
        "return super().__dir__() + dir(global_settings)"
    ],
    [
        "A series of tests to establish that the command-line management tools work as",
        "A series of tests to establish that the command-line"
    ],
    [
        "advertised - especially with regards to the handling of the",
        "advertised - especially with regards to the"
    ],
    [
        "from django.core.checks import Error, Tags, register",
        "from django.core.checks import"
    ],
    [
        "from django.core.management.commands.loaddata import Command as LoaddataCommand",
        "from django.core.management.commands.loaddata import Command as"
    ],
    [
        "from django.core.management.commands.runserver import Command as RunserverCommand",
        "from django.core.management.commands.runserver import"
    ],
    [
        "from django.core.management.commands.testserver import Command as TestserverCommand",
        "from django.core.management.commands.testserver import Command as"
    ],
    [
        "from django.test import LiveServerTestCase, SimpleTestCase, TestCase, override_settings",
        "from django.test import LiveServerTestCase,"
    ],
    [
        "SYSTEM_CHECK_MSG = \"System check identified no issues\"",
        "SYSTEM_CHECK_MSG = \"System check identified no"
    ],
    [
        "def write_settings(self, filename, apps=None, is_dir=False, sdict=None, extra=None):",
        "def write_settings(self, filename, apps=None, is_dir=False,"
    ],
    [
        "if not isinstance(o, (dict, tuple, list)):",
        "if not isinstance(o, (dict, tuple,"
    ],
    [
        "settings_file.write(\"%s = %s\\n\" % (s, o))",
        "settings_file.write(\"%s = %s\\n\" %"
    ],
    [
        "settings_file.write(\"%s = %s\\n\" % (k, v))",
        "settings_file.write(\"%s = %s\\n\""
    ],
    [
        "Returns the paths for any external backend packages.",
        "Returns the paths for any external"
    ],
    [
        "return self.run_test([\"-m\", \"django\", *args], settings_file, umask=umask)",
        "return self.run_test([\"-m\", \"django\", *args], settings_file,"
    ],
    [
        "\"Utility assertion: assert that the given stream is empty\"",
        "\"Utility assertion: assert that the given"
    ],
    [
        "\"Utility assertion: assert that the given message exists in the output\"",
        "\"Utility assertion: assert that the given message exists"
    ],
    [
        "\"'%s' does not match actual output text '%s'\" % (msg, stream),",
        "\"'%s' does not match actual output text '%s'\""
    ],
    [
        "\"'%s' does not match actual output text '%s'\" % (msg, stream),",
        "\"'%s' does not match actual output"
    ],
    [
        "\"Utility assertion: assert that the given message doesn't exist in the output\"",
        "\"Utility assertion: assert that the given"
    ],
    [
        "msg, stream, \"'%s' matches actual output text '%s'\" % (msg, stream)",
        "msg, stream, \"'%s' matches actual output text '%s'\" %"
    ],
    [
        "\"A series of tests for django-admin when there is no settings.py file.\"",
        "\"A series of tests for django-admin when there is no"
    ],
    [
        "no settings: django-admin builtin commands fail with an error when no",
        "no settings: django-admin builtin commands fail with"
    ],
    [
        "no settings: django-admin builtin commands fail if settings file (from",
        "no settings: django-admin builtin commands"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named '?bad_settings'?\","
    ],
    [
        "no settings: django-admin builtin commands fail if settings file (from",
        "no settings: django-admin builtin commands fail if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "Commands that don't require settings succeed if the settings file",
        "Commands that don't require settings succeed if the"
    ],
    [
        "self.assertOutput(err, \"You must provide a project name\", regex=True)",
        "self.assertOutput(err, \"You must provide a project name\","
    ],
    [
        "A series of tests for django-admin when using a settings.py file that",
        "A series of tests for django-admin when using a"
    ],
    [
        "default: django-admin builtin commands fail with an error when no",
        "default: django-admin builtin commands fail"
    ],
    [
        "default: django-admin builtin commands succeed if settings are provided",
        "default: django-admin builtin commands succeed if"
    ],
    [
        "default: django-admin builtin commands succeed if settings are provided",
        "default: django-admin builtin commands succeed if settings are"
    ],
    [
        "default: django-admin builtin commands fail if settings file (from",
        "default: django-admin builtin commands fail if"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "default: django-admin builtin commands fail if settings file (from",
        "default: django-admin builtin commands fail if"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named"
    ],
    [
        "default: django-admin can't execute user commands if it isn't provided",
        "default: django-admin can't execute user commands if it isn't"
    ],
    [
        "default: django-admin can execute user commands if settings are",
        "default: django-admin can execute user commands"
    ],
    [
        "default: django-admin can execute user commands if settings are",
        "default: django-admin can execute user commands if"
    ],
    [
        "A series of tests for django-admin when using a settings.py file that",
        "A series of tests for django-admin"
    ],
    [
        "contains the test application specified using a full path.",
        "contains the test application specified using a"
    ],
    [
        "fulldefault: django-admin builtin commands fail with an error when no",
        "fulldefault: django-admin builtin commands fail with"
    ],
    [
        "fulldefault: django-admin builtin commands succeed if a settings file",
        "fulldefault: django-admin builtin commands succeed if"
    ],
    [
        "fulldefault: django-admin builtin commands succeed if the environment",
        "fulldefault: django-admin builtin commands succeed if the"
    ],
    [
        "fulldefault: django-admin builtin commands fail if settings file (from",
        "fulldefault: django-admin builtin commands fail if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named"
    ],
    [
        "fulldefault: django-admin builtin commands fail if settings file (from",
        "fulldefault: django-admin builtin commands fail"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named '?bad_settings'?\","
    ],
    [
        "fulldefault: django-admin can't execute user commands unless settings",
        "fulldefault: django-admin can't execute user commands"
    ],
    [
        "fulldefault: django-admin can execute user commands if settings are",
        "fulldefault: django-admin can execute user commands if settings"
    ],
    [
        "fulldefault: django-admin can execute user commands if settings are",
        "fulldefault: django-admin can execute user commands if settings"
    ],
    [
        "A series of tests for django-admin when using a settings.py file that",
        "A series of tests for django-admin"
    ],
    [
        "minimal: django-admin builtin commands fail with an error when no",
        "minimal: django-admin builtin commands fail with an error"
    ],
    [
        "minimal: django-admin builtin commands fail if settings are provided as",
        "minimal: django-admin builtin commands fail"
    ],
    [
        "self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")",
        "self.assertOutput(err, \"No installed app"
    ],
    [
        "minimal: django-admin builtin commands fail if settings are provided in",
        "minimal: django-admin builtin commands fail if"
    ],
    [
        "self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")",
        "self.assertOutput(err, \"No installed app with label"
    ],
    [
        "minimal: django-admin builtin commands fail if settings file (from",
        "minimal: django-admin builtin commands fail if"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "minimal: django-admin builtin commands fail if settings file (from",
        "minimal: django-admin builtin commands fail if settings file"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named"
    ],
    [
        "\"minimal: django-admin can't execute user commands unless settings are provided\"",
        "\"minimal: django-admin can't execute user commands unless"
    ],
    [
        "minimal: django-admin can't execute user commands, even if settings are",
        "minimal: django-admin can't execute user commands, even if settings"
    ],
    [
        "minimal: django-admin can't execute user commands, even if settings are",
        "minimal: django-admin can't execute user commands, even"
    ],
    [
        "A series of tests for django-admin when using a settings file with a name",
        "A series of tests for django-admin when using a settings file with a"
    ],
    [
        "alternate: django-admin builtin commands fail with an error when no",
        "alternate: django-admin builtin commands fail with an error when"
    ],
    [
        "alternate: django-admin builtin commands succeed if settings are",
        "alternate: django-admin builtin commands succeed"
    ],
    [
        "alternate: django-admin builtin commands succeed if settings are",
        "alternate: django-admin builtin commands succeed"
    ],
    [
        "alternate: django-admin builtin commands fail if settings file (from",
        "alternate: django-admin builtin commands fail if settings file"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named"
    ],
    [
        "alternate: django-admin builtin commands fail if settings file (from",
        "alternate: django-admin builtin commands fail if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named"
    ],
    [
        "alternate: django-admin can't execute user commands unless settings",
        "alternate: django-admin can't execute user commands"
    ],
    [
        "alternate: django-admin can execute user commands if settings are",
        "alternate: django-admin can execute user commands if settings"
    ],
    [
        "alternate: django-admin can execute user commands if settings are",
        "alternate: django-admin can execute user commands if"
    ],
    [
        "A series of tests for django-admin when multiple settings files",
        "A series of tests for"
    ],
    [
        "(including the default 'settings.py') are available. The default settings",
        "(including the default 'settings.py') are available."
    ],
    [
        "file is insufficient for performing the operations described, so the",
        "file is insufficient for performing the operations described,"
    ],
    [
        "alternate settings must be used by the running script.",
        "alternate settings must be used by the running"
    ],
    [
        "alternate: django-admin builtin commands fail with an error when no",
        "alternate: django-admin builtin commands fail with an error when"
    ],
    [
        "alternate: django-admin builtin commands succeed if settings are",
        "alternate: django-admin builtin commands succeed if settings"
    ],
    [
        "alternate: django-admin builtin commands succeed if settings are",
        "alternate: django-admin builtin commands succeed if"
    ],
    [
        "alternate: django-admin builtin commands fail if settings file (from",
        "alternate: django-admin builtin commands fail if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "alternate: django-admin builtin commands fail if settings file (from",
        "alternate: django-admin builtin commands fail if settings file"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named '?bad_settings'?\","
    ],
    [
        "alternate: django-admin can't execute user commands unless settings are",
        "alternate: django-admin can't execute user commands unless settings"
    ],
    [
        "alternate: django-admin can execute user commands if settings are",
        "alternate: django-admin can execute user"
    ],
    [
        "alternate: django-admin can execute user commands if settings are",
        "alternate: django-admin can execute user commands if"
    ],
    [
        "A series of tests for django-admin when the settings file is in a",
        "A series of tests for django-admin when the"
    ],
    [
        "\"directory: startapp creates the correct directory\"",
        "\"directory: startapp creates"
    ],
    [
        "'name = \"settings_test\"' if HAS_BLACK else \"name = 'settings_test'\",",
        "'name = \"settings_test\"' if HAS_BLACK else \"name"
    ],
    [
        "\"directory: startapp creates the correct directory with a custom template\"",
        "\"directory: startapp creates the correct directory with a custom"
    ],
    [
        "args = [\"startapp\", \"--template\", template_path, \"custom_settings_test\"]",
        "args = [\"startapp\","
    ],
    [
        "\"\"\"startapp creates the correct directory with Unicode characters.\"\"\"",
        "\"\"\"startapp creates the correct directory with Unicode"
    ],
    [
        "'name = \"こんにちは\"' if HAS_BLACK else \"name = 'こんにちは'\", content",
        "'name = \"こんにちは\"' if HAS_BLACK else \"name"
    ],
    [
        "directory: django-admin builtin commands fail with an error when no",
        "directory: django-admin builtin commands fail"
    ],
    [
        "directory: django-admin builtin commands fail if settings file (from",
        "directory: django-admin builtin commands fail if"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named '?bad_settings'?\","
    ],
    [
        "directory: django-admin builtin commands fail if settings file (from",
        "directory: django-admin builtin commands fail if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named"
    ],
    [
        "directory: django-admin can't execute user commands unless settings are",
        "directory: django-admin can't execute user"
    ],
    [
        "directory: django-admin builtin commands succeed if settings are",
        "directory: django-admin builtin commands succeed if"
    ],
    [
        "directory: django-admin builtin commands succeed if settings are",
        "directory: django-admin builtin commands succeed if settings"
    ],
    [
        "\"A series of tests for manage.py when there is no settings.py file.\"",
        "\"A series of tests for manage.py when there"
    ],
    [
        "no settings: manage.py builtin commands fail with an error when no",
        "no settings: manage.py builtin commands fail with"
    ],
    [
        "err, r\"No module named '?(test_project\\.)?settings'?\", regex=True",
        "err, r\"No module named"
    ],
    [
        "no settings: manage.py builtin commands fail if settings file (from",
        "no settings: manage.py builtin commands fail if settings file"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named '?bad_settings'?\","
    ],
    [
        "no settings: manage.py builtin commands fail if settings file (from",
        "no settings: manage.py builtin commands fail if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named '?bad_settings'?\","
    ],
    [
        "\"\"\"A series of tests for manage.py when using a settings.py file that",
        "\"\"\"A series of tests for manage.py when using"
    ],
    [
        "default: manage.py builtin commands succeed when default settings are",
        "default: manage.py builtin commands succeed when default"
    ],
    [
        "default: manage.py builtin commands succeed if settings are provided as",
        "default: manage.py builtin commands succeed if settings"
    ],
    [
        "default: manage.py builtin commands succeed if settings are provided in",
        "default: manage.py builtin commands succeed if"
    ],
    [
        "default: manage.py builtin commands succeed if settings file (from",
        "default: manage.py builtin commands succeed if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named"
    ],
    [
        "default: manage.py builtin commands fail if settings file (from",
        "default: manage.py builtin commands fail if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "default: manage.py can execute user commands when default settings are",
        "default: manage.py can execute user commands"
    ],
    [
        "default: manage.py can execute user commands when settings are provided",
        "default: manage.py can execute user"
    ],
    [
        "default: manage.py can execute user commands when settings are provided",
        "default: manage.py can execute user commands"
    ],
    [
        "\"\"\"A series of tests for manage.py when using a settings.py file that",
        "\"\"\"A series of tests for manage.py when using a settings.py file"
    ],
    [
        "contains the test application specified using a full path.",
        "contains the test application specified"
    ],
    [
        "fulldefault: manage.py builtin commands succeed when default settings",
        "fulldefault: manage.py builtin commands succeed when default"
    ],
    [
        "fulldefault: manage.py builtin commands succeed if settings are",
        "fulldefault: manage.py builtin commands succeed"
    ],
    [
        "fulldefault: manage.py builtin commands succeed if settings are",
        "fulldefault: manage.py builtin commands"
    ],
    [
        "fulldefault: manage.py builtin commands succeed if settings file (from",
        "fulldefault: manage.py builtin commands succeed if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "fulldefault: manage.py builtin commands fail if settings file (from",
        "fulldefault: manage.py builtin commands fail"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named"
    ],
    [
        "fulldefault: manage.py can execute user commands when default settings",
        "fulldefault: manage.py can execute user commands when"
    ],
    [
        "fulldefault: manage.py can execute user commands when settings are",
        "fulldefault: manage.py can execute user"
    ],
    [
        "fulldefault: manage.py can execute user commands when settings are",
        "fulldefault: manage.py can execute user commands when"
    ],
    [
        "\"\"\"A series of tests for manage.py when using a settings.py file that",
        "\"\"\"A series of tests for manage.py when using a settings.py file"
    ],
    [
        "minimal: manage.py builtin commands fail with an error when no settings",
        "minimal: manage.py builtin commands fail with an"
    ],
    [
        "self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")",
        "self.assertOutput(err, \"No installed app with"
    ],
    [
        "\"minimal: manage.py builtin commands fail if settings are provided as argument\"",
        "\"minimal: manage.py builtin commands fail if settings are provided as"
    ],
    [
        "self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")",
        "self.assertOutput(err, \"No installed app with"
    ],
    [
        "minimal: manage.py builtin commands fail if settings are provided in",
        "minimal: manage.py builtin commands fail if settings are provided"
    ],
    [
        "self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")",
        "self.assertOutput(err, \"No installed app"
    ],
    [
        "minimal: manage.py builtin commands fail if settings file (from",
        "minimal: manage.py builtin commands fail if"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "minimal: manage.py builtin commands fail if settings file (from",
        "minimal: manage.py builtin commands fail if settings file"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "\"minimal: manage.py can't execute user commands without appropriate settings\"",
        "\"minimal: manage.py can't execute user"
    ],
    [
        "minimal: manage.py can't execute user commands, even if settings are",
        "minimal: manage.py can't execute user commands, even if settings"
    ],
    [
        "minimal: manage.py can't execute user commands, even if settings are",
        "minimal: manage.py can't execute user commands, even if"
    ],
    [
        "\"\"\"A series of tests for manage.py when using a settings file",
        "\"\"\"A series of tests for manage.py when using"
    ],
    [
        "with a name other than 'settings.py'.",
        "with a name other"
    ],
    [
        "alternate: manage.py builtin commands fail with an error when no",
        "alternate: manage.py builtin commands fail with an error"
    ],
    [
        "err, r\"No module named '?(test_project\\.)?settings'?\", regex=True",
        "err, r\"No module named '?(test_project\\.)?settings'?\","
    ],
    [
        "\"alternate: manage.py builtin commands work with settings provided as argument\"",
        "\"alternate: manage.py builtin commands work with settings provided"
    ],
    [
        "alternate: manage.py builtin commands work if settings are provided in",
        "alternate: manage.py builtin commands work if settings"
    ],
    [
        "alternate: manage.py builtin commands fail if settings file (from",
        "alternate: manage.py builtin commands fail if settings"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named '?bad_settings'?\","
    ],
    [
        "alternate: manage.py builtin commands fail if settings file (from",
        "alternate: manage.py builtin commands fail if"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "\"alternate: manage.py can't execute user commands without settings\"",
        "\"alternate: manage.py can't execute user commands"
    ],
    [
        "err, r\"No module named '?(test_project\\.)?settings'?\", regex=True",
        "err, r\"No module named"
    ],
    [
        "alternate: manage.py can execute user commands if settings are provided",
        "alternate: manage.py can execute user commands if settings are"
    ],
    [
        "\"('no_color', False), ('pythonpath', None), ('settings', \"",
        "\"('no_color', False), ('pythonpath', None),"
    ],
    [
        "alternate: manage.py can execute user commands if settings are provided",
        "alternate: manage.py can execute user commands if settings are"
    ],
    [
        "\"('no_color', False), ('pythonpath', None), ('settings', None), \"",
        "\"('no_color', False), ('pythonpath', None), ('settings',"
    ],
    [
        "alternate: manage.py output syntax color can be deactivated with the",
        "alternate: manage.py output syntax color"
    ],
    [
        "\"('no_color', True), ('pythonpath', None), ('settings', \"",
        "\"('no_color', True), ('pythonpath', None),"
    ],
    [
        "\"\"\"A series of tests for manage.py when multiple settings files",
        "\"\"\"A series of tests for manage.py when multiple settings"
    ],
    [
        "(including the default 'settings.py') are available. The default settings",
        "(including the default 'settings.py') are available."
    ],
    [
        "file is insufficient for performing the operations described, so the",
        "file is insufficient for performing the"
    ],
    [
        "alternate settings must be used by the running script.",
        "alternate settings must be used by the"
    ],
    [
        "multiple: manage.py builtin commands fail with an error when no",
        "multiple: manage.py builtin commands fail with an"
    ],
    [
        "self.assertOutput(err, \"No installed app with label 'admin_scripts'.\")",
        "self.assertOutput(err, \"No installed app"
    ],
    [
        "multiple: manage.py builtin commands succeed if settings are provided",
        "multiple: manage.py builtin commands succeed if settings"
    ],
    [
        "multiple: manage.py can execute builtin commands if settings are",
        "multiple: manage.py can execute builtin"
    ],
    [
        "multiple: manage.py builtin commands fail if settings file (from",
        "multiple: manage.py builtin commands fail if settings file"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module named '?bad_settings'?\","
    ],
    [
        "multiple: manage.py builtin commands fail if settings file (from",
        "multiple: manage.py builtin commands fail if"
    ],
    [
        "self.assertOutput(err, \"No module named '?bad_settings'?\", regex=True)",
        "self.assertOutput(err, \"No module"
    ],
    [
        "\"multiple: manage.py can't execute user commands using default settings\"",
        "\"multiple: manage.py can't execute user commands"
    ],
    [
        "multiple: manage.py can execute user commands if settings are provided",
        "multiple: manage.py can execute user commands"
    ],
    [
        "multiple: manage.py can execute user commands if settings are provided",
        "multiple: manage.py can execute user commands if"
    ],
    [
        "Tests for manage.py when using the default settings.py file containing",
        "Tests for manage.py when using the default settings.py"
    ],
    [
        "import error: manage.py builtin commands shows useful diagnostic info",
        "import error: manage.py builtin commands shows useful"
    ],
    [
        "manage.py builtin commands does not swallow attribute error due to bad",
        "manage.py builtin commands does not swallow"
    ],
    [
        "self.assertOutput(err, \"AttributeError: 'list' object has no attribute 'crash'\")",
        "self.assertOutput(err, \"AttributeError: 'list' object has no attribute"
    ],
    [
        "Test listing available commands output note when only core commands are",
        "Test listing available commands output note when only core"
    ],
    [
        "self.assertOutput(out, \"only Django core commands are listed\")",
        "self.assertOutput(out, \"only Django core"
    ],
    [
        "\"\"\"check reports an error on a nonexistent app in INSTALLED_APPS.\"\"\"",
        "\"\"\"check reports an error on a nonexistent"
    ],
    [
        "\"\"\"manage.py check reports an ImportError if an app's models.py",
        "\"\"\"manage.py check reports an ImportError"
    ],
    [
        "\"\"\"manage.py check does not raise an ImportError validating a",
        "\"\"\"manage.py check does not raise"
    ],
    [
        "complex app with nested calls to load_app\"\"\"",
        "complex app with nested calls to"
    ],
    [
        "\"\"\"manage.py check does not raise errors when an app imports a base",
        "\"\"\"manage.py check does not raise errors when an app imports a"
    ],
    [
        "class that itself has an abstract base.\"\"\"",
        "class that itself has an abstract"
    ],
    [
        "\"\"\"All errors/warnings should be sorted by level and by message.\"\"\"",
        "\"\"\"All errors/warnings should be sorted by"
    ],
    [
        "\"SystemCheckError: System check identified some issues:\\n\"",
        "\"SystemCheckError: System check identified"
    ],
    [
        "When there are only warnings or less serious messages, then Django",
        "When there are only warnings or"
    ],
    [
        "should not prevent user from launching their project, so `check`",
        "should not prevent user from launching their project, so"
    ],
    [
        "command should not raise `CommandError` exception.",
        "command should not raise `CommandError`"
    ],
    [
        "In this test we also test output format.",
        "In this test we"
    ],
    [
        "\"WARNING: This is a development server. Do not use it in a \"",
        "\"WARNING: This is a development server. Do not use"
    ],
    [
        "\"production setting. Use a production WSGI or ASGI server instead.\"",
        "\"production setting. Use a production WSGI or ASGI"
    ],
    [
        "\"\\nFor more information on production servers see: \"",
        "\"\\nFor more information on"
    ],
    [
        "\"WARNING: This is a development server. Do not use it in a \"",
        "\"WARNING: This is a development server. Do"
    ],
    [
        "\"production setting. Use a production WSGI or ASGI server instead.\"",
        "\"production setting. Use a production WSGI or ASGI"
    ],
    [
        "\"\\nFor more information on production servers see: \"",
        "\"\\nFor more information on production servers see:"
    ],
    [
        "\"WARNING: This is a development server. Do not use it in a \"",
        "\"WARNING: This is a development server. Do not use it in a"
    ],
    [
        "\"production setting. Use a production WSGI or ASGI server instead.\"",
        "\"production setting. Use a production WSGI or ASGI server"
    ],
    [
        "\"\\nFor more information on production servers see: \"",
        "\"\\nFor more information on"
    ],
    [
        "Ensure runserver.check_migrations doesn't choke on empty DATABASES.",
        "Ensure runserver.check_migrations doesn't choke"
    ],
    [
        "runserver.check_migrations() doesn't choke when a database is read-only.",
        "runserver.check_migrations() doesn't choke when a"
    ],
    [
        "\"\"\"Rather than mock run(), raise immediately after system checks run.\"\"\"",
        "\"\"\"Rather than mock run(), raise immediately after"
    ],
    [
        "self.assertIn(\"apply the migrations for app(s): app_waiting_migration.\", output)",
        "self.assertIn(\"apply the migrations for app(s): app_waiting_migration.\","
    ],
    [
        "\"apply the migrations for app(s): another_app_waiting_migration, \"",
        "\"apply the migrations for app(s): another_app_waiting_migration,"
    ],
    [
        "err, \"CommandError: You must set settings.ALLOWED_HOSTS if DEBUG is False.\"",
        "err, \"CommandError: You must set settings.ALLOWED_HOSTS if DEBUG"
    ],
    [
        "\"\"\"runserver doesn't support --verbosity and --trackback options.\"\"\"",
        "\"\"\"runserver doesn't support --verbosity and --trackback"
    ],
    [
        "\"\\nServer stopped.\\nNote that the test database, 'test_db', \"",
        "\"\\nServer stopped.\\nNote that the"
    ],
    [
        "\"has not been deleted. You can explore it on your own.\"",
        "\"has not been deleted. You can"
    ],
    [
        "\"Tests for the various types of base command types that can be defined.\"",
        "\"Tests for the various types of base command types that can be"
    ],
    [
        "\"version is handled as a special case\"",
        "\"version is handled as"
    ],
    [
        "\"help is handled as a special case\"",
        "\"help is handled as a"
    ],
    [
        "out, \"Type 'manage.py help <subcommand>' for help on a specific subcommand.\"",
        "out, \"Type 'manage.py help <subcommand>' for help on"
    ],
    [
        "\"help --commands shows the list of all available commands\"",
        "\"help --commands shows the list of all"
    ],
    [
        "\"-h is handled as a short form of --help\"",
        "\"-h is handled as a short form of"
    ],
    [
        "\"--help can be used on a specific command\"",
        "\"--help can be used"
    ],
    [
        "out, \"Checks the entire Django project for potential problems.\"",
        "out, \"Checks the entire Django project for potential"
    ],
    [
        "\"--no-color prevent colorization of the output\"",
        "\"--no-color prevent colorization of the"
    ],
    [
        "msg = \"The --no-color and --force-color options can't be used together.\"",
        "msg = \"The --no-color and --force-color options can't"
    ],
    [
        "msg = \"'no_color' and 'force_color' can't be used together.\"",
        "msg = \"'no_color' and 'force_color' can't be"
    ],
    [
        "\"User BaseCommands can execute when a label is provided\"",
        "\"User BaseCommands can execute when"
    ],
    [
        "\"User BaseCommands can execute when no labels are provided\"",
        "\"User BaseCommands can execute when no labels"
    ],
    [
        "\"User BaseCommands can execute when no labels are provided\"",
        "\"User BaseCommands can execute when no"
    ],
    [
        "\"User BaseCommands can execute with options when a label is provided\"",
        "\"User BaseCommands can execute with options when"
    ],
    [
        "\"User BaseCommands can execute with multiple options when a label is provided\"",
        "\"User BaseCommands can execute with multiple"
    ],
    [
        "args = [\"base_command\", \"testlabel\", \"-a\", \"x\", \"--option_b=y\"]",
        "args = [\"base_command\", \"testlabel\", \"-a\","
    ],
    [
        "\"User BaseCommands outputs command usage when wrong option is specified\"",
        "\"User BaseCommands outputs command usage when wrong option is"
    ],
    [
        "\"('pythonpath', None), ('settings', None), ('traceback', False), \"",
        "\"('pythonpath', None), ('settings', None), ('traceback', False),"
    ],
    [
        "Non-ASCII message of CommandError does not raise any",
        "Non-ASCII message of CommandError does not"
    ],
    [
        "A command called from the command line should close connections after",
        "A command called from the command line should close"
    ],
    [
        "command.handle = lambda *args, **kwargs: args",
        "command.handle = lambda *args, **kwargs:"
    ],
    [
        "\"('no_color', False), ('pythonpath', None), ('settings', None), \"",
        "\"('no_color', False), ('pythonpath', None), ('settings',"
    ],
    [
        "\"NoArg Commands raise an error if an argument is provided\"",
        "\"NoArg Commands raise an error if"
    ],
    [
        "\"User AppCommands can execute when a single app name is provided\"",
        "\"User AppCommands can execute when a single app name is"
    ],
    [
        "\", options=[('force_color', False), ('no_color', False), \"",
        "\", options=[('force_color', False), ('no_color',"
    ],
    [
        "\"('pythonpath', None), ('settings', None), ('traceback', False), \"",
        "\"('pythonpath', None), ('settings', None), ('traceback', False),"
    ],
    [
        "\"User AppCommands raise an error when no app name is provided\"",
        "\"User AppCommands raise an error when no"
    ],
    [
        "self.assertOutput(err, \"error: Enter at least one application label.\")",
        "self.assertOutput(err, \"error: Enter at least one application"
    ],
    [
        "\"User AppCommands raise an error when multiple app names are provided\"",
        "\"User AppCommands raise an error when"
    ],
    [
        "\", options=[('force_color', False), ('no_color', False), \"",
        "\", options=[('force_color', False), ('no_color', False),"
    ],
    [
        "\"('pythonpath', None), ('settings', None), ('traceback', False), \"",
        "\"('pythonpath', None), ('settings', None), ('traceback',"
    ],
    [
        "\", options=[('force_color', False), ('no_color', False), \"",
        "\", options=[('force_color', False),"
    ],
    [
        "\"('pythonpath', None), ('settings', None), ('traceback', False), \"",
        "\"('pythonpath', None), ('settings', None), ('traceback', False),"
    ],
    [
        "\"User AppCommands can execute when a single app name is provided\"",
        "\"User AppCommands can execute when a single app name is"
    ],
    [
        "self.assertOutput(err, \"No installed app with label 'NOT_AN_APP'.\")",
        "self.assertOutput(err, \"No installed app with"
    ],
    [
        "\"User AppCommands can execute when some of the provided app names are invalid\"",
        "\"User AppCommands can execute when some of"
    ],
    [
        "self.assertOutput(err, \"No installed app with label 'NOT_AN_APP'.\")",
        "self.assertOutput(err, \"No installed app with label"
    ],
    [
        "\"User LabelCommands can execute when a label is provided\"",
        "\"User LabelCommands can execute when a label"
    ],
    [
        "\"False), ('no_color', False), ('pythonpath', None), ('settings', \"",
        "\"False), ('no_color', False), ('pythonpath', None), ('settings',"
    ],
    [
        "\"User LabelCommands raise an error if no label is provided\"",
        "\"User LabelCommands raise an error if no"
    ],
    [
        "self.assertOutput(err, \"Enter at least one label\")",
        "self.assertOutput(err, \"Enter at least one"
    ],
    [
        "\"User LabelCommands are executed multiple times if multiple labels are provided\"",
        "\"User LabelCommands are executed multiple times if"
    ],
    [
        "\"False), ('no_color', False), ('pythonpath', None), \"",
        "\"False), ('no_color', False), ('pythonpath',"
    ],
    [
        "\"False), ('no_color', False), ('pythonpath', None), \"",
        "\"False), ('no_color', False), ('pythonpath', None),"
    ],
    [
        "self.assertOutput(out, \"Test suppress base options command.\")",
        "self.assertOutput(out, \"Test suppress base"
    ],
    [
        "Apps listed first in INSTALLED_APPS have precedence.",
        "Apps listed first in INSTALLED_APPS"
    ],
    [
        "r\"Error: argument --database: invalid choice: 'deflaut' \"",
        "r\"Error: argument --database: invalid choice: 'deflaut'"
    ],
    [
        "(--settings, --traceback and --pythonpath) are parsed using a basic parser,",
        "(--settings, --traceback and --pythonpath) are parsed"
    ],
    [
        "ignoring any unknown options. Then the full settings are",
        "ignoring any unknown options. Then the full settings"
    ],
    [
        "passed to the command parser, which extracts commands of interest to the",
        "passed to the command parser, which extracts"
    ],
    [
        "\"\"\"Options passed after settings are correctly handled.\"\"\"",
        "\"\"\"Options passed after settings are correctly"
    ],
    [
        "\"\"\"Short options passed after settings are correctly handled.\"\"\"",
        "\"\"\"Short options passed after settings are correctly"
    ],
    [
        "args = [\"base_command\", \"testlabel\", \"--settings=alternate_settings\", \"-a\", \"x\"]",
        "args = [\"base_command\", \"testlabel\", \"--settings=alternate_settings\","
    ],
    [
        "\"\"\"Options passed before settings are correctly handled.\"\"\"",
        "\"\"\"Options passed before settings are correctly"
    ],
    [
        "\"\"\"Short options passed before settings are correctly handled.\"\"\"",
        "\"\"\"Short options passed before settings are"
    ],
    [
        "args = [\"base_command\", \"testlabel\", \"-a\", \"x\", \"--settings=alternate_settings\"]",
        "args = [\"base_command\", \"testlabel\", \"-a\","
    ],
    [
        "\"\"\"Options are correctly handled when they are passed before and after",
        "\"\"\"Options are correctly handled when they"
    ],
    [
        "\"('force_color', False), ('no_color', False), ('option_a', 'x'), \"",
        "\"('force_color', False), ('no_color', False),"
    ],
    [
        "Program name is computed from the execute_from_command_line()'s argv",
        "Program name is computed from the"
    ],
    [
        "with captured_stdout() as out, captured_stderr() as err:",
        "with captured_stdout() as out, captured_stderr() as"
    ],
    [
        "Passing the wrong kinds of arguments outputs an error and prints usage.",
        "Passing the wrong kinds of arguments outputs an"
    ],
    [
        "self.assertOutput(err, \"You must provide a project name.\")",
        "self.assertOutput(err, \"You must provide a project"
    ],
    [
        "\"Make sure the startproject management command creates a project\"",
        "\"Make sure the startproject management command creates a"
    ],
    [
        "\"CommandError: 'testproject' conflicts with the name of an \"",
        "\"CommandError: 'testproject' conflicts with the"
    ],
    [
        "\"existing Python module and cannot be used as a project name. \"",
        "\"existing Python module and cannot be"
    ],
    [
        "\"Make sure the startproject management command validates a project name\"",
        "\"Make sure the startproject management command"
    ],
    [
        "\"Error: '%s' is not a valid project name. Please make \"",
        "\"Error: '%s' is not a valid project name. Please make"
    ],
    [
        "\"sure the name is a valid identifier.\" % bad_name,",
        "\"sure the name is a valid"
    ],
    [
        "startproject validates that project name doesn't clash with existing",
        "startproject validates that project name doesn't clash"
    ],
    [
        "\"CommandError: 'os' conflicts with the name of an existing \"",
        "\"CommandError: 'os' conflicts with the name of an"
    ],
    [
        "\"Python module and cannot be used as a project name. Please try \"",
        "\"Python module and cannot be used as a project name."
    ],
    [
        "startproject doesn't import modules (and cannot be fooled by a module",
        "startproject doesn't import modules (and cannot be fooled by a"
    ],
    [
        "with open(os.path.join(self.test_dir, \"raises_import_error.py\"), \"w\") as f:",
        "with open(os.path.join(self.test_dir, \"raises_import_error.py\"), \"w\")"
    ],
    [
        "\"CommandError: 'raises_import_error' conflicts with the name of an \"",
        "\"CommandError: 'raises_import_error' conflicts with the name of an"
    ],
    [
        "\"existing Python module and cannot be used as a project name. Please try \"",
        "\"existing Python module and cannot be used as a project name."
    ],
    [
        "The startproject management command creates a project in a specific",
        "The startproject management command creates a project"
    ],
    [
        "\"already exists. Overlaying a project into an existing directory \"",
        "\"already exists. Overlaying a project into"
    ],
    [
        "The startproject management command is able to use a different project",
        "The startproject management command is able to use a"
    ],
    [
        "args = [\"startproject\", \"--template\", template_path, \"customtestproject\"]",
        "args = [\"startproject\", \"--template\","
    ],
    [
        "args = [\"startproject\", \"--template\", template_path, \"customtestproject\"]",
        "args = [\"startproject\","
    ],
    [
        "template_path = os.path.join(custom_templates_dir, \"project_template\" + os.sep)",
        "template_path = os.path.join(custom_templates_dir, \"project_template\""
    ],
    [
        "args = [\"startproject\", \"--template\", template_path, \"customtestproject\"]",
        "args = [\"startproject\", \"--template\","
    ],
    [
        "The startproject management command is able to use a different project",
        "The startproject management command is able to use a different"
    ],
    [
        "args = [\"startproject\", \"--template\", template_path, \"tarballtestproject\"]",
        "args = [\"startproject\", \"--template\", template_path,"
    ],
    [
        "Startproject can use a project template from a tarball and create it in",
        "Startproject can use a project template from"
    ],
    [
        "The startproject management command is able to use a different project",
        "The startproject management command is able to use a different"
    ],
    [
        "template from a tarball via a URL.",
        "template from a tarball via"
    ],
    [
        "args = [\"startproject\", \"--template\", template_url, \"urltestproject\"]",
        "args = [\"startproject\","
    ],
    [
        "args = [\"startproject\", \"--template\", template_url, \"urltestproject\"]",
        "args = [\"startproject\","
    ],
    [
        "Startproject management command handles project template tar/zip balls",
        "Startproject management command handles project"
    ],
    [
        "args = [\"startproject\", \"--template\", template_url, \"urltestproject\"]",
        "args = [\"startproject\", \"--template\", template_url,"
    ],
    [
        "\"Make sure the startproject management command is able to render custom files\"",
        "\"Make sure the startproject management command is able to render"
    ],
    [
        "for f in (\"Procfile\", \"additional_file.py\", \"requirements.txt\"):",
        "for f in"
    ],
    [
        "\"Make sure template context variables are rendered with proper values\"",
        "\"Make sure template context variables are rendered"
    ],
    [
        "self.assertIn('project_directory = \"%s\"' % testproject_dir, content)",
        "self.assertIn('project_directory = \"%s\"' %"
    ],
    [
        "\"Make sure template context variables are not html escaped\"",
        "\"Make sure template context variables are not"
    ],
    [
        "Make sure an exception is raised when the provided",
        "Make sure an exception is raised"
    ],
    [
        "\"Destination directory '%s' does not exist, please create it first.\"",
        "\"Destination directory '%s' does not exist, please"
    ],
    [
        "The startproject management command is able to render templates with",
        "The startproject management command is able"
    ],
    [
        "\"\"\"Hidden directories are excluded by default.\"\"\"",
        "\"\"\"Hidden directories are"
    ],
    [
        "Template context variables in hidden directories are rendered, if not",
        "Template context variables in hidden directories are rendered,"
    ],
    [
        "Excluded directories (in addition to .git and __pycache__) are not",
        "Excluded directories (in addition to .git and"
    ],
    [
        "\"Windows only partially supports umasks and chmod.\",",
        "\"Windows only partially supports umasks and"
    ],
    [
        "\"\"\"startapp validates that app name is a valid Python identifier.\"\"\"",
        "\"\"\"startapp validates that app name is a valid Python"
    ],
    [
        "\"CommandError: '{}' is not a valid app name. Please make \"",
        "\"CommandError: '{}' is not a valid app name. Please make"
    ],
    [
        "\"sure the name is a valid identifier.\".format(bad_name),",
        "\"sure the name is a valid"
    ],
    [
        "startapp validates that app name doesn't clash with existing Python",
        "startapp validates that app name doesn't"
    ],
    [
        "\"CommandError: 'os' conflicts with the name of an existing \"",
        "\"CommandError: 'os' conflicts with the"
    ],
    [
        "\"Python module and cannot be used as an app name. Please try \"",
        "\"Python module and cannot be used as an app name. Please try"
    ],
    [
        "_, err = self.run_django_admin([\"startapp\", \"app\", bad_target])",
        "_, err = self.run_django_admin([\"startapp\", \"app\","
    ],
    [
        "\"CommandError: '%s' is not a valid app directory. Please \"",
        "\"CommandError: '%s' is not a"
    ],
    [
        "\"make sure the directory is a valid identifier.\" % bad_target,",
        "\"make sure the directory is"
    ],
    [
        "_, err = self.run_django_admin([\"startapp\", \"app\", \"os\"])",
        "_, err ="
    ],
    [
        "\"CommandError: 'os' conflicts with the name of an existing Python \"",
        "\"CommandError: 'os' conflicts with the name of an"
    ],
    [
        "\"module and cannot be used as an app directory. Please try \"",
        "\"module and cannot be used as an app directory. Please"
    ],
    [
        "\"already exists. Overlaying an app into an existing directory \"",
        "\"already exists. Overlaying an app into an"
    ],
    [
        "'name = \"new_app\"' if HAS_BLACK else \"name = 'new_app'\",",
        "'name = \"new_app\"' if HAS_BLACK else \"name"
    ],
    [
        "\"\"\"Runs without error and emits settings diff.\"\"\"",
        "\"\"\"Runs without error and"
    ],
    [
        "\"\"\"The all option also shows settings with the default value.\"\"\"",
        "\"\"\"The all option also shows settings"
    ],
    [
        "The --default option specifies an alternate settings module for",
        "The --default option specifies an"
    ],
    [
        "\"\"\"--output=unified emits settings diff in unified mode.\"\"\"",
        "\"\"\"--output=unified emits settings diff"
    ],
    [
        "--output=unified --all emits settings diff in unified mode and includes",
        "--output=unified --all emits settings diff"
    ],
    [
        "Test would raise an exception rather than printing an error message.",
        "Test would raise an exception rather than printing an error"
    ],
    [
        "self.assertOutput(err, \"You can only use --pks option with one model\")",
        "self.assertOutput(err, \"You can only use --pks"
    ],
    [
        "\"\"\"python -m django works like django-admin.\"\"\"",
        "\"\"\"python -m django works"
    ],
    [
        "out, err = self.run_test([\"-m\", \"django\", \"help\"])",
        "out, err ="
    ],
    [
        "\"Type 'python -m django help <subcommand>' for help on a specific \"",
        "\"Type 'python -m django help <subcommand>' for help on a"
    ],
    [
        "self.assertOutput(err, \"Unknown command: 'rnserver'. Did you mean runserver?\")",
        "self.assertOutput(err, \"Unknown command: 'rnserver'. Did you mean"
    ],
    [
        "from django.core.management.commands.startproject import Command as BaseCommand",
        "from django.core.management.commands.startproject import Command"
    ],
    [
        "\"--extra\", help=\"An arbitrary extra value passed to the context\"",
        "\"--extra\", help=\"An arbitrary extra value passed"
    ],
    [
        "help = \"Test suppress base options command.\"",
        "help = \"Test suppress base"
    ],
    [
        "By default, Django adds an ``\"id\"`` field to each model. But you can override",
        "By default, Django adds an ``\"id\"`` field to"
    ],
    [
        "this behavior by explicitly adding ``primary_key=True`` to a field.",
        "this behavior by explicitly adding ``primary_key=True``"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\""
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self.value)",
        "return \"<%s: %s>\" % (self.__class__.__name__,"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TestCase, skipIfDBFeature,"
    ],
    [
        "from .models import Bar, Business, CustomAutoFieldModel, Employee, Foo",
        "from .models import Bar, Business,"
    ],
    [
        "Both pk and custom attribute_name can be used in filter and friends",
        "Both pk and custom attribute_name can be used"
    ],
    [
        "Custom pk doesn't affect related_name based lookups",
        "Custom pk doesn't affect related_name"
    ],
    [
        "Queries across tables, involving primary key",
        "Queries across tables, involving primary"
    ],
    [
        "Get can accept pk or the real attribute name",
        "Get can accept pk or the real attribute"
    ],
    [
        "pk and attribute name are available on the model",
        "pk and attribute name are available on the"
    ],
    [
        "No default id attribute is added",
        "No default id"
    ],
    [
        "AttributeError, \"'Employee' object has no attribute 'id'\"",
        "AttributeError, \"'Employee' object has no attribute"
    ],
    [
        "Custom pks work with in_bulk, both for integer and non-integer types",
        "Custom pks work with in_bulk, both for integer and non-integer"
    ],
    [
        "custom pks do not affect save",
        "custom pks do"
    ],
    [
        "New objects can be created both with pk and the custom name",
        "New objects can be created both with pk"
    ],
    [
        "Need to use a reserved SQL name as a column name or table name? Need to include",
        "Need to use a reserved SQL name as a column name or"
    ],
    [
        "a hyphen in a column or table name? No problem. Django quotes names",
        "a hyphen in a column or table name? No problem."
    ],
    [
        "appropriately behind the scenes, so your database won't complain about",
        "appropriately behind the scenes, so your database won't complain"
    ],
    [
        "things = [t.when for t in Thing.objects.order_by(\"when\")]",
        "things = [t.when for"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "from .models import AbstractPerson, BasePerson, Person, ProxyPerson, Relating, Relation",
        "from .models import AbstractPerson, BasePerson, Person, ProxyPerson, Relating,"
    ],
    [
        "from django.db.models import CharField, Field, ForeignObjectRel, ManyToManyField",
        "from django.db.models import CharField,"
    ],
    [
        "return tuple((o.name, m) for o, m in res)",
        "return tuple((o.name, m) for o,"
    ],
    [
        "return tuple((f.name, m) for f, m in res)",
        "return tuple((f.name, m) for f, m"
    ],
    [
        "return None if model == current_model else model",
        "return None if model == current_model"
    ],
    [
        "field = relation if direct else relation.field",
        "field = relation if direct"
    ],
    [
        "self.assertEqual([f.attname for f in fields], expected_result)",
        "self.assertEqual([f.attname for f in"
    ],
    [
        "return isinstance(f, Field) and not f.many_to_many",
        "return isinstance(f, Field) and"
    ],
    [
        "self.assertEqual([f.attname for f in fields], expected_result)",
        "self.assertEqual([f.attname for f in fields],"
    ],
    [
        "self.assertEqual([f.attname for f in fields], expected_result)",
        "self.assertEqual([f.attname for f in"
    ],
    [
        "self.assertEqual([f.attname for f in fields], expected_result)",
        "self.assertEqual([f.attname for f in fields],"
    ],
    [
        "models = [self._model(model, field) for field in model._meta.many_to_many]",
        "models = [self._model(model, field) for"
    ],
    [
        "self.assertEqual(sorted(f.name for f in objects), sorted(expected_names))",
        "self.assertEqual(sorted(f.name for f in"
    ],
    [
        "\"Person has no field named 'relating_baseperson'. The app \"",
        "\"Person has no field named 'relating_baseperson'. The"
    ],
    [
        "\"cache isn't ready yet, so if this is an auto-created related \"",
        "\"cache isn't ready yet, so if this is an auto-created"
    ],
    [
        "\"field, it won't be available yet.\"",
        "\"field, it won't"
    ],
    [
        "all_models = (Relation, AbstractPerson, BasePerson, Person, ProxyPerson, Relating)",
        "all_models = (Relation, AbstractPerson, BasePerson, Person,"
    ],
    [
        "all_models_with_cache = (m for m in self.all_models if not m._meta.abstract)",
        "all_models_with_cache = (m for m"
    ],
    [
        "m for m in self.all_models if m is not AbstractPerson",
        "m for m in self.all_models if m is not"
    ],
    [
        "msg = \"Abstract models cannot be instantiated.\"",
        "msg = \"Abstract models cannot"
    ],
    [
        "return f\"{value} -- decorated by @wraps.\"",
        "return f\"{value} --"
    ],
    [
        "description = \"A more thorough description of my blog.\"",
        "description = \"A more thorough description of my"
    ],
    [
        "return \"Overridden description: %s\" % item",
        "return \"Overridden description:"
    ],
    [
        "A feed where the latest entry date is an `updated` element.",
        "A feed where the latest entry date is an"
    ],
    [
        "A feed to test no link being defined. Articles have no get_absolute_url()",
        "A feed to test no link being defined. Articles"
    ],
    [
        "method, and item_link() is not defined.",
        "method, and item_link() is not"
    ],
    [
        "A feed to test that RSS feeds work with a single enclosure.",
        "A feed to test that RSS feeds"
    ],
    [
        "A feed to test that RSS feeds raise an exception with multiple enclosures.",
        "A feed to test that RSS feeds raise an exception with multiple"
    ],
    [
        "A feed to test defining item titles and descriptions with templates.",
        "A feed to test defining item titles and descriptions"
    ],
    [
        "A feed to test custom context data in templates for title or description.",
        "A feed to test custom context data in templates for title or"
    ],
    [
        "return \"Article description: %s\" % item.title",
        "return \"Article description: %s\" %"
    ],
    [
        "A feed with naive (non-timezone-aware) dates.",
        "A feed with"
    ],
    [
        "Test of a custom feed generator class.",
        "Test of a custom feed"
    ],
    [
        "A feed to test that Atom feeds work with a single enclosure.",
        "A feed to test that Atom feeds work with"
    ],
    [
        "A feed to test that Atom feeds work with multiple enclosures.",
        "A feed to test that Atom"
    ],
    [
        "title=\"A & B < C > D\",",
        "title=\"A & B < C"
    ],
    [
        "actual = {n.nodeName for n in elem.childNodes}",
        "actual = {n.nodeName for n"
    ],
    [
        "Tests for the high-level syndication feed framework.",
        "Tests for the high-level syndication feed"
    ],
    [
        "\"description\": \"A more thorough description of my blog.\",",
        "\"description\": \"A more thorough description"
    ],
    [
        "\"description\": \"Overridden description: My first entry\",",
        "\"description\": \"Overridden description: My"
    ],
    [
        "\"title\": \"Overridden title -- decorated by @wraps.\",",
        "\"title\": \"Overridden title -- decorated"
    ],
    [
        "\"description\": \"Overridden description -- decorated by @wraps.\",",
        "\"description\": \"Overridden description --"
    ],
    [
        "\"description\": \"Overridden item description -- decorated by @wraps.\",",
        "\"description\": \"Overridden item description -- decorated by"
    ],
    [
        "\"Feed method 'item_description' decorated by 'wrapper' needs to use \"",
        "\"Feed method 'item_description' decorated by 'wrapper'"
    ],
    [
        "Test if the 'isPermaLink' attribute of <guid> element of an item",
        "Test if the 'isPermaLink' attribute of"
    ],
    [
        "in the RSS feed is 'false'.",
        "in the RSS"
    ],
    [
        "Test if the 'isPermaLink' attribute of <guid> element of an item",
        "Test if the 'isPermaLink' attribute of <guid> element"
    ],
    [
        "in the RSS feed is 'true'.",
        "in the RSS feed is"
    ],
    [
        "\"RSS feed items may only have one enclosure, see \"",
        "\"RSS feed items may only have one enclosure, see"
    ],
    [
        "\"description\": \"Overridden description: My first entry\",",
        "\"description\": \"Overridden description: My"
    ],
    [
        "The published and updated elements are not",
        "The published and updated elements"
    ],
    [
        "links = [link for link in links if link.getAttribute(\"rel\") == \"enclosure\"]",
        "links = [link for link in links if link.getAttribute(\"rel\")"
    ],
    [
        "links = [link for link in links if link.getAttribute(\"rel\") == \"enclosure\"]",
        "links = [link for link in links if link.getAttribute(\"rel\") =="
    ],
    [
        "Both the published and updated dates are",
        "Both the published and"
    ],
    [
        "considered when determining the latest post date.",
        "considered when determining the latest post"
    ],
    [
        "Titles are escaped correctly in RSS feeds.",
        "Titles are escaped correctly in"
    ],
    [
        "self.assertEqual(title.firstChild.wholeText, \"A &amp; B &lt; C &gt; D\")",
        "self.assertEqual(title.firstChild.wholeText, \"A &amp; B &lt;"
    ],
    [
        "Datetimes are correctly converted to the local time zone.",
        "Datetimes are correctly converted to the"
    ],
    [
        "Datetimes with timezones don't get trodden on.",
        "Datetimes with timezones don't"
    ],
    [
        "(\"/stylesheet.xsl\", \"stylesheets should be a list, not <class 'str'>\"),",
        "(\"/stylesheet.xsl\", \"stylesheets should be a list, not"
    ],
    [
        "\"stylesheets should be a list, \"",
        "\"stylesheets should be"
    ],
    [
        "Tests the Last-Modified header with naive publication dates.",
        "Tests the Last-Modified header with naive publication"
    ],
    [
        "Tests the Last-Modified header with aware publication dates.",
        "Tests the Last-Modified header with aware"
    ],
    [
        "Test URLs are prefixed with https:// when feed is requested over HTTPS.",
        "Test URLs are prefixed with https://"
    ],
    [
        "An ImproperlyConfigured is raised if no link could be found for the",
        "An ImproperlyConfigured is raised if no link could be"
    ],
    [
        "\"Give your Article class a get_absolute_url() method, or define \"",
        "\"Give your Article class a get_absolute_url() method, or"
    ],
    [
        "\"an item_link() method in your Feed class.\"",
        "\"an item_link() method in your"
    ],
    [
        "The item title and description can be overridden with templates.",
        "The item title and description"
    ],
    [
        "\"title\": \"Title in your templates: My first entry\\n\",",
        "\"title\": \"Title in your templates:"
    ],
    [
        "\"description\": \"Description in your templates: My first entry\\n\",",
        "\"description\": \"Description in your templates: My first"
    ],
    [
        "Custom context data can be passed to templates for title",
        "Custom context data can be passed"
    ],
    [
        "\"title\": \"My first entry (foo is bar)\\n\",",
        "\"title\": \"My first entry (foo is"
    ],
    [
        "\"description\": \"My first entry (foo is bar)\\n\",",
        "\"description\": \"My first entry"
    ],
    [
        "add_domain() prefixes domains onto the correct URLs.",
        "add_domain() prefixes domains onto the"
    ],
    [
        "\"description\": \"Article description: My first article\",",
        "\"description\": \"Article description: My first"
    ],
    [
        "Django handles transactions in three different ways. The default is to commit",
        "Django handles transactions in three different ways."
    ],
    [
        "each transaction upon a write, but you can decorate a function to get",
        "each transaction upon a write, but you can decorate"
    ],
    [
        "commit-on-success behavior. Alternatively, you can manage the transaction",
        "commit-on-success behavior. Alternatively, you can manage the"
    ],
    [
        "return (\"%s %s\" % (self.first_name, self.last_name)).strip()",
        "return (\"%s %s\" % (self.first_name,"
    ],
    [
        "Tests for the atomic decorator and context manager.",
        "Tests for the atomic decorator and context"
    ],
    [
        "The tests make assertions on internal attributes because there isn't a",
        "The tests make assertions on internal attributes because there"
    ],
    [
        "robust way to ask the database for its current transaction state.",
        "robust way to ask the database for its"
    ],
    [
        "Since the decorator syntax is converted into a context manager (see the",
        "Since the decorator syntax is converted"
    ],
    [
        "implementation), there are only a few basic tests with the decorator",
        "implementation), there are only a few"
    ],
    [
        "syntax and the bulk of the tests use the context manager syntax.",
        "syntax and the bulk of the tests use the context"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's his last"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's his"
    ],
    [
        "raise Exception(\"Oops, that's his first name\")",
        "raise Exception(\"Oops, that's"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's"
    ],
    [
        "raise Exception(\"Oops, that's his first name\")",
        "raise Exception(\"Oops, that's"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's his last"
    ],
    [
        "raise Exception(\"Oops, that's his first name\")",
        "raise Exception(\"Oops, that's his"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's his last"
    ],
    [
        "raise Exception(\"Oops, that's his first name\")",
        "raise Exception(\"Oops, that's"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's"
    ],
    [
        "raise Exception(\"Oops, that's his first name\")",
        "raise Exception(\"Oops, that's his"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's his last"
    ],
    [
        "raise Exception(\"Oops, that's his first name\")",
        "raise Exception(\"Oops, that's his first"
    ],
    [
        "\"\"\"All basic tests for atomic should also pass within an existing transaction.\"\"\"",
        "\"\"\"All basic tests for atomic should also pass within"
    ],
    [
        "\"\"\"All basic tests for atomic should also pass when autocommit is turned off.\"\"\"",
        "\"\"\"All basic tests for atomic should also pass"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's his last"
    ],
    [
        "raise Exception(\"Oops, that's his last name\")",
        "raise Exception(\"Oops, that's his last"
    ],
    [
        "forbidden_atomic_msg = \"This is forbidden when an 'atomic' block is active.\"",
        "forbidden_atomic_msg = \"This is forbidden when an 'atomic'"
    ],
    [
        "\"An error occurred in the current transaction. You can't \"",
        "\"An error occurred in the current transaction."
    ],
    [
        "\"execute queries until the end of the 'atomic' block.\"",
        "\"execute queries until the end"
    ],
    [
        "@skipIf(threading is None, \"Test requires threading\")",
        "@skipIf(threading is None, \"Test"
    ],
    [
        "msg = \"You can't execute queries until the end of the 'atomic' block.\"",
        "msg = \"You can't execute queries until the end of the"
    ],
    [
        "ORM queries are allowed after an error and a rollback in non-autocommit",
        "ORM queries are allowed after an"
    ],
    [
        "msg = \"A durable atomic block cannot be nested within another atomic block.\"",
        "msg = \"A durable atomic block cannot be nested within another atomic"
    ],
    [
        "msg = \"A durable atomic block cannot be nested within another atomic block.\"",
        "msg = \"A durable atomic block cannot be nested within another atomic"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, router, transaction",
        "from django.db import"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import SimpleTestCase,"
    ],
    [
        "from .models import Book, Person, Pet, Review, UserProfile",
        "from .models import Book, Person, Pet, Review,"
    ],
    [
        "from .routers import AuthRouter, TestRouter, WriteRouter",
        "from .routers import"
    ],
    [
        "\"Querysets will use the default database by default\"",
        "\"Querysets will use the default"
    ],
    [
        "\"Objects created on the default database don't leak onto other databases\"",
        "\"Objects created on the default database don't leak"
    ],
    [
        "self.fail('\"Pro Django\" should exist on default database')",
        "self.fail('\"Pro Django\" should exist"
    ],
    [
        "self.fail('\"Dive into Python\" should exist on default database')",
        "self.fail('\"Dive into Python\" should"
    ],
    [
        "\"Objects created on another database don't leak onto the default database\"",
        "\"Objects created on another database don't leak"
    ],
    [
        "self.fail('\"Pro Django\" should exist on other database')",
        "self.fail('\"Pro Django\" should exist on other"
    ],
    [
        "self.fail('\"Dive into Python\" should exist on other database')",
        "self.fail('\"Dive into Python\" should exist"
    ],
    [
        "self.assertEqual(dive.title, \"Dive into Python (on default)\")",
        "self.assertEqual(dive.title, \"Dive into"
    ],
    [
        "\"Queries are constrained to a single database\"",
        "\"Queries are constrained to"
    ],
    [
        "self.assertEqual([o.year for o in years], [])",
        "self.assertEqual([o.year for o in"
    ],
    [
        "self.assertEqual([o.month for o in months], [])",
        "self.assertEqual([o.month for o in months],"
    ],
    [
        "'Cannot assign \"<Person: Marty Alchin>\": the current database '",
        "'Cannot assign \"<Person: Marty Alchin>\": the"
    ],
    [
        "'Cannot add \"<Book: Dive into Python>\": instance is on '",
        "'Cannot add \"<Book: Dive into Python>\":"
    ],
    [
        "'database \"default\", value is on database \"other\"'",
        "'database \"default\", value is on"
    ],
    [
        "'Cannot add \"<Person: Marty Alchin>\": instance is on '",
        "'Cannot add \"<Person: Marty Alchin>\": instance is"
    ],
    [
        "'database \"other\", value is on database \"default\"'",
        "'database \"other\", value is on database"
    ],
    [
        "\"FK fields are constrained to a single database\"",
        "\"FK fields are constrained to"
    ],
    [
        "\"FK reverse manipulations are all constrained to a single DB\"",
        "\"FK reverse manipulations are all"
    ],
    [
        "\"Operations that involve sharing FK objects across databases raise an error\"",
        "\"Operations that involve sharing FK objects across"
    ],
    [
        "'Cannot assign \"<Person: Marty Alchin>\": the current database '",
        "'Cannot assign \"<Person: Marty Alchin>\": the current"
    ],
    [
        "Cascaded deletions of Foreign Key relations issue queries on the right",
        "Cascaded deletions of Foreign Key relations issue queries on"
    ],
    [
        "ForeignKey.validate() passes `model` to db_for_read() even if",
        "ForeignKey.validate() passes `model` to db_for_read() even"
    ],
    [
        "\"OneToOne fields are constrained to a single database\"",
        "\"OneToOne fields are constrained to a"
    ],
    [
        "\"Operations that involve sharing FK objects across databases raise an error\"",
        "\"Operations that involve sharing FK objects across databases raise"
    ],
    [
        "'Cannot assign \"%r\": the current database router prevents this '",
        "'Cannot assign \"%r\": the current"
    ],
    [
        "\"Generic fields are constrained to a single database\"",
        "\"Generic fields are constrained to"
    ],
    [
        "\"Generic reverse manipulations are all constrained to a single DB\"",
        "\"Generic reverse manipulations are all constrained to a"
    ],
    [
        "Operations that involve sharing generic key objects across databases",
        "Operations that involve sharing generic"
    ],
    [
        "'Cannot assign \"<ContentType: Multiple_Database | book>\": the '",
        "'Cannot assign \"<ContentType: Multiple_Database |"
    ],
    [
        "\"current database router prevents this relation.\"",
        "\"current database router prevents this"
    ],
    [
        "\"<Review: Python Monthly> instance isn't saved. \"",
        "\"<Review: Python Monthly> instance isn't saved."
    ],
    [
        "\"Use bulk=False or save the object first.\"",
        "\"Use bulk=False or save"
    ],
    [
        "Cascaded deletions of Generic Key relations issue queries on the right",
        "Cascaded deletions of Generic Key relations"
    ],
    [
        "\"get_next_by_XXX commands stick to a single database\"",
        "\"get_next_by_XXX commands stick to"
    ],
    [
        "\"test the raw() method across databases\"",
        "\"test the raw()"
    ],
    [
        "val = Book.objects.raw(\"SELECT id FROM multiple_database_book\").using(\"other\")",
        "val = Book.objects.raw(\"SELECT id"
    ],
    [
        "Database assignment is retained if an object is retrieved with",
        "Database assignment is retained if an object"
    ],
    [
        "\"\"\"Make sure as_sql works with subqueries and primary/replica.\"\"\"",
        "\"\"\"Make sure as_sql works with subqueries and"
    ],
    [
        "\"Subqueries aren't allowed across different databases. Force the \"",
        "\"Subqueries aren't allowed across different databases."
    ],
    [
        "\"inner query to be evaluated using `list(inner_query)`.\"",
        "\"inner query to be"
    ],
    [
        "\"Related managers return managers, not querysets\"",
        "\"Related managers return"
    ],
    [
        "\"Querysets obey the router for db suggestions\"",
        "\"Querysets obey the router for"
    ],
    [
        "\"A router can choose to implement a subset of methods\"",
        "\"A router can choose to implement"
    ],
    [
        "\"<Book: Dive into Python> instance isn't saved. Use bulk=False or save the \"",
        "\"<Book: Dive into Python> instance isn't saved. Use bulk=False or save"
    ],
    [
        "\"Foreign keys can cross databases if they two databases have a common source\"",
        "\"Foreign keys can cross databases if they two"
    ],
    [
        "\"Operations that involve sharing FK objects across databases raise an error\"",
        "\"Operations that involve sharing FK objects across databases raise an"
    ],
    [
        "\"Generic Key operations can span databases if they share a source\"",
        "\"Generic Key operations can span databases"
    ],
    [
        "nyt = dive.reviews.create(source=\"New York Times\", content_object=dive)",
        "nyt = dive.reviews.create(source=\"New York"
    ],
    [
        "FK reverse relations are represented by managers, and can be controlled",
        "FK reverse relations are represented by"
    ],
    [
        "Generic key relations are represented by managers, and can be",
        "Generic key relations are represented"
    ],
    [
        "\"\"\"Make sure as_sql works with subqueries and primary/replica.\"\"\"",
        "\"\"\"Make sure as_sql works"
    ],
    [
        "\"The methods on the auth manager obey database hints\"",
        "\"The methods on the auth manager"
    ],
    [
        "\"dumpdata honors allow_migrate restrictions on the router\"",
        "\"dumpdata honors allow_migrate restrictions on"
    ],
    [
        "def allow_migrate(self, db, app_label, model_name=None, **hints):",
        "def allow_migrate(self, db,"
    ],
    [
        "A fixture can contain entries, but lead to nothing in the database;",
        "A fixture can contain entries, but lead to nothing in the"
    ],
    [
        "A router that sends all writes to the other database.",
        "A router that sends all"
    ],
    [
        "The pre/post_save signal contains the correct database.",
        "The pre/post_save signal contains"
    ],
    [
        "\"A router to test the exception handling of ConnectionRouter\"",
        "\"A router to test the exception handling of"
    ],
    [
        "\"The AttributeError from AttributeErrorRouter bubbles up\"",
        "\"The AttributeError from AttributeErrorRouter"
    ],
    [
        "\"The AttributeError from AttributeErrorRouter bubbles up\"",
        "\"The AttributeError from AttributeErrorRouter"
    ],
    [
        "\"The AttributeError from AttributeErrorRouter bubbles up\"",
        "\"The AttributeError from AttributeErrorRouter bubbles"
    ],
    [
        "\"The AttributeError from AttributeErrorRouter bubbles up\"",
        "\"The AttributeError from AttributeErrorRouter"
    ],
    [
        "\"A router to ensure model arguments are real model classes\"",
        "\"A router to ensure model arguments"
    ],
    [
        "\"\"\"allow_relation() is called with unsaved model instances.\"\"\"",
        "\"\"\"allow_relation() is called with unsaved model"
    ],
    [
        "router_prevents_msg = \"the current database router prevents this relation\"",
        "router_prevents_msg = \"the current database router prevents this"
    ],
    [
        "Vaguely behave like primary/replica, but the databases aren't assumed to",
        "Vaguely behave like primary/replica, but the databases aren't"
    ],
    [
        "Control all database operations on models in the contrib.auth application.",
        "Control all database operations on models"
    ],
    [
        "\"Point all read operations on auth models to 'default'\"",
        "\"Point all read operations on auth models"
    ],
    [
        "\"Point all operations on auth models to 'other'\"",
        "\"Point all operations on auth"
    ],
    [
        "\"Allow any relation if a model in Auth is involved\"",
        "\"Allow any relation if a model in"
    ],
    [
        "\"Make sure the auth app only appears on the 'other' db\"",
        "\"Make sure the auth app only appears on"
    ],
    [
        "from django.core.serializers.json import Deserializer as JsonDeserializer",
        "from django.core.serializers.json import Deserializer as"
    ],
    [
        "from django.core.serializers.jsonl import Deserializer as JsonlDeserializer",
        "from django.core.serializers.jsonl import Deserializer"
    ],
    [
        "from django.core.serializers.pyyaml import Deserializer as YamlDeserializer",
        "from django.core.serializers.pyyaml import Deserializer"
    ],
    [
        "\"Objects with PK=%d not equal; expected '%s' (%s), got '%s' (%s)\"",
        "\"Objects with PK=%d not equal; expected '%s'"
    ],
    [
        "\"title\": \"The Definitive Guide to Django: Web Development Done Right\",",
        "\"title\": \"The Definitive Guide to Django: Web Development"
    ],
    [
        "[(book.object.title, book.object.pk) for book in books],",
        "[(book.object.title, book.object.pk) for"
    ],
    [
        "If serializing objects in a multi-table inheritance relationship using",
        "If serializing objects in a"
    ],
    [
        "natural primary keys, the natural foreign key for the parent is output in",
        "natural primary keys, the natural foreign key for the"
    ],
    [
        "the fields of the child so it's possible to relate the child to the parent",
        "the fields of the child so it's possible to relate the"
    ],
    [
        "msg = \"NaturalKeyThing matching query does not exist\"",
        "msg = \"NaturalKeyThing matching"
    ],
    [
        "msg = \"NaturalKeyThing matching query does not exist\"",
        "msg = \"NaturalKeyThing matching query"
    ],
    [
        "The deserializer works with natural keys when the primary key has a default",
        "The deserializer works with natural keys when the primary key has"
    ],
    [
        "The deserializer doesn't rely on natural keys when a model has a custom",
        "The deserializer doesn't rely on natural keys when a model"
    ],
    [
        "primary key that is a ForeignKey.",
        "primary key that"
    ],
    [
        "pkless_str = \"\\n\".join([s.replace(\"\\n\", \"\") for s in pkless_str])",
        "pkless_str = \"\\n\".join([s.replace(\"\\n\", \"\")"
    ],
    [
        "'\"headline\": \"Poker has no place on ESPN\",'",
        "'\"headline\": \"Poker has no place on"
    ],
    [
        "serial_list = [json.loads(line) for line in serial_str.split(\"\\n\") if line]",
        "serial_list = [json.loads(line) for line in serial_str.split(\"\\n\")"
    ],
    [
        "return [obj_dict[\"pk\"] for obj_dict in serial_list]",
        "return [obj_dict[\"pk\"] for obj_dict in"
    ],
    [
        "serial_list = [json.loads(line) for line in serial_str.split(\"\\n\") if line]",
        "serial_list = [json.loads(line) for line in serial_str.split(\"\\n\") if"
    ],
    [
        "If there is an invalid primary key, the error message contains the",
        "If there is an invalid primary key, the error"
    ],
    [
        "If there is an invalid field value, the error message contains the",
        "If there is an invalid field value, the"
    ],
    [
        "Invalid foreign keys with a natural key throws a helpful error message,",
        "Invalid foreign keys with a natural"
    ],
    [
        "such as what the failing key is.",
        "such as what the"
    ],
    [
        "Invalid many-to-many keys throws a helpful error message.",
        "Invalid many-to-many keys throws a"
    ],
    [
        "test_string = \"\\n\".join([s.replace(\"\\n\", \"\") for s in test_strings])",
        "test_string = \"\\n\".join([s.replace(\"\\n\", \"\") for s in"
    ],
    [
        "Invalid many-to-many keys throws a helpful error message where one of a",
        "Invalid many-to-many keys throws a helpful error message where one"
    ],
    [
        "list of natural keys is invalid.",
        "list of natural keys is"
    ],
    [
        "test_string = \"\\n\".join([s.replace(\"\\n\", \"\") for s in test_strings])",
        "test_string = \"\\n\".join([s.replace(\"\\n\", \"\") for s in"
    ],
    [
        "Invalid many-to-many keys throws a helpful error message where a",
        "Invalid many-to-many keys throws a"
    ],
    [
        "natural many-to-many key has only a single value.",
        "natural many-to-many key has only a single"
    ],
    [
        "test_string = \"\\n\".join([s.replace(\"\\n\", \"\") for s in test_strings])",
        "test_string = \"\\n\".join([s.replace(\"\\n\", \"\")"
    ],
    [
        "for obj in serializers.deserialize(\"jsonl\", test_string, ignore=False):",
        "for obj in"
    ],
    [
        "Not iterable many-to-many field value throws a helpful error message.",
        "Not iterable many-to-many field value throws a helpful"
    ],
    [
        "\"headline\": \"Forward references pose no problem\",",
        "\"headline\": \"Forward references pose no"
    ],
    [
        "fwd_ref_str = \"\\n\".join([s.replace(\"\\n\", \"\") for s in fwd_ref_str])",
        "fwd_ref_str = \"\\n\".join([s.replace(\"\\n\", \"\") for s"
    ],
    [
        "<field name=\"headline\" type=\"CharField\">Poker has no place on ESPN</field>",
        "<field name=\"headline\" type=\"CharField\">Poker has no"
    ],
    [
        "<field name=\"categories\" rel=\"ManyToManyRel\" to=\"serializers.category\"><object pk=\"%(first_category_pk)s\"></object><object pk=\"%(second_category_pk)s\"></object></field>",
        "<field name=\"categories\" rel=\"ManyToManyRel\" to=\"serializers.category\"><object pk=\"%(first_category_pk)s\"></object><object"
    ],
    [
        "Serializing control characters with XML should fail as those characters",
        "Serializing control characters with XML should fail as those"
    ],
    [
        "\"HT \\t, LF \\n, and CR \\r are allowed\",",
        "\"HT \\t, LF \\n, and CR \\r are"
    ],
    [
        "The XML deserializer shouldn't allow a DTD.",
        "The XML deserializer shouldn't"
    ],
    [
        "This is the most straightforward way to prevent all entity definitions",
        "This is the most straightforward way to"
    ],
    [
        "and avoid both external entities and entity-expansion attacks.",
        "and avoid both external entities and"
    ],
    [
        "<field type=\"CharField\" name=\"headline\">Forward references pose no problem</field>",
        "<field type=\"CharField\" name=\"headline\">Forward references pose no"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, TransactionTestCase",
        "from django.test import"
    ],
    [
        "YAML_IMPORT_ERROR_MESSAGE = r\"No module named yaml\"",
        "YAML_IMPORT_ERROR_MESSAGE = r\"No module named"
    ],
    [
        "\"\"\"Provides a wrapped import_module function to simulate yaml ImportError",
        "\"\"\"Provides a wrapped import_module function to simulate"
    ],
    [
        "In order to run tests that verify the behavior of the YAML serializer",
        "In order to run tests that verify the behavior"
    ],
    [
        "when run on a system that has yaml installed (like the django CI server),",
        "when run on a system that has yaml installed (like"
    ],
    [
        "mock import_module, so that it raises an ImportError when the yaml",
        "mock import_module, so that it raises"
    ],
    [
        "serializer is being imported.  The importlib.import_module() call is",
        "serializer is being imported. The importlib.import_module() call"
    ],
    [
        "\"\"\"Not having pyyaml installed provides a misleading error",
        "\"\"\"Not having pyyaml installed provides a"
    ],
    [
        "\"\"\"Removes imported yaml and stubs importlib.import_module\"\"\"",
        "\"\"\"Removes imported yaml"
    ],
    [
        "\"\"\"Using yaml serializer without pyyaml raises ImportError\"\"\"",
        "\"\"\"Using yaml serializer without pyyaml raises"
    ],
    [
        "\"\"\"Using yaml deserializer without pyyaml raises ImportError\"\"\"",
        "\"\"\"Using yaml deserializer without pyyaml"
    ],
    [
        "\"\"\"Calling dumpdata produces an error when yaml package missing\"\"\"",
        "\"\"\"Calling dumpdata produces an error when yaml package"
    ],
    [
        "headline: Poker has no place on ESPN",
        "headline: Poker has no place"
    ],
    [
        "else \"\\n    - %(first_category_pk)s\\n    - %(second_category_pk)s\"",
        "else \"\\n - %(first_category_pk)s\\n -"
    ],
    [
        "if \"fields\" in obj_dict and field_name in obj_dict[\"fields\"]:",
        "if \"fields\" in obj_dict and field_name"
    ],
    [
        "headline: Forward references pose no problem",
        "headline: Forward references"
    ],
    [
        "A test spanning all the capabilities of all the serializers.",
        "A test spanning all the"
    ],
    [
        "This class defines sample data and a dynamically generated",
        "This class defines sample data and a dynamically"
    ],
    [
        "test case that is capable of testing the capabilities of",
        "test case that is capable of"
    ],
    [
        "the serializers. This includes all valid data values, plus",
        "the serializers. This includes all"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TestCase,"
    ],
    [
        "if klass == BinaryData and data is not None:",
        "if klass == BinaryData and data is not"
    ],
    [
        "\"Objects with PK=%d not equal; expected '%s' (%s), got '%s' (%s)\"",
        "\"Objects with PK=%d not equal; expected '%s' (%s),"
    ],
    [
        "\"Objects with PK=%d not equal; expected '%s' (%s), got '%s' (%s)\"",
        "\"Objects with PK=%d not equal; expected"
    ],
    [
        "testcase.assertEqual(data, [obj.id for obj in instance.data.order_by(\"id\")])",
        "testcase.assertEqual(data, [obj.id for obj in"
    ],
    [
        "\"\"\"This is a long piece of text.",
        "\"\"\"This is a long piece of"
    ],
    [
        "for test_helper, pk, model, data_value in data:",
        "for test_helper, pk, model, data_value"
    ],
    [
        "for _, _, model, _ in data:",
        "for _, _, model,"
    ],
    [
        "for test_helper, pk, model, data_value in data:",
        "for test_helper, pk, model,"
    ],
    [
        "\"\"\"This is a long piece of text.",
        "\"\"\"This is a long piece of"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, TransactionTestCase",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "\"headline\": \"Poker has no place on ESPN\",",
        "\"headline\": \"Poker has no place on"
    ],
    [
        "return [obj_dict[\"pk\"] for obj_dict in serial_list]",
        "return [obj_dict[\"pk\"] for"
    ],
    [
        "If there is an invalid primary key, the error message should contain",
        "If there is an invalid primary key,"
    ],
    [
        "If there is an invalid field value, the error message should contain",
        "If there is an invalid field value,"
    ],
    [
        "Invalid foreign keys with a natural key should throw a helpful error",
        "Invalid foreign keys with a natural"
    ],
    [
        "message, such as what the failing key is.",
        "message, such as what the failing"
    ],
    [
        "Invalid many-to-many keys should throw a helpful error message.",
        "Invalid many-to-many keys should throw"
    ],
    [
        "Invalid many-to-many keys should throw a helpful error message.",
        "Invalid many-to-many keys should throw a helpful error"
    ],
    [
        "This tests the code path where one of a list of natural keys is invalid.",
        "This tests the code path where one of a list of natural"
    ],
    [
        "Invalid many-to-many keys should throw a helpful error message. This",
        "Invalid many-to-many keys should throw a helpful error message."
    ],
    [
        "tests the code path where a natural many-to-many key has only a single",
        "tests the code path where a natural many-to-many key has only"
    ],
    [
        "for obj in serializers.deserialize(\"json\", test_string, ignore=False):",
        "for obj in"
    ],
    [
        "Not iterable many-to-many field value throws a helpful error message.",
        "Not iterable many-to-many field value throws a"
    ],
    [
        "\"headline\": \"Forward references pose no problem\",",
        "\"headline\": \"Forward references pose no"
    ],
    [
        "from django.test import SimpleTestCase, override_settings, skipUnlessDBFeature",
        "from django.test import SimpleTestCase,"
    ],
    [
        "Unregistering a serializer doesn't cause the registry to be",
        "Unregistering a serializer doesn't cause"
    ],
    [
        "\"Requesting a list of serializer formats populates the registry\"",
        "\"Requesting a list of serializer"
    ],
    [
        "headline=\"Poker has no place on ESPN\",",
        "headline=\"Poker has no place on"
    ],
    [
        "The ability to create new objects by modifying serialized content.",
        "The ability to create new objects by modifying serialized"
    ],
    [
        "old_headline = \"Poker has no place on ESPN\"",
        "old_headline = \"Poker has no place"
    ],
    [
        "new_headline = \"Poker has no place on television\"",
        "new_headline = \"Poker has no"
    ],
    [
        "If you use your own primary key field (such as a OneToOneField), it",
        "If you use your own primary key field"
    ],
    [
        "doesn't appear in the serialized field list - it replaces the pk",
        "doesn't appear in the serialized field list -"
    ],
    [
        "\"\"\"Output can be restricted to a subset of fields\"\"\"",
        "\"\"\"Output can be restricted to a subset"
    ],
    [
        "\"[\" + \".\" * ProgressBar.progress_width + \"]\\n\"",
        "\"[\" + \".\" * ProgressBar.progress_width +"
    ],
    [
        "\"\"\"Ensure no superfluous queries are made when serializing ForeignKeys",
        "\"\"\"Ensure no superfluous queries are made"
    ],
    [
        "Serialized data with no primary key results",
        "Serialized data with no primary"
    ],
    [
        "in a model instance with no id",
        "in a model instance with"
    ],
    [
        "\"\"\"Float values serialize and deserialize intact\"\"\"",
        "\"\"\"Float values serialize and"
    ],
    [
        "\"\"\"Custom fields serialize and deserialize intact\"\"\"",
        "\"\"\"Custom fields serialize"
    ],
    [
        "Serialized strings without PKs can be turned into models",
        "Serialized strings without PKs can be turned"
    ],
    [
        "\"\"\"Deserialized content can be saved with force_insert as a parameter.\"\"\"",
        "\"\"\"Deserialized content can be saved"
    ],
    [
        "Objects ids can be referenced before they are",
        "Objects ids can be referenced before they"
    ],
    [
        "for model_cls in (Category, Author, Article):",
        "for model_cls in (Category, Author,"
    ],
    [
        "Dynamically create serializer tests to ensure that all registered",
        "Dynamically create serializer tests to ensure that"
    ],
    [
        "if format_ == \"geojson\" or format_ in exclude:",
        "if format_ == \"geojson\""
    ],
    [
        "\"The Python library for the %s serializer is not installed.\" % format_,",
        "\"The Python library for the %s serializer"
    ],
    [
        "test_class, method_name % format_, partialmethod(decorated_func, format_)",
        "test_class, method_name % format_,"
    ],
    [
        "raise NotImplementedError(\"This method was not expected to be called.\")",
        "raise NotImplementedError(\"This method was not expected to"
    ],
    [
        "``django.core.serializers`` provides interfaces to converting Django",
        "``django.core.serializers`` provides interfaces"
    ],
    [
        "``QuerySet`` objects to and from \"flat\" data (i.e. strings).",
        "``QuerySet`` objects to and from \"flat\""
    ],
    [
        "return \"[%s:%s]=%s\" % (self.kind, self.name, self.value)",
        "return \"[%s:%s]=%s\" % (self.kind, self.name,"
    ],
    [
        "return \"Profile of %s\" % self.author",
        "return \"Profile of %s\" %"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "return \"%s (%d) playing for %s\" % (self.name, self.rank, self.team.to_string())",
        "return \"%s (%d) playing for %s\" % (self.name,"
    ],
    [
        "The following classes are for testing basic data marshalling, including",
        "The following classes are for"
    ],
    [
        "The basic idea is to have a model for each Django data type.",
        "The basic idea is to have a model"
    ],
    [
        "\"\"\"This is a model that can be used as",
        "\"\"\"This is a model that"
    ],
    [
        "something for other models to point at\"\"\"",
        "something for other models to point"
    ],
    [
        "\"\"\"This is a model that can be used as",
        "\"\"\"This is a model that"
    ],
    [
        "something for other models to point at\"\"\"",
        "something for other models to point"
    ],
    [
        "data = models.ForeignKey(UniqueAnchor, models.SET_NULL, null=True, to_field=\"data\")",
        "data = models.ForeignKey(UniqueAnchor, models.SET_NULL, null=True,"
    ],
    [
        "A save method that modifies the data in the object.",
        "A save method that modifies the"
    ],
    [
        "A user-defined save() method isn't called when objects are deserialized",
        "A user-defined save() method isn't called when objects"
    ],
    [
        "You can use a custom ``Manager`` in a particular model by extending the base",
        "You can use a custom ``Manager`` in a particular model by extending"
    ],
    [
        "``Manager`` class and instantiating your custom ``Manager`` in your model.",
        "``Manager`` class and instantiating your"
    ],
    [
        "There are two reasons you might want to customize a ``Manager``: to add extra",
        "There are two reasons you might want to customize"
    ],
    [
        "``Manager`` methods, and/or to modify the initial ``QuerySet`` the ``Manager``",
        "``Manager`` methods, and/or to modify the initial ``QuerySet`` the"
    ],
    [
        "self, custom_optional_arg=None, model=None, query=None, using=None, hints=None",
        "self, custom_optional_arg=None, model=None,"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\" % (self.first_name,"
    ],
    [
        "top_speed = models.IntegerField(help_text=\"In miles per hour.\")",
        "top_speed = models.IntegerField(help_text=\"In miles"
    ],
    [
        "title=\"How to program\", author=\"Rodney Dangerfield\", is_published=True",
        "title=\"How to program\", author=\"Rodney"
    ],
    [
        "title=\"How to be smart\", author=\"Albert Einstein\", is_published=False",
        "title=\"How to be smart\", author=\"Albert"
    ],
    [
        "The methods of a custom QuerySet are properly copied onto the",
        "The methods of a custom QuerySet are properly copied onto"
    ],
    [
        "\"%r object has no attribute 'optout_public_method'\"",
        "\"%r object has no attribute"
    ],
    [
        "Custom manager will use the queryset methods",
        "Custom manager will use the queryset"
    ],
    [
        "The custom manager __init__() argument has been set.",
        "The custom manager __init__() argument has"
    ],
    [
        "Custom manager method is only available on the manager and not on",
        "Custom manager method is only available on the manager and not"
    ],
    [
        "msg = \"'CustomQuerySet' object has no attribute 'manager_only'\"",
        "msg = \"'CustomQuerySet' object has"
    ],
    [
        "Queryset method doesn't override the custom manager method.",
        "Queryset method doesn't override the"
    ],
    [
        "The related managers extend the default manager.",
        "The related managers extend"
    ],
    [
        "The default manager, \"objects\", doesn't exist, because a custom one",
        "The default manager, \"objects\", doesn't exist, because a custom"
    ],
    [
        "msg = \"type object 'Book' has no attribute 'objects'\"",
        "msg = \"type object 'Book' has no"
    ],
    [
        "Custom managers respond to usual filtering methods",
        "Custom managers respond to usual filtering"
    ],
    [
        "as_manager, mgr_path, qs_path, args, kwargs = mgr.deconstruct()",
        "as_manager, mgr_path, qs_path, args, kwargs ="
    ],
    [
        "as_manager, mgr_path, qs_path, args, kwargs = mgr.deconstruct()",
        "as_manager, mgr_path, qs_path, args, kwargs ="
    ],
    [
        "as_manager, mgr_path, qs_path, args, kwargs = mgr.deconstruct()",
        "as_manager, mgr_path, qs_path, args, kwargs ="
    ],
    [
        "as_manager, mgr_path, qs_path, args, kwargs = mgr.deconstruct()",
        "as_manager, mgr_path, qs_path, args, kwargs ="
    ],
    [
        "\"Could not find manager BaseCustomManagerFromCustomQuerySet in \"",
        "\"Could not find manager"
    ],
    [
        "\"Please note that you need to inherit from managers you \"",
        "\"Please note that you need to inherit from managers you"
    ],
    [
        "A custom manager may be defined on an abstract model.",
        "A custom manager may be defined"
    ],
    [
        "It will be inherited by the abstract model's children.",
        "It will be inherited by the abstract model's"
    ],
    [
        "\"\"\"Even though the default manager filters out some records,",
        "\"\"\"Even though the default manager"
    ],
    [
        "we must still be able to save (particularly, save by updating",
        "we must still be able to save (particularly,"
    ],
    [
        "existing records) those filtered instances. This is a",
        "existing records) those filtered"
    ],
    [
        "Model.refresh_from_db() works for instances hidden by the default",
        "Model.refresh_from_db() works for instances hidden by the"
    ],
    [
        "\"\"\"Model.save() clears annotations from the base manager.\"\"\"",
        "\"\"\"Model.save() clears annotations from the base"
    ],
    [
        "\"\"\"Deleting related objects should also not be distracted by a",
        "\"\"\"Deleting related objects should also"
    ],
    [
        "restricted manager on the related object. This is a regression",
        "restricted manager on the related"
    ],
    [
        "for name, public in ((\"one\", True), (\"two\", False), (\"three\", False)):",
        "for name, public in ((\"one\", True), (\"two\","
    ],
    [
        "BaseManager.get_queryset() should use kwargs rather than args to allow",
        "BaseManager.get_queryset() should use kwargs rather"
    ],
    [
        "get_absolute_url() functions as a normal method.",
        "get_absolute_url() functions as a normal"
    ],
    [
        "ABSOLUTE_URL_OVERRIDES should work even if the model doesn't have a",
        "ABSOLUTE_URL_OVERRIDES should work even if the"
    ],
    [
        "\"absolute_url_overrides.testc\": lambda o: \"/test-c/%s/\" % o.pk,",
        "\"absolute_url_overrides.testc\": lambda o: \"/test-c/%s/\" %"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings, skipUnlessDBFeature",
        "from django.test import SimpleTestCase, TestCase, override_settings,"
    ],
    [
        "ValueError, \"Index.fields must be a list or tuple.\"",
        "ValueError, \"Index.fields must be a"
    ],
    [
        "msg = \"Index.fields must contain only strings with field names.\"",
        "msg = \"Index.fields must contain only strings with field"
    ],
    [
        "msg = \"At least one field or expression is required to define an index.\"",
        "msg = \"At least one field or"
    ],
    [
        "msg = \"Index.fields and expressions are mutually exclusive.\"",
        "msg = \"Index.fields and expressions"
    ],
    [
        "ValueError, \"An index must be named to use opclasses.\"",
        "ValueError, \"An index must be"
    ],
    [
        "ValueError, \"Index.opclasses must be a list or tuple.\"",
        "ValueError, \"Index.opclasses must be a list or"
    ],
    [
        "msg = \"Index.fields and Index.opclasses must have the same number of elements.\"",
        "msg = \"Index.fields and Index.opclasses must have"
    ],
    [
        "ValueError, \"An index must be named to use condition.\"",
        "ValueError, \"An index must be"
    ],
    [
        "msg = \"An index must be named to use expressions.\"",
        "msg = \"An index must be named to use"
    ],
    [
        "\"Index.opclasses cannot be used with expressions. Use \"",
        "\"Index.opclasses cannot be used with expressions."
    ],
    [
        "ValueError, \"Index.condition must be a Q instance.\"",
        "ValueError, \"Index.condition must be a"
    ],
    [
        "msg = \"Index.include must be a list or tuple.\"",
        "msg = \"Index.include must be a list or"
    ],
    [
        "msg = \"A covering index must be named.\"",
        "msg = \"A covering index"
    ],
    [
        "\"Index too long for multiple database support. Is self.suffix \"",
        "\"Index too long for multiple database support. Is self.suffix"
    ],
    [
        "index_names = [index.name for index in Book._meta.indexes]",
        "index_names = [index.name for index in"
    ],
    [
        "for fields in [[\"author\"], [\"shortcut\", \"isbn\"], [\"title\", \"author\"]]:",
        "for fields in [[\"author\"], [\"shortcut\", \"isbn\"], [\"title\","
    ],
    [
        "msg = \"runserver can't serve media if MEDIA_URL is within STATIC_URL.\"",
        "msg = \"runserver can't serve media"
    ],
    [
        "\"\"\"ASGI application that returns a string indicating that it was called.\"\"\"",
        "\"\"\"ASGI application that returns a string"
    ],
    [
        "async def __call__(self, scope, receive, send):",
        "async def __call__(self,"
    ],
    [
        "scope = {\"type\": \"websocket\", \"path\": path}",
        "scope = {\"type\":"
    ],
    [
        "response = await handler(scope, None, None)",
        "response = await handler(scope,"
    ],
    [
        "from .cases import CollectionTestCase, StaticFilesTestCase, TestDefaults",
        "from .cases import"
    ],
    [
        "Make sure no files were create in the destination directory.",
        "Make sure no files were create in the destination"
    ],
    [
        "lines = [line.strip() for line in result.split(\"\\n\")]",
        "lines = [line.strip() for line"
    ],
    [
        "lines = [line.strip() for line in result.split(\"\\n\")]",
        "lines = [line.strip() for line"
    ],
    [
        "lines = [line.strip() for line in result.split(\"\\n\")]",
        "lines = [line.strip() for line"
    ],
    [
        "msg = \"Enter at least one staticfile.\"",
        "msg = \"Enter at least one"
    ],
    [
        "msg = \"without having set the STATIC_ROOT setting to a filesystem path\"",
        "msg = \"without having set the"
    ],
    [
        "msg = \"The STATICFILES_DIRS setting is not a tuple or list.\"",
        "msg = \"The STATICFILES_DIRS setting is not a tuple or"
    ],
    [
        "Even if the STATIC_ROOT setting is not set, one can still call the",
        "Even if the STATIC_ROOT setting is not set,"
    ],
    [
        "Common ignore patterns (*~, .*, CVS) are ignored.",
        "Common ignore patterns (*~, .*, CVS) are"
    ],
    [
        "staticfiles_copied_msg = \"static files copied to\"",
        "staticfiles_copied_msg = \"static files copied"
    ],
    [
        "Test the ``--clear`` option of the ``collectstatic`` management command.",
        "Test the ``--clear`` option of the ``collectstatic``"
    ],
    [
        "overwrite_warning_msg = \"This will overwrite existing files!\"",
        "overwrite_warning_msg = \"This will overwrite"
    ],
    [
        "delete_warning_msg = \"This will DELETE ALL FILES in this location!\"",
        "delete_warning_msg = \"This will DELETE ALL FILES in this"
    ],
    [
        "The ``--no-default-ignore`` option of the ``collectstatic`` management",
        "The ``--no-default-ignore`` option of the"
    ],
    [
        "With --no-default-ignore, common ignore patterns (*~, .*, CVS)",
        "With --no-default-ignore, common ignore patterns (*~,"
    ],
    [
        "A custom ignore_patterns list, ['*.css', '*/vendor/*.js'] in this case,",
        "A custom ignore_patterns list, ['*.css',"
    ],
    [
        "can be specified in an AppConfig definition.",
        "can be specified in"
    ],
    [
        "Test ``--dry-run`` option for ``collectstatic`` management command.",
        "Test ``--dry-run`` option for"
    ],
    [
        "Test overriding duplicated files by ``collectstatic`` management command.",
        "Test overriding duplicated files by"
    ],
    [
        "Check for proper handling of apps order in installed apps even if file modification",
        "Check for proper handling of apps order in installed apps"
    ],
    [
        "Test if collectstatic takes files in proper order",
        "Test if collectstatic takes"
    ],
    [
        "Test warning in ``collectstatic`` output when a file is skipped because a",
        "Test warning in ``collectstatic`` output when a"
    ],
    [
        "previous file was already written to the same path.",
        "previous file was already written to"
    ],
    [
        "Run collectstatic, and capture and return the output. We want to run",
        "Run collectstatic, and capture and return the"
    ],
    [
        "the command at highest verbosity, which is why we can't",
        "the command at highest verbosity, which is"
    ],
    [
        "There isn't a warning if there isn't a duplicate destination.",
        "There isn't a warning if there isn't"
    ],
    [
        "There is a warning when there are duplicate destinations.",
        "There is a warning when there are duplicate"
    ],
    [
        "Tests for a Storage that implements get_modified_time() but not path()",
        "Tests for a Storage that implements"
    ],
    [
        "NotImplementedError, \"This backend doesn't support absolute paths.\"",
        "NotImplementedError, \"This backend doesn't support"
    ],
    [
        "collectstatic skips newer files in a remote storage.",
        "collectstatic skips newer files in a remote"
    ],
    [
        "run_collectstatic() in setUp() copies the static files, then files are",
        "run_collectstatic() in setUp() copies the static files,"
    ],
    [
        "always skipped after NeverCopyRemoteStorage is activated since",
        "always skipped after NeverCopyRemoteStorage"
    ],
    [
        "NeverCopyRemoteStorage.get_modified_time() returns a datetime in the",
        "NeverCopyRemoteStorage.get_modified_time() returns a datetime in"
    ],
    [
        "future to simulate an unmodified file.",
        "future to simulate an unmodified"
    ],
    [
        "@unittest.skipUnless(symlinks_supported(), \"Must be able to symlink to run this test.\")",
        "@unittest.skipUnless(symlinks_supported(), \"Must be able to symlink to run this"
    ],
    [
        "Test ``--link`` option for ``collectstatic`` management command.",
        "Test ``--link`` option for"
    ],
    [
        "Note that by inheriting ``TestDefaults`` we repeat all",
        "Note that by inheriting ``TestDefaults``"
    ],
    [
        "the standard file resolving tests here, to make sure using",
        "the standard file resolving tests here, to make"
    ],
    [
        "``--link`` does not change the file-selection semantics.",
        "``--link`` does not change"
    ],
    [
        "With ``--link``, symbolic links are created.",
        "With ``--link``, symbolic links are"
    ],
    [
        "Running collectstatic in non-symlink mode replaces symlinks with files,",
        "Running collectstatic in non-symlink mode replaces"
    ],
    [
        "while symlink mode replaces files with symlinks.",
        "while symlink mode replaces files"
    ],
    [
        "With ``--clear``, broken symbolic links are deleted.",
        "With ``--clear``, broken symbolic links"
    ],
    [
        "CommandError, \"Can't symlink to a remote destination.\"",
        "CommandError, \"Can't symlink to a remote"
    ],
    [
        "\"Passing the `all` argument to find() is deprecated. Use `find_all` instead.\"",
        "\"Passing the `all` argument to find() is deprecated. Use"
    ],
    [
        "On Windows, sometimes the case of the path we ask the finders for and the",
        "On Windows, sometimes the case of the path we ask the"
    ],
    [
        "path(s) they find can differ. Compare them using os.path.normcase() to",
        "path(s) they find can differ."
    ],
    [
        "found = [os.path.normcase(f) for f in found]",
        "found = [os.path.normcase(f) for f in"
    ],
    [
        "dst = [os.path.normcase(d) for d in dst]",
        "dst = [os.path.normcase(d) for d"
    ],
    [
        "found = [os.path.normcase(f) for f in found]",
        "found = [os.path.normcase(f) for f"
    ],
    [
        "dst = [os.path.normcase(d) for d in dst]",
        "dst = [os.path.normcase(d) for"
    ],
    [
        "f\"{self.finder.__class__.__qualname__}.find() got multiple values for \"",
        "f\"{self.finder.__class__.__qualname__}.find() got multiple values for"
    ],
    [
        "f\"{self.finder.__class__.__qualname__}.find() got an unexpected keyword \"",
        "f\"{self.finder.__class__.__qualname__}.find() got an unexpected"
    ],
    [
        "msg = \"find() got multiple values for argument 'find_all'\"",
        "msg = \"find() got multiple values"
    ],
    [
        "msg = \"find() got an unexpected keyword argument 'wrong'\"",
        "msg = \"find() got an unexpected keyword"
    ],
    [
        "\"The storage backend of the staticfiles finder \"",
        "\"The storage backend of the staticfiles finder"
    ],
    [
        "Test case with a couple utility assertions.",
        "Test case with a couple utility"
    ],
    [
        "\"'%s' not in '%s'\" % (text, filepath),",
        "\"'%s' not in '%s'\" % (text,"
    ],
    [
        "\"{%% load static from static %%}{%% static '%s' as var %%}{{ var }}\"",
        "\"{%% load static from static %%}{%% static '%s' as var"
    ],
    [
        "return \"{%% load static from static %%}{%% static '%s' %%}\" % path",
        "return \"{%% load static from static"
    ],
    [
        "def assertStaticRenders(self, path, result, asvar=False, **kwargs):",
        "def assertStaticRenders(self, path, result,"
    ],
    [
        "def assertStaticRaises(self, exc, path, result, asvar=False, **kwargs):",
        "def assertStaticRaises(self, exc, path,"
    ],
    [
        "Tests shared by all file finding features (collectstatic,",
        "Tests shared by all file finding features"
    ],
    [
        "This relies on the asserts defined in BaseStaticFilesTestCase, but",
        "This relies on the asserts defined in BaseStaticFilesTestCase,"
    ],
    [
        "is separated because some test cases need those asserts without",
        "is separated because some test cases need those asserts"
    ],
    [
        "Can find a file in a STATICFILES_DIRS directory.",
        "Can find a file"
    ],
    [
        "Can find a file in a subdirectory of a STATICFILES_DIRS",
        "Can find a file in a subdirectory of"
    ],
    [
        "File in STATICFILES_DIRS has priority over file in app.",
        "File in STATICFILES_DIRS has priority over file in"
    ],
    [
        "Can find a file in an app static/ directory.",
        "Can find a file in an"
    ],
    [
        "Can find a file with non-ASCII character in an app static/ directory.",
        "Can find a file with non-ASCII character in an"
    ],
    [
        "self.assertFileContains(\"test/⊗.txt\", \"⊗ in the app dir\")",
        "self.assertFileContains(\"test/⊗.txt\", \"⊗ in"
    ],
    [
        "Can find a file with capital letters.",
        "Can find a file with"
    ],
    [
        "A subset of the tests in tests/servers/tests exercising",
        "A subset of the"
    ],
    [
        "raise Exception(\"setUpClass() should have raised an exception.\")",
        "raise Exception(\"setUpClass() should have raised an"
    ],
    [
        "StaticLiveServerTestCase use of staticfiles' serve() allows it",
        "StaticLiveServerTestCase use of staticfiles' serve()"
    ],
    [
        "to discover app's static assets without having to collectstatic first.",
        "to discover app's static assets"
    ],
    [
        "Test serving static files disabled when DEBUG is False.",
        "Test serving static files disabled when DEBUG"
    ],
    [
        "Test static asset serving view with manually configured URLconf.",
        "Test static asset serving view with"
    ],
    [
        "Test static asset serving view with staticfiles_urlpatterns helper.",
        "Test static asset serving"
    ],
    [
        "Assert post conditions for a test are met. Must be manually called at",
        "Assert post conditions for a test are met. Must be manually"
    ],
    [
        "with self.assertRaisesMessage(RuntimeError, \"Max post-process passes exceeded\"):",
        "with self.assertRaisesMessage(RuntimeError, \"Max"
    ],
    [
        "Files that are alterable should always be post-processed; files that",
        "Files that are alterable should always be post-processed; files"
    ],
    [
        "collectstatic has already been called once in setUp() for this testcase,",
        "collectstatic has already been called once in setUp()"
    ],
    [
        "therefore we check by verifying behavior on a second run.",
        "therefore we check by verifying behavior"
    ],
    [
        "post_processing indicates the origin of the error when it fails.",
        "post_processing indicates the origin of the"
    ],
    [
        "With storage classes having several file extension patterns, only the",
        "With storage classes having several"
    ],
    [
        "files matching a specific file pattern should be affected by the",
        "files matching a specific file pattern should be affected"
    ],
    [
        "Tests for the Cache busting storage",
        "Tests for the Cache"
    ],
    [
        "f.write(\"to be deleted in one test\")",
        "f.write(\"to be deleted in"
    ],
    [
        "\"Missing staticfiles manifest entry for '%s'\" % missing_file_name,",
        "\"Missing staticfiles manifest entry for '%s'\" %"
    ],
    [
        "err_msg = \"The file '%s' could not be found with %r.\" % (",
        "err_msg = \"The file '%s' could not"
    ],
    [
        "Files referenced from CSS use the correct final hashed name regardless of",
        "Files referenced from CSS use the"
    ],
    [
        "the order in which the files are post-processed.",
        "the order in which the"
    ],
    [
        "f.write(b\"new content of file to change its hash\")",
        "f.write(b\"new content of file to change its"
    ],
    [
        "from datetime import datetime, timedelta, timezone",
        "from datetime import datetime, timedelta,"
    ],
    [
        "A storage class that implements get_modified_time() but raises",
        "A storage class that implements"
    ],
    [
        "Return a future modified time for all files so that nothing is collected.",
        "Return a future modified time for all"
    ],
    [
        "A storage class to test pattern substitutions with more than one pattern",
        "A storage class to test pattern substitutions with more than one"
    ],
    [
        "entry. The added pattern rewrites strings like \"url(...)\" to JS_URL(\"...\").",
        "entry. The added pattern rewrites strings like \"url(...)\" to"
    ],
    [
        "from django.conf import DEFAULT_STORAGE_ALIAS, STATICFILES_STORAGE_ALIAS, settings",
        "from django.conf import DEFAULT_STORAGE_ALIAS,"
    ],
    [
        "\"subclasses may provide a check() method to verify the finder is \"",
        "\"subclasses may provide a check() method to verify the finder"
    ],
    [
        "\"The STATICFILES_DIRS setting is not a tuple or list.\",",
        "\"The STATICFILES_DIRS setting is not a"
    ],
    [
        "hint=\"Perhaps you forgot a trailing comma?\",",
        "hint=\"Perhaps you forgot a"
    ],
    [
        "\"The STATICFILES_DIRS setting should not contain the \"",
        "\"The STATICFILES_DIRS setting should not"
    ],
    [
        "\"The STATICFILES_DIRS setting should not contain the \"",
        "\"The STATICFILES_DIRS setting should"
    ],
    [
        "static_dir = Path(TEST_ROOT) / \"project\" / \"documents\"",
        "static_dir = Path(TEST_ROOT) /"
    ],
    [
        "\"The prefix 'prefix/' in the STATICFILES_DIRS setting must \"",
        "\"The prefix 'prefix/' in the"
    ],
    [
        "\"The directory '/fake/path' in the STATICFILES_DIRS \"",
        "\"The directory '/fake/path' in the STATICFILES_DIRS"
    ],
    [
        "\"The directory '/fake/prefixed/path' in the \"",
        "\"The directory '/fake/prefixed/path' in the"
    ],
    [
        "Storage.url() should return an encoded path and might be overridden",
        "Storage.url() should return an encoded path and"
    ],
    [
        "to also include a querystring. {% static %} escapes the URL to avoid",
        "to also include a querystring. {% static"
    ],
    [
        "{\"name\": [\"Adrian\", \"Simon\"], \"position\": [\"Developer\"], \"empty\": []}",
        "{\"name\": [\"Adrian\", \"Simon\"], \"position\":"
    ],
    [
        "[(\"name\", \"Simon\"), (\"position\", \"Developer\"), (\"empty\", [])],",
        "[(\"name\", \"Simon\"), (\"position\","
    ],
    [
        "[(\"name\", [\"Adrian\", \"Simon\"]), (\"position\", [\"Developer\"]), (\"empty\", [])],",
        "[(\"name\", [\"Adrian\", \"Simon\"]), (\"position\", [\"Developer\"]), (\"empty\","
    ],
    [
        "for copy_func in [copy.copy, lambda d: d.copy()]:",
        "for copy_func in [copy.copy,"
    ],
    [
        "x = MultiValueDict({\"a\": None, \"b\": []})",
        "x = MultiValueDict({\"a\": None, \"b\":"
    ],
    [
        "for value in [\"\", b\"\", (), [], set(), {}]:",
        "for value in [\"\", b\"\", (),"
    ],
    [
        "d = DictWrapper({\"a\": \"a\"}, f, \"xx_\")",
        "d = DictWrapper({\"a\": \"a\"},"
    ],
    [
        "\"Normal: %(a)s. Modified: %(xx_a)s\" % d, \"Normal: a. Modified: *a\"",
        "\"Normal: %(a)s. Modified: %(xx_a)s\" % d,"
    ],
    [
        "other = {\"Accept\": \"application/json\", \"content-type\": \"text/html\"}",
        "other = {\"Accept\": \"application/json\", \"content-type\":"
    ],
    [
        "msg = \"'CaseInsensitiveMapping' object does not support item deletion\"",
        "msg = \"'CaseInsensitiveMapping' object does"
    ],
    [
        "msg = \"'CaseInsensitiveMapping' object does not support item assignment\"",
        "msg = \"'CaseInsensitiveMapping' object does not support item"
    ],
    [
        "from datetime import date, datetime, time, timezone, tzinfo",
        "from datetime import date, datetime,"
    ],
    [
        "from django.utils.timezone import get_default_timezone, get_fixed_timezone, make_aware",
        "from django.utils.timezone import"
    ],
    [
        "for specifier in [\"e\", \"O\", \"T\", \"Z\"]:",
        "for specifier in [\"e\", \"O\","
    ],
    [
        "for specifier in [\"a\", \"A\", \"f\", \"g\", \"G\", \"h\", \"H\", \"i\", \"P\", \"s\", \"u\"]:",
        "for specifier in [\"a\", \"A\", \"f\", \"g\", \"G\", \"h\", \"H\", \"i\","
    ],
    [
        "\"The format for date objects may not contain time-related \"",
        "\"The format for date objects may"
    ],
    [
        "for hour, g_expected, h_expected in tests:",
        "for hour, g_expected, h_expected in"
    ],
    [
        "for args, kwargs, digest in tests:",
        "for args, kwargs,"
    ],
    [
        "msg = \"'whatever' is not an algorithm accepted by the hashlib module.\"",
        "msg = \"'whatever' is not an algorithm accepted by"
    ],
    [
        "from unittest import mock, skip, skipIf",
        "from unittest import mock,"
    ],
    [
        "from .test_module import __main__ as test_main",
        "from .test_module import __main__"
    ],
    [
        "from .test_module import main_module as test_main_module",
        "from .test_module import"
    ],
    [
        "When a file is added, it's returned by iter_all_python_module_files().",
        "When a file is added,"
    ],
    [
        "When a file containing an error is imported in a function wrapped by",
        "When a file containing an error is imported in a function wrapped"
    ],
    [
        "Since Python may raise arbitrary exceptions when importing code,",
        "Since Python may raise arbitrary exceptions"
    ],
    [
        "check_errors() must catch Exception, not just some subclasses.",
        "check_errors() must catch Exception, not just some"
    ],
    [
        "Modules imported from zipped files have their archive location included",
        "Modules imported from zipped files have their archive location"
    ],
    [
        "with zipfile.ZipFile(str(zip_file), \"w\", zipfile.ZIP_DEFLATED) as zipf:",
        "with zipfile.ZipFile(str(zip_file), \"w\", zipfile.ZIP_DEFLATED) as"
    ],
    [
        "\"\"\".pyc and .pyo files are included in the files list.\"\"\"",
        "\"\"\".pyc and .pyo files are included"
    ],
    [
        "msg = \"Script does-not-exist does not exist.\"",
        "msg = \"Script does-not-exist"
    ],
    [
        "for module, expected in ((zoneinfo, False), (sys, False), (autoreload, True)):",
        "for module, expected in ((zoneinfo, False), (sys, False),"
    ],
    [
        "non_py_file = self.ensure_file(self.tempdir / \"dir\" / \"non_py_file\")",
        "non_py_file = self.ensure_file(self.tempdir / \"dir\""
    ],
    [
        "py_file = self.ensure_file(self.tempdir / \"dir\" / \"file.py\")",
        "py_file = self.ensure_file(self.tempdir / \"dir\" /"
    ],
    [
        "non_py_file = self.ensure_file(self.tempdir / \"dir\" / \"test.txt\")",
        "non_py_file = self.ensure_file(self.tempdir / \"dir\""
    ],
    [
        "py_file = self.ensure_file(self.tempdir / \"dir\" / \"file.py\")",
        "py_file = self.ensure_file(self.tempdir / \"dir\""
    ],
    [
        "inner_py_file = self.ensure_file(self.tempdir / \"dir\" / \"file.py\")",
        "inner_py_file = self.ensure_file(self.tempdir / \"dir\" /"
    ],
    [
        "py_file = self.ensure_file(self.tempdir / \"dir\" / \"file.py\")",
        "py_file = self.ensure_file(self.tempdir / \"dir\""
    ],
    [
        "inner_file = self.ensure_file(self.tempdir / \"test\" / \"test.py\")",
        "inner_file = self.ensure_file(self.tempdir / \"test\""
    ],
    [
        "with mock.patch.object(self.reloader, \"tick\", side_effect=mocked_tick) as tick:",
        "with mock.patch.object(self.reloader, \"tick\","
    ],
    [
        "with mock.patch.object(self.reloader, \"tick\", side_effect=mocked_tick) as tick:",
        "with mock.patch.object(self.reloader, \"tick\", side_effect=mocked_tick)"
    ],
    [
        "return skip(\"Watchman unavailable: %s\" % e)",
        "return skip(\"Watchman unavailable: %s\""
    ],
    [
        "self.reloader._watch_glob(self.tempdir / \"does_not_exist\" / \"more\", [\"*\"])",
        "self.reloader._watch_glob(self.tempdir / \"does_not_exist\" /"
    ],
    [
        "[\"anyof\", [\"match\", \"*\", \"wholename\"], [\"match\", \"*.py\", \"wholename\"]],",
        "[\"anyof\", [\"match\", \"*\", \"wholename\"], [\"match\","
    ],
    [
        "WatchmanUnavailable, \"Cannot connect to the watchman service\"",
        "WatchmanUnavailable, \"Cannot connect to the watchman"
    ],
    [
        "@skipIf(on_macos_with_hfs(), \"These tests do not work with HFS+ as a filesystem\")",
        "@skipIf(on_macos_with_hfs(), \"These tests do not work with HFS+"
    ],
    [
        "def process_view(self, request, view_func, view_args, view_kwargs):",
        "def process_view(self, request, view_func,"
    ],
    [
        "def process_view(self, request, view_func, view_args, view_kwargs):",
        "def process_view(self, request,"
    ],
    [
        "Tests for view decorators created using",
        "Tests for view"
    ],
    [
        "Test a middleware that implements process_view.",
        "Test a middleware"
    ],
    [
        "Test a middleware that implements process_view, operating on a callable class.",
        "Test a middleware that implements process_view, operating on"
    ],
    [
        "All methods of middleware are called for normal HttpResponses",
        "All methods of middleware are called for"
    ],
    [
        "All methods of middleware are called for TemplateResponses in",
        "All methods of middleware are"
    ],
    [
        "self.assertEqual(node, Node([Node([\"a\", \"b\"], OR), \"a\"], AND))",
        "self.assertEqual(node, Node([Node([\"a\", \"b\"],"
    ],
    [
        "a = SubNode([SubNode([\"a\", \"b\"], OR), \"c\"], AND)",
        "a = SubNode([SubNode([\"a\", \"b\"], OR), \"c\"],"
    ],
    [
        "for a_child, b_child in zip(a.children, b.children):",
        "for a_child, b_child"
    ],
    [
        "a = Node([Node([\"a\", \"b\"], OR), \"c\"], AND)",
        "a = Node([Node([\"a\", \"b\"], OR),"
    ],
    [
        "for a_child, b_child in zip(a.children, b.children):",
        "for a_child, b_child in zip(a.children,"
    ],
    [
        "a = Node([Node([\"a\", \"b\"], OR), \"c\"], AND)",
        "a = Node([Node([\"a\", \"b\"], OR), \"c\"],"
    ],
    [
        "for a_child, b_child in zip(a.children, b.children):",
        "for a_child, b_child"
    ],
    [
        "f\"Could not find object DeconstructibleInvalidPathClass in \"",
        "f\"Could not find object DeconstructibleInvalidPathClass in"
    ],
    [
        "f\"Please note that you cannot serialize things like inner \"",
        "f\"Please note that you cannot serialize things"
    ],
    [
        "f\"classes. Please move the object into the main module body to \"",
        "f\"classes. Please move the object into the main module body"
    ],
    [
        "\"Normal module existence can be tested\"",
        "\"Normal module existence"
    ],
    [
        "\"\"\"Nested module existence can be tested.\"\"\"",
        "\"\"\"Nested module existence"
    ],
    [
        "\"Module existence can be tested inside eggs\"",
        "\"Module existence can be tested"
    ],
    [
        "\"Modules deep inside an egg can still be tested for existence\"",
        "\"Modules deep inside an egg can still be tested for"
    ],
    [
        "msg = 'Module \"utils_tests\" does not define a \"unexistent\" attribute'",
        "msg = 'Module \"utils_tests\" does not"
    ],
    [
        "\"\"\"The Custom Loader test is exactly the same as the EggLoader, but",
        "\"\"\"The Custom Loader test is exactly the"
    ],
    [
        "it uses a custom defined Loader class. Although the EggLoader combines both",
        "it uses a custom defined Loader"
    ],
    [
        "functions into one class, this isn't required.",
        "functions into one class, this isn't"
    ],
    [
        "msg = \"flags must be empty if regex is passed pre-compiled\"",
        "msg = \"flags must be empty"
    ],
    [
        "from django.utils.functional import cached_property, classproperty, lazy",
        "from django.utils.functional import cached_property, classproperty,"
    ],
    [
        "\"\"\"lazy also finds base class methods in the proxy object\"\"\"",
        "\"\"\"lazy also finds base class"
    ],
    [
        "\"\"\"lazy finds the correct (overridden) method implementation\"\"\"",
        "\"\"\"lazy finds the correct"
    ],
    [
        "\"\"\"cached_property caches its value and behaves like a property.\"\"\"",
        "\"\"\"cached_property caches its value and"
    ],
    [
        "cached_property caches its value and behaves like a property",
        "cached_property caches its value and behaves like a"
    ],
    [
        "on mangled methods or when the name kwarg isn't set.",
        "on mangled methods or when the name kwarg"
    ],
    [
        "\"\"\"Disallow this case because the decorated function wouldn't be cached.\"\"\"",
        "\"\"\"Disallow this case because the decorated"
    ],
    [
        "\"Cannot assign the same cached_property to two different names ('a' and \"",
        "\"Cannot assign the same cached_property to"
    ],
    [
        "Reusing a cached_property on different classes under the same name is",
        "Reusing a cached_property on different classes under the same"
    ],
    [
        "\"Cannot use cached_property instance without calling __set_name__() on it.\"",
        "\"Cannot use cached_property instance without"
    ],
    [
        "self.assertEqual(f\"I said, {f}\", \"I said, “Hello!”\")",
        "self.assertEqual(f\"I said, {f}\","
    ],
    [
        "== and != work correctly for Promises.",
        "== and != work correctly for"
    ],
    [
        "lazy_obj = lazy(lambda: \"test\", str, bytes)",
        "lazy_obj = lazy(lambda: \"test\", str,"
    ],
    [
        "from datetime import date, datetime, time, timedelta",
        "from datetime import date, datetime,"
    ],
    [
        "msg = \"Subclasses must implement create_connection().\"",
        "msg = \"Subclasses must implement"
    ],
    [
        "from django.utils.functional import Promise, lazy, lazystr",
        "from django.utils.functional import Promise, lazy,"
    ],
    [
        "from django.utils.safestring import SafeData, SafeString, mark_safe",
        "from django.utils.safestring import SafeData,"
    ],
    [
        "Calling str() on a SafeString instance doesn't lose the safe status.",
        "Calling str() on a SafeString instance"
    ],
    [
        "mark_safe used as a decorator leaves the result of a function",
        "mark_safe used as a decorator leaves the result"
    ],
    [
        "mark_safe doesn't affect a callable that has an __html__() method.",
        "mark_safe doesn't affect a callable that has"
    ],
    [
        "mark_safe doesn't affect lazy strings (Promise objects).",
        "mark_safe doesn't affect lazy"
    ],
    [
        "msg = \"object has no attribute 'dynamic_attr'\"",
        "msg = \"object has no"
    ],
    [
        "msg = \"object has no attribute 'dynamic_attr'\"",
        "msg = \"object has"
    ],
    [
        "self.assertRenderEqual(\"{{ s }}\", expected, s=s + case)",
        "self.assertRenderEqual(\"{{ s }}\", expected, s=s"
    ],
    [
        "for lhs, rhs, expected, expected_type in cases:",
        "for lhs, rhs, expected, expected_type in"
    ],
    [
        "Broken __str__ actually raises an error.",
        "Broken __str__ actually raises"
    ],
    [
        "reason = \"unexpected end of data\" if PYPY else \"invalid start byte\"",
        "reason = \"unexpected end of data\" if"
    ],
    [
        "\"You passed in b'\\\\xff' (<class 'bytes'>)\"",
        "\"You passed in b'\\\\xff'"
    ],
    [
        "force_bytes knows how to convert to bytes an exception",
        "force_bytes knows how to convert to"
    ],
    [
        "containing non-ASCII characters in its args.",
        "containing non-ASCII characters in"
    ],
    [
        "error_msg = \"This is an exception, voilà\"",
        "error_msg = \"This is"
    ],
    [
        "error_msg = \"This is an exception, voilà\".encode()",
        "error_msg = \"This is an exception,"
    ],
    [
        "self.assertEqual(result, b\"This is an exception, voil\")",
        "self.assertEqual(result, b\"This is an"
    ],
    [
        "function(value) equals output. If output is None, function(value)",
        "function(value) equals output. If output is"
    ],
    [
        "self.check_output(escape, pattern % value, pattern % output)",
        "self.check_output(escape, pattern % value, pattern"
    ],
    [
        "escape, lazystr(pattern % value), pattern % output",
        "escape, lazystr(pattern % value), pattern"
    ],
    [
        "\"&lt; Dangerous &gt; <b>safe</b> &lt; dangerous again <i>safe again</i>\",",
        "\"&lt; Dangerous &gt; <b>safe</b> &lt; dangerous again <i>safe"
    ],
    [
        "msg = \"args or kwargs must be provided.\"",
        "msg = \"args or"
    ],
    [
        "(\"hi, <f x\", \"hi, <f x\"),",
        "(\"hi, <f x\", \"hi, <f"
    ],
    [
        "self.assertIn(\"Test string that has not been stripped.\", stripped)",
        "self.assertIn(\"Test string that has not"
    ],
    [
        "items = (\" <adf>\", \"<adf> \", \" </adf> \", \" <f> x</f>\")",
        "items = (\" <adf>\", \"<adf> \", \" </adf> \","
    ],
    [
        "(\"<p>hello </p>\\n<p> world</p>\", \"<p>hello </p><p> world</p>\"),",
        "(\"<p>hello </p>\\n<p> world</p>\", \"<p>hello"
    ],
    [
        "msg = \"can't apply @html_safe to HtmlClass because it defines __html__().\"",
        "msg = \"can't apply @html_safe to HtmlClass"
    ],
    [
        "msg = \"can't apply @html_safe to HtmlClass because it doesn't define __str__().\"",
        "msg = \"can't apply @html_safe to HtmlClass because"
    ],
    [
        "'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and '",
        "'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and"
    ],
    [
        "from django.utils.numberformat import format as nformat",
        "from django.utils.numberformat import format as"
    ],
    [
        "for value, decimal_pos, expected_value in tests:",
        "for value, decimal_pos,"
    ],
    [
        "for value, decimal_pos, expected_value in tests:",
        "for value, decimal_pos, expected_value"
    ],
    [
        "Wrapper for Decimal which prefixes each amount with the € symbol.",
        "Wrapper for Decimal which prefixes each amount"
    ],
    [
        "ValueError, \"localtime() cannot be applied to a naive datetime\"",
        "ValueError, \"localtime() cannot be applied"
    ],
    [
        "ValueError, \"localtime() cannot be applied to a naive datetime\"",
        "ValueError, \"localtime() cannot be applied"
    ],
    [
        "ValueError, \"make_naive() cannot be applied to a naive datetime\"",
        "ValueError, \"make_naive() cannot be applied"
    ],
    [
        "The _get_timezone_name() helper must return the offset for fixed offset",
        "The _get_timezone_name() helper must return the offset for"
    ],
    [
        "timezones, for usage with Trunc DB functions.",
        "timezones, for usage with"
    ],
    [
        "The datetime.timezone examples show the current behavior.",
        "The datetime.timezone examples show the current"
    ],
    [
        "mask = stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO",
        "mask = stat.S_IRWXU |"
    ],
    [
        "or (entry.name.endswith((\".lzma\", \".xz\")) and not HAS_LZMA)",
        "or (entry.name.endswith((\".lzma\", \".xz\"))"
    ],
    [
        "msg = \"Archive contains invalid path: '%s'\"",
        "msg = \"Archive contains invalid"
    ],
    [
        "\"Cannot encode None for key 'a' in a query string. Did you mean to \"",
        "\"Cannot encode None for key 'a' in a query string. Did you"
    ],
    [
        "\"pass an empty string or omit the value?\"",
        "\"pass an empty string or omit the"
    ],
    [
        "\"\"\"Non-ASCII unicode decimals raise an error.\"\"\"",
        "\"\"\"Non-ASCII unicode decimals"
    ],
    [
        "for (is_attachment, filename), expected in tests:",
        "for (is_attachment, filename), expected"
    ],
    [
        "HFS+ has a time resolution of only one second which can be too low for",
        "HFS+ has a time resolution of only one"
    ],
    [
        "parsed_macos_version = tuple(int(x) for x in macos_version.split(\".\"))",
        "parsed_macos_version = tuple(int(x) for"
    ],
    [
        "self.assertEqual(text.get_text_list([\"a\", \"b\", \"c\", \"d\"]), \"a, b, c or d\")",
        "self.assertEqual(text.get_text_list([\"a\", \"b\", \"c\", \"d\"]), \"a, b, c or"
    ],
    [
        "self.assertEqual(text.get_text_list([\"a\", \"b\", \"c\"], \"and\"), \"a, b and c\")",
        "self.assertEqual(text.get_text_list([\"a\", \"b\", \"c\"], \"and\"), \"a,"
    ],
    [
        "self.assertEqual(text.get_text_list([\"a\", \"b\"], \"and\"), \"a and b\")",
        "self.assertEqual(text.get_text_list([\"a\", \"b\"], \"and\"), \"a"
    ],
    [
        "self.assertEqual(text.get_text_list([\"a\", \"b\", \"c\"]), \"a، b أو c\")",
        "self.assertEqual(text.get_text_list([\"a\", \"b\", \"c\"]), \"a، b أو"
    ],
    [
        "('This is \"a person\" test.', [\"This\", \"is\", '\"a person\"', \"test.\"]),",
        "('This is \"a person\" test.',"
    ],
    [
        "('This is \"a person\\'s\" test.', [\"This\", \"is\", '\"a person\\'s\"', \"test.\"]),",
        "('This is \"a person\\'s\" test.', [\"This\", \"is\", '\"a person\\'s\"',"
    ],
    [
        "('This is \"a person\\\\\"s\" test.', [\"This\", \"is\", '\"a person\\\\\"s\"', \"test.\"]),",
        "('This is \"a person\\\\\"s\" test.', [\"This\", \"is\","
    ],
    [
        "(\"all friends' tests\", [\"all\", \"friends'\", \"tests\"]),",
        "(\"all friends' tests\","
    ],
    [
        "(\"url search_page words=hello\", [\"url\", \"search_page\", \"words=hello\"]),",
        "(\"url search_page words=hello\", [\"url\", \"search_page\","
    ],
    [
        "truncator = text.Truncator(\"The quick brown fox jumped over the lazy dog.\")",
        "truncator = text.Truncator(\"The quick brown fox jumped over"
    ],
    [
        "'<p id=\"par\"><strong><em>The quick brown fox jumped over the lazy dog.</em>'",
        "'<p id=\"par\"><strong><em>The quick brown fox"
    ],
    [
        "'<p id=\"par\"><strong><em>The quick brown fox jumped over the lazy dog.</em>'",
        "'<p id=\"par\"><strong><em>The quick brown fox jumped over the lazy"
    ],
    [
        "'<p id=\"par\"><strong><em>The quick brown fox jumped over the lazy dog.</em>'",
        "'<p id=\"par\"><strong><em>The quick brown fox jumped"
    ],
    [
        "'<p id=\"par\"><strong><em>The quick brown fox jumped over the lazy dog…</em>'",
        "'<p id=\"par\"><strong><em>The quick brown fox jumped over"
    ],
    [
        "(\"</p\" + \"\\t\" * bigger_len + \"//>\", \"</p>\"),",
        "(\"</p\" + \"\\t\" * bigger_len + \"//>\","
    ],
    [
        "'<p>The quick <a href=\"xyz.html\"\\n id=\"mylink\">brown fox</a> jumped over '",
        "'<p>The quick <a href=\"xyz.html\"\\n id=\"mylink\">brown fox</a> jumped"
    ],
    [
        "\"<br/>The <hr />quick brown fox jumped over the lazy dog.\"",
        "\"<br/>The <hr />quick brown fox jumped over the"
    ],
    [
        "\"<br>The <hr/>quick <em>brown fox</em> jumped over the lazy dog.\"",
        "\"<br>The <hr/>quick <em>brown fox</em> jumped"
    ],
    [
        "truncator = text.Truncator(\"The quick brown fox jumped over the lazy dog.\")",
        "truncator = text.Truncator(\"The quick brown fox jumped over the lazy"
    ],
    [
        "lazystr(\"The quick brown fox jumped over the lazy dog.\")",
        "lazystr(\"The quick brown fox jumped over the"
    ],
    [
        "'<p id=\"par\"><strong><em>The quick brown fox jumped over the lazy dog.</em>'",
        "'<p id=\"par\"><strong><em>The quick brown fox"
    ],
    [
        "'<p id=\"par\"><strong><em>The quick brown fox jumped over the lazy dog.</em>'",
        "'<p id=\"par\"><strong><em>The quick brown fox jumped"
    ],
    [
        "\"<p>The  quick \\t brown fox jumped over the lazy dog.</p>\"",
        "\"<p>The quick \\t brown fox jumped over the lazy"
    ],
    [
        "'<p>The quick <a href=\"xyz.html\"\\n id=\"mylink\">brown fox</a> jumped over '",
        "'<p>The quick <a href=\"xyz.html\"\\n id=\"mylink\">brown fox</a> jumped over"
    ],
    [
        "\"<br/>The <hr />quick brown fox jumped over the lazy dog.\"",
        "\"<br/>The <hr />quick brown fox jumped over the"
    ],
    [
        "\"<br>The <hr/>quick <em>brown fox</em> jumped over the lazy dog.\"",
        "\"<br>The <hr/>quick <em>brown fox</em> jumped over"
    ],
    [
        "truncator = text.Truncator(\"\"\"<p data-x=\"א\">Hello, my dear lady!</p>\"\"\")",
        "truncator = text.Truncator(\"\"\"<p data-x=\"א\">Hello,"
    ],
    [
        "(\"</p\" + \"\\t\" * bigger_len + \"//>\", \"</p>\"),",
        "(\"</p\" + \"\\t\" * bigger_len + \"//>\","
    ],
    [
        "(\" multiple---dash and  space \", \"multiple-dash-and-space\", False),",
        "(\" multiple---dash and space \", \"multiple-dash-and-space\","
    ],
    [
        "(\"    foo ıç bar\", \"foo-ıç-bar\", True),",
        "(\" foo ıç bar\","
    ],
    [
        "for value, output, is_unicode in items:",
        "for value, output,"
    ],
    [
        "msg = f\"Not a string literal: {item!r}\"",
        "msg = f\"Not a"
    ],
    [
        "msg = \"Could not derive file name from '???'\"",
        "msg = \"Could not derive file"
    ],
    [
        "msg = \"Could not derive file name from '$.$.$'\"",
        "msg = \"Could not derive"
    ],
    [
        "seq = [s.encode() for s in seq]",
        "seq = [s.encode() for"
    ],
    [
        "\"django/test\", format_lazy(\"{a}/{b}\", **{\"a\": \"django\", \"b\": \"test\"})",
        "\"django/test\", format_lazy(\"{a}/{b}\", **{\"a\": \"django\", \"b\":"
    ],
    [
        "from django.utils.functional import LazyObject, SimpleLazyObject, empty",
        "from django.utils.functional import LazyObject,"
    ],
    [
        "A simple class with just one attribute.",
        "A simple class with just one"
    ],
    [
        "Wrap the given object into a LazyObject",
        "Wrap the given object"
    ],
    [
        "Proxy methods don't exist on wrapped objects unless they're set.",
        "Proxy methods don't exist on wrapped objects unless"
    ],
    [
        "A base class with a funky __reduce__ method, meant to simulate the",
        "A base class with a funky __reduce__"
    ],
    [
        "__reduce__ method of Model, which sets self._django_version.",
        "__reduce__ method of Model,"
    ],
    [
        "for attr in [\"bar\", \"baz\", \"quux\"]:",
        "for attr in [\"bar\","
    ],
    [
        "if hasattr(self, attr) != hasattr(other, attr):",
        "if hasattr(self, attr) !="
    ],
    [
        "elif getattr(self, attr, None) != getattr(other, attr, None):",
        "elif getattr(self, attr, None) != getattr(other, attr,"
    ],
    [
        "A class that inherits from BaseBaz and has its own __reduce_ex__ method.",
        "A class that inherits from BaseBaz and has"
    ],
    [
        "A class that acts as a proxy for Baz. It does some scary mucking about with",
        "A class that acts as a proxy for Baz. It does some scary mucking"
    ],
    [
        "dicts, which simulates some crazy things that people might do with",
        "dicts, which simulates some crazy things that"
    ],
    [
        "Also covers other classes with a custom __reduce__ method.",
        "Also covers other classes with a custom"
    ],
    [
        "Test in a fairly synthetic setting.",
        "Test in a fairly synthetic"
    ],
    [
        "from django.utils.lorem_ipsum import paragraph, paragraphs, sentence, words",
        "from django.utils.lorem_ipsum import paragraph, paragraphs, sentence,"
    ],
    [
        "\"lorem ipsum dolor sit amet consectetur adipisicing elit sed do \"",
        "\"lorem ipsum dolor sit amet consectetur adipisicing elit"
    ],
    [
        "\"lorem ipsum dolor sit amet consectetur adipisicing elit sed \"",
        "\"lorem ipsum dolor sit amet consectetur adipisicing elit"
    ],
    [
        "\"do eiusmod tempor incididunt ut labore et dolore magna aliqua\"",
        "\"do eiusmod tempor incididunt ut"
    ],
    [
        "\"\"\"words(n) has n words when n is greater than len(WORDS).\"\"\"",
        "\"\"\"words(n) has n words when n is greater"
    ],
    [
        "\"\"\"A sentence starts with a capital letter.\"\"\"",
        "\"\"\"A sentence starts with a"
    ],
    [
        "Sentences are built using some number of phrases and a set of words.",
        "Sentences are built using some number of phrases and"
    ],
    [
        "\"\"\"Sentences end with a question mark or a period.\"\"\"",
        "\"\"\"Sentences end with a question"
    ],
    [
        "\"Lorem ipsum dolor sit amet, consectetur adipisicing elit, \"",
        "\"Lorem ipsum dolor sit amet, consectetur"
    ],
    [
        "\"sed do eiusmod tempor incididunt ut labore et dolore magna \"",
        "\"sed do eiusmod tempor incididunt ut labore et dolore magna"
    ],
    [
        "\"aliqua. Ut enim ad minim veniam, quis nostrud exercitation \"",
        "\"aliqua. Ut enim ad minim"
    ],
    [
        "\"ullamco laboris nisi ut aliquip ex ea commodo consequat. \"",
        "\"ullamco laboris nisi ut aliquip ex"
    ],
    [
        "\"Duis aute irure dolor in reprehenderit in voluptate velit \"",
        "\"Duis aute irure dolor in"
    ],
    [
        "\"esse cillum dolore eu fugiat nulla pariatur. Excepteur sint \"",
        "\"esse cillum dolore eu fugiat"
    ],
    [
        "\"occaecat cupidatat non proident, sunt in culpa qui officia \"",
        "\"occaecat cupidatat non proident, sunt in culpa qui"
    ],
    [
        "\"deserunt mollit anim id est laborum.\"",
        "\"deserunt mollit anim id"
    ],
    [
        "ERROR={\"fg\": \"green\", \"bg\": \"blue\", \"opts\": (\"blink\",)},",
        "ERROR={\"fg\": \"green\", \"bg\":"
    ],
    [
        "ERROR={\"fg\": \"green\", \"bg\": \"blue\", \"opts\": (\"blink\", \"bold\")},",
        "ERROR={\"fg\": \"green\", \"bg\": \"blue\", \"opts\": (\"blink\","
    ],
    [
        "ERROR={\"fg\": \"green\", \"bg\": \"blue\", \"opts\": (\"blink\",)},",
        "ERROR={\"fg\": \"green\", \"bg\":"
    ],
    [
        "msg = \"This is the error message.\"",
        "msg = \"This is the error"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "msg = \"BaseChoiceIterator subclasses must implement __iter__().\"",
        "msg = \"BaseChoiceIterator subclasses must"
    ],
    [
        "for choices in ({}, [], (), set(), frozenset(), generator(), None, \"\"):",
        "for choices in ({}, [], (),"
    ],
    [
        "(\"Video\", [(\"vhs\", _(\"VHS Tape\")), (\"dvd\", _(\"DVD\"))]),",
        "(\"Video\", [(\"vhs\", _(\"VHS"
    ],
    [
        "(\"Video\", [(\"vhs\", _(\"VHS Tape\")), (\"dvd\", _(\"DVD\"))]),",
        "(\"Video\", [(\"vhs\", _(\"VHS Tape\")),"
    ],
    [
        "for choices in ({}, [], (), set(), frozenset(), generator()):",
        "for choices in ({}, [], (), set(),"
    ],
    [
        "return [(\"vhs\", _(\"VHS Tape\")), (\"dvd\", _(\"DVD\"))]",
        "return [(\"vhs\", _(\"VHS"
    ],
    [
        "\"Video\": {\"vhs\": _(\"VHS Tape\"), \"dvd\": _(\"DVD\")},",
        "\"Video\": {\"vhs\": _(\"VHS"
    ],
    [
        "(\"Video\", [(\"vhs\", _(\"VHS Tape\")), (\"dvd\", _(\"DVD\"))]),",
        "(\"Video\", [(\"vhs\", _(\"VHS Tape\")),"
    ],
    [
        "return [[\"vhs\", _(\"VHS Tape\")], [\"dvd\", _(\"DVD\")]]",
        "return [[\"vhs\", _(\"VHS Tape\")],"
    ],
    [
        "[\"Video\", [[\"vhs\", _(\"VHS Tape\")], [\"dvd\", _(\"DVD\")]]],",
        "[\"Video\", [[\"vhs\", _(\"VHS"
    ],
    [
        "yield [\"Audio\", [[\"vinyl\", _(\"Vinyl\")], [\"cd\", _(\"CD\")]]]",
        "yield [\"Audio\", [[\"vinyl\","
    ],
    [
        "yield [\"Video\", [[\"vhs\", _(\"VHS Tape\")], [\"dvd\", _(\"DVD\")]]]",
        "yield [\"Video\", [[\"vhs\", _(\"VHS Tape\")],"
    ],
    [
        "\"Video\": [(\"vhs\", _(\"VHS Tape\")), (\"dvd\", _(\"DVD\"))],",
        "\"Video\": [(\"vhs\", _(\"VHS"
    ],
    [
        "(\"Video\", {\"vhs\": _(\"VHS Tape\"), \"dvd\": _(\"DVD\")}),",
        "(\"Video\", {\"vhs\": _(\"VHS Tape\"),"
    ],
    [
        "for value in self.invalid + self.invalid_iterable + self.invalid_nested:",
        "for value in self.invalid"
    ],
    [
        "for value in self.invalid_iterable + self.invalid_nested:",
        "for value in"
    ],
    [
        "If the two differing units aren't adjacent, only the first unit is",
        "If the two differing units aren't adjacent, only the first"
    ],
    [
        "When the second date occurs before the first, we should always",
        "When the second date occurs before the"
    ],
    [
        "for now in [self.t, self.t - self.onemicrosecond, self.t - self.oneday]:",
        "for now in [self.t, self.t -"
    ],
    [
        "for value, depth, expected in tests:",
        "for value, depth, expected in"
    ],
    [
        "Tests for the low-level syndication feed framework.",
        "Tests for the low-level syndication"
    ],
    [
        "get_tag_uri() correctly generates TagURIs from URLs with port numbers.",
        "get_tag_uri() correctly generates TagURIs from"
    ],
    [
        "\"\"\"Test QueryDict with one key/value pair\"\"\"",
        "\"\"\"Test QueryDict with one key/value"
    ],
    [
        "\"\"\"A copy of a QueryDict is mutable.\"\"\"",
        "\"\"\"A copy of a QueryDict is"
    ],
    [
        "q.lists(), [(\"foo\", [\"bar\", \"baz\", \"another\"]), (\"name\", [\"john\"])]",
        "q.lists(), [(\"foo\", [\"bar\", \"baz\", \"another\"]),"
    ],
    [
        "\"\"\"Test QueryDict with two key/value pairs with same keys.\"\"\"",
        "\"\"\"Test QueryDict with two key/value pairs with same"
    ],
    [
        "AttributeError, \"This QueryDict instance is immutable\"",
        "AttributeError, \"This QueryDict instance"
    ],
    [
        "h.headers[\"Content-Disposition\"] = 'attachment; filename=\"%s\"' % f",
        "h.headers[\"Content-Disposition\"] = 'attachment;"
    ],
    [
        "Keys & values which throw a UnicodeError when encoding/decoding should",
        "Keys & values which throw a UnicodeError when encoding/decoding"
    ],
    [
        "still be checked for newlines and re-raised as a BadHeaderError.",
        "still be checked for newlines and re-raised as"
    ],
    [
        "These specifically would still throw BadHeaderError after decoding",
        "These specifically would still throw BadHeaderError after"
    ],
    [
        "successfully, because the newlines are sandwiched in the middle of the",
        "successfully, because the newlines are sandwiched"
    ],
    [
        "string and email.Header leaves those as they are.",
        "string and email.Header leaves"
    ],
    [
        "msg = \"Header values can't contain newlines\"",
        "msg = \"Header values can't contain"
    ],
    [
        "\"'headers' must not contain 'Content-Type' when the \"",
        "\"'headers' must not contain 'Content-Type'"
    ],
    [
        "\"\"\"Make sure HttpResponseRedirect works with lazy strings.\"\"\"",
        "\"\"\"Make sure HttpResponseRedirect works with"
    ],
    [
        "for response_class, content, preserve_request, expected_status_code in cases:",
        "for response_class, content, preserve_request,"
    ],
    [
        "If HttpResponseRedirect raises DisallowedRedirect, its __repr__()",
        "If HttpResponseRedirect raises DisallowedRedirect,"
    ],
    [
        "should work (in the debug view, for example).",
        "should work (in the debug view, for"
    ],
    [
        "DisallowedRedirect, \"Unsafe redirect to URL with protocol 'ssh'\"",
        "DisallowedRedirect, \"Unsafe redirect to URL with"
    ],
    [
        "[\"GET\"], content=\"Only the GET method is allowed\"",
        "[\"GET\"], content=\"Only the GET method"
    ],
    [
        "\"In order to allow non-dict objects to be serialized set the \"",
        "\"In order to allow non-dict objects to be"
    ],
    [
        "r.streaming_content = (chunk.upper() for chunk in r.streaming_content)",
        "r.streaming_content = (chunk.upper() for"
    ],
    [
        "\"StreamingHttpResponse must consume asynchronous iterators in order to \"",
        "\"StreamingHttpResponse must consume asynchronous iterators in"
    ],
    [
        "\"serve them synchronously. Use a synchronous iterator instead.\"",
        "\"serve them synchronously. Use a synchronous"
    ],
    [
        "\"StreamingHttpResponse must consume synchronous iterators in order to \"",
        "\"StreamingHttpResponse must consume synchronous iterators in order to"
    ],
    [
        "\"serve them asynchronously. Use an asynchronous iterator instead.\"",
        "\"serve them asynchronously. Use an"
    ],
    [
        "msg = \"This %s instance has no `text` attribute.\" % r.__class__.__name__",
        "msg = \"This %s instance has"
    ],
    [
        "Test cases copied from Python's Lib/test/test_http_cookies.py",
        "Test cases copied from"
    ],
    [
        "parse_cookie(\"a=b; c=[; d=r; f=h\"), {\"a\": \"b\", \"c\": \"[\", \"d\": \"r\", \"f\": \"h\"}",
        "parse_cookie(\"a=b; c=[; d=r; f=h\"), {\"a\": \"b\", \"c\": \"[\", \"d\": \"r\", \"f\":"
    ],
    [
        "parse_cookie(\"a=b; Domain=example.com\"), {\"a\": \"b\", \"Domain\": \"example.com\"}",
        "parse_cookie(\"a=b; Domain=example.com\"), {\"a\": \"b\","
    ],
    [
        "self.assertEqual(parse_cookie(\"a=b; h=i; a=c\"), {\"a\": \"c\", \"h\": \"i\"})",
        "self.assertEqual(parse_cookie(\"a=b; h=i; a=c\"), {\"a\":"
    ],
    [
        "self.assertEqual(parse_cookie('a=b; \"; c=d'), {\"a\": \"b\", \"\": '\"', \"c\": \"d\"})",
        "self.assertEqual(parse_cookie('a=b; \"; c=d'), {\"a\": \"b\", \"\": '\"',"
    ],
    [
        "parse_cookie(\"a b c=d e = f; gh=i\"), {\"a b c\": \"d e = f\", \"gh\": \"i\"}",
        "parse_cookie(\"a b c=d e = f; gh=i\"), {\"a b c\": \"d e = f\", \"gh\":"
    ],
    [
        "{\"a   b,c<>@:/[]?{}\": 'd  \"  =e,f g'},",
        "{\"a b,c<>@:/[]?{}\": 'd \""
    ],
    [
        "parse_cookie(\"  =  b  ;  ;  =  ;   c  =  ;  \"), {\"\": \"b\", \"c\": \"\"}",
        "parse_cookie(\" = b ; ; = ; c = ; \"), {\"\": \"b\","
    ],
    [
        "expected_output = \"Set-Cookie: %s\" % rawdata",
        "expected_output = \"Set-Cookie: %s\""
    ],
    [
        "\"\"\"Headers by treating HttpResponse like a dictionary.\"\"\"",
        "\"\"\"Headers by treating HttpResponse"
    ],
    [
        "@skipUnless(connection.vendor == \"oracle\", \"Requires oracledb to be installed\")",
        "@skipUnless(connection.vendor == \"oracle\", \"Requires"
    ],
    [
        "\"shutil.which\", return_value=\"/usr/bin/rlwrap\" if rlwrap else None",
        "\"shutil.which\", return_value=\"/usr/bin/rlwrap\" if rlwrap"
    ],
    [
        "for keys in [(\"database\", \"password\"), (\"db\", \"passwd\")]:",
        "for keys in [(\"database\", \"password\"),"
    ],
    [
        "@skipUnless(connection.vendor == \"mysql\", \"Requires a MySQL connection\")",
        "@skipUnless(connection.vendor == \"mysql\", \"Requires"
    ],
    [
        "\"\"\"SIGINT is ignored in Python and passed to mysql to abort queries.\"\"\"",
        "\"\"\"SIGINT is ignored in Python and passed to mysql to"
    ],
    [
        "@skipUnless(connection.vendor == \"postgresql\", \"Requires a PostgreSQL connection\")",
        "@skipUnless(connection.vendor == \"postgresql\", \"Requires"
    ],
    [
        "\"\"\"SIGINT is ignored in Python and passed to psql to abort queries.\"\"\"",
        "\"\"\"SIGINT is ignored in Python and passed"
    ],
    [
        "args, env = self.settings_to_cmd_args_env({\"PASSWORD\": \"somepassword\"}, [])",
        "args, env ="
    ],
    [
        "\"You appear not to have the %r program installed or on your path.\"",
        "\"You appear not to have the %r program installed or on your"
    ],
    [
        "Ensure headers sent by the default MIDDLEWARE don't inadvertently",
        "Ensure headers sent by the default MIDDLEWARE"
    ],
    [
        "change. For example, we never want \"Vary: Cookie\" to appear in the list",
        "change. For example, we never want \"Vary: Cookie\" to appear in"
    ],
    [
        "since it prevents the caching of responses.",
        "since it prevents the caching"
    ],
    [
        "Use properties on models just like on any other Python object.",
        "Use properties on models just like on"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\""
    ],
    [
        "class that are specified as dotted strings don't retain any path",
        "class that are specified as dotted strings don't"
    ],
    [
        "component for the field or column name.",
        "component for the field or column"
    ],
    [
        "\"test_development() checks the same when __file__ is already missing, \"",
        "\"test_development() checks the same when __file__ is already"
    ],
    [
        "A simple cookie-based session storage implementation.",
        "A simple cookie-based session"
    ],
    [
        "The session key is actually the session data, pickled and encoded.",
        "The session key is actually the"
    ],
    [
        "This means that saving the session will change the session key.",
        "This means that saving the session will change"
    ],
    [
        "Regression tests for the Test Client, especially the customized assertions.",
        "Regression tests for the Test Client, especially the"
    ],
    [
        "from django.template import Context, RequestContext, TemplateSyntaxError, engines",
        "from django.template import Context,"
    ],
    [
        "from django.test.client import RedirectCycleError, RequestFactory, encode_file",
        "from django.test.client import"
    ],
    [
        "\"Responses can be inspected for content, including counting repeated substrings\"",
        "\"Responses can be inspected for content, including"
    ],
    [
        "\"'once' unexpectedly found in the following response\\n\"",
        "\"'once' unexpectedly found in the"
    ],
    [
        "\"abc: 'once' unexpectedly found in the following response\\n\"",
        "\"abc: 'once' unexpectedly found"
    ],
    [
        "f\"Couldn't find 'thrice' in the following response\\n{response.content}\",",
        "f\"Couldn't find 'thrice' in"
    ],
    [
        "\"abc: Couldn't find 'thrice' in the following response\\n\"",
        "\"abc: Couldn't find 'thrice' in"
    ],
    [
        "b\"This is a very very very very very very very very long message which \"",
        "b\"This is a very very very very very very very very long message which"
    ],
    [
        "b\"exceeds the max limit of truncation.\"",
        "b\"exceeds the max limit of"
    ],
    [
        "msg = f\"Couldn't find 'thrice' in the following response\\n{long_content}\"",
        "msg = f\"Couldn't find 'thrice' in"
    ],
    [
        "msg = f\"'very' unexpectedly found in the following response\\n{long_content}\"",
        "msg = f\"'very' unexpectedly found"
    ],
    [
        "\"Unicode characters can be found in template context\"",
        "\"Unicode characters can be found"
    ],
    [
        "\"Unicode characters can be searched for, and not found in template context\"",
        "\"Unicode characters can be searched for,"
    ],
    [
        "An unrendered SimpleTemplateResponse may be used in assertContains().",
        "An unrendered SimpleTemplateResponse may"
    ],
    [
        "\"\"\"auto-rendering does not affect responses that aren't",
        "\"\"\"auto-rendering does not affect responses that"
    ],
    [
        "An unrendered SimpleTemplateResponse may be used in assertNotContains().",
        "An unrendered SimpleTemplateResponse may be used in"
    ],
    [
        "auto-rendering does not affect responses that aren't instances (or",
        "auto-rendering does not affect responses"
    ],
    [
        "\"Template usage assertions work then templates aren't in use\"",
        "\"Template usage assertions work then templates"
    ],
    [
        "self.assertIn(\"No templates used to render the response\", str(e))",
        "self.assertIn(\"No templates used to"
    ],
    [
        "self.assertIn(\"abc: No templates used to render the response\", str(e))",
        "self.assertIn(\"abc: No templates used to render"
    ],
    [
        "msg = \"No templates used to render the response\"",
        "msg = \"No templates used to"
    ],
    [
        "\"Template assertions work when there is a single context\"",
        "\"Template assertions work when there is"
    ],
    [
        "\": Template 'Empty GET Template' was used unexpectedly in \"",
        "\": Template 'Empty GET Template' was"
    ],
    [
        "\": Template 'Empty POST Template' was not a template used to \"",
        "\": Template 'Empty POST Template' was not a template"
    ],
    [
        "\"render the response. Actual template(s) used: Empty GET Template\"",
        "\"render the response. Actual template(s) used: Empty GET"
    ],
    [
        "\"Template assertions work when there are multiple contexts\"",
        "\"Template assertions work when there"
    ],
    [
        "msg = \"Template '%s' was used unexpectedly in rendering the response\"",
        "msg = \"Template '%s' was used unexpectedly in"
    ],
    [
        "\"Template 'Valid POST Template' was not a template used to render \"",
        "\"Template 'Valid POST Template' was not a template"
    ],
    [
        "\"the response. Actual template(s) used: form_view.html, base.html\"",
        "\"the response. Actual template(s)"
    ],
    [
        "\"\"\"Template assertions work when a template is rendered multiple times.\"\"\"",
        "\"\"\"Template assertions work when a template is rendered"
    ],
    [
        "\"An assertion is raised if the original page couldn't be retrieved as expected\"",
        "\"An assertion is raised if the original"
    ],
    [
        "An assertion is raised if the redirect location doesn't preserve GET",
        "An assertion is raised if the redirect location doesn't preserve"
    ],
    [
        "\"Response redirected to '/get_view/?var=value', expected '/get_view/'\",",
        "\"Response redirected to '/get_view/?var=value',"
    ],
    [
        "\"abc: Response redirected to '/get_view/?var=value', expected \"",
        "\"abc: Response redirected to '/get_view/?var=value', expected"
    ],
    [
        "\"An assertion is raised if the response redirects to another target\"",
        "\"An assertion is raised if the"
    ],
    [
        "An assertion is raised if the response redirect target cannot be",
        "An assertion is raised if the"
    ],
    [
        "\"Couldn't retrieve redirection page '/permanent_redirect_view/': \"",
        "\"Couldn't retrieve redirection"
    ],
    [
        "\"abc: Couldn't retrieve redirection page '/permanent_redirect_view/': \"",
        "\"abc: Couldn't retrieve redirection page '/permanent_redirect_view/':"
    ],
    [
        "\"You can follow a redirect chain of multiple redirects\"",
        "\"You can follow a redirect chain of multiple"
    ],
    [
        "\"You can follow a redirect chain of multiple redirects\"",
        "\"You can follow a redirect chain of"
    ],
    [
        "\"You can follow a chain to a nonexistent view.\"",
        "\"You can follow a chain to"
    ],
    [
        "\"Redirections to self are caught and escaped\"",
        "\"Redirections to self are caught"
    ],
    [
        "\"Redirections don't loop forever even if query is changing\"",
        "\"Redirections don't loop forever even if query is"
    ],
    [
        "\"Circular redirect chains are caught and escaped\"",
        "\"Circular redirect chains are caught"
    ],
    [
        "\"A redirect chain will be followed from an initial POST post\"",
        "\"A redirect chain will be followed from"
    ],
    [
        "response = self.client.post(\"/redirects/\", {\"nothing\": \"to_send\"}, follow=True)",
        "response = self.client.post(\"/redirects/\","
    ],
    [
        "\"A redirect chain will be followed from an initial HEAD request\"",
        "\"A redirect chain will be followed"
    ],
    [
        "response = self.client.head(\"/redirects/\", {\"nothing\": \"to_send\"}, follow=True)",
        "response = self.client.head(\"/redirects/\", {\"nothing\": \"to_send\"},"
    ],
    [
        "\"A redirect chain will be followed from an initial OPTIONS request\"",
        "\"A redirect chain will be followed from an initial OPTIONS"
    ],
    [
        "\"A redirect chain will be followed from an initial PUT request\"",
        "\"A redirect chain will be followed from an initial PUT"
    ],
    [
        "\"A redirect chain will be followed from an initial DELETE request\"",
        "\"A redirect chain will be followed"
    ],
    [
        "\"The test client will preserve scheme, host and port changes\"",
        "\"The test client will preserve scheme,"
    ],
    [
        "An assertion is raised if the original page couldn't be retrieved as",
        "An assertion is raised if the original page couldn't be"
    ],
    [
        "\"An assertion is raised if the original page couldn't be retrieved as expected\"",
        "\"An assertion is raised if the original page couldn't be retrieved"
    ],
    [
        "An assertion is raised if the response doesn't have the scheme",
        "An assertion is raised if the response doesn't have"
    ],
    [
        "\"\"\"Preserve extra headers of requests made with django.test.Client.\"\"\"",
        "\"\"\"Preserve extra headers of requests made with"
    ],
    [
        "\"Using a different test client doesn't violate authentication\"",
        "\"Using a different test client doesn't"
    ],
    [
        "\"A session engine that modifies the session key can be used to log in\"",
        "\"A session engine that modifies the session"
    ],
    [
        "\"Get a view that has a simple string argument\"",
        "\"Get a view that has a simple"
    ],
    [
        "\"Get a view that has a string argument that requires escaping\"",
        "\"Get a view that has a"
    ],
    [
        "\"Post for a view that has a simple string argument\"",
        "\"Post for a view that has a simple"
    ],
    [
        "\"Post for a view that has a string argument that requires escaping\"",
        "\"Post for a view that has"
    ],
    [
        "\"TestCase can enforce a custom URLconf on a per-test basis\"",
        "\"TestCase can enforce a custom"
    ],
    [
        "\"\"\"URLconf is reverted to original value after modification in a TestCase",
        "\"\"\"URLconf is reverted to original value after modification in"
    ],
    [
        "This will not find a match as the default ROOT_URLCONF is empty.",
        "This will not find a match as the default ROOT_URLCONF"
    ],
    [
        "\"Context variables can be retrieved from a single context\"",
        "\"Context variables can be retrieved from a single"
    ],
    [
        "\"Context variables can be retrieved from a list of contexts\"",
        "\"Context variables can be retrieved from a list of"
    ],
    [
        "{\"None\", \"True\", \"False\", \"hello\", \"goodbye\", \"python\", \"dolly\"}, k.keys()",
        "{\"None\", \"True\", \"False\", \"hello\","
    ],
    [
        "response.context is not lost when view call another view.",
        "response.context is not lost when"
    ],
    [
        "\"The session isn't lost if a user logs in\"",
        "\"The session isn't lost if a user logs"
    ],
    [
        "\"\"\"Logout should send user_logged_out signal if user was logged in.\"\"\"",
        "\"\"\"Logout should send user_logged_out signal if"
    ],
    [
        "\"\"\"Logout should send user_logged_out signal if custom user was logged in.\"\"\"",
        "\"\"\"Logout should send user_logged_out signal if custom"
    ],
    [
        "\"Request a logout after logging in with custom authentication backend\"",
        "\"Request a logout after logging in"
    ],
    [
        "\"\"\"Logout should send signal even if user not authenticated.\"\"\"",
        "\"\"\"Logout should send signal even if"
    ],
    [
        "\"\"\"Login should send user_logged_in signal on successful login.\"\"\"",
        "\"\"\"Login should send user_logged_in"
    ],
    [
        "\"\"\"Login shouldn't send signal if user wasn't logged in\"\"\"",
        "\"\"\"Login shouldn't send signal if user wasn't logged"
    ],
    [
        "\"Request a view via request method GET\"",
        "\"Request a view via"
    ],
    [
        "\"Request a view via request method POST\"",
        "\"Request a view via request"
    ],
    [
        "\"Request a view via request method HEAD\"",
        "\"Request a view via"
    ],
    [
        "\"Request a view via request method OPTIONS\"",
        "\"Request a view via request method"
    ],
    [
        "\"Request a view via request method PUT\"",
        "\"Request a view via"
    ],
    [
        "\"Request a view via request method DELETE\"",
        "\"Request a view via"
    ],
    [
        "\"Request a view via request method PATCH\"",
        "\"Request a view via request method"
    ],
    [
        "\"Request a view with string data via request method POST\"",
        "\"Request a view with string data via request"
    ],
    [
        "\"Request a view with string data via request method PUT\"",
        "\"Request a view with string data via request"
    ],
    [
        "\"Request a view with string data via request method PATCH\"",
        "\"Request a view with string data"
    ],
    [
        "\"Request a view with empty string data via request method GET/POST/HEAD\"",
        "\"Request a view with empty string data via"
    ],
    [
        "\"\"\"A simple ASCII-only text can be POSTed.\"\"\"",
        "\"\"\"A simple ASCII-only text"
    ],
    [
        "\"\"\"Non-ASCII data as a non-UTF based encoding can be POSTed.\"\"\"",
        "\"\"\"Non-ASCII data as a non-UTF based"
    ],
    [
        "\"A test client can receive custom headers\"",
        "\"A test client can"
    ],
    [
        "\"Test client headers are preserved through redirects\"",
        "\"Test client headers are preserved through"
    ],
    [
        "\"\"\"HttpRequest.body on a test client GET request should return",
        "\"\"\"HttpRequest.body on a test client GET"
    ],
    [
        "\"\"\"HttpRequest.read() on a test client GET request should return the",
        "\"\"\"HttpRequest.read() on a test client GET request"
    ],
    [
        "\"\"\"HttpRequest.read(LARGE_BUFFER) on a test client GET request should",
        "\"\"\"HttpRequest.read(LARGE_BUFFER) on a test client"
    ],
    [
        "\"\"\"HttpRequest.read() on a test client PUT request with some payload",
        "\"\"\"HttpRequest.read() on a test client"
    ],
    [
        "\"\"\"HttpRequest.read(LARGE_BUFFER) on a test client PUT request with",
        "\"\"\"HttpRequest.read(LARGE_BUFFER) on a test client"
    ],
    [
        "some payload should return that payload.\"\"\"",
        "some payload should return"
    ],
    [
        "from django.http import HttpResponse, HttpResponseRedirect, JsonResponse",
        "from django.http import HttpResponse,"
    ],
    [
        "\"A simple view that expects a GET request, and returns a rendered template\"",
        "\"A simple view that expects a GET request, and returns a rendered"
    ],
    [
        "\"No template used. Sample content: twice once twice. Content ends.\"",
        "\"No template used. Sample content: twice once twice. Content"
    ],
    [
        "\"A view that can only be visited by staff. Non staff members get an exception\"",
        "\"A view that can only be visited by staff. Non staff members get an"
    ],
    [
        "\"A simple view that returns the request data in the context\"",
        "\"A simple view that returns the request data in the"
    ],
    [
        "\"\"\"A view that takes a string argument",
        "\"\"\"A view that takes a"
    ],
    [
        "The purpose of this view is to check that if a space is provided in",
        "The purpose of this view is to check that"
    ],
    [
        "A view that uses test client to call another view.",
        "A view that uses test client to call another"
    ],
    [
        "\"A view that redirects all requests to the GET view\"",
        "\"A view that redirects all requests"
    ],
    [
        "\"A view that sets a session variable\"",
        "\"A view that sets a session"
    ],
    [
        "\"A view that reads a session variable\"",
        "\"A view that reads a"
    ],
    [
        "\"A view that responds with the request method\"",
        "\"A view that responds"
    ],
    [
        "return HttpResponse(\"request method: %s\" % request.method)",
        "return HttpResponse(\"request method: %s\""
    ],
    [
        "kwargs = {\"content_type\": content_type} if content_type else {}",
        "kwargs = {\"content_type\": content_type}"
    ],
    [
        "\"A view that parses and returns text as a file.\"",
        "\"A view that parses and returns text as a"
    ],
    [
        "\"A view that responds with value of the X-ARG-CHECK header\"",
        "\"A view that responds with value of the"
    ],
    [
        "\"A view that is requested with accesses request.read().\"",
        "\"A view that is"
    ],
    [
        "\"A view that is requested with accesses request.read(LARGE_BUFFER).\"",
        "\"A view that is requested with accesses"
    ],
    [
        "\"\"\"A view that renders a template multiple times.\"\"\"",
        "\"\"\"A view that renders"
    ],
    [
        "for user_type in (\"view\", \"add\", \"change\", \"delete\", \"custom\"):",
        "for user_type in (\"view\","
    ],
    [
        "for permission, user, expected in cases:",
        "for permission, user, expected"
    ],
    [
        "[description for _, _, description in ma._get_base_actions()],",
        "[description for _, _, description in"
    ],
    [
        "for _, name, desc in ma._get_base_actions()",
        "for _, name, desc"
    ],
    [
        "from django.contrib.admin.models import ADDITION, CHANGE, DELETION, LogEntry",
        "from django.contrib.admin.models import ADDITION, CHANGE, DELETION,"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, TestCase",
        "from django.test import RequestFactory, SimpleTestCase,"
    ],
    [
        "from .models import Band, Concert, Song",
        "from .models import Band,"
    ],
    [
        "A lookup_allowed allows a parameter whose field lookup doesn't exist.",
        "A lookup_allowed allows a parameter whose field lookup"
    ],
    [
        "The custom ModelForm's `Meta.exclude` is respected when used in",
        "The custom ModelForm's `Meta.exclude` is respected when used"
    ],
    [
        "conjunction with `ModelAdmin.readonly_fields` and when no",
        "conjunction with `ModelAdmin.readonly_fields`"
    ],
    [
        "The custom ModelForm's `Meta.exclude` is overridden if",
        "The custom ModelForm's `Meta.exclude` is overridden"
    ],
    [
        "The `exclude` kwarg passed to `ModelAdmin.get_form()` overrides all",
        "The `exclude` kwarg passed to `ModelAdmin.get_form()`"
    ],
    [
        "The `exclude` kwarg passed to `InlineModelAdmin.get_formset()`",
        "The `exclude` kwarg passed"
    ],
    [
        "fields = [\"main_band\", \"opening_band\", \"day\", \"transport\"]",
        "fields = [\"main_band\", \"opening_band\","
    ],
    [
        "The autocomplete_fields, raw_id_fields, and radio_fields widgets may",
        "The autocomplete_fields, raw_id_fields, and"
    ],
    [
        "overridden by specifying a widget in get_formset().",
        "overridden by specifying a widget"
    ],
    [
        "`obj` is passed from `InlineModelAdmin.get_fieldsets()` to",
        "`obj` is passed from"
    ],
    [
        "(ma.log_change, CHANGE, {\"changed\": {\"fields\": [\"name\", \"bio\"]}}),",
        "(ma.log_change, CHANGE, {\"changed\": {\"fields\":"
    ],
    [
        "for method, flag, message in tests:",
        "for method, flag, message in"
    ],
    [
        "bio=\"A legendary rock band from Liverpool.\",",
        "bio=\"A legendary rock"
    ],
    [
        "bio=\"A progressive rock band from Calcutta.\",",
        "bio=\"A progressive rock band from"
    ],
    [
        "has_view_permission() returns True for users who can view objects and",
        "has_view_permission() returns True for users who"
    ],
    [
        "has_add_permission returns True for users who can add objects and",
        "has_add_permission returns True for users who can"
    ],
    [
        "has_change_permission returns True for users who can edit objects and",
        "has_change_permission returns True for users who"
    ],
    [
        "has_delete_permission returns True for users who can delete objects and",
        "has_delete_permission returns True for users who can delete"
    ],
    [
        "as_module_permission returns True for users who have any permission",
        "as_module_permission returns True for users who have"
    ],
    [
        "for the module and False for users who don't.",
        "for the module and False"
    ],
    [
        "from django.contrib.admin.options import VERTICAL, ModelAdmin, TabularInline",
        "from django.contrib.admin.options import VERTICAL,"
    ],
    [
        "from django.db.models import CASCADE, F, Field, ForeignKey, ManyToManyField, Model",
        "from django.db.models import CASCADE, F, Field, ForeignKey,"
    ],
    [
        "from .models import Band, Song, User, ValidationTestInlineModel, ValidationTestModel",
        "from .models import Band, Song, User,"
    ],
    [
        "self, model_admin, model, msg, id=None, hint=None, invalid_obj=None",
        "self, model_admin, model, msg,"
    ],
    [
        "Same as assertIsInvalid but treats the given msg as a regexp.",
        "Same as assertIsInvalid but treats the"
    ],
    [
        "\"The value of 'raw_id_fields' must be a list or tuple.\",",
        "\"The value of 'raw_id_fields' must be a"
    ],
    [
        "\"which is not a field of 'modeladmin.ValidationTestModel'.\",",
        "\"which is not a"
    ],
    [
        "\"The value of 'fieldsets' must be a list or tuple.\",",
        "\"The value of 'fieldsets' must be a list or"
    ],
    [
        "\"Both 'fieldsets' and 'fields' are specified.\",",
        "\"Both 'fieldsets' and 'fields' are"
    ],
    [
        "fieldsets = [(None, {\"fields\": [\"name\", \"name\"]})]",
        "fieldsets = [(None,"
    ],
    [
        "\"The value of 'fields' contains duplicate field(s).\",",
        "\"The value of 'fields' contains duplicate"
    ],
    [
        "\"The value of 'fields' must be a list or tuple.\",",
        "\"The value of 'fields' must be"
    ],
    [
        "\"The value of 'form' must inherit from 'BaseModelForm'.\",",
        "\"The value of 'form' must inherit"
    ],
    [
        "fieldsets = ((\"Band\", {\"fields\": (\"name\", \"bio\", \"sign_date\", \"delete\")}),)",
        "fieldsets = ((\"Band\", {\"fields\": (\"name\", \"bio\","
    ],
    [
        "\"The value of 'filter_vertical' must be a list or tuple.\",",
        "\"The value of 'filter_vertical' must"
    ],
    [
        "\"which is not a field of 'modeladmin.ValidationTestModel'.\",",
        "\"which is not a field of"
    ],
    [
        "\"'bands', because that field manually specifies a relationship model.\",",
        "\"'bands', because that field manually specifies a"
    ],
    [
        "\"The value of 'filter_horizontal' must be a list or tuple.\",",
        "\"The value of 'filter_horizontal' must"
    ],
    [
        "\"which is not a field of 'modeladmin.ValidationTestModel'.\",",
        "\"which is not a field of"
    ],
    [
        "\"'bands', because that field manually specifies a relationship model.\",",
        "\"'bands', because that field manually specifies a"
    ],
    [
        "\"The value of 'radio_fields' must be a dictionary.\",",
        "\"The value of 'radio_fields' must"
    ],
    [
        "\"The value of 'radio_fields' refers to 'non_existent_field', \"",
        "\"The value of 'radio_fields' refers"
    ],
    [
        "\"which is not a field of 'modeladmin.ValidationTestModel'.\",",
        "\"which is not a field of"
    ],
    [
        "\"The value of 'radio_fields' refers to 'name', which is not an instance \"",
        "\"The value of 'radio_fields' refers to 'name', which is not"
    ],
    [
        "\"of ForeignKey, and does not have a 'choices' definition.\",",
        "\"of ForeignKey, and does not have"
    ],
    [
        "\"The value of 'radio_fields[\\\"state\\\"]' must be either admin.HORIZONTAL or \"",
        "\"The value of 'radio_fields[\\\"state\\\"]' must be either admin.HORIZONTAL or"
    ],
    [
        "\"The value of 'prepopulated_fields[\\\"slug\\\"]' must be a list or tuple.\",",
        "\"The value of 'prepopulated_fields[\\\"slug\\\"]' must be a list"
    ],
    [
        "\"The value of 'prepopulated_fields' must be a dictionary.\",",
        "\"The value of 'prepopulated_fields' must be"
    ],
    [
        "\"The value of 'prepopulated_fields' refers to 'non_existent_field', \"",
        "\"The value of 'prepopulated_fields' refers to 'non_existent_field',"
    ],
    [
        "\"which is not a field of 'modeladmin.ValidationTestModel'.\",",
        "\"which is not a field"
    ],
    [
        "\"'non_existent_field', which is not a field of \"",
        "\"'non_existent_field', which is not a field of"
    ],
    [
        "\"The value of 'prepopulated_fields' refers to 'users', which must not be \"",
        "\"The value of 'prepopulated_fields' refers to 'users', which must"
    ],
    [
        "\"a DateTimeField, a ForeignKey, a OneToOneField, or a ManyToManyField.\",",
        "\"a DateTimeField, a ForeignKey, a OneToOneField, or a"
    ],
    [
        "\"The value of 'prepopulated_fields' refers to 'best_friend', which must \"",
        "\"The value of 'prepopulated_fields' refers to 'best_friend', which must"
    ],
    [
        "\"not be a DateTimeField, a ForeignKey, a OneToOneField, or a \"",
        "\"not be a DateTimeField, a ForeignKey, a"
    ],
    [
        "\"The value of 'list_display' must be a list or tuple.\",",
        "\"The value of 'list_display' must"
    ],
    [
        "\"which is not a callable or attribute of 'TestModelAdmin', \"",
        "\"which is not a callable or"
    ],
    [
        "\"or an attribute, method, or field on 'modeladmin.ValidationTestModel'.\",",
        "\"or an attribute, method, or field on"
    ],
    [
        "\"which is not a callable or attribute of 'TestModelAdmin', \"",
        "\"which is not a callable or"
    ],
    [
        "\"or an attribute, method, or field on 'modeladmin.ValidationTestModel'.\",",
        "\"or an attribute, method, or field"
    ],
    [
        "list_display = (\"name\", \"decade_published_in\", \"a_method\", a_callable)",
        "list_display = (\"name\", \"decade_published_in\","
    ],
    [
        "\"\"\"Custom field accessible only via instance.\"\"\"",
        "\"\"\"Custom field accessible only via"
    ],
    [
        "\"The value of 'list_display_links' must be a list, a tuple, or None.\",",
        "\"The value of 'list_display_links' must be a list, a tuple,"
    ],
    [
        "\"'non_existent_field', which is not defined in 'list_display'.\"",
        "\"'non_existent_field', which is not defined"
    ],
    [
        "list_display = (\"name\", \"decade_published_in\", \"a_method\", a_callable)",
        "list_display = (\"name\","
    ],
    [
        "list_display_links = (\"name\", \"decade_published_in\", \"a_method\", a_callable)",
        "list_display_links = (\"name\", \"decade_published_in\","
    ],
    [
        "list_display_links check is skipped if get_list_display() is overridden.",
        "list_display_links check is skipped if"
    ],
    [
        "list_display_links is checked for list/tuple/None even if",
        "list_display_links is checked for"
    ],
    [
        "\"The value of 'list_display_links' must be a list, a tuple, or None.\",",
        "\"The value of 'list_display_links' must be a list,"
    ],
    [
        "\"The value of 'list_filter' must be a list or tuple.\",",
        "\"The value of 'list_filter' must be a list"
    ],
    [
        "\"does not refer to a Field.\",",
        "\"does not refer to"
    ],
    [
        "\"which does not refer to a Field.\",",
        "\"which does not refer"
    ],
    [
        "return ((\"bit\", \"A bit awesome\"), (\"very\", \"Very awesome\"))",
        "return ((\"bit\", \"A bit awesome\"),"
    ],
    [
        "return ((\"bit\", \"A bit awesome\"), (\"very\", \"Very awesome\"))",
        "return ((\"bit\", \"A bit awesome\"), (\"very\", \"Very"
    ],
    [
        "\"The value of 'list_per_page' must be an integer.\",",
        "\"The value of 'list_per_page' must be an"
    ],
    [
        "\"The value of 'list_max_show_all' must be an integer.\",",
        "\"The value of 'list_max_show_all'"
    ],
    [
        "\"The value of 'search_fields' must be a list or tuple.\",",
        "\"The value of 'search_fields' must be"
    ],
    [
        "\"The value of 'date_hierarchy' refers to 'non_existent_field', \"",
        "\"The value of 'date_hierarchy' refers to 'non_existent_field',"
    ],
    [
        "\"which does not refer to a Field.\",",
        "\"which does not refer"
    ],
    [
        "\"The value of 'date_hierarchy' must be a DateField or DateTimeField.\",",
        "\"The value of 'date_hierarchy' must be a DateField"
    ],
    [
        "\"The value of 'date_hierarchy' must be a DateField or DateTimeField.\",",
        "\"The value of 'date_hierarchy' must be"
    ],
    [
        "\"The value of 'date_hierarchy' must be a DateField or DateTimeField.\",",
        "\"The value of 'date_hierarchy' must be a DateField or"
    ],
    [
        "\"The value of 'ordering' must be a list or tuple.\",",
        "\"The value of 'ordering' must be a"
    ],
    [
        "\"which is not a field of 'modeladmin.ValidationTestModel'.\",",
        "\"which is not a"
    ],
    [
        "\"The value of 'ordering' has the random ordering marker '?', but contains \"",
        "\"The value of 'ordering' has the random ordering marker '?', but"
    ],
    [
        "hint='Either remove the \"?\", or remove the other fields.',",
        "hint='Either remove the \"?\", or remove"
    ],
    [
        "\"The value of 'list_select_related' must be a boolean, tuple or list.\",",
        "\"The value of 'list_select_related' must be a boolean, tuple"
    ],
    [
        "\"The value of 'save_as' must be a boolean.\",",
        "\"The value of 'save_as' must"
    ],
    [
        "\"The value of 'save_on_top' must be a boolean.\",",
        "\"The value of 'save_on_top' must"
    ],
    [
        "\"The value of 'inlines' must be a list or tuple.\",",
        "\"The value of 'inlines' must"
    ],
    [
        "r\"'.*\\.ValidationTestInline' must have a 'model' attribute\\.\",",
        "r\"'.*\\.ValidationTestInline' must have a"
    ],
    [
        "r\"The value of '.*\\.ValidationTestInline.model' must be a Model\\.\",",
        "r\"The value of '.*\\.ValidationTestInline.model' must"
    ],
    [
        "r\"The value of '.*\\.ValidationTestInline.model' must be a Model\\.\",",
        "r\"The value of '.*\\.ValidationTestInline.model' must be"
    ],
    [
        "\"'modeladmin.ValidationTestInlineModel' has no field named \"",
        "\"'modeladmin.ValidationTestInlineModel' has no"
    ],
    [
        "\"The value of 'extra' must be an integer.\",",
        "\"The value of 'extra'"
    ],
    [
        "\"The value of 'max_num' must be an integer.\",",
        "\"The value of 'max_num' must be an"
    ],
    [
        "\"The value of 'min_num' must be an integer.\",",
        "\"The value of 'min_num' must"
    ],
    [
        "\"The value of 'formset' must inherit from 'BaseModelFormSet'.\",",
        "\"The value of 'formset' must inherit from"
    ],
    [
        "formset = \"Not a FormSet Class\"",
        "formset = \"Not a FormSet"
    ],
    [
        "\"The value of 'formset' must inherit from 'BaseModelFormSet'.\",",
        "\"The value of 'formset' must inherit"
    ],
    [
        "list_display and list_editable can contain the same values",
        "list_display and list_editable can contain the"
    ],
    [
        "The first item in list_display can be the same as the first in",
        "The first item in list_display can be the same"
    ],
    [
        "The first item in list_display can be in list_editable as long as",
        "The first item in list_display can be in list_editable as long"
    ],
    [
        "The first item in list_display cannot be the same as the first item",
        "The first item in list_display cannot be the same as"
    ],
    [
        "in list_editable if list_display_links is not defined.",
        "in list_editable if list_display_links is not"
    ],
    [
        "\"in 'list_display' ('name'), which cannot be used unless \"",
        "\"in 'list_display' ('name'), which cannot be used unless"
    ],
    [
        "The first item in list_display cannot be in list_editable if",
        "The first item in list_display cannot be in list_editable"
    ],
    [
        "\"in 'list_display' ('name'), which cannot be used unless \"",
        "\"in 'list_display' ('name'), which cannot be"
    ],
    [
        "\"The value of 'name' cannot be in both 'list_editable' and \"",
        "\"The value of 'name' cannot be"
    ],
    [
        "msg=\"The value of 'autocomplete_fields' must be a list or tuple.\",",
        "msg=\"The value of 'autocomplete_fields' must"
    ],
    [
        "\"which is not a field of 'modeladmin.ValidationTestModel'.\"",
        "\"which is not a field of"
    ],
    [
        "'An admin for model \"Band\" has to be registered '",
        "'An admin for model \"Band\""
    ],
    [
        "'NoSearchFieldsAdmin must define \"search_fields\", because '",
        "'NoSearchFieldsAdmin must define"
    ],
    [
        "\"BandAdmin must define a has_custom_permission() method for the \"",
        "\"BandAdmin must define a has_custom_permission() method"
    ],
    [
        "\"__name__ attributes of actions defined in BandAdmin must be \"",
        "\"__name__ attributes of actions defined in BandAdmin"
    ],
    [
        "\"unique. Name 'action' is not unique.\",",
        "\"unique. Name 'action' is"
    ],
    [
        "Tests of ModelAdmin system checks logic.",
        "Tests of ModelAdmin system checks"
    ],
    [
        "from .models import Album, Author, Book, City, Influence, Song, State, TwoAlbumFKAndAnE",
        "from .models import Album, Author, Book, City,"
    ],
    [
        "\"INSTALLED_APPS in order to use the admin application.\",",
        "\"INSTALLED_APPS in order to"
    ],
    [
        "\"'django.contrib.auth' must be in INSTALLED_APPS in order \"",
        "\"'django.contrib.auth' must be in INSTALLED_APPS"
    ],
    [
        "\"'django.contrib.messages' must be in INSTALLED_APPS in order \"",
        "\"'django.contrib.messages' must be in INSTALLED_APPS in"
    ],
    [
        "\"instance must be configured in TEMPLATES in order to use \"",
        "\"instance must be configured in TEMPLATES in"
    ],
    [
        "\"enabled in DjangoTemplates (TEMPLATES) if using the default \"",
        "\"enabled in DjangoTemplates (TEMPLATES) if using the default"
    ],
    [
        "\"auth backend in order to use the admin application.\",",
        "\"auth backend in order to use the"
    ],
    [
        "\"be enabled in DjangoTemplates (TEMPLATES) in order to use \"",
        "\"be enabled in DjangoTemplates (TEMPLATES) in order to use"
    ],
    [
        "\"in DjangoTemplates (TEMPLATES) in order to use the admin \"",
        "\"in DjangoTemplates (TEMPLATES) in order to use the"
    ],
    [
        "\"enabled in DjangoTemplates (TEMPLATES) if using the default \"",
        "\"enabled in DjangoTemplates (TEMPLATES) if"
    ],
    [
        "\"auth backend in order to use the admin application.\",",
        "\"auth backend in order to use the"
    ],
    [
        "\"must be in MIDDLEWARE in order to use the admin application.\",",
        "\"must be in MIDDLEWARE in order"
    ],
    [
        "\"must be in MIDDLEWARE in order to use the admin application.\",",
        "\"must be in MIDDLEWARE in order to use the admin"
    ],
    [
        "\"must be in MIDDLEWARE in order to use the admin application.\",",
        "\"must be in MIDDLEWARE in order to"
    ],
    [
        "\"which is not contained in 'list_display'.\",",
        "\"which is not contained in"
    ],
    [
        "\"The value of 'list_editable' must be a list or tuple.\",",
        "\"The value of 'list_editable' must"
    ],
    [
        "\"which is not editable through the admin.\",",
        "\"which is not editable through"
    ],
    [
        "The fieldsets checks are skipped when the ModelAdmin.get_form() method",
        "The fieldsets checks are skipped when the"
    ],
    [
        "The first fieldset's fields must be a list/tuple.",
        "The first fieldset's fields"
    ],
    [
        "The second fieldset's fields must be a list/tuple.",
        "The second fieldset's fields must"
    ],
    [
        "\"The value of 'exclude' must be a list or tuple.\",",
        "\"The value of 'exclude' must be a list"
    ],
    [
        "\"The value of 'exclude' contains duplicate field(s).\",",
        "\"The value of 'exclude' contains"
    ],
    [
        "\"The value of 'exclude' must be a list or tuple.\",",
        "\"The value of 'exclude' must be a"
    ],
    [
        "contain the ForeignKey field used in ModelAdmin.model",
        "contain the ForeignKey field used in"
    ],
    [
        "\"Cannot exclude the field 'album', because it is the foreign key \"",
        "\"Cannot exclude the field 'album', because"
    ],
    [
        "A model without a GenericForeignKey raises problems if it's included",
        "A model without a GenericForeignKey raises problems"
    ],
    [
        "A GenericInlineModelAdmin errors if the ct_field points to a",
        "A GenericInlineModelAdmin errors if the"
    ],
    [
        "\"'ct_field' references 'nonexistent', which is not a field on \"",
        "\"'ct_field' references 'nonexistent', which is not"
    ],
    [
        "A GenericInlineModelAdmin errors if the ct_fk_field points to a",
        "A GenericInlineModelAdmin errors if the"
    ],
    [
        "\"'ct_fk_field' references 'nonexistent', which is not a field on \"",
        "\"'ct_fk_field' references 'nonexistent', which is not a field"
    ],
    [
        "A GenericInlineModelAdmin raises problems if the ct_field points to a",
        "A GenericInlineModelAdmin raises problems if the"
    ],
    [
        "field that isn't part of a GenericForeignKey.",
        "field that isn't part of"
    ],
    [
        "\"'admin_checks.Influence' has no GenericForeignKey using \"",
        "\"'admin_checks.Influence' has no"
    ],
    [
        "\"content type field 'name' and object ID field 'object_id'.\",",
        "\"content type field 'name' and object ID"
    ],
    [
        "A GenericInlineModelAdmin raises problems if the ct_fk_field points to",
        "A GenericInlineModelAdmin raises problems if the ct_fk_field"
    ],
    [
        "a field that isn't part of a GenericForeignKey.",
        "a field that isn't part"
    ],
    [
        "\"'admin_checks.Influence' has no GenericForeignKey using \"",
        "\"'admin_checks.Influence' has no GenericForeignKey"
    ],
    [
        "\"content type field 'content_type' and object ID field 'name'.\",",
        "\"content type field 'content_type' and object ID"
    ],
    [
        "\"which is not a field of 'admin_checks.Album'.\",",
        "\"which is not a field of"
    ],
    [
        "given) make sure fk_name is honored or things blow up when there is more",
        "given) make sure fk_name is honored or things blow up when"
    ],
    [
        "than one fk to the parent model.",
        "than one fk to"
    ],
    [
        "\"'admin_checks.TwoAlbumFKAndAnE' has more than one ForeignKey \"",
        "\"'admin_checks.TwoAlbumFKAndAnE' has more than one ForeignKey"
    ],
    [
        "\"to 'admin_checks.Album'. You must specify a 'fk_name' \"",
        "\"to 'admin_checks.Album'. You must specify a 'fk_name'"
    ],
    [
        "\"not a callable, an attribute of 'SongAdmin', or an attribute of \"",
        "\"not a callable, an attribute of 'SongAdmin', or an"
    ],
    [
        "\"not a callable, an attribute of 'CityInline', or an attribute of \"",
        "\"not a callable, an attribute of 'CityInline', or an attribute"
    ],
    [
        "\"The value of 'readonly_fields' must be a list or tuple.\",",
        "\"The value of 'readonly_fields' must be a list or"
    ],
    [
        "if instance.title == \"Born to Run\":",
        "if instance.title == \"Born to"
    ],
    [
        "specifies the 'through' option is included in the 'fields' or the 'fieldsets'",
        "specifies the 'through' option is included in the 'fields'"
    ],
    [
        "\"The value of 'fields' cannot include the ManyToManyField 'authors', \"",
        "\"The value of 'fields' cannot include"
    ],
    [
        "\"because that field manually specifies a relationship model.\",",
        "\"because that field manually specifies a"
    ],
    [
        "\"ManyToManyField 'authors', because that field manually specifies a \"",
        "\"ManyToManyField 'authors', because that field"
    ],
    [
        "fieldsets = ((\"Main\", {\"fields\": (\"price\", (\"name\", \"subtitle\"))}),)",
        "fieldsets = ((\"Main\", {\"fields\": (\"price\","
    ],
    [
        "is specified as a string, the admin should still be able use",
        "is specified as a string, the admin"
    ],
    [
        "Regression for ensuring ModelAdmin.fields can contain non-model fields",
        "Regression for ensuring ModelAdmin.fields can contain"
    ],
    [
        "Regression for ensuring ModelAdmin.field can handle first elem being a",
        "Regression for ensuring ModelAdmin.field can handle"
    ],
    [
        "\"The value of 'fields' contains duplicate field(s).\",",
        "\"The value of 'fields' contains duplicate"
    ],
    [
        "(None, {\"fields\": [\"title\", \"album\", (\"title\", \"album\")]}),",
        "(None, {\"fields\": [\"title\", \"album\", (\"title\","
    ],
    [
        "Ensure list_filter can access reverse fields even when the app registry",
        "Ensure list_filter can access reverse fields even when the"
    ],
    [
        "\"a callable or attribute of 'SongAdmin', or an attribute, method, or \"",
        "\"a callable or attribute of 'SongAdmin', or an attribute, method, or"
    ],
    [
        "return \"I am %s, a child of %s\" % (self.name, self.parent)",
        "return \"I am %s, a child"
    ],
    [
        "dummy = models.IntegerField(help_text=\"Awesome stacked help text is awesome.\")",
        "dummy = models.IntegerField(help_text=\"Awesome stacked help text"
    ],
    [
        "dummy = models.IntegerField(help_text=\"Awesome tabular help text is awesome.\")",
        "dummy = models.IntegerField(help_text=\"Awesome tabular help text is"
    ],
    [
        "parent = models.ForeignKey(\"self\", models.SET_NULL, null=True, blank=True)",
        "parent = models.ForeignKey(\"self\", models.SET_NULL,"
    ],
    [
        "verbose_name = \"Model with verbose name only\"",
        "verbose_name = \"Model with"
    ],
    [
        "verbose_name_plural = \"Model with verbose name plural only\"",
        "verbose_name_plural = \"Model with verbose name plural"
    ],
    [
        "verbose_name = \"Model with both - name\"",
        "verbose_name = \"Model with both -"
    ],
    [
        "verbose_name_plural = \"Model with both - plural name\"",
        "verbose_name_plural = \"Model with"
    ],
    [
        "(None, {\"fields\": [\"image\", \"title\"], \"description\": \"First group\"}),",
        "(None, {\"fields\": [\"image\", \"title\"],"
    ],
    [
        "{\"fields\": [\"update_date\", \"updated_by\"], \"description\": \"Third group\"},",
        "{\"fields\": [\"update_date\", \"updated_by\"],"
    ],
    [
        "raise ValidationError(\"The two titles must be the same\")",
        "raise ValidationError(\"The two titles must"
    ],
    [
        "labels = {\"readonly_field\": \"Label from ModelForm.Meta\"}",
        "labels = {\"readonly_field\": \"Label"
    ],
    [
        "help_texts = {\"readonly_field\": \"Help text from ModelForm.Meta\"}",
        "help_texts = {\"readonly_field\": \"Help text from"
    ],
    [
        "if obj is not None and obj.show_inlines:",
        "if obj is not"
    ],
    [
        "from django.test import RequestFactory, TestCase, override_settings",
        "from django.test import RequestFactory,"
    ],
    [
        "from .admin import site as admin_site",
        "from .admin import site"
    ],
    [
        "can_delete should be passed to inlineformset factory.",
        "can_delete should be passed to"
    ],
    [
        "self.assertEqual(expected, actual, \"can_delete must be equal\")",
        "self.assertEqual(expected, actual, \"can_delete must be"
    ],
    [
        "Field names are included in the context to output a field-specific",
        "Field names are included in the"
    ],
    [
        "CSS class name in the column headers.",
        "CSS class name in the"
    ],
    [
        "its label rendered in the tabular inline.",
        "its label rendered in the tabular"
    ],
    [
        "SomeChildModelForm.__init__() overrides the label of a form field.",
        "SomeChildModelForm.__init__() overrides the label"
    ],
    [
        "That label is displayed in the TabularInline.",
        "That label is displayed in the"
    ],
    [
        "response, '<th class=\"column-name required\">New label</th>', html=True",
        "response, '<th class=\"column-name required\">New"
    ],
    [
        "non_field_errors are displayed correctly, including the correct value",
        "non_field_errors are displayed correctly, including the"
    ],
    [
        "\"<li>The two titles must be the same</li></ul></td></tr>\",",
        "\"<li>The two titles must"
    ],
    [
        "\"\"\"Admin inline `readonly_field` shouldn't invoke parent ModelAdmin callable\"\"\"",
        "\"\"\"Admin inline `readonly_field` shouldn't invoke parent ModelAdmin"
    ],
    [
        "Admin inline should invoke local callable when its name is listed in",
        "Admin inline should invoke local callable when"
    ],
    [
        "The inlines' model field help texts are displayed when using both the",
        "The inlines' model field help texts"
    ],
    [
        "'alt=\"(Awesome tabular help text is awesome.)\" '",
        "'alt=\"(Awesome tabular help text is awesome.)\""
    ],
    [
        "'title=\"Awesome tabular help text is awesome.\">',",
        "'title=\"Awesome tabular help"
    ],
    [
        "Tabular inlines use ModelForm.Meta.help_texts and labels for read-only",
        "Tabular inlines use ModelForm.Meta.help_texts"
    ],
    [
        "Content of hidden field is not visible in tabular inline when user has",
        "Content of hidden field is not visible in tabular"
    ],
    [
        "Content of hidden field is not visible in stacked inline when user has",
        "Content of hidden field is not visible in stacked inline when user"
    ],
    [
        "Content of hidden field is not visible in stacked inline when user has",
        "Content of hidden field is not visible in stacked inline when user"
    ],
    [
        "view-only permission and the field is grouped on a separate line.",
        "view-only permission and the field is grouped on a separate"
    ],
    [
        "In tabular inlines, when a form has non-field errors, those errors",
        "In tabular inlines, when a form has non-field"
    ],
    [
        "are rendered in a table line with a single cell spanning the whole",
        "are rendered in a table line with a single cell spanning the"
    ],
    [
        "table width. Colspan must be equal to the number of visible columns.",
        "table width. Colspan must be equal to the"
    ],
    [
        "Multiple inlines with related_name='+' have correct form prefixes.",
        "Multiple inlines with related_name='+' have"
    ],
    [
        "The \"View on Site\" link is correct for locales that use thousand",
        "The \"View on Site\" link is correct for locales"
    ],
    [
        "The \"View on Site\" link is correct for models with a custom primary key",
        "The \"View on Site\" link is correct for"
    ],
    [
        "An object can be created with inlines when it inherits another class.",
        "An object can be created with inlines when it inherits another"
    ],
    [
        "min_num and extra determine number of forms.",
        "min_num and extra determine"
    ],
    [
        "\"Inlines `show_change_link` for registered models when enabled.\"",
        "\"Inlines `show_change_link` for registered"
    ],
    [
        "url = reverse(\"admin:admin_inlines_%s_change\" % model, args=(pk,))",
        "url = reverse(\"admin:admin_inlines_%s_change\""
    ],
    [
        "response, '<a href=\"%s\" %s' % (url, INLINE_CHANGELINK_HTML)",
        "response, '<a href=\"%s\" %s' %"
    ],
    [
        "\"Inlines `show_change_link` disabled for unregistered models.\"",
        "\"Inlines `show_change_link` disabled for unregistered"
    ],
    [
        "\"\"\"Inlines without change permission shows field inputs on add form.\"\"\"",
        "\"\"\"Inlines without change permission shows field inputs on"
    ],
    [
        "The problem depends only on InlineAdminForm and its \"original\"",
        "The problem depends only on"
    ],
    [
        "argument, so we can safely set the other arguments to None/{}. We just",
        "argument, so we can safely set the other arguments to None/{}. We"
    ],
    [
        "need to check that the content_type argument of Child isn't altered by",
        "need to check that the content_type argument of"
    ],
    [
        "the internals of the inline form.\"\"\"",
        "the internals of the"
    ],
    [
        "iaf = InlineAdminForm(None, None, {}, {}, joe)",
        "iaf = InlineAdminForm(None, None, {},"
    ],
    [
        "lotr = Novel.objects.create(name=\"Lord of the rings\")",
        "lotr = Novel.objects.create(name=\"Lord"
    ],
    [
        "\"Deleting chapter %s would require deleting \"",
        "\"Deleting chapter %s would require"
    ],
    [
        "\"the following protected related objects: foot note %s\"",
        "\"the following protected related objects: foot note"
    ],
    [
        "Make sure the admin respects permissions for objects that are edited",
        "Make sure the admin respects permissions for objects"
    ],
    [
        "response, '<div class=\"readonly\">%s</div>' % self.poll.name, html=True",
        "response, '<div class=\"readonly\">%s</div>' % self.poll.name,"
    ],
    [
        "'<input type=\"text\" name=\"name\" value=\"%s\" class=\"vTextField\" '",
        "'<input type=\"text\" name=\"name\" value=\"%s\""
    ],
    [
        "text=\"How will this be rendered?\", poll=self.poll",
        "text=\"How will this be rendered?\","
    ],
    [
        "response, '<td class=\"field-text\"><p>%s</p></td>' % question.text, html=True",
        "response, '<td class=\"field-text\"><p>%s</p></td>' % question.text,"
    ],
    [
        "'<input type=\"submit\" value=\"Save and add another\" name=\"_addanother\">',",
        "'<input type=\"submit\" value=\"Save and add"
    ],
    [
        "'<input type=\"submit\" value=\"Save and continue editing\" name=\"_continue\">',",
        "'<input type=\"submit\" value=\"Save and continue"
    ],
    [
        "Question.objects.create(text=\"How will this be rendered?\", poll=self.poll)",
        "Question.objects.create(text=\"How will this be rendered?\","
    ],
    [
        "verbose_name = \"Childs with verbose name\"",
        "verbose_name = \"Childs with verbose"
    ],
    [
        "verbose_name = \"Childs with verbose name plural\"",
        "verbose_name = \"Childs with verbose"
    ],
    [
        "verbose_name = \"Childs with both verbose names\"",
        "verbose_name = \"Childs with both verbose"
    ],
    [
        "self.assertContains(response, \"Add another Childs with verbose name\")",
        "self.assertContains(response, \"Add another Childs with"
    ],
    [
        "self.assertNotContains(response, \"Add another Model with verbose name only\")",
        "self.assertNotContains(response, \"Add another Model with"
    ],
    [
        "self.assertContains(response, \"Add another Childs with verbose name plural\")",
        "self.assertContains(response, \"Add another Childs with verbose name"
    ],
    [
        "self.assertContains(response, \"Add another Childs with both verbose names\")",
        "self.assertContains(response, \"Add another Childs with"
    ],
    [
        "self.assertNotContains(response, \"Add another Model with both - name\")",
        "self.assertNotContains(response, \"Add another Model with"
    ],
    [
        "verbose_name_plural = \"Childs with verbose name\"",
        "verbose_name_plural = \"Childs with"
    ],
    [
        "verbose_name_plural = \"Childs with verbose name plural\"",
        "verbose_name_plural = \"Childs with verbose name"
    ],
    [
        "verbose_name_plural = \"Childs with both verbose names\"",
        "verbose_name_plural = \"Childs with both"
    ],
    [
        "self.assertContains(response, \"Add another Model with verbose name only\")",
        "self.assertContains(response, \"Add another Model with verbose"
    ],
    [
        "self.assertContains(response, \"Add another Model with both - name\")",
        "self.assertContains(response, \"Add another Model with both -"
    ],
    [
        "verbose_name = \"Non-verbose childs - name\"",
        "verbose_name = \"Non-verbose childs -"
    ],
    [
        "verbose_name_plural = \"Non-verbose childs - plural name\"",
        "verbose_name_plural = \"Non-verbose childs"
    ],
    [
        "verbose_name = \"Childs with verbose name - name\"",
        "verbose_name = \"Childs with verbose"
    ],
    [
        "verbose_name_plural = \"Childs with verbose name - plural name\"",
        "verbose_name_plural = \"Childs with verbose name -"
    ],
    [
        "verbose_name = \"Childs with verbose name plural - name\"",
        "verbose_name = \"Childs with verbose name plural"
    ],
    [
        "verbose_name_plural = \"Childs with verbose name plural - plural name\"",
        "verbose_name_plural = \"Childs with verbose name plural -"
    ],
    [
        "verbose_name = \"Childs with both - name\"",
        "verbose_name = \"Childs with"
    ],
    [
        "verbose_name_plural = \"Childs with both - plural name\"",
        "verbose_name_plural = \"Childs with both -"
    ],
    [
        "self.assertContains(response, \"Add another Non-verbose childs - name\")",
        "self.assertContains(response, \"Add another Non-verbose childs"
    ],
    [
        "self.assertContains(response, \"Add another Childs with verbose name - name\")",
        "self.assertContains(response, \"Add another Childs with verbose"
    ],
    [
        "\"Add another Childs with verbose name plural - name\",",
        "\"Add another Childs with verbose name"
    ],
    [
        "self.assertContains(response, \"Add another Childs with both - name\")",
        "self.assertContains(response, \"Add another Childs with"
    ],
    [
        "self.assertNotContains(response, \"Add another Model with both - name\")",
        "self.assertNotContains(response, \"Add another Model"
    ],
    [
        "The \"Add another XXX\" link correctly adds items to the stacked formset.",
        "The \"Add another XXX\" link correctly adds items to"
    ],
    [
        "self.assertEqual(\"Please correct the duplicate values below.\", errorlist.text)",
        "self.assertEqual(\"Please correct the duplicate values"
    ],
    [
        "self.assertEqual(\"Please correct the duplicate values below.\", errorlist.text)",
        "self.assertEqual(\"Please correct the duplicate values"
    ],
    [
        "The \"Add another XXX\" link correctly adds items to the inline form.",
        "The \"Add another XXX\" link correctly adds items"
    ],
    [
        "add_text = gettext(\"Add another %(verbose_name)s\") % {\"verbose_name\": \"Child\"}",
        "add_text = gettext(\"Add another"
    ],
    [
        "width, style, color = border.split(\" \")",
        "width, style, color ="
    ],
    [
        "\"rgb(%d, %d, %d)\" % (r, g, b),",
        "\"rgb(%d, %d, %d)\" % (r, g,"
    ],
    [
        "for field_name in (\"name\", \"select\", \"text\"):",
        "for field_name in"
    ],
    [
        "stacked_selectors = [\".errors input\", \".errors select\", \".errors textarea\"]",
        "stacked_selectors = [\".errors input\", \".errors select\", \".errors"
    ],
    [
        "The item added by the \"Add another XXX\" link must use the correct",
        "The item added by the \"Add another XXX\""
    ],
    [
        "autodiscover() and an admin.py module contains an error.",
        "autodiscover() and an admin.py module contains"
    ],
    [
        "return \"Comment to %s (%s)\" % (self.article.title, self.pub_date)",
        "return \"Comment to %s"
    ],
    [
        "from .models import Article, Category, Comment",
        "from .models import"
    ],
    [
        "title=\"Third one, in the first day\",",
        "title=\"Third one, in"
    ],
    [
        "title=\"Don't put dates into datetime functions!\",",
        "title=\"Don't put dates into"
    ],
    [
        "ValueError, \"Cannot truncate DateField 'published_on' to DateTimeField\"",
        "ValueError, \"Cannot truncate DateField 'published_on'"
    ],
    [
        "\"'kind' must be one of 'year', 'month', 'week', 'day', 'hour', \"",
        "\"'kind' must be one of 'year', 'month', 'week',"
    ],
    [
        "msg = \"'order' must be either 'ASC' or 'DESC'.\"",
        "msg = \"'order' must be either"
    ],
    [
        "Specify default ordering for a model using the ``ordering`` attribute, which",
        "Specify default ordering for a model"
    ],
    [
        "should be a list or tuple of field names. This tells Django how to order",
        "should be a list or tuple of field names."
    ],
    [
        "If a field name in ``ordering`` starts with a hyphen, that field will be",
        "If a field name in ``ordering`` starts with a hyphen, that field"
    ],
    [
        "ordered in descending order. Otherwise, it'll be ordered in ascending order.",
        "ordered in descending order. Otherwise, it'll be ordered in ascending"
    ],
    [
        "The special-case field name ``\"?\"`` specifies random order.",
        "The special-case field name ``\"?\"`` specifies random"
    ],
    [
        "The ordering attribute is not required. If you leave it off, ordering will be",
        "The ordering attribute is not required. If you leave it off,"
    ],
    [
        "undefined -- not random, just undefined.",
        "undefined -- not random, just"
    ],
    [
        "By default, Article.objects.all() orders by pub_date descending, then",
        "By default, Article.objects.all() orders by pub_date"
    ],
    [
        "Override ordering with order_by, which is in the same format as the",
        "Override ordering with order_by, which is in"
    ],
    [
        "Attempts to override default ordering on related models with an unknown",
        "Attempts to override default ordering on"
    ],
    [
        "field should result in an error.",
        "field should result"
    ],
    [
        "\"Cannot resolve keyword 'unknown_field' into field. Choices are: \"",
        "\"Cannot resolve keyword 'unknown_field' into"
    ],
    [
        "\"article, author, editor, editor_id, id, name\"",
        "\"article, author, editor, editor_id,"
    ],
    [
        "Only the last order_by has any effect (since they each override any",
        "Only the last order_by has any effect (since they each"
    ],
    [
        "msg = \"nulls_first and nulls_last are mutually exclusive\"",
        "msg = \"nulls_first and nulls_last"
    ],
    [
        "Use the 'stop' part of slicing notation to limit the results.",
        "Use the 'stop' part of slicing notation to limit"
    ],
    [
        "Use the 'stop' and 'start' parts of slicing notation to offset the",
        "Use the 'stop' and 'start' parts"
    ],
    [
        "Ordering can be reversed using the reverse() method on a queryset.",
        "Ordering can be reversed using the reverse() method on"
    ],
    [
        "This allows you to extract things like \"the last two items\" (reverse",
        "This allows you to extract things like \"the last"
    ],
    [
        "and then take the first two).",
        "and then take the first"
    ],
    [
        "msg = \"Cannot reverse a query once a slice has been taken.\"",
        "msg = \"Cannot reverse a query once a"
    ],
    [
        "Ordering can be based on fields included from an 'extra' clause",
        "Ordering can be based on fields included from an"
    ],
    [
        "If the extra clause uses an SQL keyword for a name, it will be",
        "If the extra clause uses an SQL keyword for a name, it will"
    ],
    [
        "'pk' works as an ordering option in Meta.",
        "'pk' works as an ordering option"
    ],
    [
        "ordering by a foreign key by its attribute name prevents the query",
        "ordering by a foreign key by its attribute"
    ],
    [
        "A column may only be included once (the first occurrence) so we check",
        "A column may only be included once (the first occurrence) so"
    ],
    [
        "to ensure there are no duplicates by inspecting the SQL.",
        "to ensure there are no duplicates"
    ],
    [
        "An ordering referencing a model with an ordering referencing a model",
        "An ordering referencing a model with an ordering referencing"
    ],
    [
        "\"\"\"F expressions can be used in Meta.ordering.\"\"\"",
        "\"\"\"F expressions can be used in"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import SimpleTestCase, TestCase, skipIfDBFeature,"
    ],
    [
        "from .models import Classification, Detail, Employee, PastEmployeeDepartment",
        "from .models import Classification, Detail, Employee,"
    ],
    [
        "Rank the employees based on the year they're were hired. Since there",
        "Rank the employees based on the year they're were hired."
    ],
    [
        "are multiple employees hired in different years, this will contain",
        "are multiple employees hired in different years, this will"
    ],
    [
        "The row number window function computes the number based on the order",
        "The row number window function computes the number"
    ],
    [
        "in which the tuples were inserted. Depending on the backend,",
        "in which the tuples were inserted. Depending"
    ],
    [
        "Oracle requires an ordering-clause in the Window expression.",
        "Oracle requires an ordering-clause in the Window"
    ],
    [
        "The row number window function computes the number based on the order",
        "The row number window function computes the number based on"
    ],
    [
        "in which the tuples were inserted.",
        "in which the tuples"
    ],
    [
        "Compute the difference between an employee's salary and the next",
        "Compute the difference between an"
    ],
    [
        "highest salary in the employee's department. Return None if the",
        "highest salary in the employee's department. Return"
    ],
    [
        "transform=lambda row: (row.name, row.salary, row.department, row.lag),",
        "transform=lambda row: (row.name,"
    ],
    [
        "transform=lambda row: (row.name, row.bonus, row.department, row.lag),",
        "transform=lambda row: (row.name,"
    ],
    [
        "\"\"\"An alternative way to specify a query for FirstValue.\"\"\"",
        "\"\"\"An alternative way to specify a query for"
    ],
    [
        "lambda row: (row.name, row.department, row.salary, row.min_salary),",
        "lambda row: (row.name, row.department,"
    ],
    [
        "Find the maximum salary awarded in the same year as the",
        "Find the maximum salary awarded in"
    ],
    [
        "employee was hired, regardless of the department.",
        "employee was hired, regardless of the"
    ],
    [
        "Compute the cumulative distribution for the employees based on the",
        "Compute the cumulative distribution for the employees based"
    ],
    [
        "Determine what the next person hired in the same department makes.",
        "Determine what the next person hired"
    ],
    [
        "Because the dataset is ambiguous, the name is also part of the",
        "Because the dataset is ambiguous, the name is also part"
    ],
    [
        "ordering clause. No default is provided, so None/NULL should be",
        "ordering clause. No default is provided, so"
    ],
    [
        "Determine what the person hired after someone makes. Due to",
        "Determine what the person hired after"
    ],
    [
        "ambiguity, the name is also included in the ordering.",
        "ambiguity, the name is also included"
    ],
    [
        "Compute the group for each of the employees across the entire company,",
        "Compute the group for each of"
    ],
    [
        "based on how high the salary is for them. There are twelve employees",
        "based on how high the salary is for them. There are twelve"
    ],
    [
        "so it divides evenly into four groups.",
        "so it divides evenly into four"
    ],
    [
        "lambda x: (x.name, x.department, x.salary, x.ntile),",
        "lambda x: (x.name, x.department,"
    ],
    [
        "Calculate the percentage rank of the employees across the entire",
        "Calculate the percentage rank of the employees"
    ],
    [
        "company based on salary and name (in case of ambiguity).",
        "company based on salary and name (in case"
    ],
    [
        "Find the nth row of the data set. None is returned since there are",
        "Find the nth row of the data set. None is returned since there"
    ],
    [
        "Find the maximum salary for each department for people hired in the",
        "Find the maximum salary for each department"
    ],
    [
        "Accumulate the salaries over the departments based on hire_date.",
        "Accumulate the salaries over the departments based"
    ],
    [
        "If two people were hired on the same date in the same department, the",
        "If two people were hired on the same date in the same department,"
    ],
    [
        "ordering clause will render a different result for those people.",
        "ordering clause will render a different"
    ],
    [
        "Explicit empty ordering makes little sense but it is something that",
        "Explicit empty ordering makes little sense"
    ],
    [
        "qs, [\"Adams\", \"Johnson\", \"Miller\", \"Smith\", \"Wilkinson\"]",
        "qs, [\"Adams\", \"Johnson\","
    ],
    [
        "qs, [\"Adams\", \"Johnson\", \"Miller\", \"Smith\", \"Wilkinson\"]",
        "qs, [\"Adams\", \"Johnson\","
    ],
    [
        "A query filtering against a window function have its limit applied",
        "A query filtering against a window function have"
    ],
    [
        "\"\"\"A query with RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING.\"\"\"",
        "\"\"\"A query with RANGE BETWEEN UNBOUNDED PRECEDING AND"
    ],
    [
        "\"RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\", str(qs.query)",
        "\"RANGE BETWEEN UNBOUNDED PRECEDING AND"
    ],
    [
        "msg = \"This backend does not support window frame exclusions.\"",
        "msg = \"This backend does"
    ],
    [
        "msg = \"RowRange.exclusion must be a WindowFrameExclusion instance.\"",
        "msg = \"RowRange.exclusion must be a WindowFrameExclusion"
    ],
    [
        "The resulting sum is the sum of the three next (if they exist) and all",
        "The resulting sum is the sum of the three next (if"
    ],
    [
        "previous rows according to the ordering clause.",
        "previous rows according to the ordering"
    ],
    [
        "The resulting sum is the sum of the previous two (if they exist) rows",
        "The resulting sum is the sum of the previous two (if"
    ],
    [
        "The resulting sum is the sum of the following two (if they exist) rows",
        "The resulting sum is the sum of the"
    ],
    [
        "Window functions are not aggregates, and hence a query to filter out",
        "Window functions are not aggregates, and hence a query to filter"
    ],
    [
        "for idx, val in zip(range(len(results)), results):",
        "for idx, val in zip(range(len(results)),"
    ],
    [
        "\"\"\"Window expressions can't be used in an UPDATE statement.\"\"\"",
        "\"\"\"Window expressions can't be used in an UPDATE"
    ],
    [
        "\"Window expressions are not allowed in this query (salary=<Window: \"",
        "\"Window expressions are not allowed in this query (salary=<Window:"
    ],
    [
        "\"\"\"Window expressions can't be used in an INSERT statement.\"\"\"",
        "\"\"\"Window expressions can't be used in an INSERT"
    ],
    [
        "\"Window expressions are not allowed in this query (salary=<Window: \"",
        "\"Window expressions are not allowed"
    ],
    [
        "msg = \"start cannot be greater than end.\"",
        "msg = \"start cannot be"
    ],
    [
        "msg = \"end argument must be a positive integer, zero, or None, but got 'a'.\"",
        "msg = \"end argument must be a positive"
    ],
    [
        "msg = \"start argument must be a negative integer, zero, or None, but got 'a'.\"",
        "msg = \"start argument must be a negative integer, zero,"
    ],
    [
        "msg = \"end argument must be an integer, zero, or None, but got 'a'.\"",
        "msg = \"end argument must be an integer, zero,"
    ],
    [
        "\"%s only supports UNBOUNDED together with PRECEDING and FOLLOWING.\"",
        "\"%s only supports UNBOUNDED together with PRECEDING"
    ],
    [
        "\"%s only supports UNBOUNDED together with PRECEDING and FOLLOWING.\"",
        "\"%s only supports UNBOUNDED together with PRECEDING"
    ],
    [
        "msg = \"start argument must be an integer, zero, or None, but got 'a'.\"",
        "msg = \"start argument must be an"
    ],
    [
        "\"Heterogeneous disjunctive predicates against window functions are not \"",
        "\"Heterogeneous disjunctive predicates against window functions"
    ],
    [
        "msg = \"This backend does not support window expressions.\"",
        "msg = \"This backend does not support"
    ],
    [
        "\"Referencing outer query window expression is not supported: \"",
        "\"Referencing outer query window expression"
    ],
    [
        "\"<Window: Sum(F(salary)) OVER (PARTITION BY F(department))>\",",
        "\"<Window: Sum(F(salary)) OVER (PARTITION BY"
    ],
    [
        "\"<ValueRange: RANGE BETWEEN CURRENT ROW AND CURRENT ROW>\",",
        "\"<ValueRange: RANGE BETWEEN CURRENT ROW"
    ],
    [
        "\"<RowRange: ROWS BETWEEN CURRENT ROW AND CURRENT ROW>\",",
        "\"<RowRange: ROWS BETWEEN CURRENT"
    ],
    [
        "msg = \"Subclasses must implement window_frame_start_end().\"",
        "msg = \"Subclasses"
    ],
    [
        "\"Window.order_by must be either a string reference to a field, an \"",
        "\"Window.order_by must be either a string reference to a"
    ],
    [
        "\"expression, or a list or tuple of them.\"",
        "\"expression, or a list or tuple of"
    ],
    [
        "msg = \"Expression 'Upper' isn't compatible with OVER clauses.\"",
        "msg = \"Expression 'Upper' isn't"
    ],
    [
        "Relating an object to itself, many-to-one",
        "Relating an object"
    ],
    [
        "To define a many-to-one relationship between a model and itself, use",
        "To define a many-to-one relationship between a model and"
    ],
    [
        "In this example, a ``Category`` is related to itself. That is, each",
        "In this example, a ``Category`` is"
    ],
    [
        "Set ``related_name`` to designate what the reverse relationship is called.",
        "Set ``related_name`` to designate what the reverse relationship"
    ],
    [
        "cls.r = Category.objects.create(id=None, name=\"Root category\", parent=None)",
        "cls.r = Category.objects.create(id=None, name=\"Root category\","
    ],
    [
        "cls.c = Category.objects.create(id=None, name=\"Child category\", parent=cls.r)",
        "cls.c = Category.objects.create(id=None, name=\"Child"
    ],
    [
        "from .d import e, f as g",
        "from .d import e, f"
    ],
    [
        "self.assertEqual(locator.import_locations, {\"b\": \"a\", \"c\": \"a\", \"e\": \".d\"})",
        "self.assertEqual(locator.import_locations, {\"b\": \"a\", \"c\": \"a\", \"e\":"
    ],
    [
        "info = {\"module\": None, \"fullname\": None}",
        "info = {\"module\": None, \"fullname\":"
    ],
    [
        "msg = \"Could not import '.....test' in 'tests.sphinx.testdata.package'.\"",
        "msg = \"Could not import"
    ],
    [
        "from .models import CustomArticle, ExclusiveArticle, SyndicatedArticle",
        "from .models import CustomArticle, ExclusiveArticle,"
    ],
    [
        "\"CurrentSiteManager could not find a field named \"",
        "\"CurrentSiteManager could not find"
    ],
    [
        "\"CurrentSiteManager cannot use 'ConfusedArticle.site' as it is \"",
        "\"CurrentSiteManager cannot use 'ConfusedArticle.site'"
    ],
    [
        "\"not a foreign key or a many-to-many field.\",",
        "\"not a foreign key"
    ],
    [
        "To define a many-to-one relationship, use ``ForeignKey()``.",
        "To define a many-to-one relationship, use"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\" %"
    ],
    [
        "city = models.ForeignKey(City, models.CASCADE, related_name=\"districts\", null=True)",
        "city = models.ForeignKey(City,"
    ],
    [
        "return \"%s - %s\" % (self.left.category.name, self.right.category.name)",
        "return \"%s - %s\" % (self.left.category.name,"
    ],
    [
        "from django.db import IntegrityError, models, transaction",
        "from django.db import IntegrityError, models,"
    ],
    [
        "\"<Article: Paul's story> instance isn't saved. Use bulk=False or save the \"",
        "\"<Article: Paul's story> instance isn't saved. Use bulk=False or"
    ],
    [
        "TypeError, \"'Article' instance expected, got <Reporter:\"",
        "TypeError, \"'Article' instance"
    ],
    [
        "\"Direct assignment to the reverse side of a related set is \"",
        "\"Direct assignment to the reverse side of"
    ],
    [
        "d = {\"reporter__first_name\": \"John\", \"reporter__last_name\": \"Smith\"}",
        "d = {\"reporter__first_name\": \"John\", \"reporter__last_name\":"
    ],
    [
        "\"Cannot resolve keyword 'notafield' into field. Choices are: %s\"",
        "\"Cannot resolve keyword 'notafield' into field. Choices"
    ],
    [
        "reporter_fields = \", \".join(sorted(f.name for f in Reporter._meta.get_fields()))",
        "reporter_fields = \", \".join(sorted(f.name for f"
    ],
    [
        "[\"EXTRA\"] + sorted(f.name for f in Article._meta.get_fields())",
        "[\"EXTRA\"] + sorted(f.name for"
    ],
    [
        "\"save() prohibited to prevent data loss due to unsaved related object \"",
        "\"save() prohibited to prevent data loss due to unsaved related"
    ],
    [
        "msg = 'Cannot assign \"%r\": \"Child.parent\" must be a \"Parent\" instance.' % c",
        "msg = 'Cannot assign \"%r\": \"Child.parent\" must be a \"Parent\""
    ],
    [
        "\"'Third' instance needs to have a primary key value before this \"",
        "\"'Third' instance needs to have a primary"
    ],
    [
        "Model.save() invalidates stale ForeignKey relations after a primary key",
        "Model.save() invalidates stale ForeignKey relations after a primary"
    ],
    [
        "msg = \"'City' instance expected, got %s\" % chicago.pk",
        "msg = \"'City' instance expected, got"
    ],
    [
        "def save(self, *args, force_insert=False, force_update=False, **kwargs):",
        "def save(self, *args, force_insert=False,"
    ],
    [
        "return \"TestObject: %s,%s,%s\" % (self.first, self.second, self.third)",
        "return \"TestObject: %s,%s,%s\" % (self.first,"
    ],
    [
        "from .models import Order, RevisionableModel, TestObject",
        "from .models import Order,"
    ],
    [
        "\"(SELECT MAX(rev.id) FROM %(table)s rev GROUP BY rev.base_id)\"",
        "\"(SELECT MAX(rev.id) FROM %(table)s"
    ],
    [
        "corresponding parameters associated with the right extra() bit. I.e.",
        "corresponding parameters associated with the right extra()"
    ],
    [
        "extra(...) in a query, remove any corresponding parameters from the",
        "extra(...) in a query, remove any corresponding parameters"
    ],
    [
        "from extra(). This test is the critical case: ordering uses a table,",
        "from extra(). This test is the"
    ],
    [
        "but then removes the reference because of an optimization. The table",
        "but then removes the reference because of an optimization. The"
    ],
    [
        "should still be present because of the extra() call.",
        "should still be present because of the"
    ],
    [
        "When calling the dates() method on a queryset with extra selection",
        "When calling the dates() method on a queryset with extra"
    ],
    [
        "columns, we can (and should) ignore those columns. They don't change",
        "columns, we can (and should) ignore those columns. They don't"
    ],
    [
        "the result and cause incorrect SQL to be produced otherwise.",
        "the result and cause incorrect SQL to be produced"
    ],
    [
        "columns are only returned if they are explicitly mentioned.",
        "columns are only returned if they are"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\":"
    ],
    [
        "[{\"second\": \"second\", \"foo\": \"first\", \"first\": \"first\"}],",
        "[{\"second\": \"second\", \"foo\": \"first\", \"first\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\":"
    ],
    [
        "[(\"first\", \"second\", \"third\", obj.pk, \"first\", \"second\", \"third\")],",
        "[(\"first\", \"second\", \"third\", obj.pk, \"first\","
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\","
    ],
    [
        "[(\"first\", \"second\", \"third\", obj.pk, \"first\", \"second\", \"third\")],",
        "[(\"first\", \"second\", \"third\", obj.pk, \"first\","
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\","
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\": \"second\","
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\":"
    ],
    [
        "select={\"foo\": \"first\", \"bar\": \"second\", \"whiz\": \"third\"}",
        "select={\"foo\": \"first\", \"bar\":"
    ],
    [
        "accurately evaluated. Using an inner query ensures that as_sql() is",
        "accurately evaluated. Using an inner query ensures"
    ],
    [
        "producing correct output without requiring full evaluation and",
        "producing correct output without requiring"
    ],
    [
        "Extra WHERE clauses get correctly ANDed, even when they",
        "Extra WHERE clauses get correctly ANDed,"
    ],
    [
        "where=[\"first = 'a' OR second = 'a'\", \"third = 'a'\"],",
        "where=[\"first = 'a' OR second = 'a'\", \"third ="
    ],
    [
        "\", \".join(q.name for q in self.qualifications.all()),",
        "\", \".join(q.name for q in"
    ],
    [
        "boss = models.ForeignKey(\"self\", models.SET_NULL, null=True, related_name=\"serfs\")",
        "boss = models.ForeignKey(\"self\", models.SET_NULL,"
    ],
    [
        "from .models import Author, Book, House, Reader, Room",
        "from .models import Author, Book, House,"
    ],
    [
        "Since prefetch_related_objects() is just the inner part of",
        "Since prefetch_related_objects() is just"
    ],
    [
        "prefetch_related(), only do basic tests to ensure its API hasn't changed.",
        "prefetch_related(), only do basic tests to ensure its API hasn't"
    ],
    [
        "[[str(r) for r in b.read_by.all()] for b in a.books.all()]",
        "[[str(r) for r in b.read_by.all()] for"
    ],
    [
        "from django.db.models import F, Prefetch, QuerySet, prefetch_related_objects",
        "from django.db.models import F, Prefetch, QuerySet,"
    ],
    [
        "msg=\"WHERE clause doesn't contain %s, actual SQL: %s\"",
        "msg=\"WHERE clause doesn't contain"
    ],
    [
        "normal_lists = [list(b.authors.all()) for b in Book.objects.all()]",
        "normal_lists = [list(b.authors.all()) for"
    ],
    [
        "normal_lists = [list(a.books.all()) for a in Author.objects.all()]",
        "normal_lists = [list(a.books.all()) for a"
    ],
    [
        "normal_books = [a.first_book for a in Author.objects.all()]",
        "normal_books = [a.first_book for"
    ],
    [
        "A model (Bio) with a OneToOneField primary key (author) that references",
        "A model (Bio) with a OneToOneField"
    ],
    [
        "a non-pk field (name) on the related model (Author) is prefetchable.",
        "a non-pk field (name) on the related model (Author) is"
    ],
    [
        "when using prefetch_related. This was fixed by the removal of chunked",
        "when using prefetch_related. This was fixed by the removal of"
    ],
    [
        "[[str(r) for r in b.read_by.all()] for b in a.books.all()] for a in qs",
        "[[str(r) for r in b.read_by.all()] for b"
    ],
    [
        "[[str(r) for r in b.read_by.all()] for b in a.books.all()] for a in qs",
        "[[str(r) for r in b.read_by.all()] for b in"
    ],
    [
        "[[str(r) for r in b.read_by.all()] for b in a.books.all()] for a in qs",
        "[[str(r) for r in b.read_by.all()] for b in a.books.all()] for"
    ],
    [
        "Objects retrieved with .get() get the prefetch behavior.",
        "Objects retrieved with .get()"
    ],
    [
        "lists = [[str(r) for r in b.read_by.all()] for b in author.books.all()]",
        "lists = [[str(r) for r in"
    ],
    [
        "lists = [[str(r) for r in a.first_book.read_by.all()] for a in qs]",
        "lists = [[str(r) for r in"
    ],
    [
        "self.assertEqual(lists, [[\"Amy\"], [\"Amy\"], [\"Amy\"], [\"Amy\", \"Belinda\"]])",
        "self.assertEqual(lists, [[\"Amy\"], [\"Amy\"], [\"Amy\"],"
    ],
    [
        "\"Cannot find 'xyz' on Book object, 'books_read__xyz' \"",
        "\"Cannot find 'xyz' on Book object,"
    ],
    [
        "\"is an invalid parameter to prefetch_related()\"",
        "\"is an invalid parameter"
    ],
    [
        "\"'authors__name' does not resolve to an item that supports \"",
        "\"'authors__name' does not resolve to"
    ],
    [
        "\"prefetching - this is an invalid parameter to prefetch_related().\"",
        "\"prefetching - this is an invalid parameter"
    ],
    [
        "msg = \"to_attr=authors conflicts with a field on the Book model.\"",
        "msg = \"to_attr=authors conflicts with a field on"
    ],
    [
        "msg = \"to_attr=books conflicts with a field on the Author model.\"",
        "msg = \"to_attr=books conflicts with a field on the Author"
    ],
    [
        "side_effect=lambda self, q, reuse_all: add_q(self, q),",
        "side_effect=lambda self, q, reuse_all: add_q(self,"
    ],
    [
        "[value.name for value in qs.values_list(\"name\", named=True)],",
        "[value.name for value in qs.values_list(\"name\","
    ],
    [
        "\"chunk_size must be provided when using QuerySet.iterator() after \"",
        "\"chunk_size must be provided when using"
    ],
    [
        "Helper method that returns a list containing a list of the objects in the",
        "Helper method that returns a list containing a"
    ],
    [
        "obj_iter. Then for each object in the obj_iter, the path will be",
        "obj_iter. Then for each object in"
    ],
    [
        "recursively travelled and the found objects are added to the return value.",
        "recursively travelled and the found objects"
    ],
    [
        "related_objs_normal = ([list(p.houses.all()) for p in qs],)",
        "related_objs_normal = ([list(p.houses.all()) for p"
    ],
    [
        "\"'houses' lookup was already seen with a different queryset. You \"",
        "\"'houses' lookup was already seen with a different queryset."
    ],
    [
        "\"may need to adjust the ordering of your lookups.\"",
        "\"may need to adjust the ordering of your"
    ],
    [
        "\"Cannot find 'houses_lst' on Person object, 'houses_lst__rooms' is \"",
        "\"Cannot find 'houses_lst' on Person object, 'houses_lst__rooms' is"
    ],
    [
        "Nested prefetches whose name clashes with descriptor names",
        "Nested prefetches whose name clashes with"
    ],
    [
        "msg = \"Prefetch querysets cannot use raw(), values(), and values_list().\"",
        "msg = \"Prefetch querysets cannot"
    ],
    [
        "msg = \"Prefetch querysets cannot use raw(), values(), and values_list().\"",
        "msg = \"Prefetch querysets cannot use raw(), values(), and"
    ],
    [
        "Related filtering of prefetched querysets is deferred until necessary.",
        "Related filtering of prefetched querysets"
    ],
    [
        "side_effect=lambda self, q, reuse_all: add_q(self, q),",
        "side_effect=lambda self, q, reuse_all:"
    ],
    [
        "% (dept.name, \", \".join(str(t) for t in dept.teachers.all()))",
        "% (dept.name, \", \".join(str(t) for t"
    ],
    [
        "\"English department: Mr Cleese (BA, BSci, MA, PhD), Mr Idle (BA)\\n\"",
        "\"English department: Mr Cleese (BA, BSci, MA,"
    ],
    [
        "\"Physics department: Mr Cleese (BA, BSci, MA, PhD), Mr Chapman \"",
        "\"Physics department: Mr Cleese (BA, BSci,"
    ],
    [
        "self.assertEqual([c.content_object_uuid for c in qs], [article])",
        "self.assertEqual([c.content_object_uuid for c"
    ],
    [
        "self.assertEqual([c.content_object for c in qs], [book_with_year])",
        "self.assertEqual([c.content_object for c in qs],"
    ],
    [
        "A 'content_object' can be traversed with prefetch_related() and",
        "A 'content_object' can be traversed"
    ],
    [
        "get to related objects on the other side (assuming it is suitably",
        "get to related objects on the other side"
    ],
    [
        "r.name for tag in qs for r in tag.content_object.read_by.all()",
        "r.name for tag in qs for r"
    ],
    [
        "self.assertEqual(result, [t.created_by for t in TaggedItem.objects.all()])",
        "self.assertEqual(result, [t.created_by for t"
    ],
    [
        "sorted(i.tag for i in bookmark.tags.all()), [\"django\", \"python\"]",
        "sorted(i.tag for i in"
    ],
    [
        "self.assertEqual([i.tag for i in bookmark.favorite_tags.all()], [\"python\"])",
        "self.assertEqual([i.tag for i"
    ],
    [
        "(tag.object_id, tag.content_type_id, tag.content_object) for tag in qs",
        "(tag.object_id, tag.content_type_id, tag.content_object) for tag"
    ],
    [
        "[str(address) for address in obj.addresses.all()] for obj in qs",
        "[str(address) for address in obj.addresses.all()] for obj in"
    ],
    [
        "titles = [obj.book.title for obj in qs]",
        "titles = [obj.book.title for obj"
    ],
    [
        "[str(book) for book in author.books_with_year.all()] for author in qs",
        "[str(book) for book in author.books_with_year.all()] for author"
    ],
    [
        "lst = [[str(author) for author in book.aged_authors.all()] for book in qs]",
        "lst = [[str(author) for author in"
    ],
    [
        "self.assertEqual(authors, [a.authorwithage for a in Author.objects.all()])",
        "self.assertEqual(authors, [a.authorwithage for a"
    ],
    [
        "[str(address) for address in obj.addresses.all()] for obj in qs",
        "[str(address) for address in obj.addresses.all()] for"
    ],
    [
        "Test cases that demonstrate that ordering of lookups is important, and",
        "Test cases that demonstrate that ordering of"
    ],
    [
        "list(e.boss.serfs.all()) if e.boss is not None else [] for e in qs",
        "list(e.boss.serfs.all()) if e.boss is not None else"
    ],
    [
        "list(e.boss.serfs.all()) if e.boss is not None else [] for e in qs",
        "list(e.boss.serfs.all()) if e.boss is not None else"
    ],
    [
        "In-bulk does correctly prefetch objects by not using .iterator()",
        "In-bulk does correctly prefetch objects"
    ],
    [
        "% (book.title, \", \".join(a.name for a in book.authors.all()))",
        "% (book.title, \", \".join(a.name"
    ],
    [
        "% (author.name, \", \".join(b.title for b in author.books.all()))",
        "% (author.name, \", \".join(b.title for b"
    ],
    [
        "% (b.title, \", \".join(a.name for a in b.first_time_authors.all()))",
        "% (b.title, \", \".join(a.name for a"
    ],
    [
        "\"Poems (Charlotte Bronte)\\nSense and Sensibility (Jane Austen)\\n\",",
        "\"Poems (Charlotte Bronte)\\nSense and"
    ],
    [
        "authors = \", \".join(a.author.name for a in A.prefetch_related(\"author\"))",
        "authors = \", \".join(a.author.name for"
    ],
    [
        "% (b.title, \", \".join(a.name for a in b.first_time_authors.all()))",
        "% (b.title, \", \".join(a.name for a in"
    ],
    [
        "\"Poems (Charlotte Bronte)\\nSense and Sensibility (Jane Austen)\\n\",",
        "\"Poems (Charlotte Bronte)\\nSense and Sensibility"
    ],
    [
        "% (b.title, \", \".join(a.name for a in b.first_time_authors.all()))",
        "% (b.title, \", \".join(a.name for a in"
    ],
    [
        "\"Poems (Charlotte Bronte)\\nSense and Sensibility (Jane Austen)\\n\",",
        "\"Poems (Charlotte Bronte)\\nSense and Sensibility (Jane"
    ],
    [
        "% (b.title, \", \".join(a.name for a in b.first_time_authors.all()))",
        "% (b.title, \", \".join(a.name for"
    ],
    [
        "self.assertEqual(books, \"Poems ()\\n\" \"Sense and Sensibility ()\\n\")",
        "self.assertEqual(books, \"Poems ()\\n\" \"Sense"
    ],
    [
        "for id_, lesson_entry_id, name in [",
        "for id_, lesson_entry_id,"
    ],
    [
        "prefetch_related() reuses objects fetched in _prefetched_objects_cache.",
        "prefetch_related() reuses objects fetched in"
    ],
    [
        "When objects are prefetched and not stored as an instance attribute (often",
        "When objects are prefetched and not stored as an instance attribute"
    ],
    [
        "intermediary relationships), they are saved to the",
        "intermediary relationships), they are saved to"
    ],
    [
        "_prefetched_objects_cache into account when determining whether an object",
        "_prefetched_objects_cache into account when determining"
    ],
    [
        "Nested prefetch_related() shouldn't trigger duplicate queries for the same",
        "Nested prefetch_related() shouldn't trigger duplicate queries for"
    ],
    [
        "When intermediary results are prefetched without a destination",
        "When intermediary results are"
    ],
    [
        "attribute, they are saved in the RelatedManager's cache",
        "attribute, they are saved"
    ],
    [
        "The prefetched relationship is used rather than populating the reverse",
        "The prefetched relationship is used rather than populating"
    ],
    [
        "relationship from the parent, when prefetching a set of child objects",
        "relationship from the parent, when prefetching"
    ],
    [
        "related to a set of parent objects and the child queryset itself",
        "related to a set of parent objects"
    ],
    [
        "specifies a prefetch back to the parent.",
        "specifies a prefetch back to"
    ],
    [
        "\"Prefetching from a limited queryset is only supported on backends that \"",
        "\"Prefetching from a limited queryset is only supported on backends"
    ],
    [
        "from .models import Flea, House, Person, Pet, Room",
        "from .models import Flea, House, Person,"
    ],
    [
        "assert isinstance(data, bytes), \"write() argument must be bytestring\"",
        "assert isinstance(data, bytes), \"write()"
    ],
    [
        "for chunk in iter(lambda: data.read(MAX_SOCKET_CHUNK_SIZE), b\"\"):",
        "for chunk in"
    ],
    [
        "The wsgi.file_wrapper works for the builtin server.",
        "The wsgi.file_wrapper works for the"
    ],
    [
        "We need to mock a couple of handlers and keep track of what",
        "We need to mock a couple of handlers and keep track"
    ],
    [
        "gets called when using a couple kinds of WSGI apps.",
        "gets called when using a couple kinds of WSGI"
    ],
    [
        "handler = FileWrapperHandler(BytesIO(), BytesIO(), BytesIO(), env)",
        "handler = FileWrapperHandler(BytesIO(), BytesIO(),"
    ],
    [
        "handler = FileWrapperHandler(BytesIO(), BytesIO(), BytesIO(), env)",
        "handler = FileWrapperHandler(BytesIO(), BytesIO(),"
    ],
    [
        "View returning a FileResponse properly closes the file and http",
        "View returning a FileResponse properly closes the file and"
    ],
    [
        "handler = FileWrapperHandler(BytesIO(), BytesIO(), BytesIO(), env)",
        "handler = FileWrapperHandler(BytesIO(),"
    ],
    [
        "handler = FileWrapperHandler(BytesIO(), BytesIO(), BytesIO(), env)",
        "handler = FileWrapperHandler(BytesIO(),"
    ],
    [
        "Server handler that counts the number of chunks written after headers were",
        "Server handler that counts the number of chunks written"
    ],
    [
        "sent. Used to make sure large response body chunking works properly.",
        "sent. Used to make sure large response"
    ],
    [
        "handler = WriteChunkCounterHandler(None, BytesIO(), BytesIO(), env)",
        "handler = WriteChunkCounterHandler(None,"
    ],
    [
        "Regression tests for defer() / only() behavior.",
        "Regression tests for defer() / only()"
    ],
    [
        "profile = models.ForeignKey(Profile, models.SET_NULL, null=True, blank=True)",
        "profile = models.ForeignKey(Profile, models.SET_NULL, null=True,"
    ],
    [
        "msg = \"QuerySet.only() return bogus results with proxy models\"",
        "msg = \"QuerySet.only() return bogus results"
    ],
    [
        "msg = \"QuerySet.defer() return bogus results with proxy models\"",
        "msg = \"QuerySet.defer() return bogus"
    ],
    [
        "CharField passes its max_length attribute to form fields created using",
        "CharField passes its max_length attribute to form fields"
    ],
    [
        "msg = \"This field cannot be blank.\"",
        "msg = \"This field cannot"
    ],
    [
        "f = models.CharField(choices=[(\"a\", \"A\"), (\"b\", \"B\")])",
        "f = models.CharField(choices=[(\"a\", \"A\"), (\"b\","
    ],
    [
        "msg = \"Value 'not a' is not a valid choice.\"",
        "msg = \"Value 'not a' is not"
    ],
    [
        "msg = \"Value 'a' is not a valid choice.\"",
        "msg = \"Value 'a' is not a valid"
    ],
    [
        "msg = \"This field cannot be null.\"",
        "msg = \"This field"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "a = models.ForeignKey(Foo, models.CASCADE, default=get_foo, related_name=\"bars\")",
        "a = models.ForeignKey(Foo, models.CASCADE, default=get_foo,"
    ],
    [
        "Custom Field File class that records whether or not the underlying file",
        "Custom Field File class that records whether"
    ],
    [
        "Model that defines an ImageField with no dimension fields.",
        "Model that defines an ImageField"
    ],
    [
        "Abstract model that defines an ImageField with only one dimension field",
        "Abstract model that defines an ImageField with only one"
    ],
    [
        "to make sure the dimension update is correctly run on concrete subclass",
        "to make sure the dimension update"
    ],
    [
        "Concrete model that subclass an abstract one with only on dimension",
        "Concrete model that subclass an abstract"
    ],
    [
        "Model that defines height and width fields after the ImageField.",
        "Model that defines height and width fields after the"
    ],
    [
        "Model that defines height and width fields before the ImageField.",
        "Model that defines height and"
    ],
    [
        "* Defines the height/width fields before the ImageFields",
        "* Defines the height/width fields"
    ],
    [
        "Model that defines an ImageField with a storage backend that does not",
        "Model that defines an ImageField with a storage backend that"
    ],
    [
        "fk = models.ForeignKey(Foo, on_delete=models.CASCADE, null=True, blank=True)",
        "fk = models.ForeignKey(Foo, on_delete=models.CASCADE, null=True,"
    ],
    [
        "fk = models.ForeignKey(Foo, on_delete=models.CASCADE, null=True, blank=True)",
        "fk = models.ForeignKey(Foo, on_delete=models.CASCADE,"
    ],
    [
        "models.UniqueConstraint(F(\"a\"), name=\"Generated model unique constraint a\"),",
        "models.UniqueConstraint(F(\"a\"), name=\"Generated model unique"
    ],
    [
        "F(\"a\"), name=\"Generated model unique constraint virtual a\"",
        "F(\"a\"), name=\"Generated model unique constraint"
    ],
    [
        "self.assertTrue(all(f.concrete.__class__ == bool for f in self.fields))",
        "self.assertTrue(all(f.concrete.__class__ == bool for f in"
    ],
    [
        "self.assertTrue(all(f.editable.__class__ == bool for f in self.all_fields))",
        "self.assertTrue(all(f.editable.__class__ == bool for f in"
    ],
    [
        "self.assertTrue(all(f.is_relation.__class__ == bool for f in self.all_fields))",
        "self.assertTrue(all(f.is_relation.__class__ == bool for"
    ],
    [
        "\"Field %s does not have flag %s\" % (field, flag),",
        "\"Field %s does not have flag %s\" %"
    ],
    [
        "f for f in self.all_fields if f.is_relation and f.many_to_many",
        "f for f in self.all_fields if f.is_relation"
    ],
    [
        "\"Tried to update field model_fields.FloatModel.size with a model \"",
        "\"Tried to update field model_fields.FloatModel.size with a model"
    ],
    [
        "\"instance, %r. Use a value compatible with FloatField.\"",
        "\"instance, %r. Use a value"
    ],
    [
        "msg = \"Field 'size' expected a number but got %r.\" % (value,)",
        "msg = \"Field 'size' expected a number but got %r.\""
    ],
    [
        "from django.db import IntegrityError, connection, models",
        "from django.db import"
    ],
    [
        "Values within the documented safe range pass validation, and can be",
        "Values within the documented safe range pass"
    ],
    [
        "Backend specific ranges can be saved without corruption.",
        "Backend specific ranges can be saved without"
    ],
    [
        "Backend specific ranges are enforced at the model validation level",
        "Backend specific ranges are enforced at the model validation"
    ],
    [
        "raise SkipTest(\"Backend doesn't define an integer min value.\")",
        "raise SkipTest(\"Backend doesn't define"
    ],
    [
        "raise SkipTest(\"Backend doesn't define an integer max value.\")",
        "raise SkipTest(\"Backend doesn't define an integer"
    ],
    [
        "If there are stricter validators than the ones from the database",
        "If there are stricter validators than the ones from"
    ],
    [
        "backend then the backend validators aren't added.",
        "backend then the backend validators aren't"
    ],
    [
        "msg = \"Field 'value' expected a number but got %r.\" % (value,)",
        "msg = \"Field 'value' expected a number but"
    ],
    [
        "from .models import Bar, FkToChar, Foo, PrimaryKeyCharModel",
        "from .models import Bar,"
    ],
    [
        "\"\"\"A lazy callable may be used for ForeignKey.default.\"\"\"",
        "\"\"\"A lazy callable may be used for"
    ],
    [
        "\"Setting unique=True on a ForeignKey has the same effect as using a \"",
        "\"Setting unique=True on a ForeignKey has the same effect as using a"
    ],
    [
        "\"ForeignKey(unique=True) is usually better served by a \"",
        "\"ForeignKey(unique=True) is usually better served by"
    ],
    [
        "Foreign key fields declared on abstract models should not add lazy",
        "Foreign key fields declared on abstract models should not add"
    ],
    [
        "\"Pending lookup added for a foreign key on an abstract model\",",
        "\"Pending lookup added for a foreign key"
    ],
    [
        "\"'model_fields.Related.child' refers to field 'key' which is not \"",
        "\"'model_fields.Related.child' refers to field 'key'"
    ],
    [
        "\"either a model, a model name, or the string 'self'\"",
        "\"either a model, a model name, or the string"
    ],
    [
        "FileField.save_form_data() will clear its instance attribute value if",
        "FileField.save_form_data() will clear its instance"
    ],
    [
        "FileField.save_form_data() considers None to mean \"no change\" rather",
        "FileField.save_form_data() considers None to mean \"no change\""
    ],
    [
        "FileField.save_form_data(), if passed a truthy value, updates its",
        "FileField.save_form_data(), if passed a truthy value,"
    ],
    [
        "Calling delete on an unset FileField should not call the file deletion",
        "Calling delete on an unset FileField should not call the file"
    ],
    [
        "msg = f\"Detected path traversal attempt in '{tmp.name}'\"",
        "msg = f\"Detected path traversal attempt in"
    ],
    [
        "msg = \"File for myfile must have the name attribute specified to be saved.\"",
        "msg = \"File for myfile must have the name attribute specified to"
    ],
    [
        "cm.exception.__notes__, [\"Pass a 'name' argument to ContentFile.\"]",
        "cm.exception.__notes__, [\"Pass a 'name'"
    ],
    [
        "msg = \"The 'myfile' attribute has no file associated with it.\"",
        "msg = \"The 'myfile' attribute has no file associated"
    ],
    [
        "A FileField with unique=True shouldn't allow two instances with the",
        "A FileField with unique=True shouldn't allow two instances with"
    ],
    [
        "The temporary uploaded file is moved rather than copied to the",
        "The temporary uploaded file is moved rather"
    ],
    [
        "FieldField.open() returns self so it can be used as a context manager.",
        "FieldField.open() returns self so it can be used"
    ],
    [
        "FileField.model returns the concrete model for fields defined in an",
        "FileField.model returns the concrete model for"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings, skipUnlessDBFeature",
        "from django.test import SimpleTestCase,"
    ],
    [
        "TextField passes its max_length attribute to form fields created using",
        "TextField passes its max_length attribute to form fields"
    ],
    [
        "\"\"\"A TextField with choices uses a Select widget.\"\"\"",
        "\"\"\"A TextField with choices uses a Select"
    ],
    [
        "f = models.TextField(choices=[(\"A\", \"A\"), (\"B\", \"B\")])",
        "f = models.TextField(choices=[(\"A\", \"A\"),"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import SimpleTestCase,"
    ],
    [
        "from .models import CustomJSONDecoder, JSONModel, NullableJSONModel, RelatedJSONModel",
        "from .models import CustomJSONDecoder, JSONModel, NullableJSONModel,"
    ],
    [
        "msg = \"is not JSON serializable\"",
        "msg = \"is not"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "\"Transform should be an instance of KeyTransform in order to use \"",
        "\"Transform should be an instance of KeyTransform in"
    ],
    [
        "msg = \"The encoder parameter must be a callable object.\"",
        "msg = \"The encoder parameter must be a"
    ],
    [
        "msg = \"The decoder parameter must be a callable object.\"",
        "msg = \"The decoder parameter must be a"
    ],
    [
        "msg = \"Value must be valid JSON.\"",
        "msg = \"Value must be valid"
    ],
    [
        "'[{\"fields\": {\"value\": %s}, \"model\": \"model_fields.jsonmodel\", \"pk\": null}]'",
        "'[{\"fields\": {\"value\": %s}, \"model\": \"model_fields.jsonmodel\","
    ],
    [
        "({\"a\": \"b\", \"c\": None}, '{\"a\": \"b\", \"c\": null}'),",
        "({\"a\": \"b\", \"c\": None}, '{\"a\":"
    ],
    [
        "{\"k\": True, \"l\": False, \"foo\": \"bax\"},",
        "{\"k\": True, \"l\": False,"
    ],
    [
        "cls.objs = [NullableJSONModel.objects.create(value=value) for value in values]",
        "cls.objs = [NullableJSONModel.objects.create(value=value) for value in"
    ],
    [
        "cls.raw_sql = \"%s::jsonb\" if connection.vendor == \"postgresql\" else \"%s\"",
        "cls.raw_sql = \"%s::jsonb\" if connection.vendor == \"postgresql\" else"
    ],
    [
        "mariadb = connection.vendor == \"mysql\" and connection.mysql_is_mariadb",
        "mariadb = connection.vendor == \"mysql\" and"
    ],
    [
        "if mariadb or connection.vendor == \"oracle\":",
        "if mariadb or connection.vendor"
    ],
    [
        "none_val = \"\" if connection.features.interprets_empty_strings_as_nulls else None",
        "none_val = \"\" if connection.features.interprets_empty_strings_as_nulls else"
    ],
    [
        "expr = RawSQL(self.raw_sql, ['{\"x\": {\"y\": \"bar\"}}'])",
        "expr = RawSQL(self.raw_sql,"
    ],
    [
        "value={\"d\": [\"e\", {\"f\": \"g\"}, {\"f\": \"g\"}]},",
        "value={\"d\": [\"e\", {\"f\": \"g\"}, {\"f\":"
    ],
    [
        "msg = \"contains lookup is not supported on this database backend.\"",
        "msg = \"contains lookup is not supported on this database"
    ],
    [
        "msg = \"contained_by lookup is not supported on this database backend.\"",
        "msg = \"contained_by lookup is not supported on this database"
    ],
    [
        "json_value = {key: \"some value\" for key in test_keys}",
        "json_value = {key: \"some value\" for key"
    ],
    [
        "json_value = {key: \"some value\" for key in test_keys}",
        "json_value = {key: \"some value\" for"
    ],
    [
        "for lookup, value, expected in tests:",
        "for lookup, value, expected in"
    ],
    [
        "(\"value__baz__contained_by\", {\"a\": \"b\", \"c\": \"d\", \"e\": \"f\"}),",
        "(\"value__baz__contained_by\", {\"a\": \"b\", \"c\": \"d\", \"e\":"
    ],
    [
        "msg = \"Lookup must contain key or index transforms.\"",
        "msg = \"Lookup must contain key"
    ],
    [
        "from django.db import IntegrityError, models, transaction",
        "from django.db import IntegrityError, models,"
    ],
    [
        "from .models import BooleanModel, FksToBooleans, NullBooleanModel",
        "from .models import BooleanModel, FksToBooleans,"
    ],
    [
        "BooleanField with choices and defaults doesn't generate a formfield",
        "BooleanField with choices and defaults"
    ],
    [
        "BooleanField with choices and no default should generated a formfield",
        "BooleanField with choices and no default"
    ],
    [
        "Boolean fields retrieved via select_related() should return booleans.",
        "Boolean fields retrieved via select_related() should return"
    ],
    [
        "NullBooleanField shouldn't throw a validation error when given a value",
        "NullBooleanField shouldn't throw a validation error when given"
    ],
    [
        "raise AssertionError(\"This storage class does not support reading.\")",
        "raise AssertionError(\"This storage class does not support"
    ],
    [
        "from .models import AutoModel, BigAutoModel, SmallAutoModel",
        "from .models import AutoModel, BigAutoModel,"
    ],
    [
        "msg = \"“%s” value must be a decimal number.\"",
        "msg = \"“%s” value must be a"
    ],
    [
        "Ensure decimals don't go through a corrupting float conversion during",
        "Ensure decimals don't go through"
    ],
    [
        "msg = \"“nan” value must be a decimal number.\"",
        "msg = \"“nan” value must be a decimal"
    ],
    [
        "for value in [float(\"nan\"), math.nan, \"nan\"]:",
        "for value in [float(\"nan\"), math.nan,"
    ],
    [
        "msg = \"“inf” value must be a decimal number.\"",
        "msg = \"“inf” value must be"
    ],
    [
        "for value in [float(\"inf\"), math.inf, \"inf\"]:",
        "for value in"
    ],
    [
        "msg = \"“-inf” value must be a decimal number.\"",
        "msg = \"“-inf” value must be a decimal"
    ],
    [
        "for value in [float(\"-inf\"), -math.inf, \"-inf\"]:",
        "for value in"
    ],
    [
        "Really big values can be used in a filter statement.",
        "Really big values can be used in"
    ],
    [
        "\"\"\"Trailing zeros in the fractional part aren't truncated.\"\"\"",
        "\"\"\"Trailing zeros in the fractional part aren't"
    ],
    [
        "GenericIPAddressField with a specified protocol does not generate a",
        "GenericIPAddressField with a specified protocol does"
    ],
    [
        "Null values should be resolved to None.",
        "Null values should be"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase,"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"GeneratedField cannot be editable.\"):",
        "with self.assertRaisesMessage(ValueError, \"GeneratedField cannot be"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"GeneratedField must be blank.\"):",
        "with self.assertRaisesMessage(ValueError, \"GeneratedField must be"
    ],
    [
        "msg = \"GeneratedField cannot have a default.\"",
        "msg = \"GeneratedField cannot"
    ],
    [
        "msg = \"GeneratedField cannot have a database default.\"",
        "msg = \"GeneratedField cannot have a database"
    ],
    [
        "msg = \"GeneratedField.db_persist must be True or False.\"",
        "msg = \"GeneratedField.db_persist must be"
    ],
    [
        "_, path, args, kwargs = field.deconstruct()",
        "_, path, args, kwargs"
    ],
    [
        "msg = \"Cannot read a generated field from an unsaved model.\"",
        "msg = \"Cannot read a generated field from an"
    ],
    [
        "{\"__all__\": [f\"Constraint “{model_name} a” is violated.\"]},",
        "{\"__all__\": [f\"Constraint “{model_name} a”"
    ],
    [
        "\"\"\"Lookups from the output_field are available on GeneratedFields.\"\"\"",
        "\"\"\"Lookups from the output_field are"
    ],
    [
        "self.skipTest(\"Backend doesn't define an integer min value.\")",
        "self.skipTest(\"Backend doesn't define an"
    ],
    [
        "self.skipTest(\"Backend doesn't define an integer max value.\")",
        "self.skipTest(\"Backend doesn't define an"
    ],
    [
        "none_val = \"\" if connection.features.interprets_empty_strings_as_nulls else None",
        "none_val = \"\" if"
    ],
    [
        "Many-to-many fields declared on abstract models should not add lazy",
        "Many-to-many fields declared on abstract models should"
    ],
    [
        "\"Pending lookup added for a many-to-many field on an abstract model\",",
        "\"Pending lookup added for a many-to-many field on an abstract"
    ],
    [
        "\"ManyToManyField must be either a model, a model name, or the \"",
        "\"ManyToManyField must be either a model, a"
    ],
    [
        "msg = \"Cannot specify a db_table if an intermediary model is used.\"",
        "msg = \"Cannot specify a db_table if an intermediary"
    ],
    [
        "Fields with choices respect show_hidden_initial as a kwarg to",
        "Fields with choices respect show_hidden_initial as"
    ],
    [
        "__repr__() of a field displays its name.",
        "__repr__() of a field displays its"
    ],
    [
        "\"\"\"__repr__() uses __qualname__ for nested class support.\"\"\"",
        "\"\"\"__repr__() uses __qualname__ for"
    ],
    [
        "A defined field name (name=\"fieldname\") is used instead of the model",
        "A defined field name (name=\"fieldname\") is used instead"
    ],
    [
        "m._meta.get_field(\"field%d\" % i).verbose_name, \"verbose field%d\" % i",
        "m._meta.get_field(\"field%d\" % i).verbose_name, \"verbose"
    ],
    [
        "\"\"\"Can supply a custom choices form class to Field.formfield()\"\"\"",
        "\"\"\"Can supply a custom choices form"
    ],
    [
        "\"\"\"Field.formfield() sets disabled for fields with choices.\"\"\"",
        "\"\"\"Field.formfield() sets disabled for"
    ],
    [
        "\"\"\"Fields are ordered based on their creation.\"\"\"",
        "\"\"\"Fields are ordered based on"
    ],
    [
        "\"\"\"deconstruct() uses __qualname__ for nested class support.\"\"\"",
        "\"\"\"deconstruct() uses __qualname__ for nested"
    ],
    [
        "name, path, args, kwargs = Nested.Field().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "\"\"\"Field instances from abstract models are not equal.\"\"\"",
        "\"\"\"Field instances from abstract"
    ],
    [
        "get_choices() interacts with get_FIELD_display() to return the expected",
        "get_choices() interacts with get_FIELD_display() to return the"
    ],
    [
        "\"\"\"A translated display value is coerced to str.\"\"\"",
        "\"\"\"A translated display value"
    ],
    [
        "choices = [(\"\", \"<><>\"), (\"a\", \"A\")]",
        "choices = [(\"\","
    ],
    [
        "f = models.CharField(choices=[(lazy_func(\"group\"), [(\"a\", \"A\"), (\"b\", \"B\")])])",
        "f = models.CharField(choices=[(lazy_func(\"group\"), [(\"a\", \"A\"), (\"b\","
    ],
    [
        "self.assertEqual(choices, [(obj.pk, str(obj)) for obj in objs])",
        "self.assertEqual(choices, [(obj.pk, str(obj)) for obj in"
    ],
    [
        "self.assertCountEqual(choices, [(obj.pk, str(obj)) for obj in objs])",
        "self.assertCountEqual(choices, [(obj.pk, str(obj)) for obj"
    ],
    [
        "PersonWithHeight = PersonWithHeightAndWidth = PersonDimensionsFirst = Person",
        "PersonWithHeight = PersonWithHeightAndWidth = PersonDimensionsFirst ="
    ],
    [
        "Mixin class to provide common functionality to ImageField test classes.",
        "Mixin class to provide common functionality to ImageField test"
    ],
    [
        "Creates a pristine temp directory (or deletes and recreates if it",
        "Creates a pristine temp directory (or deletes and recreates"
    ],
    [
        "already exists) that the model uses as its storage directory.",
        "already exists) that the model uses as"
    ],
    [
        "Sets up two ImageFile instances for use in tests.",
        "Sets up two ImageFile instances"
    ],
    [
        "def check_dimensions(self, instance, width, height, field_name=\"mugshot\"):",
        "def check_dimensions(self, instance,"
    ],
    [
        "Asserts that the given width and height values match both the",
        "Asserts that the given width and"
    ],
    [
        "field's height and width attributes and the height and width fields",
        "field's height and width attributes and the height"
    ],
    [
        "(if defined) the image field is caching to.",
        "(if defined) the image field is"
    ],
    [
        "Note, this method will check for dimension fields named by adding",
        "Note, this method will check for dimension fields"
    ],
    [
        "\"_width\" or \"_height\" to the name of the ImageField.  So, the",
        "\"_width\" or \"_height\" to the name of"
    ],
    [
        "models used in these tests must have their fields named",
        "models used in these tests must have"
    ],
    [
        "By default, we check the field named \"mugshot\", but this can be",
        "By default, we check the field named"
    ],
    [
        "specified by passing the field_name parameter.",
        "specified by passing the"
    ],
    [
        "if width is None and height is None:",
        "if width is None and"
    ],
    [
        "@skipIf(Image is None, \"Pillow is required to test ImageField\")",
        "@skipIf(Image is None, \"Pillow is required to test"
    ],
    [
        "Tests for ImageField that don't need to be run with each of the",
        "Tests for ImageField that don't need to be"
    ],
    [
        "If the underlying file is unavailable, still create instantiate the",
        "If the underlying file is unavailable, still create instantiate"
    ],
    [
        "ImageField can be pickled, unpickled, and that the image of",
        "ImageField can be pickled, unpickled, and"
    ],
    [
        "the unpickled version is the same as the original.",
        "the unpickled version is the"
    ],
    [
        "@skipIf(Image is None, \"Pillow is required to test ImageField\")",
        "@skipIf(Image is None, \"Pillow is"
    ],
    [
        "Tests behavior of an ImageField and its dimensions fields.",
        "Tests behavior of an ImageField and"
    ],
    [
        "Tests assigning an image field through the model's constructor.",
        "Tests assigning an image field through"
    ],
    [
        "Tests behavior when image is not passed in constructor.",
        "Tests behavior when image is"
    ],
    [
        "Tests assigning an image in Manager.create().",
        "Tests assigning an"
    ],
    [
        "The default value for an ImageField is an instance of",
        "The default value for an ImageField is an"
    ],
    [
        "the field's attr_class (TestImageFieldFile in this case) with no",
        "the field's attr_class (TestImageFieldFile in this"
    ],
    [
        "Assigning ImageField to None clears dimensions.",
        "Assigning ImageField to"
    ],
    [
        "Tests assignment using the field's save method and deletion using",
        "Tests assignment using the field's"
    ],
    [
        "Dimensions are updated correctly in various situations.",
        "Dimensions are updated correctly in"
    ],
    [
        "@skipIf(Image is None, \"Pillow is required to test ImageField\")",
        "@skipIf(Image is None, \"Pillow is"
    ],
    [
        "Tests behavior of an ImageField with no dimension fields.",
        "Tests behavior of an ImageField with no"
    ],
    [
        "[sender_id for (_, sender_id), *_ in signals.post_init.receivers],",
        "[sender_id for (_, sender_id), *_ in"
    ],
    [
        "@skipIf(Image is None, \"Pillow is required to test ImageField\")",
        "@skipIf(Image is None, \"Pillow is required to"
    ],
    [
        "Tests behavior of an ImageField with one dimensions field.",
        "Tests behavior of an ImageField with"
    ],
    [
        "@skipIf(Image is None, \"Pillow is required to test ImageField\")",
        "@skipIf(Image is None, \"Pillow is"
    ],
    [
        "Tests behavior of an ImageField where the dimensions fields are",
        "Tests behavior of an ImageField where the dimensions fields"
    ],
    [
        "@skipIf(Image is None, \"Pillow is required to test ImageField\")",
        "@skipIf(Image is None, \"Pillow is"
    ],
    [
        "Tests behavior of an ImageField when assigning it a File instance",
        "Tests behavior of an ImageField when assigning it"
    ],
    [
        "@skipIf(Image is None, \"Pillow is required to test ImageField\")",
        "@skipIf(Image is None, \"Pillow is required to test"
    ],
    [
        "Tests a model with two ImageFields.",
        "Tests a model with two"
    ],
    [
        "Dimensions are updated correctly in various situations.",
        "Dimensions are updated correctly in"
    ],
    [
        "@skipIf(Image is None, \"Pillow is required to test ImageField\")",
        "@skipIf(Image is None, \"Pillow is required to test"
    ],
    [
        "from django.db import IntegrityError, connection, models",
        "from django.db import"
    ],
    [
        "from django.db.models import CharField, F, Value",
        "from django.db.models import CharField, F,"
    ],
    [
        "exceptions.ValidationError, \"is not a valid UUID\"",
        "exceptions.ValidationError, \"is not a valid"
    ],
    [
        "exceptions.ValidationError, \"is not a valid UUID\"",
        "exceptions.ValidationError, \"is not a valid"
    ],
    [
        "exceptions.ValidationError, \"is not a valid UUID\"",
        "exceptions.ValidationError, \"is not a valid"
    ],
    [
        "exceptions.ValidationError, \"is not a valid UUID\"",
        "exceptions.ValidationError, \"is not a"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "Backends with a native datatype for UUID don't support fragment lookups",
        "Backends with a native datatype for UUID don't support fragment"
    ],
    [
        "without hyphens because they store values with them.",
        "without hyphens because they store values"
    ],
    [
        "\"“not a datetime” value has an invalid format. \"",
        "\"“not a datetime” value has an invalid format."
    ],
    [
        "\"It must be in [DD] [[HH:]MM:]ss[.uuuuuu] format.\",",
        "\"It must be in [DD]"
    ],
    [
        "msg = \"Unable to write a payload after it's been read\"",
        "msg = \"Unable to write a payload"
    ],
    [
        "from django.http import HttpRequest, HttpResponse, StreamingHttpResponse",
        "from django.http import HttpRequest,"
    ],
    [
        "Content is removed from regular and streaming responses with a",
        "Content is removed from regular and"
    ],
    [
        "The test client is a class that can act like a simple",
        "The test client is a class that can act like a"
    ],
    [
        "It allows the user to compose GET and POST requests, and",
        "It allows the user to compose GET"
    ],
    [
        "obtain the response that the server gave to those requests.",
        "obtain the response that the server gave"
    ],
    [
        "The server Response objects are annotated with the details",
        "The server Response objects are annotated with"
    ],
    [
        "of the contexts and templates that were rendered during the",
        "of the contexts and templates that were rendered during"
    ],
    [
        "``Client`` objects are stateful - they will retain cookie (and",
        "``Client`` objects are stateful - they will retain"
    ],
    [
        "thus session) details for the lifetime of the ``Client`` instance.",
        "thus session) details for the lifetime of"
    ],
    [
        "This is not intended as a replacement for Twill, Selenium, or",
        "This is not intended as a"
    ],
    [
        "other browser automation frameworks - it is here to allow",
        "other browser automation frameworks -"
    ],
    [
        "testing against the contexts and templates produced by a view,",
        "testing against the contexts and templates produced by"
    ],
    [
        "rather than the HTML rendered to the end-user.",
        "rather than the HTML"
    ],
    [
        "from .views import TwoArgException, get_view, post_view, trace_view",
        "from .views import TwoArgException,"
    ],
    [
        "\"Cannot encode None for key 'value' in a query string. Did you \"",
        "\"Cannot encode None for key 'value' in a query string."
    ],
    [
        "\"mean to pass an empty string or omit the value?\"",
        "\"mean to pass an empty string or omit the"
    ],
    [
        "\"GET a view that normally expects POSTs\"",
        "\"GET a view that normally"
    ],
    [
        "\"POST an empty dictionary to a view\"",
        "\"POST an empty dictionary"
    ],
    [
        "\"POST some data to a view\"",
        "\"POST some data to"
    ],
    [
        "\"Cannot encode None for key 'value' as POST data. Did you mean \"",
        "\"Cannot encode None for key 'value' as"
    ],
    [
        "\"to pass an empty string or omit the value?\"",
        "\"to pass an empty string or"
    ],
    [
        "\"\"\"The test client serializes JSON data.\"\"\"",
        "\"\"\"The test client serializes"
    ],
    [
        "methods = (\"post\", \"put\", \"patch\", \"delete\")",
        "methods = (\"post\", \"put\", \"patch\","
    ],
    [
        "self.assertContains(response, \"Viewing %s page.\" % method_name)",
        "self.assertContains(response, \"Viewing %s page.\""
    ],
    [
        "\"\"\"The test Client accepts a json_encoder.\"\"\"",
        "\"\"\"The test Client accepts"
    ],
    [
        "\"Check the value of HTTP headers returned in a response\"",
        "\"Check the value of HTTP headers returned in"
    ],
    [
        "The returned response has a ``request`` attribute with the originating",
        "The returned response has a ``request`` attribute with"
    ],
    [
        "environ dict and a ``wsgi_request`` with the originating WSGIRequest.",
        "environ dict and a ``wsgi_request`` with the"
    ],
    [
        "The response contains a ResolverMatch instance.",
        "The response contains"
    ],
    [
        "The response ResolverMatch instance contains the correct",
        "The response ResolverMatch instance contains"
    ],
    [
        "The response ResolverMatch instance contains the correct",
        "The response ResolverMatch instance"
    ],
    [
        "information when accessing a regular view.",
        "information when accessing a"
    ],
    [
        "The response ResolverMatch instance can be used to access the CBV view",
        "The response ResolverMatch instance can be used"
    ],
    [
        "\"POST raw data (with a content type) to a view\"",
        "\"POST raw data (with a content"
    ],
    [
        "\"GET a URL that redirects elsewhere\"",
        "\"GET a URL that redirects"
    ],
    [
        "\"GET a URL that redirects with given GET parameters\"",
        "\"GET a URL that redirects with given GET"
    ],
    [
        "\"\"\"assertRedirects() ignores the order of query string parameters.\"\"\"",
        "\"\"\"assertRedirects() ignores the order of"
    ],
    [
        "response = self.client.get(\"/redirect_view/\", {\"var\": \"value\", \"foo\": \"bar\"})",
        "response = self.client.get(\"/redirect_view/\", {\"var\": \"value\", \"foo\":"
    ],
    [
        "\"GET a URL that redirects permanently elsewhere\"",
        "\"GET a URL that redirects permanently"
    ],
    [
        "\"GET a URL that does a non-permanent redirect\"",
        "\"GET a URL that"
    ],
    [
        "\"A URL that redirects can be followed to termination.\"",
        "\"A URL that redirects can be followed"
    ],
    [
        "\"A URL with a relative redirect can be followed.\"",
        "\"A URL with a relative redirect can"
    ],
    [
        "\"A URL with a relative redirect with no trailing slash can be followed.\"",
        "\"A URL with a relative redirect with no trailing"
    ],
    [
        "\"\"\"A URL that consists of a querystring only can be followed\"\"\"",
        "\"\"\"A URL that consists of a querystring"
    ],
    [
        "self.assertEqual(response.content, b\"The value of success is true.\")",
        "self.assertEqual(response.content, b\"The value of"
    ],
    [
        "methods = (\"get\", \"post\", \"head\", \"options\", \"put\", \"patch\", \"delete\", \"trace\")",
        "methods = (\"get\", \"post\", \"head\", \"options\","
    ],
    [
        "for method, code in itertools.product(methods, codes):",
        "for method, code"
    ],
    [
        "\"/redirect_view_%s/\" % code, data={\"value\": \"test\"}, follow=True",
        "\"/redirect_view_%s/\" % code, data={\"value\":"
    ],
    [
        "methods = (\"post\", \"options\", \"put\", \"patch\", \"delete\", \"trace\")",
        "methods = (\"post\", \"options\", \"put\", \"patch\","
    ],
    [
        "for method, code in itertools.product(methods, codes):",
        "for method, code"
    ],
    [
        "for method, code in itertools.product(methods, codes):",
        "for method, code in itertools.product(methods,"
    ],
    [
        "\"/redirect_view_%s/\" % code, data={\"value\": \"test\"}, follow=True",
        "\"/redirect_view_%s/\" % code,"
    ],
    [
        "\"\"\"GET a URL that redirects to an HTTP URI.\"\"\"",
        "\"\"\"GET a URL that redirects"
    ],
    [
        "\"\"\"GET a URL that redirects to an HTTPS URI.\"\"\"",
        "\"\"\"GET a URL that redirects to"
    ],
    [
        "\"POST valid data to a form\"",
        "\"POST valid data to"
    ],
    [
        "\"GET a form, providing hints in the GET data\"",
        "\"GET a form, providing hints in the"
    ],
    [
        "hints = {\"text\": \"Hello World\", \"multi\": (\"b\", \"c\", \"e\")}",
        "hints = {\"text\": \"Hello World\","
    ],
    [
        "\"POST incomplete data to a form\"",
        "\"POST incomplete data to"
    ],
    [
        "self.assertFormError(form, \"email\", \"This field is required.\")",
        "self.assertFormError(form, \"email\", \"This field is"
    ],
    [
        "self.assertFormError(form, \"single\", \"This field is required.\")",
        "self.assertFormError(form, \"single\", \"This field"
    ],
    [
        "self.assertFormError(form, \"multi\", \"This field is required.\")",
        "self.assertFormError(form, \"multi\", \"This field"
    ],
    [
        "\"POST erroneous data to a form\"",
        "\"POST erroneous data"
    ],
    [
        "response.context[\"form\"], \"email\", \"Enter a valid email address.\"",
        "response.context[\"form\"], \"email\", \"Enter a"
    ],
    [
        "\"POST valid data to a form using multiple templates\"",
        "\"POST valid data to a form using multiple"
    ],
    [
        "\"POST incomplete data to a form using multiple templates\"",
        "\"POST incomplete data to a form using multiple"
    ],
    [
        "self.assertFormError(form, \"email\", \"This field is required.\")",
        "self.assertFormError(form, \"email\", \"This field is"
    ],
    [
        "self.assertFormError(form, \"single\", \"This field is required.\")",
        "self.assertFormError(form, \"single\", \"This"
    ],
    [
        "self.assertFormError(form, \"multi\", \"This field is required.\")",
        "self.assertFormError(form, \"multi\", \"This field"
    ],
    [
        "\"POST erroneous data to a form using multiple templates\"",
        "\"POST erroneous data to a form"
    ],
    [
        "response.context[\"form\"], \"email\", \"Enter a valid email address.\"",
        "response.context[\"form\"], \"email\", \"Enter a"
    ],
    [
        "\"Make sure that URL ;-parameters are not stripped.\"",
        "\"Make sure that URL ;-parameters are not"
    ],
    [
        "\"Request a page that is protected with @login_required\"",
        "\"Request a page that is protected"
    ],
    [
        "\"Request a page that is protected with @login_required\"",
        "\"Request a page that is"
    ],
    [
        "\"Request a page that is protected with a @login_required method\"",
        "\"Request a page that is protected with a @login_required"
    ],
    [
        "\"Request a page that is protected with a @login_required method\"",
        "\"Request a page that is protected with"
    ],
    [
        "Request a page that is protected with",
        "Request a page that is"
    ],
    [
        "Request a page that is protected with",
        "Request a page that is protected"
    ],
    [
        "\"Request a page that is protected with @login, but use bad credentials\"",
        "\"Request a page that is protected with"
    ],
    [
        "An inactive user may login if the authenticate backend allows it.",
        "An inactive user may login if the authenticate backend allows"
    ],
    [
        "credentials = {\"username\": \"inactive\", \"password\": \"password\"}",
        "credentials = {\"username\": \"inactive\","
    ],
    [
        "\"Request a page that is protected with @login, but use an inactive login\"",
        "\"Request a page that is protected with @login,"
    ],
    [
        "\"Request a logout after logging in\"",
        "\"Request a logout after logging"
    ],
    [
        "\"Request a logout after logging in\"",
        "\"Request a logout"
    ],
    [
        "Request a page that is protected with @login_required when using",
        "Request a page that is protected with @login_required when"
    ],
    [
        "force_login() without passing a backend and with multiple backends",
        "force_login() without passing a backend"
    ],
    [
        "configured should automatically use the first backend.",
        "configured should automatically use"
    ],
    [
        "force_login() skips auth backends without a get_user() method.",
        "force_login() skips auth backends without a"
    ],
    [
        "\"Request a page that is protected with @permission_required\"",
        "\"Request a page that is protected with"
    ],
    [
        "Request a page that is protected with @permission_required but raises",
        "Request a page that is protected with @permission_required but"
    ],
    [
        "\"Request a page that is protected with a @permission_required method\"",
        "\"Request a page that is protected"
    ],
    [
        "a relevant ValueError rather than a non-descript AssertionError.",
        "a relevant ValueError rather than a non-descript"
    ],
    [
        "\"The test client is unable to fetch remote URLs (got \"",
        "\"The test client is unable to fetch remote URLs (got"
    ],
    [
        "\"https://www.djangoproject.com/). If the host is served by Django, \"",
        "\"https://www.djangoproject.com/). If the host is"
    ],
    [
        "\"Request a page that modifies the session\"",
        "\"Request a page that modifies the"
    ],
    [
        "\"Request a page that is known to throw an error\"",
        "\"Request a page that is"
    ],
    [
        "self.assertEqual(str(exc_value), \"'Oops! Looks like you wrote some bad code.'\")",
        "self.assertEqual(str(exc_value), \"'Oops! Looks like you wrote some"
    ],
    [
        "\"Mail is redirected to a dummy outbox during test setup\"",
        "\"Mail is redirected to a dummy"
    ],
    [
        "\"reverse_lazy() works in the test client\"",
        "\"reverse_lazy() works in"
    ],
    [
        "\"Mass mail is redirected to a dummy outbox during test setup\"",
        "\"Mass mail is redirected to a dummy outbox during"
    ],
    [
        "A nested test client request shouldn't clobber exception signals from",
        "A nested test client request shouldn't clobber"
    ],
    [
        "\"\"\"A request may raise an exception with more than one required arg.\"\"\"",
        "\"\"\"A request may raise an exception with more than one"
    ],
    [
        "msg = \"query_params and data arguments are mutually exclusive.\"",
        "msg = \"query_params and data"
    ],
    [
        "\"A client can be instantiated with CSRF checks enabled\"",
        "\"A client can be instantiated with CSRF checks"
    ],
    [
        "\"\"\"A test case can specify a custom class for self.client.\"\"\"",
        "\"\"\"A test case can specify a custom"
    ],
    [
        "The request factory returns a templated response for a GET request.",
        "The request factory returns a templated response for"
    ],
    [
        "\"\"\"The request factory returns an echo response for a TRACE request.\"\"\"",
        "\"\"\"The request factory returns an echo response for a TRACE"
    ],
    [
        "echoed_request_line = \"TRACE {} {}\".format(url_path, protocol)",
        "echoed_request_line = \"TRACE {}"
    ],
    [
        "response = await self.async_client.get(\"/get_view/\", {\"var\": \"val\"})",
        "response = await self.async_client.get(\"/get_view/\", {\"var\":"
    ],
    [
        "self.assertContains(response, \"This is a test. val is the value.\")",
        "self.assertContains(response, \"This is a test. val is the"
    ],
    [
        "msg = \"query_params and data arguments are mutually exclusive.\"",
        "msg = \"query_params and data arguments"
    ],
    [
        "from django.contrib.auth import views as auth_views",
        "from django.contrib.auth import views"
    ],
    [
        "\"A simple view that expects a GET request, and returns a rendered template\"",
        "\"A simple view that expects a GET request, and returns a rendered"
    ],
    [
        "t = Template(\"This is a test. {{ var }} is the value.\", name=\"GET Template\")",
        "t = Template(\"This is a test. {{ var }} is"
    ],
    [
        "A simple view that expects a TRACE request and echoes its status line.",
        "A simple view that expects a TRACE"
    ],
    [
        "return HttpResponseBadRequest(\"TRACE requests MUST NOT include an entity\")",
        "return HttpResponseBadRequest(\"TRACE requests MUST NOT include an"
    ],
    [
        "\"{{ method }} {{ uri }} {{ version }}\",",
        "\"{{ method }} {{ uri"
    ],
    [
        "t = Template(\"Data received: {{ data }} is the body.\", name=\"PUT Template\")",
        "t = Template(\"Data received: {{ data }} is the body.\", name=\"PUT"
    ],
    [
        "t = Template(\"Viewing GET page.\", name=\"Empty GET Template\")",
        "t = Template(\"Viewing GET page.\", name=\"Empty GET"
    ],
    [
        "\"\"\"A view that expects a POST, and returns a different template depending",
        "\"\"\"A view that expects a POST, and returns"
    ],
    [
        "on whether any POST data is available",
        "on whether any POST"
    ],
    [
        "\"Data received: {{ data }} is the value.\", name=\"POST Template\"",
        "\"Data received: {{ data }} is"
    ],
    [
        "t = Template(\"Viewing POST page.\", name=\"Empty POST Template\")",
        "t = Template(\"Viewing POST page.\", name=\"Empty"
    ],
    [
        "t = Template(\"Viewing GET page.\", name=\"Empty GET Template\")",
        "t = Template(\"Viewing GET page.\","
    ],
    [
        "A view that expects a POST request, returns a redirect response",
        "A view that expects a POST request, returns a"
    ],
    [
        "to itself providing only a ?success=true querystring,",
        "to itself providing only a ?success=true"
    ],
    [
        "the value of this querystring is then rendered upon GET.",
        "the value of this querystring is then"
    ],
    [
        "t = Template(\"The value of success is {{ value }}.\", name=\"GET Template\")",
        "t = Template(\"The value of success"
    ],
    [
        "A view that expects a request with the header 'application/json' and JSON",
        "A view that expects a request with the header"
    ],
    [
        "data, which is deserialized and included in the context.",
        "data, which is deserialized and"
    ],
    [
        "t = Template(\"Viewing {} page. With data {{ data }}.\".format(request.method))",
        "t = Template(\"Viewing {} page. With"
    ],
    [
        "\"A view that has a custom header\"",
        "\"A view that has a"
    ],
    [
        "\"\"\"A view which expects raw XML to be posted and returns content extracted",
        "\"\"\"A view which expects raw XML to be posted and returns content"
    ],
    [
        "title, author = [n.firstChild.nodeValue for n in first_book.childNodes]",
        "title, author = [n.firstChild.nodeValue"
    ],
    [
        "t = Template(\"{{ title }} - {{ author }}\", name=\"Book template\")",
        "t = Template(\"{{ title }} - {{ author }}\","
    ],
    [
        "c = Context({\"title\": title, \"author\": author})",
        "c = Context({\"title\":"
    ],
    [
        "t = Template(\"GET request.\", name=\"Book GET template\")",
        "t = Template(\"GET request.\", name=\"Book GET"
    ],
    [
        "\"A view that redirects all requests to the GET view\"",
        "\"A view that redirects all requests to the"
    ],
    [
        "query = \"?\" + urlencode(request.GET, True)",
        "query = \"?\""
    ],
    [
        "\"\"\"Redirect to /post_view/ using the status code.\"\"\"",
        "\"\"\"Redirect to /post_view/ using the status"
    ],
    [
        "\"A view that indicates if the request was secure\"",
        "\"A view that indicates if the"
    ],
    [
        "\"A view that redirects all requests to a redirection view\"",
        "\"A view that redirects all requests"
    ],
    [
        "return HttpResponseNotFound(\"Not found!. This page contains some MAGIC content\")",
        "return HttpResponseNotFound(\"Not found!. This page contains some"
    ],
    [
        "if cleaned_data.get(\"text\") == \"Raise non-field error\":",
        "if cleaned_data.get(\"text\") == \"Raise"
    ],
    [
        "\"A view that tests a simple form\"",
        "\"A view that tests"
    ],
    [
        "t = Template(\"Valid POST data.\", name=\"Valid POST Template\")",
        "t = Template(\"Valid POST data.\", name=\"Valid"
    ],
    [
        "\"Invalid POST data. {{ form.errors }}\", name=\"Invalid POST Template\"",
        "\"Invalid POST data. {{ form.errors }}\", name=\"Invalid"
    ],
    [
        "t = Template(\"Viewing base form. {{ form }}.\", name=\"Form GET Template\")",
        "t = Template(\"Viewing base form. {{ form }}.\", name=\"Form"
    ],
    [
        "\"A view that tests a simple form\"",
        "\"A view that tests a"
    ],
    [
        "message = \"POST data has errors\"",
        "message = \"POST"
    ],
    [
        "\"A simple view that is login protected.\"",
        "\"A simple view that is"
    ],
    [
        "\"This is a login protected test. Username is {{ user.username }}.\",",
        "\"This is a login protected test. Username is {{"
    ],
    [
        "\"A simple view that is login protected with a custom redirect field set\"",
        "\"A simple view that is login protected"
    ],
    [
        "\"This is a login protected test. Username is {{ user.username }}.\",",
        "\"This is a login protected test. Username is {{ user.username"
    ],
    [
        "\"A simple view that is permission protected.\"",
        "\"A simple view that"
    ],
    [
        "\"This is a permission protected test. \"",
        "\"This is a permission protected"
    ],
    [
        "\"Username is {{ user.username }}. \"",
        "\"Username is {{ user.username }}."
    ],
    [
        "\"This is a login protected test using a method. \"",
        "\"This is a login protected test using a"
    ],
    [
        "\"This is a permission protected test using a method. \"",
        "\"This is a permission protected test using a method."
    ],
    [
        "\"Username is {{ user.username }}. \"",
        "\"Username is {{ user.username }}."
    ],
    [
        "\"A view that modifies the session\"",
        "\"A view that modifies the"
    ],
    [
        "\"This is a view that modifies the session.\",",
        "\"This is a view that modifies the"
    ],
    [
        "\"\"\"A view which just raises an exception, simulating a broken view.\"\"\"",
        "\"\"\"A view which just raises an exception,"
    ],
    [
        "raise KeyError(\"Oops! Looks like you wrote some bad code.\")",
        "raise KeyError(\"Oops! Looks like you wrote some"
    ],
    [
        "\"This is the first test email\",",
        "\"This is the first test"
    ],
    [
        "\"This is the second test email\",",
        "\"This is the second"
    ],
    [
        "A view that uses a nested client to call another view and then raises an",
        "A view that uses a nested client to call"
    ],
    [
        "Use https://testserver, rather than an external domain, in order to allow",
        "Use https://testserver, rather than an external domain, in"
    ],
    [
        "\"\"\"Prints keys of request.FILES to the response.\"\"\"",
        "\"\"\"Prints keys of request.FILES to the"
    ],
    [
        "To define a one-to-one relationship, use ``OneToOneField()``.",
        "To define a one-to-one"
    ],
    [
        "In this example, a ``Place`` optionally can be a ``Restaurant``.",
        "In this example, a ``Place`` optionally can be"
    ],
    [
        "return \"%s the place\" % self.name",
        "return \"%s the"
    ],
    [
        "return \"%s the restaurant\" % self.place.name",
        "return \"%s the restaurant\""
    ],
    [
        "return \"%s the waiter at %s\" % (self.name, self.restaurant)",
        "return \"%s the waiter at %s\" % (self.name,"
    ],
    [
        "from django.db import IntegrityError, connection, transaction",
        "from django.db import"
    ],
    [
        "self.assertEqual(repr(r.place), \"<Place: Demon Dogs the place>\")",
        "self.assertEqual(repr(r.place), \"<Place: Demon Dogs"
    ],
    [
        "repr(Place.objects.get(**params)), \"<Place: Demon Dogs the place>\"",
        "repr(Place.objects.get(**params)), \"<Place: Demon Dogs the"
    ],
    [
        "repr(w), \"<Waiter: Joe the waiter at Demon Dogs the restaurant>\"",
        "repr(w), \"<Waiter: Joe the waiter at"
    ],
    [
        "\"save() prohibited to prevent data loss due to unsaved related object \"",
        "\"save() prohibited to prevent data loss due"
    ],
    [
        "'Cannot assign \"<Place: Demon Dogs the place>\": '",
        "'Cannot assign \"<Place: Demon Dogs the"
    ],
    [
        "'\"Place.restaurant\" must be a \"Restaurant\" instance.'",
        "'\"Place.restaurant\" must be"
    ],
    [
        "filtering reverse one-to-one relations with primary_key=True was",
        "filtering reverse one-to-one relations with"
    ],
    [
        "misbehaving. We test both (primary_key=True & False) cases here to",
        "misbehaving. We test both (primary_key=True & False)"
    ],
    [
        "prevent any reappearance of the problem.",
        "prevent any reappearance of the"
    ],
    [
        "DoesNotExist on a reverse one-to-one relation is cached.",
        "DoesNotExist on a reverse"
    ],
    [
        "p = Place(name=\"Zombie Cats\", address=\"Not sure\")",
        "p = Place(name=\"Zombie Cats\", address=\"Not"
    ],
    [
        "The target of a one-to-one relation is cached",
        "The target of a"
    ],
    [
        "when the origin is accessed through the reverse relation.",
        "when the origin is accessed through"
    ],
    [
        "The origin of a one-to-one relation is cached",
        "The origin of a one-to-one"
    ],
    [
        "when the target is accessed through the reverse relation.",
        "when the target is accessed through"
    ],
    [
        "The target of a one-to-one relation is always cached.",
        "The target of a one-to-one relation is always"
    ],
    [
        "p = Place(name=\"Zombie Cats\", address=\"Not sure\")",
        "p = Place(name=\"Zombie Cats\", address=\"Not"
    ],
    [
        "The target of a one-to-one relation is always cached.",
        "The target of a one-to-one relation"
    ],
    [
        "Accessing the reverse relation on an unsaved object",
        "Accessing the reverse relation"
    ],
    [
        "Writing to the reverse relation on an unsaved object",
        "Writing to the reverse relation on an"
    ],
    [
        "\"save() prohibited to prevent data loss due to unsaved related object \"",
        "\"save() prohibited to prevent data loss due to unsaved related"
    ],
    [
        "When a '+' ending related name is specified no reverse accessor should",
        "When a '+' ending related name is specified no reverse accessor"
    ],
    [
        "be added to the related model.",
        "be added to the"
    ],
    [
        "msg = \"The following fields do not exist in this model: restaurant\"",
        "msg = \"The following fields do not exist in this"
    ],
    [
        "msg = \"The following fields do not exist in this model: restaurant\"",
        "msg = \"The following fields do"
    ],
    [
        "msg = \"The following fields do not exist in this model: restaurant\"",
        "msg = \"The following fields do not"
    ],
    [
        "Model.save() invalidates stale OneToOneField relations after a primary",
        "Model.save() invalidates stale OneToOneField"
    ],
    [
        "msg = \"get_response must be provided.\"",
        "msg = \"get_response must be"
    ],
    [
        "The process_request() and process_response() hooks must be called with",
        "The process_request() and process_response() hooks"
    ],
    [
        "the sync_to_async thread_sensitive flag enabled, so that database",
        "the sync_to_async thread_sensitive flag enabled, so"
    ],
    [
        "operations use the correct thread and connection.",
        "operations use the correct thread and"
    ],
    [
        "Tests the `RenameMethodsBase` type introduced to rename `get_query_set`",
        "Tests the `RenameMethodsBase` type introduced to rename"
    ],
    [
        "Ensure a warning is raised upon class definition to suggest renaming",
        "Ensure a warning is raised upon class"
    ],
    [
        "msg = \"`Manager.old` method should be renamed `new`.\"",
        "msg = \"`Manager.old` method should be"
    ],
    [
        "Ensure `old` complains and not `new` when only `new` is defined.",
        "Ensure `old` complains and not `new` when only `new`"
    ],
    [
        "msg = \"`Manager.old` is deprecated, use `new` instead.\"",
        "msg = \"`Manager.old` is"
    ],
    [
        "Ensure `old` complains when only `old` is defined.",
        "Ensure `old` complains when only `old`"
    ],
    [
        "msg = \"`Manager.old` method should be renamed `new`.\"",
        "msg = \"`Manager.old` method should be renamed"
    ],
    [
        "msg = \"`Manager.old` is deprecated, use `new` instead.\"",
        "msg = \"`Manager.old` is"
    ],
    [
        "Ensure the correct warnings are raised when a class that didn't rename",
        "Ensure the correct warnings are raised when a class that didn't"
    ],
    [
        "msg = \"`Deprecated.old` method should be renamed `new`.\"",
        "msg = \"`Deprecated.old` method should be"
    ],
    [
        "msg = \"`Renamed.old` is deprecated, use `new` instead.\"",
        "msg = \"`Renamed.old` is"
    ],
    [
        "msg = \"`Deprecated.old` is deprecated, use `new` instead.\"",
        "msg = \"`Deprecated.old` is deprecated, use"
    ],
    [
        "Ensure the correct warnings are raised when a class that renamed",
        "Ensure the correct warnings are raised when"
    ],
    [
        "msg = \"`Deprecated.old` method should be renamed `new`.\"",
        "msg = \"`Deprecated.old` method should"
    ],
    [
        "msg = \"`Renamed.old` is deprecated, use `new` instead.\"",
        "msg = \"`Renamed.old` is deprecated, use `new`"
    ],
    [
        "Ensure the correct warnings are raised when a subclass inherit from a",
        "Ensure the correct warnings are raised when a"
    ],
    [
        "class that renamed `old` and mixins that may or may not have renamed",
        "class that renamed `old` and mixins that may"
    ],
    [
        "msg = \"`DeprecatedMixin.old` method should be renamed `new`.\"",
        "msg = \"`DeprecatedMixin.old` method"
    ],
    [
        "msg = \"`RenamedMixin.old` is deprecated, use `new` instead.\"",
        "msg = \"`RenamedMixin.old` is deprecated, use"
    ],
    [
        "msg = \"`DeprecatedMixin.old` is deprecated, use `new` instead.\"",
        "msg = \"`DeprecatedMixin.old` is deprecated, use"
    ],
    [
        "from django.template import Context, Template, defaultfilters",
        "from django.template import Context, Template,"
    ],
    [
        "from django.test import SimpleTestCase, modify_settings, override_settings",
        "from django.test import SimpleTestCase, modify_settings,"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "if tz is None or tz.utcoffset(now) is None:",
        "if tz is None or tz.utcoffset(now) is"
    ],
    [
        "for test_content, result in zip(test_list, result_list):",
        "for test_content, result"
    ],
    [
        "t = Template(\"{%% load humanize %%}{{ test_content|%s }}\" % method)",
        "t = Template(\"{%% load humanize %%}{{ test_content|%s }}\""
    ],
    [
        "msg=\"%s test failed, produced '%s', should've produced '%s'\"",
        "msg=\"%s test failed, produced"
    ],
    [
        "self.humanize_tester(test_list, result_list, \"ordinal\", lambda x: x)",
        "self.humanize_tester(test_list, result_list, \"ordinal\", lambda"
    ],
    [
        "\"the quick brown fox jumped over the lazy dog\",",
        "\"the quick brown fox jumped"
    ],
    [
        "\"the quick brown fox jumped over the lazy dog\",",
        "\"the quick brown fox jumped over the"
    ],
    [
        "\"the quick brown fox jumped over the lazy dog\",",
        "\"the quick brown fox jumped"
    ],
    [
        "\"the quick brown fox jumped over the lazy dog\",",
        "\"the quick brown fox jumped"
    ],
    [
        "test_list_negative = (\"-\" + test for test in test_list_positive)",
        "test_list_negative = (\"-\" + test for"
    ],
    [
        "result_list_negative = (\"-\" + result for result in result_list_positive)",
        "result_list_negative = (\"-\" + result for result in"
    ],
    [
        "test_list_negative = (\"-\" + test for test in test_list_positive)",
        "test_list_negative = (\"-\" + test for"
    ],
    [
        "result_list_negative = (\"-\" + result for result in result_list_positive)",
        "result_list_negative = (\"-\" + result"
    ],
    [
        "notdate = \"I'm not a date value\"",
        "notdate = \"I'm not a"
    ],
    [
        "test_list = (today, yesterday, tomorrow, someday, notdate, None)",
        "test_list = (today, yesterday, tomorrow,"
    ],
    [
        "date_one = datetime.datetime(today.year, today.month, today.day, tzinfo=tz_one)",
        "date_one = datetime.datetime(today.year,"
    ],
    [
        "date_two = datetime.datetime(today.year, today.month, today.day, tzinfo=tz_two)",
        "date_two = datetime.datetime(today.year,"
    ],
    [
        "time_format = \"%d %b %Y %H:%M:%S\"",
        "time_format = \"%d %b"
    ],
    [
        "if tz is None or tz.utcoffset(documented_now) is None:",
        "if tz is None or tz.utcoffset(documented_now) is"
    ],
    [
        "Translation of '%d day'/'%d month'/… may differ depending on the context",
        "Translation of '%d day'/'%d month'/… may differ depending on the"
    ],
    [
        "of the string it is inserted in.",
        "of the string it"
    ],
    [
        "from .models import Company, Employee, JSONFieldModel",
        "from .models import Company, Employee,"
    ],
    [
        "crafted_alias = \"\"\"injected_name\" from \"expressions_company\"; --\"\"\"",
        "crafted_alias = \"\"\"injected_name\""
    ],
    [
        "\"Column aliases cannot contain whitespace characters, quotation marks, \"",
        "\"Column aliases cannot contain whitespace characters, quotation"
    ],
    [
        "crafted_alias = \"\"\"injected_name\" from \"expressions_company\"; --\"\"\"",
        "crafted_alias = \"\"\"injected_name\" from \"expressions_company\";"
    ],
    [
        "\"Column aliases cannot contain whitespace characters, quotation marks, \"",
        "\"Column aliases cannot contain whitespace characters, quotation marks,"
    ],
    [
        "Tests for F() query expression syntax.",
        "Tests for F() query"
    ],
    [
        "return \"%s %s\" % (self.firstname, self.lastname)",
        "return \"%s %s\" %"
    ],
    [
        "return \"%i, %s, %s\" % (",
        "return \"%i, %s,"
    ],
    [
        "return \"Result at %s\" % self.result_time",
        "return \"Result at"
    ],
    [
        "start = models.ForeignKey(Time, models.CASCADE, null=True, related_name=\"+\")",
        "start = models.ForeignKey(Time,"
    ],
    [
        "end = models.ForeignKey(Time, models.CASCADE, null=True, related_name=\"+\")",
        "end = models.ForeignKey(Time, models.CASCADE,"
    ],
    [
        "return \"%s (%s to %s)\" % (self.midpoint, self.start, self.end)",
        "return \"%s (%s to %s)\" %"
    ],
    [
        "from django.db import DatabaseError, NotSupportedError, connection",
        "from django.db import DatabaseError, NotSupportedError,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import SimpleTestCase, TestCase,"
    ],
    [
        "(\"after_three\", [\"mple Inc.\", \"bar Ltd.\", \"t GmbH\"]),",
        "(\"after_three\", [\"mple Inc.\", \"bar Ltd.\", \"t"
    ],
    [
        "msg = \"Negative indexing is not supported.\"",
        "msg = \"Negative indexing"
    ],
    [
        "msg = \"Slice stop must be greater than slice start.\"",
        "msg = \"Slice stop must be greater than slice"
    ],
    [
        "msg = \"Argument to slice must be either int or slice instance.\"",
        "msg = \"Argument to slice must be"
    ],
    [
        "msg = \"Step argument is not supported.\"",
        "msg = \"Step argument"
    ],
    [
        "msg = \"This field does not support slicing.\"",
        "msg = \"This field does"
    ],
    [
        "[\"Joe Smith\", \"Frank Meyer\", \"Max Mustermann\"],",
        "[\"Joe Smith\", \"Frank Meyer\", \"Max"
    ],
    [
        "Number.objects.all(), [None, None], lambda n: n.float, ordered=False",
        "Number.objects.all(), [None, None], lambda"
    ],
    [
        "msg = \"Joined field references are not permitted in this query\"",
        "msg = \"Joined field references are"
    ],
    [
        "\"Aggregate functions are not allowed in this query \"",
        "\"Aggregate functions are not allowed in this query"
    ],
    [
        "msg = 'F(ceo)\": \"Company.point_of_contact\" must be a \"Employee\" instance.'",
        "msg = 'F(ceo)\": \"Company.point_of_contact\" must be a \"Employee\""
    ],
    [
        "msg = \"Joined field references are not permitted in this query\"",
        "msg = \"Joined field references are"
    ],
    [
        "msg = \"Joined field references are not permitted in this query\"",
        "msg = \"Joined field references are not permitted"
    ],
    [
        "'Failed to insert expression \"Col(expressions_company, '",
        "'Failed to insert expression \"Col(expressions_company,"
    ],
    [
        "\"expressions.Company.num_employees. F() expressions can only be \"",
        "\"expressions.Company.num_employees. F() expressions can only"
    ],
    [
        "\"used to update, not to insert.\"",
        "\"used to update, not to"
    ],
    [
        "'Failed to insert expression \"Lower(Col(expressions_company, '",
        "'Failed to insert"
    ],
    [
        "\"expressions can only be used to update, not to insert.\"",
        "\"expressions can only be used to update, not to"
    ],
    [
        "\"This queryset contains a reference to an outer query and may only \"",
        "\"This queryset contains a reference to an outer query"
    ],
    [
        "salary=RawSQL(\"SUM(num_chairs) OVER (ORDER BY num_employees)\", []),",
        "salary=RawSQL(\"SUM(num_chairs) OVER (ORDER BY"
    ],
    [
        "FieldError, \"Cannot resolve keyword 'nope' into field.\"",
        "FieldError, \"Cannot resolve keyword 'nope' into"
    ],
    [
        "FieldError, \"Cannot resolve keyword 'nope' into field.\"",
        "FieldError, \"Cannot resolve keyword 'nope'"
    ],
    [
        "\"This defensive test only works on databases that don't validate parameter \"",
        "\"This defensive test only works on databases that don't validate"
    ],
    [
        "This tests that SQL injection isn't possible using compilation of",
        "This tests that SQL injection isn't"
    ],
    [
        "expressions in iterable filters, as their compilation happens before",
        "expressions in iterable filters, as their"
    ],
    [
        "the main query compilation. It's limited to SQLite, as PostgreSQL,",
        "the main query compilation. It's"
    ],
    [
        "Oracle and other vendors have defense in depth against this by type",
        "Oracle and other vendors have defense in"
    ],
    [
        "checking. Testing against SQLite (the most permissive of the built-in",
        "checking. Testing against SQLite (the most"
    ],
    [
        "databases) demonstrates that the problem doesn't exist while keeping",
        "databases) demonstrates that the problem doesn't exist while"
    ],
    [
        "msg = \"argument of type 'F' is not iterable\"",
        "msg = \"argument of type 'F' is not"
    ],
    [
        "Special characters (e.g. %, _ and \\) stored in database are",
        "Special characters (e.g. %, _ and \\)"
    ],
    [
        "properly escaped when using a pattern lookup with an expression",
        "properly escaped when using a pattern lookup with an"
    ],
    [
        "Special characters (e.g. %, _ and \\) stored in database are",
        "Special characters (e.g. %, _ and \\) stored in"
    ],
    [
        "properly escaped when using a case insensitive pattern lookup with an",
        "properly escaped when using a case insensitive"
    ],
    [
        "\"Expressions with constraint_validation_compatible set to False must have \"",
        "\"Expressions with constraint_validation_compatible set to False must have"
    ],
    [
        "We can fill a value in all objects with an other value of the",
        "We can fill a value in all"
    ],
    [
        "We can increment a value of all objects in a query set.",
        "We can increment a value of"
    ],
    [
        "We can filter for objects, where a value is not equals the value",
        "We can filter for objects, where a value is not equals"
    ],
    [
        "Complex expressions of different connection types are possible.",
        "Complex expressions of different connection types are"
    ],
    [
        "connection.vendor == \"oracle\", \"Oracle doesn't support bitwise XOR.\"",
        "connection.vendor == \"oracle\", \"Oracle doesn't"
    ],
    [
        "msg = \"Bitwise XOR is not supported in Oracle.\"",
        "msg = \"Bitwise XOR is not supported in"
    ],
    [
        "cls.expnames = [e.name for e in Experiment.objects.all()]",
        "cls.expnames = [e.name for e"
    ],
    [
        "e.name for e in Experiment.objects.filter(end__lt=F(\"start\") + delta)",
        "e.name for e in Experiment.objects.filter(end__lt=F(\"start\")"
    ],
    [
        "e.name for e in Experiment.objects.filter(end__lt=delta + F(\"start\"))",
        "e.name for e in Experiment.objects.filter(end__lt=delta"
    ],
    [
        "e.name for e in Experiment.objects.filter(end__lte=F(\"start\") + delta)",
        "e.name for e in"
    ],
    [
        "e.name for e in Experiment.objects.filter(start__gt=F(\"end\") - delta)",
        "e.name for e in Experiment.objects.filter(start__gt=F(\"end\")"
    ],
    [
        "e.name for e in Experiment.objects.filter(start__gte=F(\"end\") - delta)",
        "e.name for e in"
    ],
    [
        "e.name for e in Experiment.objects.exclude(end__lt=F(\"start\") + delta)",
        "e.name for e in Experiment.objects.exclude(end__lt=F(\"start\") +"
    ],
    [
        "e.name for e in Experiment.objects.exclude(end__lte=F(\"start\") + delta)",
        "e.name for e in"
    ],
    [
        "for e in Experiment.objects.filter(completed__lt=F(\"assigned\") + days)",
        "for e in"
    ],
    [
        "for e in Experiment.objects.filter(completed__lte=F(\"assigned\") + days)",
        "for e in Experiment.objects.filter(completed__lte=F(\"assigned\")"
    ],
    [
        "if e.end == e.start + e.estimated_time",
        "if e.end == e.start"
    ],
    [
        "[e.start + e.estimated_time for e in test_set],",
        "[e.start + e.estimated_time for e"
    ],
    [
        "[e.end - e.start for e in test_set],",
        "[e.end - e.start for e in"
    ],
    [
        "for e in Experiment.objects.filter(assigned__gt=F(\"start\") - delay)",
        "for e in Experiment.objects.filter(assigned__gt=F(\"start\")"
    ],
    [
        "for e in Experiment.objects.filter(assigned__gte=F(\"start\") - delay)",
        "for e in Experiment.objects.filter(assigned__gte=F(\"start\") -"
    ],
    [
        "for e in Experiment.objects.filter(start__lt=F(\"assigned\") + delay)",
        "for e in Experiment.objects.filter(start__lt=F(\"assigned\") +"
    ],
    [
        "expected_durations = [e.duration() for e in exps]",
        "expected_durations = [e.duration() for"
    ],
    [
        "expected_starts = [e.start + delta for e in exps]",
        "expected_starts = [e.start + delta"
    ],
    [
        "expected_ends = [e.end + delta for e in exps]",
        "expected_ends = [e.end + delta for e in"
    ],
    [
        "Experiment.objects.update(start=F(\"start\") + delta, end=F(\"end\") + delta)",
        "Experiment.objects.update(start=F(\"start\") + delta, end=F(\"end\") +"
    ],
    [
        "new_starts = [e.start for e in exps]",
        "new_starts = [e.start for"
    ],
    [
        "new_ends = [e.end for e in exps]",
        "new_ends = [e.end for e in"
    ],
    [
        "new_durations = [e.duration() for e in exps]",
        "new_durations = [e.duration() for e"
    ],
    [
        "for e in Experiment.objects.filter(start=F(\"start\") + F(\"estimated_time\"))",
        "for e in"
    ],
    [
        "for e in Experiment.objects.filter(end__lt=F(\"start\") + F(\"estimated_time\"))",
        "for e in Experiment.objects.filter(end__lt=F(\"start\")"
    ],
    [
        "for e in Experiment.objects.filter(estimated_time__gt=F(\"end\") - F(\"start\"))",
        "for e in Experiment.objects.filter(estimated_time__gt=F(\"end\") -"
    ],
    [
        "for e in Experiment.objects.filter(estimated_time__lt=F(\"end\") - F(\"start\"))",
        "for e in Experiment.objects.filter(estimated_time__lt=F(\"end\") -"
    ],
    [
        "msg = \"Cannot resolve expression type, unknown output_field\"",
        "msg = \"Cannot resolve expression"
    ],
    [
        "The output field for a given Value doesn't get cleaned & validated,",
        "The output field for a given Value doesn't get cleaned"
    ],
    [
        "however validators may still be instantiated for a given field type",
        "however validators may still be instantiated for a given"
    ],
    [
        "and this demonstrates that they don't throw an exception.",
        "and this demonstrates that they don't throw an"
    ],
    [
        "repr(F(\"cost\") + F(\"tax\")), \"<CombinedExpression: F(cost) + F(tax)>\"",
        "repr(F(\"cost\") + F(\"tax\")), \"<CombinedExpression:"
    ],
    [
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise logical operations.\"",
        "\"Use .bitand(), .bitor(), and .bitxor()"
    ],
    [
        "for lhs, rhs, combined in tests:",
        "for lhs, rhs, combined"
    ],
    [
        "for lhs, connector, rhs in tests:",
        "for lhs, connector,"
    ],
    [
        "f\"Cannot infer type of {connector!r} expression involving these types: \"",
        "f\"Cannot infer type of {connector!r} expression involving"
    ],
    [
        "for lhs, rhs, expected_output_field in test_values:",
        "for lhs, rhs,"
    ],
    [
        "for lhs, connector, rhs, combined in tests:",
        "for lhs, connector, rhs, combined"
    ],
    [
        "f\"Cannot infer type of {connector!r} expression involving these types: \"",
        "f\"Cannot infer type of {connector!r} expression involving these"
    ],
    [
        "\"Cannot infer type of '+' expression involving these types: CharField, \"",
        "\"Cannot infer type of '+' expression involving these types:"
    ],
    [
        "[(\"Example Inc.\", False), (\"Foobar Ltd.\", True)],",
        "[(\"Example Inc.\", False), (\"Foobar"
    ],
    [
        "msg = \"nulls_first and nulls_last values must be True or None.\"",
        "msg = \"nulls_first and nulls_last values must"
    ],
    [
        "for permanent, preserve_request, expected_status_code in tests:",
        "for permanent, preserve_request, expected_status_code in"
    ],
    [
        "\"A minimal generic sitemap can be rendered\"",
        "\"A minimal generic sitemap can"
    ],
    [
        "expected += \"<url><loc>%s/testmodel/%s/</loc></url>\" % (self.base_url, pk)",
        "expected += \"<url><loc>%s/testmodel/%s/</loc></url>\" % (self.base_url,"
    ],
    [
        "\"To use sitemaps, either enable the sites framework or pass a \"",
        "\"To use sitemaps, either enable the sites"
    ],
    [
        "\"A simple sitemap index can be rendered\"",
        "\"A simple sitemap index can"
    ],
    [
        "\"\"\"A sitemap may not be callable.\"\"\"",
        "\"\"\"A sitemap may not"
    ],
    [
        "\"\"\"A sitemap may have multiple pages.\"\"\"",
        "\"\"\"A sitemap may have multiple"
    ],
    [
        "\"A simple sitemap index can be rendered with a custom template\"",
        "\"A simple sitemap index can be rendered"
    ],
    [
        "<!-- This is a customised template -->",
        "<!-- This is a customised"
    ],
    [
        "\"A simple sitemap section can be rendered\"",
        "\"A simple sitemap section can"
    ],
    [
        "\"A simple sitemap can be rendered\"",
        "\"A simple sitemap can be"
    ],
    [
        "\"A simple sitemap can be rendered with a custom template\"",
        "\"A simple sitemap can be"
    ],
    [
        "<!-- This is a customised template -->",
        "<!-- This is a customised template"
    ],
    [
        "The Last-Modified header should be support dates (without time).",
        "The Last-Modified header should be support dates (without"
    ],
    [
        "The Last-Modified header should be converted from timezone aware dates",
        "The Last-Modified header should be"
    ],
    [
        "\"Last-Modified header is missing when sitemap has no lastmod\"",
        "\"Last-Modified header is missing when sitemap"
    ],
    [
        "\"Last-Modified header is omitted when lastmod not on all items\"",
        "\"Last-Modified header is omitted when lastmod not on all"
    ],
    [
        "The Last-Modified header is omitted when lastmod isn't found in all",
        "The Last-Modified header is omitted when"
    ],
    [
        "sitemaps. Test sitemaps are sorted by lastmod in ascending order.",
        "sitemaps. Test sitemaps are sorted by lastmod in ascending"
    ],
    [
        "The Last-Modified header is omitted when lastmod isn't found in all",
        "The Last-Modified header is omitted when lastmod"
    ],
    [
        "sitemaps. Test sitemaps are sorted by lastmod in descending order.",
        "sitemaps. Test sitemaps are sorted"
    ],
    [
        "The Last-Modified header is set to the most recent sitemap lastmod.",
        "The Last-Modified header is set to the most"
    ],
    [
        "Test sitemaps are sorted by lastmod in ascending order.",
        "Test sitemaps are sorted by"
    ],
    [
        "The Last-Modified header is set to the most recent sitemap lastmod.",
        "The Last-Modified header is set to the most"
    ],
    [
        "Test sitemaps are sorted by lastmod in descending order.",
        "Test sitemaps are sorted by lastmod in"
    ],
    [
        "sitemapindex.lastmod is omitted when Sitemap.lastmod is",
        "sitemapindex.lastmod is omitted when Sitemap.lastmod"
    ],
    [
        "callable and Sitemap.get_latest_lastmod is not implemented",
        "callable and Sitemap.get_latest_lastmod"
    ],
    [
        "sitemapindex.lastmod is included when Sitemap.lastmod is",
        "sitemapindex.lastmod is included when"
    ],
    [
        "lastmod datestamp shows timezones if Sitemap.get_latest_lastmod",
        "lastmod datestamp shows"
    ],
    [
        "\"\"\"The priority value should not be localized.\"\"\"",
        "\"\"\"The priority value should"
    ],
    [
        "Check we get ImproperlyConfigured if we don't pass a site object to",
        "Check we get ImproperlyConfigured if we don't pass a"
    ],
    [
        "Sitemap.get_urls and no Site objects exist",
        "Sitemap.get_urls and no"
    ],
    [
        "Check we get ImproperlyConfigured when we don't pass a site object to",
        "Check we get ImproperlyConfigured when we don't"
    ],
    [
        "Sitemap.get_urls if Site objects exists, but the sites framework is not",
        "Sitemap.get_urls if Site objects exists, but the sites"
    ],
    [
        "Check to make sure that the raw item is included with each",
        "Check to make sure that the raw item is included"
    ],
    [
        "LANGUAGES=((\"en\", \"English\"), (\"pt\", \"Portuguese\"), (\"es\", \"Spanish\"))",
        "LANGUAGES=((\"en\", \"English\"), (\"pt\", \"Portuguese\"),"
    ],
    [
        "Not all items have `lastmod`. Therefore the `Last-Modified` header",
        "Not all items have `lastmod`."
    ],
    [
        "is not set by the detail or index sitemap view.",
        "is not set by the detail or"
    ],
    [
        "All items in the sitemap have `lastmod`. The `Last-Modified` header",
        "All items in the sitemap have `lastmod`."
    ],
    [
        "is set for the detail and index sitemap view.",
        "is set for the detail and index sitemap"
    ],
    [
        "\"A secure sitemap index can be rendered\"",
        "\"A secure sitemap index"
    ],
    [
        "\"A secure sitemap section can be rendered\"",
        "\"A secure sitemap section can"
    ],
    [
        "\"A sitemap index requested in HTTPS is rendered with HTTPS links\"",
        "\"A sitemap index requested in HTTPS is"
    ],
    [
        "\"A sitemap section requested in HTTPS is rendered with HTTPS links\"",
        "\"A sitemap section requested in HTTPS is rendered with HTTPS"
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import TestCase, modify_settings,"
    ],
    [
        "domain = \"example.com\" if sites_installed else \"testserver\"",
        "domain = \"example.com\" if"
    ],
    [
        "self.base_url = \"%s://%s\" % (self.protocol, self.domain)",
        "self.base_url = \"%s://%s\" % (self.protocol,"
    ],
    [
        "from django.contrib.sitemaps import GenericSitemap, Sitemap, views",
        "from django.contrib.sitemaps import"
    ],
    [
        "if item.name == \"Only for PT\":",
        "if item.name == \"Only"
    ],
    [
        "if item.name == \"Only for PT\":",
        "if item.name == \"Only for"
    ],
    [
        "from django.http import HttpRequest, HttpResponse, UnreadablePostError",
        "from django.http import HttpRequest, HttpResponse,"
    ],
    [
        "\"\"\"Test that a string is a valid masked version of a secret.\"\"\"",
        "\"\"\"Test that a string is a valid masked version"
    ],
    [
        "for (token, secret), expected in cases:",
        "for (token, secret),"
    ],
    [
        "A version of SessionStore that stores what cookie values are passed to",
        "A version of SessionStore that stores what cookie values are passed"
    ],
    [
        "A version of HttpRequest that lets one track and change some things more",
        "A version of HttpRequest that lets one track and change some things"
    ],
    [
        "TestingHttpRequest that can raise errors when accessing POST data.",
        "TestingHttpRequest that can raise errors when accessing"
    ],
    [
        "Shared methods and tests for session-based and cookie-based tokens.",
        "Shared methods and tests for session-based"
    ],
    [
        "raise NotImplementedError(\"This method must be implemented by a subclass.\")",
        "raise NotImplementedError(\"This method must be"
    ],
    [
        "Return the CSRF cookie as a string, or False if no cookie is present.",
        "Return the CSRF cookie as a string, or False if no cookie"
    ],
    [
        "raise NotImplementedError(\"This method must be implemented by a subclass.\")",
        "raise NotImplementedError(\"This method must be implemented by a"
    ],
    [
        "Return a list of the cookie values passed to set_cookie() over the",
        "Return a list of the cookie values passed to set_cookie()"
    ],
    [
        "raise NotImplementedError(\"This method must be implemented by a subclass.\")",
        "raise NotImplementedError(\"This method must be implemented by"
    ],
    [
        "The method argument defaults to \"GET\". The cookie argument defaults to",
        "The method argument defaults to \"GET\". The cookie argument"
    ],
    [
        "this class's default test cookie. The post_token and meta_token",
        "this class's default test cookie."
    ],
    [
        "arguments are included in the request's req.POST and req.META headers,",
        "arguments are included in the request's"
    ],
    [
        "respectively, when that argument is provided and non-None. The",
        "respectively, when that argument is provided and non-None."
    ],
    [
        "token_header argument is the header key to use for req.META, defaults",
        "token_header argument is the header key to use for"
    ],
    [
        "\"\"\"The cookie argument defaults to this class's default test cookie.\"\"\"",
        "\"\"\"The cookie argument defaults to this"
    ],
    [
        "f\"Could not find a csrfmiddlewaretoken value in: {text}\",",
        "f\"Could not find a csrfmiddlewaretoken value in:"
    ],
    [
        "If get_token() is not called, the view middleware does not",
        "If get_token() is not called, the view middleware does"
    ],
    [
        "\"\"\"Passing None for cookie includes no cookie.\"\"\"",
        "\"\"\"Passing None for cookie includes no"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view,"
    ],
    [
        "If no CSRF cookies is present, the middleware rejects the incoming",
        "If no CSRF cookies is present, the"
    ],
    [
        "request. This will stop login CSRF.",
        "request. This will stop"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view,"
    ],
    [
        "If a CSRF cookie is present but the token is missing or invalid, the",
        "If a CSRF cookie is present but the token"
    ],
    [
        "\"CSRF token from the 'X-Csrftoken' HTTP header has incorrect length.\",",
        "\"CSRF token from the 'X-Csrftoken' HTTP header"
    ],
    [
        "\"CSRF token from the 'X-Csrftoken' HTTP header has invalid characters.\",",
        "\"CSRF token from the 'X-Csrftoken' HTTP header has"
    ],
    [
        "\"CSRF token from the 'X-Csrftoken' HTTP header incorrect.\",",
        "\"CSRF token from the 'X-Csrftoken' HTTP"
    ],
    [
        "for post_token, meta_token, expected in cases:",
        "for post_token, meta_token,"
    ],
    [
        "If a CSRF cookie is present and an invalid token is passed via a",
        "If a CSRF cookie is present and an invalid token"
    ],
    [
        "custom CSRF_HEADER_NAME, the middleware rejects the incoming request.",
        "custom CSRF_HEADER_NAME, the middleware rejects"
    ],
    [
        "\"CSRF token from the 'X-Csrftoken-Customized' HTTP header has \"",
        "\"CSRF token from the 'X-Csrftoken-Customized' HTTP header"
    ],
    [
        "If both a cookie and a token is present, the middleware lets it through.",
        "If both a cookie and a token is"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view, (),"
    ],
    [
        "If a CSRF cookie is present and no token, but the csrf_exempt decorator",
        "If a CSRF cookie is present and no"
    ],
    [
        "has been applied to the view, the middleware lets it through",
        "has been applied to the view, the"
    ],
    [
        "resp = mw.process_view(req, csrf_exempt(post_form_view), (), {})",
        "resp = mw.process_view(req, csrf_exempt(post_form_view),"
    ],
    [
        "The token may be passed in a header instead of in the form.",
        "The token may be passed in a header instead of"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view, (),"
    ],
    [
        "settings.CSRF_HEADER_NAME can be used to customize the CSRF header name",
        "settings.CSRF_HEADER_NAME can be used to customize the"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view,"
    ],
    [
        "HTTP PUT and DELETE methods have protection",
        "HTTP PUT and DELETE methods have"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view,"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view, (),"
    ],
    [
        "HTTP PUT and DELETE can get through with X-CSRFToken and a cookie.",
        "HTTP PUT and DELETE can get through with X-CSRFToken and a"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req,"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req,"
    ],
    [
        "If rotate_token() is called after the token is reset in",
        "If rotate_token() is called after"
    ],
    [
        "CsrfViewMiddleware's process_response() and before another call to",
        "CsrfViewMiddleware's process_response() and before"
    ],
    [
        "the same process_response(), the cookie is reset a second time.",
        "the same process_response(), the cookie is reset a second"
    ],
    [
        "CsrfTokenNode works when no CSRF cookie is set.",
        "CsrfTokenNode works when no CSRF"
    ],
    [
        "A new token is sent if the csrf_cookie is the empty string.",
        "A new token is sent if"
    ],
    [
        "CsrfTokenNode works when a CSRF cookie is set.",
        "CsrfTokenNode works when a CSRF cookie is"
    ],
    [
        "get_token still works for a view decorated with 'csrf_exempt'.",
        "get_token still works for a view"
    ],
    [
        "get_token() works for a view decorated solely with requires_csrf_token.",
        "get_token() works for a view"
    ],
    [
        "CsrfTokenNode works when a CSRF cookie is created by",
        "CsrfTokenNode works when a CSRF cookie is created"
    ],
    [
        "the middleware (when one was not already present)",
        "the middleware (when one was"
    ],
    [
        "The csrf token used in posts is changed on every request (although",
        "The csrf token used in posts is"
    ],
    [
        "stays equivalent). The csrf cookie should not change on accepted",
        "stays equivalent). The csrf cookie"
    ],
    [
        "requests. If it appears in the response, it should keep its value.",
        "requests. If it appears in the response,"
    ],
    [
        "\"CSRF cookie was changed on an accepted request\",",
        "\"CSRF cookie was changed on"
    ],
    [
        "A POST HTTPS request with a bad referer is rejected",
        "A POST HTTPS request with a"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view, (),"
    ],
    [
        "\"Referer checking failed - https://www.evil.org/somepage does not \"",
        "\"Referer checking failed - https://www.evil.org/somepage does"
    ],
    [
        "\"\"\"A POST HTTPS request with a missing referer is rejected.\"\"\"",
        "\"\"\"A POST HTTPS request with a"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "\"Referer checking failed - no Referer.\",",
        "\"Referer checking failed"
    ],
    [
        "\"Referer checking failed - https://www.evil.org/somepage does not \"",
        "\"Referer checking failed -"
    ],
    [
        "response = mw.process_view(req, token_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "response = mw.process_view(req, token_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "A POST HTTPS request with a bad referer is rejected.",
        "A POST HTTPS request with a bad referer is"
    ],
    [
        "malformed_referer_msg = \"Referer checking failed - Referer is malformed.\"",
        "malformed_referer_msg = \"Referer checking failed - Referer"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "\"Referer checking failed - Referer is insecure while host is secure.\",",
        "\"Referer checking failed - Referer is"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view,"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view,"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view, (),"
    ],
    [
        "A POST HTTPS request with a good referer is accepted.",
        "A POST HTTPS request with a good referer"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req,"
    ],
    [
        "A POST HTTPS request with a good referer is accepted where the referer",
        "A POST HTTPS request with a good referer is accepted"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req,"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view, (),"
    ],
    [
        "A POST HTTPS request is accepted if it receives a good referer with",
        "A POST HTTPS request is accepted if it receives a good"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view,"
    ],
    [
        "A POST HTTPS request with a referer added to the CSRF_TRUSTED_ORIGINS",
        "A POST HTTPS request with a referer added to the"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view,"
    ],
    [
        "A POST HTTPS request with a referer that matches a CSRF_TRUSTED_ORIGINS",
        "A POST HTTPS request with a referer"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view,"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view, (),"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "An UnreadablePostError raised while reading the POST data should be",
        "An UnreadablePostError raised while reading"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view, (),"
    ],
    [
        "req.post_error = UnreadablePostError(\"Error reading input data.\")",
        "req.post_error = UnreadablePostError(\"Error"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req, post_form_view,"
    ],
    [
        "An OSError raised while reading the POST data should not be handled by",
        "An OSError raised while reading the POST data should"
    ],
    [
        "\"\"\"A request with a bad origin is rejected.\"\"\"",
        "\"\"\"A request with a bad origin"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view, (),"
    ],
    [
        "\"\"\"A request with a null origin is rejected.\"\"\"",
        "\"\"\"A request with a"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view,"
    ],
    [
        "\"\"\"A request with an origin with wrong protocol is rejected.\"\"\"",
        "\"\"\"A request with an origin with wrong protocol"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view,"
    ],
    [
        "A request with an origin with the wrong protocol compared to",
        "A request with an origin with the"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "A POST request with an origin that can't be parsed by urlsplit() is",
        "A POST request with an origin that can't"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view,"
    ],
    [
        "\"\"\"A POST HTTP request with a good origin is accepted.\"\"\"",
        "\"\"\"A POST HTTP request with"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view, (),"
    ],
    [
        "\"\"\"A POST HTTPS request with a good origin is accepted.\"\"\"",
        "\"\"\"A POST HTTPS request with a good origin"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view, (),"
    ],
    [
        "A POST request with an origin added to the CSRF_TRUSTED_ORIGINS",
        "A POST request with an origin"
    ],
    [
        "resp = mw.process_view(req, post_form_view, (), {})",
        "resp = mw.process_view(req,"
    ],
    [
        "A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS",
        "A POST request with an origin that matches a"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view,"
    ],
    [
        "Return the CSRF cookie as a string, or False if no cookie is present.",
        "Return the CSRF cookie as a string, or"
    ],
    [
        "The ensure_csrf_cookie() decorator works without middleware.",
        "The ensure_csrf_cookie() decorator"
    ],
    [
        "The ensure_csrf_cookie() decorator works with the CsrfViewMiddleware",
        "The ensure_csrf_cookie() decorator works with the"
    ],
    [
        "CSRF cookie age can be set using settings.CSRF_COOKIE_AGE.",
        "CSRF cookie age can be"
    ],
    [
        "CSRF cookie age does not have max age set and therefore uses",
        "CSRF cookie age does not have max age set"
    ],
    [
        "If the CSRF cookie has invalid characters in a POST request, the",
        "If the CSRF cookie has invalid characters in a"
    ],
    [
        "If the CSRF cookie has an incorrect length in a POST request, the",
        "If the CSRF cookie has an incorrect"
    ],
    [
        "If the token is longer than expected, it is ignored and a new token is",
        "If the token is longer than expected, it"
    ],
    [
        "If the token contains non-alphanumeric characters, it is ignored and a",
        "If the token contains non-alphanumeric characters, it is ignored"
    ],
    [
        "resp = mw.process_view(req, token_view, (), {})",
        "resp = mw.process_view(req,"
    ],
    [
        "set_cookie() is called only once when the view is decorated with both",
        "set_cookie() is called only once when the view is"
    ],
    [
        "A CSRF cookie with the wrong format is replaced during a GET request.",
        "A CSRF cookie with the wrong format is"
    ],
    [
        "self.assertTrue(csrf_cookie, msg=\"No CSRF cookie was sent.\")",
        "self.assertTrue(csrf_cookie, msg=\"No CSRF cookie"
    ],
    [
        "Masked and unmasked CSRF cookies are not replaced during a GET request.",
        "Masked and unmasked CSRF cookies are not replaced during a"
    ],
    [
        "self.assertFalse(csrf_cookie, msg=\"A CSRF cookie was sent.\")",
        "self.assertFalse(csrf_cookie, msg=\"A CSRF"
    ],
    [
        "For a view that uses the csrf_token, the csrf cookie is replaced with",
        "For a view that uses the csrf_token, the csrf cookie is"
    ],
    [
        "the unmasked version if originally masked.",
        "the unmasked version"
    ],
    [
        "resp = mw.process_view(req, token_view, (), {})",
        "resp = mw.process_view(req,"
    ],
    [
        "The csrf cookie is left unchanged if originally not masked.",
        "The csrf cookie is left unchanged"
    ],
    [
        "resp = mw.process_view(req, token_view, (), {})",
        "resp = mw.process_view(req, token_view,"
    ],
    [
        "A POST HTTPS request is accepted when USE_X_FORWARDED_PORT=True.",
        "A POST HTTPS request"
    ],
    [
        "A POST HTTPS request with a good referer should be accepted from a",
        "A POST HTTPS request with a good referer"
    ],
    [
        "A POST HTTPS request with a good referer should be accepted from a",
        "A POST HTTPS request with a good referer should be accepted from"
    ],
    [
        "A POST HTTPS request from an insecure referer should be rejected.",
        "A POST HTTPS request from an insecure"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req,"
    ],
    [
        "\"Referer checking failed - Referer is insecure while host is secure.\",",
        "\"Referer checking failed - Referer is"
    ],
    [
        "Return the CSRF cookie as a string, or False if no cookie is present.",
        "Return the CSRF cookie as a string,"
    ],
    [
        "\"CSRF_USE_SESSIONS is enabled, but request.session is not set. \"",
        "\"CSRF_USE_SESSIONS is enabled, but request.session"
    ],
    [
        "\"SessionMiddleware must appear before CsrfViewMiddleware in MIDDLEWARE.\"",
        "\"SessionMiddleware must appear before CsrfViewMiddleware in"
    ],
    [
        "Masked and unmasked tokens are allowed both as POST and as the",
        "Masked and unmasked tokens are allowed both as POST and"
    ],
    [
        "resp = mw.process_view(req, token_view, (), {})",
        "resp = mw.process_view(req, token_view, (),"
    ],
    [
        "\"\"\"The ensure_csrf_cookie() decorator works without middleware.\"\"\"",
        "\"\"\"The ensure_csrf_cookie() decorator works"
    ],
    [
        "\"\"\"The session isn't saved if the CSRF cookie is unchanged.\"\"\"",
        "\"\"\"The session isn't saved if"
    ],
    [
        "The ensure_csrf_cookie() decorator works with the CsrfViewMiddleware",
        "The ensure_csrf_cookie() decorator works"
    ],
    [
        "A POST HTTPS request is accepted when USE_X_FORWARDED_PORT=True.",
        "A POST HTTPS request is accepted when"
    ],
    [
        "A POST HTTPS request with a good referer should be accepted from a",
        "A POST HTTPS request with a good referer should"
    ],
    [
        "A POST HTTPS request with a good referer should be accepted from a",
        "A POST HTTPS request with a good referer should be"
    ],
    [
        "A POST HTTPS request from an insecure referer should be rejected.",
        "A POST HTTPS request from an insecure referer should"
    ],
    [
        "response = mw.process_view(req, post_form_view, (), {})",
        "response = mw.process_view(req, post_form_view, (),"
    ],
    [
        "\"Referer checking failed - Referer is insecure while host is secure.\",",
        "\"Referer checking failed - Referer is insecure"
    ],
    [
        "from django.template import Context, RequestContext, Template",
        "from django.template import"
    ],
    [
        "A version of HttpResponse that stores what cookie values are passed to",
        "A version of HttpResponse that stores what cookie values"
    ],
    [
        "This is a view that calls rotate_token() in process_response() between two",
        "This is a view that calls"
    ],
    [
        "\"\"\"Return a POST form (without a token).\"\"\"",
        "\"\"\"Return a POST form (without"
    ],
    [
        "\"\"\"Use the csrf view processor instead of the token.\"\"\"",
        "\"\"\"Use the csrf view processor instead"
    ],
    [
        "\"\"\"This error handler accesses the CSRF token.\"\"\"",
        "\"\"\"This error handler accesses the"
    ],
    [
        "return \"%s: %s\" % (self.my_pk, self.title)",
        "return \"%s: %s\" %"
    ],
    [
        "alt_editor = models.ForeignKey(Editor, models.SET_NULL, blank=True, null=True)",
        "alt_editor = models.ForeignKey(Editor, models.SET_NULL, blank=True,"
    ],
    [
        "return \"%s - %s\" % (self.title, self.notes)",
        "return \"%s - %s\" %"
    ],
    [
        "return \"%s at %s\" % (self.name, self.place)",
        "return \"%s at %s\" % (self.name,"
    ],
    [
        "return \"%s is %d\" % (self.owner.name, self.age)",
        "return \"%s is %d\""
    ],
    [
        "return \"%s for %s\" % (self.quantity, self.price)",
        "return \"%s for %s\""
    ],
    [
        "return \"%s (%s)\" % (self.revision, str(self.repository))",
        "return \"%s (%s)\" % (self.revision,"
    ],
    [
        "Make sure that an add form that is filled out, but marked for deletion",
        "Make sure that an add form that"
    ],
    [
        "Make sure that a change form that is filled out, but marked for deletion",
        "Make sure that a change form that is filled out, but marked for"
    ],
    [
        "poem = Poem.objects.create(name=\"Brevity is the soul of wit\", poet=poet)",
        "poem = Poem.objects.create(name=\"Brevity is the soul of wit\","
    ],
    [
        "\"Calling modelformset_factory without defining 'fields' or 'exclude' \"",
        "\"Calling modelformset_factory without defining"
    ],
    [
        "model_formset_factory() respects fields and exclude parameters of a",
        "model_formset_factory() respects fields and exclude parameters"
    ],
    [
        "A queryset can be overridden in the formset's __init__() method.",
        "A queryset can be overridden in the formset's"
    ],
    [
        "PoemFormSet = inlineformset_factory(Poet, Poem, form=PoemForm, fields=\"__all__\")",
        "PoemFormSet = inlineformset_factory(Poet,"
    ],
    [
        "The ModelForm.save() method should be able to access the related object",
        "The ModelForm.save() method should be able to access the"
    ],
    [
        "poem.name = \"%s by %s\" % (poem.name, poem.poet.name)",
        "poem.name = \"%s by"
    ],
    [
        "message = \"fk_name 'title' is not a ForeignKey to 'model_formsets.Author'.\"",
        "message = \"fk_name 'title' is not a ForeignKey to"
    ],
    [
        "formset.errors, [{\"slug\": [\"Product with this Slug already exists.\"]}]",
        "formset.errors, [{\"slug\": [\"Product with this"
    ],
    [
        "[{\"__all__\": [\"Price with this Price and Quantity already exists.\"]}],",
        "[{\"__all__\": [\"Price with this Price"
    ],
    [
        "\"Revision with this Repository and Revision already exists.\"",
        "\"Revision with this Repository and"
    ],
    [
        "return value.split(\",\") if value else []",
        "return value.split(\",\") if"
    ],
    [
        "[{}, {\"__all__\": [\"Please correct the duplicate values below.\"]}, {}],",
        "[{}, {\"__all__\": [\"Please correct the duplicate values"
    ],
    [
        "[{}, {\"__all__\": [\"Please correct the duplicate values below.\"]}, {}],",
        "[{}, {\"__all__\": [\"Please correct the duplicate values below.\"]},"
    ],
    [
        "formset._non_form_errors, [\"Please correct the duplicate data for slug.\"]",
        "formset._non_form_errors, [\"Please correct the duplicate data"
    ],
    [
        "\"Please correct the duplicate data for price and quantity, which must \"",
        "\"Please correct the duplicate data for price"
    ],
    [
        "formset._non_form_errors, [\"Please correct the duplicate data for title.\"]",
        "formset._non_form_errors, [\"Please correct the duplicate data for"
    ],
    [
        "[{}, {\"__all__\": [\"Please correct the duplicate values below.\"]}],",
        "[{}, {\"__all__\": [\"Please correct"
    ],
    [
        "\"Please correct the duplicate data for title which must be unique for \"",
        "\"Please correct the duplicate data for title which must"
    ],
    [
        "[{}, {\"__all__\": [\"Please correct the duplicate values below.\"]}],",
        "[{}, {\"__all__\": [\"Please correct the duplicate"
    ],
    [
        "\"Please correct the duplicate data for slug which must be unique for \"",
        "\"Please correct the duplicate data for slug which must be"
    ],
    [
        "\"Please correct the duplicate data for subtitle which must be unique \"",
        "\"Please correct the duplicate data for subtitle which must"
    ],
    [
        "\"Select a valid choice. That choice is not one of the \"",
        "\"Select a valid choice. That choice is not one of the"
    ],
    [
        "\"Select a valid choice. That choice is not one of the \"",
        "\"Select a valid choice. That choice"
    ],
    [
        "book = Book.objects.create(author=charles, title=\"Les Paradis Artificiels\")",
        "book = Book.objects.create(author=charles, title=\"Les"
    ],
    [
        "Author, Book, fields=\"__all__\", help_texts={\"title\": \"Choose carefully.\"}",
        "Author, Book, fields=\"__all__\","
    ],
    [
        "from the model field default should be ignored as it's regenerated on",
        "from the model field default should be ignored as it's"
    ],
    [
        "Tests the case where both the parent and child have a UUID primary key.",
        "Tests the case where both the parent and child have"
    ],
    [
        "value to avoid triggering validation on empty forms.",
        "value to avoid triggering validation"
    ],
    [
        "the case of a parent object with a UUID primary key and a child object",
        "the case of a parent object with a UUID primary key and a child"
    ],
    [
        "the case of a parent object with an AutoField primary key and a child",
        "the case of a parent object with an AutoField primary key and a"
    ],
    [
        "object with a UUID primary key.",
        "object with a"
    ],
    [
        "the case of a parent object with a UUID primary key and a child",
        "the case of a parent object with a"
    ],
    [
        "object with an editable natural key for a primary key.",
        "object with an editable natural"
    ],
    [
        "the case of a parent object with a UUID alternate key and a child",
        "the case of a parent object with a UUID alternate"
    ],
    [
        "object that relates to that alternate key.",
        "object that relates to that alternate"
    ],
    [
        "If form data is provided, a parent's auto-generated alternate key is",
        "If form data is provided, a parent's auto-generated alternate key"
    ],
    [
        "from io import BytesIO, StringIO, TextIOWrapper",
        "from io import BytesIO, StringIO,"
    ],
    [
        "The symbol django.core.files.NamedTemporaryFile is assigned as",
        "The symbol django.core.files.NamedTemporaryFile"
    ],
    [
        "a different class on different operating systems. In",
        "a different class on different"
    ],
    [
        "any case, the result should minimally mock some of the API of",
        "any case, the result should minimally mock"
    ],
    [
        "tempfile.NamedTemporaryFile from the Python standard library.",
        "tempfile.NamedTemporaryFile from the Python standard"
    ],
    [
        "File objects should yield lines when iterated over.",
        "File objects should yield lines when iterated"
    ],
    [
        "Other examples of unnamed files may be tempfile.SpooledTemporaryFile or",
        "Other examples of unnamed files"
    ],
    [
        "name = \"I can have a name too!\"",
        "name = \"I can have a"
    ],
    [
        "ContentFile can accept both bytes and strings and the retrieved content",
        "ContentFile can accept both bytes and strings and the"
    ],
    [
        "\"\"\"The temporary file name has the same suffix as the original file.\"\"\"",
        "\"\"\"The temporary file name has the same"
    ],
    [
        "Open files passed into get_image_dimensions() should stay opened.",
        "Open files passed into get_image_dimensions() should"
    ],
    [
        "get_image_dimensions() called with a filename should closed the file.",
        "get_image_dimensions() called with a filename should closed"
    ],
    [
        "get_image_dimensions() works properly after various calls",
        "get_image_dimensions() works properly"
    ],
    [
        "Multiple calls of get_image_dimensions() should return the same size.",
        "Multiple calls of get_image_dimensions() should return the same"
    ],
    [
        "get_image_dimensions() fails on some PNGs, while Image.size is working",
        "get_image_dimensions() fails on some PNGs, while Image.size is"
    ],
    [
        "get_image_dimensions() should return (None, None) for the dimensions of",
        "get_image_dimensions() should return (None, None) for the"
    ],
    [
        "brokenimg.png is not a valid image and it has been generated by:",
        "brokenimg.png is not a valid image and it has been"
    ],
    [
        "get_image_dimensions() should catch struct.error while feeding the PIL",
        "get_image_dimensions() should catch struct.error while feeding the"
    ],
    [
        "Emulates the Parser feed error. Since the error is raised on every feed",
        "Emulates the Parser feed error. Since the error is raised"
    ],
    [
        "attempt, the resulting image size should be invalid: (None, None).",
        "attempt, the resulting image size should be invalid:"
    ],
    [
        "msg = r\"Destination file .* exists and allow_overwrite is False\\.\"",
        "msg = r\"Destination file .* exists and allow_overwrite is"
    ],
    [
        "file_move_safe() ignores PermissionError thrown by copystat() and",
        "file_move_safe() ignores PermissionError thrown by"
    ],
    [
        "For example, PermissionError can be raised when the destination",
        "For example, PermissionError can be raised"
    ],
    [
        "filesystem is CIFS, or when relabel is disabled by SELinux across",
        "filesystem is CIFS, or when relabel is disabled by"
    ],
    [
        "from datetime import date, datetime, timedelta",
        "from datetime import date,"
    ],
    [
        "from threading import Event, Thread, Timer",
        "from threading import Event, Thread,"
    ],
    [
        "from django.db import DatabaseError, IntegrityError, connection",
        "from django.db import"
    ],
    [
        "from django.test import TestCase, TransactionTestCase, skipUnlessDBFeature",
        "from django.test import TestCase, TransactionTestCase,"
    ],
    [
        "If we execute the exact same statement twice, the second time,",
        "If we execute the exact same statement"
    ],
    [
        "If you don't specify a value or default value for all required",
        "If you don't specify a value or"
    ],
    [
        "fields, you will get an error.",
        "fields, you will"
    ],
    [
        "Using the pk property of a model is allowed.",
        "Using the pk property of a"
    ],
    [
        "\"\"\"Using a property with a setter implemented is allowed.\"\"\"",
        "\"\"\"Using a property with a setter implemented is"
    ],
    [
        "book, created = p.books.get_or_create(name=\"The Book of Ed & Fred\")",
        "book, created = p.books.get_or_create(name=\"The Book of"
    ],
    [
        "book, created = p.books.get_or_create(name=\"The Book of Ed & Fred\")",
        "book, created = p.books.get_or_create(name=\"The Book of Ed"
    ],
    [
        "_, created = ed.books.get_or_create(name=\"Ed's Recipes\", publisher=p)",
        "_, created = ed.books.get_or_create(name=\"Ed's"
    ],
    [
        "name=\"The Great Book of Ed\", publisher_id=p.id",
        "name=\"The Great Book of"
    ],
    [
        "name=\"The Great Book of Ed\", publisher_id=p.id",
        "name=\"The Great Book of Ed\","
    ],
    [
        "If you have a field named defaults and want to use it as an exact",
        "If you have a field named defaults and want to use it as"
    ],
    [
        "lookup, you need to use 'defaults__exact'.",
        "lookup, you need to use"
    ],
    [
        "Callables in `defaults` are evaluated if the instance is created.",
        "Callables in `defaults` are evaluated if the instance"
    ],
    [
        "\"\"\"`defaults` aren't evaluated if the instance isn't created.\"\"\"",
        "\"\"\"`defaults` aren't evaluated if the instance isn't"
    ],
    [
        "If you specify an existing primary key, but different other fields,",
        "If you specify an existing primary key, but different other"
    ],
    [
        "then you will get an error and data will not be updated.",
        "then you will get an error and"
    ],
    [
        "The database connection is still usable after a DatabaseError in",
        "The database connection is still usable after a DatabaseError"
    ],
    [
        "If all the attributes on a model have defaults, get_or_create() doesn't",
        "If all the attributes on a"
    ],
    [
        "databases that delay integrity checks until the end of transactions,",
        "databases that delay integrity checks"
    ],
    [
        "otherwise the exception is never raised.",
        "otherwise the exception is"
    ],
    [
        "self.skipTest(\"This backend does not support integrity checks.\")",
        "self.skipTest(\"This backend does not"
    ],
    [
        "If you don't specify a value or default value for all required",
        "If you don't specify a value or default value for"
    ],
    [
        "fields, you will get an error.",
        "fields, you will get an"
    ],
    [
        "If you specify an existing primary key, but different other fields,",
        "If you specify an existing primary key, but different other"
    ],
    [
        "then you will get an error and data will not be updated.",
        "then you will get an error"
    ],
    [
        "Using the pk property of a model is allowed.",
        "Using the pk property of a model"
    ],
    [
        "\"\"\"Using a property with a setter implemented is allowed.\"\"\"",
        "\"\"\"Using a property with a setter implemented"
    ],
    [
        "update_or_create should raise IntegrityErrors with the full traceback.",
        "update_or_create should raise IntegrityErrors with"
    ],
    [
        "This is tested by checking that a known method call is in the traceback.",
        "This is tested by checking that a known method call is in the"
    ],
    [
        "We cannot use assertRaises/assertRaises here because we need to inspect",
        "We cannot use assertRaises/assertRaises here"
    ],
    [
        "Should be able to use update_or_create from the related manager to",
        "Should be able to use update_or_create from"
    ],
    [
        "book, created = p.books.update_or_create(name=\"The Book of Ed & Fred\")",
        "book, created = p.books.update_or_create(name=\"The Book of Ed &"
    ],
    [
        "name=\"Basics of Django\", create_defaults={\"name\": \"Advanced Django\"}",
        "name=\"Basics of Django\", create_defaults={\"name\":"
    ],
    [
        "Should be able to use update_or_create from the related manager to",
        "Should be able to use update_or_create from the related manager"
    ],
    [
        "book = Book.objects.create(name=\"The Book of Ed & Fred\", publisher=p)",
        "book = Book.objects.create(name=\"The Book of Ed"
    ],
    [
        "name = \"The Book of Django\"",
        "name = \"The Book"
    ],
    [
        "book, created = p.books.update_or_create(defaults={\"name\": name}, id=book.id)",
        "book, created = p.books.update_or_create(defaults={\"name\": name},"
    ],
    [
        "name=\"The Book of Ed & Fred\", publisher=p",
        "name=\"The Book of Ed &"
    ],
    [
        "book = Book.objects.create(name=\"The Book of Ed & Fred\", publisher=p)",
        "book = Book.objects.create(name=\"The Book of"
    ],
    [
        "name = \"The Book of Django\"",
        "name = \"The"
    ],
    [
        "If you have a field named defaults and want to use it as an exact",
        "If you have a field named defaults and want"
    ],
    [
        "lookup, you need to use 'defaults__exact'.",
        "lookup, you need to"
    ],
    [
        "If you have a field named create_defaults and want to use it as an",
        "If you have a field named create_defaults"
    ],
    [
        "exact lookup, you need to use 'create_defaults__exact'.",
        "exact lookup, you need"
    ],
    [
        "\"\"\"`defaults` aren't evaluated if the instance isn't created.\"\"\"",
        "\"\"\"`defaults` aren't evaluated if the instance"
    ],
    [
        "book = Book.objects.create(publisher=publisher, name=\"The Book of Ed & Fred\")",
        "book = Book.objects.create(publisher=publisher, name=\"The Book of Ed &"
    ],
    [
        "for defaults in [{\"publisher\": publisher}, {\"publisher_id\": publisher}]:",
        "for defaults in [{\"publisher\": publisher},"
    ],
    [
        "q[\"sql\"] for q in captured_queries if q[\"sql\"].startswith(\"UPDATE\")",
        "q[\"sql\"] for q in captured_queries"
    ],
    [
        "If an existing primary key is specified with different values for other",
        "If an existing primary key is specified"
    ],
    [
        "fields, then IntegrityError is raised and data isn't updated.",
        "fields, then IntegrityError is raised and"
    ],
    [
        "Objects are selected and updated in a transaction to avoid race",
        "Objects are selected and updated in a"
    ],
    [
        "conditions. This test forces update_or_create() to hold the lock",
        "conditions. This test forces update_or_create()"
    ],
    [
        "in another thread for a relatively long time so that it can update",
        "in another thread for a relatively long time so that it can"
    ],
    [
        "while it holds the lock. The updated field isn't a field in 'defaults',",
        "while it holds the lock. The updated"
    ],
    [
        "so update_or_create() shouldn't have an effect on it.",
        "so update_or_create() shouldn't have an effect on"
    ],
    [
        "self.skipTest(\"Database took too long to lock the row\")",
        "self.skipTest(\"Database took too long to lock"
    ],
    [
        "Objects are selected and updated in a transaction to avoid race",
        "Objects are selected and updated in"
    ],
    [
        "conditions. This test checks the behavior of update_or_create() when",
        "conditions. This test checks the behavior of update_or_create()"
    ],
    [
        "the object doesn't already exist, but another thread creates the",
        "the object doesn't already exist, but another"
    ],
    [
        "object before update_or_create() does and then attempts to update the",
        "object before update_or_create() does and then attempts to update"
    ],
    [
        "object, also before update_or_create(). It forces update_or_create() to",
        "object, also before update_or_create(). It"
    ],
    [
        "hold the lock in another thread for a relatively long time so that it",
        "hold the lock in another thread for a relatively long time so that"
    ],
    [
        "can update while it holds the lock. The updated field isn't a field in",
        "can update while it holds the lock. The updated field isn't"
    ],
    [
        "'defaults', so update_or_create() shouldn't have an effect on it.",
        "'defaults', so update_or_create() shouldn't have an effect"
    ],
    [
        "wait_or_fail(save_allowed, \"Test took too long to allow save\")",
        "wait_or_fail(save_allowed, \"Test took too"
    ],
    [
        "wait_or_fail(locked_for_update, \"Database took too long to lock row\")",
        "wait_or_fail(locked_for_update, \"Database took too long"
    ],
    [
        "wait_or_fail(locked_for_update, \"Database took too long to lock row\")",
        "wait_or_fail(locked_for_update, \"Database took too long to lock"
    ],
    [
        "msg = \"Invalid field name(s) for model Thing: 'nonexistent'.\"",
        "msg = \"Invalid field name(s)"
    ],
    [
        "\"Cannot resolve keyword 'nonexistent' into field. Choices are: id, name, tags\"",
        "\"Cannot resolve keyword 'nonexistent' into field."
    ],
    [
        "FieldError, \"Invalid field name(s) for model Thing: 'name_in_all_caps'\"",
        "FieldError, \"Invalid field name(s) for model Thing:"
    ],
    [
        "\"Cannot resolve keyword 'name_in_all_caps' into field. Choices are: id, \"",
        "\"Cannot resolve keyword 'name_in_all_caps' into field. Choices are:"
    ],
    [
        "Many-to-many and many-to-one relationships to the same table",
        "Many-to-many and many-to-one relationships to the same"
    ],
    [
        "Make sure to set ``related_name`` if you use relationships to the same table.",
        "Make sure to set ``related_name`` if you use relationships to"
    ],
    [
        "from .models import Issue, StringReferenceModel, User",
        "from .models import"
    ],
    [
        "strings, providing they are directly convertible to ASCII.",
        "strings, providing they are directly convertible"
    ],
    [
        "You can pass callable objects as the ``default`` parameter to a field. When",
        "You can pass callable objects as the ``default`` parameter to a field."
    ],
    [
        "the object is created without an explicit value passed in, Django will call",
        "the object is created without an explicit value passed in, Django"
    ],
    [
        "the method to determine the default value.",
        "the method to determine"
    ],
    [
        "This example uses ``datetime.datetime.now`` as the default for the ``pub_date``",
        "This example uses ``datetime.datetime.now`` as the default for"
    ],
    [
        "from django.db.models.functions import Coalesce, ExtractYear, Now, Pi",
        "from django.db.models.functions import Coalesce,"
    ],
    [
        "Values or expressions can be passed as the db_default parameter to a field.",
        "Values or expressions can be passed as the db_default parameter to a"
    ],
    [
        "When the object is created without an explicit value passed in, the",
        "When the object is created without an explicit value passed"
    ],
    [
        "database will insert the default value automatically.",
        "database will insert the default value"
    ],
    [
        "from django.db.models import Case, F, FloatField, Value, When",
        "from django.db.models import Case, F, FloatField,"
    ],
    [
        "Fixtures are a way of loading data into the database in bulk. Fixure data",
        "Fixtures are a way of loading data into"
    ],
    [
        "can be stored in any serializable format (including JSON and XML). Fixtures",
        "can be stored in any serializable format"
    ],
    [
        "are identified by name, and are stored in either a directory named 'fixtures'",
        "are identified by name, and are stored in either a directory"
    ],
    [
        "in the application directory, or in one of the directories named in the",
        "in the application directory, or in one of the directories"
    ],
    [
        "return '<%s: %s> tagged \"%s\"' % (",
        "return '<%s: %s> tagged \"%s\"'"
    ],
    [
        "\", \".join(p.name for p in self.permissions.all()),",
        "\", \".join(p.name for p"
    ],
    [
        "authors = \" and \".join(a.name for a in self.authors.all())",
        "authors = \" and \".join(a.name"
    ],
    [
        "return \"%s by %s\" % (self.name, authors) if authors else self.name",
        "return \"%s by %s\" % (self.name, authors) if authors"
    ],
    [
        "from django.test import TestCase, TransactionTestCase, skipUnlessDBFeature",
        "from django.test import TestCase,"
    ],
    [
        "\"Copyright is fine the way it is\",",
        "\"Copyright is fine the"
    ],
    [
        "\"Poker has no place on ESPN\",",
        "\"Poker has no place"
    ],
    [
        "\"There were no fixture objects installed\"",
        "\"There were no fixture objects"
    ],
    [
        "filename = filename and os.path.join(tempfile.gettempdir(), filename)",
        "filename = filename and"
    ],
    [
        "[\"Time to reform copyright\", \"Poker has no place on ESPN\"],",
        "[\"Time to reform copyright\", \"Poker"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform copyright\","
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}]',",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}},"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform copyright\","
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}},"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform copyright\","
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}},"
    ],
    [
        "\"Copyright is fine the way it is\",",
        "\"Copyright is fine the"
    ],
    [
        "\"Poker has no place on ESPN\",",
        "\"Poker has no place"
    ],
    [
        "\"XML identified as leading cause of cancer\",",
        "\"XML identified as leading cause"
    ],
    [
        "\"Copyright is fine the way it is\",",
        "\"Copyright is fine the way it"
    ],
    [
        "'<Tag: <Article: Copyright is fine the way it is> tagged \"copyright\">',",
        "'<Tag: <Article: Copyright is fine the"
    ],
    [
        "'<Tag: <Article: Copyright is fine the way it is> tagged \"law\">',",
        "'<Tag: <Article: Copyright is fine the"
    ],
    [
        "'<Tag: <Article: Copyright is fine the way it is> tagged \"copyright\">',",
        "'<Tag: <Article: Copyright is fine the"
    ],
    [
        "'<Tag: <Article: Copyright is fine the way it is> tagged \"legal\">',",
        "'<Tag: <Article: Copyright is fine the"
    ],
    [
        "'<Tag: <Article: Django conquers world!> tagged \"django\">',",
        "'<Tag: <Article: Django conquers world!> tagged"
    ],
    [
        "'<Tag: <Article: Django conquers world!> tagged \"world domination\">',",
        "'<Tag: <Article: Django conquers world!> tagged \"world"
    ],
    [
        "\"<Visa: Django Reinhardt Can add user, Can change user, Can delete \"",
        "\"<Visa: Django Reinhardt Can add user, Can"
    ],
    [
        "\"<Visa: Stephane Grappelli Can add user>\",",
        "\"<Visa: Stephane Grappelli Can add"
    ],
    [
        "\"<Visa: Django Reinhardt Can add user, Can change user, Can delete \"",
        "\"<Visa: Django Reinhardt Can add user, Can change user, Can"
    ],
    [
        "\"<Visa: Stephane Grappelli Can add user, Can delete user>\",",
        "\"<Visa: Stephane Grappelli Can add"
    ],
    [
        "'<Visa: Artist formerly known as \"Prince\" Can change user>',",
        "'<Visa: Artist formerly known as \"Prince\" Can"
    ],
    [
        "\"XML identified as leading cause of cancer\",",
        "\"XML identified as leading cause"
    ],
    [
        "\"Copyright is fine the way it is\",",
        "\"Copyright is fine the way"
    ],
    [
        "'{\"name\": \"Music for all ages\", \"authors\": '",
        "'{\"name\": \"Music for all ages\", \"authors\":"
    ],
    [
        "'[[\"Artist formerly known as \\\\\"Prince\\\\\"\"], [\"Django Reinhardt\"]]}}]',",
        "'[[\"Artist formerly known as"
    ],
    [
        "'[{\"fields\": {\"name\": \"Django Reinhardt\"}, \"model\": \"fixtures.person\"}, '",
        "'[{\"fields\": {\"name\": \"Django Reinhardt\"}, \"model\":"
    ],
    [
        "'{\"fields\": {\"name\": \"Stephane Grappelli\"}, \"model\": \"fixtures.person\"}, '",
        "'{\"fields\": {\"name\": \"Stephane Grappelli\"}, \"model\": \"fixtures.person\"},"
    ],
    [
        "'{\"fields\": {\"name\": \"Artist formerly known as \\\\\"Prince\\\\\"\"}, '",
        "'{\"fields\": {\"name\": \"Artist formerly known as"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "'{\"headline\": \"Poker on TV is great!\", '",
        "'{\"headline\": \"Poker on TV is"
    ],
    [
        "'{\"headline\": \"Copyright is fine the way it is\", '",
        "'{\"headline\": \"Copyright is fine the way it is\","
    ],
    [
        "'{\"headline\": \"XML identified as leading cause of cancer\", '",
        "'{\"headline\": \"XML identified as leading cause of cancer\","
    ],
    [
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"copyright\", '",
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"copyright\","
    ],
    [
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"legal\", '",
        "'{\"tagged_type\": [\"fixtures\", \"article\"],"
    ],
    [
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"django\", '",
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"django\","
    ],
    [
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"world domination\", '",
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\":"
    ],
    [
        "'\"fields\": {\"name\": \"Artist formerly known as \\\\\"Prince\\\\\"\"}}, '",
        "'\"fields\": {\"name\": \"Artist formerly known as \\\\\"Prince\\\\\"\"}},"
    ],
    [
        "'\"fields\": {\"person\": [\"Django Reinhardt\"], \"permissions\": '",
        "'\"fields\": {\"person\": [\"Django Reinhardt\"], \"permissions\":"
    ],
    [
        "'[[\"add_user\", \"auth\", \"user\"], [\"change_user\", \"auth\", \"user\"], '",
        "'[[\"add_user\", \"auth\", \"user\"], [\"change_user\","
    ],
    [
        "'[[\"add_user\", \"auth\", \"user\"], [\"delete_user\", \"auth\", \"user\"]]}}, '",
        "'[[\"add_user\", \"auth\", \"user\"], [\"delete_user\","
    ],
    [
        "'{\"person\": [\"Artist formerly known as \\\\\"Prince\\\\\"\"], \"permissions\": '",
        "'{\"person\": [\"Artist formerly known as \\\\\"Prince\\\\\"\"],"
    ],
    [
        "'{\"name\": \"Music for all ages\", \"authors\": '",
        "'{\"name\": \"Music for all ages\","
    ],
    [
        "'[[\"Artist formerly known as \\\\\"Prince\\\\\"\"], [\"Django Reinhardt\"]]}}]',",
        "'[[\"Artist formerly known as"
    ],
    [
        "'<field type=\"CharField\" name=\"headline\">Poker on TV is great!</field>'",
        "'<field type=\"CharField\" name=\"headline\">Poker on TV"
    ],
    [
        "'<field type=\"CharField\" name=\"headline\">Copyright is fine the way it is'",
        "'<field type=\"CharField\" name=\"headline\">Copyright is fine the"
    ],
    [
        "\"XML identified as leading cause of cancer</field>\"",
        "\"XML identified as leading"
    ],
    [
        "'<field type=\"CharField\" name=\"name\">Artist formerly known as \"Prince\"'",
        "'<field type=\"CharField\" name=\"name\">Artist formerly"
    ],
    [
        "'<field type=\"CharField\" name=\"name\">Music for all ages</field>'",
        "'<field type=\"CharField\" name=\"name\">Music for all"
    ],
    [
        "'\"fields\": {\"domain\": \"example.com\", \"name\": \"example.com\"}}, '",
        "'\"fields\": {\"domain\": \"example.com\", \"name\":"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}]',",
        "'{\"description\": \"Latest news stories\","
    ],
    [
        "'\"fields\": {\"domain\": \"example.com\", \"name\": \"example.com\"}}, '",
        "'\"fields\": {\"domain\": \"example.com\", \"name\": \"example.com\"}},"
    ],
    [
        "'\"fields\": {\"description\": \"Latest news stories\", '",
        "'\"fields\": {\"description\": \"Latest news stories\","
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}]',",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "management.CommandError, \"No installed app with label 'foo_app'.\"",
        "management.CommandError, \"No installed app with"
    ],
    [
        "\"How To Deal With Special Characters\",",
        "\"How To Deal With Special"
    ],
    [
        "'[{\"pk\": %d, \"model\": \"fixtures.spy\", \"fields\": {\"cover_blown\": false}}]'",
        "'[{\"pk\": %d, \"model\": \"fixtures.spy\", \"fields\":"
    ],
    [
        "'[{\"pk\": %d, \"model\": \"fixtures.spy\", \"fields\": {\"cover_blown\": true}}, '",
        "'[{\"pk\": %d, \"model\": \"fixtures.spy\", \"fields\": {\"cover_blown\": true}},"
    ],
    [
        "'{\"pk\": %d, \"model\": \"fixtures.spy\", \"fields\": {\"cover_blown\": false}}]'",
        "'{\"pk\": %d, \"model\": \"fixtures.spy\","
    ],
    [
        "'\"fields\": {\"headline\": \"Poker has no place on ESPN\", '",
        "'\"fields\": {\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Copyright is fine the way it is\", '",
        "'{\"headline\": \"Copyright is fine the way"
    ],
    [
        "'\"fields\": {\"headline\": \"Poker has no place on ESPN\", '",
        "'\"fields\": {\"headline\": \"Poker has no place on"
    ],
    [
        "management.CommandError, \"You can only use --pks option with one model\"",
        "management.CommandError, \"You can only use --pks option"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Copyright is fine the way it is\", '",
        "'{\"headline\": \"Copyright is fine the way it is\","
    ],
    [
        "management.CommandError, \"You can only use --pks option with one model\"",
        "management.CommandError, \"You can only use"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Copyright is fine the way it is\", '",
        "'{\"headline\": \"Copyright is fine the way it is\","
    ],
    [
        "management.CommandError, \"You can only use --pks option with one model\"",
        "management.CommandError, \"You can only use --pks"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on"
    ],
    [
        "'{\"headline\": \"Copyright is fine the way it is\", '",
        "'{\"headline\": \"Copyright is fine the way it"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\": \"News"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}},"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform copyright\","
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\","
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform copyright\","
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform"
    ],
    [
        "msg = \"Unsupported file extension (.zip). Fixtures saved in 'dumpdata.json'.\"",
        "msg = \"Unsupported file extension (.zip). Fixtures"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\": \"News"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to"
    ],
    [
        "Dumpdata shows a progress bar on the command line when --output is set,",
        "Dumpdata shows a progress bar on the command line when"
    ],
    [
        "\"[\" + \".\" * ProgressBar.progress_width + \"]\\n\"",
        "\"[\" + \".\" * ProgressBar.progress_width"
    ],
    [
        "A warning is displayed if a proxy model is dumped without its concrete",
        "A warning is displayed if a proxy model"
    ],
    [
        "msg = \"fixtures.ProxySpy is a proxy model and won't be serialized.\"",
        "msg = \"fixtures.ProxySpy is a proxy model and won't"
    ],
    [
        "A warning isn't displayed if a proxy model is dumped with its concrete",
        "A warning isn't displayed if a proxy model is"
    ],
    [
        "\"Who needs more than one database?\",",
        "\"Who needs more than one"
    ],
    [
        "\"Who needs to use compressed data?\",",
        "\"Who needs to use"
    ],
    [
        "Loading a fixture which contains an invalid object outputs an error",
        "Loading a fixture which contains an invalid"
    ],
    [
        "message which contains the pk of the object that triggered the error.",
        "message which contains the pk of the object"
    ],
    [
        "\"Who needs more than one database?\",",
        "\"Who needs more"
    ],
    [
        "\"Who needs more than one database?\",",
        "\"Who needs more than one"
    ],
    [
        "\"Who needs to use compressed data?\",",
        "\"Who needs to use"
    ],
    [
        "'<Tag: <Article: Time to reform copyright> tagged \"copyright\">',",
        "'<Tag: <Article: Time to reform"
    ],
    [
        "'<Tag: <Article: Time to reform copyright> tagged \"law\">',",
        "'<Tag: <Article: Time to reform"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\","
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no"
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to reform copyright\","
    ],
    [
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"copyright\", '",
        "'{\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"copyright\","
    ],
    [
        "'<field type=\"CharField\" name=\"headline\">Poker has no place on ESPN</field>'",
        "'<field type=\"CharField\" name=\"headline\">Poker has no"
    ],
    [
        "'<field type=\"CharField\" name=\"headline\">Time to reform copyright</field>'",
        "'<field type=\"CharField\" name=\"headline\">Time to"
    ],
    [
        "\"\"\"Excluding a bogus app or model should raise an error.\"\"\"",
        "\"\"\"Excluding a bogus app or"
    ],
    [
        "msg = \"No installed app with label 'foo_app'.\"",
        "msg = \"No installed app with"
    ],
    [
        "\"\"\"Reading from stdin raises an error if format isn't specified.\"\"\"",
        "\"\"\"Reading from stdin raises an error if"
    ],
    [
        "msg = \"--format must be specified when reading from stdin.\"",
        "msg = \"--format must be specified"
    ],
    [
        "\"\"\"Loading fixtures from stdin with json and xml.\"\"\"",
        "\"\"\"Loading fixtures from stdin with json and"
    ],
    [
        "[\"Time to reform copyright\", \"Poker has no place on ESPN\"],",
        "[\"Time to reform copyright\", \"Poker has no"
    ],
    [
        "\"XML identified as leading cause of cancer\",",
        "\"XML identified as leading cause"
    ],
    [
        "Custom class to limit fixture dirs.",
        "Custom class to"
    ],
    [
        "CommandError, \"No fixture named 'this_fixture_doesnt_exist' found.\"",
        "CommandError, \"No fixture"
    ],
    [
        "If no fixtures match the loaddata command, constraints checks on the",
        "If no fixtures match the loaddata command, constraints"
    ],
    [
        "database shouldn't be disabled. This is performance critical on MSSQL.",
        "database shouldn't be disabled. This is performance critical"
    ],
    [
        "CommandError, \"No fixture named 'this_fixture_doesnt_exist' found.\"",
        "CommandError, \"No fixture named 'this_fixture_doesnt_exist'"
    ],
    [
        "[\"Time to reform copyright\", \"Poker has no place on ESPN\"],",
        "[\"Time to reform copyright\", \"Poker has no place on"
    ],
    [
        "[\"Time to reform copyright\", \"Poker has no place on ESPN\"],",
        "[\"Time to reform copyright\", \"Poker has no place on"
    ],
    [
        "'{\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '",
        "'{\"description\": \"Latest news stories\", \"title\":"
    ],
    [
        "'{\"headline\": \"Poker has no place on ESPN\", '",
        "'{\"headline\": \"Poker has no place on ESPN\","
    ],
    [
        "'{\"headline\": \"Time to reform copyright\", '",
        "'{\"headline\": \"Time to"
    ],
    [
        "\"Poker has no place on ESPN\",",
        "\"Poker has no place"
    ],
    [
        "'\"fields\": {\"key\": \"x\", \"obj\": [\"y\"]}}, '",
        "'\"fields\": {\"key\": \"x\", \"obj\":"
    ],
    [
        "Regression tests for proper working of ForeignKey(null=True).",
        "Regression tests for proper working"
    ],
    [
        "from .models import Comment, Forum, Item, Post, PropertyValue, SystemDetails, SystemInfo",
        "from .models import Comment, Forum, Item, Post, PropertyValue,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "g = Group.objects.create(name=\"Ponies Who Own Maybachs\")",
        "g = Group.objects.create(name=\"Ponies"
    ],
    [
        "A model not defined on module level is picklable.",
        "A model not defined on module level is"
    ],
    [
        "Test intentionally the automatically created through model.",
        "Test intentionally the automatically created through"
    ],
    [
        "caused subsequent QuerySet pickling to fail.",
        "caused subsequent QuerySet pickling"
    ],
    [
        "msg = \"Pickled queryset instance's Django version is not specified.\"",
        "msg = \"Pickled queryset instance's Django version is"
    ],
    [
        "unpickled with a different Django version than the current",
        "unpickled with a different Django"
    ],
    [
        "\"the current version %s.\" % django.__version__",
        "\"the current version %s.\" %"
    ],
    [
        "Neither pickling nor unpickling a QuerySet.query with an __in=inner_qs",
        "Neither pickling nor unpickling a"
    ],
    [
        "Tests for forcing insert and update queries (instead of Django's normal",
        "Tests for forcing insert and update queries (instead of Django's"
    ],
    [
        "from django.db import DatabaseError, IntegrityError, models, transaction",
        "from django.db import DatabaseError, IntegrityError,"
    ],
    [
        "msg = \"Cannot force both insert and updating in model saving.\"",
        "msg = \"Cannot force both insert"
    ],
    [
        "msg = \"Cannot force an update in save() with no primary key.\"",
        "msg = \"Cannot force an update in save()"
    ],
    [
        "msg = \"Forced update did not affect any rows.\"",
        "msg = \"Forced update did not"
    ],
    [
        "msg = \"force_insert must be a bool or tuple.\"",
        "msg = \"force_insert must be"
    ],
    [
        "msg = f\"Invalid force_insert member. {object!r} must be a model subclass.\"",
        "msg = f\"Invalid force_insert member. {object!r}"
    ],
    [
        "msg = f\"Invalid force_insert member. {instance!r} must be a model subclass.\"",
        "msg = f\"Invalid force_insert member. {instance!r} must be a"
    ],
    [
        "msg = \"Invalid force_insert member. SubCounter must be a base of Counter.\"",
        "msg = \"Invalid force_insert member. SubCounter must be a"
    ],
    [
        "from .models import Choice, Inner, OuterA, OuterB, Poll",
        "from .models import Choice, Inner, OuterA,"
    ],
    [
        "Regression test for the use of None as a query value.",
        "Regression test for the use of"
    ],
    [
        "None is interpreted as an SQL NULL, but only in __exact and __iexact",
        "None is interpreted as an SQL NULL, but"
    ],
    [
        "Set up some initial polls and choices",
        "Set up some initial polls"
    ],
    [
        "\"Cannot resolve keyword 'foo' into field. Choices are: choice, id, poll, \"",
        "\"Cannot resolve keyword 'foo' into field. Choices"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"Cannot use None as a query value\"):",
        "with self.assertRaisesMessage(ValueError, \"Cannot use None as"
    ],
    [
        "\"'Poll' instance needs to have a primary key value before this \"",
        "\"'Poll' instance needs to have a primary key"
    ],
    [
        "Querying across reverse relations and then another relation should",
        "Querying across reverse relations and then another"
    ],
    [
        "insert outer joins correctly so as not to exclude results.",
        "insert outer joins correctly so"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, ProgrammingError, connection",
        "from django.db import"
    ],
    [
        "Empty DATABASES and empty 'default' settings default to the dummy",
        "Empty DATABASES and empty 'default' settings default to the"
    ],
    [
        "\"settings.DATABASES is improperly configured. Please supply the \"",
        "\"settings.DATABASES is improperly configured. Please supply"
    ],
    [
        "\"ENGINE value. Check settings documentation for more details.\"",
        "\"ENGINE value. Check settings documentation for"
    ],
    [
        "msg = \"You must define a 'default' database.\"",
        "msg = \"You must define a 'default'"
    ],
    [
        "msg = \"The connection 'nonexistent' doesn't exist.\"",
        "msg = \"The connection"
    ],
    [
        "msg = 'table \"X\" does not exist'",
        "msg = 'table \"X\" does not"
    ],
    [
        "\"'foo' isn't an available database backend or couldn't be \"",
        "\"'foo' isn't an available database backend"
    ],
    [
        "\"imported. Check the above exception. To use one of the built-in \"",
        "\"imported. Check the above exception. To use one of"
    ],
    [
        "\"backends, use 'django.db.backends.XXX', where XXX is one of:\\n\"",
        "\"backends, use 'django.db.backends.XXX', where XXX is"
    ],
    [
        "EXTENDED_SCHEMES = [\"http\", \"https\", \"ftp\", \"ftps\", \"git\", \"file\", \"git+ssh\"]",
        "EXTENDED_SCHEMES = [\"http\", \"https\", \"ftp\", \"ftps\","
    ],
    [
        "TEST_DATA.extend((URLValidator(), url, None) for url in VALID_URLS)",
        "TEST_DATA.extend((URLValidator(), url, None) for"
    ],
    [
        "TEST_DATA.extend((URLValidator(), url, ValidationError) for url in INVALID_URLS)",
        "TEST_DATA.extend((URLValidator(), url, ValidationError) for"
    ],
    [
        "for validator, value, expected in TEST_DATA:",
        "for validator, value, expected"
    ],
    [
        "exception_expected = expected is not None and issubclass(",
        "exception_expected = expected is not"
    ],
    [
        "\"Pillow is required to test validate_image_file_extension.\"",
        "\"Pillow is required"
    ],
    [
        "v = ValidationError([\"First Problem\", \"Second Problem\"])",
        "v = ValidationError([\"First Problem\","
    ],
    [
        "msg = \"If the flags are set, regex must be a regular expression string.\"",
        "msg = \"If the flags are set, regex must be a regular expression"
    ],
    [
        "If your database column name is different than your model attribute, use the",
        "If your database column name is different than"
    ],
    [
        "``db_column`` parameter. Note that you'll use the field's name, not its column",
        "``db_column`` parameter. Note that you'll use"
    ],
    [
        "If your database table name is different than your model name, use the",
        "If your database table name is different than your model"
    ],
    [
        "``db_table`` Meta attribute. This has no effect on the API used to",
        "``db_table`` Meta attribute. This has no effect on the API used"
    ],
    [
        "If you need to use a table name for a many-to-many relationship that differs",
        "If you need to use a table name for a many-to-many relationship"
    ],
    [
        "from the default generated name, use the ``db_table`` parameter on the",
        "from the default generated name, use the ``db_table`` parameter"
    ],
    [
        "``ManyToManyField``. This has no effect on the API for querying the database.",
        "``ManyToManyField``. This has no effect on"
    ],
    [
        "return \"%s %s\" % (self.first_name, self.last_name)",
        "return \"%s %s\" % (self.first_name,"
    ],
    [
        "\"Cannot resolve keyword 'firstname' into field. Choices are: \"",
        "\"Cannot resolve keyword 'firstname' into field. Choices"
    ],
    [
        "\"Django lets you build web apps easily\",",
        "\"Django lets you build web apps"
    ],
    [
        "\"Cannot resolve keyword 'firstname' into field. Choices are: \"",
        "\"Cannot resolve keyword 'firstname' into field."
    ],
    [
        "AttributeError, \"'Author' object has no attribute 'firstname'\"",
        "AttributeError, \"'Author' object has no attribute"
    ],
    [
        "AttributeError, \"'Author' object has no attribute 'last'\"",
        "AttributeError, \"'Author' object has"
    ],
    [
        "from django.db.models import DateField, DateTimeField, F, Func, Value",
        "from django.db.models import DateField, DateTimeField, F,"
    ],
    [
        "from django.contrib.postgres import fields as pg_fields",
        "from django.contrib.postgres import"
    ],
    [
        "from django.contrib.postgres import forms as pg_forms",
        "from django.contrib.postgres import forms"
    ],
    [
        "msg = f\"Cannot use 'default_bounds' with {field_type.__name__}.\"",
        "msg = f\"Cannot use 'default_bounds'"
    ],
    [
        "tests = [\")]\", \")[\", \"](\", \"])\", \"([\", \"[(\", \"x\", \"\", None]",
        "tests = [\")]\", \")[\", \"](\", \"])\", \"([\","
    ],
    [
        "msg = \"default_bounds must be one of '[)', '(]', '()', or '[]'.\"",
        "msg = \"default_bounds must be one of '[)', '(]',"
    ],
    [
        "for lookup, filter_arg, excepted_result in tests:",
        "for lookup, filter_arg, excepted_result"
    ],
    [
        "'\\\\\"bounds\\\\\": \\\\\"[)\\\\\"}\", \"decimals\": \"{\\\\\"empty\\\\\": true}\", '",
        "'\\\\\"bounds\\\\\": \\\\\"[)\\\\\"}\", \"decimals\":"
    ],
    [
        "'\\\\\"bounds\\\\\": \\\\\"[)\\\\\"}\", \"dates_inner\": null }, '",
        "'\\\\\"bounds\\\\\": \\\\\"[)\\\\\"}\", \"dates_inner\": null },"
    ],
    [
        "for field in (\"ints\", \"dates\", \"timestamps\", \"timestamps_closed_bounds\"):",
        "for field in (\"ints\", \"dates\","
    ],
    [
        "for field in (\"ints\", \"dates\", \"timestamps\", \"timestamps_closed_bounds\"):",
        "for field in (\"ints\", \"dates\", \"timestamps\","
    ],
    [
        "\"The start of the range must not exceed the end of the range.\",",
        "\"The start of the range must not exceed the end"
    ],
    [
        "\"The start of the range must not exceed the end of the range.\",",
        "\"The start of the range must not exceed"
    ],
    [
        "\"The start of the range must not exceed the end of the range.\",",
        "\"The start of the range must not exceed the end of the"
    ],
    [
        "\"The start of the range must not exceed the end of the range.\",",
        "\"The start of the range must not"
    ],
    [
        "field=\"Gumby rides on the path of Middlesbrough\",",
        "field=\"Gumby rides on the path"
    ],
    [
        "field=\"Gumby rides on the path of Middlesbrough\",",
        "field=\"Gumby rides on the"
    ],
    [
        "search = \"Bat sat on cat.\"",
        "search = \"Bat sat"
    ],
    [
        "TextField has the same behavior as CharField regarding trigram lookups.",
        "TextField has the same behavior as CharField regarding"
    ],
    [
        "return isinstance(other, Tag) and self.tag_id == other.tag_id",
        "return isinstance(other, Tag) and"
    ],
    [
        "parent = models.ForeignKey(RangesModel, models.SET_NULL, blank=True, null=True)",
        "parent = models.ForeignKey(RangesModel, models.SET_NULL,"
    ],
    [
        "To test postgres-specific general aggregation functions",
        "To test postgres-specific general aggregation"
    ],
    [
        "To test postgres-specific aggregation functions for statistics",
        "To test postgres-specific aggregation functions"
    ],
    [
        "Indirection layer for PostgreSQL-specific fields, so the tests don't fail when",
        "Indirection layer for PostgreSQL-specific fields, so the tests don't fail"
    ],
    [
        "run with a backend other than PostgreSQL.",
        "run with a backend"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "return value.value if isinstance(value, enum.Enum) else value",
        "return value.value if isinstance(value,"
    ],
    [
        "self.assertTrue(all(isinstance(oid, int) for oid in oids))",
        "self.assertTrue(all(isinstance(oid, int) for"
    ],
    [
        "\"\"\"Registering type handlers for the nodb connection does nothing.\"\"\"",
        "\"\"\"Registering type handlers for the nodb connection does"
    ],
    [
        "All text copyright Python (Monty) Pictures. Thanks to sacred-texts.com for the",
        "All text copyright Python (Monty) Pictures."
    ],
    [
        "from .models import Character, Line, LineSavedSearch, Scene",
        "from .models import Character, Line, LineSavedSearch,"
    ],
    [
        "\"Bravely bold Sir Robin, rode forth from Camelot. \"",
        "\"Bravely bold Sir Robin, rode forth from Camelot."
    ],
    [
        "\"He was not afraid to die, o Brave Sir Robin. \"",
        "\"He was not afraid to die, o Brave Sir"
    ],
    [
        "\"He was not at all afraid to be killed in nasty ways. \"",
        "\"He was not at all afraid to be"
    ],
    [
        "\"Brave, brave, brave, brave Sir Robin\"",
        "\"Brave, brave, brave, brave"
    ],
    [
        "\"He was not in the least bit scared to be mashed into a pulp, \"",
        "\"He was not in the least bit scared to be mashed into"
    ],
    [
        "\"Or to have his eyes gouged out, and his elbows broken. \"",
        "\"Or to have his eyes gouged out, and his elbows"
    ],
    [
        "\"To have his kneecaps split, and his body burned away, \"",
        "\"To have his kneecaps split, and"
    ],
    [
        "\"And his limbs all hacked and mangled, brave Sir Robin!\"",
        "\"And his limbs all hacked and mangled, brave Sir"
    ],
    [
        "\"His head smashed in and his heart cut out, \"",
        "\"His head smashed in and his heart cut out,"
    ],
    [
        "\"And his liver removed and his bowels unplugged, \"",
        "\"And his liver removed and"
    ],
    [
        "\"And his nostrils ripped and his bottom burned off,\"",
        "\"And his nostrils ripped and his bottom"
    ],
    [
        "dialogue=\"We shall use my larger scales!\",",
        "dialogue=\"We shall use my"
    ],
    [
        "scene=cls.witch_scene, character=crowd, dialogue=\"A witch! A witch!\"",
        "scene=cls.witch_scene, character=crowd, dialogue=\"A witch! A"
    ],
    [
        "scene=cls.witch_scene, character=witch, dialogue=\"It's a fair cop.\"",
        "scene=cls.witch_scene, character=witch, dialogue=\"It's a fair"
    ],
    [
        "dialogue=\"Oh. Un beau cadeau. Oui oui.\",",
        "dialogue=\"Oh. Un beau cadeau. Oui"
    ],
    [
        "\"SearchVector can only be combined with other SearchVector \"",
        "\"SearchVector can only be combined with other SearchVector"
    ],
    [
        "| SearchQuery(\"rode forth from Camelot\", search_type=\"phrase\")",
        "| SearchQuery(\"rode forth from Camelot\","
    ],
    [
        "\"SearchQuery can only be combined with other SearchQuery \"",
        "\"SearchQuery can only be combined with"
    ],
    [
        "vector = SearchVector(\"dialogue\", weight=\"A\") + SearchVector(",
        "vector = SearchVector(\"dialogue\", weight=\"A\") +"
    ],
    [
        "vector = SearchVector(\"dialogue\", weight=\"D\") + SearchVector(",
        "vector = SearchVector(\"dialogue\", weight=\"D\") +"
    ],
    [
        "vector = SearchVector(\"dialogue\", weight=\"D\") + SearchVector(",
        "vector = SearchVector(\"dialogue\", weight=\"D\") +"
    ],
    [
        "\"Bravely taking to his feet, he beat a very brave retreat. \"",
        "\"Bravely taking to his feet, he beat a very brave retreat."
    ],
    [
        "\"A brave retreat brave Sir Robin.\"",
        "\"A brave retreat"
    ],
    [
        "dialogue=\"A brave retreat brave Sir Robin.\",",
        "dialogue=\"A brave retreat brave"
    ],
    [
        "dialogue=\"A brave retreat brave Sir Robin.\",",
        "dialogue=\"A brave retreat brave"
    ],
    [
        "& (SearchQuery(\"b\") & (SearchQuery(\"c\") | SearchQuery(\"d\"))),",
        "& (SearchQuery(\"b\") & (SearchQuery(\"c\") |"
    ],
    [
        "\"<b>Robin</b>. He was not at all afraid to be killed in nasty \"",
        "\"<b>Robin</b>. He was not at all afraid to be killed in"
    ],
    [
        "\"ways. <b>Brave</b>, <b>brave</b>, <b>brave</b>, <b>brave</b> \"",
        "\"ways. <b>Brave</b>, <b>brave</b>,"
    ],
    [
        "\"Robin. He was not at all afraid to be <b>killed</b> in nasty \"",
        "\"Robin. He was not at all afraid to be <b>killed</b> in"
    ],
    [
        "\"ways. Brave, brave, brave, brave Sir Robin\",",
        "\"ways. Brave, brave, brave, brave"
    ],
    [
        "\"Oh. Un beau <b>cadeau</b>. Oui oui.\",",
        "\"Oh. Un beau <b>cadeau</b>. Oui"
    ],
    [
        "\"Oh. Un beau <b>cadeau</b>. Oui oui.\",",
        "\"Oh. Un beau"
    ],
    [
        "\"<span>Robin</span>. He was not at all afraid to be killed in \"",
        "\"<span>Robin</span>. He was not at all"
    ],
    [
        "\"<b>Bravely</b> bold <b>Sir</b> <b>Robin</b>, rode forth from \"",
        "\"<b>Bravely</b> bold <b>Sir</b> <b>Robin</b>,"
    ],
    [
        "\"Camelot. He was not afraid to die, o \",",
        "\"Camelot. He was not afraid to"
    ],
    [
        "\"<b>Camelot</b>. He was not afraid to die, o Brave Sir Robin. He \"",
        "\"<b>Camelot</b>. He was not afraid to die, o"
    ],
    [
        "from django.test.utils import CaptureQueriesContext, modify_settings, override_settings",
        "from django.test.utils import"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "ValueError, \"Cannot serialize: %s\" % default.__class__.__name__",
        "ValueError, \"Cannot serialize: %s\""
    ],
    [
        "from django.core import checks, exceptions, serializers, validators",
        "from django.core import checks, exceptions,"
    ],
    [
        "from django.db import IntegrityError, connection, models",
        "from django.db import"
    ],
    [
        "from django.db.models.expressions import Exists, F, OuterRef, RawSQL, Value",
        "from django.db.models.expressions import Exists, F, OuterRef,"
    ],
    [
        "from django.db.models.functions import Cast, JSONObject, Upper",
        "from django.db.models.functions import"
    ],
    [
        "from django.test import TransactionTestCase, override_settings, skipUnlessDBFeature",
        "from django.test import TransactionTestCase, override_settings,"
    ],
    [
        "from . import PostgreSQLSimpleTestCase, PostgreSQLTestCase, PostgreSQLWidgetTestCase",
        "from . import PostgreSQLSimpleTestCase,"
    ],
    [
        "(((\"a\", \"b\"), (\"c\",)), \"(('a', 'b'), ('c',))\"),",
        "(((\"a\", \"b\"), (\"c\",)),"
    ],
    [
        "([[\"a\", \"b\"], [\"c\"]], \"[['a', 'b'], ['c']]\"),",
        "([[\"a\", \"b\"], [\"c\"]],"
    ],
    [
        "for lookup, value, expected in tests:",
        "for lookup, value, expected"
    ],
    [
        "qs, [{\"order\": obj.order, \"ids\": [obj.id]} for obj in reversed(self.objs)]",
        "qs, [{\"order\": obj.order, \"ids\": [obj.id]} for obj"
    ],
    [
        "\"ArrayField default should be a callable instead of an \"",
        "\"ArrayField default should be a callable instead of an"
    ],
    [
        "\"instance so that it's not shared between all field \"",
        "\"instance so that it's not shared between all"
    ],
    [
        "hint=\"Use a callable instead, e.g., use `list` instead of `[]`.\",",
        "hint=\"Use a callable instead, e.g., use"
    ],
    [
        "[([\"vinyl\", \"cd\"], \"Audio\"), ((\"vhs\", \"dvd\"), \"Video\")],",
        "[([\"vinyl\", \"cd\"], \"Audio\"), ((\"vhs\","
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "ArrayField shouldn't have varchar_patterns_ops or text_patterns_ops indexes.",
        "ArrayField shouldn't have varchar_patterns_ops or text_patterns_ops"
    ],
    [
        "field_values = [[\"Django\", \"Python\", None], [\"Джанго\", \"פייתון\", None, \"król\"]]",
        "field_values = [[\"Django\", \"Python\", None], [\"Джанго\", \"פייתון\","
    ],
    [
        "[{\"model\": \"postgres_tests.chararraymodel\", \"pk\": None, \"fields\": fields}]",
        "[{\"model\": \"postgres_tests.chararraymodel\", \"pk\": None, \"fields\":"
    ],
    [
        "self.assertEqual(form.errors, {\"array\": [\"This field is required.\"]})",
        "self.assertEqual(form.errors, {\"array\": [\"This"
    ],
    [
        "for initial, data, expected_result in tests:",
        "for initial, data, expected_result"
    ],
    [
        "for initial, data, expected_result in tests:",
        "for initial, data, expected_result"
    ],
    [
        "from django.db import IntegrityError, NotSupportedError, connection, transaction",
        "from django.db import IntegrityError,"
    ],
    [
        "from django.db.models import CheckConstraint, Index, Q, UniqueConstraint",
        "from django.db.models import CheckConstraint,"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests.\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "\"The AddIndexConcurrently operation cannot be executed inside \"",
        "\"The AddIndexConcurrently operation cannot be"
    ],
    [
        "\"a transaction (set atomic = False on the migration).\"",
        "\"a transaction (set atomic = False on the"
    ],
    [
        "\"Concurrently create index pony_pink_idx on field(s) pink of model Pony\",",
        "\"Concurrently create index pony_pink_idx on field(s) pink of"
    ],
    [
        "\"+ Concurrently create index pony_pink_idx on field(s) pink of model Pony\",",
        "\"+ Concurrently create index pony_pink_idx on field(s) pink of model"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests.\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\","
    ],
    [
        "\"The RemoveIndexConcurrently operation cannot be executed inside \"",
        "\"The RemoveIndexConcurrently operation cannot be executed inside"
    ],
    [
        "\"a transaction (set atomic = False on the migration).\"",
        "\"a transaction (set atomic = False on the"
    ],
    [
        "\"Concurrently remove index pony_pink_idx from Pony\",",
        "\"Concurrently remove index pony_pink_idx"
    ],
    [
        "\"- Concurrently remove index pony_pink_idx from Pony\",",
        "\"- Concurrently remove index pony_pink_idx"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests.\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests.\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests.\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\","
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests.\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "msg = \"AddConstraintNotValid.constraint must be a check constraint.\"",
        "msg = \"AddConstraintNotValid.constraint must"
    ],
    [
        "f\"Create not valid constraint {constraint_name} on model Pony\",",
        "f\"Create not valid constraint {constraint_name} on"
    ],
    [
        "f\"+ Create not valid constraint {constraint_name} on model Pony\",",
        "f\"+ Create not valid constraint {constraint_name} on model"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests.\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "f\"Validate constraint {constraint_name} on model Pony\",",
        "f\"Validate constraint {constraint_name} on"
    ],
    [
        "f\"~ Validate constraint {constraint_name} on model Pony\",",
        "f\"~ Validate constraint {constraint_name} on model"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, modify_settings",
        "from django.test import SimpleTestCase,"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "self.skipTest(\"The default text search config is not 'english'.\")",
        "self.skipTest(\"The default text search config is"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific tests\")",
        "@unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific"
    ],
    [
        "from django.db.models.functions import Cast, Concat, LPad, Substr",
        "from django.db.models.functions import Cast, Concat, LPad,"
    ],
    [
        "from .models import AggregateTestModel, HotelReservation, Room, StatTestModel",
        "from .models import AggregateTestModel,"
    ],
    [
        "msg = \"The ordering argument is deprecated. Use order_by instead.\"",
        "msg = \"The ordering argument is deprecated. Use"
    ],
    [
        "\"Cannot specify both order_by and ordering.\",",
        "\"Cannot specify both order_by and"
    ],
    [
        "self.assertEqual(values, {\"arrayagg\": [True, False, False, True]})",
        "self.assertEqual(values, {\"arrayagg\": [True,"
    ],
    [
        "requirements={\"double_bed\": False, \"sea_view\": True, \"parking\": False},",
        "requirements={\"double_bed\": False, \"sea_view\": True,"
    ],
    [
        "{\"double_bed\": False, \"sea_view\": True, \"parking\": False},",
        "{\"double_bed\": False, \"sea_view\": True, \"parking\":"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"Both y and x must be provided.\"):",
        "with self.assertRaisesMessage(ValueError, \"Both y and x"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"Complex aggregates require an alias\"):",
        "with self.assertRaisesMessage(TypeError, \"Complex aggregates require"
    ],
    [
        "msg = \"RegrCount does not allow default.\"",
        "msg = \"RegrCount does"
    ],
    [
        "This is more complex test to check if JOIN on field and",
        "This is more complex test to check if JOIN on field"
    ],
    [
        "number as argument works as expected.",
        "number as argument"
    ],
    [
        "from django.core import checks, exceptions, serializers",
        "from django.core import checks,"
    ],
    [
        "from django.db.models import F, OuterRef, Subquery",
        "from django.db.models import"
    ],
    [
        "expr = RawSQL(\"%s::hstore\", [\"x => b, y => c\"])",
        "expr = RawSQL(\"%s::hstore\", [\"x => b,"
    ],
    [
        "[\"b\", \"b\", None, None, None, None, None, None, None],",
        "[\"b\", \"b\", None, None, None, None,"
    ],
    [
        "\"HStoreField default should be a callable instead of an \"",
        "\"HStoreField default should be a callable instead of an"
    ],
    [
        "\"instance so that it's not shared between all field \"",
        "\"instance so that it's not"
    ],
    [
        "hint=\"Use a callable instead, e.g., use `dict` instead of `{}`.\",",
        "hint=\"Use a callable instead, e.g., use `dict` instead of"
    ],
    [
        "({\"a\": \"b\"}, [{\"a\": \"b\"}, {\"b\": \"a\"}]),",
        "({\"a\": \"b\"}, [{\"a\": \"b\"}, {\"b\":"
    ],
    [
        "[json.dumps(item, ensure_ascii=False) for item in array_field_value],",
        "[json.dumps(item, ensure_ascii=False) for item in"
    ],
    [
        "[{\"model\": \"postgres_tests.hstoremodel\", \"pk\": None, \"fields\": fields}]",
        "[{\"model\": \"postgres_tests.hstoremodel\", \"pk\": None,"
    ],
    [
        "{\"Енеїда\": \"Ти знаєш, він який суціга\", \"Зефір\": None},",
        "{\"Енеїда\": \"Ти знаєш, він який суціга\","
    ],
    [
        "\"The value of “a” is not a string or null.\",",
        "\"The value of “a” is"
    ],
    [
        "msg = \"Input must be a JSON dictionary.\"",
        "msg = \"Input must be a JSON"
    ],
    [
        "validator({\"a\": \"foo\", \"b\": \"bar\", \"c\": \"baz\"})",
        "validator({\"a\": \"foo\", \"b\": \"bar\","
    ],
    [
        "validator({\"a\": \"foo\", \"b\": \"bar\", \"c\": \"baz\"})",
        "validator({\"a\": \"foo\", \"b\":"
    ],
    [
        "validator = KeysValidator(keys=[\"a\", \"b\"], strict=True, messages=messages)",
        "validator = KeysValidator(keys=[\"a\", \"b\"],"
    ],
    [
        "validator({\"a\": \"foo\", \"b\": \"bar\", \"c\": \"baz\"})",
        "validator({\"a\": \"foo\", \"b\": \"bar\","
    ],
    [
        "validator = KeysValidator(keys=[\"a\", \"b\"], strict=True, messages=messages)",
        "validator = KeysValidator(keys=[\"a\", \"b\"], strict=True,"
    ],
    [
        "kwargs, {\"keys\": [\"a\", \"b\"], \"strict\": True, \"messages\": messages}",
        "kwargs, {\"keys\": [\"a\", \"b\"],"
    ],
    [
        "from django.db import IntegrityError, connection, transaction",
        "from django.db import"
    ],
    [
        "from django.db.models.functions import Cast, Left, Lower",
        "from django.db.models.functions import Cast, Left,"
    ],
    [
        "from .models import HotelReservation, IntegerArrayModel, RangesModel, Room, Scene",
        "from .models import HotelReservation,"
    ],
    [
        "SELECT opcname, c.relname FROM pg_opclass AS oc",
        "SELECT opcname, c.relname FROM pg_opclass AS"
    ],
    [
        "JOIN pg_index as i on oc.oid = ANY(i.indclass)",
        "JOIN pg_index as i on oc.oid ="
    ],
    [
        "JOIN pg_class as c on c.oid = i.indexrelid",
        "JOIN pg_class as c on"
    ],
    [
        "\"\"\"Get the constraints on the table using a new cursor.\"\"\"",
        "\"\"\"Get the constraints on the table using a new"
    ],
    [
        "msg = f\"Constraint “{constraint.name}” is violated.\"",
        "msg = f\"Constraint"
    ],
    [
        "msg = f\"Constraint “{constraint.name}” is violated.\"",
        "msg = f\"Constraint"
    ],
    [
        "msg = f\"Constraint “{constraint.name}” is violated.\"",
        "msg = f\"Constraint"
    ],
    [
        "msg = f\"Constraint “{constraint.name}” is violated.\"",
        "msg = f\"Constraint “{constraint.name}” is"
    ],
    [
        "msg = f\"Constraint “{constraint_name}” is violated.\"",
        "msg = f\"Constraint “{constraint_name}” is"
    ],
    [
        "\"\"\"Get the constraints on the table using a new cursor.\"\"\"",
        "\"\"\"Get the constraints on the table using a"
    ],
    [
        "msg = \"ExclusionConstraint.condition must be a Q instance.\"",
        "msg = \"ExclusionConstraint.condition must"
    ],
    [
        "msg = \"Exclusion constraints only support GiST or SP-GiST indexes.\"",
        "msg = \"Exclusion constraints only support GiST"
    ],
    [
        "msg = \"At least one expression is required to define an exclusion constraint.\"",
        "msg = \"At least one expression is required to define"
    ],
    [
        "msg = \"ExclusionConstraint.deferrable must be a Deferrable instance.\"",
        "msg = \"ExclusionConstraint.deferrable must"
    ],
    [
        "msg = \"ExclusionConstraint.include must be a list or tuple.\"",
        "msg = \"ExclusionConstraint.include must be a"
    ],
    [
        "\"'constraints' refers to the nonexistent field 'nonexistent'.\",",
        "\"'constraints' refers to the nonexistent field"
    ],
    [
        "\"'constraints' refers to the joined field 'author__alias'.\",",
        "\"'constraints' refers to the joined"
    ],
    [
        "\"'constraints' refers to the joined field 'author__name'.\",",
        "\"'constraints' refers to the"
    ],
    [
        "msg = f\"Constraint “{constraint.name}” is violated.\"",
        "msg = f\"Constraint “{constraint.name}”"
    ],
    [
        "cursor.execute(\"SET CONSTRAINTS %s IMMEDIATE\" % quoted_name)",
        "cursor.execute(\"SET CONSTRAINTS %s"
    ],
    [
        "msg = \"Constraint “ints_equal” is violated.\"",
        "msg = \"Constraint “ints_equal”"
    ],
    [
        "The test case puts everything under a transaction, so two models",
        "The test case puts everything under a"
    ],
    [
        "updated with a short gap should have the same time.",
        "updated with a short gap should have the"
    ],
    [
        "from django.db.models import CharField, F, Index, Q",
        "from django.db.models import CharField, F,"
    ],
    [
        "from django.db.models.functions import Cast, Collate, Length, Lower",
        "from django.db.models.functions import Cast, Collate,"
    ],
    [
        "from .models import CharFieldModel, IntegerArrayModel, Scene, TextFieldModel",
        "from .models import CharFieldModel, IntegerArrayModel, Scene,"
    ],
    [
        "{\"fields\": [\"title\"], \"name\": \"test_title_%s\" % self.index_class.suffix},",
        "{\"fields\": [\"title\"], \"name\": \"test_title_%s\""
    ],
    [
        "msg = \"BloomIndex.columns must be a list or tuple.\"",
        "msg = \"BloomIndex.columns must be a list or"
    ],
    [
        "msg = \"BloomIndex.columns cannot have more values than fields.\"",
        "msg = \"BloomIndex.columns cannot have more values than"
    ],
    [
        "ValueError, \"pages_per_range must be None or a positive integer\"",
        "ValueError, \"pages_per_range must be None or a"
    ],
    [
        "SELECT opcname, c.relname FROM pg_opclass AS oc",
        "SELECT opcname, c.relname FROM"
    ],
    [
        "JOIN pg_index as i on oc.oid = ANY(i.indclass)",
        "JOIN pg_index as i on oc.oid"
    ],
    [
        "JOIN pg_class as c on c.oid = i.indexrelid",
        "JOIN pg_class as c on c.oid"
    ],
    [
        "Get the indexes on the table using a new cursor.",
        "Get the indexes on the table using"
    ],
    [
        "\"\"\"SearchVector generates IMMUTABLE SQL in order to be indexable.\"\"\"",
        "\"\"\"SearchVector generates IMMUTABLE SQL in order to"
    ],
    [
        "index = Index(SearchVector(\"id\", \"scene\", config=\"english\"), name=index_name)",
        "index = Index(SearchVector(\"id\", \"scene\","
    ],
    [
        "def create_sql(self, model, schema_editor, using=\"gin\", **kwargs):",
        "def create_sql(self, model,"
    ],
    [
        "def create_sql(self, model, schema_editor, using=\"\", **kwargs):",
        "def create_sql(self, model, schema_editor,"
    ],
    [
        "self.skipTest(\"This backend does not support case-insensitive collations.\")",
        "self.skipTest(\"This backend does not support"
    ],
    [
        "for Model, field, initial, new in test_data:",
        "for Model, field, initial, new"
    ],
    [
        "Unaccent can be used chained with a lookup (which should be the case",
        "Unaccent can be used chained with a lookup (which"
    ],
    [
        "since unaccent implements the Transform API)",
        "since unaccent implements the Transform"
    ],
    [
        "\"\"\"SQL is valid when standard_conforming_strings is off.\"\"\"",
        "\"\"\"SQL is valid when standard_conforming_strings"
    ],
    [
        "TextField should have the exact same behavior as CharField",
        "TextField should have the exact"
    ],
    [
        "To perform an OR lookup, or a lookup that combines ANDs and ORs, combine",
        "To perform an OR lookup, or a lookup"
    ],
    [
        "``QuerySet`` objects using ``&`` and ``|`` operators.",
        "``QuerySet`` objects using ``&`` and"
    ],
    [
        "Alternatively, use positional arguments, and pass one or more expressions of",
        "Alternatively, use positional arguments, and pass one or more"
    ],
    [
        "self.assertEqual(repr(or_expr), \"<Q: (AND: ('baz', <Article: Foö>))>\")",
        "self.assertEqual(repr(or_expr), \"<Q: (AND: ('baz', <Article:"
    ],
    [
        "self.assertEqual(repr(negated_or), \"<Q: (NOT (AND: ('baz', <Article: Foö>)))>\")",
        "self.assertEqual(repr(negated_or), \"<Q: (NOT (AND:"
    ],
    [
        "Queries are not redone when going back through known relations.",
        "Queries are not redone when going back through"
    ],
    [
        "from .models import Organiser, Pool, PoolStyle, Tournament",
        "from .models import Organiser, Pool,"
    ],
    [
        "related_objects = {pool.tournament for pool in pools}",
        "related_objects = {pool.tournament for pool"
    ],
    [
        "related_objects = {pool.tournament for pool in pools}",
        "related_objects = {pool.tournament for pool in"
    ],
    [
        "related_objects = {pool.tournament for pool in pools}",
        "related_objects = {pool.tournament for pool in"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label,"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "from .models import Album, Band, ReleaseEvent, VideoStream",
        "from .models import Album,"
    ],
    [
        "'<option value=\"%s\" selected>The Beatles</option>' % beatles.uuid",
        "'<option value=\"%s\" selected>The"
    ],
    [
        "option = '<option value=\"%s\">The Who</option>' % who.uuid",
        "option = '<option value=\"%s\">The"
    ],
    [
        "'<option value=\"%s\" selected>The Beatles</option>' % beatles.pk",
        "'<option value=\"%s\" selected>The"
    ],
    [
        "option = '<option value=\"%s\" selected>The Who</option>' % who.pk",
        "option = '<option value=\"%s\" selected>The Who</option>'"
    ],
    [
        "\"\"\"Empty option is present if the field isn't required.\"\"\"",
        "\"\"\"Empty option is present if the"
    ],
    [
        "\"\"\"Empty option isn't present if the field isn't required.\"\"\"",
        "\"\"\"Empty option isn't present if"
    ],
    [
        "'<option value=\"%s\" selected>Test Target</option>' % release_event.pk",
        "'<option value=\"%s\" selected>Test Target</option>'"
    ],
    [
        "Used to check that autocomplete widget correctly resolves attname for FK as",
        "Used to check that autocomplete widget correctly resolves attname for FK"
    ],
    [
        "return \"%s %s\" % (self.make, self.model)",
        "return \"%s %s\" %"
    ],
    [
        "A single car tire. This to test that a user can only select their own cars.",
        "A single car tire. This to test that"
    ],
    [
        "A model with a FK to a model that won't be registered with the admin",
        "A model with a FK to a model that won't be registered"
    ],
    [
        "(Honeycomb) so the corresponding raw ID widget won't have a magnifying",
        "(Honeycomb) so the corresponding raw ID widget won't"
    ],
    [
        "glass link to select related honeycomb instances.",
        "glass link to select related"
    ],
    [
        "A model with a FK to itself. It won't be registered with the admin, so the",
        "A model with a FK to itself. It won't be registered with the admin,"
    ],
    [
        "corresponding raw ID widget won't have a magnifying glass link to select",
        "corresponding raw ID widget won't have a magnifying glass link"
    ],
    [
        "related instances (rendering will be called programmatically in this case).",
        "related instances (rendering will be called programmatically"
    ],
    [
        "(Company) so the corresponding raw ID widget won't have a magnifying",
        "(Company) so the corresponding raw ID widget"
    ],
    [
        "glass link to select related company instances.",
        "glass link to select"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, override_settings",
        "from django.test import"
    ],
    [
        "from .widgetadmin import site as widget_admin_site",
        "from .widgetadmin import site as"
    ],
    [
        "Tests for correct behavior of ModelAdmin.formfield_for_dbfield",
        "Tests for correct behavior"
    ],
    [
        "def assertFormfield(self, model, fieldname, widgetclass, **admin_overrides):",
        "def assertFormfield(self, model, fieldname, widgetclass,"
    ],
    [
        "Helper to call formfield_for_dbfield for a given model and field name",
        "Helper to call formfield_for_dbfield for a given model"
    ],
    [
        "and verify that the returned formfield is appropriate.",
        "and verify that the returned"
    ],
    [
        "Widget instances in formfield_overrides are not shared between",
        "Widget instances in formfield_overrides are not shared"
    ],
    [
        "filter_horizontal widgets for ManyToManyFields may be overridden by",
        "filter_horizontal widgets for ManyToManyFields"
    ],
    [
        "Overriding the widget for DateTimeField doesn't overrides the default",
        "Overriding the widget for DateTimeField doesn't"
    ],
    [
        "formfield_overrides works for a custom field class.",
        "formfield_overrides works for a custom"
    ],
    [
        "\"Hold down “Control”, or “Command” on a Mac, to select more than one.\",",
        "\"Hold down “Control”, or “Command” on a"
    ],
    [
        "Ensure the user can only see their own cars in the foreign key dropdown.",
        "Ensure the user can only see their own cars in the"
    ],
    [
        "\"Select a valid choice. That choice is not one of the available choices.\",",
        "\"Select a valid choice. That choice is not one of the"
    ],
    [
        "\"Select a valid choice. That choice is not one of the available \"",
        "\"Select a valid choice. That choice is"
    ],
    [
        "w.render(\"test\", \"\"), '<input class=\"vURLField\" name=\"test\" type=\"url\">'",
        "w.render(\"test\", \"\"), '<input class=\"vURLField\""
    ],
    [
        "WARNING: This test doesn't use assertHTMLEqual since it will get rid",
        "WARNING: This test doesn't use assertHTMLEqual since it"
    ],
    [
        "of some escapes which are tested here!",
        "of some escapes which are tested"
    ],
    [
        "File widgets should render as a link when they're marked \"read only.\"",
        "File widgets should render as a link when"
    ],
    [
        "\"</strong></div>\" % {\"banduuid\": band.uuid, \"bandpk\": band.pk},",
        "\"</strong></div>\" % {\"banduuid\": band.uuid,"
    ],
    [
        "Pressing the ESC key or clicking on a widget value closes the date and",
        "Pressing the ESC key or clicking on a widget value closes"
    ],
    [
        "Ensure cells that are not days of the month have the `nonday` CSS class.",
        "Ensure cells that are not days of"
    ],
    [
        "Ensure cell for the day in the input has the `selected` CSS class.",
        "Ensure cell for the day in the"
    ],
    [
        "Ensure no cells are given the selected class when the field is empty.",
        "Ensure no cells are given the selected class when the"
    ],
    [
        "selected = [td for td in tds if td.get_attribute(\"class\") == \"selected\"]",
        "selected = [td for td in tds if td.get_attribute(\"class\") =="
    ],
    [
        "The calendar shows the date from the input field for every locale",
        "The calendar shows the date from the input field"
    ],
    [
        "date/time/datetime picker shortcuts work in the current time zone.",
        "date/time/datetime picker shortcuts work in the current time"
    ],
    [
        "This test case is fairly tricky, it relies on selenium still running the browser",
        "This test case is fairly tricky, it relies on selenium still running"
    ],
    [
        "in the default time zone \"America/Chicago\" despite `override_settings` changing",
        "in the default time zone \"America/Chicago\" despite `override_settings`"
    ],
    [
        "By.CSS_SELECTOR, from_box + \" > option\"",
        "By.CSS_SELECTOR, from_box +"
    ],
    [
        "By.CSS_SELECTOR, to_box + \" > option\"",
        "By.CSS_SELECTOR, to_box + \" >"
    ],
    [
        "Typing in the search box filters out options displayed in the 'from'",
        "Typing in the search box filters out options"
    ],
    [
        "input = self.selenium.find_element(By.ID, \"id_%s_input\" % field_name)",
        "input = self.selenium.find_element(By.ID, \"id_%s_input\""
    ],
    [
        "Some browsers had a bug where navigating away from the change page",
        "Some browsers had a bug where navigating"
    ],
    [
        "and then clicking the browser's back button would clear the",
        "and then clicking the browser's back button would clear"
    ],
    [
        "Horizontal and vertical filter widgets keep selected options on page",
        "Horizontal and vertical filter widgets keep"
    ],
    [
        "\"li.success\", \"The profile “changednewuser” was added successfully.\"",
        "\"li.success\", \"The profile “changednewuser” was added"
    ],
    [
        "\"Upload a valid image. The file you uploaded was either not an image \"",
        "\"Upload a valid image. The file you uploaded"
    ],
    [
        "[p.name for p in result], [\"Django Plushie\", \"Talking Django Plushie\"]",
        "[p.name for p in result], [\"Django Plushie\", \"Talking"
    ],
    [
        "Rverse related fields should be listed in the validation message when an",
        "Rverse related fields should be listed in"
    ],
    [
        "invalid field is given in select_related().",
        "invalid field is given"
    ],
    [
        "\"Non-relational field given in select_related: '%s'. Choices are: %s\"",
        "\"Non-relational field given in select_related: '%s'. Choices"
    ],
    [
        "\"Invalid field name(s) given in select_related: '%s'. Choices are: %s\"",
        "\"Invalid field name(s) given in"
    ],
    [
        "version = models.ForeignKey(Version, models.SET_NULL, blank=True, null=True)",
        "version = models.ForeignKey(Version, models.SET_NULL,"
    ],
    [
        "location = models.ForeignKey(Location, models.SET_NULL, blank=True, null=True)",
        "location = models.ForeignKey(Location,"
    ],
    [
        "from django.db import connection, models, transaction",
        "from django.db import connection, models,"
    ],
    [
        "Django cascades deletes through generic-related objects to their",
        "Django cascades deletes through generic-related objects to"
    ],
    [
        "some other model has an FK to that through model, deletion is cascaded",
        "some other model has an FK to that through model, deletion"
    ],
    [
        "Auto-created many-to-many through tables referencing a parent model are",
        "Auto-created many-to-many through tables referencing"
    ],
    [
        "correctly found by the delete cascade when a child of that parent is",
        "correctly found by the delete cascade when"
    ],
    [
        "Cascade deletion works with ForeignKey.to_field set to non-PK.",
        "Cascade deletion works with ForeignKey.to_field set to"
    ],
    [
        "If the number of objects > chunk size, deletion still occurs.",
        "If the number of objects >"
    ],
    [
        "Tests on_delete behavior for proxy models.",
        "Tests on_delete behavior"
    ],
    [
        "\"\"\"Return an Image referenced by both a FooImage and a FooFile.\"\"\"",
        "\"\"\"Return an Image referenced by both"
    ],
    [
        "Deleting the *proxy* instance bubbles through to its non-proxy and",
        "Deleting the *proxy* instance bubbles through to its"
    ],
    [
        "Deleting a proxy-of-proxy instance should bubble through to its proxy",
        "Deleting a proxy-of-proxy instance should bubble through to"
    ],
    [
        "and non-proxy parents, deleting *all* referring objects.",
        "and non-proxy parents, deleting"
    ],
    [
        "Deleting an instance of a concrete model should also delete objects",
        "Deleting an instance of a concrete model should also delete"
    ],
    [
        "If a pair of proxy models are linked by an FK from one concrete parent",
        "If a pair of proxy models are linked by an"
    ],
    [
        "to the other, deleting one proxy model cascade-deletes the other, and",
        "to the other, deleting one proxy model"
    ],
    [
        "the deletion happens in the right order (not triggering an",
        "the deletion happens in the right order (not triggering"
    ],
    [
        "IntegrityError on databases unable to defer integrity checks).",
        "IntegrityError on databases unable"
    ],
    [
        "msg = \"Cannot call delete() after .values() or .values_list()\"",
        "msg = \"Cannot call delete() after .values()"
    ],
    [
        "Test different queries which alter the SELECT clause of the query. We",
        "Test different queries which alter the SELECT clause of the query."
    ],
    [
        "also must be using a subquery for the deletion (that is, the original",
        "also must be using a subquery for the deletion (that is, the"
    ],
    [
        "query has a join in it). The deletion should be done as \"fast-path\"",
        "query has a join in it). The deletion should be"
    ],
    [
        "deletion (that is, just one query for the .delete() call).",
        "deletion (that is, just one query for the .delete()"
    ],
    [
        "Note that .values() is not tested here on purpose. .values().delete()",
        "Note that .values() is not tested here on"
    ],
    [
        "doesn't work for non fast-path deletes at all.",
        "doesn't work for non"
    ],
    [
        "With a model (Researcher) that has two foreign keys pointing to the",
        "With a model (Researcher) that has two foreign keys"
    ],
    [
        "same model (Contact), deleting an instance of the target model",
        "same model (Contact), deleting an instance"
    ],
    [
        "msg = \"Cannot call delete() after .distinct(*fields).\"",
        "msg = \"Cannot call delete()"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "from django.core.management.commands.makemessages import Command as MakeMessagesCommand",
        "from django.core.management.commands.makemessages import"
    ],
    [
        "from .utils import POFileAssertionMixin, RunInTmpDirMixin, copytree",
        "from .utils import"
    ],
    [
        "@skipUnless(has_xgettext, \"xgettext is mandatory for extraction tests\")",
        "@skipUnless(has_xgettext, \"xgettext is mandatory for"
    ],
    [
        "return self.assertTrue(not re.search(\"^msgid %s\" % msgid, s, re.MULTILINE))",
        "return self.assertTrue(not re.search(\"^msgid %s\" % msgid,"
    ],
    [
        "cwd_prefix = \"%s%s\" % (os.curdir, os.sep)",
        "cwd_prefix = \"%s%s\" %"
    ],
    [
        "po_contents, pattern, '\"%s\" not found in final .po file.' % needle",
        "po_contents, pattern, '\"%s\" not found in final .po"
    ],
    [
        "po_contents, pattern, '\"%s\" shouldn\\'t be in final .po file.' % needle",
        "po_contents, pattern, '\"%s\" shouldn\\'t be in final .po file.' %"
    ],
    [
        "\"The token '%s' could not be found in %s, please check the test config\"",
        "\"The token '%s' could not be found in %s,"
    ],
    [
        "verifies that the django.po file has a gettext-style location comment",
        "verifies that the django.po file"
    ],
    [
        "None can be passed for the line_number argument to skip checking of",
        "None can be passed for the line_number argument to skip checking"
    ],
    [
        "A string token can also be passed as line_number, in which case it",
        "A string token can also be passed as line_number, in which"
    ],
    [
        "will be searched in the template, and its line number will be used.",
        "will be searched in the template, and its line"
    ],
    [
        "A msgid is a suitable candidate.",
        "A msgid is a"
    ],
    [
        "Assert that file was recently modified (modification time was less than",
        "Assert that file was recently modified (modification"
    ],
    [
        "Assert that file was not recently modified (modification time was more",
        "Assert that file was not recently modified (modification time"
    ],
    [
        "msg = \"Type 'manage.py help makemessages' for usage information.\"",
        "msg = \"Type 'manage.py help makemessages' for"
    ],
    [
        "self.assertIn(\"invalid locale PL, did you mean pl?\", out.getvalue())",
        "self.assertIn(\"invalid locale PL, did you mean pl?\","
    ],
    [
        "self.assertIn(\"invalid locale pl-PL, did you mean pl_PL?\", out.getvalue())",
        "self.assertIn(\"invalid locale pl-PL, did you"
    ],
    [
        "self.assertIn(\"invalid locale pl_pl, did you mean pl_PL?\", out.getvalue())",
        "self.assertIn(\"invalid locale pl_pl, did you mean pl_PL?\","
    ],
    [
        "\"invalid locale nl-nl-x-informal, did you mean nl_NL-x-informal?\",",
        "\"invalid locale nl-nl-x-informal, did you"
    ],
    [
        "self.assertIn(\"invalid locale en+GB, did you mean en_GB?\", out.getvalue())",
        "self.assertIn(\"invalid locale en+GB, did"
    ],
    [
        "self.assertNotIn(\"This comment should not be extracted\", po_contents)",
        "self.assertNotIn(\"This comment should not"
    ],
    [
        "self.assertNotMsgId(\"Text with a few line breaks.\", po_contents)",
        "self.assertNotMsgId(\"Text with a few line breaks.\","
    ],
    [
        "\"Again some text with a few line breaks, this time should be trimmed.\",",
        "\"Again some text with a few line breaks,"
    ],
    [
        "self.PO_FILE, \"Get my line number\", \"templates\", \"test.html\"",
        "self.PO_FILE, \"Get my line number\", \"templates\","
    ],
    [
        "\"Translation blocks must not include other block tags: blocktranslate \"",
        "\"Translation blocks must not include"
    ],
    [
        "\"\"\"test xgettext warning about multiple bare interpolation placeholders\"\"\"",
        "\"\"\"test xgettext warning about multiple bare"
    ],
    [
        "Message contexts are correctly extracted for the {% translate %} and",
        "Message contexts are correctly extracted for the"
    ],
    [
        "self.assertIn('msgctxt \"Context wrapped in double quotes\"', po_contents)",
        "self.assertIn('msgctxt \"Context wrapped in double"
    ],
    [
        "self.assertIn('msgctxt \"Context wrapped in single quotes\"', po_contents)",
        "self.assertIn('msgctxt \"Context wrapped in single"
    ],
    [
        "'msgctxt \"Special blocktranslate context wrapped in double quotes\"',",
        "'msgctxt \"Special blocktranslate context wrapped"
    ],
    [
        "'msgctxt \"Special blocktranslate context wrapped in single quotes\"',",
        "'msgctxt \"Special blocktranslate context"
    ],
    [
        "r\"was ignored, because it wasn't the last item on the line\\.\",",
        "r\"was ignored, because it wasn't the"
    ],
    [
        "r\"was ignored, because it wasn't the last item on the line\\.\",",
        "r\"was ignored, because it wasn't the last item on"
    ],
    [
        "r\"was ignored, because it wasn't the last item on the line\\.\",",
        "r\"was ignored, because it wasn't the last item on the"
    ],
    [
        "find_files only discover files having the proper extensions.",
        "find_files only discover files having"
    ],
    [
        "cmd.ignore_patterns = [\"CVS\", \".*\", \"*~\", \"*.pyc\"]",
        "cmd.ignore_patterns = [\"CVS\","
    ],
    [
        "\"This is free software: you are free to change and redistribute it.\\n\"",
        "\"This is free software: you are free to"
    ],
    [
        "\"There is NO WARRANTY, to the extent permitted by law.\\n\"",
        "\"There is NO WARRANTY, to"
    ],
    [
        "CommandError, \"Unable to get gettext version. Is it installed?\"",
        "CommandError, \"Unable to get gettext version. Is it"
    ],
    [
        "shutil.copyfile(BR_PO_BASE + \".pristine\", BR_PO_BASE + \".po\")",
        "shutil.copyfile(BR_PO_BASE + \".pristine\","
    ],
    [
        "self.assertMsgId(\"This literal should be included.\", po_contents)",
        "self.assertMsgId(\"This literal should"
    ],
    [
        "\"/* but this one will be too */ 'cause there is no way of telling...\",",
        "\"/* but this one will be too */ 'cause there is no"
    ],
    [
        "\"Static content inside app should be included.\", po_contents",
        "\"Static content inside app should be"
    ],
    [
        "\"Content from STATIC_ROOT should not be included\", po_contents",
        "\"Content from STATIC_ROOT should not"
    ],
    [
        "self.assertMsgId(\"Static content inside app should be included.\", po_contents)",
        "self.assertMsgId(\"Static content inside app should"
    ],
    [
        "self.assertMsgId(\"This literal should be included.\", po_contents)",
        "self.assertMsgId(\"This literal should be included.\","
    ],
    [
        "self.assertNotMsgId(\"This subdir should be ignored too.\", po_contents)",
        "self.assertNotMsgId(\"This subdir should be ignored too.\","
    ],
    [
        "self.assertNotMsgId(\"This should be ignored too.\", po_contents)",
        "self.assertNotMsgId(\"This should be"
    ],
    [
        "\"os.symlink() not available on this OS + Python version combination.\"",
        "\"os.symlink() not available on this OS + Python version"
    ],
    [
        "self.assertMsgId(\"This literal should be included.\", po_contents)",
        "self.assertMsgId(\"This literal should be"
    ],
    [
        "Ensures a correct workaround for the gettext bug when handling a literal",
        "Ensures a correct workaround for the gettext bug when handling a"
    ],
    [
        "found inside a {% translate %} tag and also in another file inside a",
        "found inside a {% translate %} tag and also in another file"
    ],
    [
        "\"First `translate`, then `blocktranslate` with a plural\", po_contents",
        "\"First `translate`, then `blocktranslate` with a"
    ],
    [
        "\"Plural for a `translate` and `blocktranslate` collision case\",",
        "\"Plural for a `translate` and `blocktranslate`"
    ],
    [
        "\"This literal should also be included wrapped or not wrapped \"",
        "\"This literal should also be included wrapped or not"
    ],
    [
        "\"depending on the use of the --no-wrap option.\",",
        "\"depending on the use of"
    ],
    [
        "'\"\"\\n\"This literal should also be included wrapped or not '",
        "'\"\"\\n\"This literal should also be"
    ],
    [
        "'wrapped depending on the \"\\n\"use of the --no-wrap option.\"',",
        "'wrapped depending on the \"\\n\"use of"
    ],
    [
        "\"\"\"Behavior is correct if --no-location switch isn't specified.\"\"\"",
        "\"\"\"Behavior is correct if --no-location"
    ],
    [
        "self.assertMsgId(\"This is a translatable string.\", po_contents)",
        "self.assertMsgId(\"This is a"
    ],
    [
        "self.assertMsgStr(\"This is a translated string.\", po_contents)",
        "self.assertMsgStr(\"This is a"
    ],
    [
        "When the `locale` flag is absent, all dirs from the parent locale dir",
        "When the `locale` flag is absent, all dirs from"
    ],
    [
        "are considered as language directories, except if the directory doesn't",
        "are considered as language directories, except if the directory"
    ],
    [
        "start with two letters (which excludes __pycache__, .gitignore, etc.).",
        "start with two letters (which"
    ],
    [
        "Set access and modification times to the Unix epoch time for all the .po files.",
        "Set access and modification times to the Unix epoch time for all"
    ],
    [
        "\"Unable to find a locale path to store translations for file \"",
        "\"Unable to find a locale path to store"
    ],
    [
        "\"__init__.py. Make sure the 'locale' directory exists in an app \"",
        "\"__init__.py. Make sure the 'locale' directory exists in"
    ],
    [
        "* translations for an app containing a locale folder are stored in that folder",
        "* translations for an app containing a"
    ],
    [
        "self.assertMsgId(\"This app has no locale directory\", po_contents)",
        "self.assertMsgId(\"This app has no locale directory\","
    ],
    [
        "self.assertMsgId(\"This is a project-level string\", po_contents)",
        "self.assertMsgId(\"This is a project-level string\","
    ],
    [
        "self.assertMsgId(\"This app has a locale directory\", po_contents)",
        "self.assertMsgId(\"This app has a"
    ],
    [
        "@skipUnless(has_xgettext, \"xgettext is mandatory for extraction tests\")",
        "@skipUnless(has_xgettext, \"xgettext is mandatory"
    ],
    [
        "\"\"\"PO files are unchanged unless there are new changes.\"\"\"",
        "\"\"\"PO files are unchanged unless"
    ],
    [
        "\"\"\"PO files are updated when new changes are detected.\"\"\"",
        "\"\"\"PO files are updated when new"
    ],
    [
        "\"This is a hitherto undiscovered translatable string.\",",
        "\"This is a hitherto undiscovered"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "def _assertPoKeyword(self, keyword, expected_value, haystack, use_quotes=True):",
        "def _assertPoKeyword(self, keyword, expected_value,"
    ],
    [
        "needle = \"%s %s\" % (keyword, expected_value)",
        "needle = \"%s %s\""
    ],
    [
        "re.search(\"^%s %s\" % (keyword, expected_value), haystack, re.MULTILINE),",
        "re.search(\"^%s %s\" % (keyword, expected_value), haystack,"
    ],
    [
        "\"Could not find %(q)s%(n)s%(q)s in generated PO file\"",
        "\"Could not find %(q)s%(n)s%(q)s in"
    ],
    [
        "temporary filesystem tree created by tempfile.mkdtemp() that contains a",
        "temporary filesystem tree created by tempfile.mkdtemp() that contains"
    ],
    [
        "clean copy of the relevant test code.",
        "clean copy of the"
    ],
    [
        "Test classes using this mixin need to define a `work_subdir` attribute",
        "Test classes using this mixin need to define"
    ],
    [
        "temporary tree from which its test cases will run.",
        "temporary tree from which its"
    ],
    [
        "The setUp() method sets the current working dir to the temporary tree.",
        "The setUp() method sets the current working dir to"
    ],
    [
        "It'll be removed when cleaning up.",
        "It'll be removed"
    ],
    [
        "from django.core.management import CommandError, call_command, execute_from_command_line",
        "from django.core.management import CommandError,"
    ],
    [
        "@unittest.skipUnless(has_msgfmt, \"msgfmt is mandatory for compilation tests\")",
        "@unittest.skipUnless(has_msgfmt, \"msgfmt is mandatory"
    ],
    [
        "CommandError, \"compilemessages generated one or more errors.\"",
        "CommandError, \"compilemessages generated one or"
    ],
    [
        "self.assertIn(\"file has a BOM (Byte Order Mark)\", stderr.getvalue())",
        "self.assertIn(\"file has a BOM (Byte"
    ],
    [
        "CommandError, \"compilemessages generated one or more errors.\"",
        "CommandError, \"compilemessages generated one"
    ],
    [
        "msg = \"%s” is already compiled and up to date.\" % mo_file_en.with_suffix(\".po\")",
        "msg = \"%s” is already compiled and up to date.\""
    ],
    [
        "all(Path(self.MO_FILE % (dir, lang)).exists() for lang in langs)",
        "all(Path(self.MO_FILE % (dir, lang)).exists() for lang"
    ],
    [
        "all(Path(self.MO_FILE % (dir, lang)).exists() is False for lang in langs)",
        "all(Path(self.MO_FILE % (dir, lang)).exists() is False for lang in"
    ],
    [
        "self.assertEqual([c.args for c in mock_compile_messages.mock_calls], expected)",
        "self.assertEqual([c.args for c in mock_compile_messages.mock_calls],"
    ],
    [
        "lambda *args, **kwargs: run(*args, env=env, **kwargs),",
        "lambda *args, **kwargs: run(*args,"
    ],
    [
        "CommandError, \"compilemessages generated one or more errors\"",
        "CommandError, \"compilemessages generated one or more"
    ],
    [
        "self.assertIn(\"' cannot start a field name\", stderr.getvalue())",
        "self.assertIn(\"' cannot start a"
    ],
    [
        "from django.test import RequestFactory, SimpleTestCase, TestCase, override_settings",
        "from django.test import RequestFactory,"
    ],
    [
        "from django.utils.numberformat import format as nformat",
        "from django.utils.numberformat import format as"
    ],
    [
        "@skipUnless(find_command(\"msgfmt\"), \"msgfmt is mandatory for this test\")",
        "@skipUnless(find_command(\"msgfmt\"), \"msgfmt is mandatory"
    ],
    [
        "The language restored is the one used when the function was",
        "The language restored is the one used when the"
    ],
    [
        "Format string interpolation should work with *_lazy objects.",
        "Format string interpolation should work with *_lazy"
    ],
    [
        "simple_with_format = ngettext_lazy(\"%d good result\", \"%d good results\")",
        "simple_with_format = ngettext_lazy(\"%d good"
    ],
    [
        "\"Exclamation\", \"%d good result\", \"%d good results\"",
        "\"Exclamation\", \"%d good result\","
    ],
    [
        "simple_without_format = ngettext_lazy(\"good result\", \"good results\")",
        "simple_without_format = ngettext_lazy(\"good"
    ],
    [
        "with self.assertRaisesMessage(KeyError, \"Your dictionary lacks key\"):",
        "with self.assertRaisesMessage(KeyError, \"Your"
    ],
    [
        "with self.assertRaisesMessage(KeyError, \"Your dictionary lacks key\"):",
        "with self.assertRaisesMessage(KeyError, \"Your dictionary lacks"
    ],
    [
        "simple_with_format = ngettext_lazy(\"{} good result\", \"{} good results\")",
        "simple_with_format = ngettext_lazy(\"{} good result\", \"{}"
    ],
    [
        "\"Exclamation\", \"{} good result\", \"{} good results\"",
        "\"Exclamation\", \"{} good result\", \"{} good"
    ],
    [
        "\"Hi {name}, {num} good result\", \"Hi {name}, {num} good results\", \"num\"",
        "\"Hi {name}, {num} good result\", \"Hi {name},"
    ],
    [
        "with self.assertRaisesMessage(KeyError, \"Your dictionary lacks key\"):",
        "with self.assertRaisesMessage(KeyError, \"Your dictionary lacks"
    ],
    [
        "with self.assertRaisesMessage(KeyError, \"Your dictionary lacks key\"):",
        "with self.assertRaisesMessage(KeyError, \"Your"
    ],
    [
        "self.assertTrue(ngettext_lazy(\"%d good result\", \"%d good results\"))",
        "self.assertTrue(ngettext_lazy(\"%d good result\","
    ],
    [
        "Translating a string requiring no auto-escaping with gettext or pgettext",
        "Translating a string requiring no auto-escaping with gettext"
    ],
    [
        "Translations on files with Mac or DOS end of lines will be converted",
        "Translations on files with Mac or DOS end of lines will"
    ],
    [
        "to unix EOF in .po catalogs.",
        "to unix EOF"
    ],
    [
        "\"loading_app\" does not have translations for all languages provided by",
        "\"loading_app\" does not have translations for"
    ],
    [
        "The active locale's formats take precedence over the default settings",
        "The active locale's formats take precedence over the default"
    ],
    [
        "even if they would be interpreted as False in a conditional test",
        "even if they would be interpreted as False"
    ],
    [
        "Check if sublocales fall back to the main locale",
        "Check if sublocales fall back"
    ],
    [
        "Tests if form input is correctly localized",
        "Tests if form input is correctly"
    ],
    [
        "'<input id=\"id_name\" type=\"text\" name=\"name\" value=\"acme\" '",
        "'<input id=\"id_name\" type=\"text\" name=\"name\" value=\"acme\""
    ],
    [
        "Tests the iter_format_modules function always yields format modules in",
        "Tests the iter_format_modules function always"
    ],
    [
        "a stable and correct order in presence of both base ll and ll_CC formats.",
        "a stable and correct order in presence of"
    ],
    [
        "Test the {% localize %} templatetag and the localize/unlocalize filters.",
        "Test the {% localize %} templatetag and the localize/unlocalize"
    ],
    [
        "\"{{ int }}/{{ float }}/{{ date }}{% endlocalize %}; \"",
        "\"{{ int }}/{{ float }}/{{ date }}{%"
    ],
    [
        "\"{% localize on %}{{ int }}/{{ float }}/{{ date }}{% endlocalize %}\"",
        "\"{% localize on %}{{ int }}/{{ float }}/{{ date }}{% endlocalize"
    ],
    [
        "\"{% localize off %}{{ int }}/{{ float }}/{{ date }};{% endlocalize %} \"",
        "\"{% localize off %}{{ int }}/{{ float }}/{{ date }};{% endlocalize %}"
    ],
    [
        "\"{{ int }}/{{ float }}/{{ date }}\"",
        "\"{{ int }}/{{ float"
    ],
    [
        "\"{{ int|unlocalize }}/{{ float|unlocalize }}/{{ date|unlocalize }}\"",
        "\"{{ int|unlocalize }}/{{ float|unlocalize"
    ],
    [
        "\"\"\"A string representation is returned for unlocalized numbers.\"\"\"",
        "\"\"\"A string representation is returned"
    ],
    [
        "\"{{ int }}/{{ float }}/{{ decimal }}{% endlocalize %}\"",
        "\"{{ int }}/{{ float }}/{{ decimal }}{%"
    ],
    [
        "Form input with 'as_hidden' or 'as_text' is correctly localized.",
        "Form input with 'as_hidden' or"
    ],
    [
        "\"{{ form.date_added.as_text }}; {{ form.cents_paid.as_text }}\"",
        "\"{{ form.date_added.as_text }};"
    ],
    [
        "\"{{ form.date_added.as_hidden }}; {{ form.cents_paid.as_hidden }}\"",
        "\"{{ form.date_added.as_hidden }}; {{"
    ],
    [
        "The first input format for DATE_INPUT_FORMATS, TIME_INPUT_FORMATS, and",
        "The first input format for"
    ],
    [
        "DATETIME_INPUT_FORMATS must not contain %f since that's unsupported by",
        "DATETIME_INPUT_FORMATS must not contain %f since that's"
    ],
    [
        "\"%s locale's %s uses an unsupported format code.\"",
        "\"%s locale's %s uses"
    ],
    [
        "With a non-English LANGUAGE_CODE and if the active language is English",
        "With a non-English LANGUAGE_CODE and if the active"
    ],
    [
        "or one of its variants, the untranslated string should be returned",
        "or one of its variants, the untranslated string should be"
    ],
    [
        "Testing HTTP header parsing. First, we test that we can parse the",
        "Testing HTTP header parsing. First, we"
    ],
    [
        "values according to the spec (and that we extract all the pieces in",
        "values according to the spec (and that we"
    ],
    [
        "Some browsers (Firefox, IE, etc.) use deprecated language codes. As these",
        "Some browsers (Firefox, IE, etc.) use"
    ],
    [
        "matched. For example zh-tw (traditional) will be interpreted as zh-hans",
        "matched. For example zh-tw (traditional) will be interpreted as"
    ],
    [
        "(simplified), which is wrong. So we should also accept these deprecated",
        "(simplified), which is wrong. So we should also accept these"
    ],
    [
        "Some languages may have special fallbacks that don't follow the simple",
        "Some languages may have special fallbacks that"
    ],
    [
        "'fr-ca' -> 'fr' logic (notably Chinese codes).",
        "'fr-ca' -> 'fr' logic (notably"
    ],
    [
        "Subsequent language codes should be used when the language code is not",
        "Subsequent language codes should be used when"
    ],
    [
        "After setting LANGUAGE, the cache should be cleared and languages",
        "After setting LANGUAGE, the cache should be"
    ],
    [
        "\"The string '%s' isn't in the translation of '%s'; the actual result is \"",
        "\"The string '%s' isn't in the translation of '%s'; the"
    ],
    [
        "Untranslated strings for territorial language variants use the",
        "Untranslated strings for territorial language"
    ],
    [
        "translations of the generic language. In this case, the de-de",
        "translations of the generic language. In this case, the"
    ],
    [
        "with self.assertRaisesMessage(KeyError, \"Unknown language code xx\"):",
        "with self.assertRaisesMessage(KeyError, \"Unknown"
    ],
    [
        "with self.assertRaisesMessage(KeyError, \"Unknown language code xx-xx and xx\"):",
        "with self.assertRaisesMessage(KeyError, \"Unknown language code xx-xx"
    ],
    [
        "get_language_info return the first fallback language info if the lang_info",
        "get_language_info return the first fallback language info if the"
    ],
    [
        "struct does not contain the 'name' key.",
        "struct does not contain"
    ],
    [
        "language (settings.LANGUAGE_CODE) should be accessible without a prefix.",
        "language (settings.LANGUAGE_CODE) should be accessible"
    ],
    [
        "A request for a nonexistent URL shouldn't cause a redirect to",
        "A request for a nonexistent URL"
    ],
    [
        "gettext_module.find = lambda *args, **kw: None",
        "gettext_module.find = lambda *args, **kw:"
    ],
    [
        "\"\"\"OSError is raised if the default language is unparseable.\"\"\"",
        "\"\"\"OSError is raised if the"
    ],
    [
        "A language non present in default Django languages can still be",
        "A language non present in default Django languages can"
    ],
    [
        "project_dir = Path(__file__).parent / \"sampleproject\" / \"locale\"",
        "project_dir = Path(__file__).parent /"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "path(\"streaming/\", lambda r: StreamingHttpResponse([_(\"Yes\"), \"/\", _(\"No\")])),",
        "path(\"streaming/\", lambda r:"
    ],
    [
        "from django.utils.translation import activate, get_language, trans_real",
        "from django.utils.translation import activate, get_language,"
    ],
    [
        "\"\"\"Tests using the French translations of the sampleproject.\"\"\"",
        "\"\"\"Tests using the French"
    ],
    [
        "PO_FILE = os.path.join(SAMPLEPROJECT_LOCALE, \"fr\", \"LC_MESSAGES\", \"django.po\")",
        "PO_FILE = os.path.join(SAMPLEPROJECT_LOCALE,"
    ],
    [
        "Tests the extracted string found in the gettext catalog.",
        "Tests the extracted string found in the gettext"
    ],
    [
        "These tests should all have an analogous translation tests below, ensuring",
        "These tests should all have an analogous translation"
    ],
    [
        "the Python formatting does not persist through to a rendered template.",
        "the Python formatting does not persist through"
    ],
    [
        "\"Literal with a percent symbol at the end %%\", self.po_contents",
        "\"Literal with a percent symbol at the end %%\","
    ],
    [
        "\"Literal with a percent %% symbol in the middle\", self.po_contents",
        "\"Literal with a percent %% symbol in the middle\","
    ],
    [
        "\"Looks like a str fmt spec %%s but should not be interpreted as such\",",
        "\"Looks like a str fmt spec %%s but"
    ],
    [
        "\"Looks like a str fmt spec %% o but should not be interpreted as such\",",
        "\"Looks like a str fmt spec %% o but should"
    ],
    [
        "Test rendering of templates that use percent signs.",
        "Test rendering of templates that use percent"
    ],
    [
        "Ensures both translate and blocktranslate tags behave consistently.",
        "Ensures both translate and blocktranslate tags behave"
    ],
    [
        "expected = \"Littérale avec un symbole de pour cent à la fin %\"",
        "expected = \"Littérale avec un symbole de pour"
    ],
    [
        "'{% translate \"Literal with a percent symbol at the end %\" %}'",
        "'{% translate \"Literal with a percent symbol at the"
    ],
    [
        "expected = \"Pour cent littérale % avec un symbole au milieu\"",
        "expected = \"Pour cent littérale % avec un"
    ],
    [
        "'{% translate \"Literal with a percent % symbol in the middle\" %}'",
        "'{% translate \"Literal with a percent"
    ],
    [
        "\"On dirait un spec str fmt %s mais ne devrait pas être interprété comme \"",
        "\"On dirait un spec str fmt %s mais ne devrait pas être interprété"
    ],
    [
        "'should not be interpreted as such\" %}'",
        "'should not be interpreted as such\""
    ],
    [
        "\"should not be interpreted as such{% endblocktranslate %}\"",
        "\"should not be interpreted as"
    ],
    [
        "\"On dirait un spec str fmt % o mais ne devrait pas être interprété comme \"",
        "\"On dirait un spec str fmt % o mais ne devrait pas être"
    ],
    [
        "'{% translate \"Looks like a str fmt spec % o but should not be '",
        "'{% translate \"Looks like a str fmt spec %"
    ],
    [
        "\"{% blocktranslate %}Looks like a str fmt spec % o but should not be \"",
        "\"{% blocktranslate %}Looks like a str fmt spec %"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "from django.urls import clear_url_caches, resolve, reverse, translate_url",
        "from django.urls import clear_url_caches,"
    ],
    [
        "TestCase base-class for the URL tests.",
        "TestCase base-class for"
    ],
    [
        "activation happens based on url prefix.",
        "activation happens based on url"
    ],
    [
        "Tests if the pattern-strings are translated correctly (within the",
        "Tests if the pattern-strings are translated"
    ],
    [
        "Tests if the translations are still working within namespaces.",
        "Tests if the translations are still working"
    ],
    [
        "Tests if the user gets redirected to the right URL when there is no",
        "Tests if the user gets redirected to the right URL"
    ],
    [
        "'Accept-Language' is not added to the Vary header when using prefixed URLs.",
        "'Accept-Language' is not added to the Vary header"
    ],
    [
        "The redirect to a prefixed URL depends on 'Accept-Language' and",
        "The redirect to a prefixed URL"
    ],
    [
        "'Cookie', but once prefixed no header is set.",
        "'Cookie', but once prefixed no header is"
    ],
    [
        "Tests the redirect when the requested URL doesn't end with a slash",
        "Tests the redirect when the requested URL"
    ],
    [
        "Tests the redirect when the requested URL doesn't end with a slash",
        "Tests the redirect when the requested URL doesn't"
    ],
    [
        "\"\"\"Tests if the response has the correct language code.\"\"\"",
        "\"\"\"Tests if the response has"
    ],
    [
        "Test if the language tag works.",
        "Test if the language"
    ],
    [
        "{% language 'nl' %}{% url 'no-prefix-translated' %}{% endlanguage %}",
        "{% language 'nl' %}{% url 'no-prefix-translated'"
    ],
    [
        "{% language 'pt-br' %}{% url 'no-prefix-translated' %}{% endlanguage %}\"\"\"",
        "{% language 'pt-br' %}{% url 'no-prefix-translated' %}{% endlanguage"
    ],
    [
        "{% url 'no-prefix-translated-slug' 'apo' %}{% endlanguage %}",
        "{% url 'no-prefix-translated-slug' 'apo' %}{%"
    ],
    [
        "{% url 'no-prefix-translated-slug' 'apo' %}{% endlanguage %}",
        "{% url 'no-prefix-translated-slug' 'apo' %}{%"
    ],
    [
        "{% url 'no-prefix-translated-slug' slug='apo' %}{% endlanguage %}",
        "{% url 'no-prefix-translated-slug' slug='apo' %}{%"
    ],
    [
        "{% url 'no-prefix-translated-slug' slug='apo' %}{% endlanguage %}",
        "{% url 'no-prefix-translated-slug' slug='apo'"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import include, path,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "Helper script to update sampleproject's translation catalogs.",
        "Helper script to update sampleproject's translation"
    ],
    [
        "by using catalogs created from management commands.",
        "by using catalogs created from management"
    ],
    [
        "The string \"Two %% Three %%%\" renders differently using translate and",
        "The string \"Two %% Three %%%\" renders differently"
    ],
    [
        "blocktranslate. This issue is difficult to debug, it could be a problem with",
        "blocktranslate. This issue is difficult to debug, it"
    ],
    [
        "* Add {% translate \"Two %% Three %%%\" %} and blocktranslate equivalent to templates.",
        "* Add {% translate \"Two %% Three %%%\" %} and"
    ],
    [
        "* Test extraction - verify the new msgid in sampleproject's django.po.",
        "* Test extraction - verify the new"
    ],
    [
        "* Add a translation to sampleproject's django.po.",
        "* Add a translation to sampleproject's"
    ],
    [
        "* Test interpolation - verify templatetag rendering, test each in a template",
        "* Test interpolation - verify templatetag rendering, test each"
    ],
    [
        "that is rendered using an activated language from sampleproject's locale.",
        "that is rendered using an activated language"
    ],
    [
        "* Tests should fail, issue captured.",
        "* Tests should fail, issue"
    ],
    [
        "\"\"\"Run makemessages and compilemessages in sampleproject.\"\"\"",
        "\"\"\"Run makemessages and compilemessages in"
    ],
    [
        "pofile = os.path.join(proj_dir, \"locale\", \"fr\", \"LC_MESSAGES\", \"django.po\")",
        "pofile = os.path.join(proj_dir, \"locale\","
    ],
    [
        "content = re.sub(r'^\"POT-Creation-Date.+$\\s', \"\", content, flags=re.MULTILINE)",
        "content = re.sub(r'^\"POT-Creation-Date.+$\\s', \"\","
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "string = _(\"This is a project-level string\")",
        "string = _(\"This is a"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "string = _(\"This app has a locale directory\")",
        "string = _(\"This app has"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "string = _(\"This app has no locale directory\")",
        "string = _(\"This app has"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "return \"%s is a member of %s\" % (self.person.name, self.group.name)",
        "return \"%s is a member of %s\" %"
    ],
    [
        "return \"%s is a member of %s\" % (self.person.name, self.group.name)",
        "return \"%s is a member of %s\" % (self.person.name,"
    ],
    [
        "from datetime import date, datetime, timedelta",
        "from datetime import"
    ],
    [
        "self.assertEqual(repr(queryset), \"<Membership: Jane is a member of Rock>\")",
        "self.assertEqual(repr(queryset), \"<Membership: Jane is a member of"
    ],
    [
        "return \"They were good at %s\" % datetime.now()",
        "return \"They were good"
    ],
    [
        "name=\"Annie\", through_defaults={\"invite_reason\": \"She was just awesome.\"}",
        "name=\"Annie\", through_defaults={\"invite_reason\": \"She"
    ],
    [
        "through_defaults={\"invite_reason\": lambda: \"She was just awesome.\"},",
        "through_defaults={\"invite_reason\": lambda: \"She was"
    ],
    [
        "person=self.jane, group=self.roll, invite_reason=\"She was just awesome.\"",
        "person=self.jane, group=self.roll, invite_reason=\"She was just"
    ],
    [
        "qs = Group.objects.filter(membership__invite_reason=\"She was just awesome.\")",
        "qs = Group.objects.filter(membership__invite_reason=\"She"
    ],
    [
        "person=self.jane, group=self.roll, invite_reason=\"She was just awesome.\"",
        "person=self.jane, group=self.roll, invite_reason=\"She was just"
    ],
    [
        "qs = Person.objects.filter(membership__invite_reason=\"She was just awesome.\")",
        "qs = Person.objects.filter(membership__invite_reason=\"She"
    ],
    [
        "Relations with intermediary tables with multiple FKs",
        "Relations with intermediary tables with multiple"
    ],
    [
        "By specifying the 'proxy' Meta attribute, model subclasses can specify that",
        "By specifying the 'proxy' Meta attribute, model subclasses"
    ],
    [
        "they will take data directly from the table of their base class table rather",
        "they will take data directly from the table of"
    ],
    [
        "than using a new table of their own. This allows them to act as simple proxies,",
        "than using a new table of their own. This allows them to act as"
    ],
    [
        "providing a modified interface to the data from the base class.",
        "providing a modified interface to the data"
    ],
    [
        "A simple abstract base class, to be used for error checking.",
        "A simple abstract base class, to"
    ],
    [
        "A proxy subclass, this should not get a new table. Overrides the default",
        "A proxy subclass, this should not get a new"
    ],
    [
        "permissions = ((\"display_users\", \"May display users information\"),)",
        "permissions = ((\"display_users\", \"May"
    ],
    [
        "A class with the default manager from Person, plus a secondary manager.",
        "A class with the default manager from Person, plus a secondary"
    ],
    [
        "A non-proxy subclass of a proxy, it should get a new table.",
        "A non-proxy subclass of a proxy, it should get"
    ],
    [
        "A proxy of proxy model with related field",
        "A proxy of proxy model with related"
    ],
    [
        "A model that has relation to a proxy model",
        "A model that has relation"
    ],
    [
        "or to a proxy of proxy model",
        "or to a proxy"
    ],
    [
        "from django.contrib.auth.models import User as AuthUser",
        "from django.contrib.auth.models import User"
    ],
    [
        "The MyPerson model should be generating the same database queries as",
        "The MyPerson model should be generating the same database queries"
    ],
    [
        "the Person model (when the same manager is used in each case).",
        "the Person model (when the same manager is used in"
    ],
    [
        "The StatusPerson models should have its own table (it's using ORM-level",
        "The StatusPerson models should have its own table (it's"
    ],
    [
        "Creating a Person makes them accessible through the MyPerson proxy.",
        "Creating a Person makes them"
    ],
    [
        "Person is not proxied by StatusPerson subclass.",
        "Person is not proxied by"
    ],
    [
        "A new MyPerson also shows up as a standard Person.",
        "A new MyPerson also shows up as a"
    ],
    [
        "lsps = [lsp.name for lsp in LowerStatusPerson.objects.all()]",
        "lsps = [lsp.name for lsp"
    ],
    [
        "Correct type when querying a proxy of proxy",
        "Correct type when querying"
    ],
    [
        "pp = sorted(mpp.name for mpp in MyPersonProxy.objects.all())",
        "pp = sorted(mpp.name for"
    ],
    [
        "self.assertEqual(pp, [\"Bazza del Frob\", \"Foo McBar\", \"homer\"])",
        "self.assertEqual(pp, [\"Bazza del Frob\","
    ],
    [
        "Proxy models are included in the ancestors for a model's DoesNotExist",
        "Proxy models are included in the"
    ],
    [
        "\"Abstract base class containing model fields not permitted for proxy model \"",
        "\"Abstract base class containing model fields not permitted for proxy model"
    ],
    [
        "\"Proxy model 'TooManyBases' has more than one non-abstract model base \"",
        "\"Proxy model 'TooManyBases' has more than one"
    ],
    [
        "msg = \"Proxy model 'NoBaseClasses' has no non-abstract model base class.\"",
        "msg = \"Proxy model 'NoBaseClasses' has no non-abstract model base"
    ],
    [
        "\"Proxy model 'NoNewFields' contains model fields.\",",
        "\"Proxy model 'NoNewFields' contains model"
    ],
    [
        "resp = [p.name for p in MyPerson.objects.all()]",
        "resp = [p.name for p"
    ],
    [
        "resp = [p.name for p in MyPerson._default_manager.all()]",
        "resp = [p.name for"
    ],
    [
        "resp = [p.name for p in OtherPerson.objects.all()]",
        "resp = [p.name for"
    ],
    [
        "resp = [p.name for p in OtherPerson.excluder.all()]",
        "resp = [p.name for p in"
    ],
    [
        "resp = [p.name for p in OtherPerson._default_manager.all()]",
        "resp = [p.name for p in"
    ],
    [
        "Test save signals for proxy models",
        "Test save signals for proxy"
    ],
    [
        "output.append(\"%s %s save\" % (model, event))",
        "output.append(\"%s %s save\""
    ],
    [
        "self.assertEqual(output, [\"MyPerson pre save\", \"MyPerson post save\"])",
        "self.assertEqual(output, [\"MyPerson pre save\", \"MyPerson post"
    ],
    [
        "self.assertEqual(output, [\"MyPersonProxy pre save\", \"MyPersonProxy post save\"])",
        "self.assertEqual(output, [\"MyPersonProxy pre save\", \"MyPersonProxy"
    ],
    [
        "resp = [u.name for u in User.objects.all()]",
        "resp = [u.name for u in"
    ],
    [
        "resp = [u.name for u in UserProxy.objects.all()]",
        "resp = [u.name for u in"
    ],
    [
        "resp = [u.name for u in UserProxyProxy.objects.all()]",
        "resp = [u.name for"
    ],
    [
        "self.assertEqual([u.name for u in MultiUserProxy.objects.all()], [\"Bruce\"])",
        "self.assertEqual([u.name for u in MultiUserProxy.objects.all()],"
    ],
    [
        "resp = [u.name for u in UserProxy.objects.all()]",
        "resp = [u.name for u in"
    ],
    [
        "resp = [u.name for u in UserProxy.objects.all()]",
        "resp = [u.name for u"
    ],
    [
        "We can still use `select_related()` to include related models in our",
        "We can still use `select_related()` to include related"
    ],
    [
        "resp = [s.name for s in State.objects.select_related()]",
        "resp = [s.name for s in"
    ],
    [
        "resp = [s.name for s in StateProxy.objects.select_related()]",
        "resp = [s.name for s in"
    ],
    [
        "StateProxy.objects.get(name=\"New South Wales\").name, \"New South Wales\"",
        "StateProxy.objects.get(name=\"New South Wales\").name,"
    ],
    [
        "Test if admin gives warning about cascade deleting models referenced",
        "Test if admin gives warning about cascade deleting models"
    ],
    [
        "to concrete model by deleting proxy object.",
        "to concrete model by"
    ],
    [
        "Test if the admin delete page shows the correct string representation",
        "Test if the admin delete page shows the correct string"
    ],
    [
        "user_str = 'Tracker user: <a href=\"%s\">%s</a>' % (",
        "user_str = 'Tracker user: <a href=\"%s\">%s</a>' %"
    ],
    [
        "proxy_str = 'Proxy tracker user: <a href=\"%s\">%s</a>' % (",
        "proxy_str = 'Proxy tracker user: <a href=\"%s\">%s</a>' %"
    ],
    [
        "for field in (\"email\", \"vcard\", \"homepage\", \"avatar\"):",
        "for field in (\"email\", \"vcard\", \"homepage\","
    ],
    [
        "Let's make sure that ModelAdmin.get_queryset uses the ordering we define",
        "Let's make sure that ModelAdmin.get_queryset"
    ],
    [
        "in ModelAdmin rather that ordering defined in the model's inner Meta",
        "in ModelAdmin rather that ordering defined"
    ],
    [
        "The default ordering should be by name, as specified in the inner Meta",
        "The default ordering should be by name, as"
    ],
    [
        "names = [b.name for b in ma.get_queryset(request)]",
        "names = [b.name for"
    ],
    [
        "Let's use a custom ModelAdmin that changes the ordering, and make sure",
        "Let's use a custom ModelAdmin that changes"
    ],
    [
        "names = [b.name for b in ma.get_queryset(request)]",
        "names = [b.name for"
    ],
    [
        "names = [b.name for b in band_admin.get_queryset(request)]",
        "names = [b.name for b"
    ],
    [
        "Let's use a custom ModelAdmin that changes the ordering dynamically.",
        "Let's use a custom ModelAdmin"
    ],
    [
        "names = [b.name for b in ma.get_queryset(request)]",
        "names = [b.name for"
    ],
    [
        "names = [b.name for b in ma.get_queryset(request)]",
        "names = [b.name for"
    ],
    [
        "Let's make sure that InlineModelAdmin.get_queryset uses the ordering we",
        "Let's make sure that InlineModelAdmin.get_queryset uses"
    ],
    [
        "The default ordering should be by name, as specified in the inner Meta",
        "The default ordering should be by name, as specified in the inner"
    ],
    [
        "names = [s.name for s in inline.get_queryset(request)]",
        "names = [s.name for s in"
    ],
    [
        "self.assertEqual([\"Dude (Looks Like a Lady)\", \"Jaded\", \"Pink\"], names)",
        "self.assertEqual([\"Dude (Looks Like a Lady)\", \"Jaded\","
    ],
    [
        "Let's check with ordering set to something different than the default.",
        "Let's check with ordering set to something different"
    ],
    [
        "names = [s.name for s in inline.get_queryset(request)]",
        "names = [s.name for s"
    ],
    [
        "self.assertEqual([\"Jaded\", \"Pink\", \"Dude (Looks Like a Lady)\"], names)",
        "self.assertEqual([\"Jaded\", \"Pink\", \"Dude (Looks Like a"
    ],
    [
        "from .models import Account, Employee, Person, Profile, ProxyEmployee",
        "from .models import Account, Employee, Person, Profile,"
    ],
    [
        "\"fields, primary keys, or are non-concrete fields: %s\"",
        "\"fields, primary keys, or are non-concrete"
    ],
    [
        "from django.test import TestCase as DjangoTestCase",
        "from django.test import"
    ],
    [
        "Doctest example from the official Python documentation.",
        "Doctest example from the official Python"
    ],
    [
        "Factorials of floats are OK, but the float must be an exact integer:",
        "Factorials of floats are OK, but the float must be an exact"
    ],
    [
        "ValueError: n must be exact integer",
        "ValueError: n must"
    ],
    [
        "It must also not be ridiculously large:",
        "It must also not be"
    ],
    [
        "raise ValueError(\"n must be exact integer\")",
        "raise ValueError(\"n must be"
    ],
    [
        "from django.test import TestCase as DjangoTestCase",
        "from django.test import TestCase as"
    ],
    [
        "name=\"The Definitive Guide to Django: Web Development Done Right\",",
        "name=\"The Definitive Guide to Django: Web"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming: Case"
    ],
    [
        "The subselect works and returns results equivalent to a",
        "The subselect works and returns"
    ],
    [
        "Same as the above test, but evaluates the queryset for the subquery",
        "Same as the above test, but evaluates the queryset for the"
    ],
    [
        "before it's used as a subquery.",
        "before it's used as"
    ],
    [
        "Before the corresponding fix for this bug, this test failed in both",
        "Before the corresponding fix for this bug,"
    ],
    [
        "\"name\": \"The Definitive Guide to Django: Web Development Done Right\",",
        "\"name\": \"The Definitive Guide to Django:"
    ],
    [
        "\"name\": \"The Definitive Guide to Django: Web Development Done Right\",",
        "\"name\": \"The Definitive Guide to Django: Web Development"
    ],
    [
        "[{\"name\": \"Python Web Development with Django\"}],",
        "[{\"name\": \"Python Web Development"
    ],
    [
        "\"name\": \"The Definitive Guide to Django: Web Development Done Right\",",
        "\"name\": \"The Definitive Guide to Django: Web Development Done"
    ],
    [
        "Filtering on an aggregate annotation with Decimal values should work.",
        "Filtering on an aggregate annotation"
    ],
    [
        "\"Cannot resolve keyword 'foo' into field. Choices are: authors, \"",
        "\"Cannot resolve keyword 'foo' into field. Choices"
    ],
    [
        "\"contact, contact_id, hardbackbook, id, isbn, name, pages, price, \"",
        "\"contact, contact_id, hardbackbook, id, isbn,"
    ],
    [
        "\"pubdate, publisher, publisher_id, rating, store, tags\"",
        "\"pubdate, publisher, publisher_id, rating, store,"
    ],
    [
        "\"Cannot resolve keyword 'foo' into field. Choices are: authors, \"",
        "\"Cannot resolve keyword 'foo' into"
    ],
    [
        "\"contact, contact_id, hardbackbook, id, isbn, name, num_authors, \"",
        "\"contact, contact_id, hardbackbook, id,"
    ],
    [
        "\"pages, price, pubdate, publisher, publisher_id, rating, store, tags\"",
        "\"pages, price, pubdate, publisher, publisher_id,"
    ],
    [
        "\"name\": \"Artificial Intelligence: A Modern Approach\",",
        "\"name\": \"Artificial Intelligence: A Modern"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django: Web"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming: Case Studies"
    ],
    [
        "lambda b: (b.name, b.authors__age__avg, b.publisher.name, b.contact.name),",
        "lambda b: (b.name,"
    ],
    [
        "\"The named annotation 'authors__age__avg' conflicts with \"",
        "\"The named annotation 'authors__age__avg'"
    ],
    [
        "\"the default name for another annotation.\"",
        "\"the default name for another"
    ],
    [
        "msg = \"The annotation 'age' conflicts with a field on the model.\"",
        "msg = \"The annotation 'age' conflicts with a field on"
    ],
    [
        "msg = \"The annotation 'friends' conflicts with a field on the model.\"",
        "msg = \"The annotation 'friends' conflicts with a field on the"
    ],
    [
        "msg = \"The annotation 'contact_id' conflicts with a field on the model.\"",
        "msg = \"The annotation 'contact_id' conflicts with a"
    ],
    [
        "msg = \"The annotation 'book_contact_set' conflicts with a field on the model.\"",
        "msg = \"The annotation 'book_contact_set' conflicts with a field on the"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming:"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django: Web"
    ],
    [
        "self.assertEqual(sorted(p.name for p in publishers), [\"Apress\", \"Sams\"])",
        "self.assertEqual(sorted(p.name for p in"
    ],
    [
        "sorted_publishers = sorted(publishers, key=lambda x: x.name)",
        "sorted_publishers = sorted(publishers,"
    ],
    [
        "self.assertEqual(sorted(p.name for p in publishers), [\"Apress\", \"Sams\"])",
        "self.assertEqual(sorted(p.name for p in publishers),"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django: Web Development"
    ],
    [
        "self.assertEqual(sorted(p.name for p in publishers), [\"Apress\", \"Sams\"])",
        "self.assertEqual(sorted(p.name for p in"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case \"",
        "\"Paradigms of Artificial Intelligence Programming: Case"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case \"",
        "\"Paradigms of Artificial Intelligence Programming:"
    ],
    [
        "msg = \"Cannot compute Avg('mean_age'): 'mean_age' is an aggregate\"",
        "msg = \"Cannot compute Avg('mean_age'): 'mean_age' is"
    ],
    [
        "Annotate *args ordering should be preserved in values_list results.",
        "Annotate *args ordering should be preserved"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django: Web Development Done"
    ],
    [
        "Q(name=\"The Definitive Guide to Django: Web Development Done Right\")",
        "Q(name=\"The Definitive Guide to Django: Web Development"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done Right\",",
        "\"The Definitive Guide to Django: Web"
    ],
    [
        "self.assertQuerySetEqual(qs, [\"Peter Norvig\"], lambda b: b.name)",
        "self.assertQuerySetEqual(qs, [\"Peter Norvig\"], lambda b:"
    ],
    [
        "self.assertQuerySetEqual(qs, [\"Peter Norvig\"], lambda b: b.name)",
        "self.assertQuerySetEqual(qs, [\"Peter Norvig\"], lambda b:"
    ],
    [
        "self.assertQuerySetEqual(qs, [\"Peter Norvig\"], lambda b: b.name)",
        "self.assertQuerySetEqual(qs, [\"Peter Norvig\"], lambda b:"
    ],
    [
        "The base table's join isn't promoted to LOUTER. This could",
        "The base table's join isn't promoted to LOUTER. This"
    ],
    [
        "cause the query generation to fail if there is an exclude() for fk-field",
        "cause the query generation to fail if there is"
    ],
    [
        "[(a.name, a.num_contacts) for a in results.order_by(\"name\")],",
        "[(a.name, a.num_contacts) for a"
    ],
    [
        "[(a.name, a.num_contacts) for a in results.order_by(\"name\")],",
        "[(a.name, a.num_contacts) for"
    ],
    [
        "[(b.name, b.num_authors) for b in results.order_by(\"name\")],",
        "[(b.name, b.num_authors) for b"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in"
    ],
    [
        "Unmanaged models are sometimes used to represent database views which",
        "Unmanaged models are sometimes used to"
    ],
    [
        "may not allow grouping by selected primary key.",
        "may not allow grouping by selected"
    ],
    [
        "[(b.name, b.num_authors) for b in queryset.order_by(\"name\")],",
        "[(b.name, b.num_authors) for"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case \"",
        "\"Paradigms of Artificial Intelligence Programming: Case"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case \"",
        "\"Paradigms of Artificial Intelligence"
    ],
    [
        "\"The Definitive Guide to Django: Web Development Done \"",
        "\"The Definitive Guide to Django:"
    ],
    [
        "tests aggregations with generic reverse relations",
        "tests aggregations with generic"
    ],
    [
        "[(b.name, b.tags__count) for b in results],",
        "[(b.name, b.tags__count) for b"
    ],
    [
        "\"Paradigms of Artificial Intelligence Programming: Case Studies in \"",
        "\"Paradigms of Artificial Intelligence Programming:"
    ],
    [
        "expected_results = [a.name for a in expected_results]",
        "expected_results = [a.name for"
    ],
    [
        "expected_results = [a.name for a in expected_results]",
        "expected_results = [a.name for a in"
    ],
    [
        "qs, [\"Adrian Holovaty\", \"Peter Norvig\"], lambda b: b.name",
        "qs, [\"Adrian Holovaty\", \"Peter Norvig\"],"
    ],
    [
        "qs, [\"Adrian Holovaty\", \"Peter Norvig\"], lambda b: b.name",
        "qs, [\"Adrian Holovaty\", \"Peter Norvig\"], lambda b:"
    ],
    [
        "Splitting a q object to parts for where/having doesn't alter",
        "Splitting a q object to parts for where/having"
    ],
    [
        "An F() object referring to related column works correctly in group by.",
        "An F() object referring to related"
    ],
    [
        "\"\"\"Find ages that are shared by at least two authors.\"\"\"",
        "\"\"\"Find ages that are shared"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"MyAggregate does not allow distinct\"):",
        "with self.assertRaisesMessage(TypeError, \"MyAggregate does"
    ],
    [
        "self.assertIn(\" LEFT OUTER JOIN \", str(qs.query))",
        "self.assertIn(\" LEFT OUTER JOIN"
    ],
    [
        "A series of tests to establish that the command-line bash completion works.",
        "A series of tests to establish"
    ],
    [
        "Testing the Python level bash completion code.",
        "Testing the Python level"
    ],
    [
        "This requires setting up the environment as if we got passed data",
        "This requires setting up the environment as if we got passed"
    ],
    [
        "Set the environment and the list of command line arguments.",
        "Set the environment and the list of command line"
    ],
    [
        "This sets the bash variables $COMP_WORDS and $COMP_CWORD. The former is",
        "This sets the bash variables $COMP_WORDS and $COMP_CWORD. The"
    ],
    [
        "an array consisting of the individual words in the current command",
        "an array consisting of the individual words in the current"
    ],
    [
        "line, the latter is the index of the current cursor position, so in",
        "line, the latter is the index of"
    ],
    [
        "case a word is completed and the cursor is placed after a whitespace,",
        "case a word is completed and the cursor is placed after"
    ],
    [
        "\"A custom command can autocomplete option flags\"",
        "\"A custom command can autocomplete"
    ],
    [
        "\"Show option flags in case a subcommand is completed\"",
        "\"Show option flags in case a subcommand is"
    ],
    [
        "\"No errors, just an empty list if there are no autocomplete options\"",
        "\"No errors, just an empty list"
    ],
    [
        "\"Application names will be autocompleted for an AppCommand\"",
        "\"Application names will be autocompleted for an"
    ],
    [
        "from django.contrib.auth import models as auth",
        "from django.contrib.auth import"
    ],
    [
        "raise RuntimeError(\"split should not be called\")",
        "raise RuntimeError(\"split should"
    ],
    [
        "Model with a split method should not cause an error in add_lazy_relation",
        "Model with a split method should not cause"
    ],
    [
        "\"Choices are: id, name, references, related, selfreferchild, \"",
        "\"Choices are: id, name,"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"'int' object is not iterable\"):",
        "with self.assertRaisesMessage(TypeError, \"'int' object is not"
    ],
    [
        "verbose_name = \"All your password are belong to us.\"",
        "verbose_name = \"All your password are"
    ],
    [
        "\"\"\"This class doesn't supply the mandatory 'name' attribute.\"\"\"",
        "\"\"\"This class doesn't supply"
    ],
    [
        "name = \"there is no such app\"",
        "name = \"there is no such"
    ],
    [
        "from .models import SoAlternative, TotallyNormal, new_apps",
        "from .models import SoAlternative, TotallyNormal,"
    ],
    [
        "Only one main registry can exist.",
        "Only one main"
    ],
    [
        "Tests the ready property of the main registry.",
        "Tests the ready property of"
    ],
    [
        "Tests when INSTALLED_APPS contains an incorrect app config.",
        "Tests when INSTALLED_APPS contains an incorrect"
    ],
    [
        "msg = \"'apps.apps.BadConfig' must supply a name attribute.\"",
        "msg = \"'apps.apps.BadConfig' must"
    ],
    [
        "Tests when INSTALLED_APPS contains a class that isn't an app config.",
        "Tests when INSTALLED_APPS contains a class that isn't an app"
    ],
    [
        "msg = \"'apps.apps.NotAConfig' isn't a subclass of AppConfig.\"",
        "msg = \"'apps.apps.NotAConfig' isn't a subclass"
    ],
    [
        "Tests when INSTALLED_APPS contains an app that doesn't exist, either",
        "Tests when INSTALLED_APPS contains an app that"
    ],
    [
        "directly or via an app config.",
        "directly or via an"
    ],
    [
        "with self.settings(INSTALLED_APPS=[\"there is no such app\"]):",
        "with self.settings(INSTALLED_APPS=[\"there is"
    ],
    [
        "\"Cannot import 'there is no such app'. Check that \"",
        "\"Cannot import 'there is no such"
    ],
    [
        "msg = \"Module 'apps' does not contain a 'NoSuchConfig' class.\"",
        "msg = \"Module 'apps' does not contain"
    ],
    [
        "\"Module 'apps.apps' does not contain a 'NoSuchConfig' class. \"",
        "\"Module 'apps.apps' does not contain a 'NoSuchConfig' class."
    ],
    [
        "\"Choices are: 'BadConfig', 'ModelPKAppsConfig', 'MyAdmin', \"",
        "\"Choices are: 'BadConfig', 'ModelPKAppsConfig', 'MyAdmin',"
    ],
    [
        "\"\"\"Load an app that doesn't provide an AppConfig class.\"\"\"",
        "\"\"\"Load an app that doesn't provide"
    ],
    [
        "\"\"\"Load an app that provides an AppConfig class.\"\"\"",
        "\"\"\"Load an app that provides"
    ],
    [
        "\"\"\"Load an app that provides two AppConfig classes.\"\"\"",
        "\"\"\"Load an app that provides two"
    ],
    [
        "\"\"\"Load an app that provides two default AppConfig classes.\"\"\"",
        "\"\"\"Load an app that provides"
    ],
    [
        "\"'apps.two_default_configs_app.apps' declares more than one \"",
        "\"'apps.two_default_configs_app.apps' declares more"
    ],
    [
        "Load an app that provides two AppConfig classes, one being the default.",
        "Load an app that provides two AppConfig classes, one being"
    ],
    [
        "[app_config.name for app_config in app_configs], SOME_INSTALLED_APPS_NAMES",
        "[app_config.name for app_config"
    ],
    [
        "msg = \"No installed app with label 'django.contrib.auth'. Did you mean 'myauth'\"",
        "msg = \"No installed app with"
    ],
    [
        "The models in the models.py file were loaded correctly.",
        "The models in the models.py file were"
    ],
    [
        "apps.get_models() raises an exception if apps.models_ready isn't True.",
        "apps.get_models() raises an exception if apps.models_ready"
    ],
    [
        "Makes a new model at runtime and ensures it goes into the right place.",
        "Makes a new model at runtime and ensures it goes into"
    ],
    [
        "Test for behavior when two models clash in the app registry.",
        "Test for behavior when two models clash in"
    ],
    [
        "\"Model 'apps.southponies' was already registered. \"",
        "\"Model 'apps.southponies' was"
    ],
    [
        "\"Reloading models is not advised as it can lead to inconsistencies, \"",
        "\"Reloading models is not advised as it can lead"
    ],
    [
        "RuntimeError, \"Conflicting 'southponies' models in application 'apps':\"",
        "RuntimeError, \"Conflicting 'southponies' models in application"
    ],
    [
        "apps.get_containing_app_config() should raise an exception if",
        "apps.get_containing_app_config() should raise"
    ],
    [
        "for model_name in [\"lazya\", \"lazyb\", \"lazyb\", \"lazyc\", \"lazya\"]",
        "for model_name in [\"lazya\", \"lazyb\", \"lazyb\", \"lazyc\","
    ],
    [
        "self.assertEqual(model_classes, [LazyA, LazyB, LazyB, LazyC, LazyA])",
        "self.assertEqual(model_classes, [LazyA, LazyB,"
    ],
    [
        "\"\"\"If subclass sets path as class attr, no module attributes needed.\"\"\"",
        "\"\"\"If subclass sets path as class attr, no module attributes"
    ],
    [
        "\"\"\"If path set as class attr, overrides __path__ and __file__.\"\"\"",
        "\"\"\"If path set as class"
    ],
    [
        "\"\"\"If single element in __path__, use it (in preference to __file__).\"\"\"",
        "\"\"\"If single element in __path__, use it (in preference"
    ],
    [
        "\"\"\"If there is no __path__ attr, use __file__.\"\"\"",
        "\"\"\"If there is no __path__ attr,"
    ],
    [
        "\"\"\"If the __path__ attr is empty, use __file__ if set.\"\"\"",
        "\"\"\"If the __path__ attr is empty,"
    ],
    [
        "ac = AppConfig(\"label\", Stub(__path__=[\"a\", \"b\"], __file__=\"c/__init__.py\"))",
        "ac = AppConfig(\"label\","
    ],
    [
        "\"\"\"If there is no __path__ or __file__, raise ImproperlyConfigured.\"\"\"",
        "\"\"\"If there is no __path__ or __file__,"
    ],
    [
        "\"\"\"If the __path__ attr is empty and there is no __file__, raise.\"\"\"",
        "\"\"\"If the __path__ attr is empty and there is no"
    ],
    [
        "If the __path__ attr contains duplicate paths and there is no",
        "If the __path__ attr contains duplicate paths and there"
    ],
    [
        "msg = \"The app label 'invalid.label' is not a valid Python identifier.\"",
        "msg = \"The app label 'invalid.label' is"
    ],
    [
        "(Because then we wouldn't know where to load its templates, static",
        "(Because then we wouldn't know where to load"
    ],
    [
        "Multiple locations are ok only if app-config has explicit path.",
        "Multiple locations are ok only if app-config"
    ],
    [
        "\"Accessing the database during app initialization is discouraged. To fix this \"",
        "\"Accessing the database during app initialization is discouraged."
    ],
    [
        "\"warning, avoid executing queries in AppConfig.ready() or when your app \"",
        "\"warning, avoid executing queries in AppConfig.ready() or when your app"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, modify_settings, override_settings",
        "from django.test import SimpleTestCase,"
    ],
    [
        "The site is matched if the name in the request has a trailing dot.",
        "The site is matched if the name in the"
    ],
    [
        "site = Site(name=\"test name\", domain=\"test test\")",
        "site = Site(name=\"test"
    ],
    [
        "msg = \"Site with this Domain name already exists.\"",
        "msg = \"Site with this Domain name already"
    ],
    [
        "msg=\"The SITE_ID setting must be an integer\",",
        "msg=\"The SITE_ID setting must be"
    ],
    [
        "msg = \"RequestSite cannot be saved.\"",
        "msg = \"RequestSite cannot"
    ],
    [
        "msg = \"RequestSite cannot be deleted.\"",
        "msg = \"RequestSite"
    ],
    [
        "On some backends the sequence needs to be reset after saving with an",
        "On some backends the sequence needs to"
    ],
    [
        "explicit ID. There shouldn't be a sequence collisions by saving another",
        "explicit ID. There shouldn't be a sequence collisions by saving"
    ],
    [
        "site. This test is only meaningful with databases that use sequences",
        "site. This test is only meaningful with databases"
    ],
    [
        "for automatic primary keys such as PostgreSQL and Oracle.",
        "for automatic primary keys such as PostgreSQL"
    ],
    [
        "from .models import Article, Bar, Base, Child, Foo, Whiz",
        "from .models import Article, Bar, Base,"
    ],
    [
        "String form referencing of models works, both as pre and post",
        "String form referencing of models works, both as pre"
    ],
    [
        "make sure we can use unicode characters in queries.",
        "make sure we can use"
    ],
    [
        "If these tests fail on MySQL, it's a problem with the test setup.",
        "If these tests fail on MySQL, it's a"
    ],
    [
        "make sure we can perform queries on TextFields.",
        "make sure we can perform queries on"
    ],
    [
        "a = Article(name=\"Test\", text=\"The quick brown fox jumps over the lazy dog.\")",
        "a = Article(name=\"Test\", text=\"The quick brown"
    ],
    [
        "text__exact=\"The quick brown fox jumps over the lazy dog.\"",
        "text__exact=\"The quick brown fox jumps"
    ],
    [
        "\"like\" queries on IP address fields require casting with HOST() (on PostgreSQL).",
        "\"like\" queries on IP address fields require casting with HOST() (on"
    ],
    [
        "from django.http import HttpResponse, HttpResponseForbidden, HttpResponseRedirect",
        "from django.http import"
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import TestCase, modify_settings,"
    ],
    [
        "Exercise the second Redirect.DoesNotExist branch in",
        "Exercise the second Redirect.DoesNotExist branch"
    ],
    [
        "\"You cannot use RedirectFallbackMiddleware when \"",
        "\"You cannot use"
    ],
    [
        "from django.test import SimpleTestCase, modify_settings, override_settings",
        "from django.test import"
    ],
    [
        "BaseHandler should render TemplateResponse if necessary.",
        "BaseHandler should render"
    ],
    [
        "response = WSGIHandler()(self.get_suspicious_environ(), lambda *a, **k: None)",
        "response = WSGIHandler()(self.get_suspicious_environ(), lambda"
    ],
    [
        "response = WSGIHandler()(self.get_suspicious_environ(), lambda *a, **k: None)",
        "response = WSGIHandler()(self.get_suspicious_environ(), lambda *a,"
    ],
    [
        "response = WSGIHandler()(environ, lambda *a, **k: None)",
        "response = WSGIHandler()(environ, lambda *a, **k:"
    ],
    [
        "from django.core.handlers.wsgi import WSGIHandler, WSGIRequest, get_script_name",
        "from django.core.handlers.wsgi import WSGIHandler,"
    ],
    [
        "response = handler(environ, lambda *a, **k: None)",
        "response = handler(environ, lambda *a, **k:"
    ],
    [
        "Invalid cookie content should result in an absent cookie, but not in a",
        "Invalid cookie content should result in an"
    ],
    [
        "Invalid boundary string should produce a \"Bad Request\" response, not a",
        "Invalid boundary string should produce a \"Bad Request\" response,"
    ],
    [
        "response = handler(environ, lambda *a, **k: None)",
        "response = handler(environ, lambda"
    ],
    [
        "msg = \"You cannot use ATOMIC_REQUESTS with async views.\"",
        "msg = \"You cannot use ATOMIC_REQUESTS with async"
    ],
    [
        "\"\"\"Calling an async view down the normal synchronous path.\"\"\"",
        "\"\"\"Calling an async view down"
    ],
    [
        "msg = \"Middleware factory handlers.tests.empty_middleware returned None.\"",
        "msg = \"Middleware factory handlers.tests.empty_middleware returned"
    ],
    [
        "\"The view %s didn't return an HttpResponse object. It returned None \"",
        "\"The view %s didn't return an HttpResponse object. It"
    ],
    [
        "\"StreamingHttpResponse must consume asynchronous iterators in order to \"",
        "\"StreamingHttpResponse must consume asynchronous iterators in order"
    ],
    [
        "\"serve them synchronously. Use a synchronous iterator instead.\"",
        "\"serve them synchronously. Use"
    ],
    [
        "script_name = get_script_name({\"SCRIPT_URL\": \"/foobar/\", \"PATH_INFO\": \"/\"})",
        "script_name = get_script_name({\"SCRIPT_URL\": \"/foobar/\","
    ],
    [
        "WSGI squashes multiple successive slashes in PATH_INFO, get_script_name",
        "WSGI squashes multiple successive slashes"
    ],
    [
        "\"\"\"Async variants of the normal handler request tests.\"\"\"",
        "\"\"\"Async variants of the normal handler request"
    ],
    [
        "\"\"\"Calling a sync view down the asynchronous path.\"\"\"",
        "\"\"\"Calling a sync view down the"
    ],
    [
        "\"\"\"Calling an async view down the asynchronous path.\"\"\"",
        "\"\"\"Calling an async view down the asynchronous"
    ],
    [
        "\"The view handlers.views.no_response didn't return an \"",
        "\"The view handlers.views.no_response didn't return"
    ],
    [
        "\"HttpResponse object. It returned None instead.\"",
        "\"HttpResponse object. It"
    ],
    [
        "\" return an HttpResponse object. It returned an unawaited\"",
        "\" return an HttpResponse object. It"
    ],
    [
        "\" coroutine instead. You may need to add an 'await'\"",
        "\" coroutine instead. You may need to add an"
    ],
    [
        "\"StreamingHttpResponse must consume synchronous iterators in order to \"",
        "\"StreamingHttpResponse must consume synchronous iterators in order"
    ],
    [
        "\"serve them asynchronously. Use an asynchronous iterator instead.\"",
        "\"serve them asynchronously. Use an"
    ],
    [
        "b\"\".join([chunk async for chunk in response]), b\"streaming content\"",
        "b\"\".join([chunk async for chunk in response]),"
    ],
    [
        "b\"\".join([chunk async for chunk in response]), b\"streaming content\"",
        "b\"\".join([chunk async for chunk"
    ],
    [
        "\"\"\"Return an unawaited coroutine (common error for async views).\"\"\"",
        "\"\"\"Return an unawaited coroutine (common error for async"
    ],
    [
        "request.makefile = lambda *args, **kwargs: BytesIO()",
        "request.makefile = lambda *args, **kwargs:"
    ],
    [
        "request.makefile = lambda *args, **kwargs: BytesIO()",
        "request.makefile = lambda *args, **kwargs:"
    ],
    [
        "\"You're accessing the development server over HTTPS, \"",
        "\"You're accessing the development server over"
    ],
    [
        "ambiguity between dashes and underscores in mapping to WSGI environ,",
        "ambiguity between dashes and underscores"
    ],
    [
        "\"\"\"A WSGI app that just reflects its HTTP environ.\"\"\"",
        "\"\"\"A WSGI app that just reflects its HTTP"
    ],
    [
        "\"%s:%s\" % (k, v) for k, v in environ.items() if k.startswith(\"HTTP_\")",
        "\"%s:%s\" % (k, v) for k,"
    ],
    [
        "\"\"\"A WSGI app that returns a hello world.\"\"\"",
        "\"\"\"A WSGI app that returns a hello"
    ],
    [
        "any([line.startswith(b\"Content-Length:\") for line in lines]), False",
        "any([line.startswith(b\"Content-Length:\") for line in"
    ],
    [
        "A WSGI app that returns a hello world with non-zero Content-Length.",
        "A WSGI app that returns a"
    ],
    [
        "msg = f\"- Broken pipe from {client_address}\"",
        "msg = f\"- Broken pipe from"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connection, connections",
        "from django.db import DEFAULT_DB_ALIAS,"
    ],
    [
        "@unittest.skipUnless(connection.vendor == \"sqlite\", \"SQLite specific test.\")",
        "@unittest.skipUnless(connection.vendor == \"sqlite\", \"SQLite"
    ],
    [
        "With a threaded LiveServer and an in-memory database, an error can",
        "With a threaded LiveServer and an in-memory database,"
    ],
    [
        "at the same time, if the requests do not share the same database",
        "at the same time, if the requests do not share"
    ],
    [
        "self.fail(\"Unexpected error due to a database lock.\")",
        "self.fail(\"Unexpected error due to a database"
    ],
    [
        "development server is rather simple we support it only in cases where",
        "development server is rather simple we"
    ],
    [
        "we can detect a content length from the response. This should be doable",
        "we can detect a content length from"
    ],
    [
        "for all simple views and streaming responses where an iterable with",
        "for all simple views and streaming"
    ],
    [
        "length of one is passed. The latter follows as result of `set_content_length`",
        "length of one is passed. The latter"
    ],
    [
        "If we cannot detect a content length we explicitly set the `Connection`",
        "If we cannot detect a content"
    ],
    [
        "header to `close` to notify the client that we do not actually support",
        "header to `close` to notify the client that we do"
    ],
    [
        "is a follow up test, which ensure that we do not close the connection",
        "is a follow up test, which ensure"
    ],
    [
        "if not needed, hence allowing us to take advantage of keep-alive.",
        "if not needed, hence allowing us to"
    ],
    [
        "tries to access a static file that isn't explicitly put under",
        "tries to access a static file that isn't"
    ],
    [
        "with self.urlopen(\"/environ_view/?%s\" % urlencode({\"q\": \"тест\"})) as f:",
        "with self.urlopen(\"/environ_view/?%s\" % urlencode({\"q\":"
    ],
    [
        "Fixtures are properly loaded and visible to the live server thread.",
        "Fixtures are properly loaded and visible to"
    ],
    [
        "Data written to the database by a view can be read.",
        "Data written to the database by a view can be"
    ],
    [
        "Each LiveServerTestCase binds to a unique port or fails to start a",
        "Each LiveServerTestCase binds to a unique"
    ],
    [
        "f\"Acquired duplicate server addresses for server threads: \"",
        "f\"Acquired duplicate server addresses"
    ],
    [
        "f\"Did not use specified port for LiveServerTestCase thread: \"",
        "f\"Did not use specified port"
    ],
    [
        "\"\"\"If LiveServerTestCase isn't threaded, these tests will hang.\"\"\"",
        "\"\"\"If LiveServerTestCase isn't threaded, these tests"
    ],
    [
        "url = \"/subview_calling_view/?%s\" % urlencode({\"url\": self.live_server_url})",
        "url = \"/subview_calling_view/?%s\""
    ],
    [
        "return HttpResponse(\"\\n\".join(person.name for person in people))",
        "return HttpResponse(\"\\n\".join(person.name for"
    ],
    [
        "\"\\n\".join(\"%s: %r\" % (k, v) for k, v in request.environ.items())",
        "\"\\n\".join(\"%s: %r\" % (k, v)"
    ],
    [
        "with urlopen(request.GET[\"url\"] + \"/subview/\") as response:",
        "with urlopen(request.GET[\"url\"] + \"/subview/\") as"
    ],
    [
        "with urlopen(request.GET[\"url\"] + \"/model_view/\") as response:",
        "with urlopen(request.GET[\"url\"] + \"/model_view/\")"
    ],
    [
        "Regression tests for Model inheritance behavior.",
        "Regression tests for Model inheritance"
    ],
    [
        "dicts, [{\"name\": \"Guido's House of Pasta\", \"serves_hot_dogs\": True}]",
        "dicts, [{\"name\": \"Guido's House"
    ],
    [
        "\"name\": \"Guido's All New House of Pasta\",",
        "\"name\": \"Guido's All New House of"
    ],
    [
        "\"name\": \"Guido's All New House of Pasta\",",
        "\"name\": \"Guido's All New House"
    ],
    [
        "\"name\": \"Guido's All New House of Pasta\",",
        "\"name\": \"Guido's All New House"
    ],
    [
        "If the parent class has a self-referential link, make sure that any",
        "If the parent class has a self-referential link,"
    ],
    [
        "updates to that link via the child update the right table.",
        "updates to that link via the child update"
    ],
    [
        "It is possible to call update() and only change a field in",
        "It is possible to call update()"
    ],
    [
        "The connector from child to parent need not be the pk on the child.",
        "The connector from child to parent need not be the pk on"
    ],
    [
        "birthday = BirthdayParty.objects.create(name=\"Birthday party for Alice\")",
        "birthday = BirthdayParty.objects.create(name=\"Birthday party for"
    ],
    [
        "bachelor = BachelorParty.objects.create(name=\"Bachelor party for Bob\")",
        "bachelor = BachelorParty.objects.create(name=\"Bachelor party"
    ],
    [
        "messy = MessyBachelorParty.objects.create(name=\"Bachelor party for Dave\")",
        "messy = MessyBachelorParty.objects.create(name=\"Bachelor party"
    ],
    [
        "verbose_name_plural correctly inherited from ABC if inheritance chain",
        "verbose_name_plural correctly inherited from ABC if"
    ],
    [
        "Primary key set correctly with concrete->abstract->concrete inheritance.",
        "Primary key set correctly"
    ],
    [
        "[field for field in BusStation._meta.local_fields if field.primary_key]",
        "[field for field in"
    ],
    [
        "A model which has different primary key for the parent model passes",
        "A model which has different primary key for"
    ],
    [
        "senator = Senator.objects.create(name=\"John Doe\", title=\"X\", state=\"Y\")",
        "senator = Senator.objects.create(name=\"John"
    ],
    [
        "Although it's not a strict requirement, each model should have a ``_str__()``",
        "Although it's not a strict requirement, each"
    ],
    [
        "method to return a \"human-readable\" representation of the object. Do this not",
        "method to return a \"human-readable\" representation of the object. Do"
    ],
    [
        "only for your own sanity when dealing with the interactive prompt, but also",
        "only for your own sanity when dealing with the interactive"
    ],
    [
        "because objects' representations are used throughout Django's",
        "because objects' representations are used throughout"
    ],
    [
        "The default implementation of __str__ and __repr__ should return",
        "The default implementation of __str__ and __repr__ should"
    ],
    [
        "\"\"\"Model subclass with a custom base using metaclass.\"\"\"",
        "\"\"\"Model subclass with a custom base using"
    ],
    [
        "from django.conf import ENVIRONMENT_VARIABLE, LazySettings, Settings, settings",
        "from django.conf import ENVIRONMENT_VARIABLE, LazySettings, Settings,"
    ],
    [
        "@modify_settings(ITEMS={\"prepend\": [\"b\"], \"append\": [\"d\"], \"remove\": [\"a\", \"e\"]})",
        "@modify_settings(ITEMS={\"prepend\": [\"b\"], \"append\": [\"d\"], \"remove\": [\"a\","
    ],
    [
        "@modify_settings(ITEMS={\"prepend\": [\"b\"], \"append\": [\"d\"], \"remove\": [\"a\", \"e\"]})",
        "@modify_settings(ITEMS={\"prepend\": [\"b\"], \"append\": [\"d\"],"
    ],
    [
        "Dummy class for testing max recursion error in child class call to",
        "Dummy class for testing max recursion error in"
    ],
    [
        "Overriding a method on a super class and then calling that method on",
        "Overriding a method on a super class and then"
    ],
    [
        "def signal_callback(self, sender, setting, value, **kwargs):",
        "def signal_callback(self, sender, setting,"
    ],
    [
        "Exception, \"Only subclasses of Django SimpleTestCase\"",
        "Exception, \"Only subclasses of Django"
    ],
    [
        "msg = \"'Settings' object has no attribute 'TEST'\"",
        "msg = \"'Settings' object has no attribute"
    ],
    [
        "override_settings uses the actual _wrapped attribute at",
        "override_settings uses the actual"
    ],
    [
        "runtime, not when it was instantiated.",
        "runtime, not when it was"
    ],
    [
        "msg = \"The SECRET_KEY setting must not be empty.\"",
        "msg = \"The SECRET_KEY setting"
    ],
    [
        "\"Requested setting%s, but settings are not configured. You \"",
        "\"Requested setting%s, but settings are not"
    ],
    [
        "\"must either define the environment variable DJANGO_SETTINGS_MODULE \"",
        "\"must either define the"
    ],
    [
        "\"or call settings.configure() before accessing settings.\"",
        "\"or call settings.configure() before accessing"
    ],
    [
        "with self.assertRaisesMessage(ImproperlyConfigured, msg % \" TEST\"):",
        "with self.assertRaisesMessage(ImproperlyConfigured, msg"
    ],
    [
        "with self.assertRaisesMessage(TypeError, \"Setting 'foo' must be uppercase.\"):",
        "with self.assertRaisesMessage(TypeError, \"Setting 'foo' must be"
    ],
    [
        "with self.assertRaisesMessage(ValueError, \"Incorrect timezone setting: test\"):",
        "with self.assertRaisesMessage(ValueError, \"Incorrect timezone setting:"
    ],
    [
        "msg = \"Overriding setting TEST_WARN can lead to unexpected behavior.\"",
        "msg = \"Overriding setting TEST_WARN can"
    ],
    [
        "expected = '<LazySettings \"%s\">' % module",
        "expected = '<LazySettings \"%s\">'"
    ],
    [
        "expected = '<Settings \"%s\">' % module",
        "expected = '<Settings"
    ],
    [
        "Make sure settings that should be lists or tuples throw",
        "Make sure settings that should"
    ],
    [
        "ImproperlyConfigured if they are set to a string instead of a list or tuple.",
        "ImproperlyConfigured if they are set to a"
    ],
    [
        "msg = \"The %s setting must be a list or a tuple.\"",
        "msg = \"The %s setting must be a list or"
    ],
    [
        "The override_settings context manager restore settings if one of the",
        "The override_settings context manager restore settings"
    ],
    [
        "receivers of \"setting_changed\" signal fails. Check the three cases of",
        "receivers of \"setting_changed\" signal fails. Check"
    ],
    [
        "receiver failure detailed in receiver(). In each case, ALL receivers are",
        "receiver failure detailed in receiver(). In"
    ],
    [
        "called when exiting the context manager.",
        "called when exiting the context"
    ],
    [
        "A receiver that fails while certain settings are being changed.",
        "A receiver that fails while"
    ],
    [
        "- SETTING_BOTH raises an error while receiving the signal",
        "- SETTING_BOTH raises an error while receiving"
    ],
    [
        "on both entering and exiting the context manager.",
        "on both entering and exiting the"
    ],
    [
        "- SETTING_ENTER raises an error only on enter.",
        "- SETTING_ENTER raises an"
    ],
    [
        "- SETTING_EXIT raises an error only on exit.",
        "- SETTING_EXIT raises an error"
    ],
    [
        "if setting in (\"SETTING_BOTH\", \"SETTING_ENTER\") and enter:",
        "if setting in (\"SETTING_BOTH\", \"SETTING_ENTER\") and"
    ],
    [
        "if setting in (\"SETTING_BOTH\", \"SETTING_EXIT\") and not enter:",
        "if setting in (\"SETTING_BOTH\","
    ],
    [
        "\"\"\"Assert that settings for these tests aren't present.\"\"\"",
        "\"\"\"Assert that settings for"
    ],
    [
        "Assert that `self.spy_receiver` was called exactly `call_count` times",
        "Assert that `self.spy_receiver` was called"
    ],
    [
        "\"\"\"Receiver fails on both enter and exit.\"\"\"",
        "\"\"\"Receiver fails on both enter and"
    ],
    [
        "Error is raised correctly when reusing the same override_settings",
        "Error is raised correctly when reusing"
    ],
    [
        "for script_name in [\"/somesubpath\", \"/somesubpath/\", \"/\", \"\", None]:",
        "for script_name in [\"/somesubpath\", \"/somesubpath/\", \"/\","
    ],
    [
        "for script_name, path, expected_path in tests:",
        "for script_name, path,"
    ],
    [
        "unique=True, error_messages={\"unique\": \"Custom unique number message.\"}",
        "unique=True, error_messages={\"unique\": \"Custom"
    ],
    [
        "\"Unique constraint product with this Name and Color \"",
        "\"Unique constraint product with this Name and"
    ],
    [
        "\"Unique constraint product with this Rank already exists.\"",
        "\"Unique constraint product with this"
    ],
    [
        "[\"This is not the answer to life, universe and everything!\"],",
        "[\"This is not the answer to life, universe"
    ],
    [
        "[\"This is not the answer to life, universe and everything!\"],",
        "[\"This is not the answer"
    ],
    [
        "self._test_validation_messages(f, \"fõo\", [\"“fõo” value must be an integer.\"])",
        "self._test_validation_messages(f, \"fõo\", [\"“fõo” value must be"
    ],
    [
        "self._test_validation_messages(f, \"fõo\", [\"“fõo” value must be an integer.\"])",
        "self._test_validation_messages(f, \"fõo\", [\"“fõo” value must be an"
    ],
    [
        "f, \"fõo\", [\"“fõo” value must be either True or False.\"]",
        "f, \"fõo\", [\"“fõo” value must be either True"
    ],
    [
        "f, \"fõo\", [\"“fõo” value must be either True, False, or None.\"]",
        "f, \"fõo\", [\"“fõo” value must be either True, False, or"
    ],
    [
        "self._test_validation_messages(f, \"fõo\", [\"“fõo” value must be a float.\"])",
        "self._test_validation_messages(f, \"fõo\", [\"“fõo” value must be"
    ],
    [
        "f, \"fõo\", [\"“fõo” value must be a decimal number.\"]",
        "f, \"fõo\", [\"“fõo” value must be"
    ],
    [
        "f, \"fõo\", [\"“fõo” value must be either True, False, or None.\"]",
        "f, \"fõo\", [\"“fõo” value must be"
    ],
    [
        "\"“fõo” value has an invalid date format. It must be in YYYY-MM-DD \"",
        "\"“fõo” value has an invalid date format. It must be in"
    ],
    [
        "\"“fõo” value has an invalid format. It must be in \"",
        "\"“fõo” value has an invalid format. It"
    ],
    [
        "\"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) but it is an invalid date/time.\"",
        "\"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) but it is an invalid"
    ],
    [
        "\"“fõo” value has an invalid format. It must be in HH:MM[:ss[.uuuuuu]] \"",
        "\"“fõo” value has an invalid format. It must"
    ],
    [
        "\"model to validate instance with id %r is not a valid choice.\"",
        "\"model to validate instance with id %r is not a valid"
    ],
    [
        "\"unique fields model instance with unique_charfield %r is not \"",
        "\"unique fields model instance with"
    ],
    [
        "mtv.full_clean, \"url\", [\"Enter a valid URL.\"]",
        "mtv.full_clean, \"url\", [\"Enter"
    ],
    [
        "\"title\": \"The state of model validation\",",
        "\"title\": \"The state of"
    ],
    [
        "\"title\": \"The state of model validation\",",
        "\"title\": \"The state"
    ],
    [
        "data = {\"title\": \"The state of model validation\", \"pub_date\": \"never\"}",
        "data = {\"title\": \"The state of model validation\","
    ],
    [
        "Test the Meta.unique_together normalization with different sorts of",
        "Test the Meta.unique_together normalization with different"
    ],
    [
        "\"Meta\", (), {\"unique_together\": unique_together, \"apps\": Apps()}",
        "\"Meta\", (), {\"unique_together\": unique_together,"
    ],
    [
        "\"Unique fields model with this Unique integerfield already exists.\"",
        "\"Unique fields model with this Unique"
    ],
    [
        "{\"title\": [\"Title must be unique for Posted date.\"]},",
        "{\"title\": [\"Title must be unique for"
    ],
    [
        "{\"slug\": [\"Slug must be unique for Posted year.\"]},",
        "{\"slug\": [\"Slug must be"
    ],
    [
        "{\"subtitle\": [\"Subtitle must be unique for Posted month.\"]},",
        "{\"subtitle\": [\"Subtitle must be unique"
    ],
    [
        "cm.exception.message_dict, {\"posted\": [\"This field cannot be null.\"]}",
        "cm.exception.message_dict, {\"posted\": [\"This field cannot"
    ],
    [
        "unique_for_date/year/month checks shouldn't trigger when the",
        "unique_for_date/year/month checks shouldn't trigger when"
    ],
    [
        "cm.exception.message_dict, {\"name\": [\"Custom unique name message.\"]}",
        "cm.exception.message_dict, {\"name\": [\"Custom unique"
    ],
    [
        "cm.exception.message_dict, {\"no\": [\"Custom unique number message.\"]}",
        "cm.exception.message_dict, {\"no\": [\"Custom unique"
    ],
    [
        "Tests the deconstruct() method on all core fields.",
        "Tests the deconstruct() method on all"
    ],
    [
        "Tests the outputting of the correct name if assigned one.",
        "Tests the outputting of the correct"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "_, _, args, kwargs = field.deconstruct()",
        "_, _, args, kwargs"
    ],
    [
        "_, _, args, kwargs = field.deconstruct()",
        "_, _, args,"
    ],
    [
        "_, _, args, kwargs = field.deconstruct()",
        "_, _, args, kwargs"
    ],
    [
        "_, _, args, kwargs = field.deconstruct()",
        "_, _, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "{\"to\": \"auth.permission\", \"unique\": True, \"on_delete\": models.CASCADE},",
        "{\"to\": \"auth.permission\", \"unique\": True, \"on_delete\":"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "kwargs, {\"to\": \"auth.permission\", \"limit_choices_to\": {\"foo\": \"bar\"}}",
        "kwargs, {\"to\": \"auth.permission\", \"limit_choices_to\":"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args,"
    ],
    [
        "name, path, args, kwargs = field.deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "To define a many-to-many relationship, use ``ManyToManyField()``.",
        "To define a many-to-many"
    ],
    [
        "In this example, an ``Article`` can be published in multiple ``Publication``",
        "In this example, an ``Article`` can be published in"
    ],
    [
        "objects, and a ``Publication`` has multiple ``Article`` objects.",
        "objects, and a ``Publication`` has multiple ``Article``"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import"
    ],
    [
        "headline=\"Django lets you build web apps easily\"",
        "headline=\"Django lets you build web"
    ],
    [
        "'\"<Article: Django lets you create web apps easily>\" needs to have '",
        "'\"<Article: Django lets you create web"
    ],
    [
        "'a value for field \"id\" before this many-to-many relationship can be used.'",
        "'a value for field \"id\" before"
    ],
    [
        "\"'Publication' instance expected, got <Article: Django lets you create web \"",
        "\"'Publication' instance expected, got <Article: Django"
    ],
    [
        "msg = \"Field 'id' expected a number but got 'invalid'.\"",
        "msg = \"Field 'id' expected"
    ],
    [
        "A single query is necessary to add auto-created through instances if",
        "A single query is necessary to add"
    ],
    [
        "the database backend supports bulk_create(ignore_conflicts) and no",
        "the database backend supports bulk_create(ignore_conflicts)"
    ],
    [
        "\"Direct assignment to the reverse side of a many-to-many set is \"",
        "\"Direct assignment to the reverse side of a many-to-many set is"
    ],
    [
        "\"Direct assignment to the forward side of a many-to-many \"",
        "\"Direct assignment to the forward side of a"
    ],
    [
        "\"set is prohibited. Use publications.set() instead.\"",
        "\"set is prohibited. Use publications.set()"
    ],
    [
        "headline=\"Django lets you build web apps easily\"",
        "headline=\"Django lets you build"
    ],
    [
        "SQL is optimized to reference the through table without joining against the",
        "SQL is optimized to reference the through table without"
    ],
    [
        "related table when using count() and exists() functions on a queryset for",
        "related table when using count() and exists() functions on a"
    ],
    [
        "many to many relations. The optimization applies to the case where there",
        "many to many relations. The optimization"
    ],
    [
        "headline=\"Django lets you build Web apps easily\"",
        "headline=\"Django lets you build Web"
    ],
    [
        "from .models import Car, Part, Person, SportsCar",
        "from .models import Car, Part,"
    ],
    [
        "method, but the behavior of pk_sets differs by action.",
        "method, but the behavior of pk_sets differs"
    ],
    [
        "- For signals related to `add()`, only PKs that will actually be",
        "- For signals related to `add()`, only PKs that"
    ],
    [
        "- For `remove()` all PKs are sent, even if they will not affect the DB.",
        "- For `remove()` all PKs are sent, even if they will not"
    ],
    [
        "\"Testing GeometryField with a SRID set.\"",
        "\"Testing GeometryField with a SRID"
    ],
    [
        "\"Testing GeometryField's handling of null (None) geometries.\"",
        "\"Testing GeometryField's handling of null"
    ],
    [
        "with self.assertRaisesMessage(ValidationError, \"No geometry value provided.\"):",
        "with self.assertRaisesMessage(ValidationError, \"No"
    ],
    [
        "\"Testing GeometryField's handling of different geometry types.\"",
        "\"Testing GeometryField's handling of"
    ],
    [
        "to_python() either returns a correct GEOSGeometry object or",
        "to_python() either returns a"
    ],
    [
        "Initialization of a geometry field with a valid/empty/invalid string.",
        "Initialization of a geometry field"
    ],
    [
        "Only the invalid string should trigger an error log entry.",
        "Only the invalid string should trigger an error log"
    ],
    [
        "\"unrecognized as WKT EWKT, and HEXEWKB.)\",",
        "\"unrecognized as WKT EWKT, and"
    ],
    [
        "Make sure the MapWidget js is passed in the form media and a MapWidget",
        "Make sure the MapWidget js is passed in the form"
    ],
    [
        "\"\"\"Makes sure the wkt and a textarea are in the content\"\"\"",
        "\"\"\"Makes sure the wkt and a textarea"
    ],
    [
        "invalid = PointForm(data={\"p\": \"some invalid geom\"})",
        "invalid = PointForm(data={\"p\":"
    ],
    [
        "for invalid in [geo for key, geo in self.geometries.items() if key != \"point\"]:",
        "for invalid in [geo for key, geo in self.geometries.items() if key"
    ],
    [
        "geo for key, geo in self.geometries.items() if key != \"multipoint\"",
        "geo for key, geo in"
    ],
    [
        "geo for key, geo in self.geometries.items() if key != \"linestring\"",
        "geo for key, geo in"
    ],
    [
        "geo for key, geo in self.geometries.items() if key != \"multilinestring\"",
        "geo for key, geo in self.geometries.items() if"
    ],
    [
        "geo for key, geo in self.geometries.items() if key != \"polygon\"",
        "geo for key, geo in self.geometries.items() if key !="
    ],
    [
        "geo for key, geo in self.geometries.items() if key != \"multipolygon\"",
        "geo for key, geo in self.geometries.items()"
    ],
    [
        "geo for key, geo in self.geometries.items() if key != \"geometrycollection\"",
        "geo for key, geo in self.geometries.items() if key !="
    ],
    [
        "return value.json if value else \"\"",
        "return value.json if"
    ],
    [
        "Distance and Area objects to allow for sensible and convenient calculation",
        "Distance and Area objects to allow for sensible and"
    ],
    [
        "and conversions. Here are some tests.",
        "and conversions. Here are some"
    ],
    [
        "from django.contrib.gis.measure import A, Area, D, Distance",
        "from django.contrib.gis.measure import A, Area,"
    ],
    [
        "msg = \"Unknown unit type: invalid-unit-name\"",
        "msg = \"Unknown unit type:"
    ],
    [
        "msg = \"TestFunc Func was mutated during compilation.\"",
        "msg = \"TestFunc Func"
    ],
    [
        "Skip a test unless a database supports all of gis_lookups.",
        "Skip a test unless a database supports all of"
    ],
    [
        "if any(key not in connection.ops.gis_operators for key in gis_lookups):",
        "if any(key not in connection.ops.gis_operators"
    ],
    [
        "\"Database doesn't support all the lookups: %s\"",
        "\"Database doesn't support all the lookups:"
    ],
    [
        "\"\"\"Assert that Func expressions aren't mutated during their as_sql().\"\"\"",
        "\"\"\"Assert that Func expressions aren't mutated during their"
    ],
    [
        "\"%s Func was mutated during compilation.\" % func.__class__.__name__",
        "\"%s Func was mutated"
    ],
    [
        "msg = \"Path must be a valid database or directory containing databases.\"",
        "msg = \"Path must be a valid database"
    ],
    [
        "functions = (g.city, g.geos, g.lat_lon, g.lon_lat)",
        "functions = (g.city, g.geos, g.lat_lon,"
    ],
    [
        "msg = \"Invalid GeoIP city data file: \"",
        "msg = \"Invalid GeoIP city"
    ],
    [
        "for function, value in itertools.product(functions, values):",
        "for function, value"
    ],
    [
        "msg = f\"The address {query} is not in the database.\"",
        "msg = f\"The address {query}"
    ],
    [
        "msg = \"GeoIP path must be provided via parameter or the GEOIP_PATH setting.\"",
        "msg = \"GeoIP path must be provided via parameter or the"
    ],
    [
        "Test retrieval of SpatialRefSys model objects.",
        "Test retrieval of SpatialRefSys"
    ],
    [
        "Test getting OSR objects from SpatialRefSys model objects.",
        "Test getting OSR objects from"
    ],
    [
        "Test adding a new entry in the SpatialRefSys model using the",
        "Test adding a new entry in the SpatialRefSys model"
    ],
    [
        "\"Error for WKT 'INVALID_WKT': Corrupt data.\\n\"",
        "\"Error for WKT 'INVALID_WKT':"
    ],
    [
        "This module has the mock object definitions used to hold reference geometry",
        "This module has the mock object definitions used to hold reference"
    ],
    [
        "for the GEOS and GDAL tests.",
        "for the GEOS and GDAL"
    ],
    [
        "\"Turn all nested sequences to tuples in given sequence.\"",
        "\"Turn all nested sequences to"
    ],
    [
        "return tuple(tuplize(i) for i in seq)",
        "return tuple(tuplize(i) for"
    ],
    [
        "\"Converts all keys in dictionary to str type.\"",
        "\"Converts all keys in dictionary"
    ],
    [
        "return {str(k): v for k, v in d.items()}",
        "return {str(k): v for k, v"
    ],
    [
        "return os.path.join(TEST_DATA, name, name + \".%s\" % ext)",
        "return os.path.join(TEST_DATA, name, name +"
    ],
    [
        "Base testing object, turns keyword args into attributes.",
        "Base testing object, turns keyword args"
    ],
    [
        "Object for testing GDAL data sources.",
        "Object for testing"
    ],
    [
        "def __init__(self, name, *, ext=\"shp\", **kwargs):",
        "def __init__(self, name, *,"
    ],
    [
        "Testing object used for wrapping reference geometry data",
        "Testing object used for wrapping reference"
    ],
    [
        "def __init__(self, *, coords=None, centroid=None, ext_ring_cs=None, **kwargs):",
        "def __init__(self, *, coords=None,"
    ],
    [
        "Each attribute of this object is a list of `TestGeom` instances.",
        "Each attribute of this object is a list of `TestGeom`"
    ],
    [
        "setattr(self, key, [TestGeom(**strconvert(kw)) for kw in value])",
        "setattr(self, key, [TestGeom(**strconvert(kw)) for"
    ],
    [
        "Mixin used for GEOS/GDAL test cases that defines a `geometries`",
        "Mixin used for GEOS/GDAL test cases"
    ],
    [
        "property, which returns and/or loads the reference geometry data.",
        "property, which returns and/or loads"
    ],
    [
        "raise NotImplementedError(\"This function was not expected to be called\")",
        "raise NotImplementedError(\"This function was not expected to"
    ],
    [
        "@unittest.skipUnless(HAS_POSTGRES, \"The psycopg driver is needed for these tests\")",
        "@unittest.skipUnless(HAS_POSTGRES, \"The psycopg driver is"
    ],
    [
        "The PostGIS version check parses correctly the version numbers",
        "The PostGIS version check parses correctly"
    ],
    [
        "from django.contrib.gis.gdal import GDAL_VERSION, GDALRaster, SpatialReference",
        "from django.contrib.gis.gdal import GDAL_VERSION,"
    ],
    [
        "Test a GDALRaster instance created from a file (GeoTiff).",
        "Test a GDALRaster instance created"
    ],
    [
        "rs_path = Path(__file__).parent.parent / \"data\" / \"rasters\" / \"raster.tif\"",
        "rs_path = Path(__file__).parent.parent / \"data\" / \"rasters\" /"
    ],
    [
        "msg = 'Unable to read raster source input \"nonexistent.tif\".'",
        "msg = 'Unable to read raster source input"
    ],
    [
        "msg = 'Could not open the datasource at \"/vsimem/raster.tif\"'",
        "msg = 'Could not open the datasource at"
    ],
    [
        "msg = \"Failed creating VSI raster from the input buffer.\"",
        "msg = \"Failed creating VSI raster from"
    ],
    [
        "rst_path = \"/vsizip/\" + os.path.join(rst_zipfile.name, \"raster.tif\")",
        "rst_path = \"/vsizip/\" +"
    ],
    [
        "info_lines = [line.strip() for line in infos.split(\"\\n\") if line.strip() != \"\"]",
        "info_lines = [line.strip() for line in infos.split(\"\\n\")"
    ],
    [
        "for driver, name, nodata_value in tests:",
        "for driver, name, nodata_value in"
    ],
    [
        "smin, smax, smean, sstd = band.statistics(approximate=True)",
        "smin, smax, smean,"
    ],
    [
        "smin, smax, smean, sstd = band.statistics(approximate=False, refresh=True)",
        "smin, smax, smean, sstd ="
    ],
    [
        "packed_block = struct.pack(\"<\" + \"B B B B\", *block)",
        "packed_block = struct.pack(\"<\" + \"B B B B\","
    ],
    [
        "invalid_drivers = (\"Foo baz\", \"clucka\", \"ESRI Shp\", \"ESRI rast\")",
        "invalid_drivers = (\"Foo baz\", \"clucka\","
    ],
    [
        "\"Testing valid GDAL/OGR Data Source Drivers.\"",
        "\"Testing valid GDAL/OGR"
    ],
    [
        "\"Testing invalid GDAL/OGR Data Source Drivers.\"",
        "\"Testing invalid GDAL/OGR Data Source"
    ],
    [
        "Prototypes are registered only if the driver count is zero.",
        "Prototypes are registered only if the driver count is"
    ],
    [
        "msg = \"Index out of range when accessing points of a line string: %s.\"",
        "msg = \"Index out of range when accessing points of a line string:"
    ],
    [
        "x = [tmpx for tmpx, tmpy in ls.coords]",
        "x = [tmpx for tmpx,"
    ],
    [
        "y = [tmpy for tmpx, tmpy in ls.coords]",
        "y = [tmpy for tmpx, tmpy in"
    ],
    [
        "msg = \"Index out of range when accessing geometry in a collection: %s.\"",
        "msg = \"Index out of range when accessing geometry"
    ],
    [
        "msg = \"Index out of range when accessing rings of a polygon: %s.\"",
        "msg = \"Index out of range when accessing rings"
    ],
    [
        "msg = \"Index out of range when accessing geometry in a collection: %s.\"",
        "msg = \"Index out of range when accessing geometry in a collection:"
    ],
    [
        "\"Testing OGR Geometries with Spatial Reference objects.\"",
        "\"Testing OGR Geometries with"
    ],
    [
        "\"Testing coordinate dimension is the same on transformed geometries.\"",
        "\"Testing coordinate dimension is the same on transformed"
    ],
    [
        "\"Testing coordinate dimensions on geometries after transformation.\"",
        "\"Testing coordinate dimensions on geometries"
    ],
    [
        "\"Testing equivalence methods with non-OGRGeometry instances.\"",
        "\"Testing equivalence methods with non-OGRGeometry"
    ],
    [
        "msg = f\"Unsupported geometry type: {type_}\"",
        "msg = f\"Unsupported geometry type:"
    ],
    [
        "msg = \"Input to 'set_measured' must be a boolean, got 'None'\"",
        "msg = \"Input to 'set_measured' must be a boolean,"
    ],
    [
        "msg = f\"GEOS does not support {geom.__class__.__qualname__}.\"",
        "msg = f\"GEOS does not"
    ],
    [
        "msg = f\"GEOS does not support {g.__class__.__qualname__}.\"",
        "msg = f\"GEOS does"
    ],
    [
        "\"Testing initialization on valid OGC WKT.\"",
        "\"Testing initialization on valid OGC"
    ],
    [
        "self.fail('Should not have initialized on bad WKT \"%s\"!')",
        "self.fail('Should not have initialized on"
    ],
    [
        "\"Testing the linear and angular units routines.\"",
        "\"Testing the linear and"
    ],
    [
        "\"Testing the authority name & code routines.\"",
        "\"Testing the authority name & code"
    ],
    [
        "\"Testing Well Known Names of Spatial References.\"",
        "\"Testing Well Known Names of Spatial"
    ],
    [
        "msg = \"SpatialReference.axis_order must be an AxisOrder instance.\"",
        "msg = \"SpatialReference.axis_order must be an AxisOrder"
    ],
    [
        "\"\"\"The srid property returns top-level authority code.\"\"\"",
        "\"\"\"The srid property returns top-level"
    ],
    [
        "from django.contrib.gis.gdal import DataSource, Envelope, GDALException, OGRGeometry",
        "from django.contrib.gis.gdal import DataSource, Envelope, GDALException,"
    ],
    [
        "from django.contrib.gis.gdal.field import OFTDateTime, OFTInteger, OFTReal, OFTString",
        "from django.contrib.gis.gdal.field import OFTDateTime, OFTInteger,"
    ],
    [
        "from ..test_data import TEST_DATA, TestDS, get_ds_file",
        "from ..test_data import TEST_DATA,"
    ],
    [
        "fields={\"dbl\": OFTReal, \"int\": OFTInteger, \"str\": OFTString},",
        "fields={\"dbl\": OFTReal, \"int\": OFTInteger, \"str\":"
    ],
    [
        "fields={\"float\": OFTReal, \"int\": OFTInteger, \"str\": OFTString},",
        "fields={\"float\": OFTReal, \"int\":"
    ],
    [
        "\"Testing valid SHP Data Source files.\"",
        "\"Testing valid SHP Data"
    ],
    [
        "msg = \"Index out of range when accessing layers in a datasource: %s.\"",
        "msg = \"Index out of range when accessing layers"
    ],
    [
        "IndexError, \"Invalid OGR layer name given: invalid.\"",
        "IndexError, \"Invalid OGR layer name given:"
    ],
    [
        "\"Testing invalid SHP files for the Data Source.\"",
        "\"Testing invalid SHP files for the"
    ],
    [
        "IndexError, \"Negative indices are not allowed on OGR Layers.\"",
        "IndexError, \"Negative indices are not"
    ],
    [
        "\"Index out of range when accessing field in a feature: %s.\"",
        "\"Index out of range when accessing field in a feature:"
    ],
    [
        "IndexError, \"Invalid OFT field name given: invalid.\"",
        "IndexError, \"Invalid OFT field name given:"
    ],
    [
        "\"Test indexing and slicing on Layers.\"",
        "\"Test indexing and"
    ],
    [
        "test_vals = [feat.get(fld_name) for feat in feats]",
        "test_vals = [feat.get(fld_name) for feat"
    ],
    [
        "Ensure OGR objects keep references to the objects they belong to.",
        "Ensure OGR objects keep references to the"
    ],
    [
        "\"Testing Geometries from Data Source Features.\"",
        "\"Testing Geometries from Data"
    ],
    [
        "for feat, geom, geos_geom in zip(layer, geoms, geos_geoms):",
        "for feat, geom, geos_geom in zip(layer, geoms,"
    ],
    [
        "feats = [feat for feat in lyr]",
        "feats = [feat for"
    ],
    [
        "feats = [feat for feat in lyr]",
        "feats = [feat for"
    ],
    [
        "\"Testing that OFTReal fields, treated as OFTInteger, do not overflow.\"",
        "\"Testing that OFTReal fields, treated"
    ],
    [
        "msg = \"invalid field name: nonexistent\"",
        "msg = \"invalid field"
    ],
    [
        "\"Testing Envelope expand_to_include -- point as two parameters.\"",
        "\"Testing Envelope expand_to_include --"
    ],
    [
        "\"Testing Envelope expand_to_include with Envelope as parameter.\"",
        "\"Testing Envelope expand_to_include with Envelope"
    ],
    [
        "\"Testing Envelope expand_to_include with Point as parameter.\"",
        "\"Testing Envelope expand_to_include with Point as"
    ],
    [
        "from django.contrib.gis.gdal import GDAL_VERSION, gdal_full_version, gdal_version",
        "from django.contrib.gis.gdal import"
    ],
    [
        "msg = \"invalid GEOS Geometry index: %s\" % i",
        "msg = \"invalid GEOS Geometry index: %s\""
    ],
    [
        "AttributeError, \"WKT output rounding precision must be \"",
        "AttributeError, \"WKT output rounding precision must"
    ],
    [
        "ValueError, \"Empty point is not representable in WKB.\"",
        "ValueError, \"Empty point is not representable in"
    ],
    [
        "ValueError, \"Empty point is not representable in WKB.\"",
        "ValueError, \"Empty point is"
    ],
    [
        "GEOSGeometry(wkb_w.write_hex(p)), p if srid else p_no_srid",
        "GEOSGeometry(wkb_w.write_hex(p)), p if"
    ],
    [
        "self.assertEqual(GEOSGeometry(wkb_w.write(p)), p if srid else p_no_srid)",
        "self.assertEqual(GEOSGeometry(wkb_w.write(p)), p if srid"
    ],
    [
        "msg = \"String input unrecognized as WKT EWKT, and HEXEWKB.\"",
        "msg = \"String input unrecognized"
    ],
    [
        "ewkt = \"SRID=%d;%s\" % (srid, p.wkt)",
        "ewkt = \"SRID=%d;%s\""
    ],
    [
        "(\"POINT EMPTY\", \"POINT Z EMPTY\", False),",
        "(\"POINT EMPTY\", \"POINT"
    ],
    [
        "self.assertEqual(mp.coords, tuple(m.tuple for m in mpnt))",
        "self.assertEqual(mp.coords, tuple(m.tuple for m in"
    ],
    [
        "ls.wkt, LineString(*tuple(Point(tup) for tup in ls.tuple)).wkt",
        "ls.wkt, LineString(*tuple(Point(tup) for"
    ],
    [
        "TypeError, \"Each coordinate should be a sequence (list or tuple)\"",
        "TypeError, \"Each coordinate should be"
    ],
    [
        "TypeError, \"Invalid initialization input for LineStrings.\"",
        "TypeError, \"Invalid initialization"
    ],
    [
        "msg = \"Orientation of an empty LinearRing cannot be determined.\"",
        "msg = \"Orientation of an empty LinearRing cannot be"
    ],
    [
        "msg = 'Error encountered in GEOS C function \"GEOSCoordSeq_isCCW\".'",
        "msg = 'Error encountered in GEOS C"
    ],
    [
        "self.assertEqual(ml.wkt, MultiLineString(*tuple(s.clone() for s in ml)).wkt)",
        "self.assertEqual(ml.wkt, MultiLineString(*tuple(s.clone() for s"
    ],
    [
        "ml, MultiLineString(*tuple(LineString(s.tuple) for s in ml))",
        "ml, MultiLineString(*tuple(LineString(s.tuple) for"
    ],
    [
        "self.assertEqual(lr, LinearRing([list(tup) for tup in lr.tuple]))",
        "self.assertEqual(lr, LinearRing([list(tup) for"
    ],
    [
        "ring_tuples = tuple(r.tuple for r in poly)",
        "ring_tuples = tuple(r.tuple for"
    ],
    [
        "self.assertEqual(poly.wkt, Polygon(*tuple(r for r in poly)).wkt)",
        "self.assertEqual(poly.wkt, Polygon(*tuple(r for r in"
    ],
    [
        "poly.wkt, Polygon(*tuple(LinearRing(r.tuple) for r in poly)).wkt",
        "poly.wkt, Polygon(*tuple(LinearRing(r.tuple) for r"
    ],
    [
        "mpoly.wkt, MultiPolygon(*tuple(poly.clone() for poly in mpoly)).wkt",
        "mpoly.wkt, MultiPolygon(*tuple(poly.clone() for poly"
    ],
    [
        "\"Testing Geometry __del__() on rings and polygons.\"",
        "\"Testing Geometry __del__() on"
    ],
    [
        "\"Testing the SRID property and keyword.\"",
        "\"Testing the SRID"
    ],
    [
        "ValueError, \"Input geometry already has SRID: %d.\" % pnt.srid",
        "ValueError, \"Input geometry already has"
    ],
    [
        "ValueError, \"Input geometry already has SRID: %d.\" % pnt.srid",
        "ValueError, \"Input geometry already has SRID: %d.\" %"
    ],
    [
        "\"\"\"Test with a null srid and a srid unknown to GDAL.\"\"\"",
        "\"\"\"Test with a null srid and a srid"
    ],
    [
        "\"Testing the mutability of Polygons and Geometry Collections.\"",
        "\"Testing the mutability of Polygons and Geometry"
    ],
    [
        "\"Testing GeometryCollection handling of other collections.\"",
        "\"Testing GeometryCollection handling"
    ],
    [
        "coll = [mp.wkt for mp in self.geometries.multipolygons if mp.valid]",
        "coll = [mp.wkt for mp"
    ],
    [
        "\"Testing use with the Python `copy` module.\"",
        "\"Testing use with the"
    ],
    [
        "\"\"\"Testing `transform` method (no SRID or negative SRID)\"\"\"",
        "\"\"\"Testing `transform` method (no SRID or negative"
    ],
    [
        "return [GEOSGeometry(tg.wkt, srid) for tg in lst]",
        "return [GEOSGeometry(tg.wkt, srid) for tg"
    ],
    [
        "for geom, merged in zip(ref_geoms, ref_merged):",
        "for geom, merged in zip(ref_geoms,"
    ],
    [
        "g.valid_reason.startswith(\"Too few points in geometry component\")",
        "g.valid_reason.startswith(\"Too few points in geometry"
    ],
    [
        "GEOSGeometry subclass may itself be subclassed without being forced-cast",
        "GEOSGeometry subclass may itself be"
    ],
    [
        "to the parent class during `__init__`.",
        "to the parent class during"
    ],
    [
        "return \"EXT_POLYGON - data: %d - %s\" % (self._data, self.wkt)",
        "return \"EXT_POLYGON - data: %d - %s\""
    ],
    [
        "msg = \"Expected WKT but got an empty string.\"",
        "msg = \"Expected WKT but"
    ],
    [
        "msg = \"EWKT has invalid SRID part.\"",
        "msg = \"EWKT has"
    ],
    [
        "Tests base class ListMixin by comparing a list clone which is",
        "Tests base class ListMixin by comparing a"
    ],
    [
        "a ListMixin subclass with a real Python list.",
        "a ListMixin subclass with"
    ],
    [
        "return range(-self.limit - b, self.limit + b)",
        "return range(-self.limit - b, self.limit +"
    ],
    [
        "self.assertEqual(pl[i:], ul[i:], \"slice [%d:]\" % (i))",
        "self.assertEqual(pl[i:], ul[i:], \"slice [%d:]\""
    ],
    [
        "self.assertEqual(pl[:i], ul[:i], \"slice [:%d]\" % (i))",
        "self.assertEqual(pl[:i], ul[:i], \"slice [:%d]\""
    ],
    [
        "self.assertEqual(pl[i:j], ul[i:j], \"slice [%d:%d]\" % (i, j))",
        "self.assertEqual(pl[i:j], ul[i:j], \"slice [%d:%d]\" % (i,"
    ],
    [
        "pl[i:j:k], ul[i:j:k], \"slice [%d:%d:%d]\" % (i, j, k)",
        "pl[i:j:k], ul[i:j:k], \"slice [%d:%d:%d]\" %"
    ],
    [
        "self.assertEqual(pl[i::k], ul[i::k], \"slice [%d::%d]\" % (i, k))",
        "self.assertEqual(pl[i::k], ul[i::k], \"slice [%d::%d]\" %"
    ],
    [
        "self.assertEqual(pl[:i:k], ul[:i:k], \"slice [:%d:%d]\" % (i, k))",
        "self.assertEqual(pl[:i:k], ul[:i:k], \"slice [:%d:%d]\""
    ],
    [
        "self.assertEqual(pl[::k], ul[::k], \"slice [::%d]\" % (k))",
        "self.assertEqual(pl[::k], ul[::k], \"slice [::%d]\" %"
    ],
    [
        "def setfcn(x, i, j, k, L):",
        "def setfcn(x, i, j,"
    ],
    [
        "self.assertEqual(pl, ul[:], \"set slice [%d:]\" % (i))",
        "self.assertEqual(pl, ul[:], \"set slice [%d:]\""
    ],
    [
        "self.assertEqual(pl, ul[:], \"set slice [:%d]\" % (i))",
        "self.assertEqual(pl, ul[:], \"set slice [:%d]\" %"
    ],
    [
        "self.assertEqual(pl, ul[:], \"set slice [%d:%d]\" % (i, j))",
        "self.assertEqual(pl, ul[:], \"set slice [%d:%d]\" %"
    ],
    [
        "self.assertEqual(pl, ul[:], \"set slice [%d:%d:%d]\" % (i, j, k))",
        "self.assertEqual(pl, ul[:], \"set slice [%d:%d:%d]\""
    ],
    [
        "self.assertEqual(pl, ul[:], \"set slice [%d::%d]\" % (i, k))",
        "self.assertEqual(pl, ul[:], \"set slice [%d::%d]\""
    ],
    [
        "self.assertEqual(pl, ul[:], \"set slice [:%d:%d]\" % (i, k))",
        "self.assertEqual(pl, ul[:], \"set slice"
    ],
    [
        "self.assertEqual(pl, ul[:], \"set slice [::%d]\" % (k))",
        "self.assertEqual(pl, ul[:], \"set slice"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"del slice [%d:]\" % (i))",
        "self.assertEqual(pl[:], ul[:], \"del slice [%d:]\" %"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"del slice [:%d]\" % (i))",
        "self.assertEqual(pl[:], ul[:], \"del slice [:%d]\" %"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"del slice [%d:%d]\" % (i, j))",
        "self.assertEqual(pl[:], ul[:], \"del slice [%d:%d]\" %"
    ],
    [
        "pl[:], ul[:], \"del slice [%d:%d:%d]\" % (i, j, k)",
        "pl[:], ul[:], \"del slice [%d:%d:%d]\" % (i, j,"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"del slice [:%d:%d]\" % (i, k))",
        "self.assertEqual(pl[:], ul[:], \"del slice [:%d:%d]\" % (i,"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"del slice [%d::%d]\" % (i, k))",
        "self.assertEqual(pl[:], ul[:], \"del slice [%d::%d]\""
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"del slice [::%d]\" % (k))",
        "self.assertEqual(pl[:], ul[:], \"del slice"
    ],
    [
        "self.assertEqual(pl[i], ul[i], \"get single item [%d]\" % i)",
        "self.assertEqual(pl[i], ul[i], \"get single item"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"set single item [%d]\" % i)",
        "self.assertEqual(pl[:], ul[:], \"set single item [%d]\" %"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"del single item [%d]\" % i)",
        "self.assertEqual(pl[:], ul[:], \"del single item [%d]\" %"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"insert at %d\" % i)",
        "self.assertEqual(pl[:], ul[:], \"insert at %d\""
    ],
    [
        "self.assertEqual(pl.pop(i), ul.pop(i), \"popped value at %d\" % i)",
        "self.assertEqual(pl.pop(i), ul.pop(i), \"popped value at"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"after pop at %d\" % i)",
        "self.assertEqual(pl[:], ul[:], \"after pop at"
    ],
    [
        "self.assertEqual(pl.index(val), ul.index(val), \"index of %d\" % val)",
        "self.assertEqual(pl.index(val), ul.index(val), \"index of"
    ],
    [
        "self.assertEqual(pl.count(val), ul.count(val), \"count %d\" % val)",
        "self.assertEqual(pl.count(val), ul.count(val), \"count %d\""
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"after remove val %d\" % val)",
        "self.assertEqual(pl[:], ul[:], \"after remove val %d\""
    ],
    [
        "\"Error on assigning non-iterable to slice\"",
        "\"Error on assigning non-iterable"
    ],
    [
        "ul._checkindex(i), i + self.limit, \"_checkindex(neg index)\"",
        "ul._checkindex(i), i +"
    ],
    [
        "self.assertEqual(list(pl + al), list(ul + al), \"add\")",
        "self.assertEqual(list(pl + al), list(ul +"
    ],
    [
        "self.assertEqual(type(ul), type(ul + al), \"type of add result\")",
        "self.assertEqual(type(ul), type(ul + al), \"type of add"
    ],
    [
        "self.assertEqual(list(al + pl), list(al + ul), \"radd\")",
        "self.assertEqual(list(al + pl), list(al +"
    ],
    [
        "self.assertEqual(type(al), type(al + ul), \"type of radd result\")",
        "self.assertEqual(type(al), type(al + ul), \"type of"
    ],
    [
        "self.assertEqual(list(pl * n), list(ul * n), \"mul by %d\" % n)",
        "self.assertEqual(list(pl * n), list(ul * n), \"mul by %d\""
    ],
    [
        "self.assertEqual(type(ul), type(ul * n), \"type of mul by %d result\" % n)",
        "self.assertEqual(type(ul), type(ul * n), \"type of"
    ],
    [
        "self.assertEqual(list(n * pl), list(n * ul), \"rmul by %d\" % n)",
        "self.assertEqual(list(n * pl), list(n * ul), \"rmul by"
    ],
    [
        "self.assertEqual(type(ul), type(n * ul), \"type of rmul by %d result\" % n)",
        "self.assertEqual(type(ul), type(n * ul), \"type of rmul"
    ],
    [
        "self.assertEqual(pl[:], ul[:], \"in-place mul by %d\" % n)",
        "self.assertEqual(pl[:], ul[:], \"in-place mul"
    ],
    [
        "self.assertEqual(objid, id(ul), \"in-place mul by %d id\" % n)",
        "self.assertEqual(objid, id(ul), \"in-place mul by %d id\" %"
    ],
    [
        "self.assertGreaterEqual(pl, ul, \"cmp for gte self\")",
        "self.assertGreaterEqual(pl, ul, \"cmp"
    ],
    [
        "self.assertLessEqual(pl, ul, \"cmp for lte self\")",
        "self.assertLessEqual(pl, ul, \"cmp for lte"
    ],
    [
        "self.assertGreaterEqual(ul, pl, \"cmp for self gte\")",
        "self.assertGreaterEqual(ul, pl, \"cmp"
    ],
    [
        "self.assertLessEqual(ul, pl, \"cmp for self lte\")",
        "self.assertLessEqual(ul, pl, \"cmp for self"
    ],
    [
        "self.assertGreater(pl, ul, \"cmp for gt self\")",
        "self.assertGreater(pl, ul, \"cmp"
    ],
    [
        "self.assertLess(ul, pl, \"cmp for self lt\")",
        "self.assertLess(ul, pl, \"cmp for self"
    ],
    [
        "self.assertLess(pl, ul, \"cmp for lt self\")",
        "self.assertLess(pl, ul, \"cmp"
    ],
    [
        "self.assertGreater(ul, pl, \"cmp for gt self\")",
        "self.assertGreater(ul, pl, \"cmp for gt"
    ],
    [
        "Tests Pythonic Mutability of Python GEOS geometry wrappers",
        "Tests Pythonic Mutability of Python GEOS geometry"
    ],
    [
        "get/set/delitem on a slice, normal list methods",
        "get/set/delitem on a slice, normal list"
    ],
    [
        "self.assertEqual(f(q), f(p), \"Point \" + f.__name__)",
        "self.assertEqual(f(q), f(p), \"Point"
    ],
    [
        "self.assertEqual(f(lsa), f(ls), \"LineString \" + f.__name__)",
        "self.assertEqual(f(lsa), f(ls), \"LineString \""
    ],
    [
        "self.assertEqual(f(lsa), f(pg), \"Polygon \" + f.__name__)",
        "self.assertEqual(f(lsa), f(pg), \"Polygon \" +"
    ],
    [
        "self.assertEqual(f(lsa), f(mp), \"MultiPoint \" + f.__name__)",
        "self.assertEqual(f(lsa), f(mp), \"MultiPoint \""
    ],
    [
        "from django.contrib.gis.db.models import F, GeometryField, Value, functions",
        "from django.contrib.gis.db.models import F, GeometryField, Value,"
    ],
    [
        "from .models import City, ManyPointModel, MultiFields",
        "from .models import"
    ],
    [
        "from django.contrib.gis.geos import LinearRing, Point, Polygon",
        "from django.contrib.gis.geos import LinearRing,"
    ],
    [
        "from .models import City, MultiFields, PennsylvaniaCity",
        "from .models import"
    ],
    [
        "'geojson' should be listed in available serializers.",
        "'geojson' should be listed in available"
    ],
    [
        "When a model has several geometry fields, the 'geometry_field' option",
        "When a model has several"
    ],
    [
        "can be used to specify the field to use as the 'geometry' key.",
        "can be used to specify the field to use as the"
    ],
    [
        "By default Django uses the pk of the object as the id for a feature.",
        "By default Django uses the pk of the object as the"
    ],
    [
        "The 'id_field' option can be used to specify a different field to use",
        "The 'id_field' option can be used to specify a different field"
    ],
    [
        "The fields option allows to define a subset of fields to be present in",
        "The fields option allows to define a subset of"
    ],
    [
        "the 'properties' of the generated output.",
        "the 'properties' of the generated"
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import TestCase, modify_settings,"
    ],
    [
        "actual = {n.nodeName for n in elem.childNodes}",
        "actual = {n.nodeName for n"
    ],
    [
        "from django.contrib.gis.db.models import GeometryField, PolygonField, functions",
        "from django.contrib.gis.db.models import GeometryField,"
    ],
    [
        "from django.contrib.gis.geos import GEOSGeometry, LineString, Point, Polygon, fromstr",
        "from django.contrib.gis.geos import GEOSGeometry, LineString, Point, Polygon,"
    ],
    [
        "from django.db.models import IntegerField, Sum, Value",
        "from django.db.models import"
    ],
    [
        "from .models import City, Country, CountryWebMercator, ManyPointModel, State, Track",
        "from .models import City, Country, CountryWebMercator,"
    ],
    [
        "Please keep the tests in function's alphabetic order.",
        "Please keep the tests in"
    ],
    [
        "for city, expected_distance in zip(qs, distances):",
        "for city, expected_distance in zip(qs,"
    ],
    [
        "ValueError, \"AreaField only accepts Area measurement objects.\"",
        "ValueError, \"AreaField only accepts Area"
    ],
    [
        "\"\"\"Union with all combinations of geometries/geometry fields.\"\"\"",
        "\"\"\"Union with all combinations of geometries/geometry"
    ],
    [
        "\"\"\"The result SRID depends on the order of parameters.\"\"\"",
        "\"\"\"The result SRID depends on the order of"
    ],
    [
        "ValueError, \"SRID is required for all geometries.\"",
        "ValueError, \"SRID is required for all"
    ],
    [
        "self.skipTest(\"Spatial indexes in Meta.indexes are not supported.\")",
        "self.skipTest(\"Spatial indexes in Meta.indexes are not"
    ],
    [
        "from django.contrib.gis.db.models import Extent, MakeLine, Union, functions",
        "from django.contrib.gis.db.models import Extent, MakeLine,"
    ],
    [
        "from django.db import DatabaseError, NotSupportedError, connection",
        "from django.db import DatabaseError,"
    ],
    [
        "from django.db.models import F, OuterRef, Subquery",
        "from django.db.models import F, OuterRef,"
    ],
    [
        "\"Testing geographic model initialization from fixtures.\"",
        "\"Testing geographic model initialization"
    ],
    [
        "\"Testing Lazy-Geometry support (using the GeometryProxy).\"",
        "\"Testing Lazy-Geometry support"
    ],
    [
        "\"Testing automatic transform for lookups and inserts.\"",
        "\"Testing automatic transform for lookups"
    ],
    [
        "\"Testing creating a model instance and the geometry being None\"",
        "\"Testing creating a model instance and the"
    ],
    [
        "\"Database functions on inherited Geometry fields.\"",
        "\"Database functions on"
    ],
    [
        "\"select id, name, %s as point from geoapp_city\" % point_select",
        "\"select id, name, %s as point from geoapp_city\" %"
    ],
    [
        "\"\"\"GIS queries can be represented as strings.\"\"\"",
        "\"\"\"GIS queries can be represented"
    ],
    [
        "Test a dumpdata/loaddata cycle with geographic data.",
        "Test a dumpdata/loaddata cycle with geographic"
    ],
    [
        "\"Testing the 'contained', 'contains', and 'bbcontains' lookup types.\"",
        "\"Testing the 'contained', 'contains', and 'bbcontains'"
    ],
    [
        "cities = [\"Houston\", \"Dallas\", \"Oklahoma City\"]",
        "cities = [\"Houston\", \"Dallas\", \"Oklahoma"
    ],
    [
        "\"Testing the 'left' and 'right' lookup types.\"",
        "\"Testing the 'left' and 'right' lookup"
    ],
    [
        "[\"Chicago\", \"Lawrence\", \"Oklahoma City\", \"Pueblo\", \"Victoria\"],",
        "[\"Chicago\", \"Lawrence\", \"Oklahoma City\","
    ],
    [
        "\"Testing the 'same_as' and 'equals' lookup types.\"",
        "\"Testing the 'same_as' and"
    ],
    [
        "\"Testing NULL geometry support, and the `isnull` lookup type.\"",
        "\"Testing NULL geometry support, and the `isnull` lookup"
    ],
    [
        "state_names = [s.name for s in validqs]",
        "state_names = [s.name for"
    ],
    [
        "nmi = State.objects.create(name=\"Northern Mariana Islands\", poly=None)",
        "nmi = State.objects.create(name=\"Northern"
    ],
    [
        "\"\"\"NULL features are excluded in spatial lookup functions.\"\"\"",
        "\"\"\"NULL features are excluded in"
    ],
    [
        "mask = \"anyinteract\" if connection.ops.oracle else within_mask",
        "mask = \"anyinteract\" if"
    ],
    [
        "for val, exp in zip(extent, expected):",
        "for val, exp"
    ],
    [
        "for point, ref_city in zip(sorted(line), sorted(ref_points)):",
        "for point, ref_city in"
    ],
    [
        "Using a queryset inside a geo lookup is working (using a subquery)",
        "Using a queryset inside a geo lookup"
    ],
    [
        "for c, v in zip(City.objects.all(), City.objects.values()):",
        "for c, v in zip(City.objects.all(),"
    ],
    [
        "from django.test import TestCase, modify_settings, override_settings",
        "from django.test import TestCase,"
    ],
    [
        "actual = {n.nodeName for n in elem.childNodes}",
        "actual = {n.nodeName for n"
    ],
    [
        "item, [\"title\", \"link\", \"description\", \"guid\", \"georss:point\"]",
        "item, [\"title\", \"link\","
    ],
    [
        "\"Testing geographic feeds using GeoRSS over Atom.\"",
        "\"Testing geographic feeds using"
    ],
    [
        "entry, [\"title\", \"link\", \"id\", \"summary\", \"georss:point\"]",
        "entry, [\"title\", \"link\", \"id\","
    ],
    [
        "item, [\"title\", \"link\", \"description\", \"guid\", \"geo:lat\", \"geo:lon\"]",
        "item, [\"title\", \"link\", \"description\", \"guid\","
    ],
    [
        "from django.contrib.gis import views as gis_views",
        "from django.contrib.gis import views as"
    ],
    [
        "from django.contrib.gis.sitemaps import views as gis_sitemap_views",
        "from django.contrib.gis.sitemaps import views as"
    ],
    [
        "from django.contrib.sitemaps import views as sitemap_views",
        "from django.contrib.sitemaps import views as"
    ],
    [
        "from .models import City, PennsylvaniaCity, State, Truth",
        "from .models import City,"
    ],
    [
        "ref_ext = (pnt.x, pnt.y, pnt.x, pnt.y)",
        "ref_ext = (pnt.x, pnt.y, pnt.x,"
    ],
    [
        "for ref_val, val in zip(ref_ext, extent):",
        "for ref_val, val in"
    ],
    [
        "city_shp = shp_path / \"cities\" / \"cities.shp\"",
        "city_shp = shp_path /"
    ],
    [
        "co_shp = shp_path / \"counties\" / \"counties.shp\"",
        "co_shp = shp_path / \"counties\" /"
    ],
    [
        "inter_shp = shp_path / \"interstates\" / \"interstates.shp\"",
        "inter_shp = shp_path / \"interstates\""
    ],
    [
        "invalid_shp = shp_path / \"invalid\" / \"emptypoints.shp\"",
        "invalid_shp = shp_path / \"invalid\""
    ],
    [
        "has_nulls_geojson = shp_path / \"has_nulls\" / \"has_nulls.geojson\"",
        "has_nulls_geojson = shp_path / \"has_nulls\""
    ],
    [
        "NAMES = [\"Bexar\", \"Galveston\", \"Harris\", \"Honolulu\", \"Pueblo\"]",
        "NAMES = [\"Bexar\", \"Galveston\","
    ],
    [
        "STATES = [\"Texas\", \"Texas\", \"Texas\", \"Hawaii\", \"Colorado\"]",
        "STATES = [\"Texas\", \"Texas\", \"Texas\","
    ],
    [
        "\"Test LayerMapping import of a simple point shapefile.\"",
        "\"Test LayerMapping import of a simple"
    ],
    [
        "\"Testing the `strict` keyword, and import of a LineString shapefile.\"",
        "\"Testing the `strict` keyword, and import of"
    ],
    [
        "\"Helper function for ensuring the integrity of the mapped County models.\"",
        "\"Helper function for ensuring the integrity of the mapped County"
    ],
    [
        "for name, n, st in zip(NAMES, NUMS, STATES):",
        "for name, n, st"
    ],
    [
        "The `unique`, and `transform`, geometry collection conversion, and",
        "The `unique`, and `transform`,"
    ],
    [
        "lm = LayerMapping(County, co_shp, co_mapping, transform=False)",
        "lm = LayerMapping(County,"
    ],
    [
        "for arg in (\"name\", (\"name\", \"mpoly\")):",
        "for arg in (\"name\","
    ],
    [
        "lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique=arg)",
        "lm = LayerMapping(County, co_shp, co_mapping,"
    ],
    [
        "lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique=\"name\")",
        "lm = LayerMapping(County, co_shp, co_mapping,"
    ],
    [
        "lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique=\"name\")",
        "lm = LayerMapping(County, co_shp, co_mapping,"
    ],
    [
        "lm = LayerMapping(CountyFeat, co_shp, cofeat_mapping, transform=False)",
        "lm = LayerMapping(CountyFeat, co_shp, cofeat_mapping,"
    ],
    [
        "\"Tests the `fid_range` keyword and the `step` keyword of .save().\"",
        "\"Tests the `fid_range` keyword and the `step`"
    ],
    [
        "lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique=\"name\")",
        "lm = LayerMapping(County, co_shp, co_mapping, transform=False,"
    ],
    [
        "hi_idx, co_idx = tuple(map(NAMES.index, (\"Honolulu\", \"Pueblo\")))",
        "hi_idx, co_idx = tuple(map(NAMES.index,"
    ],
    [
        "\"String content fits also in a TextField\"",
        "\"String content fits also in a"
    ],
    [
        "city_shp = shp_path / \"ch-city\" / \"ch-city.shp\"",
        "city_shp = shp_path /"
    ],
    [
        "\"\"\"LayerMapping may be created with a unique and a null geometry.\"\"\"",
        "\"\"\"LayerMapping may be created with a unique and a"
    ],
    [
        "lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique=\"name\")",
        "lm = LayerMapping(County, co_shp,"
    ],
    [
        "\"\"\"LayerMapping import of GeoJSON with a null numeric value.\"\"\"",
        "\"\"\"LayerMapping import of GeoJSON with a null numeric"
    ],
    [
        "\"Test LayerMapping import of GeoJSON with a null string value.\"",
        "\"Test LayerMapping import of GeoJSON with a"
    ],
    [
        "\"\"\"LayerMapping import of GeoJSON with a nullable boolean value.\"\"\"",
        "\"\"\"LayerMapping import of GeoJSON with a"
    ],
    [
        "\"\"\"LayerMapping import of GeoJSON with a nullable date/time value.\"\"\"",
        "\"\"\"LayerMapping import of GeoJSON with a"
    ],
    [
        "\"\"\"LayerMapping import of GeoJSON with UUIDs.\"\"\"",
        "\"\"\"LayerMapping import of GeoJSON"
    ],
    [
        "LayerMapping import of GeoJSON with nulls to fields that don't permit",
        "LayerMapping import of GeoJSON with nulls to"
    ],
    [
        "from .models import City, site, site_gis, site_gis_custom",
        "from .models import City, site,"
    ],
    [
        "\"Error creating geometry from value 'INVALID()' (String input \"",
        "\"Error creating geometry from value 'INVALID()'"
    ],
    [
        "\"unrecognized as WKT EWKT, and HEXEWKB.)\",",
        "\"unrecognized as WKT"
    ],
    [
        "Tests for geography support in PostGIS",
        "Tests for geography"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TestCase, skipIfDBFeature,"
    ],
    [
        "from .models import City, CityUnique, County, Zipcode",
        "from .models import City, CityUnique,"
    ],
    [
        "\"Testing distance lookup support on non-point geography fields.\"",
        "\"Testing distance lookup support on non-point"
    ],
    [
        "Cast geography fields to geometry type when validating uniqueness to",
        "Cast geography fields to geometry"
    ],
    [
        "remove the reliance on unavailable ~= operator.",
        "remove the reliance on"
    ],
    [
        "msg = \"City unique with this Point already exists.\"",
        "msg = \"City unique with this Point already"
    ],
    [
        "Geography fields are cast to geometry if the relevant operators or",
        "Geography fields are cast to geometry if the relevant operators"
    ],
    [
        "\"Testing LayerMapping support on models with geography fields.\"",
        "\"Testing LayerMapping support on models with"
    ],
    [
        "names = [\"Bexar\", \"Galveston\", \"Harris\", \"Honolulu\", \"Pueblo\"]",
        "names = [\"Bexar\", \"Galveston\", \"Harris\", \"Honolulu\","
    ],
    [
        "st_names = [\"Texas\", \"Texas\", \"Texas\", \"Hawaii\", \"Colorado\"]",
        "st_names = [\"Texas\", \"Texas\", \"Texas\","
    ],
    [
        "for c, name, num_poly, state in zip(",
        "for c, name, num_poly, state in"
    ],
    [
        "Cast a geography to a geometry field for an aggregate function that",
        "Cast a geography to a geometry field"
    ],
    [
        "for val, exp in zip(res[\"extent\"], expected):",
        "for val, exp in zip(res[\"extent\"],"
    ],
    [
        "Testing Distance() support on non-point geography fields.",
        "Testing Distance() support on non-point geography"
    ],
    [
        "for z, ref in zip(qs, ref_dists):",
        "for z, ref"
    ],
    [
        "for z, ref in zip(qs, ref_dists):",
        "for z, ref in"
    ],
    [
        "Testing that Area calculations work on geography columns.",
        "Testing that Area calculations work on geography"
    ],
    [
        "NotSupportedError, \"Area on geodetic coordinate systems not supported.\"",
        "NotSupportedError, \"Area on geodetic coordinate"
    ],
    [
        "author = models.ForeignKey(Author, models.SET_NULL, related_name=\"books\", null=True)",
        "author = models.ForeignKey(Author,"
    ],
    [
        "from django.contrib.gis.db.models import Collect, Count, Extent, F, MakeLine, Q, Union",
        "from django.contrib.gis.db.models import Collect, Count, Extent, F,"
    ],
    [
        "from django.contrib.gis.geos import GEOSGeometry, MultiPoint, Point",
        "from django.contrib.gis.geos import"
    ],
    [
        "from .models import Article, Author, Book, City, DirectoryEntry, Event, Location, Parcel",
        "from .models import Article, Author, Book, City,"
    ],
    [
        "for ref, c in zip(cities, qs):",
        "for ref, c"
    ],
    [
        "nm, st, lon, lat = ref",
        "nm, st, lon, lat"
    ],
    [
        "\"Testing the `Extent` aggregate on related geographic models.\"",
        "\"Testing the `Extent` aggregate on related geographic"
    ],
    [
        "for ref_val, e_val in zip(ref, e):",
        "for ref_val, e_val"
    ],
    [
        "\"Testing the `Union` aggregate on related geographic models.\"",
        "\"Testing the `Union` aggregate"
    ],
    [
        "select_related on a query over a model with an FK to a model subclass.",
        "select_related on a query over a model with an"
    ],
    [
        "msg = \"This backend doesn't support the Transform function.\"",
        "msg = \"This backend doesn't support the Transform"
    ],
    [
        "msg = \"This backend doesn't support the Transform function.\"",
        "msg = \"This backend doesn't support the"
    ],
    [
        "for m, d, t in zip(gqs, gvqs, gvlqs):",
        "for m, d, t in zip(gqs, gvqs,"
    ],
    [
        "\"Testing defer() and only() on Geographic models.\"",
        "\"Testing defer() and only() on Geographic"
    ],
    [
        "for loc, def_loc in zip(qs, def_qs):",
        "for loc, def_loc in zip(qs,"
    ],
    [
        "for val_dict, c_id, l_id in zip(ids_qs, city_ids, loc_ids):",
        "for val_dict, c_id, l_id in zip(ids_qs,"
    ],
    [
        "names = [c.name for c in combined]",
        "names = [c.name for c in"
    ],
    [
        "\"Testing `Count` aggregate on non geo-fields.\"",
        "\"Testing `Count` aggregate"
    ],
    [
        "\"Testing `select_related` on a nullable ForeignKey.\"",
        "\"Testing `select_related` on"
    ],
    [
        "select_related on the related name manager of a unique FK.",
        "select_related on the related name manager"
    ],
    [
        "from django.db.models import F, Func, Q",
        "from django.db.models import F,"
    ],
    [
        "Test creating a model where the RasterField has a null value.",
        "Test creating a model where the RasterField has a"
    ],
    [
        "Test RasterField through a test model.",
        "Test RasterField through a"
    ],
    [
        "Test automatic transformation of rasters with srid different from the",
        "Test automatic transformation of rasters with srid different"
    ],
    [
        "for val, exp in zip(r.rast.geotransform, expected):",
        "for val, exp in"
    ],
    [
        "RasterField should accept a positional verbose name argument.",
        "RasterField should accept a positional"
    ],
    [
        "Evaluate all possible lookups for all input combinations (i.e.",
        "Evaluate all possible lookups for"
    ],
    [
        "raster-raster, raster-geom, geom-raster) and for projected and",
        "raster-raster, raster-geom, geom-raster) and for projected"
    ],
    [
        "unprojected coordinate systems. This test just checks that the lookup",
        "unprojected coordinate systems. This test just"
    ],
    [
        "can be called, but doesn't check if the result makes logical sense.",
        "can be called, but doesn't check if the result"
    ],
    [
        "\"Number of lookup names and values should be the same\",",
        "\"Number of lookup names and values should be"
    ],
    [
        "[(n, x) for n, x in enumerate(combos) if x in combos[:n]],",
        "[(n, x) for n, x in enumerate(combos) if"
    ],
    [
        "combos = [{k: v} for k, v in combos]",
        "combos = [{k: v} for k,"
    ],
    [
        "Check the logical functionality of the dwithin lookup for different",
        "Check the logical functionality of the dwithin"
    ],
    [
        "msg = \"Tuple too long for lookup bbcontains.\"",
        "msg = \"Tuple too long for lookup"
    ],
    [
        "msg = \"Band indices are not allowed for this operator, it works on bbox only.\"",
        "msg = \"Band indices are not allowed for this"
    ],
    [
        "msg = \"Couldn't create spatial object from lookup value '%s'.\" % obj",
        "msg = \"Couldn't create spatial object"
    ],
    [
        "msg = \"Couldn't create spatial object from lookup value '%s'.\" % obj",
        "msg = \"Couldn't create spatial object from"
    ],
    [
        "Errors are raised when using DB functions with raster content.",
        "Errors are raised when using"
    ],
    [
        "from django.contrib.gis.geos import GEOSGeometry, LineString, Point, Polygon",
        "from django.contrib.gis.geos import GEOSGeometry, LineString, Point,"
    ],
    [
        "city_dict = {name: coords for name, coords in city_data}",
        "city_dict = {name: coords for"
    ],
    [
        "for name, line, exp_z in interstate_data:",
        "for name, line,"
    ],
    [
        "available within GeoDjango.  For more information, see the PostGIS docs",
        "available within GeoDjango. For more information, see the PostGIS"
    ],
    [
        "for name, line, exp_z in interstate_data:",
        "for name, line,"
    ],
    [
        "self.assertEqual({p.ewkt for p in ref_union}, {p.ewkt for p in union})",
        "self.assertEqual({p.ewkt for p in ref_union}, {p.ewkt for"
    ],
    [
        "Test KML() function with Z values.",
        "Test KML() function with"
    ],
    [
        "Test GeoJSON() function with Z values.",
        "Test GeoJSON() function"
    ],
    [
        "Testing Scale() function on Z values.",
        "Testing Scale() function on Z"
    ],
    [
        "Testing Translate() function on Z values.",
        "Testing Translate() function"
    ],
    [
        "\"City model on projected coordinate system for South Texas.\"",
        "\"City model on projected coordinate system"
    ],
    [
        "\"Same City model as above, but U.S. survey feet are the units.\"",
        "\"Same City model as above, but U.S."
    ],
    [
        "\"Model for a few South Texas ZIP codes.\"",
        "\"Model for a few South Texas ZIP"
    ],
    [
        "\"Projected model for South Texas Interstates.\"",
        "\"Projected model for South"
    ],
    [
        "from django.contrib.gis.geos import GEOSGeometry, LineString, Point",
        "from django.contrib.gis.geos import GEOSGeometry, LineString,"
    ],
    [
        "from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TestCase, skipIfDBFeature,"
    ],
    [
        "cities = [c.name for c in qs]",
        "cities = [c.name for"
    ],
    [
        "tx_cities = [\"Downtown Houston\", \"Southside Place\"]",
        "tx_cities = [\"Downtown Houston\", \"Southside"
    ],
    [
        "au_cities = [\"Mittagong\", \"Shellharbour\", \"Thirroul\", \"Wollongong\"]",
        "au_cities = [\"Mittagong\", \"Shellharbour\", \"Thirroul\","
    ],
    [
        "type_error = isinstance(dist, D) and not connection.ops.oracle",
        "type_error = isinstance(dist, D) and"
    ],
    [
        "self.assertEqual(cities, [\"Bellaire\", \"Pearland\", \"West University Place\"])",
        "self.assertEqual(cities, [\"Bellaire\", \"Pearland\","
    ],
    [
        "Test distance lookups on geodetic coordinate systems.",
        "Test distance lookups on"
    ],
    [
        "\"Only numeric values of degree units are allowed on geodetic distance \"",
        "\"Only numeric values of degree units are allowed"
    ],
    [
        "\"\"\"dwithin lookup in a subquery using OuterRef as a parameter.\"\"\"",
        "\"\"\"dwithin lookup in a subquery using OuterRef"
    ],
    [
        "\"This backend does not support expressions for specifying \"",
        "\"This backend does not support"
    ],
    [
        "| Projected Geometry | Lon/lat Geometry",
        "| Projected Geometry"
    ],
    [
        "Test a simple distance query, with projected coordinates and without",
        "Test a simple distance query, with projected coordinates and"
    ],
    [
        "Test the `Distance` function on projected coordinate systems.",
        "Test the `Distance` function on projected"
    ],
    [
        "Test the `Distance` function on geodetic coordinate systems.",
        "Test the `Distance` function on geodetic"
    ],
    [
        "for city, distance in zip(qs, distances):",
        "for city, distance in zip(qs,"
    ],
    [
        "msg = \"The tolerance parameter has the wrong type\"",
        "msg = \"The tolerance parameter has the"
    ],
    [
        "msg = \"Distance measure is supplied, but units are unknown for result.\"",
        "msg = \"Distance measure is supplied, but units"
    ],
    [
        "Test the `Distance` function used with `Transform` on a geographic field.",
        "Test the `Distance` function used with `Transform` on"
    ],
    [
        "self.assertEqual(ref_zips, sorted(c.name for c in qs))",
        "self.assertEqual(ref_zips, sorted(c.name for"
    ],
    [
        "Test the measurement functions on fields with NULL values.",
        "Test the measurement functions on fields with"
    ],
    [
        "from django.contrib.gis.gdal import GDAL_VERSION, Driver, GDALException",
        "from django.contrib.gis.gdal import GDAL_VERSION, Driver,"
    ],
    [
        "from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature",
        "from django.test import"
    ],
    [
        "self.skipTest(\"Unable to setup an OGR connection to your database\")",
        "self.skipTest(\"Unable to setup an OGR connection to your"
    ],
    [
        "self.skipTest(\"Unable to setup an OGR connection to your database\")",
        "self.skipTest(\"Unable to setup an OGR connection to your"
    ],
    [
        "\"    f_char = models.CharField(max_length=%s)\" % max_length, model_def",
        "\" f_char = models.CharField(max_length=%s)\" %"
    ],
    [
        "Construct the DB string that GDAL will use to inspect the database.",
        "Construct the DB string that GDAL will"
    ],
    [
        "GDAL will create its own connection to the database, so we re-use the",
        "GDAL will create its own connection to the database, so"
    ],
    [
        "connection settings from the Django test.",
        "connection settings from the Django"
    ],
    [
        "params = [db_str % {\"db_name\": db[\"NAME\"]}]",
        "params = [db_str %"
    ],
    [
        "from django.db import connection, migrations, models",
        "from django.db import connection,"
    ],
    [
        "from django.test import TransactionTestCase, skipIfDBFeature, skipUnlessDBFeature",
        "from django.test import TransactionTestCase, skipIfDBFeature,"
    ],
    [
        "SELECT opcname, c.relname FROM pg_opclass AS oc",
        "SELECT opcname, c.relname FROM pg_opclass"
    ],
    [
        "JOIN pg_index as i on oc.oid = ANY(i.indclass)",
        "JOIN pg_index as i on oc.oid"
    ],
    [
        "JOIN pg_class as c on c.oid = i.indexrelid",
        "JOIN pg_class as c on c.oid"
    ],
    [
        "self.assertIn(column, [c.name for c in self.get_table_description(table)])",
        "self.assertIn(column, [c.name for c in"
    ],
    [
        "self.assertNotIn(column, [c.name for c in self.get_table_description(table)])",
        "self.assertNotIn(column, [c.name for c"
    ],
    [
        "self.assertIn([column], [c[\"columns\"] for c in constraints.values()])",
        "self.assertIn([column], [c[\"columns\"] for c"
    ],
    [
        "self.assertNotIn([column], [c[\"columns\"] for c in constraints.values()])",
        "self.assertNotIn([column], [c[\"columns\"] for c"
    ],
    [
        "Test the AddField operation with a geometry-enabled column.",
        "Test the AddField operation with a"
    ],
    [
        "@skipUnless(connection.vendor == \"mysql\", \"MySQL specific test\")",
        "@skipUnless(connection.vendor == \"mysql\", \"MySQL"
    ],
    [
        "Test the AddField operation with a raster-enabled column.",
        "Test the AddField operation with"
    ],
    [
        "Should be able to add a GeometryField with blank=True.",
        "Should be able to add a GeometryField with"
    ],
    [
        "Should be able to add a RasterField with blank=True.",
        "Should be able to add a RasterField with"
    ],
    [
        "Test the RemoveField operation with a geometry-enabled column.",
        "Test the RemoveField operation with"
    ],
    [
        "Test the RemoveField operation with a raster-enabled column.",
        "Test the RemoveField operation"
    ],
    [
        "@skipUnless(connection.vendor == \"mysql\", \"MySQL specific test\")",
        "@skipUnless(connection.vendor == \"mysql\", \"MySQL"
    ],
    [
        "msg = \"Raster fields require backends with raster support.\"",
        "msg = \"Raster fields require backends with"
    ],
    [
        "msg = \"Raster fields require backends with raster support.\"",
        "msg = \"Raster fields require"
    ],
    [
        "Tests running the migrate command in Geodjango.",
        "Tests running the migrate command in"
    ],
    [
        "Tests basic usage of the migrate command when a model uses Geodjango",
        "Tests basic usage of the migrate command when a model"
    ],
    [
        "It's also used to showcase an error in migrations where spatialite is",
        "It's also used to showcase an error in"
    ],
    [
        "enabled and geo tables are renamed resulting in unique constraint",
        "enabled and geo tables are renamed resulting in unique"
    ],
    [
        "Creates virtual relation to the translation with model cache enabled.",
        "Creates virtual relation to the translation with model cache"
    ],
    [
        "def __init__(self, to, on_delete, from_fields, to_fields, **kwargs):",
        "def __init__(self, to, on_delete, from_fields, to_fields,"
    ],
    [
        "from django.db.models import CASCADE, CharField, ForeignKey, Index, Q",
        "from django.db.models import CASCADE, CharField,"
    ],
    [
        "Test index handling by the db.backends.schema infrastructure.",
        "Test index handling by the"
    ],
    [
        "Index names on the built-in database backends::",
        "Index names on the"
    ],
    [
        "* Include all the column names.",
        "* Include all"
    ],
    [
        "\"This test is only supported on the built-in database backends.\"",
        "\"This test is only supported on the built-in database"
    ],
    [
        "index_sql = [str(statement) for statement in editor._model_indexes_sql(Article)]",
        "index_sql = [str(statement) for"
    ],
    [
        "SELECT opcname, c.relname FROM pg_opclass AS oc",
        "SELECT opcname, c.relname FROM pg_opclass"
    ],
    [
        "JOIN pg_index as i on oc.oid = ANY(i.indclass)",
        "JOIN pg_index as i"
    ],
    [
        "JOIN pg_class as c on c.oid = i.indexrelid",
        "JOIN pg_class as c on c.oid"
    ],
    [
        "\"\"\"Test indexes are not created for related objects\"\"\"",
        "\"\"\"Test indexes are not created"
    ],
    [
        "MySQL on InnoDB already creates indexes automatically for foreign keys.",
        "MySQL on InnoDB already creates indexes automatically for"
    ],
    [
        "self.skipTest(\"This test only applies to the InnoDB storage engine\")",
        "self.skipTest(\"This test only applies to the InnoDB storage"
    ],
    [
        "\"WHERE %s IS NOT NULL\" % editor.quote_name(\"pub_date\"),",
        "\"WHERE %s IS NOT NULL\" %"
    ],
    [
        "\"WHERE %s IS NOT NULL\" % editor.quote_name(\"pub_date\"),",
        "\"WHERE %s IS NOT"
    ],
    [
        "extra_sql = \"TABLESPACE %s \" % editor.quote_name(",
        "extra_sql = \"TABLESPACE %s"
    ],
    [
        "\"(%s) INCLUDE (%s) %sWHERE %s \"",
        "\"(%s) INCLUDE (%s) %sWHERE %s"
    ],
    [
        "from django.db.backends import utils as typecasts",
        "from django.db.backends import"
    ],
    [
        "\"In %s: %r doesn't match %r. Got %r instead.\"",
        "\"In %s: %r doesn't match %r. Got %r"
    ],
    [
        "from os.path import abspath, dirname, join",
        "from os.path import abspath,"
    ],
    [
        "from sphinx import version_info as sphinx_version",
        "from sphinx import"
    ],
    [
        "copyright = \"Django Software Foundation and contributors\"",
        "copyright = \"Django Software"
    ],
    [
        "\"Utility script for the Django web framework\",",
        "\"Utility script for the Django"
    ],
    [
        "{n: node.module for n in locator.node_line_numbers if \".\" not in n}",
        "{n: node.module for n in locator.node_line_numbers if \".\""
    ],
    [
        "self.import_locations[alias.name] = (\".\" * node.level) + (",
        "self.import_locations[alias.name] = (\".\" *"
    ],
    [
        "f\"Could not import '{imported_path}' in '{module}'.\"",
        "f\"Could not import '{imported_path}'"
    ],
    [
        "def github_linkcode_resolve(domain, info, *, version, next_version):",
        "def github_linkcode_resolve(domain, info, *, version,"
    ],
    [
        "from sphinx import version_info as sphinx_version",
        "from sphinx import"
    ],
    [
        "msg = \"\"\"Only one argument accepted for directive '{directive_name}::'.",
        "msg = \"\"\"Only one argument accepted for directive"
    ],
    [
        "Comments should be provided as content,",
        "Comments should be provided"
    ],
    [
        "isinstance(c, addnodes.desc_parameter) for c in node.children",
        "isinstance(c, addnodes.desc_parameter) for"
    ],
    [
        "title = \"%s%s\" % (version_text % node[\"version\"], \":\" if len(node) else \".\")",
        "title = \"%s%s\" % (version_text % node[\"version\"], \":\" if len(node)"
    ],
    [
        "node[\"ids\"] = [\"s-\" + i for i in old_ids]",
        "node[\"ids\"] = [\"s-\" + i for"
    ],
    [
        "title = \"django-admin %s\" % sig",
        "title = \"django-admin %s\" %"
    ],
    [
        "Subclass to add some extra things we need.",
        "Subclass to add some extra"
    ],
    [
        "for ((t, n), (k, a)) in xrefs.items()",
        "for ((t, n), (k, a)) in"
    ],
    [
        "if t == \"templatetag\" and k == \"ref/templates/builtins\"",
        "if t == \"templatetag\" and k =="
    ],
    [
        "for ((t, n), (k, a)) in xrefs.items()",
        "for ((t, n), (k,"
    ],
    [
        "if t == \"templatefilter\" and k == \"ref/templates/builtins\"",
        "if t == \"templatefilter\" and"
    ],
    [
        "Custom node to override the visit/depart event handlers at registration",
        "Custom node to override the visit/depart event"
    ],
    [
        "time. Wrap a literal_block object and defer to it.",
        "time. Wrap a literal_block object and defer"
    ],
    [
        "\"\"\"Defer to the corresponding parent's handler.\"\"\"",
        "\"\"\"Defer to the corresponding"
    ],
    [
        "\"\"\"Defer to the corresponding parent's handler.\"\"\"",
        "\"\"\"Defer to the corresponding parent's"
    ],
    [
        "\"\"\"Generate HTML for the console directive.\"\"\"",
        "\"\"\"Generate HTML for the console"
    ],
    [
        "if self.builder.name in (\"djangohtml\", \"json\") and node[\"win_console_text\"]:",
        "if self.builder.name in (\"djangohtml\","
    ],
    [
        "<input class=\"c-tab-unix\" id=\"c-tab-%(id)s-unix\" type=\"radio\" name=\"console-%(id)s\" \\",
        "<input class=\"c-tab-unix\" id=\"c-tab-%(id)s-unix\" type=\"radio\""
    ],
    [
        "'<section class=\"c-content-win\" id=\"c-content-%(id)s-win\">\\n' % {\"id\": uid}",
        "'<section class=\"c-content-win\" id=\"c-content-%(id)s-win\">\\n' %"
    ],
    [
        "A reStructuredText directive which renders a two-tab code block in which",
        "A reStructuredText directive which renders a two-tab code"
    ],
    [
        "the second tab shows a Windows command line equivalent of the usual",
        "the second tab shows a Windows command line equivalent"
    ],
    [
        "if \"://\" not in token and \"git\" not in cmdline:",
        "if \"://\" not in token and \"git\" not in"
    ],
    [
        "if env.app.builder.name not in (\"djangohtml\", \"json\"):",
        "if env.app.builder.name not in"
    ],
    [
        "def html_page_context_hook(app, pagename, templatename, context, doctree):",
        "def html_page_context_hook(app, pagename, templatename, context,"
    ],
    [
        "name, rawtext, text, lineno, inliner, options=None, content=None",
        "name, rawtext, text, lineno,"
    ],
    [
        "\"Default role used (`single backticks`): %s. Did you mean to use two \"",
        "\"Default role used (`single backticks`): %s. Did you mean"
    ],
    [
        "\"backticks for ``code``, or miss an underscore for a `link`_ ?\" % rawtext",
        "\"backticks for ``code``, or miss an underscore for a"
    ],
    [
        "assert api_token, \"Please define the TRANSIFEX_API_TOKEN env var.\"",
        "assert api_token, \"Please define the TRANSIFEX_API_TOKEN"
    ],
    [
        "f\"CHECKING {resource_name} for {lang_id=} updated on {last_update}\"",
        "f\"CHECKING {resource_name} for {lang_id=} updated on"
    ],
    [
        "if last_update > date_since and (",
        "if last_update >"
    ],
    [
        "date_skip is None or last_update.date() != date_skip.date()",
        "date_skip is None or last_update.date() !="
    ],
    [
        "f\"\\n * resource {res} languages {' '.join(sorted(langs))}\"",
        "f\"\\n * resource {res} languages"
    ],
    [
        "print(f\"== SUMMARY for unchanged resources ==\\n{unchanged}\")",
        "print(f\"== SUMMARY for unchanged"
    ],
    [
        "Return a tuple (contrib name, absolute path) for all locale directories,",
        "Return a tuple (contrib name, absolute path)"
    ],
    [
        "optionally including the django core catalog.",
        "optionally including the django"
    ],
    [
        "If resources list is not None, filter directories matching resources content.",
        "If resources list is not None, filter directories matching"
    ],
    [
        "\"You have specified some unknown resources. \"",
        "\"You have specified some"
    ],
    [
        "\"Available resource names are: %s\" % (\", \".join(res_names),)",
        "\"Available resource names are: %s\""
    ],
    [
        "Output the approximate number of changed/added strings in the en catalog.",
        "Output the approximate number of changed/added"
    ],
    [
        "\"ext\": \"js\" if cat_name.endswith(\"-js\") else \"\",",
        "\"ext\": \"js\" if"
    ],
    [
        "print(\"%d changed/added messages in '%s' catalog.\" % (num_changes, cat_name))",
        "print(\"%d changed/added messages in '%s' catalog.\" %"
    ],
    [
        "Update the en/LC_MESSAGES/django.po (main and contrib) files with",
        "Update the en/LC_MESSAGES/django.po (main and contrib)"
    ],
    [
        "print(\"`update_catalogs` will always process all resources.\")",
        "print(\"`update_catalogs` will always"
    ],
    [
        "print(\"Updating en catalogs for Django and contrib apps...\")",
        "print(\"Updating en catalogs for Django"
    ],
    [
        "print(\"Updating en JS catalogs for Django and contrib apps...\")",
        "print(\"Updating en JS catalogs for Django and contrib"
    ],
    [
        "Output language statistics of committed translation files for each",
        "Output language statistics of committed translation files for"
    ],
    [
        "If resources is provided, it should be a list of translation resource to",
        "If resources is provided, it should be a list of"
    ],
    [
        "limit the output (e.g. ['core', 'gis']).",
        "limit the output (e.g. ['core',"
    ],
    [
        "print(\"\\nShowing translations stats for '%s':\" % name)",
        "print(\"\\nShowing translations stats for"
    ],
    [
        "langs = sorted(d for d in os.listdir(dir_) if not d.startswith(\"_\"))",
        "langs = sorted(d for d in os.listdir(dir_)"
    ],
    [
        "if languages and lang not in languages:",
        "if languages and lang"
    ],
    [
        "path=dir_, lang=lang, ext=\"js\" if name.endswith(\"-js\") else \"\"",
        "path=dir_, lang=lang, ext=\"js\" if name.endswith(\"-js\")"
    ],
    [
        "\"Errors happened when checking %s translation for %s:\\n%s\"",
        "\"Errors happened when checking %s"
    ],
    [
        "Fetch translations from Transifex, wrap long lines, generate mo files.",
        "Fetch translations from Transifex, wrap long lines,"
    ],
    [
        "d for d in os.listdir(dir_) if not d.startswith(\"_\") and d != \"en\"",
        "d for d in os.listdir(dir_) if not d.startswith(\"_\")"
    ],
    [
        "target_langs = [LANG_OVERRIDES.get(d, d) for d in target_langs]",
        "target_langs = [LANG_OVERRIDES.get(d, d) for d in"
    ],
    [
        "\"ext\": \"js\" if name.endswith(\"-js\") else \"\",",
        "\"ext\": \"js\" if name.endswith(\"-js\")"
    ],
    [
        "\"No %(lang)s translation for resource %(name)s\"",
        "\"No %(lang)s translation for"
    ],
    [
        "print(\"\\nWARNING: Errors have occurred in following cases:\")",
        "print(\"\\nWARNING: Errors have occurred"
    ],
    [
        "print(\"\\tResource %s for language %s\" % (resource, lang))",
        "print(\"\\tResource %s for language %s\" % (resource,"
    ],
    [
        "Fetch translations from Transifex that were modified since the given date.",
        "Fetch translations from Transifex that were modified"
    ],
    [
        "print(f\"== SUMMARY for changed resources {dry_run=} ==\\n\")",
        "print(f\"== SUMMARY for changed resources {dry_run=}"
    ],
    [
        "print(f\"\\n * resource {res} languages {' '.join(sorted(langs))}\")",
        "print(f\"\\n * resource {res} languages"
    ],
    [
        "print(f\"\\n No resource changed since {date_since}\")",
        "print(f\"\\n No resource"
    ],
    [
        "help=\"limit operation to the specified resources\",",
        "help=\"limit operation to"
    ],
    [
        "help=\"limit operation to the specified languages\",",
        "help=\"limit operation to"
    ],
    [
        "dest=\"cmd\", help=\"choose the operation to perform\"",
        "dest=\"cmd\", help=\"choose the operation to"
    ],
    [
        "help=\"update English django.po files with new/updated translatable strings\",",
        "help=\"update English django.po files with"
    ],
    [
        "help=\"print the approximate number of changed/added strings in the en catalog\",",
        "help=\"print the approximate number of changed/added"
    ],
    [
        "help=\"fetch translations from Transifex, wrap long lines, generate mo files\",",
        "help=\"fetch translations from Transifex, wrap long"
    ],
    [
        "\"fetch translations from Transifex modified since a given date \"",
        "\"fetch translations from Transifex modified since a given date"
    ],
    [
        "\"(for all languages and all resources)\"",
        "\"(for all languages and"
    ],
    [
        "help=\"fetch new translations since this date (ISO format YYYY-MM-DD).\",",
        "help=\"fetch new translations since this"
    ],
    [
        "help=\"skip changes from this date (ISO format YYYY-MM-DD).\",",
        "help=\"skip changes from this date"
    ],
    [
        "This module collects helper functions and classes that \"span\" multiple levels",
        "This module collects helper functions and"
    ],
    [
        "of MVC. In other words, these functions/classes introduce controlled coupling",
        "of MVC. In other words, these"
    ],
    [
        "request, template_name, context=None, content_type=None, status=None, using=None",
        "request, template_name, context=None,"
    ],
    [
        "Return an HttpResponse whose content is filled with the result of calling",
        "Return an HttpResponse whose content is filled with the"
    ],
    [
        "content = loader.render_to_string(template_name, context, request, using=using)",
        "content = loader.render_to_string(template_name,"
    ],
    [
        "def redirect(to, *args, permanent=False, preserve_request=False, **kwargs):",
        "def redirect(to, *args, permanent=False, preserve_request=False,"
    ],
    [
        "Return an HttpResponseRedirect to the appropriate URL for the arguments",
        "Return an HttpResponseRedirect to the appropriate URL"
    ],
    [
        "* A model: the model's `get_absolute_url()` function will be called.",
        "* A model: the model's `get_absolute_url()` function"
    ],
    [
        "* A view name, possibly with arguments: `urls.reverse()` will be used",
        "* A view name, possibly with arguments: `urls.reverse()`"
    ],
    [
        "* A URL, which will be used as-is for the redirect location.",
        "* A URL, which will be used as-is"
    ],
    [
        "Issues a temporary redirect by default. Set permanent=True to issue a",
        "Issues a temporary redirect by default."
    ],
    [
        "permanent redirect. Set preserve_request=True to instruct the user agent",
        "permanent redirect. Set preserve_request=True to instruct the user"
    ],
    [
        "to preserve the original HTTP method and body when following the redirect.",
        "to preserve the original HTTP method and body when"
    ],
    [
        "Return a QuerySet or a Manager.",
        "Return a QuerySet or"
    ],
    [
        "Duck typing in action: any class with a `get()` method (for",
        "Duck typing in action: any class with a `get()` method"
    ],
    [
        "klass may be a Model, Manager, or QuerySet object. All other passed",
        "klass may be a Model, Manager, or"
    ],
    [
        "arguments and keyword arguments are used in the get() query.",
        "arguments and keyword arguments are used in the get()"
    ],
    [
        "Like with QuerySet.get(), MultipleObjectsReturned is raised if more than",
        "Like with QuerySet.get(), MultipleObjectsReturned is raised"
    ],
    [
        "klass.__name__ if isinstance(klass, type) else klass.__class__.__name__",
        "klass.__name__ if isinstance(klass,"
    ],
    [
        "\"or QuerySet, not '%s'.\" % klass__name",
        "\"or QuerySet, not '%s'.\" %"
    ],
    [
        "\"No %s matches the given query.\" % queryset.model._meta.object_name",
        "\"No %s matches the"
    ],
    [
        "klass.__name__ if isinstance(klass, type) else klass.__class__.__name__",
        "klass.__name__ if isinstance(klass,"
    ],
    [
        "klass may be a Model, Manager, or QuerySet object. All other passed",
        "klass may be a Model, Manager, or QuerySet object. All other"
    ],
    [
        "arguments and keyword arguments are used in the filter() query.",
        "arguments and keyword arguments are"
    ],
    [
        "klass.__name__ if isinstance(klass, type) else klass.__class__.__name__",
        "klass.__name__ if isinstance(klass, type)"
    ],
    [
        "\"No %s matches the given query.\" % queryset.model._meta.object_name",
        "\"No %s matches the given query.\""
    ],
    [
        "klass.__name__ if isinstance(klass, type) else klass.__class__.__name__",
        "klass.__name__ if isinstance(klass,"
    ],
    [
        "obj_list = [obj async for obj in queryset.filter(*args, **kwargs)]",
        "obj_list = [obj async for obj in queryset.filter(*args,"
    ],
    [
        "Return a URL appropriate for the arguments passed.",
        "Return a URL appropriate for"
    ],
    [
        "* A model: the model's `get_absolute_url()` function will be called.",
        "* A model: the model's `get_absolute_url()`"
    ],
    [
        "* A view name, possibly with arguments: `urls.reverse()` will be used",
        "* A view name, possibly with arguments: `urls.reverse()` will be"
    ],
    [
        "* A URL, which will be returned as-is.",
        "* A URL, which"
    ],
    [
        "if isinstance(to, str) and to.startswith((\"./\", \"../\")):",
        "if isinstance(to, str) and"
    ],
    [
        "if \"/\" not in to and \".\" not in to:",
        "if \"/\" not in to and \".\" not"
    ],
    [
        "Configure the settings (this happens as a side effect of accessing the",
        "Configure the settings (this happens as a"
    ],
    [
        "first setting), configure logging and populate the app registry.",
        "first setting), configure logging and populate"
    ],
    [
        "Set the thread-local urlresolvers script prefix if `set_prefix` is True.",
        "Set the thread-local urlresolvers script prefix if `set_prefix`"
    ],
    [
        "\"/\" if settings.FORCE_SCRIPT_NAME is None else settings.FORCE_SCRIPT_NAME",
        "\"/\" if settings.FORCE_SCRIPT_NAME is None"
    ],
    [
        "Invokes django-admin when the django module is run as a script.",
        "Invokes django-admin when the django module"
    ],
    [
        "from django.template import Library, Node, TemplateSyntaxError",
        "from django.template import Library, Node,"
    ],
    [
        "Force a value to be rendered as a localized value.",
        "Force a value to be rendered as"
    ],
    [
        "Force a value to be rendered as a non-localized value.",
        "Force a value to be rendered as"
    ],
    [
        "Force or prevents localization of values.",
        "Force or prevents localization of"
    ],
    [
        "from datetime import timezone as datetime_timezone",
        "from datetime import timezone as"
    ],
    [
        "from django.template import Library, Node, TemplateSyntaxError",
        "from django.template import Library,"
    ],
    [
        "Convert a datetime to local time in the active time zone.",
        "Convert a datetime to local time in the active time"
    ],
    [
        "This only makes sense within a {% localtime off %} block.",
        "This only makes sense within a"
    ],
    [
        "Convert a datetime to local time in a given time zone.",
        "Convert a datetime to local time in"
    ],
    [
        "The argument must be an instance of a tzinfo subclass or a time zone name.",
        "The argument must be an instance of a tzinfo subclass or a"
    ],
    [
        "Naive datetimes are assumed to be in local time in the default time zone.",
        "Naive datetimes are assumed to be in local"
    ],
    [
        "Template node class used by ``localtime_tag``.",
        "Template node class used"
    ],
    [
        "Template node class used by ``timezone_tag``.",
        "Template node class used by"
    ],
    [
        "Template node class used by ``get_current_timezone_tag``.",
        "Template node class"
    ],
    [
        "Force or prevent conversion of datetime objects to local time,",
        "Force or prevent conversion of datetime objects to local"
    ],
    [
        "regardless of the value of ``settings.USE_TZ``.",
        "regardless of the value"
    ],
    [
        "{% localtime off %}{{ value_in_utc }}{% endlocaltime %}",
        "{% localtime off %}{{ value_in_utc }}{% endlocaltime"
    ],
    [
        "Enable a given time zone just for this block.",
        "Enable a given time zone just for this"
    ],
    [
        "The ``timezone`` argument must be an instance of a ``tzinfo`` subclass, a",
        "The ``timezone`` argument must be an"
    ],
    [
        "time zone name, or ``None``. If it is ``None``, the default time zone is",
        "time zone name, or ``None``. If it is ``None``, the default"
    ],
    [
        "It is {{ now }} in Paris.",
        "It is {{ now }}"
    ],
    [
        "Store the name of the current time zone in the context.",
        "Store the name of the current time zone in the"
    ],
    [
        "This will fetch the currently active time zone and put its name",
        "This will fetch the currently active time zone"
    ],
    [
        "\"'get_current_timezone' requires 'as variable' (got %r)\" % args",
        "\"'get_current_timezone' requires 'as variable'"
    ],
    [
        "from django.template import Library, Node, TemplateSyntaxError, VariableDoesNotExist",
        "from django.template import Library,"
    ],
    [
        "def __init__(self, nodelist, expire_time_var, fragment_name, vary_on, cache_name):",
        "def __init__(self, nodelist, expire_time_var, fragment_name, vary_on,"
    ],
    [
        "'\"cache\" tag got an unknown variable: %r' % self.expire_time_var.var",
        "'\"cache\" tag got an unknown"
    ],
    [
        "'\"cache\" tag got a non-integer timeout value: %r' % expire_time",
        "'\"cache\" tag got a non-integer timeout value: %r' %"
    ],
    [
        "'\"cache\" tag got an unknown variable: %r' % self.cache_name.var",
        "'\"cache\" tag got an unknown variable: %r'"
    ],
    [
        "\"Invalid cache name specified for cache tag: %r\" % cache_name",
        "\"Invalid cache name specified for cache tag:"
    ],
    [
        "vary_on = [var.resolve(context) for var in self.vary_on]",
        "vary_on = [var.resolve(context) for var in"
    ],
    [
        "This will cache the contents of a template fragment for a given amount",
        "This will cache the contents of a"
    ],
    [
        "This tag also supports varying by a list of arguments::",
        "This tag also supports varying by a list of"
    ],
    [
        "Optionally the cache to use may be specified thus::",
        "Optionally the cache to use may"
    ],
    [
        "Each unique set of arguments will result in a unique cache entry.",
        "Each unique set of arguments will result in"
    ],
    [
        "return \"<PrefixNode for %r>\" % self.name",
        "return \"<PrefixNode for"
    ],
    [
        "\"Prefix nodes must be given a name to return.\"",
        "\"Prefix nodes must be given"
    ],
    [
        "Class method to parse prefix node and return a Node.",
        "Class method to parse prefix node and return"
    ],
    [
        "Populate a template variable with the static prefix,",
        "Populate a template variable with the static"
    ],
    [
        "Populate a template variable with the media prefix,",
        "Populate a template variable with the"
    ],
    [
        "\"Static template nodes must be given a path to return.\"",
        "\"Static template nodes must be given a path"
    ],
    [
        "Class method to parse prefix node and return a Node.",
        "Class method to parse prefix node and"
    ],
    [
        "Join the given path with the STATIC_URL setting.",
        "Join the given path with the"
    ],
    [
        "{% static path [as varname] %}",
        "{% static path [as varname]"
    ],
    [
        "{% static \"myapp/css/base.css\" as admin_base_css %}",
        "{% static \"myapp/css/base.css\" as admin_base_css"
    ],
    [
        "{% static variable_with_path as varname %}",
        "{% static variable_with_path as"
    ],
    [
        "Given a relative path to a static asset, return the absolute path to the",
        "Given a relative path to a static"
    ],
    [
        "from django.template import Library, Node, TemplateSyntaxError, Variable",
        "from django.template import Library, Node,"
    ],
    [
        "from django.utils.safestring import SafeData, SafeString, mark_safe",
        "from django.utils.safestring import"
    ],
    [
        "(k, translation.gettext(v)) for k, v in settings.LANGUAGES",
        "(k, translation.gettext(v)) for k,"
    ],
    [
        "context[self.variable] = [self.get_language_info(lang) for lang in langs]",
        "context[self.variable] = [self.get_language_info(lang) for lang"
    ],
    [
        "def __init__(self, filter_expression, noop, asvar=None, message_context=None):",
        "def __init__(self, filter_expression, noop, asvar=None,"
    ],
    [
        "value = mark_safe(value) if is_safe else value",
        "value = mark_safe(value) if is_safe"
    ],
    [
        "{var: val.resolve(context) for var, val in self.extra_context.items()}",
        "{var: val.resolve(context) for var, val"
    ],
    [
        "if self.plural and self.countervar and self.counter:",
        "if self.plural and self.countervar"
    ],
    [
        "if not isinstance(count, (Decimal, float, int)):",
        "if not isinstance(count,"
    ],
    [
        "\"%r argument to %r tag must be a number.\"",
        "\"%r argument to %r tag"
    ],
    [
        "result = translation.npgettext(message_context, singular, plural, count)",
        "result = translation.npgettext(message_context, singular,"
    ],
    [
        "val = default_value % key if \"%s\" in default_value else default_value",
        "val = default_value % key if"
    ],
    [
        "data = {v: render_value(v) for v in vars}",
        "data = {v: render_value(v) for v"
    ],
    [
        "\"%r is unable to format string returned by gettext: %r \"",
        "\"%r is unable to format string returned by gettext:"
    ],
    [
        "\"using %r\" % (self.tag_name, result, data)",
        "\"using %r\" %"
    ],
    [
        "Store a list of available languages in the context.",
        "Store a list of available"
    ],
    [
        "{% for language in languages %}",
        "{% for language in"
    ],
    [
        "This puts settings.LANGUAGES into the named variable.",
        "This puts settings.LANGUAGES into"
    ],
    [
        "\"'get_available_languages' requires 'as variable' (got %r)\" % args",
        "\"'get_available_languages' requires 'as variable'"
    ],
    [
        "Store the language information dictionary for the given language code in a",
        "Store the language information dictionary for the given language code in"
    ],
    [
        "{% get_language_info for LANGUAGE_CODE as l %}",
        "{% get_language_info for LANGUAGE_CODE as l"
    ],
    [
        "Store a list of language information dictionaries for the given language",
        "Store a list of language information"
    ],
    [
        "codes in a context variable. The language codes can be specified either as",
        "codes in a context variable. The language codes can"
    ],
    [
        "a list of strings or a settings.LANGUAGES style list (or any sequence of",
        "a list of strings or a settings.LANGUAGES style list (or any sequence"
    ],
    [
        "sequences whose first items are language codes).",
        "sequences whose first items are language"
    ],
    [
        "{% get_language_info_list for LANGUAGES as langs %}",
        "{% get_language_info_list for LANGUAGES as"
    ],
    [
        "{% for l in langs %}",
        "{% for l in langs"
    ],
    [
        "Store the current language in the context.",
        "Store the current language in the"
    ],
    [
        "This fetches the currently active language and puts its value into the",
        "This fetches the currently active language and puts"
    ],
    [
        "\"'get_current_language' requires 'as variable' (got %r)\" % args",
        "\"'get_current_language' requires 'as variable' (got"
    ],
    [
        "Store the current language layout in the context.",
        "Store the current language layout in"
    ],
    [
        "This fetches the currently active language's layout and puts its value into",
        "This fetches the currently active language's layout and puts"
    ],
    [
        "the ``bidi`` context variable. True indicates right-to-left layout,",
        "the ``bidi`` context variable. True"
    ],
    [
        "\"'get_current_language_bidi' requires 'as variable' (got %r)\" % args",
        "\"'get_current_language_bidi' requires 'as variable'"
    ],
    [
        "Mark a string for translation and translate the string for the current",
        "Mark a string for translation and translate the string for"
    ],
    [
        "{% translate \"this is a test\" %}",
        "{% translate \"this is a test\""
    ],
    [
        "This marks the string for translation so it will be pulled out by",
        "This marks the string for translation so it will be pulled out"
    ],
    [
        "makemessages into the .po files and runs the string through the translation",
        "makemessages into the .po files and runs the string through"
    ],
    [
        "{% translate \"this is a test\" noop %}",
        "{% translate \"this is a test\""
    ],
    [
        "This marks the string for translation, but returns the string unchanged.",
        "This marks the string for translation, but returns the string"
    ],
    [
        "Use it when you need to store values into forms that should be translated",
        "Use it when you need to store values into"
    ],
    [
        "You can use variables instead of constant strings",
        "You can use variables instead of"
    ],
    [
        "to translate stuff you marked somewhere else::",
        "to translate stuff you marked"
    ],
    [
        "This tries to translate the contents of the variable ``variable``. Make",
        "This tries to translate the contents of"
    ],
    [
        "sure that the string in there is something that is in the .po file.",
        "sure that the string in there is something"
    ],
    [
        "It is possible to store the translated string into a variable::",
        "It is possible to store the translated string into"
    ],
    [
        "{% translate \"this is a test\" as var %}",
        "{% translate \"this is a test\" as"
    ],
    [
        "{% translate \"this is a test\" context \"greeting\" %}",
        "{% translate \"this is a test\" context"
    ],
    [
        "This is equivalent to calling pgettext instead of (u)gettext.",
        "This is equivalent to calling pgettext instead"
    ],
    [
        "\"The '%s' option was specified more than once.\" % option,",
        "\"The '%s' option was specified more"
    ],
    [
        "\"No argument provided to the '%s' tag for the context option.\"",
        "\"No argument provided to the '%s' tag for the"
    ],
    [
        "\"Invalid argument '%s' provided to the '%s' tag for the context \"",
        "\"Invalid argument '%s' provided to the '%s'"
    ],
    [
        "\"Unknown argument for '%s' tag: '%s'. The only options \"",
        "\"Unknown argument for '%s' tag: '%s'. The only"
    ],
    [
        "\"available are 'noop', 'context' \\\"xxx\\\", and 'as VAR'.\"",
        "\"available are 'noop', 'context' \\\"xxx\\\", and 'as"
    ],
    [
        "Translate a block of text with parameters.",
        "Translate a block of text with"
    ],
    [
        "{% blocktranslate with bar=foo|filter boo=baz|filter %}",
        "{% blocktranslate with"
    ],
    [
        "This is {{ bar }} and {{ boo }}.",
        "This is {{ bar }} and"
    ],
    [
        "There is {{ count }} object.",
        "There is {{ count"
    ],
    [
        "There are {{ count }} objects.",
        "There are {{ count }}"
    ],
    [
        "This is much like ngettext, only in template syntax.",
        "This is much like ngettext, only"
    ],
    [
        "The \"var as value\" legacy format is still supported::",
        "The \"var as value\" legacy format"
    ],
    [
        "{% blocktranslate with foo|filter as bar and baz|filter as boo %}",
        "{% blocktranslate with foo|filter as bar"
    ],
    [
        "{% blocktranslate count var|length as count %}",
        "{% blocktranslate count var|length"
    ],
    [
        "The translated string can be stored in a variable using `asvar`::",
        "The translated string can be stored"
    ],
    [
        "{% blocktranslate with bar=foo|filter boo=baz|filter asvar var %}",
        "{% blocktranslate with bar=foo|filter boo=baz|filter"
    ],
    [
        "This is {{ bar }} and {{ boo }}.",
        "This is {{ bar }} and {{ boo"
    ],
    [
        "{% blocktranslate with bar=foo|filter context \"greeting\" %}",
        "{% blocktranslate with bar=foo|filter"
    ],
    [
        "This is equivalent to calling pgettext/npgettext instead of",
        "This is equivalent to calling pgettext/npgettext instead"
    ],
    [
        "\"The %r option was specified more than once.\" % option",
        "\"The %r option was specified more than once.\""
    ],
    [
        "'\"count\" in %r tag expected exactly '",
        "'\"count\" in %r tag expected exactly"
    ],
    [
        "\"No argument provided to the '%s' tag for the asvar option.\"",
        "\"No argument provided to the '%s'"
    ],
    [
        "\"%r doesn't allow other block tags (seen %r) inside it\"",
        "\"%r doesn't allow other block"
    ],
    [
        "Enable the given language just for this block.",
        "Enable the given language just for this"
    ],
    [
        "This is {{ bar }} and {{ boo }}.",
        "This is {{ bar }} and"
    ],
    [
        "This module provides a middleware that implements protection against a",
        "This module provides a middleware"
    ],
    [
        "malicious site loading resources from your site in a hidden frame.",
        "malicious site loading resources from your site in a"
    ],
    [
        "Set the X-Frame-Options HTTP header in HTTP responses.",
        "Set the X-Frame-Options HTTP header in"
    ],
    [
        "Do not set the header if it's already set or if the response contains",
        "Do not set the header if it's already"
    ],
    [
        "a xframe_options_exempt value set to True.",
        "a xframe_options_exempt value"
    ],
    [
        "By default, set the X-Frame-Options header to 'DENY', meaning the response",
        "By default, set the X-Frame-Options header to 'DENY',"
    ],
    [
        "cannot be displayed in a frame, regardless of the site attempting to do so.",
        "cannot be displayed in a frame, regardless of the site attempting"
    ],
    [
        "To enable the response to be loaded on a frame within the same site, set",
        "To enable the response to be loaded on a"
    ],
    [
        "X_FRAME_OPTIONS in your project's Django settings to 'SAMEORIGIN'.",
        "X_FRAME_OPTIONS in your project's Django"
    ],
    [
        "Get the value to set for the X_FRAME_OPTIONS header. Use the value from",
        "Get the value to set for the X_FRAME_OPTIONS"
    ],
    [
        "the X_FRAME_OPTIONS setting, or 'DENY' if not set.",
        "the X_FRAME_OPTIONS setting, or 'DENY' if not"
    ],
    [
        "This method can be overridden if needed, allowing it to vary based on",
        "This method can be overridden if needed, allowing"
    ],
    [
        "Compress content if the browser allows gzip compression.",
        "Compress content if the browser allows gzip"
    ],
    [
        "Set the Vary header accordingly, so that caches will base their storage",
        "Set the Vary header accordingly, so that caches will"
    ],
    [
        "This module provides a middleware that implements protection",
        "This module provides a middleware"
    ],
    [
        "against request forgeries from other sites.",
        "against request forgeries from"
    ],
    [
        "REASON_BAD_ORIGIN = \"Origin checking failed - %s does not match any trusted origins.\"",
        "REASON_BAD_ORIGIN = \"Origin checking failed - %s"
    ],
    [
        "REASON_NO_REFERER = \"Referer checking failed - no Referer.\"",
        "REASON_NO_REFERER = \"Referer checking failed -"
    ],
    [
        "REASON_BAD_REFERER = \"Referer checking failed - %s does not match any trusted origins.\"",
        "REASON_BAD_REFERER = \"Referer checking failed - %s does not match any"
    ],
    [
        "REASON_NO_CSRF_COOKIE = \"CSRF cookie not set.\"",
        "REASON_NO_CSRF_COOKIE = \"CSRF cookie"
    ],
    [
        "REASON_MALFORMED_REFERER = \"Referer checking failed - Referer is malformed.\"",
        "REASON_MALFORMED_REFERER = \"Referer checking failed -"
    ],
    [
        "\"Referer checking failed - Referer is insecure while host is secure.\"",
        "\"Referer checking failed - Referer is insecure while host is"
    ],
    [
        "\"\"\"Return the view to be used for CSRF rejections.\"\"\"",
        "\"\"\"Return the view to be used for CSRF"
    ],
    [
        "Given a secret (assumed to be a string of CSRF_ALLOWED_CHARS), generate a",
        "Given a secret (assumed to be a string"
    ],
    [
        "token by adding a mask and applying it to the secret.",
        "token by adding a mask and applying it to the"
    ],
    [
        "pairs = zip((chars.index(x) for x in secret), (chars.index(x) for x in mask))",
        "pairs = zip((chars.index(x) for x in secret), (chars.index(x) for"
    ],
    [
        "cipher = \"\".join(chars[(x + y) % len(chars)] for x, y in pairs)",
        "cipher = \"\".join(chars[(x + y) % len(chars)] for x,"
    ],
    [
        "Given a token (assumed to be a string of CSRF_ALLOWED_CHARS, of length",
        "Given a token (assumed to be a string of CSRF_ALLOWED_CHARS, of"
    ],
    [
        "CSRF_TOKEN_LENGTH, and that its first half is a mask), use it to decrypt",
        "CSRF_TOKEN_LENGTH, and that its first half is a mask), use it to"
    ],
    [
        "the second half to produce the original secret.",
        "the second half to produce the"
    ],
    [
        "pairs = zip((chars.index(x) for x in token), (chars.index(x) for x in mask))",
        "pairs = zip((chars.index(x) for x in"
    ],
    [
        "\"\"\"Generate a new random CSRF_COOKIE value, and add it to request.META.\"\"\"",
        "\"\"\"Generate a new random CSRF_COOKIE value, and add it to"
    ],
    [
        "Return the CSRF token required for a POST form. The token is an",
        "Return the CSRF token required for a POST form. The token"
    ],
    [
        "alphanumeric value. A new token is created if one is not already set.",
        "alphanumeric value. A new token is created if one is not already"
    ],
    [
        "A side effect of calling this function is to make the csrf_protect",
        "A side effect of calling this function is"
    ],
    [
        "decorator and the CsrfViewMiddleware add a CSRF cookie and a 'Vary: Cookie'",
        "decorator and the CsrfViewMiddleware add a CSRF"
    ],
    [
        "header to the outgoing response.  For this reason, you may need to use this",
        "header to the outgoing response. For this reason, you may"
    ],
    [
        "function lazily, as is done by the csrf context processor.",
        "function lazily, as is done"
    ],
    [
        "Change the CSRF token in use for a request - should be done on login",
        "Change the CSRF token in use for a"
    ],
    [
        "Raise an InvalidTokenFormat error if the token has an invalid length or",
        "Raise an InvalidTokenFormat error if the token has"
    ],
    [
        "characters that aren't allowed. The token argument can be a CSRF cookie",
        "characters that aren't allowed. The token argument can be a CSRF"
    ],
    [
        "secret or non-cookie CSRF token, and either masked or unmasked.",
        "secret or non-cookie CSRF token, and either masked"
    ],
    [
        "if len(token) not in (CSRF_TOKEN_LENGTH, CSRF_SECRET_LENGTH):",
        "if len(token) not in (CSRF_TOKEN_LENGTH,"
    ],
    [
        "Return whether the given CSRF token matches the given CSRF secret, after",
        "Return whether the given CSRF token matches the given CSRF secret,"
    ],
    [
        "This function assumes that the request_csrf_token argument has been",
        "This function assumes that the"
    ],
    [
        "validated to have the correct length (CSRF_SECRET_LENGTH or",
        "validated to have the correct"
    ],
    [
        "CSRF_TOKEN_LENGTH characters) and allowed characters, and that if it has",
        "CSRF_TOKEN_LENGTH characters) and allowed characters, and"
    ],
    [
        "length CSRF_TOKEN_LENGTH, it is a masked secret.",
        "length CSRF_TOKEN_LENGTH, it is"
    ],
    [
        "Require a present and correct csrfmiddlewaretoken for POST requests that",
        "Require a present and correct csrfmiddlewaretoken"
    ],
    [
        "have a CSRF cookie, and set an outgoing CSRF cookie.",
        "have a CSRF cookie, and"
    ],
    [
        "This middleware should be used in conjunction with the {% csrf_token %}",
        "This middleware should be used in conjunction"
    ],
    [
        "return {origin for origin in settings.CSRF_TRUSTED_ORIGINS if \"*\" not in origin}",
        "return {origin for origin in settings.CSRF_TRUSTED_ORIGINS if \"*\" not in"
    ],
    [
        "A mapping of allowed schemes to list of allowed netlocs, where all",
        "A mapping of allowed schemes to list of allowed netlocs,"
    ],
    [
        "subdomains of the netloc are allowed.",
        "subdomains of the netloc"
    ],
    [
        "Return the CSRF secret originally associated with the request, or None",
        "Return the CSRF secret originally associated"
    ],
    [
        "If the CSRF_USE_SESSIONS setting is false, raises InvalidTokenFormat if",
        "If the CSRF_USE_SESSIONS setting is"
    ],
    [
        "the request's secret has invalid characters or an invalid length.",
        "the request's secret has invalid"
    ],
    [
        "\"CSRF_USE_SESSIONS is enabled, but request.session is not \"",
        "\"CSRF_USE_SESSIONS is enabled, but request.session"
    ],
    [
        "\"set. SessionMiddleware must appear before CsrfViewMiddleware \"",
        "\"set. SessionMiddleware must appear"
    ],
    [
        "good_referer = \"%s:%s\" % (good_referer, server_port)",
        "good_referer = \"%s:%s\""
    ],
    [
        "token_source = f\"the {header_name!r} HTTP header\"",
        "token_source = f\"the {header_name!r}"
    ],
    [
        "return f\"CSRF token from {token_source} {reason}.\"",
        "return f\"CSRF token from"
    ],
    [
        "def process_view(self, request, callback, callback_args, callback_kwargs):",
        "def process_view(self, request,"
    ],
    [
        "if request.method in (\"GET\", \"HEAD\", \"OPTIONS\", \"TRACE\"):",
        "if request.method in (\"GET\","
    ],
    [
        "self.redirect_exempt = [re.compile(r) for r in settings.SECURE_REDIRECT_EXEMPT]",
        "self.redirect_exempt = [re.compile(r) for r"
    ],
    [
        "and not any(pattern.search(path) for pattern in self.redirect_exempt)",
        "and not any(pattern.search(path) for"
    ],
    [
        "Cache middleware. If enabled, each Django-powered page will be cached based on",
        "Cache middleware. If enabled, each Django-powered page will be"
    ],
    [
        "URL. The canonical way to enable cache middleware is to set",
        "URL. The canonical way to enable cache middleware is"
    ],
    [
        "``UpdateCacheMiddleware`` as your first piece of middleware, and",
        "``UpdateCacheMiddleware`` as your first"
    ],
    [
        "This is counterintuitive, but correct: ``UpdateCacheMiddleware`` needs to run",
        "This is counterintuitive, but correct:"
    ],
    [
        "last during the response phase, which processes middleware bottom-up;",
        "last during the response phase, which processes middleware"
    ],
    [
        "``FetchFromCacheMiddleware`` needs to run last during the request phase, which",
        "``FetchFromCacheMiddleware`` needs to run last during the request phase,"
    ],
    [
        "The single-class ``CacheMiddleware`` can be used for some simple sites.",
        "The single-class ``CacheMiddleware`` can be"
    ],
    [
        "However, if any other piece of middleware needs to affect the cache key, you'll",
        "However, if any other piece of middleware needs to affect the"
    ],
    [
        "need to use the two-part ``UpdateCacheMiddleware`` and",
        "need to use the two-part ``UpdateCacheMiddleware``"
    ],
    [
        "``FetchFromCacheMiddleware``. This'll most often happen when you're using",
        "``FetchFromCacheMiddleware``. This'll most often happen when"
    ],
    [
        "More details about how the caching works:",
        "More details about how the caching"
    ],
    [
        "* The number of seconds each page is stored for is set by the \"max-age\" section",
        "* The number of seconds each page is stored"
    ],
    [
        "of the response's \"Cache-Control\" header, falling back to the",
        "of the response's \"Cache-Control\" header, falling back to"
    ],
    [
        "CACHE_MIDDLEWARE_SECONDS setting if the section was not found.",
        "CACHE_MIDDLEWARE_SECONDS setting if the section"
    ],
    [
        "* This middleware expects that a HEAD request is answered with the same response",
        "* This middleware expects that a HEAD request is answered with the"
    ],
    [
        "headers exactly like the corresponding GET request.",
        "headers exactly like the corresponding GET"
    ],
    [
        "* When a hit occurs, a shallow copy of the original response object is returned",
        "* When a hit occurs, a shallow copy of the original response object is"
    ],
    [
        "* Pages will be cached based on the contents of the request headers listed in",
        "* Pages will be cached based on the contents of the"
    ],
    [
        "* This middleware also sets ETag, Last-Modified, Expires and Cache-Control",
        "* This middleware also sets ETag, Last-Modified, Expires"
    ],
    [
        "Response-phase cache middleware that updates the cache if the response is",
        "Response-phase cache middleware that updates the"
    ],
    [
        "Must be used as part of the two-part update/fetch cache middleware.",
        "Must be used as part of the two-part update/fetch cache"
    ],
    [
        "UpdateCacheMiddleware must be the first piece of middleware in MIDDLEWARE",
        "UpdateCacheMiddleware must be the first piece of middleware"
    ],
    [
        "so that it'll get called last during the response phase.",
        "so that it'll get called"
    ],
    [
        "Request-phase cache middleware that fetches a page from the cache.",
        "Request-phase cache middleware that fetches a page"
    ],
    [
        "Must be used as part of the two-part update/fetch cache middleware.",
        "Must be used as part of the two-part update/fetch"
    ],
    [
        "FetchFromCacheMiddleware must be the last piece of middleware in MIDDLEWARE",
        "FetchFromCacheMiddleware must be the last piece"
    ],
    [
        "so that it'll get called last during the request phase.",
        "so that it'll get called last"
    ],
    [
        "Check whether the page is already cached and return the cached",
        "Check whether the page is already cached"
    ],
    [
        "if request.method not in (\"GET\", \"HEAD\"):",
        "if request.method not"
    ],
    [
        "cache_key = get_cache_key(request, self.key_prefix, \"GET\", cache=self.cache)",
        "cache_key = get_cache_key(request, self.key_prefix,"
    ],
    [
        "if response is None and request.method == \"HEAD\":",
        "if response is None and request.method =="
    ],
    [
        "if (max_age_seconds := get_max_age(response)) is not None and (",
        "if (max_age_seconds := get_max_age(response)) is not"
    ],
    [
        "Cache middleware that provides basic behavior for many simple sites.",
        "Cache middleware that provides basic behavior"
    ],
    [
        "Also used as the hook point for the cache decorator, which is generated",
        "Also used as the hook point for the"
    ],
    [
        "def __init__(self, get_response, cache_timeout=None, page_timeout=None, **kwargs):",
        "def __init__(self, get_response,"
    ],
    [
        "\"Common\" middleware for taking care of some basic operations:",
        "\"Common\" middleware for taking care"
    ],
    [
        "- Forbid access to User-Agents in settings.DISALLOWED_USER_AGENTS",
        "- Forbid access to"
    ],
    [
        "- URL rewriting: Based on the APPEND_SLASH and PREPEND_WWW settings,",
        "- URL rewriting: Based on"
    ],
    [
        "append missing slashes and/or prepends missing \"www.\"s.",
        "append missing slashes and/or prepends"
    ],
    [
        "- If APPEND_SLASH is set and the initial URL doesn't end with a",
        "- If APPEND_SLASH is set and the initial URL"
    ],
    [
        "slash, and it is not found in urlpatterns, form a new URL by",
        "slash, and it is not found in urlpatterns, form a"
    ],
    [
        "appending a slash at the end. If this new URL is found in",
        "appending a slash at the end. If this"
    ],
    [
        "urlpatterns, return an HTTP redirect to this new URL; otherwise",
        "urlpatterns, return an HTTP redirect"
    ],
    [
        "process the initial URL as usual.",
        "process the initial"
    ],
    [
        "This behavior can be customized by subclassing CommonMiddleware and",
        "This behavior can be customized by subclassing CommonMiddleware"
    ],
    [
        "Check for denied User-Agents and rewrite the URL based on",
        "Check for denied User-Agents and rewrite the"
    ],
    [
        "if settings.PREPEND_WWW and host and not host.startswith(\"www.\"):",
        "if settings.PREPEND_WWW and host and"
    ],
    [
        "Return True if settings.APPEND_SLASH is True and appending a slash to",
        "Return True if settings.APPEND_SLASH is True and appending"
    ],
    [
        "the request path turns an invalid path into a valid one.",
        "the request path turns an invalid path into"
    ],
    [
        "match = is_valid_path(\"%s/\" % request.path_info, urlconf)",
        "match = is_valid_path(\"%s/\""
    ],
    [
        "Return the full path of the request with a trailing slash appended.",
        "Return the full path of the request"
    ],
    [
        "Raise a RuntimeError if settings.DEBUG is True and request.method is",
        "Raise a RuntimeError if settings.DEBUG is True"
    ],
    [
        "if settings.DEBUG and request.method in (\"DELETE\", \"POST\", \"PUT\", \"PATCH\"):",
        "if settings.DEBUG and request.method in (\"DELETE\", \"POST\","
    ],
    [
        "\"You called this URL via %(method)s, but the URL doesn't end \"",
        "\"You called this URL via %(method)s,"
    ],
    [
        "\"in a slash and you have APPEND_SLASH set. Django can't \"",
        "\"in a slash and you have"
    ],
    [
        "\"redirect to the slash URL while maintaining %(method)s data. \"",
        "\"redirect to the slash URL while maintaining %(method)s data."
    ],
    [
        "\"Change your form to point to %(url)s (note the trailing \"",
        "\"Change your form to point to %(url)s (note the trailing"
    ],
    [
        "\"slash), or set APPEND_SLASH=False in your Django settings.\"",
        "\"slash), or set APPEND_SLASH=False in"
    ],
    [
        "with an appended slash if should_redirect_with_slash() returns True.",
        "with an appended slash if"
    ],
    [
        "if not response.streaming and not response.has_header(\"Content-Length\"):",
        "if not response.streaming and"
    ],
    [
        "if not self.is_ignorable_request(request, path, domain, referer):",
        "if not self.is_ignorable_request(request, path, domain,"
    ],
    [
        "\"Referrer: %s\\nRequested URL: %s\\nUser agent: %s\\n\"",
        "\"Referrer: %s\\nRequested URL: %s\\nUser"
    ],
    [
        "\"IP address: %s\\n\" % (referer, path, ua, ip),",
        "\"IP address: %s\\n\" %"
    ],
    [
        "Return True if the referring URL is the same domain as the current",
        "Return True if the referring URL is the same domain as the"
    ],
    [
        "def is_ignorable_request(self, request, uri, domain, referer):",
        "def is_ignorable_request(self, request, uri,"
    ],
    [
        "Return True if the given request *shouldn't* notify the site managers",
        "Return True if the given request *shouldn't* notify the site"
    ],
    [
        "according to project settings or in situations outlined by the inline",
        "according to project settings or in situations"
    ],
    [
        "if not self.is_internal_request(domain, referer) and \"?\" in referer:",
        "if not self.is_internal_request(domain, referer) and"
    ],
    [
        "if parsed_referer.netloc in [\"\", domain] and parsed_referer.path == uri:",
        "if parsed_referer.netloc in [\"\", domain] and parsed_referer.path"
    ],
    [
        "from django.utils.cache import cc_delim_re, get_conditional_response, set_response_etag",
        "from django.utils.cache import cc_delim_re,"
    ],
    [
        "Handle conditional GET operations. If the response has an ETag or",
        "Handle conditional GET operations. If the response"
    ],
    [
        "Last-Modified header and the request has If-None-Match or If-Modified-Since,",
        "Last-Modified header and the request has If-None-Match"
    ],
    [
        "replace the response with HttpNotModified. Add an ETag header if needed.",
        "replace the response with HttpNotModified. Add an ETag header if"
    ],
    [
        "\"\"\"Return True if an ETag header should be added to response.\"\"\"",
        "\"\"\"Return True if an ETag header should be added"
    ],
    [
        "return all(header.lower() != \"no-store\" for header in cache_control_headers)",
        "return all(header.lower() != \"no-store\" for header"
    ],
    [
        "Parse a request and decide what translation object to install in the",
        "Parse a request and decide what translation object to install in"
    ],
    [
        "current thread context. This allows pages to be dynamically translated to",
        "current thread context. This allows pages to be dynamically"
    ],
    [
        "the language the user desires (if the language is available).",
        "the language the user desires"
    ],
    [
        "language_path = \"/%s%s\" % (language, request.path_info)",
        "language_path = \"/%s%s\" % (language,"
    ],
    [
        "path_needs_slash = not path_valid and (",
        "path_needs_slash = not path_valid"
    ],
    [
        "Helper functions for creating Form classes from Django models",
        "Helper functions for creating Form classes from Django"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "Construct and return a model instance from the bound ``form``'s",
        "Construct and return a model instance"
    ],
    [
        "``cleaned_data``, but do not save the returned instance to the database.",
        "``cleaned_data``, but do not save the returned instance to"
    ],
    [
        "if fields is not None and f.name not in fields:",
        "if fields is not None and f.name not"
    ],
    [
        "if exclude and f.name in exclude:",
        "if exclude and f.name in"
    ],
    [
        "Return a dict containing the data in ``instance`` suitable for passing as",
        "Return a dict containing the data in ``instance``"
    ],
    [
        "``fields`` is an optional list of field names. If provided, return only the",
        "``fields`` is an optional list of field"
    ],
    [
        "``exclude`` is an optional list of field names. If provided, exclude the",
        "``exclude`` is an optional list of field names. If provided, exclude"
    ],
    [
        "named from the returned dict, even if they are listed in the ``fields``",
        "named from the returned dict, even if"
    ],
    [
        "for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):",
        "for f in chain(opts.concrete_fields,"
    ],
    [
        "if fields is not None and f.name not in fields:",
        "if fields is not None"
    ],
    [
        "if exclude and f.name in exclude:",
        "if exclude and f.name"
    ],
    [
        "\"\"\"Apply limit_choices_to to the formfield's queryset if needed.\"\"\"",
        "\"\"\"Apply limit_choices_to to the formfield's queryset if"
    ],
    [
        "from django.db.models import Exists, OuterRef, Q",
        "from django.db.models import Exists, OuterRef,"
    ],
    [
        "if hasattr(formfield, \"queryset\") and hasattr(formfield, \"get_limit_choices_to\"):",
        "if hasattr(formfield, \"queryset\") and"
    ],
    [
        "Return a dictionary containing form fields for the given model.",
        "Return a dictionary containing form fields for the"
    ],
    [
        "``fields`` is an optional list of field names. If provided, return only the",
        "``fields`` is an optional list of field names."
    ],
    [
        "``exclude`` is an optional list of field names. If provided, exclude the",
        "``exclude`` is an optional list of"
    ],
    [
        "named fields from the returned fields, even if they are listed in the",
        "named fields from the returned fields, even if they are listed in"
    ],
    [
        "``widgets`` is a dictionary of model field names mapped to a widget.",
        "``widgets`` is a dictionary of model field names mapped to a"
    ],
    [
        "``formfield_callback`` is a callable that takes a model field and returns",
        "``formfield_callback`` is a callable that takes a model"
    ],
    [
        "``localized_fields`` is a list of names of fields which should be localized.",
        "``localized_fields`` is a list of names of fields which should be"
    ],
    [
        "``labels`` is a dictionary of model field names mapped to a label.",
        "``labels`` is a dictionary of model field names mapped"
    ],
    [
        "``help_texts`` is a dictionary of model field names mapped to a help text.",
        "``help_texts`` is a dictionary of model field"
    ],
    [
        "``error_messages`` is a dictionary of model field names mapped to a",
        "``error_messages`` is a dictionary of model field names"
    ],
    [
        "``field_classes`` is a dictionary of model field names mapped to a form",
        "``field_classes`` is a dictionary of model"
    ],
    [
        "``apply_limit_choices_to`` is a boolean indicating if limit_choices_to",
        "``apply_limit_choices_to`` is a boolean"
    ],
    [
        "should be applied to a field's queryset.",
        "should be applied to a"
    ],
    [
        "``form_declared_fields`` is a dictionary of form fields created directly on",
        "``form_declared_fields`` is a dictionary of"
    ],
    [
        "from django.db.models import Field as ModelField",
        "from django.db.models import"
    ],
    [
        "f for f in opts.private_fields if isinstance(f, ModelField)",
        "f for f in opts.private_fields"
    ],
    [
        "and (exclude is None or f.name not in exclude)",
        "and (exclude is None or f.name not in"
    ],
    [
        "\"'%s' cannot be specified for %s model form as it is a \"",
        "\"'%s' cannot be specified for %s model form as it is a"
    ],
    [
        "if fields is not None and f.name not in fields:",
        "if fields is not None and f.name not"
    ],
    [
        "if exclude and f.name in exclude:",
        "if exclude and"
    ],
    [
        "if widgets and f.name in widgets:",
        "if widgets and"
    ],
    [
        "if localized_fields == ALL_FIELDS or (",
        "if localized_fields =="
    ],
    [
        "if labels and f.name in labels:",
        "if labels and"
    ],
    [
        "if help_texts and f.name in help_texts:",
        "if help_texts and"
    ],
    [
        "if error_messages and f.name in error_messages:",
        "if error_messages and f.name in"
    ],
    [
        "if field_classes and f.name in field_classes:",
        "if field_classes and f.name in"
    ],
    [
        "raise TypeError(\"formfield_callback must be a function or callable\")",
        "raise TypeError(\"formfield_callback must be a function or"
    ],
    [
        "if (not exclude or f not in exclude) and f not in ignored",
        "if (not exclude or f not in exclude)"
    ],
    [
        "new_class = super().__new__(mcs, name, bases, attrs)",
        "new_class = super().__new__(mcs, name,"
    ],
    [
        "opts = new_class._meta = ModelFormOptions(getattr(new_class, \"Meta\", None))",
        "opts = new_class._meta = ModelFormOptions(getattr(new_class, \"Meta\","
    ],
    [
        "for opt in [\"fields\", \"exclude\", \"localized_fields\"]:",
        "for opt in [\"fields\", \"exclude\","
    ],
    [
        "if isinstance(value, str) and value != ALL_FIELDS:",
        "if isinstance(value, str) and"
    ],
    [
        "\"%(model)s.Meta.%(opt)s cannot be a string. \"",
        "\"%(model)s.Meta.%(opt)s cannot be"
    ],
    [
        "\"Did you mean to type: ('%(value)s',)?\"",
        "\"Did you mean to type:"
    ],
    [
        "if opts.fields is None and opts.exclude is None:",
        "if opts.fields is None"
    ],
    [
        "\"Creating a ModelForm without either the 'fields' attribute \"",
        "\"Creating a ModelForm without either the"
    ],
    [
        "\"or the 'exclude' attribute is prohibited; form %s \"",
        "\"or the 'exclude' attribute is"
    ],
    [
        "none_model_fields = {k for k, v in fields.items() if not v}",
        "none_model_fields = {k for k, v in fields.items()"
    ],
    [
        "message = \"Unknown field(s) (%s) specified for %s\"",
        "message = \"Unknown field(s) (%s)"
    ],
    [
        "raise ValueError(\"ModelForm has no model class specified.\")",
        "raise ValueError(\"ModelForm has no model class"
    ],
    [
        "For backwards-compatibility, exclude several types of fields from model",
        "For backwards-compatibility, exclude several types of fields from"
    ],
    [
        "elif self._meta.fields and field not in self._meta.fields:",
        "elif self._meta.fields and field not in"
    ],
    [
        "elif self._meta.exclude and field in self._meta.exclude:",
        "elif self._meta.exclude and field"
    ],
    [
        "Call the instance's validate_unique() method and update the form's",
        "Call the instance's validate_unique() method"
    ],
    [
        "validation errors if any were raised.",
        "validation errors if any were"
    ],
    [
        "Save the many-to-many fields and generic relations for this form.",
        "Save the many-to-many fields and generic relations for this"
    ],
    [
        "if fields and f.name not in fields:",
        "if fields and f.name"
    ],
    [
        "if exclude and f.name in exclude:",
        "if exclude and f.name"
    ],
    [
        "Save this form's self.instance object if commit=True. Otherwise, add",
        "Save this form's self.instance object if"
    ],
    [
        "is saved manually at a later time. Return the model instance.",
        "is saved manually at a later"
    ],
    [
        "\"The %s could not be %s because the data didn't validate.\"",
        "\"The %s could not be %s because"
    ],
    [
        "Return a ModelForm containing form fields for the given model. You can",
        "Return a ModelForm containing form fields for the"
    ],
    [
        "optionally pass a `form` argument to use as a starting point for",
        "optionally pass a `form` argument to use as"
    ],
    [
        "``fields`` is an optional list of field names. If provided, include only",
        "``fields`` is an optional list of field names."
    ],
    [
        "the named fields in the returned fields. If omitted or '__all__', use all",
        "the named fields in the returned fields. If omitted"
    ],
    [
        "``exclude`` is an optional list of field names. If provided, exclude the",
        "``exclude`` is an optional list of field names. If"
    ],
    [
        "named fields from the returned fields, even if they are listed in the",
        "named fields from the returned fields, even if"
    ],
    [
        "``widgets`` is a dictionary of model field names mapped to a widget.",
        "``widgets`` is a dictionary of model field names mapped to a"
    ],
    [
        "``localized_fields`` is a list of names of fields which should be localized.",
        "``localized_fields`` is a list of names of fields which should"
    ],
    [
        "``formfield_callback`` is a callable that takes a model field and returns",
        "``formfield_callback`` is a callable that takes a model field and"
    ],
    [
        "``labels`` is a dictionary of model field names mapped to a label.",
        "``labels`` is a dictionary of model field names mapped to a"
    ],
    [
        "``help_texts`` is a dictionary of model field names mapped to a help text.",
        "``help_texts`` is a dictionary of model field names mapped to a help"
    ],
    [
        "``error_messages`` is a dictionary of model field names mapped to a",
        "``error_messages`` is a dictionary of model"
    ],
    [
        "``field_classes`` is a dictionary of model field names mapped to a form",
        "``field_classes`` is a dictionary of model"
    ],
    [
        "bases = (form.Meta,) if hasattr(form, \"Meta\") else ()",
        "bases = (form.Meta,) if hasattr(form,"
    ],
    [
        "if getattr(Meta, \"fields\", None) is None and getattr(Meta, \"exclude\", None) is None:",
        "if getattr(Meta, \"fields\", None) is None"
    ],
    [
        "\"Calling modelform_factory without defining 'fields' or \"",
        "\"Calling modelform_factory without defining 'fields'"
    ],
    [
        "A ``FormSet`` for editing a queryset and/or adding new objects to it.",
        "A ``FormSet`` for editing a queryset and/or adding new objects to"
    ],
    [
        "\"\"\"Return the number of forms that are required in this FormSet.\"\"\"",
        "\"\"\"Return the number of forms that"
    ],
    [
        "self._object_dict = {o.pk: o for o in self.get_queryset()}",
        "self._object_dict = {o.pk: o for o"
    ],
    [
        "If the field is a related field, fetch the concrete field's (that",
        "If the field is a related field, fetch the"
    ],
    [
        "is, the ultimate pointed-to field's) to_python.",
        "is, the ultimate pointed-to"
    ],
    [
        "pk_key = \"%s-%s\" % (self.add_prefix(i), self.model._meta.pk.name)",
        "pk_key = \"%s-%s\" % (self.add_prefix(i),"
    ],
    [
        "\"\"\"Save and return a new model instance for the given form.\"\"\"",
        "\"\"\"Save and return a new model instance for"
    ],
    [
        "\"\"\"Save and return an existing model instance for the given form.\"\"\"",
        "\"\"\"Save and return an existing model instance for"
    ],
    [
        "Save model instances for every form, adding and changing instances",
        "Save model instances for every form,"
    ],
    [
        "as necessary, and return the list of instances.",
        "as necessary, and return"
    ],
    [
        "if form.is_valid() and form not in forms_to_delete",
        "if form.is_valid() and form not"
    ],
    [
        "field if field in self.unique_fields else form.cleaned_data[field]",
        "field if field in"
    ],
    [
        "if row_data and None not in row_data:",
        "if row_data and None not in"
    ],
    [
        "uclass, lookup, field, unique_for = date_check",
        "uclass, lookup, field,"
    ],
    [
        "return gettext(\"Please correct the duplicate data for %(field)s.\") % {",
        "return gettext(\"Please correct the duplicate"
    ],
    [
        "\"Please correct the duplicate data for %(field)s, which must be unique.\"",
        "\"Please correct the duplicate data for %(field)s, which"
    ],
    [
        "\"Please correct the duplicate data for %(field_name)s \"",
        "\"Please correct the duplicate data for"
    ],
    [
        "\"which must be unique for the %(lookup)s in %(date_field)s.\"",
        "\"which must be unique for the"
    ],
    [
        "return gettext(\"Please correct the duplicate values below.\")",
        "return gettext(\"Please correct the duplicate"
    ],
    [
        "\"\"\"Add a hidden field for the object's primary key.\"\"\"",
        "\"\"\"Add a hidden field for"
    ],
    [
        "from django.db.models import AutoField, ForeignKey, OneToOneField",
        "from django.db.models import"
    ],
    [
        "if pk_is_not_editable(pk) or pk.name not in form.fields:",
        "if pk_is_not_editable(pk) or pk.name not"
    ],
    [
        "pk_value = None if form.instance._state.adding else form.instance.pk",
        "pk_value = None if form.instance._state.adding"
    ],
    [
        "\"\"\"Return a FormSet class for the given Django model class.\"\"\"",
        "\"\"\"Return a FormSet class for the"
    ],
    [
        "and getattr(meta, \"exclude\", exclude) is None",
        "and getattr(meta, \"exclude\", exclude)"
    ],
    [
        "\"Calling modelformset_factory without defining 'fields' or \"",
        "\"Calling modelformset_factory without defining"
    ],
    [
        "\"\"\"A formset for child objects related to a parent.\"\"\"",
        "\"\"\"A formset for child objects related to"
    ],
    [
        "if self.form._meta.fields and self.fk.name not in self.form._meta.fields:",
        "if self.form._meta.fields and self.fk.name"
    ],
    [
        "unique_check = [field for field in unique_check if field != self.fk.name]",
        "unique_check = [field for field in unique_check if field"
    ],
    [
        "Find and return the ForeignKey from model to parent if there is one",
        "Find and return the ForeignKey from model to parent if there"
    ],
    [
        "(return None if can_fail is True and no such field exists). If fk_name is",
        "(return None if can_fail is True and no such"
    ],
    [
        "provided, assume it is the name of the ForeignKey field. Unless can_fail is",
        "provided, assume it is the name of"
    ],
    [
        "True, raise an exception if there isn't a ForeignKey from model to",
        "True, raise an exception if there isn't a ForeignKey"
    ],
    [
        "fks_to_parent = [f for f in opts.fields if f.name == fk_name]",
        "fks_to_parent = [f for f in opts.fields"
    ],
    [
        "\"fk_name '%s' is not a ForeignKey to '%s'.\"",
        "\"fk_name '%s' is not a"
    ],
    [
        "\"'%s' has no field named '%s'.\" % (model._meta.label, fk_name)",
        "\"'%s' has no field named '%s'.\" %"
    ],
    [
        "\"'%s' has no ForeignKey to '%s'.\"",
        "\"'%s' has no ForeignKey to"
    ],
    [
        "\"'%s' has more than one ForeignKey to '%s'. You must specify \"",
        "\"'%s' has more than one ForeignKey to '%s'."
    ],
    [
        "Return an ``InlineFormSet`` for the given kwargs.",
        "Return an ``InlineFormSet`` for the given"
    ],
    [
        "``fk_name`` must be provided if ``model`` has more than one ``ForeignKey``",
        "``fk_name`` must be provided if ``model`` has more than one"
    ],
    [
        "A basic integer field that deals with validating the given value to a",
        "A basic integer field that deals with validating"
    ],
    [
        "given parent instance in an inline.",
        "given parent instance"
    ],
    [
        "\"invalid_choice\": _(\"The inline value did not match the parent instance.\"),",
        "\"invalid_choice\": _(\"The inline value did not match the"
    ],
    [
        "def __init__(self, parent_instance, *args, pk_field=False, to_field=None, **kwargs):",
        "def __init__(self, parent_instance, *args, pk_field=False,"
    ],
    [
        "return self.field.empty_label is not None or self.queryset.exists()",
        "return self.field.empty_label is not None"
    ],
    [
        "\"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"",
        "\"\"\"A ChoiceField whose choices are"
    ],
    [
        "\"Select a valid choice. That choice is not one of the available choices.\"",
        "\"Select a valid choice. That choice is not one"
    ],
    [
        "if (required and initial is not None) or (",
        "if (required and initial is not"
    ],
    [
        "Return ``limit_choices_to`` for this form field.",
        "Return ``limit_choices_to`` for this form"
    ],
    [
        "If it is a callable, invoke it and return the result.",
        "If it is a callable, invoke it and"
    ],
    [
        "self._queryset = None if queryset is None else queryset.all()",
        "self._queryset = None if queryset is"
    ],
    [
        "Convert objects into strings and generate the labels for the choices",
        "Convert objects into strings and generate the labels for the"
    ],
    [
        "presented by this object. Subclasses can override this method to",
        "presented by this object. Subclasses can override this method"
    ],
    [
        "customize the display of the choices.",
        "customize the display"
    ],
    [
        "initial_value = initial if initial is not None else \"\"",
        "initial_value = initial if initial is not None else"
    ],
    [
        "data_value = data if data is not None else \"\"",
        "data_value = data if data is not None"
    ],
    [
        "\"\"\"A MultipleChoiceField whose choices are a model QuerySet.\"\"\"",
        "\"\"\"A MultipleChoiceField whose choices are a"
    ],
    [
        "\"invalid_list\": _(\"Enter a list of values.\"),",
        "\"invalid_list\": _(\"Enter a list"
    ],
    [
        "\"Select a valid choice. %(value)s is not one of the available choices.\"",
        "\"Select a valid choice. %(value)s is not one of the available"
    ],
    [
        "\"invalid_pk_value\": _(\"“%(pk)s” is not a valid value.\"),",
        "\"invalid_pk_value\": _(\"“%(pk)s” is not"
    ],
    [
        "elif not self.required and not value:",
        "elif not self.required"
    ],
    [
        "Given a list of possible PK values, return a QuerySet of the",
        "Given a list of possible PK values, return"
    ],
    [
        "corresponding objects. Raise a ValidationError if a given value is",
        "corresponding objects. Raise a ValidationError if a given"
    ],
    [
        "invalid (not a valid PK, not in the queryset, etc.)",
        "invalid (not a valid PK, not in the"
    ],
    [
        "qs = self.queryset.filter(**{\"%s__in\" % key: value})",
        "qs = self.queryset.filter(**{\"%s__in\""
    ],
    [
        "pks = {str(getattr(o, key)) for o in qs}",
        "pks = {str(getattr(o, key)) for o in"
    ],
    [
        "return [prepare_value(v) for v in value]",
        "return [prepare_value(v) for v in"
    ],
    [
        "initial_set = {str(value) for value in self.prepare_value(initial)}",
        "initial_set = {str(value) for value in"
    ],
    [
        "data_set = {str(value) for value in data}",
        "data_set = {str(value) for value in"
    ],
    [
        "form_class._meta.fields is not None or form_class._meta.exclude is not None",
        "form_class._meta.fields is not None or form_class._meta.exclude is not"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "self.required, self.label, self.initial = required, label, initial",
        "self.required, self.label, self.initial ="
    ],
    [
        "if value in self.empty_values and self.required:",
        "if value in self.empty_values and"
    ],
    [
        "if hasattr(e, \"code\") and e.code in self.error_messages:",
        "if hasattr(e, \"code\") and e.code in"
    ],
    [
        "Validate the given value and return its \"cleaned\" value as an",
        "Validate the given value and return"
    ],
    [
        "appropriate Python object. Raise ValidationError for any errors.",
        "appropriate Python object. Raise ValidationError for"
    ],
    [
        "Return the value that should be shown for this field on render of a",
        "Return the value that should be shown for this"
    ],
    [
        "bound form, given the submitted POST data for the field and the initial",
        "bound form, given the submitted POST data for the field and the"
    ],
    [
        "For most fields, this will simply be data; FileFields need to handle it",
        "For most fields, this will simply be data;"
    ],
    [
        "Given a Widget instance (*not* a Widget class), return a dictionary of",
        "Given a Widget instance (*not* a"
    ],
    [
        "any HTML attributes that should be added to the Widget, based on this",
        "any HTML attributes that should be added to the Widget, based on"
    ],
    [
        "\"\"\"Return True if data differs from initial.\"\"\"",
        "\"\"\"Return True if data"
    ],
    [
        "initial_value = initial if initial is not None else \"\"",
        "initial_value = initial if initial is"
    ],
    [
        "data_value = data if data is not None else \"\"",
        "data_value = data if data is not"
    ],
    [
        "Return a BoundField instance that will be used when accessing the form",
        "Return a BoundField instance that will"
    ],
    [
        "value = bf.initial if self.disabled else bf.data",
        "value = bf.initial if"
    ],
    [
        "self, *, max_length=None, min_length=None, strip=True, empty_value=\"\", **kwargs",
        "self, *, max_length=None, min_length=None, strip=True,"
    ],
    [
        "if self.max_length is not None and not widget.is_hidden:",
        "if self.max_length is not None"
    ],
    [
        "if self.min_length is not None and not widget.is_hidden:",
        "if self.min_length is not None"
    ],
    [
        "def __init__(self, *, max_value=None, min_value=None, step_size=None, **kwargs):",
        "def __init__(self, *, max_value=None,"
    ],
    [
        "self.max_value, self.min_value, self.step_size = max_value, min_value, step_size",
        "self.max_value, self.min_value, self.step_size ="
    ],
    [
        "if kwargs.get(\"localize\") and self.widget == NumberInput:",
        "if kwargs.get(\"localize\") and"
    ],
    [
        "Validate that int() can be called on the input. Return the result",
        "Validate that int() can be called on the input."
    ],
    [
        "of int() or None for empty values.",
        "of int() or None for"
    ],
    [
        "Validate that float() can be called on the input. Return the result",
        "Validate that float() can be called on the input. Return"
    ],
    [
        "of float() or None for empty values.",
        "of float() or None for"
    ],
    [
        "if isinstance(widget, NumberInput) and \"step\" not in widget.attrs:",
        "if isinstance(widget, NumberInput) and \"step\" not"
    ],
    [
        "Validate that the input is a decimal number. Return a Decimal",
        "Validate that the input is a decimal number. Return a"
    ],
    [
        "instance or None for empty values. Ensure that there are no more",
        "instance or None for empty values."
    ],
    [
        "than max_digits in the number and no more than decimal_places digits",
        "than max_digits in the number and no more than decimal_places"
    ],
    [
        "if isinstance(widget, NumberInput) and \"step\" not in widget.attrs:",
        "if isinstance(widget, NumberInput) and"
    ],
    [
        "raise NotImplementedError(\"Subclasses must define this method.\")",
        "raise NotImplementedError(\"Subclasses must define this"
    ],
    [
        "Validate that the input can be converted to a date. Return a Python",
        "Validate that the input can be converted to a"
    ],
    [
        "default_error_messages = {\"invalid\": _(\"Enter a valid time.\")}",
        "default_error_messages = {\"invalid\": _(\"Enter a valid"
    ],
    [
        "Validate that the input can be converted to a time. Return a Python",
        "Validate that the input can be converted to a time. Return"
    ],
    [
        "Validate that the input can be converted to a datetime. Return a",
        "Validate that the input can be converted to a"
    ],
    [
        "\"overflow\": _(\"The number of days must be between {min_days} and {max_days}.\"),",
        "\"overflow\": _(\"The number of days must be"
    ],
    [
        "regex can be either a string or a compiled regular expression object.",
        "regex can be either a string or a compiled"
    ],
    [
        "\"invalid\": _(\"No file was submitted. Check the encoding type on the form.\"),",
        "\"invalid\": _(\"No file was submitted. Check"
    ],
    [
        "\"empty\": _(\"The submitted file is empty.\"),",
        "\"empty\": _(\"The submitted file is"
    ],
    [
        "\"Ensure this filename has at most %(max)d character (it has %(length)d).\",",
        "\"Ensure this filename has at most %(max)d character (it"
    ],
    [
        "\"Ensure this filename has at most %(max)d characters (it has %(length)d).\",",
        "\"Ensure this filename has at most %(max)d characters"
    ],
    [
        "\"Please either submit a file or check the clear checkbox, not both.\"",
        "\"Please either submit a file or"
    ],
    [
        "def __init__(self, *, max_length=None, allow_empty_file=False, **kwargs):",
        "def __init__(self, *, max_length=None,"
    ],
    [
        "if self.max_length is not None and len(file_name) > self.max_length:",
        "if self.max_length is not None and"
    ],
    [
        "params = {\"max\": self.max_length, \"length\": len(file_name)}",
        "params = {\"max\": self.max_length, \"length\":"
    ],
    [
        "if not self.allow_empty_file and not file_size:",
        "if not self.allow_empty_file"
    ],
    [
        "return not self.disabled and data is not None",
        "return not self.disabled and data is not"
    ],
    [
        "value = bf.initial if self.disabled else bf.data",
        "value = bf.initial if self.disabled"
    ],
    [
        "\"Upload a valid image. The file you uploaded was either not an \"",
        "\"Upload a valid image. The file you"
    ],
    [
        "Check that the file-upload field data contains a valid image (GIF, JPG,",
        "Check that the file-upload field data contains"
    ],
    [
        "PNG, etc. -- whatever Pillow supports).",
        "PNG, etc. -- whatever Pillow"
    ],
    [
        "if isinstance(widget, FileInput) and \"accept\" not in widget.attrs:",
        "if isinstance(widget, FileInput) and \"accept\""
    ],
    [
        "Return a list of url parts via urlsplit(), or raise",
        "Return a list of url parts via"
    ],
    [
        "A field whose valid values are None, True, and False. Clean invalid values",
        "A field whose valid values are None, True, and False. Clean"
    ],
    [
        "Explicitly check for the string 'True' and 'False', which is what a",
        "Explicitly check for the string 'True' and 'False', which is"
    ],
    [
        "hidden field will submit for True and False, for 'true' and 'false',",
        "hidden field will submit for True and False, for 'true'"
    ],
    [
        "which are likely to be returned by JavaScript serializations of forms,",
        "which are likely to be returned by JavaScript serializations of"
    ],
    [
        "the Booleanfield, this field must check for True because it doesn't",
        "the Booleanfield, this field must check for True"
    ],
    [
        "\"Select a valid choice. %(value)s is not one of the available choices.\"",
        "\"Select a valid choice. %(value)s is not"
    ],
    [
        "\"\"\"Validate that the input is in self.choices.\"\"\"",
        "\"\"\"Validate that the input"
    ],
    [
        "\"\"\"Check to see if the provided value is a valid choice.\"\"\"",
        "\"\"\"Check to see if the provided value"
    ],
    [
        "if value == k or text_value == str(k):",
        "if value == k or"
    ],
    [
        "def __init__(self, *, coerce=lambda val: val, empty_value=\"\", **kwargs):",
        "def __init__(self, *, coerce=lambda val: val,"
    ],
    [
        "Validate that the value can be coerced to the right type (if not empty).",
        "Validate that the value can be coerced to"
    ],
    [
        "if value == self.empty_value or value in self.empty_values:",
        "if value == self.empty_value or value"
    ],
    [
        "\"Select a valid choice. %(value)s is not one of the available choices.\"",
        "\"Select a valid choice. %(value)s is not one of the"
    ],
    [
        "\"invalid_list\": _(\"Enter a list of values.\"),",
        "\"invalid_list\": _(\"Enter a"
    ],
    [
        "return [str(val) for val in value]",
        "return [str(val) for val"
    ],
    [
        "\"\"\"Validate that the input is a list or tuple.\"\"\"",
        "\"\"\"Validate that the input is a list or"
    ],
    [
        "initial_set = {str(value) for value in initial}",
        "initial_set = {str(value) for value in"
    ],
    [
        "data_set = {str(value) for value in data}",
        "data_set = {str(value) for"
    ],
    [
        "def __init__(self, *, coerce=lambda val: val, **kwargs):",
        "def __init__(self, *, coerce=lambda val:"
    ],
    [
        "Validate that the values are in self.choices and can be coerced to the",
        "Validate that the values are in self.choices and"
    ],
    [
        "if value == self.empty_value or value in self.empty_values:",
        "if value == self.empty_value"
    ],
    [
        "A Field whose clean() method calls multiple Field clean() methods.",
        "A Field whose clean() method calls multiple Field clean()"
    ],
    [
        "Validate the given value against all of self.fields, which is a",
        "Validate the given value against all of self.fields,"
    ],
    [
        "Aggregate the logic of multiple Fields.",
        "Aggregate the logic"
    ],
    [
        "Its clean() method takes a \"decompressed\" list of values, which are then",
        "Its clean() method takes a \"decompressed\" list"
    ],
    [
        "cleaned into a single value according to self.fields. Each value in",
        "cleaned into a single value according to"
    ],
    [
        "this list is cleaned by the corresponding field -- the first value is",
        "this list is cleaned by the corresponding field --"
    ],
    [
        "cleaned by the first field, the second value is cleaned by the second",
        "cleaned by the first field, the second value is cleaned by"
    ],
    [
        "field, etc. Once all fields are cleaned, the list of clean values is",
        "field, etc. Once all fields are cleaned, the list of"
    ],
    [
        "Subclasses should not have to implement clean(). Instead, they must",
        "Subclasses should not have to implement clean(). Instead, they"
    ],
    [
        "implement compress(), which takes a list of valid values and returns a",
        "implement compress(), which takes a list"
    ],
    [
        "\"compressed\" version of those values -- a single value.",
        "\"compressed\" version of those values"
    ],
    [
        "You'll probably want to use this with MultiWidget.",
        "You'll probably want to use"
    ],
    [
        "\"invalid\": _(\"Enter a list of values.\"),",
        "\"invalid\": _(\"Enter a"
    ],
    [
        "def __init__(self, fields, *, require_all_fields=True, **kwargs):",
        "def __init__(self, fields, *,"
    ],
    [
        "result.fields = tuple(x.__deepcopy__(memo) for x in self.fields)",
        "result.fields = tuple(x.__deepcopy__(memo) for x in"
    ],
    [
        "Validate every value in the given list. A value is validated against",
        "Validate every value in the given list. A"
    ],
    [
        "For example, if this MultiValueField was instantiated with",
        "For example, if this MultiValueField was"
    ],
    [
        "if self.disabled and not isinstance(value, list):",
        "if self.disabled and"
    ],
    [
        "if not value or isinstance(value, (list, tuple)):",
        "if not value or isinstance(value, (list,"
    ],
    [
        "if not value or not [v for v in value if v not in self.empty_values]:",
        "if not value or not [v for v in value if v not in"
    ],
    [
        "errors.extend(m for m in e.error_list if m not in errors)",
        "errors.extend(m for m in e.error_list"
    ],
    [
        "Return a single value for the given list of values. The values can be",
        "Return a single value for the given list of values. The"
    ],
    [
        "For example, if this MultiValueField was instantiated with",
        "For example, if this MultiValueField"
    ],
    [
        "fields=(DateField(), TimeField()), this might return a datetime",
        "fields=(DateField(), TimeField()), this might return a"
    ],
    [
        "object created by combining the date and time in data_list.",
        "object created by combining the date and time in"
    ],
    [
        "raise NotImplementedError(\"Subclasses must implement this method.\")",
        "raise NotImplementedError(\"Subclasses must implement this"
    ],
    [
        "for field, initial, data in zip(self.fields, initial, data):",
        "for field, initial, data"
    ],
    [
        "self.path, self.match, self.recursive = path, match, recursive",
        "self.path, self.match, self.recursive ="
    ],
    [
        "for root, dirs, files in sorted(os.walk(self.path)):",
        "for root, dirs,"
    ],
    [
        "if self.match is None or self.match_re.search(f):",
        "if self.match is None"
    ],
    [
        "if self.match is None or self.match_re.search(f):",
        "if self.match is None"
    ],
    [
        ") and (self.match is None or self.match_re.search(f.name)):",
        ") and (self.match is"
    ],
    [
        "def __init__(self, *, input_date_formats=None, input_time_formats=None, **kwargs):",
        "def __init__(self, *, input_date_formats=None,"
    ],
    [
        "if value and \":\" in value:",
        "if value and \":\""
    ],
    [
        "elif isinstance(value, (list, dict, int, float, JSONString)):",
        "elif isinstance(value, (list, dict, int, float,"
    ],
    [
        "return json.dumps(initial, sort_keys=True, cls=self.encoder) != json.dumps(",
        "return json.dumps(initial, sort_keys=True, cls=self.encoder)"
    ],
    [
        "from django.forms.widgets import MultiWidget, Textarea, TextInput",
        "from django.forms.widgets import MultiWidget,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "Most widgets yield a single subwidget, but others like RadioSelect and",
        "Most widgets yield a single subwidget, but"
    ],
    [
        "CheckboxSelectMultiple produce one subwidget for each choice.",
        "CheckboxSelectMultiple produce one subwidget for each"
    ],
    [
        "This property is cached so that only one database query occurs when",
        "This property is cached so that only"
    ],
    [
        "attrs = {\"id\": id_} if id_ else {}",
        "attrs = {\"id\": id_} if id_ else"
    ],
    [
        "\"BoundField indices must be integers or slices, not %s.\"",
        "\"BoundField indices must be integers or"
    ],
    [
        "Return an ErrorList (empty if there are no errors) for this field.",
        "Return an ErrorList (empty if there are no errors) for"
    ],
    [
        "Render the field by rendering the passed widget, adding any HTML",
        "Render the field by rendering the passed widget, adding"
    ],
    [
        "attributes passed as attrs. If a widget isn't specified, use the",
        "attributes passed as attrs. If a widget isn't specified,"
    ],
    [
        "if self.auto_id and \"id\" not in widget.attrs:",
        "if self.auto_id and \"id\" not in"
    ],
    [
        "\"id\", self.html_initial_id if only_initial else self.auto_id",
        "\"id\", self.html_initial_id if only_initial"
    ],
    [
        "if only_initial and self.html_initial_name in self.form.data:",
        "if only_initial and"
    ],
    [
        "Return a string of HTML for representing this as an <input type=\"text\">.",
        "Return a string of HTML for representing this as an <input"
    ],
    [
        "\"\"\"Return a string of HTML for representing this as a <textarea>.\"\"\"",
        "\"\"\"Return a string of HTML for representing this"
    ],
    [
        "Return a string of HTML for representing this as an <input type=\"hidden\">.",
        "Return a string of HTML for representing this as an <input"
    ],
    [
        "Return the data for this BoundField, or None if it wasn't given.",
        "Return the data for this BoundField, or None if it"
    ],
    [
        "Return the value for this BoundField, using the initial value if",
        "Return the value for this BoundField, using"
    ],
    [
        "the form is not bound or the data otherwise.",
        "the form is not bound"
    ],
    [
        "def label_tag(self, contents=None, attrs=None, label_suffix=None, tag=None):",
        "def label_tag(self, contents=None, attrs=None,"
    ],
    [
        "Wrap the given contents in a <label>, if the field has an ID attribute.",
        "Wrap the given contents in a <label>, if the field"
    ],
    [
        "contents should be mark_safe'd to avoid HTML escaping. If contents",
        "contents should be mark_safe'd to"
    ],
    [
        "aren't given, use the field's HTML-escaped label.",
        "aren't given, use the field's HTML-escaped"
    ],
    [
        "If attrs are given, use them as HTML attributes on the <label> tag.",
        "If attrs are given, use them as HTML"
    ],
    [
        "attrs = {**(attrs or {}), \"for\": id_for_label}",
        "attrs = {**(attrs or"
    ],
    [
        "attrs[\"class\"] += \" \" + self.form.required_css_class",
        "attrs[\"class\"] += \" \""
    ],
    [
        "Wrap the given contents in a <legend>, if the field has an ID",
        "Wrap the given contents in a <legend>,"
    ],
    [
        "attribute. Contents should be mark_safe'd to avoid HTML escaping. If",
        "attribute. Contents should be mark_safe'd"
    ],
    [
        "contents aren't given, use the field's HTML-escaped label.",
        "contents aren't given, use"
    ],
    [
        "If attrs are given, use them as HTML attributes on the <legend> tag.",
        "If attrs are given, use them as HTML attributes"
    ],
    [
        "Return a string of space-separated CSS classes for this field.",
        "Return a string of space-separated CSS"
    ],
    [
        "\"\"\"Return True if this BoundField's widget is hidden.\"\"\"",
        "\"\"\"Return True if this BoundField's widget is"
    ],
    [
        "Calculate and return the ID attribute for this BoundField, if the",
        "Calculate and return the ID attribute"
    ],
    [
        "associated Form has specified auto_id. Return an empty string otherwise.",
        "associated Form has specified auto_id. Return an empty string"
    ],
    [
        "if auto_id and \"%s\" in str(auto_id):",
        "if auto_id and"
    ],
    [
        "Wrapper around the field widget's `id_for_label` method.",
        "Wrapper around the field widget's `id_for_label`"
    ],
    [
        "Useful, for example, for focusing on this field regardless of whether",
        "Useful, for example, for focusing on this"
    ],
    [
        "it has a single widget or a MultiWidget.",
        "it has a single widget or"
    ],
    [
        "for subfield, subwidget in zip(self.field.fields, widget.widgets):",
        "for subfield, subwidget in"
    ],
    [
        "if not attrs.get(\"aria-describedby\") and not self.use_fieldset:",
        "if not attrs.get(\"aria-describedby\") and"
    ],
    [
        "Return the value of this BoundField widget's use_fieldset attribute.",
        "Return the value of this BoundField"
    ],
    [
        "A container class used for iterating over widgets. This is useful for",
        "A container class used for iterating over"
    ],
    [
        "widgets that have choices. For example, the following can be used in a",
        "widgets that have choices. For example, the following can be used"
    ],
    [
        "{% for radio in myform.beatles %}",
        "{% for radio in"
    ],
    [
        "context = {\"widget\": {**self.data, \"wrap_label\": wrap_label}}",
        "context = {\"widget\":"
    ],
    [
        "Django validation and HTML form handling.",
        "Django validation and"
    ],
    [
        "Load Django templates from the built-in widget templates in",
        "Load Django templates from the built-in widget templates"
    ],
    [
        "django/forms/templates and from apps' 'templates' directory.",
        "django/forms/templates and from"
    ],
    [
        "Load templates using template.loader.get_template() which is configured",
        "Load templates using template.loader.get_template() which"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "return (self.__class__ is other.__class__ and self.path == other.path) or (",
        "return (self.__class__ is other.__class__ and"
    ],
    [
        "isinstance(other, str) and self._path == other",
        "isinstance(other, str) and"
    ],
    [
        "Relative paths are resolved via the {% static %} template tag.",
        "Relative paths are resolved via the"
    ],
    [
        "return \"Media(css=%r, js=%r)\" % (self._css, self._js)",
        "return \"Media(css=%r, js=%r)\" % (self._css,"
    ],
    [
        "return {medium: self.merge(*lists) for medium, lists in css.items()}",
        "return {medium: self.merge(*lists) for"
    ],
    [
        "getattr(self, \"render_\" + name)() for name in MEDIA_TYPES",
        "getattr(self, \"render_\" + name)() for name"
    ],
    [
        "Given a relative or absolute path to a static asset, return an absolute",
        "Given a relative or absolute path to a static asset, return an"
    ],
    [
        "path. An absolute path will be returned unchanged while a relative path",
        "path. An absolute path will be"
    ],
    [
        "\"\"\"Return a Media object that only contains media of the given type.\"\"\"",
        "\"\"\"Return a Media object that only contains media of the"
    ],
    [
        "return Media(**{str(name): getattr(self, \"_\" + name)})",
        "return Media(**{str(name): getattr(self,"
    ],
    [
        "raise KeyError('Unknown media type \"%s\"' % name)",
        "raise KeyError('Unknown media type \"%s\"'"
    ],
    [
        "Merge lists while trying to keep the relative order of the elements.",
        "Merge lists while trying to keep the relative order"
    ],
    [
        "Warn if the lists have the same elements in a different relative order.",
        "Warn if the lists have the same elements in a different relative"
    ],
    [
        "For static assets it can be important to have them included in the DOM",
        "For static assets it can be important to have"
    ],
    [
        "in a certain order. In JavaScript you may not be able to reference a",
        "in a certain order. In JavaScript you may not be"
    ],
    [
        "global or in CSS you might want to override a style.",
        "global or in CSS you might want"
    ],
    [
        "for head, *tail in filter(None, lists):",
        "for head, *tail"
    ],
    [
        "\"Detected duplicate Media files in an opposite order: {}\".format(",
        "\"Detected duplicate Media files in"
    ],
    [
        "\", \".join(repr(list_) for list_ in lists)",
        "\", \".join(repr(list_) for list_"
    ],
    [
        "if item and item not in self._css_lists:",
        "if item and item not in"
    ],
    [
        "if item and item not in self._js_lists:",
        "if item and item"
    ],
    [
        "Metaclass for classes that can have media definitions.",
        "Metaclass for classes that can"
    ],
    [
        "new_class = super().__new__(mcs, name, bases, attrs)",
        "new_class = super().__new__(mcs,"
    ],
    [
        "self.attrs = {} if attrs is None else attrs.copy()",
        "self.attrs = {} if attrs"
    ],
    [
        "return self.input_type == \"hidden\" if hasattr(self, \"input_type\") else False",
        "return self.input_type == \"hidden\" if"
    ],
    [
        "Return a value as it should appear when rendered in a template.",
        "Return a value as it should appear when rendered"
    ],
    [
        "if value == \"\" or value is None:",
        "if value == \"\" or"
    ],
    [
        "def render(self, name, value, attrs=None, renderer=None):",
        "def render(self, name, value, attrs=None,"
    ],
    [
        "\"\"\"Render the widget as an HTML string.\"\"\"",
        "\"\"\"Render the widget as"
    ],
    [
        "Given a dictionary of data and this widget's name, return the value",
        "Given a dictionary of data and this widget's name,"
    ],
    [
        "of this widget or None if it's not provided.",
        "of this widget or None if it's"
    ],
    [
        "Return the HTML ID attribute of this Widget for use by a <label>, given",
        "Return the HTML ID attribute of this Widget for"
    ],
    [
        "the ID of the field. Return an empty string if no ID is available.",
        "the ID of the field. Return an"
    ],
    [
        "This hook is necessary because some widgets have multiple HTML",
        "This hook is necessary because some widgets have multiple"
    ],
    [
        "elements and, thus, multiple IDs. In that case, this method should",
        "elements and, thus, multiple IDs. In that case, this method"
    ],
    [
        "return an ID value that corresponds to the first ID in the widget's",
        "return an ID value that corresponds to the first"
    ],
    [
        "Base class for all <input> widgets.",
        "Base class for all <input>"
    ],
    [
        "Handle <input type=\"hidden\"> for fields that have a list",
        "Handle <input type=\"hidden\"> for fields that"
    ],
    [
        "widget_attrs[\"id\"] = \"%s_%s\" % (id_, index)",
        "widget_attrs[\"id\"] = \"%s_%s\" %"
    ],
    [
        "return [] if value is None else value",
        "return [] if value"
    ],
    [
        "\"%s doesn't support uploading multiple files.\"",
        "\"%s doesn't support uploading multiple"
    ],
    [
        "\"\"\"File input never renders a value.\"\"\"",
        "\"\"\"File input never renders a"
    ],
    [
        "\"File widgets take data from FILES, not POST\"",
        "\"File widgets take data from FILES,"
    ],
    [
        "Given the name of the file input, return the name of the clear checkbox",
        "Given the name of the file input, return the name of the"
    ],
    [
        "Given the name of the clear checkbox input, return the HTML id for it.",
        "Given the name of the clear checkbox"
    ],
    [
        "Return whether value is considered to be initial value.",
        "Return whether value is considered to be"
    ],
    [
        "return bool(value and getattr(value, \"url\", False))",
        "return bool(value and"
    ],
    [
        "Return the file object if it has a defined url attribute.",
        "Return the file object if it has a defined"
    ],
    [
        "return not (v is False or v is None or v == \"\")",
        "return not (v is False or v is None"
    ],
    [
        "self.check_test = boolean_check if check_test is None else check_test",
        "self.check_test = boolean_check if check_test is"
    ],
    [
        "\"\"\"Only return the 'value' attribute if value isn't empty.\"\"\"",
        "\"\"\"Only return the 'value' attribute if value isn't"
    ],
    [
        "if value is True or value is False or value is None or value == \"\":",
        "if value is True or value is False or value is None"
    ],
    [
        "attrs = {**(attrs or {}), \"checked\": True}",
        "attrs = {**(attrs or {}), \"checked\":"
    ],
    [
        "values = {\"true\": True, \"false\": False}",
        "values = {\"true\":"
    ],
    [
        "Yield all \"subwidgets\" of this widget. Used to enable iterating",
        "Yield all \"subwidgets\" of this"
    ],
    [
        "options from a BoundField for choice widgets.",
        "options from a BoundField for"
    ],
    [
        "\"\"\"Yield a flat list of options for this widget.\"\"\"",
        "\"\"\"Yield a flat list of options"
    ],
    [
        "for group in self.optgroups(name, value, attrs):",
        "for group in self.optgroups(name, value,"
    ],
    [
        "\"\"\"Return a list of optgroups for this widget.\"\"\"",
        "\"\"\"Return a list of optgroups for this"
    ],
    [
        "for index, (option_value, option_label) in enumerate(self.choices):",
        "for index, (option_value, option_label)"
    ],
    [
        "selected = (not has_selected or self.allow_multiple_selected) and str(",
        "selected = (not has_selected"
    ],
    [
        "self, name, value, label, selected, index, subindex=None, attrs=None",
        "self, name, value, label, selected, index,"
    ],
    [
        "index = str(index) if subindex is None else \"%s_%s\" % (index, subindex)",
        "index = str(index) if subindex is None else"
    ],
    [
        "self.build_attrs(self.attrs, attrs) if self.option_inherits_attrs else {}",
        "self.build_attrs(self.attrs, attrs) if"
    ],
    [
        "Use an incremented id for each option where the main widget",
        "Use an incremented id for each option"
    ],
    [
        "id_ = \"%s_%s\" % (id_, index)",
        "id_ = \"%s_%s\" % (id_,"
    ],
    [
        "\"\"\"Return selected values as a list.\"\"\"",
        "\"\"\"Return selected values"
    ],
    [
        "if value is None and self.allow_multiple_selected:",
        "if value is"
    ],
    [
        "return [str(v) if v is not None else \"\" for v in value]",
        "return [str(v) if v is not None else \"\" for v in"
    ],
    [
        "\"\"\"Return True if the choice's value is empty string or None.\"\"\"",
        "\"\"\"Return True if the choice's value is empty"
    ],
    [
        "return value is None or value == \"\"",
        "return value is None or"
    ],
    [
        "Don't render 'required' if the first <option> has a value, as that's",
        "Don't render 'required' if the first <option> has a value, as"
    ],
    [
        "A Select Widget intended to be used with NullBooleanField.",
        "A Select Widget intended to"
    ],
    [
        "using a screen reader, in addition clicking such a label would toggle",
        "using a screen reader, in addition"
    ],
    [
        "A widget that is composed of multiple widgets.",
        "A widget that is composed of multiple"
    ],
    [
        "In addition to the values added by Widget.get_context(), this widget",
        "In addition to the values added by Widget.get_context(),"
    ],
    [
        "adds a list of subwidgets to the context as widget['subwidgets'].",
        "adds a list of subwidgets to the"
    ],
    [
        "These can be looped over and rendered like normal widgets.",
        "These can be looped over and rendered"
    ],
    [
        "You'll probably want to use this class with MultiValueField.",
        "You'll probably want to use this class with"
    ],
    [
        "self.widgets_names = [(\"_%s\" % name) if name else \"\" for name in widgets]",
        "self.widgets_names = [(\"_%s\" % name) if name else \"\" for"
    ],
    [
        "self.widgets_names = [\"_%s\" % i for i in range(len(widgets))]",
        "self.widgets_names = [\"_%s\" % i for"
    ],
    [
        "self.widgets = [w() if isinstance(w, type) else w for w in widgets]",
        "self.widgets = [w() if isinstance(w, type) else"
    ],
    [
        "return all(w.is_hidden for w in self.widgets)",
        "return all(w.is_hidden for"
    ],
    [
        "for i, (widget_name, widget) in enumerate(",
        "for i, (widget_name, widget) in"
    ],
    [
        "widget_attrs[\"id\"] = \"%s_%s\" % (id_, i)",
        "widget_attrs[\"id\"] = \"%s_%s\""
    ],
    [
        "for widget_name, widget in zip(self.widgets_names, self.widgets)",
        "for widget_name, widget in zip(self.widgets_names,"
    ],
    [
        "for widget_name, widget in zip(self.widgets_names, self.widgets)",
        "for widget_name, widget in zip(self.widgets_names,"
    ],
    [
        "Return a list of decompressed values for the given compressed value.",
        "Return a list of decompressed values for"
    ],
    [
        "The given value can be assumed to be valid, but not necessarily",
        "The given value can be assumed to be valid,"
    ],
    [
        "raise NotImplementedError(\"Subclasses must implement this method.\")",
        "raise NotImplementedError(\"Subclasses must implement"
    ],
    [
        "Media for a multiwidget is the combination of all media of the",
        "Media for a multiwidget is the combination of all"
    ],
    [
        "return any(w.needs_multipart_form for w in self.widgets)",
        "return any(w.needs_multipart_form for"
    ],
    [
        "A widget that splits datetime input into two <input type=\"text\"> boxes.",
        "A widget that splits datetime input into"
    ],
    [
        "attrs=attrs if date_attrs is None else date_attrs,",
        "attrs=attrs if date_attrs is None"
    ],
    [
        "attrs=attrs if time_attrs is None else time_attrs,",
        "attrs=attrs if time_attrs is"
    ],
    [
        "A widget that splits datetime input into two <input type=\"hidden\"> inputs.",
        "A widget that splits datetime input into two <input type=\"hidden\">"
    ],
    [
        "A widget that splits date input into three <select> boxes.",
        "A widget that splits date input into three"
    ],
    [
        "This also serves as an example of a Widget that has more than one HTML",
        "This also serves as an example of a Widget that has more than"
    ],
    [
        "def __init__(self, attrs=None, years=None, months=None, empty_label=None):",
        "def __init__(self, attrs=None,"
    ],
    [
        "year_choices = [(i, str(i)) for i in self.years]",
        "year_choices = [(i, str(i)) for i"
    ],
    [
        "Return a dict containing the year, month, and day of the current value.",
        "Return a dict containing the year, month, and day of"
    ],
    [
        "Use dict instead of a datetime to allow invalid dates such as February",
        "Use dict instead of a datetime to allow"
    ],
    [
        "year, month, day = None, None, None",
        "year, month, day = None, None,"
    ],
    [
        "year, month, day = value.year, value.month, value.day",
        "year, month, day ="
    ],
    [
        "year, month, day = [int(val) or \"\" for val in match.groups()]",
        "year, month, day = [int(val) or \"\" for val in"
    ],
    [
        "year, month, day = d.year, d.month, d.day",
        "year, month, day = d.year,"
    ],
    [
        "return {\"year\": year, \"month\": month, \"day\": day}",
        "return {\"year\": year, \"month\": month, \"day\":"
    ],
    [
        "if y == m == d == \"\":",
        "if y == m =="
    ],
    [
        "if y is not None and m is not None and d is not None:",
        "if y is not None and m is not None and d is not"
    ],
    [
        "for interval in (\"year\", \"month\", \"day\")",
        "for interval in (\"year\", \"month\","
    ],
    [
        "from django.forms.widgets import CheckboxInput, HiddenInput, NumberInput",
        "from django.forms.widgets import CheckboxInput,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "Keep track of how many form instances are displayed on the page. If adding",
        "Keep track of how many form instances are displayed on the page. If"
    ],
    [
        "new forms via JavaScript, you should increment the count field of this form",
        "new forms via JavaScript, you should increment"
    ],
    [
        "A collection of instances of the same Form class.",
        "A collection of instances of the same"
    ],
    [
        "\"ManagementForm data is missing or has been tampered with. Missing fields: \"",
        "\"ManagementForm data is missing or has been tampered"
    ],
    [
        "\"%(field_names)s. You may need to file a bug report if the issue persists.\"",
        "\"%(field_names)s. You may need to file a"
    ],
    [
        "\"Please submit at most %(num)d form.\",",
        "\"Please submit at most %(num)d"
    ],
    [
        "\"Please submit at most %(num)d forms.\",",
        "\"Please submit at"
    ],
    [
        "\"Please submit at least %(num)d form.\",",
        "\"Please submit at"
    ],
    [
        "\"Please submit at least %(num)d forms.\",",
        "\"Please submit at"
    ],
    [
        "self.is_bound = data is not None or files is not None",
        "self.is_bound = data is not None or files is"
    ],
    [
        "\"\"\"Yield the forms in the order they should be rendered.\"\"\"",
        "\"\"\"Yield the forms in the order they"
    ],
    [
        "\"\"\"Return the form at the given index, based on the rendering order.\"\"\"",
        "\"\"\"Return the form at the given index, based"
    ],
    [
        "Return True since all formsets have a management form which is not",
        "Return True since all formsets have a management form"
    ],
    [
        "and not any(form_errors for form_errors in self._errors)",
        "and not any(form_errors for form_errors in"
    ],
    [
        "return \"<%s: bound=%s valid=%s total_forms=%s>\" % (",
        "return \"<%s: bound=%s valid=%s"
    ],
    [
        "\"\"\"Return the ManagementForm instance for this FormSet.\"\"\"",
        "\"\"\"Return the ManagementForm instance for"
    ],
    [
        "\"\"\"Return the total number of forms in this FormSet.\"\"\"",
        "\"\"\"Return the total number of forms"
    ],
    [
        "total_forms = max(initial_forms, self.min_num) + self.extra",
        "total_forms = max(initial_forms,"
    ],
    [
        "\"\"\"Return the number of forms that are required in this FormSet.\"\"\"",
        "\"\"\"Return the number of forms that are required in this"
    ],
    [
        "\"\"\"Instantiate forms at first property access.\"\"\"",
        "\"\"\"Instantiate forms at first property"
    ],
    [
        "Return additional keyword arguments for each individual formset form.",
        "Return additional keyword arguments for each individual formset"
    ],
    [
        "index will be None if the form being constructed is a new empty",
        "index will be None if the form being constructed"
    ],
    [
        "\"\"\"Instantiate and return the i-th form instance in a formset.\"\"\"",
        "\"\"\"Instantiate and return the i-th form"
    ],
    [
        "if self.initial and \"initial\" not in kwargs:",
        "if self.initial and \"initial\" not in"
    ],
    [
        "if i >= self.initial_form_count() and i >= self.min_num:",
        "if i >= self.initial_form_count() and i"
    ],
    [
        "\"\"\"Return a list of all the initial forms in this formset.\"\"\"",
        "\"\"\"Return a list of all the initial forms in"
    ],
    [
        "\"\"\"Return a list of all the extra forms in this formset.\"\"\"",
        "\"\"\"Return a list of all the"
    ],
    [
        "Return a list of form.cleaned_data dicts for every form in self.forms.",
        "Return a list of form.cleaned_data dicts for every"
    ],
    [
        "\"'%s' object has no attribute 'cleaned_data'\" % self.__class__.__name__",
        "\"'%s' object has no"
    ],
    [
        "return [form.cleaned_data for form in self.forms]",
        "return [form.cleaned_data for form"
    ],
    [
        "\"\"\"Return a list of forms that have been marked for deletion.\"\"\"",
        "\"\"\"Return a list of forms that have been marked for"
    ],
    [
        "if not self.is_valid() or not self.can_delete:",
        "if not self.is_valid()"
    ],
    [
        "if i >= self.initial_form_count() and not form.has_changed():",
        "if i >= self.initial_form_count()"
    ],
    [
        "return [self.forms[i] for i in self._deleted_form_indexes]",
        "return [self.forms[i] for i"
    ],
    [
        "Return a list of form in the order specified by the incoming data.",
        "Return a list of form in the order specified"
    ],
    [
        "Raise an AttributeError if ordering is not allowed.",
        "Raise an AttributeError if ordering is not"
    ],
    [
        "if not self.is_valid() or not self.can_order:",
        "if not self.is_valid()"
    ],
    [
        "\"'%s' object has no attribute 'ordered_forms'\" % self.__class__.__name__",
        "\"'%s' object has no attribute 'ordered_forms'\""
    ],
    [
        "if i >= self.initial_form_count() and not form.has_changed():",
        "if i >= self.initial_form_count() and not"
    ],
    [
        "Return an ErrorList of errors that aren't associated with a particular",
        "Return an ErrorList of errors that aren't associated with a"
    ],
    [
        "form -- i.e., from formset.clean(). Return an empty ErrorList if there",
        "form -- i.e., from formset.clean(). Return an empty ErrorList"
    ],
    [
        "\"\"\"Return a list of form.errors for every form in self.forms.\"\"\"",
        "\"\"\"Return a list of form.errors"
    ],
    [
        "\"\"\"Return the number of errors across all forms in the formset.\"\"\"",
        "\"\"\"Return the number of errors across all forms in"
    ],
    [
        "\"\"\"Return whether or not the form was marked for deletion.\"\"\"",
        "\"\"\"Return whether or not the form was marked"
    ],
    [
        "\"\"\"Return True if every form in self.forms is valid.\"\"\"",
        "\"\"\"Return True if every form in self.forms"
    ],
    [
        "Clean all of self.data and populate self._errors and",
        "Clean all of self.data"
    ],
    [
        "if not form.has_changed() and i >= self.initial_form_count():",
        "if not form.has_changed() and i >="
    ],
    [
        "and self.total_form_count() - len(self.deleted_forms) > self.max_num",
        "and self.total_form_count() - len(self.deleted_forms)"
    ],
    [
        "Hook for doing any extra formset-wide cleaning after Form.clean() has",
        "Hook for doing any extra formset-wide cleaning after"
    ],
    [
        "been called on every form. Any ValidationError raised by this method",
        "been called on every form. Any ValidationError raised"
    ],
    [
        "will not be associated with a particular form; it will be accessible",
        "will not be associated with a particular form; it"
    ],
    [
        "\"\"\"Return True if data in any form differs from initial.\"\"\"",
        "\"\"\"Return True if data in"
    ],
    [
        "return any(form.has_changed() for form in self)",
        "return any(form.has_changed() for"
    ],
    [
        "\"\"\"A hook for adding extra fields on to each form instance.\"\"\"",
        "\"\"\"A hook for adding extra fields on"
    ],
    [
        "if index is not None and index < initial_form_count:",
        "if index is not None"
    ],
    [
        "self.can_delete_extra or (index is not None and index < initial_form_count)",
        "self.can_delete_extra or (index is not"
    ],
    [
        "Return True if the formset needs to be multipart, i.e. it",
        "Return True if the formset needs"
    ],
    [
        "\"\"\"Return a FormSet for the given form class.\"\"\"",
        "\"\"\"Return a FormSet for the"
    ],
    [
        "raise ValueError(\"'absolute_max' must be greater or equal to 'max_num'.\")",
        "raise ValueError(\"'absolute_max' must be greater or"
    ],
    [
        "\"\"\"Validate every formset and return True if all are valid.\"\"\"",
        "\"\"\"Validate every formset and return True if all are"
    ],
    [
        "return all([formset.is_valid() for formset in formsets])",
        "return all([formset.is_valid() for"
    ],
    [
        "from django.forms.utils import ErrorDict, ErrorList, RenderableFormMixin",
        "from django.forms.utils import ErrorDict,"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "\"\"\"Collect Fields declared on the base classes.\"\"\"",
        "\"\"\"Collect Fields declared on"
    ],
    [
        "new_class = super().__new__(mcs, name, bases, attrs)",
        "new_class = super().__new__(mcs, name, bases,"
    ],
    [
        "if value is None and attr in declared_fields:",
        "if value is None"
    ],
    [
        "The main implementation of all the Form logic. Note that this class is",
        "The main implementation of all the Form logic. Note"
    ],
    [
        "different than Form. See the comments by the Form class for more info. Any",
        "different than Form. See the comments by the Form class for"
    ],
    [
        "improvements to the form API should be made to this class, not to the Form",
        "improvements to the form API should be made"
    ],
    [
        "self.is_bound = data is not None or files is not None",
        "self.is_bound = data is not None or files"
    ],
    [
        "self.data = MultiValueDict() if data is None else data",
        "self.data = MultiValueDict() if data is None"
    ],
    [
        "self.files = MultiValueDict() if files is None else files",
        "self.files = MultiValueDict() if files is"
    ],
    [
        "self.label_suffix = label_suffix if label_suffix is not None else _(\":\")",
        "self.label_suffix = label_suffix if label_suffix is"
    ],
    [
        "self.order_fields(self.field_order if field_order is None else field_order)",
        "self.order_fields(self.field_order if field_order is"
    ],
    [
        "\"The empty_permitted and use_required_attribute arguments may \"",
        "\"The empty_permitted and use_required_attribute arguments"
    ],
    [
        "Rearrange the fields according to field_order.",
        "Rearrange the fields"
    ],
    [
        "field_order is a list of field names specifying the order. Append fields",
        "field_order is a list of field names specifying the"
    ],
    [
        "not included in the list in the default order for backward compatibility",
        "not included in the list in the default order for backward"
    ],
    [
        "with subclasses not overriding field_order. If field_order is None,",
        "with subclasses not overriding field_order. If"
    ],
    [
        "keep all fields in the order defined in the class. Ignore unknown",
        "keep all fields in the order"
    ],
    [
        "fields in field_order to allow disabling fields in form subclasses",
        "fields in field_order to allow disabling fields"
    ],
    [
        "is_valid = self.is_bound and not self._errors",
        "is_valid = self.is_bound and"
    ],
    [
        "return \"<%(cls)s bound=%(bound)s, valid=%(valid)s, fields=(%(fields)s)>\" % {",
        "return \"<%(cls)s bound=%(bound)s, valid=%(valid)s, fields=(%(fields)s)>\" %"
    ],
    [
        "\"\"\"Yield (name, bf) pairs, where bf is a BoundField object.\"\"\"",
        "\"\"\"Yield (name, bf) pairs, where bf is a"
    ],
    [
        "\"\"\"Yield the form's fields as BoundField objects.\"\"\"",
        "\"\"\"Yield the form's fields as BoundField"
    ],
    [
        "\"\"\"Return a BoundField with the given name.\"\"\"",
        "\"\"\"Return a BoundField with the"
    ],
    [
        "\"Key '%s' not found in '%s'. Choices are: %s.\"",
        "\"Key '%s' not found in '%s'."
    ],
    [
        "\"\"\"Return an ErrorDict for the data provided for the form.\"\"\"",
        "\"\"\"Return an ErrorDict for the"
    ],
    [
        "\"\"\"Return True if the form has no errors, or False otherwise.\"\"\"",
        "\"\"\"Return True if the form has no errors, or"
    ],
    [
        "Return the field name with a prefix appended, if this Form has a",
        "Return the field name with a prefix appended, if"
    ],
    [
        "return \"%s-%s\" % (self.prefix, field_name) if self.prefix else field_name",
        "return \"%s-%s\" % (self.prefix, field_name) if"
    ],
    [
        "\"\"\"Add an 'initial' prefix for checking dynamic initial values.\"\"\"",
        "\"\"\"Add an 'initial' prefix for checking dynamic initial"
    ],
    [
        "Return an ErrorList of errors that aren't associated with a particular",
        "Return an ErrorList of errors that aren't"
    ],
    [
        "field -- i.e., from Form.clean(). Return an empty ErrorList if there",
        "field -- i.e., from Form.clean(). Return an empty ErrorList if"
    ],
    [
        "The `field` argument is the name of the field to which the errors",
        "The `field` argument is the name of the"
    ],
    [
        "should be added. If it's None, treat the errors as NON_FIELD_ERRORS.",
        "should be added. If it's None, treat the errors"
    ],
    [
        "The `error` argument can be a single error, a list of errors, or a",
        "The `error` argument can be a single error, a list of"
    ],
    [
        "dictionary that maps field names to lists of errors. An \"error\" can be",
        "dictionary that maps field names to lists of errors. An"
    ],
    [
        "either a simple string or an instance of ValidationError with its",
        "either a simple string or an instance of ValidationError with"
    ],
    [
        "message attribute set and a \"list or dictionary\" can be an actual",
        "message attribute set and a \"list"
    ],
    [
        "`list` or `dict` or an instance of ValidationError with its",
        "`list` or `dict` or an instance of"
    ],
    [
        "If `error` is a dictionary, the `field` argument *must* be None and",
        "If `error` is a dictionary, the `field`"
    ],
    [
        "errors will be added to the fields that correspond to the keys of the",
        "errors will be added to the fields that correspond to the keys"
    ],
    [
        "\"The argument `field` must be `None` when the `error` \"",
        "\"The argument `field` must be `None` when the `error`"
    ],
    [
        "\"argument contains errors for multiple fields.\"",
        "\"argument contains errors for multiple"
    ],
    [
        "error = {field or NON_FIELD_ERRORS: error.error_list}",
        "error = {field or NON_FIELD_ERRORS:"
    ],
    [
        "if field != NON_FIELD_ERRORS and field not in self.fields:",
        "if field != NON_FIELD_ERRORS and"
    ],
    [
        "\"'%s' has no field named '%s'.\"",
        "\"'%s' has no"
    ],
    [
        "return field in self.errors and (",
        "return field in self.errors"
    ],
    [
        "or any(error.code == code for error in self.errors.as_data()[field])",
        "or any(error.code == code for error"
    ],
    [
        "Clean all of self.data and populate self._errors and self.cleaned_data.",
        "Clean all of self.data and populate"
    ],
    [
        "value = getattr(self, \"clean_%s\" % name)()",
        "value = getattr(self, \"clean_%s\" %"
    ],
    [
        "An internal hook for performing additional cleaning after form cleaning",
        "An internal hook for performing additional"
    ],
    [
        "is complete. Used for model validation in model forms.",
        "is complete. Used for model validation in model"
    ],
    [
        "Hook for doing any extra form-wide cleaning after Field.clean() has been",
        "Hook for doing any extra form-wide cleaning"
    ],
    [
        "called on every field. Any ValidationError raised by this method will",
        "called on every field. Any ValidationError raised by"
    ],
    [
        "not be associated with a particular field; it will have a special-case",
        "not be associated with a particular field; it will have"
    ],
    [
        "association with the field named '__all__'.",
        "association with the field"
    ],
    [
        "\"\"\"Return True if data differs from initial.\"\"\"",
        "\"\"\"Return True if data differs"
    ],
    [
        "return [name for name, bf in self._bound_items() if bf._has_changed()]",
        "return [name for name, bf in self._bound_items()"
    ],
    [
        "\"\"\"Return all media required to render the widgets on this form.\"\"\"",
        "\"\"\"Return all media required to render the widgets on"
    ],
    [
        "Return True if the form needs to be multipart-encoded, i.e. it has",
        "Return True if the form needs to be multipart-encoded,"
    ],
    [
        "return any(field.widget.needs_multipart_form for field in self.fields.values())",
        "return any(field.widget.needs_multipart_form for"
    ],
    [
        "Return a list of all the BoundField objects that are hidden fields.",
        "Return a list of all the BoundField objects that are"
    ],
    [
        "Useful for manual form layout in templates.",
        "Useful for manual form layout"
    ],
    [
        "return [field for field in self if field.is_hidden]",
        "return [field for field"
    ],
    [
        "Return a list of BoundField objects that aren't hidden fields.",
        "Return a list of BoundField objects"
    ],
    [
        "The opposite of the hidden_fields() method.",
        "The opposite of the hidden_fields()"
    ],
    [
        "return [field for field in self if not field.is_hidden]",
        "return [field for field in self if not"
    ],
    [
        "Return initial data for field on form. Use initial data from the form",
        "Return initial data for field on form."
    ],
    [
        "or the field, in that order. Evaluate callable values.",
        "or the field, in that order. Evaluate"
    ],
    [
        "\"A collection of Fields, plus their associated data.\"",
        "\"A collection of Fields, plus their"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "Convert a dictionary of attributes to a single string.",
        "Convert a dictionary of attributes"
    ],
    [
        "The returned string will contain a leading space followed by key=\"value\",",
        "The returned string will contain a"
    ],
    [
        "XML-style pairs. In the case of a boolean value, the key will appear",
        "XML-style pairs. In the case of a boolean value, the"
    ],
    [
        "without a value. It is assumed that the keys do not need to be",
        "without a value. It is assumed that the keys do not need to"
    ],
    [
        "XML-escaped. If the passed dictionary is empty, then return an empty",
        "XML-escaped. If the passed dictionary is empty, then"
    ],
    [
        "The result is passed through 'mark_safe' (by way of 'format_html_join').",
        "The result is passed through 'mark_safe' (by"
    ],
    [
        "return format_html_join(\"\", ' {}=\"{}\"', sorted(key_value_attrs)) + format_html_join(",
        "return format_html_join(\"\", ' {}=\"{}\"',"
    ],
    [
        "\"Subclasses of RenderableMixin must provide a get_context() method.\"",
        "\"Subclasses of RenderableMixin must provide a"
    ],
    [
        "\"Subclasses of RenderableFieldMixin must provide an as_hidden() method.\"",
        "\"Subclasses of RenderableFieldMixin must provide an as_hidden()"
    ],
    [
        "\"Subclasses of RenderableFieldMixin must provide an as_widget() method.\"",
        "\"Subclasses of RenderableFieldMixin must provide an as_widget()"
    ],
    [
        "\"\"\"Render this field as an HTML widget.\"\"\"",
        "\"\"\"Render this field as an"
    ],
    [
        "\"\"\"Render as <tr> elements excluding the surrounding <table> tag.\"\"\"",
        "\"\"\"Render as <tr> elements excluding the"
    ],
    [
        "\"\"\"Render as <li> elements excluding the surrounding <ul> tag.\"\"\"",
        "\"\"\"Render as <li> elements excluding the surrounding"
    ],
    [
        "A collection of errors that knows how to display itself in various formats.",
        "A collection of errors that knows how to display itself in various"
    ],
    [
        "The dictionary keys are the field names, and the values are the errors.",
        "The dictionary keys are the field names, and the values are the"
    ],
    [
        "return {f: e.as_data() for f, e in self.items()}",
        "return {f: e.as_data() for f, e in"
    ],
    [
        "return {f: e.get_json_data(escape_html) for f, e in self.items()}",
        "return {f: e.get_json_data(escape_html) for f,"
    ],
    [
        "A collection of errors that knows how to display itself in various formats.",
        "A collection of errors that knows how to"
    ],
    [
        "def __init__(self, initlist=None, error_class=None, renderer=None, field_id=None):",
        "def __init__(self, initlist=None,"
    ],
    [
        "\"message\": escape(message) if escape_html else message,",
        "\"message\": escape(message) if escape_html else"
    ],
    [
        "When time zone support is enabled, convert naive datetimes",
        "When time zone support is enabled,"
    ],
    [
        "entered in the current time zone to aware datetimes.",
        "entered in the current time zone to aware"
    ],
    [
        "if settings.USE_TZ and value is not None and timezone.is_naive(value):",
        "if settings.USE_TZ and value is not None and"
    ],
    [
        "\"in time zone %(current_timezone)s; it \"",
        "\"in time zone %(current_timezone)s; it"
    ],
    [
        "\"may be ambiguous or it may not exist.\"",
        "\"may be ambiguous or it"
    ],
    [
        "When time zone support is enabled, convert aware datetimes",
        "When time zone support is enabled, convert"
    ],
    [
        "to naive datetimes in the current time zone for display.",
        "to naive datetimes in the current time zone"
    ],
    [
        "if settings.USE_TZ and value is not None and timezone.is_aware(value):",
        "if settings.USE_TZ and value is not None"
    ],
    [
        "Functions for creating and restoring url-safe signed JSON objects.",
        "Functions for creating and restoring"
    ],
    [
        "The format used looks like this:",
        "The format used looks"
    ],
    [
        "There are two components here, separated by a ':'. The first component is a",
        "There are two components here, separated by"
    ],
    [
        "signing.loads(s) checks the signature and returns the deserialized object.",
        "signing.loads(s) checks the signature and returns"
    ],
    [
        "If the signature fails, a BadSignature exception is raised.",
        "If the signature fails, a"
    ],
    [
        "space, using the compress=True argument. This checks if compression actually",
        "space, using the compress=True argument. This"
    ],
    [
        "helps and only applies compression if the result is a shorter string:",
        "helps and only applies compression if the result is a shorter"
    ],
    [
        "The fact that the string is compressed is signalled by the prefixed '.' at the",
        "The fact that the string is compressed is signalled by the prefixed '.'"
    ],
    [
        "These functions make use of all of them.",
        "These functions make use of all"
    ],
    [
        "\"\"\"Signature timestamp is older than required max_age.\"\"\"",
        "\"\"\"Signature timestamp is older than required"
    ],
    [
        "Simple wrapper around json to be used in signing.dumps and",
        "Simple wrapper around json to"
    ],
    [
        "None, use settings.SECRET_KEY instead. The hmac algorithm is the default",
        "None, use settings.SECRET_KEY instead. The hmac algorithm"
    ],
    [
        "If compress is True (not the default), check if compressing using zlib can",
        "If compress is True (not the default), check if compressing using zlib"
    ],
    [
        "save some space. Prepend a '.' to signify compression. This is included",
        "save some space. Prepend a '.' to signify"
    ],
    [
        "in the signature, to protect against zip bombs.",
        "in the signature, to protect against"
    ],
    [
        "Salt can be used to namespace the hash, so that a signed string is",
        "Salt can be used to namespace the hash, so that a signed"
    ],
    [
        "only valid for a given namespace. Leaving this at the default",
        "only valid for a given namespace."
    ],
    [
        "value or re-using a salt value across different parts of your",
        "value or re-using a salt value across different"
    ],
    [
        "application without good cause is a security risk.",
        "application without good cause"
    ],
    [
        "The serializer is expected to return a bytestring.",
        "The serializer is expected to return a"
    ],
    [
        "Reverse of dumps(), raise BadSignature if signature fails.",
        "Reverse of dumps(), raise BadSignature"
    ],
    [
        "The serializer is expected to accept a bytestring.",
        "The serializer is expected to accept"
    ],
    [
        "self, *, key=None, sep=\":\", salt=None, algorithm=None, fallback_keys=None",
        "self, *, key=None, sep=\":\", salt=None,"
    ],
    [
        "self.salt = salt or \"%s.%s\" % (",
        "self.salt = salt or"
    ],
    [
        "\"Unsafe Signer separator: %r (cannot be empty or consist of \"",
        "\"Unsafe Signer separator: %r (cannot be"
    ],
    [
        "return \"%s%s%s\" % (value, self.sep, self.signature(value))",
        "return \"%s%s%s\" % (value,"
    ],
    [
        "raise BadSignature('No \"%s\" found in value' % self.sep)",
        "raise BadSignature('No \"%s\" found"
    ],
    [
        "raise BadSignature('Signature \"%s\" does not match' % sig)",
        "raise BadSignature('Signature \"%s\" does not match' %"
    ],
    [
        "If compress is True (not the default), check if compressing using zlib",
        "If compress is True (not the"
    ],
    [
        "can save some space. Prepend a '.' to signify compression. This is",
        "can save some space. Prepend a"
    ],
    [
        "included in the signature, to protect against zip bombs.",
        "included in the signature, to protect against zip"
    ],
    [
        "The serializer is expected to return a bytestring.",
        "The serializer is expected"
    ],
    [
        "value = \"%s%s%s\" % (value, self.sep, self.timestamp())",
        "value = \"%s%s%s\" %"
    ],
    [
        "Retrieve original value and check it wasn't signed more",
        "Retrieve original value and check it"
    ],
    [
        "raise SignatureExpired(\"Signature age %s > %s seconds\" % (age, max_age))",
        "raise SignatureExpired(\"Signature age %s > %s"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "EMPTY_VALUES = (None, \"\", [], (), {})",
        "EMPTY_VALUES = (None, \"\", [], (),"
    ],
    [
        "message = _(\"Enter a valid value.\")",
        "message = _(\"Enter a"
    ],
    [
        "self, regex=None, message=None, code=None, inverse_match=None, flags=None",
        "self, regex=None, message=None,"
    ],
    [
        "if self.flags and not isinstance(self.regex, str):",
        "if self.flags and not isinstance(self.regex,"
    ],
    [
        "\"If the flags are set, regex must be a regular expression string.\"",
        "\"If the flags are set, regex must be a"
    ],
    [
        "Validate that the input contains (or does *not* contain, if",
        "Validate that the input contains (or does"
    ],
    [
        "inverse_match is True) a match for the regular expression.",
        "inverse_match is True) a match"
    ],
    [
        "invalid_input = regex_matches if self.inverse_match else not regex_matches",
        "invalid_input = regex_matches if self.inverse_match else not"
    ],
    [
        "message = _(\"Enter a valid domain name.\")",
        "message = _(\"Enter a valid"
    ],
    [
        "r\"^\" + self.hostname_re + self.domain_re + self.tld_re + r\"$\",",
        "r\"^\" + self.hostname_re + self.domain_re"
    ],
    [
        "if not isinstance(value, str) or len(value) > self.max_length:",
        "if not isinstance(value, str) or"
    ],
    [
        "if not self.accept_idna and not value.isascii():",
        "if not self.accept_idna and"
    ],
    [
        "host_re = \"(\" + hostname_re + domain_re + tld_re + \"|localhost)\"",
        "host_re = \"(\" + hostname_re + domain_re +"
    ],
    [
        "message = _(\"Enter a valid URL.\")",
        "message = _(\"Enter a"
    ],
    [
        "schemes = [\"http\", \"https\", \"ftp\", \"ftps\"]",
        "schemes = [\"http\", \"https\", \"ftp\","
    ],
    [
        "if not isinstance(value, str) or len(value) > self.max_length:",
        "if not isinstance(value, str) or len(value) >"
    ],
    [
        "message = _(\"Enter a valid email address.\")",
        "message = _(\"Enter a valid"
    ],
    [
        "r\"^\" + hostname_re + domain_re + tld_no_fqdn_re + r\"\\Z\",",
        "r\"^\" + hostname_re + domain_re +"
    ],
    [
        "if domain_part not in self.domain_allowlist and not self.validate_domain_part(",
        "if domain_part not in self.domain_allowlist and"
    ],
    [
        "_(\"Enter a valid “slug” consisting of letters, numbers, underscores or hyphens.\"),",
        "_(\"Enter a valid “slug” consisting of letters,"
    ],
    [
        "\"Enter a valid “slug” consisting of Unicode letters, numbers, underscores, or \"",
        "\"Enter a valid “slug” consisting of Unicode"
    ],
    [
        "Depending on the given parameters, return the appropriate validators for",
        "Depending on the given parameters, return"
    ],
    [
        "\"The protocol '%s' is unknown. Supported: %s\"",
        "\"The protocol '%s' is"
    ],
    [
        "\"neg\": \"(-)?\" if allow_negative else \"\",",
        "\"neg\": \"(-)?\" if allow_negative"
    ],
    [
        "message=_(\"Enter only digits separated by commas.\"),",
        "message=_(\"Enter only digits separated by"
    ],
    [
        "message = _(\"Ensure this value is %(limit_value)s (it is %(show_value)s).\")",
        "message = _(\"Ensure this value"
    ],
    [
        "params = {\"limit_value\": limit_value, \"show_value\": cleaned, \"value\": value}",
        "params = {\"limit_value\": limit_value, \"show_value\":"
    ],
    [
        "message = _(\"Ensure this value is less than or equal to %(limit_value)s.\")",
        "message = _(\"Ensure this value is less"
    ],
    [
        "message = _(\"Ensure this value is greater than or equal to %(limit_value)s.\")",
        "message = _(\"Ensure this value is greater"
    ],
    [
        "message = _(\"Ensure this value is a multiple of step size %(limit_value)s.\")",
        "message = _(\"Ensure this value is a multiple of step"
    ],
    [
        "\"Ensure this value is a multiple of step size %(limit_value)s, \"",
        "\"Ensure this value is a multiple of"
    ],
    [
        "\"Ensure this value has at least %(limit_value)d character (it has \"",
        "\"Ensure this value has at least %(limit_value)d character (it"
    ],
    [
        "\"Ensure this value has at least %(limit_value)d characters (it has \"",
        "\"Ensure this value has at least"
    ],
    [
        "\"Ensure this value has at most %(limit_value)d character (it has \"",
        "\"Ensure this value has at most %(limit_value)d character (it has"
    ],
    [
        "\"Ensure this value has at most %(limit_value)d characters (it has \"",
        "\"Ensure this value has at most %(limit_value)d"
    ],
    [
        "Validate that the input does not exceed the maximum number of digits",
        "Validate that the input does not exceed the maximum number of"
    ],
    [
        "\"Ensure that there are no more than %(max)s digit in total.\",",
        "\"Ensure that there are no more"
    ],
    [
        "\"Ensure that there are no more than %(max)s digits in total.\",",
        "\"Ensure that there are no more than %(max)s digits in"
    ],
    [
        "\"Ensure that there are no more than %(max)s decimal place.\",",
        "\"Ensure that there are no more"
    ],
    [
        "\"Ensure that there are no more than %(max)s decimal places.\",",
        "\"Ensure that there are no more"
    ],
    [
        "\"Ensure that there are no more than %(max)s digit before the decimal \"",
        "\"Ensure that there are no more than %(max)s digit before the decimal"
    ],
    [
        "\"Ensure that there are no more than %(max)s digits before the decimal \"",
        "\"Ensure that there are no more than"
    ],
    [
        "if exponent in {\"F\", \"n\", \"N\"}:",
        "if exponent in {\"F\", \"n\","
    ],
    [
        "if self.max_digits is not None and digits > self.max_digits:",
        "if self.max_digits is not None and digits"
    ],
    [
        "if self.decimal_places is not None and decimals > self.decimal_places:",
        "if self.decimal_places is not None and decimals"
    ],
    [
        "and whole_digits > (self.max_digits - self.decimal_places)",
        "and whole_digits > (self.max_digits -"
    ],
    [
        "params={\"max\": (self.max_digits - self.decimal_places), \"value\": value},",
        "params={\"max\": (self.max_digits -"
    ],
    [
        "\"File extension “%(extension)s” is not allowed. \"",
        "\"File extension “%(extension)s” is"
    ],
    [
        "\"\"\"Validate that the string doesn't contain the null character.\"\"\"",
        "\"\"\"Validate that the string doesn't contain the"
    ],
    [
        "message = _(\"Null characters are not allowed.\")",
        "message = _(\"Null characters are"
    ],
    [
        "Avoids making django.core.handlers.ASGIHandler a public API, in case the",
        "Avoids making django.core.handlers.ASGIHandler a public API, in"
    ],
    [
        "internal implementation changes or moves in the future.",
        "internal implementation changes or"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"invalid_page\": _(\"That page number is not an integer\"),",
        "\"invalid_page\": _(\"That page number is not"
    ],
    [
        "\"no_results\": _(\"That page contains no results\"),",
        "\"no_results\": _(\"That page"
    ],
    [
        "if isinstance(number, float) and not number.is_integer():",
        "if isinstance(number, float)"
    ],
    [
        "Return a valid page, even if the page argument isn't a number or isn't",
        "Return a valid page, even if the page argument isn't a number or"
    ],
    [
        "if top + self.orphans >= self.count:",
        "if top + self.orphans"
    ],
    [
        "Return an instance of a single page.",
        "Return an instance of a single"
    ],
    [
        "This hook can be used by subclasses to use an alternative to the",
        "This hook can be used by subclasses to use an"
    ],
    [
        "\"\"\"Return the total number of objects, across all pages.\"\"\"",
        "\"\"\"Return the total number of objects,"
    ],
    [
        "if callable(c) and not inspect.isbuiltin(c) and method_has_no_args(c):",
        "if callable(c) and not"
    ],
    [
        "\"\"\"Return the total number of pages.\"\"\"",
        "\"\"\"Return the total"
    ],
    [
        "Warn if self.object_list is unordered (typically a QuerySet).",
        "Warn if self.object_list is unordered"
    ],
    [
        "if ordered is not None and not ordered:",
        "if ordered is not None and not"
    ],
    [
        "\"Pagination may yield inconsistent results with an unordered \"",
        "\"Pagination may yield inconsistent results with an unordered"
    ],
    [
        "If the page range is larger than a given size, the whole range is not",
        "If the page range is larger than a given size, the"
    ],
    [
        "provided and a compact form is returned instead, e.g. for a paginator",
        "provided and a compact form is returned instead, e.g. for a"
    ],
    [
        "return \"<Page %s of %s>\" % (self.number, self.paginator.num_pages)",
        "return \"<Page %s of %s>\" %"
    ],
    [
        "\"Page indices must be integers or slices, not %s.\"",
        "\"Page indices must be integers"
    ],
    [
        "relative to total objects in the paginator.",
        "relative to total objects in the"
    ],
    [
        "relative to total objects found (hits).",
        "relative to total"
    ],
    [
        "\"\"\"The requested model field does not exist\"\"\"",
        "\"\"\"The requested model field"
    ],
    [
        "\"\"\"The django.apps registry is not populated yet\"\"\"",
        "\"\"\"The django.apps registry is not populated"
    ],
    [
        "\"\"\"The requested object does not exist\"\"\"",
        "\"\"\"The requested object"
    ],
    [
        "\"\"\"The query returned multiple objects when only one was expected.\"\"\"",
        "\"\"\"The query returned multiple objects"
    ],
    [
        "\"\"\"Suspect MIME request in multipart form data\"\"\"",
        "\"\"\"Suspect MIME request in"
    ],
    [
        "\"\"\"A Suspicious filesystem operation was attempted\"\"\"",
        "\"\"\"A Suspicious filesystem operation"
    ],
    [
        "\"\"\"Redirect to scheme not in allowed list\"\"\"",
        "\"\"\"Redirect to scheme not"
    ],
    [
        "The number of fields in a GET or POST request exceeded",
        "The number of fields in a GET or POST request"
    ],
    [
        "The number of fields in a GET or POST request exceeded",
        "The number of fields in a"
    ],
    [
        "The size of the request (excluding any file uploads) exceeded",
        "The size of the request (excluding any file uploads)"
    ],
    [
        "\"\"\"The request was closed before it was completed, or timed out.\"\"\"",
        "\"\"\"The request was closed before it was completed, or"
    ],
    [
        "\"\"\"The request is malformed and cannot be processed.\"\"\"",
        "\"\"\"The request is malformed and cannot be"
    ],
    [
        "\"\"\"The user did not have permission to do that\"\"\"",
        "\"\"\"The user did not have permission to do"
    ],
    [
        "\"\"\"The requested view does not exist\"\"\"",
        "\"\"\"The requested view"
    ],
    [
        "\"\"\"This middleware is not used in this server configuration\"\"\"",
        "\"\"\"This middleware is not used in"
    ],
    [
        "\"\"\"Some kind of problem with a model field.\"\"\"",
        "\"\"\"Some kind of problem with a model"
    ],
    [
        "The `message` argument can be a single error, a list of errors, or a",
        "The `message` argument can be a single error, a list"
    ],
    [
        "dictionary that maps field names to lists of errors. What we define as",
        "dictionary that maps field names to lists of errors."
    ],
    [
        "an \"error\" can be either a simple string or an instance of",
        "an \"error\" can be either a simple string or an"
    ],
    [
        "ValidationError with its message attribute set, and what we define as",
        "ValidationError with its message attribute set, and"
    ],
    [
        "list or dictionary can be an actual `list` or `dict` or an instance",
        "list or dictionary can be an actual `list` or `dict`"
    ],
    [
        "of ValidationError with its `error_list` or `error_dict` attribute set.",
        "of ValidationError with its `error_list` or"
    ],
    [
        "message, code, params = message.message, message.code, message.params",
        "message, code, params ="
    ],
    [
        "\"\"\"A database query predicate is impossible.\"\"\"",
        "\"\"\"A database query predicate"
    ],
    [
        "\"\"\"A database query predicate is matches everything.\"\"\"",
        "\"\"\"A database query predicate is"
    ],
    [
        "\"\"\"The user tried to call a sync-only function from an async context.\"\"\"",
        "\"\"\"The user tried to call a sync-only function"
    ],
    [
        "The public interface to Django's WSGI support. Return a WSGI callable.",
        "The public interface to Django's WSGI support. Return"
    ],
    [
        "Avoids making django.core.handlers.WSGIHandler a public API, in case the",
        "Avoids making django.core.handlers.WSGIHandler a public API, in"
    ],
    [
        "internal WSGI implementation changes or moves in the future.",
        "internal WSGI implementation changes or moves in the"
    ],
    [
        "This package defines set of cache backends that all conform to a simple API.",
        "This package defines set of cache backends"
    ],
    [
        "In a nutshell, a cache is a set of values -- which can be any object that",
        "In a nutshell, a cache is a set of values -- which"
    ],
    [
        "may be pickled -- identified by string keys.  For the complete API, see",
        "may be pickled -- identified by string keys. For the"
    ],
    [
        "the abstract BaseCache class in django.core.cache.backends.base.",
        "the abstract BaseCache class in"
    ],
    [
        "Client code should use the `cache` variable defined here to access the default",
        "Client code should use the `cache` variable defined here"
    ],
    [
        "cache backend and look up non-default cache backends in the `caches` dict-like",
        "cache backend and look up non-default cache"
    ],
    [
        "See docs/topics/cache.txt for information on the public API.",
        "See docs/topics/cache.txt for information on the"
    ],
    [
        "\"Could not find backend '%s': %s\" % (backend, e)",
        "\"Could not find backend '%s': %s\" % (backend,"
    ],
    [
        "def __init__(self, server, params, library, value_not_found_exception):",
        "def __init__(self, server, params, library,"
    ],
    [
        "Implement transparent thread-safe access to a memcached client.",
        "Implement transparent thread-safe access to a memcached"
    ],
    [
        "way. Call this function to obtain a safe value for your timeout.",
        "way. Call this function to obtain a safe value"
    ],
    [
        "def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def add(self, key, value,"
    ],
    [
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def set(self, key,"
    ],
    [
        "self.make_and_validate_key(key, version=version): key for key in keys",
        "self.make_and_validate_key(key, version=version): key for key in"
    ],
    [
        "return {key_map[k]: v for k, v in ret.items()}",
        "return {key_map[k]: v for k,"
    ],
    [
        "raise ValueError(\"Key '%s' not found\" % key)",
        "raise ValueError(\"Key '%s' not"
    ],
    [
        "return [original_keys[k] for k in failed_keys]",
        "return [original_keys[k] for"
    ],
    [
        "keys = [self.make_and_validate_key(key, version=version) for key in keys]",
        "keys = [self.make_and_validate_key(key, version=version) for key in"
    ],
    [
        "\"An implementation of a cache binding using pylibmc\"",
        "\"An implementation of a cache binding"
    ],
    [
        "\"\"\"An implementation of a cache binding using pymemcache.\"\"\"",
        "\"\"\"An implementation of a cache"
    ],
    [
        "from django.db import DatabaseError, connections, models, router, transaction",
        "from django.db import DatabaseError,"
    ],
    [
        "from django.utils.timezone import now as tz_now",
        "from django.utils.timezone import"
    ],
    [
        "\"\"\"A class that will quack like a Django model _meta class.",
        "\"\"\"A class that will quack like a"
    ],
    [
        "This allows cache operations to be controlled by the router",
        "This allows cache operations to be"
    ],
    [
        "self.make_and_validate_key(key, version=version): key for key in keys",
        "self.make_and_validate_key(key, version=version): key for key"
    ],
    [
        "\"SELECT %s, %s, %s FROM %s WHERE %s IN (%s)\"",
        "\"SELECT %s, %s, %s FROM %s WHERE %s"
    ],
    [
        "for key, value, expires in rows:",
        "for key, value, expires in"
    ],
    [
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT,"
    ],
    [
        "def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def add(self, key,"
    ],
    [
        "def _base_set(self, mode, key, value, timeout=DEFAULT_TIMEOUT):",
        "def _base_set(self, mode, key, value,"
    ],
    [
        "cursor.execute(\"SELECT COUNT(*) FROM %s\" % table)",
        "cursor.execute(\"SELECT COUNT(*) FROM"
    ],
    [
        "tz = timezone.utc if settings.USE_TZ else None",
        "tz = timezone.utc if settings.USE_TZ else"
    ],
    [
        "\"SELECT %s, %s FROM %s WHERE %s = %%s\"",
        "\"SELECT %s, %s FROM %s WHERE %s ="
    ],
    [
        "if result and mode == \"touch\":",
        "if result and mode"
    ],
    [
        "\"UPDATE %s SET %s = %%s WHERE %s = %%s\"",
        "\"UPDATE %s SET %s = %%s"
    ],
    [
        "mode == \"set\" or (mode == \"add\" and current_expires < now)",
        "mode == \"set\" or (mode == \"add\" and"
    ],
    [
        "\"UPDATE %s SET %s = %%s, %s = %%s WHERE %s = %%s\"",
        "\"UPDATE %s SET %s = %%s, %s = %%s WHERE %s"
    ],
    [
        "\"INSERT INTO %s (%s, %s, %s) VALUES (%%s, %%s, %%s)\"",
        "\"INSERT INTO %s (%s, %s, %s) VALUES"
    ],
    [
        "keys = [self.make_and_validate_key(key, version=version) for key in keys]",
        "keys = [self.make_and_validate_key(key, version=version) for key"
    ],
    [
        "\"DELETE FROM %s WHERE %s IN (%s)\"",
        "\"DELETE FROM %s WHERE"
    ],
    [
        "\"SELECT %s FROM %s WHERE %s = %%s and %s > %%s\"",
        "\"SELECT %s FROM %s WHERE %s = %%s and"
    ],
    [
        "def _cull(self, db, cursor, now, num):",
        "def _cull(self, db, cursor, now,"
    ],
    [
        "\"DELETE FROM %s WHERE %s < %%s\"",
        "\"DELETE FROM %s WHERE %s <"
    ],
    [
        "\"DELETE FROM %s WHERE %s < %%s\"",
        "\"DELETE FROM %s WHERE %s"
    ],
    [
        "def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def add(self, key, value,"
    ],
    [
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT,"
    ],
    [
        "with open(self._key_to_file(key, version), \"r+b\") as f:",
        "with open(self._key_to_file(key, version), \"r+b\")"
    ],
    [
        "if not fname.startswith(self._dir) or not os.path.exists(fname):",
        "if not fname.startswith(self._dir) or"
    ],
    [
        "Remove random cache entries if max_entries is reached at a ratio",
        "Remove random cache entries if max_entries is reached"
    ],
    [
        "that the entire cache will be purged.",
        "that the entire cache will be"
    ],
    [
        "filelist = random.sample(filelist, int(num_entries / self._cull_frequency))",
        "filelist = random.sample(filelist, int(num_entries"
    ],
    [
        "Convert a key into a cache file path. Basically this is the",
        "Convert a key into a cache file path. Basically this"
    ],
    [
        "Take an open cache file `f` and delete it if it's expired.",
        "Take an open cache file `f`"
    ],
    [
        "if exp is not None and exp < time.time():",
        "if exp is not None"
    ],
    [
        "Get a list of paths to all the cache files. These are all the files",
        "Get a list of paths to all the cache files. These are"
    ],
    [
        "in the root cache dir that end on the cache_suffix.",
        "in the root cache dir"
    ],
    [
        "self.protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol",
        "self.protocol = pickle.HIGHEST_PROTOCOL if protocol"
    ],
    [
        "if ret := bool(client.set(key, value, nx=True)):",
        "if ret := bool(client.set(key, value,"
    ],
    [
        "return default if value is None else self._serializer.loads(value)",
        "return default if value is None"
    ],
    [
        "k: self._serializer.loads(v) for k, v in zip(keys, ret) if v is not None",
        "k: self._serializer.loads(v) for k, v in zip(keys, ret) if v is"
    ],
    [
        "raise ValueError(\"Key '%s' not found.\" % key)",
        "raise ValueError(\"Key '%s' not found.\" %"
    ],
    [
        "pipeline.mset({k: self._serializer.dumps(v) for k, v in data.items()})",
        "pipeline.mset({k: self._serializer.dumps(v) for k,"
    ],
    [
        "def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def add(self, key, value, timeout=DEFAULT_TIMEOUT,"
    ],
    [
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def set(self, key, value,"
    ],
    [
        "self.make_and_validate_key(key, version=version): key for key in keys",
        "self.make_and_validate_key(key, version=version): key for key"
    ],
    [
        "return {key_map[k]: v for k, v in ret.items()}",
        "return {key_map[k]: v for k, v in"
    ],
    [
        "safe_keys = [self.make_and_validate_key(key, version=version) for key in keys]",
        "safe_keys = [self.make_and_validate_key(key, version=version) for key in"
    ],
    [
        "def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def add(self, key, value,"
    ],
    [
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def set(self, key, value,"
    ],
    [
        "Construct the key used by all other methods. By default, prepend",
        "Construct the key used by all other methods. By default,"
    ],
    [
        "the `key_prefix`. KEY_FUNCTION can be used to specify an alternate",
        "the `key_prefix`. KEY_FUNCTION can be"
    ],
    [
        "function with custom key making behavior.",
        "function with custom key making"
    ],
    [
        "return \"%s:%s:%s\" % (key_prefix, version, key)",
        "return \"%s:%s:%s\" % (key_prefix,"
    ],
    [
        "Function to decide which key function to use.",
        "Function to decide which"
    ],
    [
        "Return the timeout value usable by this backend based upon the provided",
        "Return the timeout value usable by this backend based upon the"
    ],
    [
        "return None if timeout is None else time.time() + timeout",
        "return None if timeout is None else time.time() +"
    ],
    [
        "Construct the key used by all other methods. By default, use the",
        "Construct the key used by all other methods. By default,"
    ],
    [
        "key_func to generate a key (which, by default, prepends the",
        "key_func to generate a key (which, by default, prepends"
    ],
    [
        "`key_prefix' and 'version'). A different key function can be provided",
        "`key_prefix' and 'version'). A different key function"
    ],
    [
        "at the time of cache construction; alternatively, you can subclass the",
        "at the time of cache construction; alternatively, you can subclass"
    ],
    [
        "cache backend to provide custom key making behavior.",
        "cache backend to provide custom"
    ],
    [
        "Warn about keys that would not be portable to the memcached",
        "Warn about keys that would not be portable"
    ],
    [
        "backend. This encourages (but does not force) writing backend-portable",
        "backend. This encourages (but does not"
    ],
    [
        "\"\"\"Helper to make and validate keys.\"\"\"",
        "\"\"\"Helper to make"
    ],
    [
        "def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def add(self, key,"
    ],
    [
        "Set a value in the cache if the key does not already exist. If",
        "Set a value in the cache if the key"
    ],
    [
        "timeout is given, use that timeout for the key; otherwise use the",
        "timeout is given, use that timeout for the key;"
    ],
    [
        "Return True if the value was stored, False otherwise.",
        "Return True if the value was stored, False"
    ],
    [
        "\"subclasses of BaseCache must provide an add() method\"",
        "\"subclasses of BaseCache must"
    ],
    [
        "async def aadd(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "async def aadd(self, key, value,"
    ],
    [
        "Fetch a given key from the cache. If the key does not exist, return",
        "Fetch a given key from the cache."
    ],
    [
        "default, which itself defaults to None.",
        "default, which itself defaults to"
    ],
    [
        "raise NotImplementedError(\"subclasses of BaseCache must provide a get() method\")",
        "raise NotImplementedError(\"subclasses of BaseCache must provide a get()"
    ],
    [
        "async def aget(self, key, default=None, version=None):",
        "async def aget(self, key, default=None,"
    ],
    [
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def set(self, key,"
    ],
    [
        "Set a value in the cache. If timeout is given, use that timeout for the",
        "Set a value in the cache. If timeout is given, use that"
    ],
    [
        "key; otherwise use the default cache timeout.",
        "key; otherwise use the default"
    ],
    [
        "raise NotImplementedError(\"subclasses of BaseCache must provide a set() method\")",
        "raise NotImplementedError(\"subclasses of BaseCache must provide"
    ],
    [
        "async def aset(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "async def aset(self, key, value,"
    ],
    [
        "Update the key's expiry time using timeout. Return True if successful",
        "Update the key's expiry time using timeout. Return True"
    ],
    [
        "or False if the key does not exist.",
        "or False if the"
    ],
    [
        "\"subclasses of BaseCache must provide a touch() method\"",
        "\"subclasses of BaseCache must provide"
    ],
    [
        "async def atouch(self, key, timeout=DEFAULT_TIMEOUT, version=None):",
        "async def atouch(self, key,"
    ],
    [
        "Delete a key from the cache and return whether it succeeded, failing",
        "Delete a key from the cache and return"
    ],
    [
        "\"subclasses of BaseCache must provide a delete() method\"",
        "\"subclasses of BaseCache must provide a"
    ],
    [
        "Fetch a bunch of keys from the cache. For certain backends (memcached,",
        "Fetch a bunch of keys from the cache."
    ],
    [
        "pgsql) this can be *much* faster when fetching multiple values.",
        "pgsql) this can be *much*"
    ],
    [
        "Return a dict mapping each key in keys to its value. If the given",
        "Return a dict mapping each key in keys to its value."
    ],
    [
        "key is missing, it will be missing from the response dict.",
        "key is missing, it will be missing"
    ],
    [
        "val = await self.aget(k, self._missing_key, version=version)",
        "val = await self.aget(k,"
    ],
    [
        "def get_or_set(self, key, default, timeout=DEFAULT_TIMEOUT, version=None):",
        "def get_or_set(self, key,"
    ],
    [
        "Fetch a given key from the cache. If the key does not exist,",
        "Fetch a given key from the cache. If the key"
    ],
    [
        "add the key and set it to the default value. The default value can",
        "add the key and set it to the default value. The default"
    ],
    [
        "also be any callable. If timeout is given, use that timeout for the",
        "also be any callable. If timeout is given,"
    ],
    [
        "key; otherwise use the default cache timeout.",
        "key; otherwise use the default cache"
    ],
    [
        "Return the value of the key stored or retrieved.",
        "Return the value of the"
    ],
    [
        "async def aget_or_set(self, key, default, timeout=DEFAULT_TIMEOUT, version=None):",
        "async def aget_or_set(self, key, default,"
    ],
    [
        "val = await self.aget(key, self._missing_key, version=version)",
        "val = await self.aget(key,"
    ],
    [
        "Return True if the key is in the cache and has not expired.",
        "Return True if the key is in the cache and"
    ],
    [
        "self.get(key, self._missing_key, version=version) is not self._missing_key",
        "self.get(key, self._missing_key, version=version) is"
    ],
    [
        "Add delta to value in the cache. If the key does not exist, raise a",
        "Add delta to value in the cache. If the key does not exist,"
    ],
    [
        "raise ValueError(\"Key '%s' not found\" % key)",
        "raise ValueError(\"Key '%s' not"
    ],
    [
        "value = await self.aget(key, self._missing_key, version=version)",
        "value = await self.aget(key,"
    ],
    [
        "raise ValueError(\"Key '%s' not found\" % key)",
        "raise ValueError(\"Key '%s' not found\" %"
    ],
    [
        "Subtract delta from value in the cache. If the key does not exist, raise",
        "Subtract delta from value in the cache. If the key does"
    ],
    [
        "Return True if the key is in the cache and has not expired.",
        "Return True if the key is in the"
    ],
    [
        "Set a bunch of values in the cache at once from a dict of key/value",
        "Set a bunch of values in the cache at once"
    ],
    [
        "pairs.  For certain backends (memcached), this is much more efficient",
        "pairs. For certain backends (memcached), this is much"
    ],
    [
        "If timeout is given, use that timeout for the key; otherwise use the",
        "If timeout is given, use that timeout for the key;"
    ],
    [
        "On backends that support it, return a list of keys that failed",
        "On backends that support it, return a list of keys"
    ],
    [
        "insertion, or an empty list if all keys were inserted successfully.",
        "insertion, or an empty list if"
    ],
    [
        "async def aset_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):",
        "async def aset_many(self, data, timeout=DEFAULT_TIMEOUT,"
    ],
    [
        "Delete a bunch of values in the cache at once. For certain backends",
        "Delete a bunch of values in the cache at once. For"
    ],
    [
        "(memcached), this is much more efficient than calling delete() multiple",
        "(memcached), this is much more efficient than"
    ],
    [
        "\"\"\"Remove *all* values from the cache at once.\"\"\"",
        "\"\"\"Remove *all* values from the cache"
    ],
    [
        "\"subclasses of BaseCache must provide a clear() method\"",
        "\"subclasses of BaseCache must"
    ],
    [
        "Add delta to the cache version for the supplied key. Return the new",
        "Add delta to the cache version for"
    ],
    [
        "raise ValueError(\"Key '%s' not found\" % key)",
        "raise ValueError(\"Key '%s' not found\""
    ],
    [
        "value = await self.aget(key, self._missing_key, version=version)",
        "value = await self.aget(key, self._missing_key,"
    ],
    [
        "raise ValueError(\"Key '%s' not found\" % key)",
        "raise ValueError(\"Key '%s' not found\" %"
    ],
    [
        "await self.aset(key, value, version=version + delta)",
        "await self.aset(key, value, version=version"
    ],
    [
        "Subtract delta from the cache version for the supplied key. Return the",
        "Subtract delta from the cache version for"
    ],
    [
        "\"Cache key will cause errors if used with memcached: %r \"",
        "\"Cache key will cause errors if used with memcached: %r"
    ],
    [
        "\"(longer than %s)\" % (key, MEMCACHE_MAX_KEY_LENGTH)",
        "\"(longer than %s)\" % (key,"
    ],
    [
        "\"Cache key contains characters that will cause errors if used with \"",
        "\"Cache key contains characters that will cause errors"
    ],
    [
        "def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def add(self, key, value,"
    ],
    [
        "def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
        "def set(self, key,"
    ],
    [
        "raise ValueError(\"Key '%s' not found\" % key)",
        "raise ValueError(\"Key '%s' not found\" %"
    ],
    [
        "return exp is not None and exp <= time.time()",
        "return exp is not None and"
    ],
    [
        "\"\"\"Load an email backend and return an instance of it.",
        "\"\"\"Load an email backend and return an"
    ],
    [
        "If backend is None (default), use settings.EMAIL_BACKEND.",
        "If backend is None"
    ],
    [
        "Both fail_silently and other keyword arguments are used in the",
        "Both fail_silently and other keyword"
    ],
    [
        "Easy wrapper for sending a single message to a recipient list. All members",
        "Easy wrapper for sending a single message"
    ],
    [
        "of the recipient list will see the other recipients in the 'To' field.",
        "of the recipient list will see the"
    ],
    [
        "If from_email is None, use the DEFAULT_FROM_EMAIL setting.",
        "If from_email is None, use the DEFAULT_FROM_EMAIL"
    ],
    [
        "If auth_user is None, use the EMAIL_HOST_USER setting.",
        "If auth_user is None, use the"
    ],
    [
        "If auth_password is None, use the EMAIL_HOST_PASSWORD setting.",
        "If auth_password is None,"
    ],
    [
        "Note: The API for this method is frozen. New code wanting to extend the",
        "Note: The API for this method is frozen. New"
    ],
    [
        "functionality should use the EmailMessage class directly.",
        "functionality should use the EmailMessage"
    ],
    [
        "Given a datatuple of (subject, message, from_email, recipient_list), send",
        "Given a datatuple of (subject,"
    ],
    [
        "each message to each recipient list. Return the number of emails sent.",
        "each message to each recipient list. Return the number of emails"
    ],
    [
        "If from_email is None, use the DEFAULT_FROM_EMAIL setting.",
        "If from_email is None, use"
    ],
    [
        "If auth_user and auth_password are set, use them to log in.",
        "If auth_user and auth_password are set, use"
    ],
    [
        "If auth_user is None, use the EMAIL_HOST_USER setting.",
        "If auth_user is None, use the EMAIL_HOST_USER"
    ],
    [
        "If auth_password is None, use the EMAIL_HOST_PASSWORD setting.",
        "If auth_password is None, use"
    ],
    [
        "Note: The API for this method is frozen. New code wanting to extend the",
        "Note: The API for this method is frozen. New code wanting"
    ],
    [
        "functionality should use the EmailMessage class directly.",
        "functionality should use the EmailMessage"
    ],
    [
        "for subject, message, sender, recipient in datatuple",
        "for subject, message, sender, recipient in"
    ],
    [
        "\"\"\"Send a message to the admins, as defined by the ADMINS setting.\"\"\"",
        "\"\"\"Send a message to the admins, as"
    ],
    [
        "\"\"\"Send a message to the managers, as defined by the MANAGERS setting.\"\"\"",
        "\"\"\"Send a message to the managers, as defined by the"
    ],
    [
        "from email import charset as Charset",
        "from email import charset as"
    ],
    [
        "from email import encoders as Encoders",
        "from email import encoders as"
    ],
    [
        "from email.utils import formataddr, formatdate, getaddresses, make_msgid",
        "from email.utils import formataddr, formatdate,"
    ],
    [
        "from django.utils.encoding import force_bytes, force_str, punycode",
        "from django.utils.encoding import force_bytes,"
    ],
    [
        "\"\"\"Forbid multi-line headers to prevent header injection.\"\"\"",
        "\"\"\"Forbid multi-line headers to prevent"
    ],
    [
        "if \"\\n\" in val or \"\\r\" in val:",
        "if \"\\n\" in val or \"\\r\" in"
    ],
    [
        "\"Header values can't contain newlines (got %r for header %r)\" % (val, name)",
        "\"Header values can't contain newlines (got %r for header"
    ],
    [
        "sanitize_address(addr, encoding) for addr in getaddresses((val,))",
        "sanitize_address(addr, encoding) for"
    ],
    [
        "Format a pair of (name, address) or an email address string.",
        "Format a pair of (name, address) or an email address"
    ],
    [
        "raise ValueError('Invalid address \"%s\"' % addr)",
        "raise ValueError('Invalid address"
    ],
    [
        "'Invalid address; only %s could be parsed from \"%s\"' % (token, addr)",
        "'Invalid address; only %s could be parsed from \"%s\"' % (token,"
    ],
    [
        "address_parts = nm + localpart + domain",
        "address_parts = nm +"
    ],
    [
        "if \"\\n\" in address_parts or \"\\r\" in address_parts:",
        "if \"\\n\" in address_parts or \"\\r\""
    ],
    [
        "raise ValueError(\"Invalid address; address parts cannot contain newlines.\")",
        "raise ValueError(\"Invalid address; address parts cannot"
    ],
    [
        "\"\"\"Return the entire formatted message as a string.",
        "\"\"\"Return the entire formatted message as a"
    ],
    [
        "Optional `unixfrom' when True, means include the Unix From_ envelope",
        "Optional `unixfrom' when True, means include"
    ],
    [
        "This overrides the default as_string() implementation to not mangle",
        "This overrides the default as_string() implementation"
    ],
    [
        "\"\"\"Return the entire formatted message as bytes.",
        "\"\"\"Return the entire formatted message as"
    ],
    [
        "Optional `unixfrom' when True, means include the Unix From_ envelope",
        "Optional `unixfrom' when True, means include the"
    ],
    [
        "This overrides the default as_bytes() implementation to not mangle",
        "This overrides the default as_bytes()"
    ],
    [
        "name, val = forbid_multi_line_headers(name, val, \"ascii\")",
        "name, val = forbid_multi_line_headers(name,"
    ],
    [
        "name, val = forbid_multi_line_headers(name, val, self.encoding)",
        "name, val = forbid_multi_line_headers(name,"
    ],
    [
        "self, _subtype=\"mixed\", boundary=None, _subparts=None, encoding=None, **_params",
        "self, _subtype=\"mixed\", boundary=None,"
    ],
    [
        "name, val = forbid_multi_line_headers(name, val, self.encoding)",
        "name, val = forbid_multi_line_headers(name,"
    ],
    [
        "EmailAttachment = namedtuple(\"Attachment\", [\"filename\", \"content\", \"mimetype\"])",
        "EmailAttachment = namedtuple(\"Attachment\","
    ],
    [
        "Initialize a single email message (which can be sent to multiple",
        "Initialize a single email message (which can be sent to"
    ],
    [
        "raise TypeError('\"to\" argument must be a list or tuple')",
        "raise TypeError('\"to\" argument must be a"
    ],
    [
        "raise TypeError('\"cc\" argument must be a list or tuple')",
        "raise TypeError('\"cc\" argument must be"
    ],
    [
        "raise TypeError('\"bcc\" argument must be a list or tuple')",
        "raise TypeError('\"bcc\" argument must be a list or"
    ],
    [
        "raise TypeError('\"reply_to\" argument must be a list or tuple')",
        "raise TypeError('\"reply_to\" argument must be a"
    ],
    [
        "header_names = [key.lower() for key in self.extra_headers]",
        "header_names = [key.lower() for key in"
    ],
    [
        "if name.lower() not in {\"from\", \"to\", \"cc\", \"reply-to\"}:",
        "if name.lower() not in"
    ],
    [
        "Return a list of all recipients of the email (includes direct",
        "Return a list of all recipients of the email"
    ],
    [
        "addressees as well as Cc and Bcc entries).",
        "addressees as well as Cc and Bcc"
    ],
    [
        "return [email for email in (self.to + self.cc + self.bcc) if email]",
        "return [email for email in (self.to +"
    ],
    [
        "Attach a file with the given filename and content. The filename can",
        "Attach a file with the given filename and content. The filename"
    ],
    [
        "be omitted and the mimetype is guessed, if not provided.",
        "be omitted and the mimetype is guessed, if"
    ],
    [
        "If the first parameter is a MIMEBase subclass, insert it directly",
        "If the first parameter is a MIMEBase subclass, insert"
    ],
    [
        "For a text/* mimetype (guessed or specified), when a bytes object is",
        "For a text/* mimetype (guessed or specified), when a bytes object"
    ],
    [
        "mimetype to DEFAULT_ATTACHMENT_MIME_TYPE and don't decode the content.",
        "mimetype to DEFAULT_ATTACHMENT_MIME_TYPE and don't"
    ],
    [
        "if content is not None or mimetype is not None:",
        "if content is not None or mimetype is not"
    ],
    [
        "\"content and mimetype must not be given when a MIMEBase \"",
        "\"content and mimetype must not be"
    ],
    [
        "Attach a file from the filesystem.",
        "Attach a file from"
    ],
    [
        "Set the mimetype to DEFAULT_ATTACHMENT_MIME_TYPE if it isn't specified",
        "Set the mimetype to DEFAULT_ATTACHMENT_MIME_TYPE if it isn't"
    ],
    [
        "For a text/* mimetype (guessed or specified), decode the file's content",
        "For a text/* mimetype (guessed or specified), decode"
    ],
    [
        "DEFAULT_ATTACHMENT_MIME_TYPE and don't decode the content.",
        "DEFAULT_ATTACHMENT_MIME_TYPE and don't"
    ],
    [
        "Convert the content, mimetype pair into a MIME attachment object.",
        "Convert the content, mimetype pair into a MIME attachment"
    ],
    [
        "email.Message or EmailMessage object, as well as a str.",
        "email.Message or EmailMessage object, as well as a"
    ],
    [
        "Convert the filename, content, mimetype triple into a MIME attachment",
        "Convert the filename, content, mimetype triple"
    ],
    [
        "Set msg's header, either from self.extra_headers, if present, or from",
        "Set msg's header, either from self.extra_headers,"
    ],
    [
        "the values argument if not empty.",
        "the values argument if"
    ],
    [
        "msg[header] = \", \".join(str(v) for v in values)",
        "msg[header] = \", \".join(str(v) for v"
    ],
    [
        "A version of EmailMessage that makes it easy to send multipart/alternative",
        "A version of EmailMessage that makes it easy to"
    ],
    [
        "messages. For example, including text and HTML versions of the text is",
        "messages. For example, including text and HTML versions of the text"
    ],
    [
        "Initialize a single email message (which can be sent to multiple",
        "Initialize a single email message (which can be"
    ],
    [
        "EmailAlternative(*alternative) for alternative in (alternatives or [])",
        "EmailAlternative(*alternative) for alternative in (alternatives or"
    ],
    [
        "if content is None or mimetype is None:",
        "if content is None"
    ],
    [
        "raise ValueError(\"Both content and mimetype must be provided.\")",
        "raise ValueError(\"Both content and mimetype"
    ],
    [
        "Checks that ``text`` occurs in the email body and in all attached MIME",
        "Checks that ``text`` occurs in the email body and in"
    ],
    [
        "if mimetype.startswith(\"text/\") and text not in content:",
        "if mimetype.startswith(\"text/\") and text"
    ],
    [
        "Email message and email sending related helper functions.",
        "Email message and email"
    ],
    [
        "Email backend that writes messages to console instead of sending them.",
        "Email backend that writes messages to console"
    ],
    [
        "\"\"\"Write all messages to the stream in a thread-safe way.\"\"\"",
        "\"\"\"Write all messages to the stream in"
    ],
    [
        "\"\"\"Email backend that writes messages to a file.\"\"\"",
        "\"\"\"Email backend that writes"
    ],
    [
        "from django.core.mail.backends.console import EmailBackend as ConsoleEmailBackend",
        "from django.core.mail.backends.console import"
    ],
    [
        "\"Path for saving email messages exists, but is not a directory: %s\"",
        "\"Path for saving email messages exists, but is not"
    ],
    [
        "\"Could not create directory for saving email messages: %s (%s)\"",
        "\"Could not create directory for saving email messages:"
    ],
    [
        "\"Could not write to directory: %s\" % self.file_path",
        "\"Could not write to"
    ],
    [
        "fname = \"%s-%s.log\" % (timestamp, abs(id(self)))",
        "fname = \"%s-%s.log\" %"
    ],
    [
        "A wrapper that manages the SMTP network connection.",
        "A wrapper that manages the SMTP"
    ],
    [
        "self.username = settings.EMAIL_HOST_USER if username is None else username",
        "self.username = settings.EMAIL_HOST_USER if username is"
    ],
    [
        "self.password = settings.EMAIL_HOST_PASSWORD if password is None else password",
        "self.password = settings.EMAIL_HOST_PASSWORD if password is None else"
    ],
    [
        "self.use_tls = settings.EMAIL_USE_TLS if use_tls is None else use_tls",
        "self.use_tls = settings.EMAIL_USE_TLS if use_tls is None"
    ],
    [
        "self.use_ssl = settings.EMAIL_USE_SSL if use_ssl is None else use_ssl",
        "self.use_ssl = settings.EMAIL_USE_SSL if use_ssl"
    ],
    [
        "self.timeout = settings.EMAIL_TIMEOUT if timeout is None else timeout",
        "self.timeout = settings.EMAIL_TIMEOUT if timeout"
    ],
    [
        "settings.EMAIL_SSL_KEYFILE if ssl_keyfile is None else ssl_keyfile",
        "settings.EMAIL_SSL_KEYFILE if ssl_keyfile is"
    ],
    [
        "settings.EMAIL_SSL_CERTFILE if ssl_certfile is None else ssl_certfile",
        "settings.EMAIL_SSL_CERTFILE if ssl_certfile is None"
    ],
    [
        "\"EMAIL_USE_TLS/EMAIL_USE_SSL are mutually exclusive, so only set \"",
        "\"EMAIL_USE_TLS/EMAIL_USE_SSL are mutually exclusive, so"
    ],
    [
        "\"one of those settings to True.\"",
        "\"one of those settings to"
    ],
    [
        "return smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP",
        "return smtplib.SMTP_SSL if self.use_ssl else"
    ],
    [
        "Ensure an open connection to the email server. Return whether or not a",
        "Ensure an open connection to the email server. Return whether"
    ],
    [
        "new connection was required (True or False) or None if an exception",
        "new connection was required (True or"
    ],
    [
        "\"\"\"Close the connection to the email server.\"\"\"",
        "\"\"\"Close the connection to"
    ],
    [
        "Send one or more EmailMessage objects and return the number of email",
        "Send one or more EmailMessage objects"
    ],
    [
        "if not self.connection or new_conn_created is None:",
        "if not self.connection or new_conn_created"
    ],
    [
        "\"\"\"A helper method that does the actual sending.\"\"\"",
        "\"\"\"A helper method that"
    ],
    [
        "sanitize_address(addr, encoding) for addr in email_message.recipients()",
        "sanitize_address(addr, encoding) for addr"
    ],
    [
        "Dummy email backend that does nothing.",
        "Dummy email backend"
    ],
    [
        "Base class for email backend implementations.",
        "Base class for"
    ],
    [
        "Subclasses must at least overwrite send_messages().",
        "Subclasses must at least overwrite"
    ],
    [
        "open() and close() can be called indirectly by using a backend object as a",
        "open() and close() can be called indirectly"
    ],
    [
        "This method can be overwritten by backend implementations to",
        "This method can be overwritten by"
    ],
    [
        "It's up to the backend implementation to track the status of",
        "It's up to the backend implementation"
    ],
    [
        "a network connection if it's needed by the backend.",
        "a network connection if it's"
    ],
    [
        "This method can be called by applications to force a single",
        "This method can be called by"
    ],
    [
        "network connection to be used when sending mails. See the",
        "network connection to be used when sending mails. See"
    ],
    [
        "send_messages() method of the SMTP backend for a reference",
        "send_messages() method of the SMTP backend for"
    ],
    [
        "Send one or more EmailMessage objects and return the number of email",
        "Send one or more EmailMessage objects and return"
    ],
    [
        "\"subclasses of BaseEmailBackend must override send_messages() method\"",
        "\"subclasses of BaseEmailBackend must override"
    ],
    [
        "An email backend for use during test sessions.",
        "An email backend for use"
    ],
    [
        "The test connection stores email messages in a dummy outbox,",
        "The test connection stores email messages"
    ],
    [
        "rather than sending them out on the wire.",
        "rather than sending them out on"
    ],
    [
        "The dummy outbox is accessible through the outbox instance attribute.",
        "The dummy outbox is accessible"
    ],
    [
        "\"\"\"Redirect messages to the dummy outbox\"\"\"",
        "\"\"\"Redirect messages to the"
    ],
    [
        "from . import Error, Tags, register",
        "from . import"
    ],
    [
        "f\"The FILE_UPLOAD_TEMP_DIR setting refers to the nonexistent \"",
        "f\"The FILE_UPLOAD_TEMP_DIR setting refers to"
    ],
    [
        "from . import Error, Tags, Warning, register",
        "from . import Error, Tags, Warning,"
    ],
    [
        "\"You must define a '%s' cache in your CACHES setting.\" % DEFAULT_CACHE_ALIAS,",
        "\"You must define a '%s' cache in your CACHES setting.\" %"
    ],
    [
        "for name in (\"MEDIA_ROOT\", \"STATIC_ROOT\", \"STATICFILES_DIRS\"):",
        "for name in (\"MEDIA_ROOT\", \"STATIC_ROOT\","
    ],
    [
        "if any(path == cache_path for path in paths):",
        "if any(path == cache_path"
    ],
    [
        "elif any(path in cache_path.parents for path in paths):",
        "elif any(path in cache_path.parents for"
    ],
    [
        "elif any(cache_path in path.parents for path in paths):",
        "elif any(cache_path in path.parents for"
    ],
    [
        "f\"Your '{alias}' cache configuration might expose your cache \"",
        "f\"Your '{alias}' cache configuration might expose"
    ],
    [
        "f\"or lead to corruption of your data because its LOCATION \"",
        "f\"or lead to corruption of your"
    ],
    [
        "f\"Your '{alias}' cache LOCATION path is relative. Use an \"",
        "f\"Your '{alias}' cache LOCATION path is"
    ],
    [
        "Can be used as a function or a decorator. Register given function",
        "Can be used as a function or"
    ],
    [
        "`f` labeled with given `tags`. The function should receive **kwargs",
        "`f` labeled with given `tags`."
    ],
    [
        "and return list of Errors and Warnings.",
        "and return list of"
    ],
    [
        "\"Check functions must accept keyword arguments (**kwargs).\"",
        "\"Check functions must accept keyword"
    ],
    [
        "Run all registered checks and return list of Errors and Warnings.",
        "Run all registered checks and return list of Errors"
    ],
    [
        "checks = [check for check in checks if not set(check.tags).isdisjoint(tags)]",
        "checks = [check for check in checks if not"
    ],
    [
        "\"The function %r did not return a list. All functions \"",
        "\"The function %r did not return a list."
    ],
    [
        "\"registered with the checks registry must return a list.\" % check,",
        "\"registered with the checks registry must return"
    ],
    [
        "from django.core.checks import Error, Tags, Warning, register",
        "from django.core.checks import Error, Tags,"
    ],
    [
        "\"The '%s.check()' class method is currently overridden by %r.\"",
        "\"The '%s.check()' class method is currently overridden"
    ],
    [
        "\"You have configured settings.DATABASE_ROUTERS. Verify that %s \"",
        "\"You have configured settings.DATABASE_ROUTERS. Verify"
    ],
    [
        "\"are correctly routed to separate databases.\"",
        "\"are correctly routed"
    ],
    [
        "\"db_table '%s' is used by multiple models: %s.\"",
        "\"db_table '%s' is used by multiple models:"
    ],
    [
        "hint=(error_hint % model_labels_str) if error_hint else None,",
        "hint=(error_hint % model_labels_str) if error_hint"
    ],
    [
        "\"index name '%s' is not unique %s %s.\"",
        "\"index name '%s' is not unique"
    ],
    [
        "\"constraint name '%s' is not unique %s %s.\"",
        "\"constraint name '%s' is"
    ],
    [
        "Ensure all lazy (i.e. string) model references have been resolved.",
        "Ensure all lazy (i.e. string) model references"
    ],
    [
        "Lazy references are used in various places throughout Django, primarily in",
        "Lazy references are used in various places throughout"
    ],
    [
        "related fields and model signals. Identify those common cases and provide",
        "related fields and model signals. Identify those common cases"
    ],
    [
        "more helpful error messages for them.",
        "more helpful error"
    ],
    [
        "The ignore parameter is used by StateApps to exclude swappable models from",
        "The ignore parameter is used by StateApps to"
    ],
    [
        "pending_models = set(apps._pending_operations) - (ignore or set())",
        "pending_models = set(apps._pending_operations) -"
    ],
    [
        "Take a callable found in Apps._pending_operations and identify the",
        "Take a callable found in Apps._pending_operations and"
    ],
    [
        "original callable passed to Apps.lazy_model_operation(). If that",
        "original callable passed to"
    ],
    [
        "callable was a partial, return the inner, non-partial function and",
        "callable was a partial, return the"
    ],
    [
        "any arguments and keyword arguments that were supplied with it.",
        "any arguments and keyword arguments that were supplied with"
    ],
    [
        "obj is a callback defined locally in Apps.lazy_model_operation() and",
        "obj is a callback defined locally in"
    ],
    [
        "annotated there with a `func` attribute so as to imitate a partial.",
        "annotated there with a `func` attribute so as to imitate"
    ],
    [
        "operation, args, keywords = obj, [], {}",
        "operation, args, keywords = obj,"
    ],
    [
        "model_error = \"app '%s' doesn't provide model '%s'\" % model_key",
        "model_error = \"app '%s' doesn't provide model '%s'\""
    ],
    [
        "\"The field %(field)s was declared with a lazy reference \"",
        "\"The field %(field)s was declared with a lazy reference"
    ],
    [
        "\"%(receiver)s was connected to the '%(signal)s' signal with a \"",
        "\"%(receiver)s was connected to the '%(signal)s' signal"
    ],
    [
        "\"lazy reference to the sender '%(model)s', but %(model_error)s.\"",
        "\"lazy reference to the sender '%(model)s',"
    ],
    [
        "description = \"The function '%s'\" % receiver.__name__",
        "description = \"The function '%s'\""
    ],
    [
        "description = \"Bound method '%s.%s'\" % (",
        "description = \"Bound method"
    ],
    [
        "description = \"An instance of class '%s'\" % receiver.__class__.__name__",
        "description = \"An instance of"
    ],
    [
        "\"%(op)s contains a lazy reference to %(model)s, but %(model_error)s.\"",
        "\"%(op)s contains a lazy reference to %(model)s,"
    ],
    [
        "return error_fn(model_key, func, args, keywords) if error_fn else None",
        "return error_fn(model_key, func, args, keywords) if"
    ],
    [
        "from .registry import Tags, register, run_checks, tag_exists",
        "from .registry import Tags, register,"
    ],
    [
        "from . import Error, Tags, register",
        "from . import Error, Tags,"
    ],
    [
        "\"You have provided an invalid value for the LANGUAGE_CODE setting: {!r}.\",",
        "\"You have provided an invalid value for the"
    ],
    [
        "\"You have provided an invalid language code in the LANGUAGES setting: {!r}.\",",
        "\"You have provided an invalid language"
    ],
    [
        "\"You have provided an invalid language code in the LANGUAGES_BIDI setting: {!r}.\",",
        "\"You have provided an invalid language code"
    ],
    [
        "\"You have provided a value for the LANGUAGE_CODE setting that is not in \"",
        "\"You have provided a value for the LANGUAGE_CODE setting that is not in"
    ],
    [
        "\"\"\"Error if LANGUAGE_CODE setting is invalid.\"\"\"",
        "\"\"\"Error if LANGUAGE_CODE setting is"
    ],
    [
        "if not isinstance(tag, str) or not language_code_re.match(tag):",
        "if not isinstance(tag, str) or"
    ],
    [
        "\"\"\"Error if LANGUAGES setting is invalid.\"\"\"",
        "\"\"\"Error if LANGUAGES"
    ],
    [
        "if not isinstance(tag, str) or not language_code_re.match(tag)",
        "if not isinstance(tag, str) or not"
    ],
    [
        "\"\"\"Error if LANGUAGES_BIDI setting is invalid.\"\"\"",
        "\"\"\"Error if LANGUAGES_BIDI setting is"
    ],
    [
        "if not isinstance(tag, str) or not language_code_re.match(tag)",
        "if not isinstance(tag, str) or"
    ],
    [
        "\"\"\"Error if language settings are not consistent with each other.\"\"\"",
        "\"\"\"Error if language settings are not consistent with"
    ],
    [
        "from . import Error, Tags, register",
        "from . import Error, Tags,"
    ],
    [
        "\"You should not set the DJANGO_ALLOW_ASYNC_UNSAFE environment variable in \"",
        "\"You should not set the"
    ],
    [
        "\"deployment. This disables async safety protection.\",",
        "\"deployment. This disables async safety"
    ],
    [
        "def __init__(self, level, msg, hint=None, obj=None, id=None):",
        "def __init__(self, level, msg, hint=None, obj=None,"
    ],
    [
        "raise TypeError(\"The first argument should be level.\")",
        "raise TypeError(\"The first argument should be"
    ],
    [
        "for attr in [\"level\", \"msg\", \"hint\", \"obj\", \"id\"]",
        "for attr in [\"level\", \"msg\", \"hint\", \"obj\","
    ],
    [
        "id = \"(%s) \" % self.id if self.id else \"\"",
        "id = \"(%s) \" % self.id if self.id else"
    ],
    [
        "hint = \"\\n\\tHINT: %s\" % self.hint if self.hint else \"\"",
        "hint = \"\\n\\tHINT: %s\" % self.hint if"
    ],
    [
        "return \"%s: %s%s%s\" % (obj, id, self.msg, hint)",
        "return \"%s: %s%s%s\" % (obj, id,"
    ],
    [
        "return \"<%s: level=%r, msg=%r, hint=%r, obj=%r, id=%r>\" % (",
        "return \"<%s: level=%r, msg=%r, hint=%r, obj=%r,"
    ],
    [
        "from . import Error, Tags, Warning, register",
        "from . import Error,"
    ],
    [
        "Warn if URL namespaces used in applications aren't unique.",
        "Warn if URL namespaces used in applications aren't"
    ],
    [
        "\"URL namespace '{}' isn't unique. You may not be able to reverse \"",
        "\"URL namespace '{}' isn't unique. You may not be"
    ],
    [
        "Recursively load all namespaces from URL patterns.",
        "Recursively load all namespaces from"
    ],
    [
        "if getattr(url, \"namespace\", None) is not None",
        "if getattr(url, \"namespace\", None)"
    ],
    [
        "Return a list containing a warning that the pattern is invalid.",
        "Return a list containing a warning that"
    ],
    [
        "describe_pattern() cannot be used here, because we cannot rely on the",
        "describe_pattern() cannot be used here, because"
    ],
    [
        "urlpattern having regex or name attributes.",
        "urlpattern having regex or"
    ],
    [
        "\"Try removing the string '{}'. The list of urlpatterns should not \"",
        "\"Try removing the string '{}'. The"
    ],
    [
        "\"have a prefix string as the first element.\".format(pattern)",
        "\"have a prefix string as"
    ],
    [
        "hint = \"Try using path() instead of a tuple.\"",
        "hint = \"Try using path() instead of a"
    ],
    [
        "\"Your URL pattern {!r} is invalid. Ensure that urlpatterns is a list \"",
        "\"Your URL pattern {!r} is invalid. Ensure that urlpatterns is a list"
    ],
    [
        "\"The {} setting must end with a slash.\".format(name),",
        "\"The {} setting must"
    ],
    [
        "path = getattr(resolver.urlconf_module, \"handler%s\" % status_code)",
        "path = getattr(resolver.urlconf_module, \"handler%s\""
    ],
    [
        "\"The custom handler{status_code} view '{path}' could not be \"",
        "\"The custom handler{status_code} view '{path}' could not"
    ],
    [
        "\"The custom handler{status_code} view '{path}' does not \"",
        "\"The custom handler{status_code} view '{path}' does not"
    ],
    [
        "\"take the correct number of arguments ({args}).\"",
        "\"take the correct number"
    ],
    [
        "from django.core.checks import Error, Tags, register",
        "from django.core.checks import Error,"
    ],
    [
        "\"The migrate and makemigrations commands must have the same \"",
        "\"The migrate and makemigrations commands must have the same"
    ],
    [
        "from .. import Error, Tags, register",
        "from .. import"
    ],
    [
        "\"setting must start with a scheme (usually http:// or \"",
        "\"setting must start with a"
    ],
    [
        "\"https://) but found %s. See the release notes for details.\"",
        "\"https://) but found %s. See the"
    ],
    [
        "from .. import Tags, Warning, register",
        "from .. import Tags, Warning,"
    ],
    [
        "\" Using a secure-only session cookie makes it more difficult for \"",
        "\" Using a secure-only session cookie makes"
    ],
    [
        "\"network traffic sniffers to hijack user sessions.\"",
        "\"network traffic sniffers to hijack user"
    ],
    [
        "\"You have 'django.contrib.sessions' in your INSTALLED_APPS, \"",
        "\"You have 'django.contrib.sessions' in your INSTALLED_APPS,"
    ],
    [
        "\"but you have not set SESSION_COOKIE_SECURE to True.\"",
        "\"but you have not set"
    ],
    [
        "\"in your MIDDLEWARE, but you have not set \"",
        "\"in your MIDDLEWARE, but you have"
    ],
    [
        "add_session_cookie_message(\"SESSION_COOKIE_SECURE is not set to True.\"),",
        "add_session_cookie_message(\"SESSION_COOKIE_SECURE is not set to"
    ],
    [
        "\" Using an HttpOnly session cookie makes it more difficult for \"",
        "\" Using an HttpOnly session cookie makes it"
    ],
    [
        "\"cross-site scripting attacks to hijack user sessions.\"",
        "\"cross-site scripting attacks to"
    ],
    [
        "\"You have 'django.contrib.sessions' in your INSTALLED_APPS, \"",
        "\"You have 'django.contrib.sessions' in your INSTALLED_APPS,"
    ],
    [
        "\"but you have not set SESSION_COOKIE_HTTPONLY to True.\",",
        "\"but you have not set SESSION_COOKIE_HTTPONLY to"
    ],
    [
        "\"in your MIDDLEWARE, but you have not set \"",
        "\"in your MIDDLEWARE, but you"
    ],
    [
        "add_httponly_message(\"SESSION_COOKIE_HTTPONLY is not set to True.\"),",
        "add_httponly_message(\"SESSION_COOKIE_HTTPONLY is not set"
    ],
    [
        "from .. import Error, Tags, Warning, register",
        "from .. import Error,"
    ],
    [
        "\"You don't appear to be using Django's built-in \"",
        "\"You don't appear to be using Django's built-in"
    ],
    [
        "\"cross-site request forgery protection via the middleware \"",
        "\"cross-site request forgery protection via the middleware"
    ],
    [
        "\"('django.middleware.csrf.CsrfViewMiddleware' is not in your \"",
        "\"('django.middleware.csrf.CsrfViewMiddleware' is not in"
    ],
    [
        "\"MIDDLEWARE). Enabling the middleware is the safest approach \"",
        "\"MIDDLEWARE). Enabling the middleware is the safest approach"
    ],
    [
        "\"to ensure you don't leave any holes.\",",
        "\"to ensure you don't"
    ],
    [
        "\"You have 'django.middleware.csrf.CsrfViewMiddleware' in your \"",
        "\"You have 'django.middleware.csrf.CsrfViewMiddleware'"
    ],
    [
        "\"MIDDLEWARE, but you have not set CSRF_COOKIE_SECURE to True. \"",
        "\"MIDDLEWARE, but you have not set CSRF_COOKIE_SECURE to True."
    ],
    [
        "\"Using a secure-only CSRF cookie makes it more difficult for network \"",
        "\"Using a secure-only CSRF cookie makes it more difficult for network"
    ],
    [
        "\"traffic sniffers to steal the CSRF token.\",",
        "\"traffic sniffers to steal the"
    ],
    [
        "\"The CSRF failure view '%s' could not be imported.\"",
        "\"The CSRF failure view '%s' could not"
    ],
    [
        "\"The CSRF failure view '%s' does not take the correct number of \"",
        "\"The CSRF failure view '%s' does not take the correct"
    ],
    [
        "from .. import Error, Tags, Warning, register",
        "from .. import Error, Tags, Warning,"
    ],
    [
        "f\"Your %s has less than {SECRET_KEY_MIN_LENGTH} characters, less than \"",
        "f\"Your %s has less than {SECRET_KEY_MIN_LENGTH} characters,"
    ],
    [
        "f\"{SECRET_KEY_MIN_UNIQUE_CHARACTERS} unique characters, or it's prefixed \"",
        "f\"{SECRET_KEY_MIN_UNIQUE_CHARACTERS} unique characters, or"
    ],
    [
        "f\"with '{SECRET_KEY_INSECURE_PREFIX}' indicating that it was generated \"",
        "f\"with '{SECRET_KEY_INSECURE_PREFIX}' indicating that"
    ],
    [
        "f\"automatically by Django. Please generate a long and random value, \"",
        "f\"automatically by Django. Please generate a long"
    ],
    [
        "f\"otherwise many of Django's security-critical features will be \"",
        "f\"otherwise many of Django's security-critical features will"
    ],
    [
        "\"You do not have 'django.middleware.security.SecurityMiddleware' \"",
        "\"You do not have 'django.middleware.security.SecurityMiddleware'"
    ],
    [
        "\"in your MIDDLEWARE so the SECURE_HSTS_SECONDS, \"",
        "\"in your MIDDLEWARE so"
    ],
    [
        "\"SECURE_CROSS_ORIGIN_OPENER_POLICY, and SECURE_SSL_REDIRECT settings will \"",
        "\"SECURE_CROSS_ORIGIN_OPENER_POLICY, and SECURE_SSL_REDIRECT settings"
    ],
    [
        "\"MIDDLEWARE, so your pages will not be served with an \"",
        "\"MIDDLEWARE, so your pages will not be served"
    ],
    [
        "\"'x-frame-options' header. Unless there is a good reason for your \"",
        "\"'x-frame-options' header. Unless there is a"
    ],
    [
        "\"site to be served in a frame, you should consider enabling this \"",
        "\"site to be served in a frame, you should"
    ],
    [
        "\"header to help prevent clickjacking attacks.\",",
        "\"header to help"
    ],
    [
        "\"You have not set a value for the SECURE_HSTS_SECONDS setting. \"",
        "\"You have not set a value for the SECURE_HSTS_SECONDS setting."
    ],
    [
        "\"If your entire site is served only over SSL, you may want to consider \"",
        "\"If your entire site is served only over SSL, you may want to"
    ],
    [
        "\"setting a value and enabling HTTP Strict Transport Security. \"",
        "\"setting a value and enabling HTTP"
    ],
    [
        "\"Be sure to read the documentation first; enabling HSTS carelessly \"",
        "\"Be sure to read the documentation first; enabling"
    ],
    [
        "\"You have not set the SECURE_HSTS_INCLUDE_SUBDOMAINS setting to True. \"",
        "\"You have not set the SECURE_HSTS_INCLUDE_SUBDOMAINS"
    ],
    [
        "\"Without this, your site is potentially vulnerable to attack \"",
        "\"Without this, your site is potentially vulnerable to attack"
    ],
    [
        "\"via an insecure connection to a subdomain. Only set this to True if \"",
        "\"via an insecure connection to a subdomain. Only set this"
    ],
    [
        "\"you are certain that all subdomains of your domain should be served \"",
        "\"you are certain that all subdomains of your domain should be served"
    ],
    [
        "\"Your SECURE_CONTENT_TYPE_NOSNIFF setting is not set to True, \"",
        "\"Your SECURE_CONTENT_TYPE_NOSNIFF setting is not set to"
    ],
    [
        "\"so your pages will not be served with an \"",
        "\"so your pages will not be served with an"
    ],
    [
        "\"You should consider enabling this header to prevent the \"",
        "\"You should consider enabling this header"
    ],
    [
        "\"browser from identifying content types incorrectly.\",",
        "\"browser from identifying content types"
    ],
    [
        "\"Your SECURE_SSL_REDIRECT setting is not set to True. \"",
        "\"Your SECURE_SSL_REDIRECT setting is not set to True."
    ],
    [
        "\"Unless your site should be available over both SSL and non-SSL \"",
        "\"Unless your site should be available over"
    ],
    [
        "\"connections, you may want to either set this setting True \"",
        "\"connections, you may want to either set"
    ],
    [
        "\"or configure a load balancer or reverse-proxy server \"",
        "\"or configure a load balancer or reverse-proxy server"
    ],
    [
        "\"to redirect all connections to HTTPS.\",",
        "\"to redirect all connections to"
    ],
    [
        "\"You should not have DEBUG set to True in deployment.\",",
        "\"You should not have DEBUG"
    ],
    [
        "\"MIDDLEWARE, but X_FRAME_OPTIONS is not set to 'DENY'. \"",
        "\"MIDDLEWARE, but X_FRAME_OPTIONS is not set to"
    ],
    [
        "\"Unless there is a good reason for your site to serve other parts of \"",
        "\"Unless there is a good reason for your site"
    ],
    [
        "\"itself in a frame, you should change it to 'DENY'.\",",
        "\"itself in a frame, you should change it to"
    ],
    [
        "\"ALLOWED_HOSTS must not be empty in deployment.\",",
        "\"ALLOWED_HOSTS must not be empty"
    ],
    [
        "\"You have not set the SECURE_HSTS_PRELOAD setting to True. Without this, \"",
        "\"You have not set the SECURE_HSTS_PRELOAD setting to"
    ],
    [
        "\"your site cannot be submitted to the browser preload list.\",",
        "\"your site cannot be submitted to"
    ],
    [
        "\"You have not set the SECURE_REFERRER_POLICY setting. Without this, your \"",
        "\"You have not set the SECURE_REFERRER_POLICY setting."
    ],
    [
        "\"site will not send a Referrer-Policy header. You should consider \"",
        "\"site will not send a Referrer-Policy header. You should"
    ],
    [
        "\"enabling this header to protect user privacy.\",",
        "\"enabling this header to"
    ],
    [
        "\"You have set the SECURE_REFERRER_POLICY setting to an invalid value.\",",
        "\"You have set the SECURE_REFERRER_POLICY setting"
    ],
    [
        "\"You have set the SECURE_CROSS_ORIGIN_OPENER_POLICY setting to an invalid \"",
        "\"You have set the SECURE_CROSS_ORIGIN_OPENER_POLICY"
    ],
    [
        "passed_check = not _security_middleware() or settings.SECURE_HSTS_SECONDS",
        "passed_check = not"
    ],
    [
        "not _security_middleware() or settings.SECURE_CONTENT_TYPE_NOSNIFF is True",
        "not _security_middleware() or settings.SECURE_CONTENT_TYPE_NOSNIFF is"
    ],
    [
        "passed_check = not _security_middleware() or settings.SECURE_SSL_REDIRECT is True",
        "passed_check = not _security_middleware() or settings.SECURE_SSL_REDIRECT"
    ],
    [
        "passed_check = not _xframe_middleware() or settings.X_FRAME_OPTIONS == \"DENY\"",
        "passed_check = not _xframe_middleware()"
    ],
    [
        "values = {v.strip() for v in settings.SECURE_REFERRER_POLICY.split(\",\")}",
        "values = {v.strip() for v in"
    ],
    [
        "Sets up the terminal color scheme.",
        "Sets up the terminal"
    ],
    [
        "Return True if the running system's terminal supports color,",
        "Return True if the running system's terminal"
    ],
    [
        "Check the Windows Registry to see if VT code handling has been enabled",
        "Check the Windows Registry to see if VT"
    ],
    [
        "is_a_tty = hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty()",
        "is_a_tty = hasattr(sys.stdout,"
    ],
    [
        "or (HAS_COLORAMA and getattr(colorama, \"fixed_windows_console\", False))",
        "or (HAS_COLORAMA and"
    ],
    [
        "Create a Style object from the given config_string.",
        "Create a Style object from the given"
    ],
    [
        "If config_string is empty django.utils.termcolors.DEFAULT_PALETTE is used.",
        "If config_string is empty django.utils.termcolors.DEFAULT_PALETTE"
    ],
    [
        "Return a Style object with no color scheme.",
        "Return a Style object"
    ],
    [
        "Return a Style object from the Django color scheme.",
        "Return a Style object from the Django color"
    ],
    [
        "if not force_color and not supports_color():",
        "if not force_color and"
    ],
    [
        "Given a path to a management directory, return a list of all the command",
        "Given a path to a management directory,"
    ],
    [
        "for _, name, is_pkg in pkgutil.iter_modules([command_dir])",
        "for _, name,"
    ],
    [
        "if not is_pkg and not name.startswith(\"_\")",
        "if not is_pkg and"
    ],
    [
        "Given a command name and an application name, return the Command",
        "Given a command name and an"
    ],
    [
        "class instance. Allow all errors raised by the import process",
        "class instance. Allow all errors"
    ],
    [
        "module = import_module(\"%s.management.commands.%s\" % (app_name, name))",
        "module = import_module(\"%s.management.commands.%s\" %"
    ],
    [
        "Return a dictionary mapping command names to their callback applications.",
        "Return a dictionary mapping command names to their"
    ],
    [
        "Look for a management.commands package in django.core, and in each",
        "Look for a management.commands package"
    ],
    [
        "installed application -- if a commands package exists, register all",
        "installed application -- if a commands package exists, register"
    ],
    [
        "Core commands are always included. If a settings module has been",
        "Core commands are always included. If a"
    ],
    [
        "The dictionary is in the format {command_name: app_name}. Key-value",
        "The dictionary is in the format {command_name:"
    ],
    [
        "pairs from this dictionary can then be used in calls to",
        "pairs from this dictionary can then"
    ],
    [
        "The dictionary is cached on the first call and reused on subsequent",
        "The dictionary is cached on the first call and reused on"
    ],
    [
        "commands.update({name: app_config.name for name in find_commands(path)})",
        "commands.update({name: app_config.name for name in"
    ],
    [
        "Call the given command, with the given options and args/kwargs.",
        "Call the given command, with"
    ],
    [
        "This is the primary API you should use for calling specific commands.",
        "This is the primary API you should use for"
    ],
    [
        "`command_name` may be a string or a command object. Using a string is",
        "`command_name` may be a string or a command object. Using"
    ],
    [
        "preferred unless the command object is required for further processing or",
        "preferred unless the command object is required"
    ],
    [
        "raise CommandError(\"Unknown command: %r\" % command_name)",
        "raise CommandError(\"Unknown command: %r\""
    ],
    [
        "arg_options = {opt_mapping.get(key, key): value for key, value in options.items()}",
        "arg_options = {opt_mapping.get(key, key): value for"
    ],
    [
        "if opt.dest in options and (",
        "if opt.dest in options and"
    ],
    [
        "opt_dest_count = sum(v == opt.dest for v in opt_mapping.values())",
        "opt_dest_count = sum(v == opt.dest"
    ],
    [
        "f\"Cannot pass the dest {opt.dest!r} that matches multiple \"",
        "f\"Cannot pass the dest {opt.dest!r} that matches multiple"
    ],
    [
        "dest_parameters = {action.dest for action in parser_actions}",
        "dest_parameters = {action.dest for action in"
    ],
    [
        "\"Unknown option(s) for %s command: %s. \"",
        "\"Unknown option(s) for %s command: %s."
    ],
    [
        "Encapsulate the logic of the django-admin and manage.py utilities.",
        "Encapsulate the logic of the"
    ],
    [
        "\"\"\"Return the script's main help text, as a string.\"\"\"",
        "\"\"\"Return the script's main help text,"
    ],
    [
        "\"Type '%s help <subcommand>' for help on a specific subcommand.\"",
        "\"Type '%s help <subcommand>' for help"
    ],
    [
        "\"Note that only Django core commands are listed \"",
        "\"Note that only Django core commands are"
    ],
    [
        "\"as settings are not properly configured (error: %s).\"",
        "\"as settings are not properly configured"
    ],
    [
        "Try to fetch the given subcommand, printing a message with the",
        "Try to fetch the given subcommand, printing a message"
    ],
    [
        "appropriate command called from the command line (usually",
        "appropriate command called from the"
    ],
    [
        "\"django-admin\" or \"manage.py\") if it can't be found.",
        "\"django-admin\" or \"manage.py\") if"
    ],
    [
        "sys.stderr.write(\"\\nType '%s help' for usage.\\n\" % self.prog_name)",
        "sys.stderr.write(\"\\nType '%s help' for usage.\\n\" %"
    ],
    [
        "The output of this function is passed to BASH's `COMPREPLY` variable",
        "The output of this function is passed"
    ],
    [
        "and treated as completion suggestions. `COMPREPLY` expects a space",
        "and treated as completion suggestions. `COMPREPLY` expects a"
    ],
    [
        "The `COMP_WORDS` and `COMP_CWORD` BASH environment variables are used",
        "The `COMP_WORDS` and `COMP_CWORD` BASH environment"
    ],
    [
        "to get information about the cli input. Please refer to the BASH",
        "to get information about the cli input. Please"
    ],
    [
        "man-page for more information about this variables.",
        "man-page for more information about"
    ],
    [
        "Subcommand options are saved as pairs. A pair consists of",
        "Subcommand options are saved as pairs. A pair"
    ],
    [
        "the long option string (e.g. '--exclude') and a boolean",
        "the long option string (e.g. '--exclude')"
    ],
    [
        "value indicating if the option requires arguments. When printing to",
        "value indicating if the option"
    ],
    [
        "stdout, an equal sign is appended to options which require arguments.",
        "stdout, an equal sign is appended to options which"
    ],
    [
        "Note: If debugging this function, it is recommended to write the debug",
        "Note: If debugging this function, it is recommended to"
    ],
    [
        "output in a separate file. Otherwise the debug output will be treated",
        "output in a separate file. Otherwise the debug output will be"
    ],
    [
        "and formatted as potential completion suggestions.",
        "and formatted as potential"
    ],
    [
        "options = sorted((k, v) for k, v in options if k.startswith(curr))",
        "options = sorted((k, v) for k, v in"
    ],
    [
        "Given the command-line arguments, figure out which subcommand is being",
        "Given the command-line arguments, figure out"
    ],
    [
        "run, create a parser appropriate to that command, and run it.",
        "run, create a parser appropriate to that command,"
    ],
    [
        "if subcommand == \"runserver\" and \"--noreload\" not in self.argv:",
        "if subcommand == \"runserver\" and \"--noreload\" not in"
    ],
    [
        "apps.apps_ready = apps.models_ready = apps.ready = True",
        "apps.apps_ready = apps.models_ready = apps.ready"
    ],
    [
        "Copy either a Django application layout template or a Django project",
        "Copy either a Django application layout template or a Django"
    ],
    [
        "layout template into the specified directory.",
        "layout template into the"
    ],
    [
        ":param style: A color style object (see django.core.management.color).",
        ":param style: A color"
    ],
    [
        ":param app_or_project: The string 'app' or 'project'.",
        ":param app_or_project: The string"
    ],
    [
        ":param name: The name of the application or project.",
        ":param name: The name of"
    ],
    [
        ":param directory: The directory to which the template should be copied.",
        ":param directory: The directory to which the template should be"
    ],
    [
        ":param options: The additional variables passed to project or app templates",
        ":param options: The additional variables passed to project"
    ],
    [
        "parser.add_argument(\"name\", help=\"Name of the application or project.\")",
        "parser.add_argument(\"name\", help=\"Name of the"
    ],
    [
        "\"--template\", help=\"The path or URL to load the template from.\"",
        "\"--template\", help=\"The path or URL to load the"
    ],
    [
        "help='The file extension(s) to render (default: \"py\"). '",
        "help='The file extension(s) to render"
    ],
    [
        "\"Separate multiple extensions with commas, or use \"",
        "\"Separate multiple extensions with commas,"
    ],
    [
        "help=\"The file name(s) to render. Separate multiple file names \"",
        "help=\"The file name(s) to render. Separate multiple file"
    ],
    [
        "\"with commas, or use -n multiple times.\",",
        "\"with commas, or use -n"
    ],
    [
        "\"The directory name(s) to exclude, in addition to .git and \"",
        "\"The directory name(s) to exclude, in addition"
    ],
    [
        "\"__pycache__. Can be used multiple times.\"",
        "\"__pycache__. Can be"
    ],
    [
        "def handle(self, app_or_project, name, target=None, **options):",
        "def handle(self, app_or_project,"
    ],
    [
        "self.a_or_an = \"an\" if app_or_project == \"app\" else \"a\"",
        "self.a_or_an = \"an\" if app_or_project"
    ],
    [
        "raise CommandError(\"'%s' already exists\" % top_dir)",
        "raise CommandError(\"'%s' already"
    ],
    [
        "\"Destination directory '%s' does not \"",
        "\"Destination directory '%s'"
    ],
    [
        "\"exist, please create it first.\" % top_dir",
        "\"exist, please create it first.\" %"
    ],
    [
        "\"Rendering %s template files with extensions: %s\"",
        "\"Rendering %s template files with"
    ],
    [
        "\"Rendering %s template files with filenames: %s\"",
        "\"Rendering %s template files with filenames:"
    ],
    [
        "camel_case_value = \"\".join(x for x in name.title() if x != \"_\")",
        "camel_case_value = \"\".join(x for x in name.title() if x !="
    ],
    [
        "for root, dirs, files in os.walk(template_dir):",
        "for root, dirs, files in"
    ],
    [
        "if dirname.startswith(\".\") or dirname == \"__pycache__\":",
        "if dirname.startswith(\".\") or dirname =="
    ],
    [
        "\"%s already exists. Overlaying %s %s into an existing \"",
        "\"%s already exists. Overlaying %s %s into"
    ],
    [
        "if new_path.endswith(extensions) or filename in extra_files:",
        "if new_path.endswith(extensions) or filename"
    ],
    [
        "\"Notice: Couldn't set permission bits on %s. You're \"",
        "\"Notice: Couldn't set permission bits on"
    ],
    [
        "\"probably using an uncommon filesystem setup. No \"",
        "\"probably using an uncommon filesystem setup. No"
    ],
    [
        "Determine where the app or project templates are.",
        "Determine where the app"
    ],
    [
        "\"couldn't handle %s template %s.\" % (self.app_or_project, template)",
        "\"couldn't handle %s template"
    ],
    [
        "\"you must provide {an} {app} name\".format(",
        "\"you must provide {an}"
    ],
    [
        "\"'{name}' is not a valid {app} {type}. Please make sure the \"",
        "\"'{name}' is not a valid {app} {type}."
    ],
    [
        "\"'{name}' conflicts with the name of an existing Python \"",
        "\"'{name}' conflicts with the name"
    ],
    [
        "\"module and cannot be used as {an} {app} {type}. Please try \"",
        "\"module and cannot be used as {an}"
    ],
    [
        "Download the given URL and return the file name.",
        "Download the given URL and return"
    ],
    [
        "with opener.open(url) as source, open(the_path, \"wb\") as target:",
        "with opener.open(url) as source,"
    ],
    [
        "\"couldn't download URL %s to %s: %s\" % (url, filename, e)",
        "\"couldn't download URL %s to %s: %s\" % (url, filename,"
    ],
    [
        "Like os.path.splitext, but takes off .tar, too",
        "Like os.path.splitext, but takes"
    ],
    [
        "Extract the given file to a temporary directory and return",
        "Extract the given file to a temporary directory"
    ],
    [
        "the path of the directory with the extracted content.",
        "the path of the directory with the"
    ],
    [
        "\"couldn't extract file %s to %s: %s\" % (filename, tempdir, e)",
        "\"couldn't extract file %s to %s:"
    ],
    [
        "\"\"\"Return True if the name looks like a URL.\"\"\"",
        "\"\"\"Return True if the name looks like"
    ],
    [
        "Make sure that the file is writeable.",
        "Make sure that the file is"
    ],
    [
        "Useful if our source is read-only.",
        "Useful if our source"
    ],
    [
        "from django.apps import apps as installed_apps",
        "from django.apps import apps as"
    ],
    [
        "Return stdout output, stderr output, and OS status code.",
        "Return stdout output, stderr output, and"
    ],
    [
        "p = run(args, capture_output=True, close_fds=os.name != \"nt\")",
        "p = run(args, capture_output=True, close_fds=os.name !="
    ],
    [
        "Organize multiple extensions that are separated with commas or passed by",
        "Organize multiple extensions that are separated"
    ],
    [
        "For example: running 'django-admin makemessages -e js,txt -e xhtml -a'",
        "For example: running 'django-admin makemessages -e js,txt -e xhtml"
    ],
    [
        "would result in an extension list: ['.js', '.txt', '.xhtml']",
        "would result in an extension"
    ],
    [
        "Parse a list of \"app_label.ModelName\" or \"app_label\" strings into actual",
        "Parse a list of \"app_label.ModelName\" or \"app_label\" strings into"
    ],
    [
        "objects and return a two-element tuple:",
        "objects and return a two-element"
    ],
    [
        "(set of model classes, set of app_configs).",
        "(set of model classes,"
    ],
    [
        "Raise a CommandError if some specified models or apps don't exist.",
        "Raise a CommandError if some specified models or apps"
    ],
    [
        "raise CommandError(\"Unknown model: %s\" % label)",
        "raise CommandError(\"Unknown model: %s\" %"
    ],
    [
        "Return the value of a command line option (which should include leading",
        "Return the value of a command line option (which should include"
    ],
    [
        "dashes, e.g. '--testrunner') from an argument list. Return None if the",
        "dashes, e.g. '--testrunner') from an argument list. Return None if"
    ],
    [
        "option wasn't passed or if the argument list couldn't be parsed.",
        "option wasn't passed or if the argument list couldn't"
    ],
    [
        "\"\"\"Normalize an iterable of glob style patterns based on OS.\"\"\"",
        "\"\"\"Normalize an iterable of glob style patterns based on"
    ],
    [
        "patterns = [os.path.normcase(p) for p in patterns]",
        "patterns = [os.path.normcase(p) for"
    ],
    [
        "dir_suffixes = {\"%s*\" % path_sep for path_sep in {\"/\", os.sep}}",
        "dir_suffixes = {\"%s*\" % path_sep for path_sep in {\"/\","
    ],
    [
        "Check if the given path should be ignored or not based on matching",
        "Check if the given path should be ignored or not based"
    ],
    [
        "one of the glob style `ignore_patterns`.",
        "one of the glob style"
    ],
    [
        "return any(ignore(pattern) for pattern in normalize_path_patterns(ignore_patterns))",
        "return any(ignore(pattern) for pattern"
    ],
    [
        "def run_formatters(written_files, black_path=(sentinel := object()), stderr=sys.stderr):",
        "def run_formatters(written_files, black_path=(sentinel := object()),"
    ],
    [
        "Run the black formatter on the specified files.",
        "Run the black formatter"
    ],
    [
        "Return a list of the SQL statements used to flush the database.",
        "Return a list of the SQL statements used to"
    ],
    [
        "\"Running pre-migrate handlers for application %s\" % app_config.label",
        "\"Running pre-migrate handlers for application %s\""
    ],
    [
        "\"Running post-migrate handlers for application %s\" % app_config.label",
        "\"Running post-migrate handlers for application"
    ],
    [
        "Base classes for writing management commands (named commands which can",
        "Base classes for writing management"
    ],
    [
        "be executed through ``django-admin`` or ``manage.py``).",
        "be executed through ``django-admin``"
    ],
    [
        "Exception class indicating a problem while executing a management",
        "Exception class indicating a problem while executing"
    ],
    [
        "If this exception is raised during the execution of a management",
        "If this exception is raised during"
    ],
    [
        "command, it will be caught and turned into a nicely-printed error",
        "command, it will be caught and turned into a nicely-printed"
    ],
    [
        "message to the appropriate output stream (i.e., stderr); as a",
        "message to the appropriate output stream (i.e., stderr);"
    ],
    [
        "result, raising this exception (with a sensible description of the",
        "result, raising this exception (with a"
    ],
    [
        "error) is the preferred way to indicate that something has gone",
        "error) is the preferred way to indicate that something"
    ],
    [
        "wrong in the execution of a command.",
        "wrong in the execution of"
    ],
    [
        "The system check framework detected unrecoverable errors.",
        "The system check framework detected unrecoverable"
    ],
    [
        "Customized ArgumentParser class to improve some error messages and prevent",
        "Customized ArgumentParser class to improve"
    ],
    [
        "SystemExit in several occasions, as SystemExit is unacceptable when a",
        "SystemExit in several occasions, as SystemExit is unacceptable when"
    ],
    [
        "args or any(not arg.startswith(\"-\") for arg in args)",
        "args or any(not arg.startswith(\"-\")"
    ],
    [
        "Include any default options that all commands should accept here",
        "Include any default options that all commands should"
    ],
    [
        "so that ManagementUtility can handle them before searching for",
        "so that ManagementUtility can handle"
    ],
    [
        "\"\"\"Decorator that forces a command to run with translations deactivated.\"\"\"",
        "\"\"\"Decorator that forces a command to"
    ],
    [
        "Customized formatter so that command-specific arguments appear in the",
        "Customized formatter so that command-specific arguments appear in"
    ],
    [
        "--help output before arguments common to all commands.",
        "--help output before arguments common to all"
    ],
    [
        "actions, key=lambda a: set(a.option_strings) & self.show_last != set()",
        "actions, key=lambda a: set(a.option_strings)"
    ],
    [
        "def add_usage(self, usage, actions, *args, **kwargs):",
        "def add_usage(self, usage, actions,"
    ],
    [
        "ending = self.ending if ending is None else ending",
        "ending = self.ending if ending is None"
    ],
    [
        "The base class from which all management commands ultimately",
        "The base class from which all management commands"
    ],
    [
        "Use this class if you want access to all of the mechanisms which",
        "Use this class if you want access to all of"
    ],
    [
        "parse the command-line arguments and work out what code to call in",
        "parse the command-line arguments and work out what code"
    ],
    [
        "response; if you don't need to change any of that behavior,",
        "response; if you don't need to change any"
    ],
    [
        "consider using one of the subclasses defined in this file.",
        "consider using one of the subclasses defined in this"
    ],
    [
        "If you are interested in overriding/customizing various aspects of",
        "If you are interested in overriding/customizing various aspects"
    ],
    [
        "the command-parsing and -execution behavior, the normal flow works",
        "the command-parsing and -execution behavior, the"
    ],
    [
        "an ``ArgumentParser`` for the arguments, parses them, performs",
        "an ``ArgumentParser`` for the arguments, parses them,"
    ],
    [
        "any environment changes requested by options like",
        "any environment changes requested"
    ],
    [
        "``pythonpath``, and then calls the ``execute()`` method,",
        "``pythonpath``, and then calls the ``execute()``"
    ],
    [
        "calling the ``handle()`` method with the parsed arguments; any",
        "calling the ``handle()`` method with the parsed"
    ],
    [
        "output produced by ``handle()`` will be printed to standard",
        "output produced by ``handle()`` will be"
    ],
    [
        "output and, if the command is intended to produce a block of",
        "output and, if the command is"
    ],
    [
        "SQL statements, will be wrapped in ``BEGIN`` and ``COMMIT``.",
        "SQL statements, will be wrapped in ``BEGIN``"
    ],
    [
        "``CommandError``), ``run_from_argv()`` will  instead print an error",
        "``CommandError``), ``run_from_argv()`` will instead"
    ],
    [
        "Thus, the ``handle()`` method is typically the starting point for",
        "Thus, the ``handle()`` method is typically the starting point"
    ],
    [
        "subclasses; many built-in commands and command types either place",
        "subclasses; many built-in commands and"
    ],
    [
        "all of their logic in ``handle()``, or perform some additional",
        "all of their logic in"
    ],
    [
        "parsing work in ``handle()`` and then delegate from it to more",
        "parsing work in ``handle()`` and then delegate from"
    ],
    [
        "Several attributes affect behavior at various steps along the way:",
        "Several attributes affect behavior at various steps along the"
    ],
    [
        "A short description of the command, which will be printed in",
        "A short description of the command,"
    ],
    [
        "A boolean indicating whether the command outputs SQL",
        "A boolean indicating whether"
    ],
    [
        "statements; if ``True``, the output will automatically be",
        "statements; if ``True``, the output"
    ],
    [
        "wrapped with ``BEGIN;`` and ``COMMIT;``. Default value is",
        "wrapped with ``BEGIN;`` and ``COMMIT;``. Default value"
    ],
    [
        "A boolean; if ``True``, the command prints a warning if the set of",
        "A boolean; if ``True``, the command prints a warning"
    ],
    [
        "migrations on disk don't match the migrations in the database.",
        "migrations on disk don't match"
    ],
    [
        "A list or tuple of tags, e.g. [Tags.staticfiles, Tags.models]. System",
        "A list or tuple of tags,"
    ],
    [
        "checks registered in the chosen tags will be checked for errors prior",
        "checks registered in the chosen tags will"
    ],
    [
        "to executing the command. The value '__all__' can be used to specify",
        "to executing the command. The value"
    ],
    [
        "that all system checks should be performed. Default value is '__all__'.",
        "that all system checks should be performed."
    ],
    [
        "To validate an individual application's models",
        "To validate an individual"
    ],
    [
        "rather than all applications' models, call",
        "rather than all applications' models,"
    ],
    [
        "is the list of application's configuration provided by the",
        "is the list of application's"
    ],
    [
        "A tuple of any options the command uses which aren't defined by the",
        "A tuple of any options the command uses which aren't defined by"
    ],
    [
        "def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False):",
        "def __init__(self, stdout=None, stderr=None, no_color=False,"
    ],
    [
        "raise CommandError(\"'no_color' and 'force_color' can't be used together.\")",
        "raise CommandError(\"'no_color' and 'force_color'"
    ],
    [
        "raise TypeError(\"requires_system_checks must be a list or tuple.\")",
        "raise TypeError(\"requires_system_checks must be a list"
    ],
    [
        "Return the Django version, which should be correct for all built-in",
        "Return the Django version, which should be correct"
    ],
    [
        "Django commands. User-supplied commands can override this method to",
        "Django commands. User-supplied commands can override this"
    ],
    [
        "Create and return the ``ArgumentParser`` which will be used to",
        "Create and return the ``ArgumentParser`` which will"
    ],
    [
        "parse the arguments to this command.",
        "parse the arguments to"
    ],
    [
        "help=\"Show program's version number and exit.\",",
        "help=\"Show program's version number and"
    ],
    [
        "\"The Python path to a settings module, e.g. \"",
        "\"The Python path to a settings module,"
    ],
    [
        "'\"myproject.settings.main\". If this isn\\'t provided, the '",
        "'\"myproject.settings.main\". If this isn\\'t"
    ],
    [
        "\"DJANGO_SETTINGS_MODULE environment variable will be used.\"",
        "\"DJANGO_SETTINGS_MODULE environment variable will be"
    ],
    [
        "\"A directory to add to the Python path, e.g. \"",
        "\"A directory to add to"
    ],
    [
        "help=\"Display a full stack trace on CommandError exceptions.\",",
        "help=\"Display a full stack trace on"
    ],
    [
        "help=\"Force colorization of the command output.\",",
        "help=\"Force colorization of"
    ],
    [
        "Entry point for subclassed commands to add custom arguments.",
        "Entry point for subclassed commands"
    ],
    [
        "Call the parser's add_argument() method, suppressing the help text",
        "Call the parser's add_argument() method, suppressing"
    ],
    [
        "Print the help message for this command, derived from",
        "Print the help message for"
    ],
    [
        "Set up any environment changes requested (e.g., Python path",
        "Set up any environment changes requested (e.g., Python"
    ],
    [
        "and Django settings), then run this command. If the",
        "and Django settings), then run this command."
    ],
    [
        "command raises a ``CommandError``, intercept it and print it sensibly",
        "command raises a ``CommandError``, intercept"
    ],
    [
        "to stderr. If the ``--traceback`` option is present or the raised",
        "to stderr. If the ``--traceback`` option is present"
    ],
    [
        "``Exception`` is not ``CommandError``, raise it.",
        "``Exception`` is not ``CommandError``,"
    ],
    [
        "Try to execute this command, performing system checks if needed (as",
        "Try to execute this command, performing system checks if"
    ],
    [
        "controlled by the ``requires_system_checks`` attribute, except if",
        "controlled by the ``requires_system_checks``"
    ],
    [
        "\"The --no-color and --force-color options can't be used together.\"",
        "\"The --no-color and --force-color options can't"
    ],
    [
        "Use the system check framework to validate entire Django project.",
        "Use the system check framework to validate entire"
    ],
    [
        "Raise CommandError for any serious message (error or critical errors).",
        "Raise CommandError for any serious message (error"
    ],
    [
        "If there are only light messages (like warnings), print them to stderr",
        "If there are only light messages (like"
    ],
    [
        "header, body, footer = \"\", \"\", \"\"",
        "header, body, footer ="
    ],
    [
        "e for e in all_issues if e.level < checks.INFO and not e.is_silenced()",
        "e for e in all_issues if e.level"
    ],
    [
        "if checks.INFO <= e.level < checks.WARNING and not e.is_silenced()",
        "if checks.INFO <= e.level <"
    ],
    [
        "if checks.WARNING <= e.level < checks.ERROR and not e.is_silenced()",
        "if checks.WARNING <= e.level < checks.ERROR"
    ],
    [
        "if checks.ERROR <= e.level < checks.CRITICAL and not e.is_silenced()",
        "if checks.ERROR <= e.level < checks.CRITICAL"
    ],
    [
        "if checks.CRITICAL <= e.level and not e.is_silenced()",
        "if checks.CRITICAL <= e.level"
    ],
    [
        "body += \"\\n%s:\\n%s\\n\" % (group_name, formatted)",
        "body += \"\\n%s:\\n%s\\n\""
    ],
    [
        "header = \"System check identified some issues:\\n\"",
        "header = \"System check identified"
    ],
    [
        "footer += \"System check identified %s (%s silenced).\" % (",
        "footer += \"System check identified %s (%s silenced).\""
    ],
    [
        "if any(e.is_serious(fail_level) and not e.is_silenced() for e in all_issues):",
        "if any(e.is_serious(fail_level) and not e.is_silenced() for"
    ],
    [
        "msg = self.style.ERROR(\"SystemCheckError: %s\" % header) + body + footer",
        "msg = self.style.ERROR(\"SystemCheckError: %s\" % header)"
    ],
    [
        "msg = header + body + footer",
        "msg = header + body"
    ],
    [
        "Print a warning if the set of migrations on disk don't match the",
        "Print a warning if the set of migrations on disk"
    ],
    [
        "{migration.app_label for migration, backwards in plan}",
        "{migration.app_label for migration,"
    ],
    [
        "\"\\nYou have %(unapplied_migration_count)s unapplied migration(s). \"",
        "\"\\nYou have %(unapplied_migration_count)s unapplied"
    ],
    [
        "\"Your project may not work properly until you apply the \"",
        "\"Your project may not work properly until you apply the"
    ],
    [
        "self.style.NOTICE(\"Run 'python manage.py migrate' to apply them.\")",
        "self.style.NOTICE(\"Run 'python manage.py migrate'"
    ],
    [
        "The actual logic of the command. Subclasses must implement",
        "The actual logic of the"
    ],
    [
        "\"subclasses of BaseCommand must provide a handle() method\"",
        "\"subclasses of BaseCommand must provide a handle()"
    ],
    [
        "A management command which takes one or more installed application labels",
        "A management command which takes one or more installed"
    ],
    [
        "as arguments, and does something with each of them.",
        "as arguments, and does something"
    ],
    [
        "Rather than implementing ``handle()``, subclasses must implement",
        "Rather than implementing ``handle()``, subclasses"
    ],
    [
        "``handle_app_config()``, which will be called once for each application.",
        "``handle_app_config()``, which will be called"
    ],
    [
        "missing_args_message = \"Enter at least one application label.\"",
        "missing_args_message = \"Enter at least"
    ],
    [
        "app_configs = [apps.get_app_config(app_label) for app_label in app_labels]",
        "app_configs = [apps.get_app_config(app_label) for app_label in"
    ],
    [
        "\"%s. Are you sure your INSTALLED_APPS setting is correct?\" % e",
        "\"%s. Are you sure your INSTALLED_APPS"
    ],
    [
        "Perform the command's actions for app_config, an AppConfig instance",
        "Perform the command's actions for"
    ],
    [
        "corresponding to an application label given on the command line.",
        "corresponding to an application label given on"
    ],
    [
        "\"Subclasses of AppCommand must provide a handle_app_config() method.\"",
        "\"Subclasses of AppCommand must provide a"
    ],
    [
        "A management command which takes one or more arbitrary arguments",
        "A management command which takes one or"
    ],
    [
        "(labels) on the command line, and does something with each of",
        "(labels) on the command line, and does something with each"
    ],
    [
        "Rather than implementing ``handle()``, subclasses must implement",
        "Rather than implementing ``handle()``, subclasses must"
    ],
    [
        "``handle_label()``, which will be called once for each label.",
        "``handle_label()``, which will be called once"
    ],
    [
        "If the arguments should be names of installed applications, use",
        "If the arguments should be names of installed applications,"
    ],
    [
        "missing_args_message = \"Enter at least one %s.\"",
        "missing_args_message = \"Enter at"
    ],
    [
        "Perform the command's actions for ``label``, which will be the",
        "Perform the command's actions for ``label``,"
    ],
    [
        "string as given on the command line.",
        "string as given on the command"
    ],
    [
        "\"subclasses of LabelCommand must provide a handle_label() method\"",
        "\"subclasses of LabelCommand must"
    ],
    [
        "help = \"Creates the tables needed to use the SQL cache backend.\"",
        "help = \"Creates the tables needed"
    ],
    [
        "\"Optional table names. Otherwise, settings.CACHES is used to find \"",
        "\"Optional table names. Otherwise, settings.CACHES"
    ],
    [
        "help=\"Nominates a database onto which the cache tables will be \"",
        "help=\"Nominates a database onto which the cache tables will"
    ],
    [
        "'installed. Defaults to the \"default\" database.',",
        "'installed. Defaults to the"
    ],
    [
        "help=\"Does not create the table, just prints the SQL that would be run.\",",
        "help=\"Does not create the table, just prints the SQL that"
    ],
    [
        "self.stdout.write(\"Cache table '%s' already exists.\" % tablename)",
        "self.stdout.write(\"Cache table '%s' already exists.\""
    ],
    [
        "\"%sNULL\" % (\"NOT \" if not f.null else \"\"),",
        "\"%sNULL\" % (\"NOT \" if not f.null else"
    ],
    [
        "unique = \"UNIQUE \" if f.unique else \"\"",
        "unique = \"UNIQUE \" if f.unique"
    ],
    [
        "\"CREATE %sINDEX %s ON %s (%s);\"",
        "\"CREATE %sINDEX %s"
    ],
    [
        "full_statement = [\"CREATE TABLE %s (\" % qn(tablename)]",
        "full_statement = [\"CREATE TABLE %s (\""
    ],
    [
        "\"Cache table '%s' could not be created.\\nThe error was: %s.\"",
        "\"Cache table '%s' could not be created.\\nThe error was:"
    ],
    [
        "self.stdout.write(\"Cache table '%s' created.\" % tablename)",
        "self.stdout.write(\"Cache table '%s'"
    ],
    [
        "\"Introspects the database tables in the given database and outputs a Django \"",
        "\"Introspects the database tables in the given"
    ],
    [
        "help=\"Selects what tables or views should be introspected.\",",
        "help=\"Selects what tables or views should be"
    ],
    [
        "'Nominates a database to introspect. Defaults to using the \"default\" '",
        "'Nominates a database to introspect. Defaults"
    ],
    [
        "help=\"Also output models for partition tables.\",",
        "help=\"Also output models for"
    ],
    [
        "help=\"Also output models for database views.\",",
        "help=\"Also output models"
    ],
    [
        "\"Database inspection isn't supported for the currently selected \"",
        "\"Database inspection isn't supported for the currently selected"
    ],
    [
        "\"Django to create, modify, and delete the table\"",
        "\"Django to create, modify,"
    ],
    [
        "yield \"from %s import models\" % self.db_module",
        "yield \"from %s import"
    ],
    [
        "table_info = {info.name: info for info in table_info if info.type in types}",
        "table_info = {info.name: info for info in"
    ],
    [
        "for table_name in options[\"table\"] or sorted(name for name in table_info):",
        "for table_name in options[\"table\"] or sorted(name for name"
    ],
    [
        "if table_name_filter is not None and callable(table_name_filter):",
        "if table_name_filter is not"
    ],
    [
        "fields = \", \".join([f\"'{col}'\" for col in primary_key_columns])",
        "fields = \", \".join([f\"'{col}'\""
    ],
    [
        "if ref_pk_column and ref_pk_column != ref_db_column:",
        "if ref_pk_column and ref_pk_column !="
    ],
    [
        "field_type = \"%s(%s\" % (rel_type, rel_to)",
        "field_type = \"%s(%s\""
    ],
    [
        "field_type = \"%s('%s'\" % (rel_type, rel_to)",
        "field_type = \"%s('%s'\" %"
    ],
    [
        "if att_name == \"id\" and extra_params == {\"primary_key\": True}:",
        "if att_name == \"id\" and extra_params == {\"primary_key\":"
    ],
    [
        "field_desc = \"%s = %s%s\" % (",
        "field_desc = \"%s = %s%s\" %"
    ],
    [
        "\"\" if \".\" in field_type else \"models.\",",
        "\"\" if \".\" in"
    ],
    [
        "\"%s=%r\" % (k, v) for k, v in extra_params.items()",
        "\"%s=%r\" % (k, v) for k, v"
    ],
    [
        "Modify the column name to make it Python-compatible as a field name",
        "Modify the column name to make it Python-compatible"
    ],
    [
        "new_name, num_repl = re.subn(r\"\\W\", \"_\", new_name)",
        "new_name, num_repl = re.subn(r\"\\W\","
    ],
    [
        "field_notes.append(\"Field renamed to remove unsuitable characters.\")",
        "field_notes.append(\"Field renamed to remove"
    ],
    [
        "\"Field renamed because it contained more than one '_' in a row.\"",
        "\"Field renamed because it contained more than one"
    ],
    [
        "field_notes.append(\"Field renamed because it started with '_'.\")",
        "field_notes.append(\"Field renamed because it started"
    ],
    [
        "field_notes.append(\"Field renamed because it ended with '_'.\")",
        "field_notes.append(\"Field renamed because it ended"
    ],
    [
        "field_notes.append(\"Field renamed because it was a Python reserved word.\")",
        "field_notes.append(\"Field renamed because it was a Python"
    ],
    [
        "\"Field renamed because it wasn't a valid Python identifier.\"",
        "\"Field renamed because it wasn't a valid"
    ],
    [
        "while \"%s_%d\" % (new_name, num) in used_column_names:",
        "while \"%s_%d\" % (new_name,"
    ],
    [
        "new_name = \"%s_%d\" % (new_name, num)",
        "new_name = \"%s_%d\""
    ],
    [
        "field_notes.append(\"Field renamed because of name conflict.\")",
        "field_notes.append(\"Field renamed because of"
    ],
    [
        "if col_name != new_name and field_notes:",
        "if col_name != new_name"
    ],
    [
        "\"\"\"Translate the table name to a Python-compatible model name.\"\"\"",
        "\"\"\"Translate the table name to a Python-compatible model"
    ],
    [
        "Given the database connection, the table name, and the cursor row",
        "Given the database connection, the table name, and the"
    ],
    [
        "description, this routine will return the given field type name, as",
        "description, this routine will return the given"
    ],
    [
        "well as any additional keyword parameters and notes for the field.",
        "well as any additional keyword parameters and notes for"
    ],
    [
        "field_notes.append(\"This field type is a guess.\")",
        "field_notes.append(\"This field type"
    ],
    [
        "if field_type == \"CharField\" and row.display_size:",
        "if field_type == \"CharField\""
    ],
    [
        "if field_type in {\"CharField\", \"TextField\"} and row.collation:",
        "if field_type in {\"CharField\","
    ],
    [
        "if row.precision is None or row.scale is None:",
        "if row.precision is None or row.scale is"
    ],
    [
        "\"max_digits and decimal_places have been guessed, as this \"",
        "\"max_digits and decimal_places have been guessed,"
    ],
    [
        "\"database handles decimal fields as float\"",
        "\"database handles decimal"
    ],
    [
        "Return a sequence comprising the lines of code necessary",
        "Return a sequence comprising the lines of"
    ],
    [
        "to construct the inner Meta class for the model corresponding",
        "to construct the inner Meta class"
    ],
    [
        "to the given database table name.",
        "to the given database table"
    ],
    [
        "x for x in columns if x is not None and x in column_to_field_name",
        "x for x in columns if x is not None and"
    ],
    [
        "\"        managed = False%s\" % managed_comment,",
        "\" managed ="
    ],
    [
        "\"        db_table = %r\" % table_name,",
        "\" db_table = %r\" %"
    ],
    [
        "tup = \"(\" + \", \".join(unique_together) + \",)\"",
        "tup = \"(\" + \","
    ],
    [
        "meta += [\"        unique_together = %s\" % tup]",
        "meta += [\" unique_together = %s\""
    ],
    [
        "meta += [f\"        db_table_comment = {comment!r}\"]",
        "meta += [f\" db_table_comment ="
    ],
    [
        "\"Squashes an existing set of migrations (from first until specified) into a \"",
        "\"Squashes an existing set of migrations (from first until specified) into a"
    ],
    [
        "help=\"App label of the application to squash migrations for.\",",
        "help=\"App label of the application to squash"
    ],
    [
        "\"Migrations will be squashed starting from and including this \"",
        "\"Migrations will be squashed starting from"
    ],
    [
        "help=\"Migrations will be squashed until and including this migration.\",",
        "help=\"Migrations will be squashed until and including this"
    ],
    [
        "help=\"Do not try to optimize the squashed operations.\",",
        "help=\"Do not try to optimize the squashed"
    ],
    [
        "help=\"Tells Django to NOT prompt the user for input of any kind.\",",
        "help=\"Tells Django to NOT prompt the user"
    ],
    [
        "help=\"Sets the name of the new squashed migration.\",",
        "help=\"Sets the name of the new squashed"
    ],
    [
        "help=\"Do not add a header comment to the new squashed migration.\",",
        "help=\"Do not add a header comment to the"
    ],
    [
        "\"App '%s' does not have migrations (so squashmigrations on \"",
        "\"App '%s' does not have migrations (so squashmigrations on"
    ],
    [
        "\"it makes no sense)\" % app_label",
        "\"it makes no"
    ],
    [
        "\"The migration '%s' cannot be found. Maybe it comes after \"",
        "\"The migration '%s' cannot be found. Maybe"
    ],
    [
        "\"to debug this issue.\" % (start_migration, migration, app_label)",
        "\"to debug this issue.\" % (start_migration, migration,"
    ],
    [
        "while not answer or answer not in \"yn\":",
        "while not answer or answer not"
    ],
    [
        "answer = input(\"Do you wish to proceed? [y/N] \")",
        "answer = input(\"Do you wish to"
    ],
    [
        "\"  Optimized from %s operations to %s operations.\"",
        "\" Optimized from %s operations"
    ],
    [
        "replaces = [(m.app_label, m.name) for m in migrations_to_squash]",
        "replaces = [(m.app_label, m.name) for m in"
    ],
    [
        "name = \"%s_%s\" % (prefix, squashed_name)",
        "name = \"%s_%s\" % (prefix,"
    ],
    [
        "name = \"%s_squashed_%s\" % (start_migration.name, migration.name)",
        "name = \"%s_squashed_%s\" % (start_migration.name,"
    ],
    [
        "f\"Migration {new_migration.name} already exists. Use a different name.\"",
        "f\"Migration {new_migration.name} already exists. Use a different"
    ],
    [
        "\"Created new squashed migration %s\" % writer.path",
        "\"Created new squashed migration"
    ],
    [
        "\"  You should commit this migration but leave the old ones in place;\\n\"",
        "\" You should commit this migration but leave"
    ],
    [
        "\"  the new migration will be used for new installs. Once you are sure\\n\"",
        "\" the new migration will be used for new"
    ],
    [
        "\"  all instances of the codebase have applied the migrations you \"",
        "\" all instances of the codebase have"
    ],
    [
        "\"  Your migrations contained functions that must be manually \"",
        "\" Your migrations contained functions that"
    ],
    [
        "\"  as we could not safely copy their implementation.\\n\"",
        "\" as we could not safely copy"
    ],
    [
        "\"  See the comment at the top of the squashed migration for \"",
        "\" See the comment at the top of the squashed migration for"
    ],
    [
        "\"Squashed migration couldn't be formatted using the \"",
        "\"Squashed migration couldn't be formatted using the"
    ],
    [
        "'\"black\" command. You can call it manually.'",
        "'\"black\" command. You can"
    ],
    [
        "\"More than one migration matches '%s' in app '%s'. Please be \"",
        "\"More than one migration matches '%s' in app '%s'. Please"
    ],
    [
        "\"Cannot find a migration matching '%s' from app '%s'.\"",
        "\"Cannot find a migration matching '%s' from"
    ],
    [
        "help = \"Checks the entire Django project for potential problems.\"",
        "help = \"Checks the entire Django"
    ],
    [
        "help=\"Run only checks labeled with given tag.\",",
        "help=\"Run only checks labeled with given"
    ],
    [
        "\"List available tags. Specify --deploy to include available deployment \"",
        "\"List available tags. Specify --deploy"
    ],
    [
        "\"Message level that will cause the command to exit with a \"",
        "\"Message level that will cause the command"
    ],
    [
        "help=\"Run database related checks against these aliases.\",",
        "help=\"Run database related checks"
    ],
    [
        "app_configs = [apps.get_app_config(app_label) for app_label in app_labels]",
        "app_configs = [apps.get_app_config(app_label) for app_label in"
    ],
    [
        "'There is no system check with the \"%s\" tag.' % invalid_tag",
        "'There is no system check with the \"%s\" tag.' %"
    ],
    [
        "\"Creates a Django app directory structure for the given app name in \"",
        "\"Creates a Django app directory structure for the given"
    ],
    [
        "\"the current directory or optionally in the given directory.\"",
        "\"the current directory or optionally in the given"
    ],
    [
        "missing_args_message = \"You must provide an application name.\"",
        "missing_args_message = \"You must"
    ],
    [
        "help = \"Optimizes the operations for the named migration.\"",
        "help = \"Optimizes the operations for the named"
    ],
    [
        "help=\"App label of the application to optimize the migration for.\",",
        "help=\"App label of the application to optimize the"
    ],
    [
        "\"migration_name\", help=\"Migration name to optimize the operations for.\"",
        "\"migration_name\", help=\"Migration name to optimize the operations"
    ],
    [
        "help=\"Exit with a non-zero status if the migration can be optimized.\",",
        "help=\"Exit with a non-zero status if the"
    ],
    [
        "raise CommandError(f\"App '{app_label}' does not have migrations.\")",
        "raise CommandError(f\"App '{app_label}' does not have"
    ],
    [
        "f\"More than one migration matches '{migration_name}' in app \"",
        "f\"More than one migration matches '{migration_name}' in"
    ],
    [
        "f\"Cannot find a migration matching '{migration_name}' from app \"",
        "f\"Cannot find a migration matching '{migration_name}' from app"
    ],
    [
        "\"Optimizing from %d operations to %d operations.\"",
        "\"Optimizing from %d operations"
    ],
    [
        "\"Migration will require manual porting but is already a squashed \"",
        "\"Migration will require manual porting but is"
    ],
    [
        "\"migration.\\nTransition to a normal migration first: \"",
        "\"migration.\\nTransition to a normal migration first:"
    ],
    [
        "\"  Your migrations contained functions that must be manually \"",
        "\" Your migrations contained functions that must be manually"
    ],
    [
        "\"  as we could not safely copy their implementation.\\n\"",
        "\" as we could not safely copy their"
    ],
    [
        "\"  See the comment at the top of the optimized migration for \"",
        "\" See the comment at the top of the optimized migration for"
    ],
    [
        "\"Optimized migration couldn't be formatted using the \"",
        "\"Optimized migration couldn't be formatted using the"
    ],
    [
        "'\"black\" command. You can call it manually.'",
        "'\"black\" command. You can call it"
    ],
    [
        "help = \"Prints the SQL statements for the named migration.\"",
        "help = \"Prints the SQL statements"
    ],
    [
        "\"app_label\", help=\"App label of the application containing the migration.\"",
        "\"app_label\", help=\"App label of the application containing"
    ],
    [
        "\"migration_name\", help=\"Migration name to print the SQL for.\"",
        "\"migration_name\", help=\"Migration name to print"
    ],
    [
        "'Nominates a database to create SQL for. Defaults to the \"default\" '",
        "'Nominates a database to create SQL for. Defaults to the \"default\""
    ],
    [
        "help=\"Creates SQL to unapply the migration, rather than to apply it\",",
        "help=\"Creates SQL to unapply the migration, rather than to apply"
    ],
    [
        "raise CommandError(\"App '%s' does not have migrations\" % app_label)",
        "raise CommandError(\"App '%s' does not have"
    ],
    [
        "\"More than one migration matches '%s' in app '%s'. Please be more \"",
        "\"More than one migration matches '%s' in app"
    ],
    [
        "\"Cannot find a migration matching '%s' from app '%s'. Is it in \"",
        "\"Cannot find a migration matching '%s' from app"
    ],
    [
        "from django.core.management.base import BaseCommand, CommandError, no_translations",
        "from django.core.management.base import BaseCommand,"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, OperationalError, connections, router",
        "from django.db import DEFAULT_DB_ALIAS, OperationalError,"
    ],
    [
        "help = \"Creates new migration(s) for apps.\"",
        "help = \"Creates new migration(s)"
    ],
    [
        "help=\"Specify the app label(s) to create migrations for.\",",
        "help=\"Specify the app label(s) to create migrations"
    ],
    [
        "help=\"Just show what migrations would be made; don't actually write them.\",",
        "help=\"Just show what migrations would be made; don't"
    ],
    [
        "help=\"Tells Django to NOT prompt the user for input of any kind.\",",
        "help=\"Tells Django to NOT prompt the"
    ],
    [
        "help=\"Use this name for migration file(s).\",",
        "help=\"Use this name"
    ],
    [
        "help=\"Do not add header comments to new migration file(s).\",",
        "help=\"Do not add header comments"
    ],
    [
        "\"Exit with a non-zero status if model changes are missing migrations \"",
        "\"Exit with a non-zero status if model changes are missing"
    ],
    [
        "\"and don't actually write them. Implies --dry-run.\"",
        "\"and don't actually write them. Implies"
    ],
    [
        "\"Divert log output and input prompts to stderr, writing only \"",
        "\"Divert log output and input prompts"
    ],
    [
        "\"paths of generated migration files to stdout.\"",
        "\"paths of generated migration files to"
    ],
    [
        "\"Merge model changes into the latest migration and optimize the \"",
        "\"Merge model changes into the latest migration"
    ],
    [
        "return self.stderr if self.scriptable else self.stdout",
        "return self.stderr if self.scriptable else"
    ],
    [
        "raise CommandError(\"The migration name must be a valid Python identifier.\")",
        "raise CommandError(\"The migration name must be a valid Python"
    ],
    [
        "consistency_check_labels = {config.label for config in apps.get_app_configs()}",
        "consistency_check_labels = {config.label for config in"
    ],
    [
        "if connection.settings_dict[\"ENGINE\"] != \"django.db.backends.dummy\" and any(",
        "if connection.settings_dict[\"ENGINE\"] !="
    ],
    [
        "\"Got an error checking a consistent migration history \"",
        "\"Got an error checking a"
    ],
    [
        "\"performed for database connection '%s': %s\" % (alias, error),",
        "\"performed for database connection '%s': %s\" %"
    ],
    [
        "\"%s in %s\" % (\", \".join(names), app) for app, names in conflicts.items()",
        "\"%s in %s\" % (\", \".join(names),"
    ],
    [
        "\"Conflicting migrations detected; multiple leaf nodes in the \"",
        "\"Conflicting migrations detected; multiple leaf nodes in"
    ],
    [
        "\"migration graph: (%s).\\nTo fix them run \"",
        "\"migration graph: (%s).\\nTo fix them run"
    ],
    [
        "\"'python manage.py makemigrations --merge'\" % name_str",
        "\"'python manage.py makemigrations --merge'\""
    ],
    [
        "\"You must supply at least one app label when using --empty.\"",
        "\"You must supply at least one"
    ],
    [
        "changes = {app: [Migration(\"custom\", app)] for app in app_labels}",
        "changes = {app: [Migration(\"custom\", app)] for app in"
    ],
    [
        "self.log(\"No changes detected in app '%s'\" % app_labels.pop())",
        "self.log(\"No changes detected in"
    ],
    [
        "\"No changes detected in apps '%s'\"",
        "\"No changes detected in"
    ],
    [
        "f\"App {app_label} has no migration, cannot update last migration.\"",
        "f\"App {app_label} has no migration, cannot update last"
    ],
    [
        "f\"Cannot update migration '{leaf_migration}' that migrations \"",
        "f\"Cannot update migration '{leaf_migration}' that"
    ],
    [
        "Take a changes dict and write them out as migration files.",
        "Take a changes dict and write"
    ],
    [
        "f\"Previous migration {rel_prev_path} was kept and \"",
        "f\"Previous migration {rel_prev_path} was"
    ],
    [
        "f\"must be deleted after porting functions manually.\"",
        "f\"must be deleted after porting"
    ],
    [
        "\"Full migrations file '%s':\" % writer.filename",
        "\"Full migrations file '%s':\" %"
    ],
    [
        "Handles merging together conflicted migrations interactively,",
        "Handles merging together conflicted migrations"
    ],
    [
        "if it's safe; otherwise, advises on how to fix it.",
        "if it's safe; otherwise, advises"
    ],
    [
        "merge_migrations_generations = zip(*(m.ancestry for m in merge_migrations))",
        "merge_migrations_generations = zip(*(m.ancestry for m in"
    ],
    [
        "\"Could not find common ancestor of %s\" % migration_names",
        "\"Could not find common ancestor of %s\" %"
    ],
    [
        "biggest_number = max(x for x in numbers if x is not None)",
        "biggest_number = max(x for x in numbers if"
    ],
    [
        "self.log(\"\\nCreated new merge migration %s\" % writer.path)",
        "self.log(\"\\nCreated new merge migration %s\" %"
    ],
    [
        "\"Full merge migrations file '%s':\" % writer.filename",
        "\"Full merge migrations file '%s':\""
    ],
    [
        "\"Returns a list of the SQL statements required to return all tables in \"",
        "\"Returns a list of the SQL statements required to return"
    ],
    [
        "\"the database to the state they were in just after they were installed.\"",
        "\"the database to the state they were in just after"
    ],
    [
        "'Nominates a database to print the SQL for. Defaults to the \"default\" '",
        "'Nominates a database to print the SQL for. Defaults to the"
    ],
    [
        "f\"Can't find {program}. Make sure you have GNU gettext tools \"",
        "f\"Can't find {program}. Make sure you have"
    ],
    [
        "Represent the state of a translatable file during the build process.",
        "Represent the state of a translatable file"
    ],
    [
        "Path to a file which is being fed into GNU gettext pipeline. This may",
        "Path to a file which is being fed into GNU gettext"
    ],
    [
        "be either a translatable or its preprocessed version.",
        "be either a translatable or its preprocessed"
    ],
    [
        "Preprocess (if necessary) a translatable file before passing it to",
        "Preprocess (if necessary) a translatable file before passing"
    ],
    [
        "Postprocess messages generated by xgettext GNU gettext utility.",
        "Postprocess messages generated by xgettext"
    ],
    [
        "Transform paths as if these messages were generated from original",
        "Transform paths as if these messages were generated from"
    ],
    [
        "translatable files rather than from preprocessed versions.",
        "translatable files rather than from"
    ],
    [
        "Remove a preprocessed copy of a translatable file (if any).",
        "Remove a preprocessed copy of"
    ],
    [
        "Take a block of raw text that will be passed through str.splitlines() to",
        "Take a block of raw text that will be passed"
    ],
    [
        "Return the resulting block of text with normalized `\\n` EOL sequences ready",
        "Return the resulting block of text with normalized"
    ],
    [
        "to be written to disk using current platform's native EOLs.",
        "to be written to disk"
    ],
    [
        "Write the `potfile` with the `msgs` contents, making sure its format is",
        "Write the `potfile` with the `msgs` contents, making sure its"
    ],
    [
        "if not found and not header_read:",
        "if not found and"
    ],
    [
        "if not line and not found:",
        "if not line"
    ],
    [
        "\"Runs over the entire source tree of the current directory and pulls out all \"",
        "\"Runs over the entire source tree of the current directory"
    ],
    [
        "\"strings marked for translation. It creates (or updates) a message file in the \"",
        "\"strings marked for translation. It creates (or"
    ],
    [
        "\"conf/locale (in the django tree) or locale (for projects and applications) \"",
        "\"conf/locale (in the django tree) or locale (for"
    ],
    [
        "\"directory.\\n\\nYou must run this command with one of either the --locale, \"",
        "\"directory.\\n\\nYou must run this command with one of either the"
    ],
    [
        "msgmerge_options = [\"-q\", \"--backup=none\", \"--previous\", \"--update\"]",
        "msgmerge_options = [\"-q\","
    ],
    [
        "\"Creates or updates the message files for the given locale(s) (e.g. \"",
        "\"Creates or updates the message files for the given locale(s)"
    ],
    [
        "\"pt_BR). Can be used multiple times.\"",
        "\"pt_BR). Can be used multiple"
    ],
    [
        "help=\"Locales to exclude. Default is none. Can be used multiple times.\",",
        "help=\"Locales to exclude. Default is none. Can be used multiple"
    ],
    [
        "help='The domain of the message files (default: \"django\").',",
        "help='The domain of the message files (default:"
    ],
    [
        "help=\"Updates the message files for all existing locales.\",",
        "help=\"Updates the message files for"
    ],
    [
        "help='The file extension(s) to examine (default: \"html,txt,py\", or \"js\" '",
        "help='The file extension(s) to examine (default:"
    ],
    [
        "'if the domain is \"djangojs\"). Separate multiple extensions with '",
        "'if the domain is \"djangojs\"). Separate multiple extensions"
    ],
    [
        "\"commas, or use -e multiple times.\",",
        "\"commas, or use -e"
    ],
    [
        "help=\"Follows symlinks to directories when examining source code \"",
        "help=\"Follows symlinks to directories when examining source code"
    ],
    [
        "help=\"Ignore files or directories matching this glob-style pattern. \"",
        "help=\"Ignore files or directories matching this glob-style pattern."
    ],
    [
        "\"Use multiple times to ignore more.\",",
        "\"Use multiple times"
    ],
    [
        "\"Don't ignore the common glob-style patterns 'CVS', '.*', '*~' and \"",
        "\"Don't ignore the common glob-style patterns 'CVS', '.*', '*~' and"
    ],
    [
        "help=\"Don't break long message lines into several lines.\",",
        "help=\"Don't break long message lines into several"
    ],
    [
        "\"(the default if not given), the lines  include both file name \"",
        "\"(the default if not given), the lines include both file name"
    ],
    [
        "\"and line number. If it's 'file', the line number is omitted. If \"",
        "\"and line number. If it's 'file', the line number is omitted. If"
    ],
    [
        "\"it's 'never', the lines are suppressed (same as --no-location). \"",
        "\"it's 'never', the lines are suppressed"
    ],
    [
        "help=\"Keep .pot file after making messages. Useful when debugging.\",",
        "help=\"Keep .pot file after making messages."
    ],
    [
        "ignore_patterns += [\"CVS\", \".*\", \"*~\", \"*.pyc\"]",
        "ignore_patterns += [\"CVS\","
    ],
    [
        "if self.domain not in (\"django\", \"djangojs\"):",
        "if self.domain not"
    ],
    [
        "\"currently makemessages only supports domains \"",
        "\"currently makemessages only supports"
    ],
    [
        "exts = extensions or [\"html\", \"txt\", \"py\"]",
        "exts = extensions or [\"html\", \"txt\","
    ],
    [
        "if (not locale and not exclude and not process_all) or self.domain is None:",
        "if (not locale and not exclude and not process_all) or self.domain is"
    ],
    [
        "\"Type '%s help %s' for usage information.\"",
        "\"Type '%s help %s' for usage"
    ],
    [
        "\"examining files with the extensions: %s\"",
        "\"examining files with the"
    ],
    [
        "\"invalid locale %s, did you mean %s?\"",
        "\"invalid locale %s, did you"
    ],
    [
        "return tuple(int(d) for d in m.groups() if d is not None)",
        "return tuple(int(d) for d in m.groups() if d"
    ],
    [
        "raise CommandError(\"Unable to get gettext version. Is it installed?\")",
        "raise CommandError(\"Unable to get gettext version. Is"
    ],
    [
        "Build pot files and apply msguniq to them.",
        "Build pot files and apply msguniq"
    ],
    [
        "potfile = os.path.join(path, \"%s.pot\" % self.domain)",
        "potfile = os.path.join(path,"
    ],
    [
        "args = [\"msguniq\"] + self.msguniq_options + [potfile]",
        "args = [\"msguniq\"] + self.msguniq_options"
    ],
    [
        "\"errors happened while running msguniq\\n%s\" % errors",
        "\"errors happened while running"
    ],
    [
        "pot_path = os.path.join(path, \"%s.pot\" % self.domain)",
        "pot_path = os.path.join(path,"
    ],
    [
        "Get all files in the given root. Also check that there is a matching",
        "Get all files in the given root. Also"
    ],
    [
        "for dirpath, dirnames, filenames in os.walk(",
        "for dirpath, dirnames,"
    ],
    [
        "if file_ext not in self.extensions or is_ignored_path(",
        "if file_ext not in self.extensions"
    ],
    [
        "\"ignoring file %s in %s\" % (filename, dirpath)",
        "\"ignoring file %s in %s\" % (filename,"
    ],
    [
        "locale_dir = locale_dir or self.default_locale_path or NO_LOCALE_DIR",
        "locale_dir = locale_dir or"
    ],
    [
        "Group translatable files by locale directory and run pot file build",
        "Group translatable files by locale directory and run"
    ],
    [
        "Extract translatable literals from the specified files, creating or",
        "Extract translatable literals from the specified files,"
    ],
    [
        "updating the POT file for a given locale directory.",
        "updating the POT file for a"
    ],
    [
        "Use the xgettext GNU gettext utility.",
        "Use the xgettext GNU gettext"
    ],
    [
        "if self.domain not in (\"djangojs\", \"django\"):",
        "if self.domain not in"
    ],
    [
        "\"UnicodeDecodeError: skipped file %s in %s (reason: %s)\"",
        "\"UnicodeDecodeError: skipped file %s in %s (reason:"
    ],
    [
        "input_files = [bf.work_path for bf in build_files]",
        "input_files = [bf.work_path for bf"
    ],
    [
        "\"errors happened while running xgettext on %s\\n%s\"",
        "\"errors happened while running xgettext"
    ],
    [
        "\"Unable to find a locale path to store translations for \"",
        "\"Unable to find a locale path to store"
    ],
    [
        "\"file %s. Make sure the 'locale' directory exists in an \"",
        "\"file %s. Make sure the 'locale' directory exists in an"
    ],
    [
        "\"app or LOCALE_PATHS setting is set.\" % file_path",
        "\"app or LOCALE_PATHS setting is set.\""
    ],
    [
        "potfile = os.path.join(locale_dir, \"%s.pot\" % self.domain)",
        "potfile = os.path.join(locale_dir,"
    ],
    [
        "Create or update the PO file for self.domain and `locale`.",
        "Create or update the PO"
    ],
    [
        "Use contents of the existing `potfile`.",
        "Use contents of the existing"
    ],
    [
        "Use msgmerge and msgattrib GNU gettext utilities.",
        "Use msgmerge and msgattrib GNU"
    ],
    [
        "pofile = os.path.join(basedir, \"%s.po\" % self.domain)",
        "pofile = os.path.join(basedir, \"%s.po\" %"
    ],
    [
        "args = [\"msgmerge\"] + self.msgmerge_options + [pofile, potfile]",
        "args = [\"msgmerge\"] + self.msgmerge_options +"
    ],
    [
        "\"errors happened while running msgmerge\\n%s\" % errors",
        "\"errors happened while running"
    ],
    [
        "args = [\"msgattrib\"] + self.msgattrib_options + [\"-o\", pofile, pofile]",
        "args = [\"msgattrib\"] + self.msgattrib_options"
    ],
    [
        "\"errors happened while running msgattrib\\n%s\" % errors",
        "\"errors happened while running msgattrib\\n%s\""
    ],
    [
        "Copy plural forms header contents from a Django catalog of locale to",
        "Copy plural forms header contents from a Django catalog of"
    ],
    [
        "the msgs string, inserting it at the right place. msgs should be the",
        "the msgs string, inserting it at the right place. msgs should"
    ],
    [
        "contents of a newly created .po file.",
        "contents of a newly created"
    ],
    [
        "django_dir, \"conf\", \"locale\", locale, \"LC_MESSAGES\", \"%s.po\" % domain",
        "django_dir, \"conf\", \"locale\", locale, \"LC_MESSAGES\", \"%s.po\" %"
    ],
    [
        "self.stdout.write(\"copying plural forms: %s\" % plural_form_line)",
        "self.stdout.write(\"copying plural forms:"
    ],
    [
        "if not found and (not line or plural_forms_re.search(line)):",
        "if not found and (not line or"
    ],
    [
        "from django.utils.module_loading import import_string as import_dotted_path",
        "from django.utils.module_loading import import_string as"
    ],
    [
        "\"Runs a Python interactive interpreter. Tries to use IPython or \"",
        "\"Runs a Python interactive interpreter. Tries to"
    ],
    [
        "\"bpython, if one of them is available. Any standard input is executed \"",
        "\"bpython, if one of them is available. Any standard input"
    ],
    [
        "\"When using plain Python, ignore the PYTHONSTARTUP environment \"",
        "\"When using plain Python, ignore the"
    ],
    [
        "\"Specify an interactive interpreter interface. Available options: \"",
        "\"Specify an interactive interpreter interface."
    ],
    [
        "\"Instead of opening an interactive shell, run a command as Django and \"",
        "\"Instead of opening an interactive shell, run"
    ],
    [
        "\"\"\"Return a sequence of import paths for objects to be auto-imported.",
        "\"\"\"Return a sequence of import paths for"
    ],
    [
        "By default, import paths for models in INSTALLED_APPS are included,",
        "By default, import paths for models in INSTALLED_APPS"
    ],
    [
        "with models from earlier apps taking precedence in case of a name",
        "with models from earlier apps taking"
    ],
    [
        "For example, for an unchanged INSTALLED_APPS, this method returns:",
        "For example, for an unchanged INSTALLED_APPS, this method"
    ],
    [
        "obj = import_dotted_path(path) if \".\" in path else import_module(path)",
        "obj = import_dotted_path(path) if \".\" in"
    ],
    [
        "name: obj for items in auto_imports.values() for name, obj in items",
        "name: obj for items in auto_imports.values() for name,"
    ],
    [
        "msg = \"\\n\".join(f\"  {e}\" for e in import_errors)",
        "msg = \"\\n\".join(f\" {e}\" for e in"
    ],
    [
        "f\"{errors} {objects} could not be automatically imported:\\n\\n{msg}\",",
        "f\"{errors} {objects} could not"
    ],
    [
        "msg = f\"{amount} {objects_str} imported automatically\"",
        "msg = f\"{amount} {objects_str} imported"
    ],
    [
        "[f\"  import {obj}\" for obj, _ in top_level]",
        "[f\" import {obj}\" for obj, _"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connections, router",
        "from django.db import DEFAULT_DB_ALIAS,"
    ],
    [
        "\"Output the contents of the database as a fixture of the given format \"",
        "\"Output the contents of the database as a fixture of the given format"
    ],
    [
        "\"(using each model's default manager unless --all is specified).\"",
        "\"(using each model's default manager"
    ],
    [
        "\"Restricts dumped data to the specified app_label or \"",
        "\"Restricts dumped data to the specified app_label or"
    ],
    [
        "help=\"Specifies the output serialization format for fixtures.\",",
        "help=\"Specifies the output serialization format for"
    ],
    [
        "help=\"Specifies the indent level to use when pretty-printing output.\",",
        "help=\"Specifies the indent level to use when"
    ],
    [
        "help=\"Nominates a specific database to dump fixtures from. \"",
        "help=\"Nominates a specific database to"
    ],
    [
        "help=\"An app_label or app_label.ModelName to exclude \"",
        "help=\"An app_label or app_label.ModelName to"
    ],
    [
        "\"(use multiple --exclude to exclude multiple apps/models).\",",
        "\"(use multiple --exclude to exclude multiple"
    ],
    [
        "help=\"Use natural foreign keys if they are available.\",",
        "help=\"Use natural foreign keys"
    ],
    [
        "help=\"Use natural primary keys if they are available.\",",
        "help=\"Use natural primary keys"
    ],
    [
        "\"Use Django's base manager to dump all models stored in the database, \"",
        "\"Use Django's base manager to dump all models stored in the"
    ],
    [
        "\"including those that would otherwise be filtered or modified by a \"",
        "\"including those that would otherwise be filtered or modified"
    ],
    [
        "help=\"Only dump objects with given primary keys. Accepts a comma-separated \"",
        "help=\"Only dump objects with given primary keys."
    ],
    [
        "\"list of keys. This option only works when you specify one model.\",",
        "\"list of keys. This option only works when you"
    ],
    [
        "\"-o\", \"--output\", help=\"Specifies file to which the output is written.\"",
        "\"-o\", \"--output\", help=\"Specifies file to which"
    ],
    [
        "primary_keys = [pk.strip() for pk in pks.split(\",\")]",
        "primary_keys = [pk.strip() for pk"
    ],
    [
        "raise CommandError(\"You can only use --pks option with one model\")",
        "raise CommandError(\"You can only use --pks option with one"
    ],
    [
        "raise CommandError(\"You can only use --pks option with one model\")",
        "raise CommandError(\"You can only use --pks"
    ],
    [
        "if app_config.models_module is None or app_config in excluded_apps:",
        "if app_config.models_module is None or"
    ],
    [
        "\"Unknown model: %s.%s\" % (app_label, model_label)",
        "\"Unknown model: %s.%s\" % (app_label,"
    ],
    [
        "if app_list_value is not None and model not in app_list_value:",
        "if app_list_value is not None and"
    ],
    [
        "\"You can only use --pks option with one model\"",
        "\"You can only use --pks option with one"
    ],
    [
        "if app_config.models_module is None or app_config in excluded_apps:",
        "if app_config.models_module is None"
    ],
    [
        "raise CommandError(\"Unknown serialization format: %s\" % format)",
        "raise CommandError(\"Unknown serialization format: %s\""
    ],
    [
        "Collate the objects to be serialized. If count_only is True, just",
        "Collate the objects to be serialized."
    ],
    [
        "count the number of objects to be serialized.",
        "count the number of objects to be"
    ],
    [
        "if model._meta.proxy and model._meta.proxy_for_model not in models:",
        "if model._meta.proxy and model._meta.proxy_for_model"
    ],
    [
        "\"%s is a proxy model and won't be serialized.\"",
        "\"%s is a proxy model and"
    ],
    [
        "if not model._meta.proxy and router.allow_migrate_model(using, model):",
        "if not model._meta.proxy"
    ],
    [
        "open_method, kwargs, file_path = (open, {}, output)",
        "open_method, kwargs, file_path = (open,"
    ],
    [
        "raise CommandError(\"Unable to serialize database: %s\" % e)",
        "raise CommandError(\"Unable to serialize database: %s\" %"
    ],
    [
        "from django.test.utils import NullTimeKeeper, TimeKeeper, get_runner",
        "from django.test.utils import NullTimeKeeper,"
    ],
    [
        "help = \"Discover and run tests in the specified modules or the current directory.\"",
        "help = \"Discover and run tests in the specified"
    ],
    [
        "Pre-parse the command line to extract the value of the --testrunner",
        "Pre-parse the command line to extract the value of the"
    ],
    [
        "option. This allows a test runner to define additional command line",
        "option. This allows a test runner to define additional command"
    ],
    [
        "\"Module paths to test; can be modulename, modulename.TestCase or \"",
        "\"Module paths to test; can"
    ],
    [
        "help=\"Tells Django to NOT prompt the user for input of any kind.\",",
        "help=\"Tells Django to NOT prompt the user"
    ],
    [
        "help=\"Tells Django to use specified test runner class instead of \"",
        "help=\"Tells Django to use specified test runner class instead of"
    ],
    [
        "\"the one specified by the TEST_RUNNER setting.\",",
        "\"the one specified by the TEST_RUNNER"
    ],
    [
        "time_keeper = TimeKeeper() if options.get(\"timing\", False) else NullTimeKeeper()",
        "time_keeper = TimeKeeper() if"
    ],
    [
        "\"Removes ALL DATA from the database, including data added during \"",
        "\"Removes ALL DATA from the database, including data added during"
    ],
    [
        "'migrations. Does not achieve a \"fresh install\" state.'",
        "'migrations. Does not achieve a \"fresh"
    ],
    [
        "help=\"Tells Django to NOT prompt the user for input of any kind.\",",
        "help=\"Tells Django to NOT prompt the user for input of any"
    ],
    [
        "help='Nominates a database to flush. Defaults to the \"default\" database.',",
        "help='Nominates a database to flush. Defaults"
    ],
    [
        "\"\"\"You have requested a flush of the database.",
        "\"\"\"You have requested a flush of"
    ],
    [
        "This will IRREVERSIBLY DESTROY all data currently in the \"%s\" database,",
        "This will IRREVERSIBLY DESTROY all data"
    ],
    [
        "and return each table to an empty state.",
        "and return each table to"
    ],
    [
        "Are you sure you want to do this?",
        "Are you sure you want"
    ],
    [
        "Type 'yes' to continue, or 'no' to cancel: \"\"\"",
        "Type 'yes' to continue, or 'no' to cancel:"
    ],
    [
        "\"Database %s couldn't be flushed. Possible reasons:\\n\"",
        "\"Database %s couldn't be"
    ],
    [
        "\"  * The database isn't running or isn't configured correctly.\\n\"",
        "\" * The database isn't running or"
    ],
    [
        "\"  * At least one of the expected database tables doesn't exist.\\n\"",
        "\" * At least one of the expected database tables"
    ],
    [
        "\"  * The SQL was invalid.\\n\"",
        "\" * The SQL"
    ],
    [
        "\"Hint: Look at the output of 'django-admin sqlflush'. \"",
        "\"Hint: Look at the output of 'django-admin sqlflush'."
    ],
    [
        "\"That's the SQL this command wasn't able to run.\"",
        "\"That's the SQL this command wasn't able"
    ],
    [
        "help = \"Installs the named fixture(s) in the database.\"",
        "help = \"Installs the named fixture(s)"
    ],
    [
        "\"No database fixture specified. Please provide the path of at least \"",
        "\"No database fixture specified. Please provide the path of at least"
    ],
    [
        "\"one fixture in the command line.\"",
        "\"one fixture in the command"
    ],
    [
        "\"Nominates a specific database to load fixtures into. Defaults to the \"",
        "\"Nominates a specific database to load fixtures into. Defaults to"
    ],
    [
        "help=\"Only look for fixtures in the specified app.\",",
        "help=\"Only look for fixtures"
    ],
    [
        "help=\"Ignores entries in the serialized data for fields that do not \"",
        "help=\"Ignores entries in the serialized data for fields that do"
    ],
    [
        "\"An app_label or app_label.ModelName to exclude. Can be used multiple \"",
        "\"An app_label or app_label.ModelName to exclude."
    ],
    [
        "help=\"Format of serialized data when reading from stdin.\",",
        "help=\"Format of serialized data when"
    ],
    [
        "\"\"\"A dict mapping format names to (open function, mode arg) tuples.\"\"\"",
        "\"\"\"A dict mapping format names to (open function, mode"
    ],
    [
        "\"\"\"Reset database sequences for the given connection and models.\"\"\"",
        "\"\"\"Reset database sequences for the given"
    ],
    [
        "table_names = [model._meta.db_table for model in self.models]",
        "table_names = [model._meta.db_table for model"
    ],
    [
        "e.args = (\"Problem installing fixtures: %s\" % e,)",
        "e.args = (\"Problem installing fixtures: %s\""
    ],
    [
        "\"Installed %d object(s) from %d fixture(s)\"",
        "\"Installed %d object(s) from %d"
    ],
    [
        "\"Installed %d object(s) (of %d) from %d fixture(s)\"",
        "\"Installed %d object(s) (of"
    ],
    [
        "except (DatabaseError, IntegrityError, ValueError) as e:",
        "except (DatabaseError, IntegrityError,"
    ],
    [
        "\"\"\"Load fixtures files for a given label.\"\"\"",
        "\"\"\"Load fixtures files for a given"
    ],
    [
        "for fixture_file, fixture_dir, fixture_name in self.find_fixtures(",
        "for fixture_file, fixture_dir, fixture_name in"
    ],
    [
        "\"Installing %s fixture '%s' from %s.\"",
        "\"Installing %s fixture"
    ],
    [
        "\"Problem installing fixture '%s': %s\" % (fixture_file, e),",
        "\"Problem installing fixture '%s': %s\" %"
    ],
    [
        "\"No fixture data found for '%s'. (File format may be \"",
        "\"No fixture data found for '%s'. (File format may be"
    ],
    [
        "fixture_dirs = [os.path.join(dir_, dirname) for dir_ in fixture_dirs]",
        "fixture_dirs = [os.path.join(dir_, dirname)"
    ],
    [
        "cmp_fmts = self.compression_formats if cmp_fmt is None else [cmp_fmt]",
        "cmp_fmts = self.compression_formats if cmp_fmt"
    ],
    [
        "ser_fmts = self.serialization_formats if ser_fmt is None else [ser_fmt]",
        "ser_fmts = self.serialization_formats if ser_fmt is None else"
    ],
    [
        "\".\".join([ext for ext in combo if ext]),",
        "\".\".join([ext for ext in"
    ],
    [
        "for combo in product(databases, ser_fmts, cmp_fmts)",
        "for combo in product(databases, ser_fmts,"
    ],
    [
        "for candidate in glob.iglob(glob.escape(path) + \"*\"):",
        "for candidate in glob.iglob(glob.escape(path) +"
    ],
    [
        "\"\"\"Find fixture files for a given label.\"\"\"",
        "\"\"\"Find fixture files for a"
    ],
    [
        "self.stdout.write(\"Checking %s for fixtures...\" % humanize(fixture_dir))",
        "self.stdout.write(\"Checking %s for fixtures...\""
    ],
    [
        "\"No fixture '%s' in %s.\" % (fixture_name, humanize(fixture_dir))",
        "\"No fixture '%s' in %s.\" %"
    ],
    [
        "\"Multiple fixtures named '%s' in %s. Aborting.\"",
        "\"Multiple fixtures named '%s'"
    ],
    [
        "raise CommandError(\"No fixture named '%s' found.\" % fixture_name)",
        "raise CommandError(\"No fixture named '%s' found.\" %"
    ],
    [
        "Return a list of fixture directories.",
        "Return a list of"
    ],
    [
        "The list contains the 'fixtures' subdirectory of each installed",
        "The list contains the 'fixtures' subdirectory"
    ],
    [
        "application, if it exists, the directories in FIXTURE_DIRS, and the",
        "application, if it exists, the directories in"
    ],
    [
        "if app_dir in [str(d) for d in fixture_dirs]:",
        "if app_dir in [str(d)"
    ],
    [
        "\"'%s' is a default fixture directory for the '%s' app \"",
        "\"'%s' is a default fixture directory for the '%s' app"
    ],
    [
        "\"and cannot be listed in settings.FIXTURE_DIRS.\"",
        "\"and cannot be listed"
    ],
    [
        "if self.app_label and app_label != self.app_label:",
        "if self.app_label and"
    ],
    [
        "return [os.path.realpath(d) for d in dirs]",
        "return [os.path.realpath(d) for"
    ],
    [
        "Split fixture name in name, serialization format, compression format.",
        "Split fixture name in name, serialization"
    ],
    [
        "\"--format must be specified when reading from stdin.\"",
        "\"--format must be specified"
    ],
    [
        "\"Problem installing fixture '%s': %s is not a known \"",
        "\"Problem installing fixture '%s': %s is not a"
    ],
    [
        "raise ValueError(\"Zip-compressed fixtures must contain one file.\")",
        "raise ValueError(\"Zip-compressed fixtures must contain one"
    ],
    [
        "return \"'%s'\" % dirname if dirname else \"absolute path\"",
        "return \"'%s'\" % dirname if dirname"
    ],
    [
        "from django.core.servers.basehttp import WSGIServer, get_internal_wsgi_application, run",
        "from django.core.servers.basehttp import WSGIServer,"
    ],
    [
        "help = \"Starts a lightweight web server for development.\"",
        "help = \"Starts a lightweight web server for"
    ],
    [
        "\"addrport\", nargs=\"?\", help=\"Optional port number, or ipaddr:port\"",
        "\"addrport\", nargs=\"?\", help=\"Optional port"
    ],
    [
        "help=\"Tells Django to NOT use threading.\",",
        "help=\"Tells Django to"
    ],
    [
        "help=\"Tells Django to NOT use the auto-reloader.\",",
        "help=\"Tells Django to NOT use"
    ],
    [
        "\"\"\"Return the default WSGI handler for the runner.\"\"\"",
        "\"\"\"Return the default WSGI handler"
    ],
    [
        "\"\"\"Validation is called explicitly each time the server reloads.\"\"\"",
        "\"\"\"Validation is called explicitly each time the"
    ],
    [
        "if not settings.DEBUG and not settings.ALLOWED_HOSTS:",
        "if not settings.DEBUG"
    ],
    [
        "raise CommandError(\"You must set settings.ALLOWED_HOSTS if DEBUG is False.\")",
        "raise CommandError(\"You must set settings.ALLOWED_HOSTS if DEBUG"
    ],
    [
        "'\"%s\" is not a valid port number '",
        "'\"%s\" is not a"
    ],
    [
        "raise CommandError(\"%r is not a valid port number.\" % self.port)",
        "raise CommandError(\"%r is not a"
    ],
    [
        "\"\"\"Run the server, using the autoreloader if needed.\"\"\"",
        "\"\"\"Run the server, using"
    ],
    [
        "errno.EACCES: \"You don't have permission to access that port.\",",
        "errno.EACCES: \"You don't have permission to access"
    ],
    [
        "errno.EADDRINUSE: \"That port is already in use.\",",
        "errno.EADDRINUSE: \"That port is already in"
    ],
    [
        "errno.EADDRNOTAVAIL: \"That IP address can't be assigned to.\",",
        "errno.EADDRNOTAVAIL: \"That IP address"
    ],
    [
        "now = datetime.now().strftime(\"%B %d, %Y - %X\")",
        "now = datetime.now().strftime(\"%B %d,"
    ],
    [
        "f\"Django version {version}, using settings {settings.SETTINGS_MODULE!r}\\n\"",
        "f\"Django version {version}, using"
    ],
    [
        "\"WARNING: This is a development server. Do not use it in a \"",
        "\"WARNING: This is a development server. Do not use"
    ],
    [
        "\"production setting. Use a production WSGI or ASGI server \"",
        "\"production setting. Use a production WSGI or ASGI"
    ],
    [
        "\"instead.\\nFor more information on production servers see: \"",
        "\"instead.\\nFor more information on production servers"
    ],
    [
        "help = \"Shows all available migrations for the current project\"",
        "help = \"Shows all available migrations for"
    ],
    [
        "help=\"App labels of applications to limit the output to.\",",
        "help=\"App labels of applications to limit the"
    ],
    [
        "\"Nominates a database to show migrations for. Defaults to the \"",
        "\"Nominates a database to show migrations for. Defaults"
    ],
    [
        "\"Shows a list of all migrations and which are applied. \"",
        "\"Shows a list of all migrations and which are"
    ],
    [
        "\"Shows all migrations in the order they will be applied. With a \"",
        "\"Shows all migrations in the order they will"
    ],
    [
        "\"reverse dependencies (run_before) will be included.\"",
        "\"reverse dependencies (run_before) will"
    ],
    [
        "Show a list of all migrations on the system, or only those of",
        "Show a list of all migrations on the system, or"
    ],
    [
        "title += \" (%s squashed migrations)\" % len(",
        "title += \" (%s"
    ],
    [
        "output = \" [X] %s\" % title",
        "output = \" [X] %s\""
    ],
    [
        "title += \" Run 'manage.py migrate' to finish recording.\"",
        "title += \" Run 'manage.py migrate'"
    ],
    [
        "output = \" [-] %s\" % title",
        "output = \" [-] %s\" %"
    ],
    [
        "self.stdout.write(\" [ ] %s\" % title)",
        "self.stdout.write(\" [ ] %s\" %"
    ],
    [
        "Show all known migrations (or only those of the specified app_names)",
        "Show all known migrations (or only"
    ],
    [
        "in the order they will be applied.",
        "in the order they"
    ],
    [
        "return \" ... (%s)\" % \", \".join(out)",
        "return \" ... (%s)\" %"
    ],
    [
        "\"Prints the SQL statements for resetting sequences for the given app name(s).\"",
        "\"Prints the SQL statements for resetting sequences for the given"
    ],
    [
        "'Nominates a database to print the SQL for. Defaults to the \"default\" '",
        "'Nominates a database to print the SQL"
    ],
    [
        "\"Runs the command-line client for specified database, or the \"",
        "\"Runs the command-line client for specified database,"
    ],
    [
        "\"default database if none is provided.\"",
        "\"default database if none"
    ],
    [
        "\"Nominates a database onto which to open a shell. Defaults to the \"",
        "\"Nominates a database onto which to open"
    ],
    [
        "\"You appear not to have the %r program installed or on your path.\"",
        "\"You appear not to have the %r program installed or"
    ],
    [
        "'\"%s\" returned non-zero exit status %s.'",
        "'\"%s\" returned non-zero"
    ],
    [
        "from django.core.mail import mail_admins, mail_managers, send_mail",
        "from django.core.mail import mail_admins,"
    ],
    [
        "help = \"Sends a test email to the email addresses specified as arguments.\"",
        "help = \"Sends a test email to the email addresses specified as"
    ],
    [
        "\"You must specify some email recipients, or pass the --managers or --admin \"",
        "\"You must specify some email recipients, or pass the --managers or --admin"
    ],
    [
        "help=\"One or more email addresses to send a test email to.\",",
        "help=\"One or more email addresses to send a test"
    ],
    [
        "help=\"Send a test email to the addresses specified in settings.MANAGERS.\",",
        "help=\"Send a test email to the addresses specified"
    ],
    [
        "help=\"Send a test email to the addresses specified in settings.ADMINS.\",",
        "help=\"Send a test email to the addresses specified"
    ],
    [
        "subject = \"Test email from %s on %s\" % (socket.gethostname(), timezone.now())",
        "subject = \"Test email from %s on %s\""
    ],
    [
        "message=\"If you're reading this, it was successful.\",",
        "message=\"If you're reading this, it was"
    ],
    [
        "mail_managers(subject, \"This email was sent to the site managers.\")",
        "mail_managers(subject, \"This email was sent to the"
    ],
    [
        "mail_admins(subject, \"This email was sent to the site admins.\")",
        "mail_admins(subject, \"This email was sent to"
    ],
    [
        "\"Creates a Django project directory structure for the given project \"",
        "\"Creates a Django project directory structure for"
    ],
    [
        "\"name in the current directory or optionally in the given directory.\"",
        "\"name in the current directory or optionally"
    ],
    [
        "missing_args_message = \"You must provide a project name.\"",
        "missing_args_message = \"You must provide"
    ],
    [
        "from django.core.management.base import BaseCommand, CommandError, no_translations",
        "from django.core.management.base import BaseCommand, CommandError,"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connections, router",
        "from django.db import DEFAULT_DB_ALIAS,"
    ],
    [
        "\"Updates database schema. Manages both apps with migrations and those without.\"",
        "\"Updates database schema. Manages both apps with migrations and"
    ],
    [
        "help=\"App label of an application to synchronize the state.\",",
        "help=\"App label of an application to synchronize"
    ],
    [
        "help=\"Database state will be brought to the state after that \"",
        "help=\"Database state will be brought to"
    ],
    [
        "'migration. Use the name \"zero\" to unapply all migrations.',",
        "'migration. Use the name \"zero\" to unapply all"
    ],
    [
        "help=\"Tells Django to NOT prompt the user for input of any kind.\",",
        "help=\"Tells Django to NOT prompt the user for input of"
    ],
    [
        "'Nominates a database to synchronize. Defaults to the \"default\" '",
        "'Nominates a database to synchronize."
    ],
    [
        "help=\"Mark migrations as run without actually running them.\",",
        "help=\"Mark migrations as run without actually"
    ],
    [
        "\"Detect if tables already exist and fake-apply initial migrations if \"",
        "\"Detect if tables already exist and fake-apply initial migrations if"
    ],
    [
        "\"so. Make sure that the current database schema matches your initial \"",
        "\"so. Make sure that the current database schema matches"
    ],
    [
        "\"migration before using this flag. Django will only check for an \"",
        "\"migration before using this flag. Django will only check"
    ],
    [
        "help=\"Shows a list of the migration actions that will be performed.\",",
        "help=\"Shows a list of the migration actions"
    ],
    [
        "help=\"Creates tables for apps without migrations.\",",
        "help=\"Creates tables for"
    ],
    [
        "\"Exits with a non-zero status if unapplied migrations exist and does \"",
        "\"Exits with a non-zero status if unapplied migrations exist"
    ],
    [
        "help=\"Delete nonexistent migrations from the django_migrations table.\",",
        "help=\"Delete nonexistent migrations from the django_migrations"
    ],
    [
        "\"%s in %s\" % (\", \".join(names), app) for app, names in conflicts.items()",
        "\"%s in %s\" % (\", \".join(names), app) for app,"
    ],
    [
        "\"Conflicting migrations detected; multiple leaf nodes in the \"",
        "\"Conflicting migrations detected; multiple leaf"
    ],
    [
        "\"migration graph: (%s).\\nTo fix them run \"",
        "\"migration graph: (%s).\\nTo fix"
    ],
    [
        "\"'python manage.py makemigrations --merge'\" % name_str",
        "\"'python manage.py makemigrations --merge'\" %"
    ],
    [
        "\"Can't use run_syncdb with app '%s' as it has migrations.\"",
        "\"Can't use run_syncdb with app"
    ],
    [
        "raise CommandError(\"App '%s' does not have migrations.\" % app_label)",
        "raise CommandError(\"App '%s' does not have migrations.\" %"
    ],
    [
        "\"More than one migration matches '%s' in app '%s'. \"",
        "\"More than one migration matches"
    ],
    [
        "\"Please be more specific.\" % (migration_name, app_label)",
        "\"Please be more specific.\" % (migration_name,"
    ],
    [
        "\"Cannot find a migration matching '%s' from app '%s'.\"",
        "\"Cannot find a migration matching"
    ],
    [
        "\"Migrations can be pruned only when an app is specified.\"",
        "\"Migrations can be pruned only when an"
    ],
    [
        "if any(replaced in to_prune for replaced in migration_obj.replaces)",
        "if any(replaced in to_prune"
    ],
    [
        "\"  Cannot use --prune because the following squashed \"",
        "\" Cannot use --prune because the following"
    ],
    [
        "\"migrations have their 'replaces' attributes and may not \"",
        "\"migrations have their 'replaces' attributes and"
    ],
    [
        "\"  Re-run 'manage.py migrate' if they are not marked as \"",
        "\" Re-run 'manage.py migrate' if they"
    ],
    [
        "\"applied, and remove 'replaces' attributes in their \"",
        "\"applied, and remove 'replaces'"
    ],
    [
        "style = self.style.WARNING if is_error else None",
        "style = self.style.WARNING if is_error else"
    ],
    [
        "\"  Synchronize unmigrated app: %s\" % app_label",
        "\" Synchronize unmigrated app: %s\" %"
    ],
    [
        "+ (\", \".join(sorted({a for a, n in targets})) or \"(none)\")",
        "+ (\", \".join(sorted({a for a, n in"
    ],
    [
        "\"  Your models in app(s): %s have changes that are not \"",
        "\" Your models in app(s): %s have changes"
    ],
    [
        "\"yet reflected in a migration, and so won't be \"",
        "\"yet reflected in a migration, and so won't be"
    ],
    [
        "\"applied.\" % \", \".join(repr(app) for app in sorted(changes))",
        "\"applied.\" % \", \".join(repr(app)"
    ],
    [
        "\"  Run 'manage.py makemigrations' to make new \"",
        "\" Run 'manage.py makemigrations'"
    ],
    [
        "\"migrations, and then re-run 'manage.py migrate' to \"",
        "\"migrations, and then re-run 'manage.py migrate'"
    ],
    [
        "self.stdout.write(\"  Applying %s...\" % migration, ending=\"\")",
        "self.stdout.write(\" Applying %s...\""
    ],
    [
        "self.stdout.write(\"  Unapplying %s...\" % migration, ending=\"\")",
        "self.stdout.write(\" Unapplying %s...\" %"
    ],
    [
        "\"\"\"Run the old syncdb-style operation on a list of app_labels.\"\"\"",
        "\"\"\"Run the old syncdb-style operation on"
    ],
    [
        "if app_config.models_module is not None and app_config.label in app_labels",
        "if app_config.models_module is not None and app_config.label in"
    ],
    [
        "\"    Creating table %s\" % model._meta.db_table",
        "\" Creating table"
    ],
    [
        "\"\"\"Return a string that describes a migration operation for --plan.\"\"\"",
        "\"\"\"Return a string that describes a migration operation for"
    ],
    [
        "code = operation.reverse_code if backwards else operation.code",
        "code = operation.reverse_code if backwards"
    ],
    [
        "action = (code.__doc__ or \"\") if code else None",
        "action = (code.__doc__ or \"\") if code else"
    ],
    [
        "action = operation.reverse_sql if backwards else operation.sql",
        "action = operation.reverse_sql if"
    ],
    [
        "action = \" -> \" + action",
        "action = \" -> \" +"
    ],
    [
        "from django.core.management.utils import find_command, is_ignored_path, popen_wrapper",
        "from django.core.management.utils import find_command,"
    ],
    [
        "help = \"Compiles .po files to .mo files for use with builtin gettext support.\"",
        "help = \"Compiles .po files to .mo files"
    ],
    [
        "help=\"Locale(s) to process (e.g. de_AT). Default is to process all. \"",
        "help=\"Locale(s) to process (e.g. de_AT). Default is to"
    ],
    [
        "help=\"Locales to exclude. Default is none. Can be used multiple times.\",",
        "help=\"Locales to exclude. Default is none. Can be"
    ],
    [
        "help=\"Ignore directories matching this glob-style pattern. \"",
        "help=\"Ignore directories matching this"
    ],
    [
        "\"Use multiple times to ignore more.\",",
        "\"Use multiple times to"
    ],
    [
        "f\"Can't find {self.program}. Make sure you have GNU gettext \"",
        "f\"Can't find {self.program}. Make sure"
    ],
    [
        "for dirpath, dirnames, filenames in os.walk(\".\", topdown=True):",
        "for dirpath, dirnames, filenames"
    ],
    [
        "\"This script should be run from the Django Git \"",
        "\"This script should be run from"
    ],
    [
        "\"checkout or your project or app tree, or with \"",
        "\"checkout or your project or app tree,"
    ],
    [
        "locale_dirs = filter(os.path.isdir, glob.glob(\"%s/*\" % basedir))",
        "locale_dirs = filter(os.path.isdir,"
    ],
    [
        "os.path.join(basedir, locale, \"LC_MESSAGES\") for locale in locales",
        "os.path.join(basedir, locale, \"LC_MESSAGES\") for locale in"
    ],
    [
        "for dirpath, dirnames, filenames in os.walk(ldir):",
        "for dirpath, dirnames, filenames"
    ],
    [
        "(dirpath, f) for f in filenames if f.endswith(\".po\")",
        "(dirpath, f) for f in filenames"
    ],
    [
        "raise CommandError(\"compilemessages generated one or more errors.\")",
        "raise CommandError(\"compilemessages generated one or more"
    ],
    [
        "Locations is a list of tuples: [(directory, file), ...]",
        "Locations is a list of tuples:"
    ],
    [
        "for i, (dirpath, f) in enumerate(locations):",
        "for i, (dirpath, f)"
    ],
    [
        "\"File “%s” is already compiled and up to date.\"",
        "\"File “%s” is already compiled"
    ],
    [
        "self.stdout.write(\"processing file %s in %s\" % (f, dirpath))",
        "self.stdout.write(\"processing file %s in %s\" %"
    ],
    [
        "\"The %s file has a BOM (Byte Order Mark). Django only \"",
        "\"The %s file has a BOM (Byte"
    ],
    [
        "\"The po files under %s are in a seemingly not writable \"",
        "\"The po files under %s are"
    ],
    [
        "\"location. mo files will not be updated/created.\" % dirpath",
        "\"location. mo files will not be"
    ],
    [
        "args = [self.program, *self.program_options, \"-o\", mo_path, po_path]",
        "args = [self.program, *self.program_options, \"-o\","
    ],
    [
        "\"Execution of %s failed: %s\" % (self.program, errors)",
        "\"Execution of %s failed: %s\" %"
    ],
    [
        "self.stderr.write(\"Execution of %s failed\" % self.program)",
        "self.stderr.write(\"Execution of %s failed\""
    ],
    [
        "def module_to_dict(module, omittable=lambda k: k.startswith(\"_\") or not k.isupper()):",
        "def module_to_dict(module, omittable=lambda k:"
    ],
    [
        "\"\"\"Convert a module namespace to a Python dictionary.\"\"\"",
        "\"\"\"Convert a module namespace to a Python"
    ],
    [
        "return {k: repr(getattr(module, k)) for k in dir(module) if not omittable(k)}",
        "return {k: repr(getattr(module, k)) for k in dir(module) if not"
    ],
    [
        "help = \"\"\"Displays differences between the current settings.py and Django's",
        "help = \"\"\"Displays differences between the current settings.py and"
    ],
    [
        "'Display all settings, regardless of their value. In \"hash\" '",
        "'Display all settings, regardless of"
    ],
    [
        "\"The settings module to compare the current settings against. Leave \"",
        "\"The settings module to compare the"
    ],
    [
        "\"empty to compare against Django's default settings.\"",
        "\"empty to compare against Django's default"
    ],
    [
        "\"Selects the output format. 'hash' mode displays each changed \"",
        "\"Selects the output format. 'hash' mode displays each"
    ],
    [
        "\"setting, with the settings that don't appear in the defaults \"",
        "\"setting, with the settings that don't"
    ],
    [
        "\"with a minus sign, followed by the changed setting prefixed \"",
        "\"with a minus sign, followed by"
    ],
    [
        "from django.conf import Settings, global_settings, settings",
        "from django.conf import Settings, global_settings,"
    ],
    [
        "output.append(\"%s = %s\" % (key, user_settings[key]))",
        "output.append(\"%s = %s\" %"
    ],
    [
        "self.style.SUCCESS(\"+ %s = %s\" % (key, user_settings[key]))",
        "self.style.SUCCESS(\"+ %s = %s\""
    ],
    [
        "self.style.ERROR(\"- %s = %s\" % (key, default_settings[key]))",
        "self.style.ERROR(\"- %s = %s\" % (key,"
    ],
    [
        "self.style.SUCCESS(\"+ %s = %s\" % (key, user_settings[key]))",
        "self.style.SUCCESS(\"+ %s = %s\" %"
    ],
    [
        "output.append(\"  %s = %s\" % (key, user_settings[key]))",
        "output.append(\" %s = %s\""
    ],
    [
        "help = \"Runs a development server with data from the given fixture(s).\"",
        "help = \"Runs a development server with"
    ],
    [
        "help=\"Path(s) to fixtures to load before running the server.\",",
        "help=\"Path(s) to fixtures to load before running the"
    ],
    [
        "help=\"Tells Django to NOT prompt the user for input of any kind.\",",
        "help=\"Tells Django to NOT prompt the user for input of any"
    ],
    [
        "help=\"Port number or ipaddr:port to run the server on.\",",
        "help=\"Port number or ipaddr:port to run the server"
    ],
    [
        "\"\\nServer stopped.\\nNote that the test database, %r, has not been \"",
        "\"\\nServer stopped.\\nNote that the test database, %r, has"
    ],
    [
        "\"deleted. You can explore it on your own.\" % db_name",
        "\"deleted. You can explore it"
    ],
    [
        "Requires PyYaml (https://pyyaml.org/), but that's checked for in __init__.",
        "Requires PyYaml (https://pyyaml.org/), but that's checked for in"
    ],
    [
        "from django.core.serializers.python import Deserializer as PythonDeserializer",
        "from django.core.serializers.python import"
    ],
    [
        "from django.core.serializers.python import Serializer as PythonSerializer",
        "from django.core.serializers.python import Serializer"
    ],
    [
        "from yaml import CSafeDumper as SafeDumper",
        "from yaml import"
    ],
    [
        "from yaml import CSafeLoader as SafeLoader",
        "from yaml import CSafeLoader"
    ],
    [
        "\"\"\"Deserialize a stream or string of YAML data.\"\"\"",
        "\"\"\"Deserialize a stream or string"
    ],
    [
        "raise DeserializationError(f\"Error deserializing object: {exc}\") from exc",
        "raise DeserializationError(f\"Error deserializing object:"
    ],
    [
        "To add your own serializers, use the SERIALIZATION_MODULES setting::",
        "To add your own serializers, use"
    ],
    [
        "Stub serializer to hold exception raised during registration",
        "Stub serializer to hold"
    ],
    [
        "This allows the serializer registration to cache serializers and if there",
        "This allows the serializer registration to cache serializers"
    ],
    [
        "is an error raised in the process of creating a serializer it will be",
        "is an error raised in the process of"
    ],
    [
        "raised and passed along to the caller when the serializer is used.",
        "raised and passed along to the caller when the serializer is"
    ],
    [
        "``serializer_module`` should be the fully qualified module name",
        "``serializer_module`` should be the fully"
    ],
    [
        "If ``serializers`` is provided, the registration will be added",
        "If ``serializers`` is provided, the registration will be"
    ],
    [
        "If ``serializers`` is not provided, the registration will be made",
        "If ``serializers`` is not provided, the"
    ],
    [
        "directly into the global register of serializers. Adding serializers",
        "directly into the global register of serializers. Adding"
    ],
    [
        "directly is not a thread-safe operation.",
        "directly is not"
    ],
    [
        "if serializers is None and not _serializers:",
        "if serializers is None and"
    ],
    [
        "\"Unregister a given serializer. This is not a thread-safe operation.\"",
        "\"Unregister a given serializer. This is not a thread-safe"
    ],
    [
        "return [k for k, v in _serializers.items() if not v.Serializer.internal_use_only]",
        "return [k for k, v in _serializers.items() if not"
    ],
    [
        "Serialize a queryset (or any iterator that returns database objects) using",
        "Serialize a queryset (or any iterator"
    ],
    [
        "Deserialize a stream or a string. Return an iterator that yields ``(obj,",
        "Deserialize a stream or a string. Return an iterator"
    ],
    [
        "Register built-in and settings-defined serializers. This is done lazily so",
        "Register built-in and settings-defined serializers. This is done lazily"
    ],
    [
        "that user code has a chance to (e.g.) set up custom settings without",
        "that user code has a chance to (e.g.)"
    ],
    [
        "needing to be careful of import order.",
        "needing to be careful"
    ],
    [
        "\"\"\"Sort a list of (app_config, models) pairs into a single list of models.",
        "\"\"\"Sort a list of (app_config, models) pairs into a single"
    ],
    [
        "The single list of models is sorted so that any model with a natural key",
        "The single list of models is sorted so that"
    ],
    [
        "is serialized before a normal model, and any model with a natural key",
        "is serialized before a normal model, and any model with"
    ],
    [
        "dependency has it's dependencies serialized first.",
        "dependency has it's dependencies serialized"
    ],
    [
        "If allow_cycles is True, return the best-effort ordering that will respect",
        "If allow_cycles is True, return the best-effort"
    ],
    [
        "most of dependencies but ignore some of them to break the cycles.",
        "most of dependencies but ignore some of"
    ],
    [
        "deps = [apps.get_model(dep) for dep in deps]",
        "deps = [apps.get_model(dep) for dep in"
    ],
    [
        "if hasattr(rel_model, \"natural_key\") and rel_model != model:",
        "if hasattr(rel_model, \"natural_key\") and rel_model"
    ],
    [
        "if hasattr(rel_model, \"natural_key\") and rel_model != model:",
        "if hasattr(rel_model, \"natural_key\") and"
    ],
    [
        "if all(d not in models or d in model_list for d in deps):",
        "if all(d not in models or d in model_list for d"
    ],
    [
        "\"Can't resolve dependencies for %s in serialized app list.\"",
        "\"Can't resolve dependencies for %s in serialized"
    ],
    [
        "from xml.sax.expatreader import ExpatParser as _ExpatParser",
        "from xml.sax.expatreader import"
    ],
    [
        "\"\\n\" + \" \" * self.options.get(\"indent\") * level",
        "\"\\n\" + \" \" * self.options.get(\"indent\") *"
    ],
    [
        "Start serialization -- open the XML document and the root element.",
        "Start serialization -- open the XML document and"
    ],
    [
        "End serialization -- end the document.",
        "End serialization -- end"
    ],
    [
        "Called as each object is handled.",
        "Called as each object"
    ],
    [
        "\"Non-model object (%s) encountered during serialization\" % type(obj)",
        "\"Non-model object (%s) encountered"
    ],
    [
        "if not self.use_natural_primary_keys or not hasattr(obj, \"natural_key\"):",
        "if not self.use_natural_primary_keys or not"
    ],
    [
        "Called after handling all fields for an object.",
        "Called after handling all"
    ],
    [
        "Handle each field on an object (except for ForeignKeys and",
        "Handle each field on an object (except for"
    ],
    [
        "if getattr(obj, field.name) is not None:",
        "if getattr(obj, field.name) is"
    ],
    [
        "Handle a ForeignKey (they need to be treated slightly",
        "Handle a ForeignKey (they need to"
    ],
    [
        "Handle a ManyToManyField. Related objects are only serialized as",
        "Handle a ManyToManyField. Related objects"
    ],
    [
        "references to the object's PK (i.e. the related *data* is not dumped,",
        "references to the object's PK (i.e. the related *data*"
    ],
    [
        "\"\"\"Output the <field> element for relational fields.\"\"\"",
        "\"\"\"Output the <field> element for"
    ],
    [
        "\"\"\"Create a hardened XML parser (no custom/external entities).\"\"\"",
        "\"\"\"Create a hardened XML parser (no"
    ],
    [
        "if event == \"START_ELEMENT\" and node.nodeName == \"object\":",
        "if event == \"START_ELEMENT\" and node.nodeName"
    ],
    [
        "\"\"\"Convert an <object> node to a DeserializedObject.\"\"\"",
        "\"\"\"Convert an <object> node to a"
    ],
    [
        "field_names = {f.name for f in Model._meta.get_fields()}",
        "field_names = {f.name for"
    ],
    [
        "\"<field> node is missing the 'name' attribute\"",
        "\"<field> node is missing the 'name'"
    ],
    [
        "if self.ignore and field_name not in field_names:",
        "if self.ignore and field_name not in"
    ],
    [
        "Handle a <field> node for a ForeignKey",
        "Handle a <field> node for"
    ],
    [
        "field_value = [getInnerText(k).strip() for k in keys]",
        "field_value = [getInnerText(k).strip() for"
    ],
    [
        "Handle a <field> node for a ManyToManyField.",
        "Handle a <field> node for a"
    ],
    [
        "field_value = [getInnerText(k).strip() for k in keys]",
        "field_value = [getInnerText(k).strip() for"
    ],
    [
        "Look up a model from a <object model=...> or a <field rel=... to=...>",
        "Look up a model from a <object"
    ],
    [
        "\"<%s> node is missing the required '%s' attribute\"",
        "\"<%s> node is missing the"
    ],
    [
        "\"<%s> node has invalid model identifier: '%s'\"",
        "\"<%s> node has invalid model"
    ],
    [
        "\"\"\"Get all the inner text of a DOM node (recursively).\"\"\"",
        "\"\"\"Get all the inner text of a DOM node"
    ],
    [
        "An expat parser hardened against XML bomb attacks.",
        "An expat parser hardened"
    ],
    [
        "def start_doctype_decl(self, name, sysid, pubid, has_internal_subset):",
        "def start_doctype_decl(self, name, sysid, pubid,"
    ],
    [
        "self, name, is_parameter_entity, value, base, sysid, pubid, notation_name",
        "self, name, is_parameter_entity, value, base, sysid,"
    ],
    [
        "raise EntitiesForbidden(name, value, base, sysid, pubid, notation_name)",
        "raise EntitiesForbidden(name, value, base,"
    ],
    [
        "def unparsed_entity_decl(self, name, base, sysid, pubid, notation_name):",
        "def unparsed_entity_decl(self, name, base, sysid, pubid,"
    ],
    [
        "raise EntitiesForbidden(name, None, base, sysid, pubid, notation_name)",
        "raise EntitiesForbidden(name, None, base,"
    ],
    [
        "def external_entity_ref_handler(self, context, base, sysid, pubid):",
        "def external_entity_ref_handler(self, context, base,"
    ],
    [
        "def __init__(self, name, value, base, sysid, pubid, notation_name):",
        "def __init__(self, name, value,"
    ],
    [
        "\"\"\"Resolving an external reference is forbidden.\"\"\"",
        "\"\"\"Resolving an external reference"
    ],
    [
        "def __init__(self, context, base, sysid, pubid):",
        "def __init__(self, context, base,"
    ],
    [
        "from django.core.serializers.python import Deserializer as PythonDeserializer",
        "from django.core.serializers.python import Deserializer as"
    ],
    [
        "from django.core.serializers.python import Serializer as PythonSerializer",
        "from django.core.serializers.python import"
    ],
    [
        "\"\"\"Convert a queryset to JSON Lines.\"\"\"",
        "\"\"\"Convert a queryset to"
    ],
    [
        "\"\"\"Deserialize a stream or string of JSON data.\"\"\"",
        "\"\"\"Deserialize a stream or string of"
    ],
    [
        "raise DeserializationError(f\"Error deserializing object: {exc}\") from exc",
        "raise DeserializationError(f\"Error deserializing object: {exc}\")"
    ],
    [
        "A Python \"serializer\". Doesn't do much serializing per se -- just converts to",
        "A Python \"serializer\". Doesn't do much serializing per se"
    ],
    [
        "and from basic Python data types (lists, dicts, strings, etc.). Useful as a basis for",
        "and from basic Python data types (lists, dicts, strings, etc.)."
    ],
    [
        "Serialize a QuerySet to basic Python objects.",
        "Serialize a QuerySet to basic"
    ],
    [
        "if not self.use_natural_primary_keys or not hasattr(obj, \"natural_key\"):",
        "if not self.use_natural_primary_keys or not"
    ],
    [
        "return [self._value_from_field(obj, f) for f in field]",
        "return [self._value_from_field(obj, f) for f"
    ],
    [
        "return value if is_protected_type(value) else field.value_to_string(obj)",
        "return value if"
    ],
    [
        "Deserialize simple Python objects back into Django ORM instances.",
        "Deserialize simple Python objects back"
    ],
    [
        "It's expected that you pass the Python objects themselves (instead of a",
        "It's expected that you pass the Python objects themselves"
    ],
    [
        "stream or a string) to the constructor",
        "stream or a string) to the"
    ],
    [
        "self, object_list, *, using=DEFAULT_DB_ALIAS, ignorenonexistent=False, **options",
        "self, object_list, *, using=DEFAULT_DB_ALIAS,"
    ],
    [
        "self.field_names_cache[Model] = {f.name for f in Model._meta.get_fields()}",
        "self.field_names_cache[Model] = {f.name for f"
    ],
    [
        "if self.ignorenonexistent and field_name not in field_names:",
        "if self.ignorenonexistent and field_name not in"
    ],
    [
        "\"\"\"Look up a model from an \"app_label.model_name\" string.\"\"\"",
        "\"\"\"Look up a model"
    ],
    [
        "from django.core.serializers.python import Deserializer as PythonDeserializer",
        "from django.core.serializers.python import Deserializer as"
    ],
    [
        "from django.core.serializers.python import Serializer as PythonSerializer",
        "from django.core.serializers.python import"
    ],
    [
        "\"\"\"Deserialize a stream or string of JSON data.\"\"\"",
        "\"\"\"Deserialize a stream or"
    ],
    [
        "raise DeserializationError(f\"Error deserializing object: {exc}\") from exc",
        "raise DeserializationError(f\"Error deserializing object: {exc}\")"
    ],
    [
        "JSONEncoder subclass that knows how to encode date/time, decimal types, and",
        "JSONEncoder subclass that knows how to encode date/time,"
    ],
    [
        "raise ValueError(\"JSON can't represent timezone-aware times.\")",
        "raise ValueError(\"JSON can't represent timezone-aware"
    ],
    [
        "Module for abstract serializer/unserializer base classes.",
        "Module for abstract"
    ],
    [
        "\"\"\"The requested serializer was not found.\"\"\"",
        "\"\"\"The requested serializer was"
    ],
    [
        "def WithData(cls, original_exc, model, fk, field_value):",
        "def WithData(cls, original_exc,"
    ],
    [
        "Factory method for creating a deserialization error which has a more",
        "Factory method for creating a deserialization error which"
    ],
    [
        "\"\"\"Something bad happened during deserialization of a ManyToManyField.\"\"\"",
        "\"\"\"Something bad happened during"
    ],
    [
        "cr + \"[\" + \".\" * done + \" \" * (self.progress_width - done) + \"]\"",
        "cr + \"[\" + \".\" * done + \" \""
    ],
    [
        "self.stream = stream if stream is not None else self.stream_class()",
        "self.stream = stream if stream is"
    ],
    [
        "pk if pk.remote_field and pk.remote_field.parent_link else None",
        "pk if pk.remote_field and pk.remote_field.parent_link"
    ],
    [
        "if field.serialize or field is pk_parent:",
        "if field.serialize or field"
    ],
    [
        "Called when serializing of the queryset starts.",
        "Called when serializing of"
    ],
    [
        "\"subclasses of Serializer must provide a start_serialization() method\"",
        "\"subclasses of Serializer must"
    ],
    [
        "Called when serializing of the queryset ends.",
        "Called when serializing of"
    ],
    [
        "Called when serializing of an object starts.",
        "Called when serializing of"
    ],
    [
        "\"subclasses of Serializer must provide a start_object() method\"",
        "\"subclasses of Serializer must provide a"
    ],
    [
        "Called when serializing of an object ends.",
        "Called when serializing of an"
    ],
    [
        "Called to handle each individual (non-relational) field on an object.",
        "Called to handle each individual (non-relational) field"
    ],
    [
        "\"subclasses of Serializer must provide a handle_field() method\"",
        "\"subclasses of Serializer must"
    ],
    [
        "Called to handle a ForeignKey field.",
        "Called to handle a"
    ],
    [
        "\"subclasses of Serializer must provide a handle_fk_field() method\"",
        "\"subclasses of Serializer must provide a"
    ],
    [
        "Return the fully serialized queryset (or None if the output stream is",
        "Return the fully serialized queryset (or None if the output stream"
    ],
    [
        "Init this serializer given a stream or a string",
        "Init this serializer given a"
    ],
    [
        "\"\"\"Iteration interface -- return the next item in the stream\"\"\"",
        "\"\"\"Iteration interface -- return the next item in the"
    ],
    [
        "\"subclasses of Deserializer must provide a __next__() method\"",
        "\"subclasses of Deserializer must provide"
    ],
    [
        "Basically a container for holding the pre-saved deserialized data along",
        "Basically a container for holding"
    ],
    [
        "with the many-to-many data saved with the object.",
        "with the many-to-many data saved with"
    ],
    [
        "Call ``save()`` to save the object (with the many-to-many data) to the",
        "Call ``save()`` to save the object (with the many-to-many data)"
    ],
    [
        "(and not touch the many-to-many stuff.)",
        "(and not touch the many-to-many"
    ],
    [
        "label = opts.app_label + \".\" + opts.model_name",
        "label = opts.app_label + \".\" +"
    ],
    [
        "If the model instance doesn't have a primary key and the model supports",
        "If the model instance doesn't have a primary key and the"
    ],
    [
        "natural keys, try to retrieve it from the database.",
        "natural keys, try to retrieve it from"
    ],
    [
        "if hasattr(value, \"__iter__\") and not isinstance(value, str):",
        "if hasattr(value, \"__iter__\") and not"
    ],
    [
        "Based partially on an example by Jonathan Feignberg in the Python",
        "Based partially on an example by Jonathan Feignberg in"
    ],
    [
        ">>> with open('./file', 'wb') as f:",
        ">>> with open('./file',"
    ],
    [
        "__all__ = (\"LOCK_EX\", \"LOCK_SH\", \"LOCK_NB\", \"lock\", \"unlock\")",
        "__all__ = (\"LOCK_EX\", \"LOCK_SH\", \"LOCK_NB\", \"lock\","
    ],
    [
        "\"\"\"Get a filedescriptor from something which could be a file or an fd.\"\"\"",
        "\"\"\"Get a filedescriptor from something which could be a"
    ],
    [
        "return f.fileno() if hasattr(f, \"fileno\") else f",
        "return f.fileno() if hasattr(f,"
    ],
    [
        "from ctypes.wintypes import BOOL, DWORD, HANDLE",
        "from ctypes.wintypes import BOOL, DWORD,"
    ],
    [
        "_fields_ = [(\"Offset\", DWORD), (\"OffsetHigh\", DWORD)]",
        "_fields_ = [(\"Offset\","
    ],
    [
        "_fields_ = [(\"_offset\", _OFFSET), (\"Pointer\", PVOID)]",
        "_fields_ = [(\"_offset\","
    ],
    [
        "LockFileEx.argtypes = [HANDLE, DWORD, DWORD, DWORD, DWORD, LPOVERLAPPED]",
        "LockFileEx.argtypes = [HANDLE, DWORD,"
    ],
    [
        "UnlockFileEx.argtypes = [HANDLE, DWORD, DWORD, DWORD, LPOVERLAPPED]",
        "UnlockFileEx.argtypes = [HANDLE, DWORD, DWORD,"
    ],
    [
        "Base file upload handler classes, and the built-in concrete subclasses",
        "Base file upload handler classes,"
    ],
    [
        "Any error having to do with uploading files.",
        "Any error having to do"
    ],
    [
        "This exception is raised when an upload must abort.",
        "This exception is raised when an upload"
    ],
    [
        "If ``connection_reset`` is ``True``, Django knows will halt the upload",
        "If ``connection_reset`` is ``True``, Django knows will halt the"
    ],
    [
        "without consuming the rest of the upload. This will cause the browser to",
        "without consuming the rest of the upload."
    ],
    [
        "return \"StopUpload: Consume request data, then halt.\"",
        "return \"StopUpload: Consume request"
    ],
    [
        "This exception is raised by an upload handler that wants to skip a given file.",
        "This exception is raised by an upload handler that wants to skip a given"
    ],
    [
        "Upload handlers that have handled a file and do not want future handlers to",
        "Upload handlers that have handled a file and do"
    ],
    [
        "run should raise this exception instead of returning None.",
        "run should raise this exception instead of returning"
    ],
    [
        "Base class for streaming upload handlers.",
        "Base class for"
    ],
    [
        "self, input_data, META, content_length, boundary, encoding=None",
        "self, input_data, META, content_length,"
    ],
    [
        "Handle the raw input from the client.",
        "Handle the raw input from the"
    ],
    [
        "An object that supports reading via .read().",
        "An object that supports reading via"
    ],
    [
        "The (integer) value of the Content-Length header from the",
        "The (integer) value of the"
    ],
    [
        ":boundary: The boundary from the Content-Type header. Be sure to",
        ":boundary: The boundary from the Content-Type header."
    ],
    [
        "Signal that a new file has been started.",
        "Signal that a new file has"
    ],
    [
        "Warning: As with any data from the client, you should not trust",
        "Warning: As with any data from the client, you should"
    ],
    [
        "content_length (and sometimes won't even get it).",
        "content_length (and sometimes won't even"
    ],
    [
        "Receive data from the streamed upload parser. ``start`` is the position",
        "Receive data from the streamed upload parser."
    ],
    [
        "in the file of the chunk.",
        "in the file"
    ],
    [
        "\"subclasses of FileUploadHandler must provide a receive_data_chunk() method\"",
        "\"subclasses of FileUploadHandler must provide a receive_data_chunk()"
    ],
    [
        "Signal that a file has completed. File size corresponds to the actual",
        "Signal that a file has completed. File size corresponds"
    ],
    [
        "size accumulated by all the chunks.",
        "size accumulated by"
    ],
    [
        "Subclasses should return a valid ``UploadedFile`` object.",
        "Subclasses should return a valid"
    ],
    [
        "\"subclasses of FileUploadHandler must provide a file_complete() method\"",
        "\"subclasses of FileUploadHandler must provide a"
    ],
    [
        "Signal that the upload is complete. Subclasses should perform cleanup",
        "Signal that the upload is complete. Subclasses"
    ],
    [
        "that is necessary for this handler.",
        "that is necessary for"
    ],
    [
        "Signal that the upload was interrupted. Subclasses should perform",
        "Signal that the upload was"
    ],
    [
        "cleanup that is necessary for this handler.",
        "cleanup that is necessary for"
    ],
    [
        "Upload handler that streams data into a temporary file.",
        "Upload handler that streams data into"
    ],
    [
        "Create the file object to append to as data is coming in.",
        "Create the file object to append to as data"
    ],
    [
        "File upload handler to stream uploads into memory (used for small files).",
        "File upload handler to stream uploads"
    ],
    [
        "self, input_data, META, content_length, boundary, encoding=None",
        "self, input_data, META, content_length,"
    ],
    [
        "Use the content_length to signal whether or not this handler should be",
        "Use the content_length to signal whether or not this handler"
    ],
    [
        "\"\"\"Add the data to the BytesIO file.\"\"\"",
        "\"\"\"Add the data to the"
    ],
    [
        "\"\"\"Return a file object if this handler is activated.\"\"\"",
        "\"\"\"Return a file object if this handler"
    ],
    [
        "Given a path to a handler, return an instance of that handler.",
        "Given a path to a handler, return an instance"
    ],
    [
        "if os.path.basename(name) in {\"\", \".\", \"..\"}:",
        "if os.path.basename(name) in"
    ],
    [
        "raise SuspiciousFileOperation(\"Could not derive file name from '%s'\" % name)",
        "raise SuspiciousFileOperation(\"Could not derive file name from '%s'\" %"
    ],
    [
        "if path.is_absolute() or \"..\" in path.parts:",
        "if path.is_absolute() or \"..\""
    ],
    [
        "\"Detected path traversal attempt in '%s'\" % name",
        "\"Detected path traversal attempt in '%s'\" %"
    ],
    [
        "raise SuspiciousFileOperation(\"File name '%s' includes path elements\" % name)",
        "raise SuspiciousFileOperation(\"File name '%s' includes path"
    ],
    [
        "A mixin class used to forward file methods to an underlying file",
        "A mixin class used to forward file methods"
    ],
    [
        "object.  The internal file object has to be called \"file\"::",
        "object. The internal file object"
    ],
    [
        "return \"w\" in getattr(self.file, \"mode\", \"\")",
        "return \"w\" in getattr(self.file,"
    ],
    [
        "from django.core.files import temp as tempfile",
        "from django.core.files import temp as"
    ],
    [
        "An abstract uploaded file (``TemporaryUploadedFile`` and",
        "An abstract uploaded file (``TemporaryUploadedFile``"
    ],
    [
        "``InMemoryUploadedFile`` are the built-in concrete subclasses).",
        "``InMemoryUploadedFile`` are the built-in"
    ],
    [
        "An ``UploadedFile`` object behaves somewhat like a file object and",
        "An ``UploadedFile`` object behaves somewhat"
    ],
    [
        "represents some file data that the user submitted with a form.",
        "represents some file data that the user"
    ],
    [
        "return \"<%s: %s (%s)>\" % (self.__class__.__name__, self.name, self.content_type)",
        "return \"<%s: %s (%s)>\" % (self.__class__.__name__, self.name,"
    ],
    [
        "A file uploaded to a temporary location (i.e. stream-to-disk).",
        "A file uploaded to a temporary location (i.e."
    ],
    [
        "def __init__(self, name, content_type, size, charset, content_type_extra=None):",
        "def __init__(self, name, content_type, size, charset,"
    ],
    [
        "super().__init__(file, name, content_type, size, charset, content_type_extra)",
        "super().__init__(file, name, content_type, size,"
    ],
    [
        "\"\"\"Return the full path of this file.\"\"\"",
        "\"\"\"Return the full path"
    ],
    [
        "A file uploaded into memory (i.e. stream-to-memory).",
        "A file uploaded into"
    ],
    [
        "super().__init__(file, name, content_type, size, charset, content_type_extra)",
        "super().__init__(file, name, content_type, size, charset,"
    ],
    [
        "A simple representation of a file, which just has content, size, and a name.",
        "A simple representation of a file, which just has content, size, and"
    ],
    [
        "BytesIO(content), None, name, content_type, len(content), None, None",
        "BytesIO(content), None, name, content_type, len(content),"
    ],
    [
        "Create a SimpleUploadedFile object from a dictionary with keys:",
        "Create a SimpleUploadedFile object from"
    ],
    [
        "The temp module provides a NamedTemporaryFile that can be reopened in the same",
        "The temp module provides a NamedTemporaryFile that can be reopened in"
    ],
    [
        "process on any platform. Most platforms use the standard Python",
        "process on any platform. Most"
    ],
    [
        "tempfile.NamedTemporaryFile class, but Windows users are given a custom class.",
        "tempfile.NamedTemporaryFile class, but Windows users are given"
    ],
    [
        "This is needed because the Python implementation of NamedTemporaryFile uses the",
        "This is needed because the Python implementation of"
    ],
    [
        "O_TEMPORARY flag under Windows, which prevents the file from being reopened",
        "O_TEMPORARY flag under Windows, which prevents the file from being"
    ],
    [
        "more general issue of opening a file for writing and reading in multiple",
        "more general issue of opening a file for writing and"
    ],
    [
        "processes in a manner that works across platforms.",
        "processes in a manner"
    ],
    [
        "The custom version of NamedTemporaryFile doesn't support the same keyword",
        "The custom version of NamedTemporaryFile doesn't support the"
    ],
    [
        "Temporary file object constructor that supports reopening of the",
        "Temporary file object constructor that supports reopening of"
    ],
    [
        "Unlike tempfile.NamedTemporaryFile from the standard library,",
        "Unlike tempfile.NamedTemporaryFile from"
    ],
    [
        "__init__() doesn't support the 'delete', 'buffering', 'encoding', or",
        "__init__() doesn't support the 'delete',"
    ],
    [
        "fd, name = tempfile.mkstemp(suffix=suffix, prefix=prefix, dir=dir)",
        "fd, name ="
    ],
    [
        "Requires Pillow as you might imagine.",
        "Requires Pillow as"
    ],
    [
        "A mixin for use alongside django.core.files.base.File, which provides",
        "A mixin for use alongside"
    ],
    [
        "additional features for dealing with images.",
        "additional features for dealing"
    ],
    [
        "Return the (width, height) of an image, given an open file or a path.  Set",
        "Return the (width, height) of an image, given an open file or a path."
    ],
    [
        "'close' to True to close the file at the end if it is initially in an open",
        "'close' to True to close the file at the end if"
    ],
    [
        "from PIL import ImageFile as PillowImageFile",
        "from PIL import ImageFile as"
    ],
    [
        "Move a file in the safest way possible::",
        "Move a file in the"
    ],
    [
        "Move a file from one location to another in the safest way possible.",
        "Move a file from one location to another in the safest way"
    ],
    [
        "First, try ``os.rename``, which is simple but will break across filesystems.",
        "First, try ``os.rename``, which is simple"
    ],
    [
        "If that fails, stream manually from one file to another in pure Python.",
        "If that fails, stream manually from one file to"
    ],
    [
        "If the destination file exists and ``allow_overwrite`` is ``False``, raise",
        "If the destination file exists and ``allow_overwrite`` is"
    ],
    [
        "if not allow_overwrite and os.access(new_file_name, os.F_OK):",
        "if not allow_overwrite and os.access(new_file_name,"
    ],
    [
        "f\"Destination file {new_file_name} exists and allow_overwrite is False.\"",
        "f\"Destination file {new_file_name} exists and"
    ],
    [
        "from io import BytesIO, StringIO, UnsupportedOperation",
        "from io import BytesIO,"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self or \"None\")",
        "return \"<%s: %s>\" % (self.__class__.__name__,"
    ],
    [
        "if hasattr(self.file, \"tell\") and hasattr(self.file, \"seek\"):",
        "if hasattr(self.file, \"tell\")"
    ],
    [
        "raise AttributeError(\"Unable to determine the file's size.\")",
        "raise AttributeError(\"Unable to determine the file's"
    ],
    [
        "Read the file and yield chunks of ``chunk_size`` bytes (defaults to",
        "Read the file and yield chunks of"
    ],
    [
        "Return ``True`` if you can expect multiple chunks.",
        "Return ``True`` if you can"
    ],
    [
        "NB: If a particular file representation is in memory, subclasses should",
        "NB: If a particular file representation is in memory, subclasses"
    ],
    [
        "always return ``False`` -- there's no good reason to read from memory in",
        "always return ``False`` -- there's no good reason to"
    ],
    [
        "return self.size > (chunk_size or self.DEFAULT_CHUNK_SIZE)",
        "return self.size > (chunk_size or"
    ],
    [
        "self.file = open(self.name, mode or self.mode, *args, **kwargs)",
        "self.file = open(self.name, mode or self.mode, *args,"
    ],
    [
        "raise ValueError(\"The file cannot be reopened.\")",
        "raise ValueError(\"The file cannot"
    ],
    [
        "A File-like object that takes just raw content, rather than an actual file.",
        "A File-like object that takes just raw content, rather"
    ],
    [
        "stream_class = StringIO if isinstance(content, str) else BytesIO",
        "stream_class = StringIO if isinstance(content, str)"
    ],
    [
        "\"\"\"Return True if line (a text or bytestring) ends with '\\r'.\"\"\"",
        "\"\"\"Return True if line (a text or"
    ],
    [
        "return line.endswith(\"\\r\" if isinstance(line, str) else b\"\\r\")",
        "return line.endswith(\"\\r\" if isinstance(line, str)"
    ],
    [
        "\"\"\"Return True if line (a text or bytestring) ends with '\\n'.\"\"\"",
        "\"\"\"Return True if line (a text or"
    ],
    [
        "return line.endswith(\"\\n\" if isinstance(line, str) else b\"\\n\")",
        "return line.endswith(\"\\n\" if isinstance(line, str) else"
    ],
    [
        "\"\"\"Return True if line (a text or bytestring) equals '\\n'.\"\"\"",
        "\"\"\"Return True if line (a text or"
    ],
    [
        "return line == (\"\\n\" if isinstance(line, str) else b\"\\n\")",
        "return line == (\"\\n\" if isinstance(line, str) else"
    ],
    [
        "return setting if value is None else value",
        "return setting if value is None else"
    ],
    [
        "f\"Could not find config for '{alias}' in settings.STORAGES.\"",
        "f\"Could not find config for '{alias}'"
    ],
    [
        "raise InvalidStorageError(f\"Could not find backend {backend!r}: {e}\") from e",
        "raise InvalidStorageError(f\"Could not find backend"
    ],
    [
        "Based on dj-inmemorystorage (BSD) by Cody Soyland, Seán Hayes, Tore Birkeland,",
        "Based on dj-inmemorystorage (BSD) by Cody Soyland,"
    ],
    [
        "Helper class representing an in-memory file node.",
        "Helper class representing an"
    ],
    [
        "Handle unicode/bytes conversion during I/O operations and record creation,",
        "Handle unicode/bytes conversion during I/O operations and record"
    ],
    [
        "\"\"\"Initialize underlying stream according to the content type.\"\"\"",
        "\"\"\"Initialize underlying stream according to the content"
    ],
    [
        "self.file = io.BytesIO() if self._content_type == bytes else io.StringIO()",
        "self.file = io.BytesIO() if self._content_type == bytes"
    ],
    [
        "\"\"\"Convert actual file content according to the opening mode.\"\"\"",
        "\"\"\"Convert actual file content according to the opening"
    ],
    [
        "new_content_type = bytes if \"b\" in mode else str",
        "new_content_type = bytes if \"b\" in"
    ],
    [
        "content = content.encode() if isinstance(content, str) else content.decode()",
        "content = content.encode() if"
    ],
    [
        "Helper class representing an in-memory directory node.",
        "Helper class representing an"
    ],
    [
        "Handle path navigation of directory trees, creating missing nodes if",
        "Handle path navigation of directory trees, creating missing nodes"
    ],
    [
        "def resolve(self, path, create_if_missing=False, leaf_cls=None, check_exists=True):",
        "def resolve(self, path, create_if_missing=False,"
    ],
    [
        "Navigate current directory tree, returning node matching path or",
        "Navigate current directory tree, returning node"
    ],
    [
        "creating a new one, if missing.",
        "creating a new"
    ],
    [
        "- path: path of the node to search",
        "- path: path of the node to"
    ],
    [
        "- create_if_missing: create nodes if not exist. Defaults to False.",
        "- create_if_missing: create nodes if not"
    ],
    [
        "- leaf_cls: expected type of leaf node. Defaults to None.",
        "- leaf_cls: expected type of leaf node. Defaults to"
    ],
    [
        "- check_exists: if True and the leaf node does not exist, raise a",
        "- check_exists: if True and the leaf node does"
    ],
    [
        "if current_node is None and check_exists:",
        "if current_node is"
    ],
    [
        "if leaf_cls and not isinstance(current_node, leaf_cls):",
        "if leaf_cls and"
    ],
    [
        "\"\"\"A storage saving files in memory.\"\"\"",
        "\"\"\"A storage saving"
    ],
    [
        "if self._base_url is not None and not self._base_url.endswith(\"/\"):",
        "if self._base_url is not"
    ],
    [
        "def _resolve(self, name, create_if_missing=False, leaf_cls=None, check_exists=True):",
        "def _resolve(self, name,"
    ],
    [
        "raise FileExistsError(f\"{absolute_path} exists and is not a directory.\")",
        "raise FileExistsError(f\"{absolute_path} exists and"
    ],
    [
        "mode = \"wb\" if isinstance(chunk, bytes) else \"wt\"",
        "mode = \"wb\" if"
    ],
    [
        "return self._resolve(name, check_exists=False) is not None",
        "return self._resolve(name, check_exists=False) is"
    ],
    [
        "raise ValueError(\"This file is not accessible via a URL.\")",
        "raise ValueError(\"This file is not accessible via a"
    ],
    [
        "if self._base_url is not None and not self._base_url.endswith(\"/\"):",
        "if self._base_url is not None"
    ],
    [
        "raise FileExistsError(\"%s exists and is not a directory.\" % directory)",
        "raise FileExistsError(\"%s exists and is not a"
    ],
    [
        "mode = \"wb\" if isinstance(chunk, bytes) else \"wt\"",
        "mode = \"wb\" if isinstance(chunk,"
    ],
    [
        "raise ValueError(\"The name must be given to delete().\")",
        "raise ValueError(\"The name must"
    ],
    [
        "return not (max_length and len(name) > max_length)",
        "return not (max_length and len(name)"
    ],
    [
        "raise ValueError(\"This file is not accessible via a URL.\")",
        "raise ValueError(\"This file is not accessible"
    ],
    [
        "If timezone support is enabled, make an aware datetime object in UTC;",
        "If timezone support is enabled, make an aware datetime object in"
    ],
    [
        "otherwise make a naive one in the local timezone.",
        "otherwise make a naive one in the local"
    ],
    [
        "tz = timezone.utc if settings.USE_TZ else None",
        "tz = timezone.utc if settings.USE_TZ else"
    ],
    [
        "A base storage class, providing some default behaviors that all other",
        "A base storage class, providing some default behaviors that all"
    ],
    [
        "storage systems can inherit or override, as necessary.",
        "storage systems can inherit or override, as"
    ],
    [
        "\"\"\"Retrieve the specified file from storage.\"\"\"",
        "\"\"\"Retrieve the specified"
    ],
    [
        "Save new content to the file specified by name. The content should be",
        "Save new content to the file specified by"
    ],
    [
        "a proper File object or any Python file-like object, ready to be read",
        "a proper File object or any Python file-like object, ready to be"
    ],
    [
        "exceeds_max_length = max_length and len(name) > max_length",
        "exceeds_max_length = max_length and len(name) >"
    ],
    [
        "return not self.exists(name) and not exceeds_max_length",
        "return not self.exists(name) and not"
    ],
    [
        "Return a filename, based on the provided filename, that's suitable for",
        "Return a filename, based on the provided filename,"
    ],
    [
        "use in the target storage system.",
        "use in the"
    ],
    [
        "character alphanumeric string (before the file extension, if one",
        "character alphanumeric string (before the file extension, if"
    ],
    [
        "Return a filename that's free on the target storage system and",
        "Return a filename that's free on the target storage system"
    ],
    [
        "available for new content to be written to.",
        "available for new content to be"
    ],
    [
        "\"Detected path traversal attempt in '%s'\" % dir_name",
        "\"Detected path traversal attempt"
    ],
    [
        "'Storage can not find an available filename for \"%s\". '",
        "'Storage can not find an available filename for \"%s\"."
    ],
    [
        "\"Please make sure that the corresponding file field \"",
        "\"Please make sure that the"
    ],
    [
        "Validate the filename by calling get_valid_name() and return a filename",
        "Validate the filename by calling get_valid_name()"
    ],
    [
        "to be passed to the save() method.",
        "to be passed to the save()"
    ],
    [
        "\"Detected path traversal attempt in '%s'\" % dirname",
        "\"Detected path traversal attempt in"
    ],
    [
        "Return a local filesystem path where the file can be retrieved using",
        "Return a local filesystem path where the file"
    ],
    [
        "Python's built-in open() function. Storage systems that can't be",
        "Python's built-in open() function. Storage systems that can't"
    ],
    [
        "accessed using open() should *not* implement this method.",
        "accessed using open() should *not* implement this"
    ],
    [
        "raise NotImplementedError(\"This backend doesn't support absolute paths.\")",
        "raise NotImplementedError(\"This backend doesn't"
    ],
    [
        "Delete the specified file from the storage system.",
        "Delete the specified file from the storage"
    ],
    [
        "\"subclasses of Storage must provide a delete() method\"",
        "\"subclasses of Storage must provide a delete()"
    ],
    [
        "Return True if a file referenced by the given name already exists in the",
        "Return True if a file referenced by the given name already"
    ],
    [
        "storage system, or False if the name is available for a new file.",
        "storage system, or False if the name is available for"
    ],
    [
        "\"subclasses of Storage must provide an exists() method\"",
        "\"subclasses of Storage must provide an exists()"
    ],
    [
        "the first item being directories, the second item being files.",
        "the first item being directories,"
    ],
    [
        "\"subclasses of Storage must provide a listdir() method\"",
        "\"subclasses of Storage must provide a listdir()"
    ],
    [
        "Return the total size, in bytes, of the file specified by name.",
        "Return the total size, in bytes, of the file specified"
    ],
    [
        "raise NotImplementedError(\"subclasses of Storage must provide a size() method\")",
        "raise NotImplementedError(\"subclasses of Storage must provide a"
    ],
    [
        "Return an absolute URL where the file's contents can be accessed",
        "Return an absolute URL where the file's contents can"
    ],
    [
        "raise NotImplementedError(\"subclasses of Storage must provide a url() method\")",
        "raise NotImplementedError(\"subclasses of Storage must provide a"
    ],
    [
        "Return the last accessed time (as a datetime) of the file specified by",
        "Return the last accessed time (as a datetime) of the file"
    ],
    [
        "name. The datetime will be timezone-aware if USE_TZ=True.",
        "name. The datetime will be"
    ],
    [
        "\"subclasses of Storage must provide a get_accessed_time() method\"",
        "\"subclasses of Storage must provide a get_accessed_time()"
    ],
    [
        "Return the creation time (as a datetime) of the file specified by name.",
        "Return the creation time (as a datetime) of"
    ],
    [
        "The datetime will be timezone-aware if USE_TZ=True.",
        "The datetime will be timezone-aware"
    ],
    [
        "\"subclasses of Storage must provide a get_created_time() method\"",
        "\"subclasses of Storage must"
    ],
    [
        "Return the last modified time (as a datetime) of the file specified by",
        "Return the last modified time (as a datetime) of"
    ],
    [
        "name. The datetime will be timezone-aware if USE_TZ=True.",
        "name. The datetime will be"
    ],
    [
        "\"subclasses of Storage must provide a get_modified_time() method\"",
        "\"subclasses of Storage must provide a"
    ],
    [
        "Wrap the given get_response callable in exception-to-response conversion.",
        "Wrap the given get_response"
    ],
    [
        "converted to the appropriate response, and all other exceptions will be",
        "converted to the appropriate response, and all"
    ],
    [
        "This decorator is automatically applied to all middleware to ensure that",
        "This decorator is automatically applied to all middleware to ensure"
    ],
    [
        "no middleware leaks an exception and that the next middleware in the stack",
        "no middleware leaks an exception and that"
    ],
    [
        "can rely on getting a response instead of an exception.",
        "can rely on getting a response instead of an"
    ],
    [
        "\"Bad request (Unable to parse request body): %s\",",
        "\"Bad request (Unable to"
    ],
    [
        "if not getattr(response, \"is_rendered\", True) and callable(",
        "if not getattr(response, \"is_rendered\", True)"
    ],
    [
        "Processing for any otherwise uncaught exceptions (those that will",
        "Processing for any otherwise uncaught exceptions (those that"
    ],
    [
        "Return the script prefix to use from either the scope or a setting.",
        "Return the script prefix to use from either the scope or a"
    ],
    [
        "Custom request subclass that decodes from an ASGI-standard request dict",
        "Custom request subclass that decodes from an ASGI-standard request"
    ],
    [
        "for name, value in self.scope.get(\"headers\", []):",
        "for name, value in self.scope.get(\"headers\","
    ],
    [
        "corrected_name = \"HTTP_%s\" % name.upper().replace(\"-\", \"_\")",
        "corrected_name = \"HTTP_%s\" % name.upper().replace(\"-\","
    ],
    [
        "value = self.META[corrected_name] + \",\" + value",
        "value = self.META[corrected_name] +"
    ],
    [
        "async def __call__(self, scope, receive, send):",
        "async def __call__(self, scope, receive,"
    ],
    [
        "Async entrypoint - parses the request and hands off to get_response.",
        "Async entrypoint - parses the request and hands off"
    ],
    [
        "\"Django can only handle ASGI/HTTP connections, not %s.\" % scope[\"type\"]",
        "\"Django can only handle ASGI/HTTP"
    ],
    [
        "async def handle(self, scope, receive, send):",
        "async def handle(self,"
    ],
    [
        "Handles the ASGI request. Called via the __call__ method.",
        "Handles the ASGI request. Called via the"
    ],
    [
        "\"\"\"Listen for disconnect from the client.\"\"\"",
        "\"\"\"Listen for disconnect from the"
    ],
    [
        "assert False, \"Invalid ASGI message after request body: %s\" % message[\"type\"]",
        "assert False, \"Invalid ASGI message after request body:"
    ],
    [
        "\"\"\"Reads an HTTP body from an ASGI connection.\"\"\"",
        "\"\"\"Reads an HTTP body from an"
    ],
    [
        "Create the Request object and returns either (request, None) or",
        "Create the Request object and"
    ],
    [
        "(None, response) if there is an error response.",
        "(None, response) if there is"
    ],
    [
        "traceback.format_exc() if settings.DEBUG else \"Internal Server Error\",",
        "traceback.format_exc() if settings.DEBUG else \"Internal Server"
    ],
    [
        "\"\"\"Encode and send a response out over ASGI.\"\"\"",
        "\"\"\"Encode and send a response out over"
    ],
    [
        "Chunks some data up so it can be sent in reasonable size messages.",
        "Chunks some data up so it can be sent in reasonable size"
    ],
    [
        "from asgiref.sync import async_to_sync, iscoroutinefunction, sync_to_async",
        "from asgiref.sync import async_to_sync, iscoroutinefunction,"
    ],
    [
        "Must be called after the environment is fixed (see __call__ in subclasses).",
        "Must be called after the environment is fixed"
    ],
    [
        "get_response = self._get_response_async if is_async else self._get_response",
        "get_response = self._get_response_async if is_async else"
    ],
    [
        "if not middleware_can_sync and not middleware_can_async:",
        "if not middleware_can_sync and not"
    ],
    [
        "\"Middleware %s must have at least one of \"",
        "\"Middleware %s must have at"
    ],
    [
        "\"sync_capable/async_capable set to True.\" % middleware_path",
        "\"sync_capable/async_capable set to True.\" %"
    ],
    [
        "\"Middleware factory %s returned None.\" % middleware_path",
        "\"Middleware factory %s returned None.\" %"
    ],
    [
        "Adapt a method to be in the correct \"mode\":",
        "Adapt a method to be in"
    ],
    [
        "- Synchronous methods are left alone",
        "- Synchronous methods are"
    ],
    [
        "- Asynchronous methods are wrapped with async_to_sync",
        "- Asynchronous methods are wrapped with"
    ],
    [
        "- Synchronous methods are wrapped with sync_to_async()",
        "- Synchronous methods are"
    ],
    [
        "- Asynchronous methods are left alone",
        "- Asynchronous methods are"
    ],
    [
        "name = name or \"method %s()\" % method.__qualname__",
        "name = name or \"method %s()\" %"
    ],
    [
        "logger.debug(\"Synchronous handler adapted for %s.\", name)",
        "logger.debug(\"Synchronous handler adapted for"
    ],
    [
        "logger.debug(\"Asynchronous handler adapted for %s.\", name)",
        "logger.debug(\"Asynchronous handler adapted for"
    ],
    [
        "\"\"\"Return an HttpResponse object for the given HttpRequest.\"\"\"",
        "\"\"\"Return an HttpResponse object for"
    ],
    [
        "Funneling everything, including WSGI, into a single async",
        "Funneling everything, including WSGI, into a"
    ],
    [
        "get_response() is too slow. Avoid the context switch by using",
        "get_response() is too slow. Avoid the context switch by"
    ],
    [
        "Resolve and call the view, then apply view, exception, and",
        "Resolve and call the view, then"
    ],
    [
        "template_response middleware. This method is everything that happens",
        "template_response middleware. This method is everything that"
    ],
    [
        "Resolve and call the view, then apply view, exception, and",
        "Resolve and call the view, then apply"
    ],
    [
        "template_response middleware. This method is everything that happens",
        "template_response middleware. This method is everything"
    ],
    [
        "raise RuntimeError(\"Response is still a coroutine.\")",
        "raise RuntimeError(\"Response is still a"
    ],
    [
        "Retrieve/set the urlconf for the request. Return the view resolved,",
        "Retrieve/set the urlconf for the request. Return the"
    ],
    [
        "Raise an error if the view returned None or an uncalled coroutine.",
        "Raise an error if the view returned None or an uncalled"
    ],
    [
        "if not (response is None or asyncio.iscoroutine(response)):",
        "if not (response is None"
    ],
    [
        "name = \"The view %s.%s\" % (callback.__module__, callback.__name__)",
        "name = \"The view"
    ],
    [
        "name = \"The view %s.%s.__call__\" % (",
        "name = \"The view %s.%s.__call__\""
    ],
    [
        "\"%s didn't return an HttpResponse object. It returned None \"",
        "\"%s didn't return an HttpResponse object. It returned"
    ],
    [
        "\"%s didn't return an HttpResponse object. It returned an \"",
        "\"%s didn't return an HttpResponse object. It"
    ],
    [
        "\"unawaited coroutine instead. You may need to add an 'await' \"",
        "\"unawaited coroutine instead. You may need to"
    ],
    [
        "if settings_dict[\"ATOMIC_REQUESTS\"] and alias not in non_atomic_requests:",
        "if settings_dict[\"ATOMIC_REQUESTS\"] and alias not in"
    ],
    [
        "\"You cannot use ATOMIC_REQUESTS with async views.\"",
        "\"You cannot use ATOMIC_REQUESTS"
    ],
    [
        "Pass the exception to the exception middleware. If no middleware",
        "Pass the exception to the exception"
    ],
    [
        "return a response for this exception, return None.",
        "return a response for"
    ],
    [
        "\"\"\"Reset the URLconf after each request is finished.\"\"\"",
        "\"\"\"Reset the URLconf after"
    ],
    [
        "from django.http import HttpRequest, QueryDict, parse_cookie",
        "from django.http import"
    ],
    [
        "Wrap another stream to disallow reading it past a number of bytes.",
        "Wrap another stream to disallow reading it past a"
    ],
    [
        "Based on the implementation from werkzeug.wsgi.LimitedStream",
        "Based on the implementation from"
    ],
    [
        "size = min(size, limit - _pos)",
        "size = min(size, limit"
    ],
    [
        "size = min(size, limit - _pos)",
        "size = min(size,"
    ],
    [
        "status = \"%d %s\" % (response.status_code, response.reason_phrase)",
        "status = \"%d %s\" %"
    ],
    [
        "*((\"Set-Cookie\", c.output(header=\"\")) for c in response.cookies.values()),",
        "*((\"Set-Cookie\", c.output(header=\"\")) for"
    ],
    [
        "if getattr(response, \"file_to_stream\", None) is not None and environ.get(",
        "if getattr(response, \"file_to_stream\", None) is not None and"
    ],
    [
        "\"\"\"Return the HTTP request's PATH_INFO as a string.\"\"\"",
        "\"\"\"Return the HTTP request's"
    ],
    [
        "Return the equivalent of the HTTP request's SCRIPT_NAME environment",
        "Return the equivalent of the HTTP request's SCRIPT_NAME"
    ],
    [
        "variable. If Apache mod_rewrite is used, return what would have been",
        "variable. If Apache mod_rewrite is used, return"
    ],
    [
        "the script name prior to any rewriting (so it's the script name as seen",
        "the script name prior to any rewriting (so it's the"
    ],
    [
        "from the client's perspective), unless the FORCE_SCRIPT_NAME setting is",
        "from the client's perspective), unless"
    ],
    [
        "script_url = get_bytes_from_wsgi(environ, \"SCRIPT_URL\", \"\") or get_bytes_from_wsgi(",
        "script_url = get_bytes_from_wsgi(environ, \"SCRIPT_URL\","
    ],
    [
        "Get a value from the WSGI environ dictionary as bytes.",
        "Get a value from the"
    ],
    [
        "key and default should be strings.",
        "key and default"
    ],
    [
        "Get a value from the WSGI environ dictionary as str.",
        "Get a value from the WSGI"
    ],
    [
        "key and default should be str objects.",
        "key and default should be"
    ],
    [
        "This is a simple server for use in testing or debugging Django apps. It hasn't",
        "This is a simple server for use in testing or"
    ],
    [
        "been reviewed for security issues. DON'T USE IT FOR PRODUCTION USE!",
        "been reviewed for security issues. DON'T USE IT"
    ],
    [
        "Load and return the WSGI application as configured by the user in",
        "Load and return the WSGI application"
    ],
    [
        "``settings.WSGI_APPLICATION``. With the default ``startproject`` layout,",
        "``settings.WSGI_APPLICATION``. With the default"
    ],
    [
        "this will be the ``application`` object in ``projectname/wsgi.py``.",
        "this will be the ``application`` object"
    ],
    [
        "This function, and the ``WSGI_APPLICATION`` setting itself, are only useful",
        "This function, and the ``WSGI_APPLICATION`` setting"
    ],
    [
        "for Django's internal server (runserver); external WSGI servers should just",
        "for Django's internal server (runserver); external WSGI servers"
    ],
    [
        "be configured to point to the correct application object directly.",
        "be configured to point to the correct"
    ],
    [
        "If settings.WSGI_APPLICATION is not set (is ``None``), return",
        "If settings.WSGI_APPLICATION is not set"
    ],
    [
        "\"WSGI application '%s' could not be loaded; \"",
        "\"WSGI application '%s' could"
    ],
    [
        "\"\"\"BaseHTTPServer that implements the Python WSGI protocol\"\"\"",
        "\"\"\"BaseHTTPServer that implements the Python"
    ],
    [
        "logger.info(\"- Broken pipe from %s\", client_address)",
        "logger.info(\"- Broken pipe"
    ],
    [
        "\"\"\"A threaded version of the WSGIServer\"\"\"",
        "\"\"\"A threaded version"
    ],
    [
        "def __init__(self, stdin, stdout, stderr, environ, **kwargs):",
        "def __init__(self, stdin, stdout, stderr, environ,"
    ],
    [
        "Use a LimitedStream so that unread request data will be ignored at",
        "Use a LimitedStream so that unread request data will be"
    ],
    [
        "the end of the request. WSGIRequest uses a LimitedStream but it",
        "the end of the request. WSGIRequest uses a"
    ],
    [
        "shouldn't discard the data since the upstream servers usually do this.",
        "shouldn't discard the data since the upstream"
    ],
    [
        "This fix applies only for testserver/runserver.",
        "This fix applies only for"
    ],
    [
        "LimitedStream(stdin, content_length), stdout, stderr, environ, **kwargs",
        "LimitedStream(stdin, content_length), stdout, stderr, environ,"
    ],
    [
        "\"You're accessing the development server over HTTPS, but \"",
        "\"You're accessing the development server over"
    ],
    [
        "\"\"\"Copy of WSGIRequestHandler.handle() but with different ServerHandler\"\"\"",
        "\"\"\"Copy of WSGIRequestHandler.handle() but"
    ],
    [
        "httpd_cls = type(\"WSGIServer\", (socketserver.ThreadingMixIn, server_cls), {})",
        "httpd_cls = type(\"WSGIServer\", (socketserver.ThreadingMixIn, server_cls),"
    ],
    [
        "if setting in {\"LANGUAGES\", \"LANGUAGE_CODE\", \"LOCALE_PATHS\"}:",
        "if setting in {\"LANGUAGES\","
    ],
    [
        "if setting in FORMAT_SETTINGS or setting == \"USE_THOUSAND_SEPARATOR\":",
        "if setting in FORMAT_SETTINGS or setting"
    ],
    [
        "if enter and setting in COMPLEX_OVERRIDE_SETTINGS:",
        "if enter and setting in"
    ],
    [
        "f\"Overriding setting {setting} can lead to unexpected behavior.\",",
        "f\"Overriding setting {setting} can lead to"
    ],
    [
        "from django.test.utils import NullTimeKeeper, TimeKeeper, iter_test_cases",
        "from django.test.utils import NullTimeKeeper,"
    ],
    [
        "from django.test.utils import setup_databases as _setup_databases",
        "from django.test.utils import setup_databases as"
    ],
    [
        "from django.test.utils import teardown_databases as _teardown_databases",
        "from django.test.utils import"
    ],
    [
        "for test, err, sql_debug in errors:",
        "for test, err, sql_debug"
    ],
    [
        "Custom result class that triggers a PDB session when an error or failure",
        "Custom result class that triggers a PDB session"
    ],
    [
        "Dummy list class for faking storage of results in unittest.TestResult.",
        "Dummy list class for faking storage of"
    ],
    [
        "Extend unittest.TestResult to record events in the child processes so they",
        "Extend unittest.TestResult to record events in the child processes so"
    ],
    [
        "can be replayed in the parent process. Events include things like which",
        "can be replayed in the parent process. Events include"
    ],
    [
        "Confirm that obj can be pickled and unpickled as multiprocessing will",
        "Confirm that obj can be pickled and unpickled"
    ],
    [
        "need to pickle the exception in the child process and unpickle it in",
        "need to pickle the exception in the child process and"
    ],
    [
        "the parent process. Let the exception rise, if not.",
        "the parent process. Let the exception"
    ],
    [
        "Unfortunately, the subtest that failed cannot be pickled, so the parallel",
        "Unfortunately, the subtest that failed cannot be"
    ],
    [
        "test runner cannot handle it cleanly. Here is the pickling error:",
        "test runner cannot handle it cleanly. Here is the pickling"
    ],
    [
        "Unfortunately, tracebacks cannot be pickled, making it impossible for the",
        "Unfortunately, tracebacks cannot be pickled,"
    ],
    [
        "parallel test runner to handle this exception cleanly.",
        "parallel test runner to handle"
    ],
    [
        "In order to see the traceback, you should install tblib:",
        "In order to see the traceback, you should install"
    ],
    [
        "Unfortunately, the exception it raised cannot be pickled, making it impossible",
        "Unfortunately, the exception it raised cannot be pickled, making it"
    ],
    [
        "for the parallel test runner to handle it cleanly.",
        "for the parallel test runner"
    ],
    [
        "Here's the error encountered while trying to pickle the exception:",
        "Here's the error encountered while trying to pickle the"
    ],
    [
        "failure and get a correct traceback.",
        "failure and get a correct"
    ],
    [
        "\"\"\"Tells whether or not this result was a success.\"\"\"",
        "\"\"\"Tells whether or not this result was"
    ],
    [
        "failure_types = {\"addError\", \"addFailure\", \"addSubTest\", \"addUnexpectedSuccess\"}",
        "failure_types = {\"addError\","
    ],
    [
        "Run tests and record everything but don't display anything.",
        "Run tests and record everything but don't display"
    ],
    [
        "The maximum number of test processes when using the --parallel option.",
        "The maximum number of test processes when using the"
    ],
    [
        "if multiprocessing.get_start_method() not in {\"fork\", \"spawn\"}:",
        "if multiprocessing.get_start_method() not in"
    ],
    [
        "\"\"\"Parse value passed to the --parallel option.\"\"\"",
        "\"\"\"Parse value passed to the"
    ],
    [
        "f\"{value!r} is not an integer or the string 'auto'\"",
        "f\"{value!r} is not an integer or the"
    ],
    [
        "Switch to databases dedicated to this worker.",
        "Switch to databases dedicated"
    ],
    [
        "This helper lives at module-level because of the multiprocessing module's",
        "This helper lives at module-level because"
    ],
    [
        "db_aliases = used_aliases if used_aliases is not None else connections",
        "db_aliases = used_aliases if used_aliases"
    ],
    [
        "Run a suite of tests with a RemoteTestRunner and return a RemoteTestResult.",
        "Run a suite of tests with a RemoteTestRunner and"
    ],
    [
        "This helper lives at module-level and its arguments are wrapped in a tuple",
        "This helper lives at module-level and its arguments are wrapped in"
    ],
    [
        "because of the multiprocessing module's requirements.",
        "because of the multiprocessing module's"
    ],
    [
        "runner_class, subsuite_index, subsuite, failfast, buffer = args",
        "runner_class, subsuite_index, subsuite, failfast,"
    ],
    [
        "\"\"\"Stub method to simplify run() implementation.\"\"\"",
        "\"\"\"Stub method to simplify run()"
    ],
    [
        "Run a series of tests in parallel in several processes.",
        "Run a series of tests in parallel in"
    ],
    [
        "While the unittest module's documentation implies that orchestrating the",
        "While the unittest module's documentation implies that"
    ],
    [
        "execution of tests is the responsibility of the test runner, in practice,",
        "execution of tests is the responsibility of the test runner, in"
    ],
    [
        "it appears that TestRunner classes are more concerned with formatting and",
        "it appears that TestRunner classes are"
    ],
    [
        "Since there are fewer use cases for customizing TestSuite than TestRunner,",
        "Since there are fewer use cases for customizing"
    ],
    [
        "implementing parallelization at the level of the TestSuite improves",
        "implementing parallelization at the level"
    ],
    [
        "interoperability with existing custom test runners. A single instance of a",
        "interoperability with existing custom test runners. A single"
    ],
    [
        "test runner can still collect results from all tests without being aware",
        "test runner can still collect results from all tests without"
    ],
    [
        "that they have been run in parallel.",
        "that they have been"
    ],
    [
        "self, subsuites, processes, failfast=False, debug_mode=False, buffer=False",
        "self, subsuites, processes, failfast=False,"
    ],
    [
        "Return an identifier of each TestCase with its result in order to use",
        "Return an identifier of each TestCase with its result"
    ],
    [
        "imap_unordered to show results as soon as they're available.",
        "imap_unordered to show results as soon as they're"
    ],
    [
        "To minimize pickling errors when getting results from workers:",
        "To minimize pickling errors when getting"
    ],
    [
        "- pass back numeric indexes in self.subsuites instead of tests",
        "- pass back numeric indexes in self.subsuites instead of"
    ],
    [
        "- make tracebacks picklable with tblib, if available",
        "- make tracebacks picklable"
    ],
    [
        "Even with tblib, errors may still occur for dynamically created",
        "Even with tblib, errors may still occur for dynamically"
    ],
    [
        "exception classes which cannot be unpickled.",
        "exception classes which cannot be"
    ],
    [
        "alias: connections[alias].settings_dict for alias in connections",
        "alias: connections[alias].settings_dict for alias in"
    ],
    [
        "This class implements shuffling with a special consistency property.",
        "This class implements shuffling with"
    ],
    [
        "Consistency means that, for a given seed and key function, if two sets of",
        "Consistency means that, for a given seed and key function, if two sets"
    ],
    [
        "items are shuffled, the resulting order will agree on the intersection of",
        "items are shuffled, the resulting order"
    ],
    [
        "the two sets. For example, if items are removed from an original set, the",
        "the two sets. For example, if items are removed"
    ],
    [
        "shuffled order for the new set will be the shuffled order of the original",
        "shuffled order for the new set will be the shuffled order"
    ],
    [
        "set restricted to the smaller set.",
        "set restricted to the smaller"
    ],
    [
        "Return a new list of the items in a shuffled order.",
        "Return a new list of the items in a"
    ],
    [
        "The `key` is a function that accepts an item in `items` and returns",
        "The `key` is a function that accepts"
    ],
    [
        "a string unique for that item that can be viewed as a string id. The",
        "a string unique for that item that can"
    ],
    [
        "order of the return value is deterministic. It depends on the seed",
        "order of the return value is deterministic."
    ],
    [
        "and key function but not on the original order.",
        "and key function but not on"
    ],
    [
        "msg = \"item {!r} has same hash {!r} as item {!r}\".format(",
        "msg = \"item {!r} has same hash {!r} as item"
    ],
    [
        "return [hashes[hashed] for hashed in sorted(hashes)]",
        "return [hashes[hashed] for hashed in"
    ],
    [
        "self.time_keeper = TimeKeeper() if timing else NullTimeKeeper()",
        "self.time_keeper = TimeKeeper() if timing"
    ],
    [
        "pattern if \"*\" in pattern else \"*%s*\" % pattern",
        "pattern if \"*\" in pattern else \"*%s*\""
    ],
    [
        "help=\"Stops the test suite after the first failure.\",",
        "help=\"Stops the test suite after the"
    ],
    [
        "help=\"Top level of project for unittest discovery.\",",
        "help=\"Top level of project for unittest"
    ],
    [
        "help=\"The test matching pattern. Defaults to test*.py.\",",
        "help=\"The test matching pattern."
    ],
    [
        "\"--keepdb\", action=\"store_true\", help=\"Preserves the test DB between runs.\"",
        "\"--keepdb\", action=\"store_true\", help=\"Preserves the test"
    ],
    [
        "help=\"Prints logged SQL queries on failure.\",",
        "help=\"Prints logged SQL queries on"
    ],
    [
        "\"Run tests using up to N parallel processes. Use the value \"",
        "\"Run tests using up to N parallel processes."
    ],
    [
        "'\"auto\" to run one test process for each processor core.'",
        "'\"auto\" to run one test process"
    ],
    [
        "help=\"Run only tests with the specified tag. Can be used multiple times.\",",
        "help=\"Run only tests with the specified tag. Can be used"
    ],
    [
        "help=\"Do not run tests with the specified tag. Can be used multiple times.\",",
        "help=\"Do not run tests with the specified"
    ],
    [
        "help=\"Runs a debugger (pdb, or ipdb if installed) on error or failure.\",",
        "help=\"Runs a debugger (pdb, or ipdb"
    ],
    [
        "help=\"Disables the Python faulthandler module during tests.\",",
        "help=\"Disables the Python faulthandler module during"
    ],
    [
        "help=(\"Output timings, including database set up and total run time.\"),",
        "help=(\"Output timings, including database set"
    ],
    [
        "\"Only run test methods and classes that match the pattern \"",
        "\"Only run test methods and classes that"
    ],
    [
        "\"or substring. Can be used multiple times. Same as \"",
        "\"or substring. Can be used multiple times."
    ],
    [
        "Log the message at the given logging level (the default is INFO).",
        "Log the message at the given"
    ],
    [
        "If a logger isn't set, the message is instead printed to the console,",
        "If a logger isn't set, the message is instead printed to the"
    ],
    [
        "f\"One of the test labels is a path to a file: {label!r}, \"",
        "f\"One of the test labels is a path to"
    ],
    [
        "f\"which is not supported. Use a dotted module name or \"",
        "f\"which is not supported. Use a dotted"
    ],
    [
        "\"Including test tag(s): %s.\" % \", \".join(sorted(self.tags)),",
        "\"Including test tag(s): %s.\" %"
    ],
    [
        "\"Excluding test tag(s): %s.\" % \", \".join(sorted(self.exclude_tags)),",
        "\"Excluding test tag(s): %s.\""
    ],
    [
        "unused_databases = [alias for alias in connections if alias not in databases]",
        "unused_databases = [alias for alias in connections if alias not in"
    ],
    [
        "\"Skipping setup of unused database(s): %s.\"",
        "\"Skipping setup of"
    ],
    [
        "Run the unit tests for all the test labels in the provided list.",
        "Run the unit tests for all the test labels in"
    ],
    [
        "Test labels should be dotted Python paths to test modules, test",
        "Test labels should be dotted Python paths to"
    ],
    [
        "Return the number of tests that failed.",
        "Return the number of tests"
    ],
    [
        "alias for alias, serialize in databases.items() if serialize",
        "alias for alias, serialize in"
    ],
    [
        "Try importing a test label, and return (is_importable, is_package).",
        "Try importing a test label, and"
    ],
    [
        "Relative labels like \".\" and \"..\" are seen as directories.",
        "Relative labels like \".\" and \"..\""
    ],
    [
        "Return an iterator over the given tests in a shuffled order, keeping tests",
        "Return an iterator over the given tests in a shuffled order, keeping"
    ],
    [
        "next to other tests of their class.",
        "next to other tests of their"
    ],
    [
        "`tests` should be an iterable of tests.",
        "`tests` should be an iterable"
    ],
    [
        "for _, class_tests in itertools.groupby(tests, type):",
        "for _, class_tests in itertools.groupby(tests,"
    ],
    [
        "class_tests = shuffler.shuffle(class_tests, key=lambda test: test.id())",
        "class_tests = shuffler.shuffle(class_tests, key=lambda"
    ],
    [
        "return itertools.chain(*(tests_by_type[cls] for cls in classes))",
        "return itertools.chain(*(tests_by_type[cls] for cls"
    ],
    [
        "Return an iterator that reorders the given tests, keeping tests next to",
        "Return an iterator that reorders the"
    ],
    [
        "`tests` should be an iterable of tests that supports reversed().",
        "`tests` should be an iterable of tests that"
    ],
    [
        "Reorder an iterable of tests, grouping by the given TestCase classes.",
        "Reorder an iterable of tests, grouping by the given"
    ],
    [
        "This function also removes any duplicates and reorders so that tests of the",
        "This function also removes any duplicates and reorders so that"
    ],
    [
        "The result is returned as an iterator. `classes` is a sequence of types.",
        "The result is returned as an iterator. `classes` is a sequence of"
    ],
    [
        "If `reverse` is True, the tests within each `classes` group are reversed,",
        "If `reverse` is True, the tests within"
    ],
    [
        "but without reversing the order of `classes` itself.",
        "but without reversing the order of"
    ],
    [
        "The `shuffler` argument is an optional instance of this module's `Shuffler`",
        "The `shuffler` argument is an optional"
    ],
    [
        "class. If provided, tests will be shuffled within each `classes` group, but",
        "class. If provided, tests will be shuffled within"
    ],
    [
        "keeping tests with other tests of their TestCase class. Reversing is",
        "keeping tests with other tests of their TestCase class."
    ],
    [
        "applied after shuffling to allow reversing the same random order.",
        "applied after shuffling to allow"
    ],
    [
        "for test_bin, test_class in zip(class_bins, classes):",
        "for test_bin, test_class in"
    ],
    [
        "\"\"\"Partition a test suite by TestCase, preserving the order of tests.\"\"\"",
        "\"\"\"Partition a test suite by TestCase,"
    ],
    [
        "return [suite_class(tests) for _, tests in itertools.groupby(all_tests, type)]",
        "return [suite_class(tests) for _, tests in"
    ],
    [
        "\"\"\"Return the matching tests as an iterator.\"\"\"",
        "\"\"\"Return the matching tests as"
    ],
    [
        "return (test for test in tests if test_match_tags(test, tags, exclude_tags))",
        "return (test for test in tests if test_match_tags(test,"
    ],
    [
        "from urllib.parse import unquote_to_bytes, urljoin, urlsplit",
        "from urllib.parse import"
    ],
    [
        "from django.core.signals import got_request_exception, request_finished, request_started",
        "from django.core.signals import got_request_exception, request_finished,"
    ],
    [
        "from django.http import HttpHeaders, HttpRequest, QueryDict, SimpleCookie",
        "from django.http import HttpHeaders,"
    ],
    [
        "MULTIPART_CONTENT = \"multipart/form-data; boundary=%s\" % BOUNDARY",
        "MULTIPART_CONTENT = \"multipart/form-data; boundary=%s\""
    ],
    [
        "\"\"\"The test client has been asked to follow a redirect loop.\"\"\"",
        "\"\"\"The test client has been asked to follow"
    ],
    [
        "A wrapper around BytesIO that restricts what can be read since data from",
        "A wrapper around BytesIO that restricts what can be"
    ],
    [
        "the network can't be sought and cannot be read outside of its content",
        "the network can't be sought and cannot be"
    ],
    [
        "length. This makes sure that views can't do anything under the test client",
        "length. This makes sure that views can't do anything"
    ],
    [
        "that wouldn't work in real life.",
        "that wouldn't work in real"
    ],
    [
        "), \"Cannot read more than the available bytes from the HTTP incoming data.\"",
        "), \"Cannot read more than the available"
    ],
    [
        "), \"Cannot read more than the available bytes from the HTTP incoming data.\"",
        "), \"Cannot read more than the available bytes from"
    ],
    [
        "raise ValueError(\"Unable to write a payload after it's been read\")",
        "raise ValueError(\"Unable to write a payload"
    ],
    [
        "Simulate the behavior of most web servers by removing the content of",
        "Simulate the behavior of most web servers by removing the content"
    ],
    [
        "An HTTP Handler that can be used for testing purposes. Use the WSGI",
        "An HTTP Handler that can be used for testing purposes. Use the"
    ],
    [
        "interface to compose requests, but return the raw HttpResponse object with",
        "interface to compose requests, but return the raw HttpResponse"
    ],
    [
        "the originating WSGIRequest attached to its ``wsgi_request`` attribute.",
        "the originating WSGIRequest attached to its"
    ],
    [
        "def store_rendered_templates(store, signal, sender, template, context, **kwargs):",
        "def store_rendered_templates(store, signal, sender, template,"
    ],
    [
        "Store templates and contexts that are rendered.",
        "Store templates and contexts that are"
    ],
    [
        "The context is copied so that it is an accurate representation at the time",
        "The context is copied so that it is"
    ],
    [
        "Encode multipart POST data from a dictionary of form values.",
        "Encode multipart POST data from"
    ],
    [
        "The key will be used as the form data name; the value will be transmitted",
        "The key will be used as the form data name; the value will be"
    ],
    [
        "as content. If the value is a file, the contents of the file will be sent",
        "as content. If the value is a file, the contents of"
    ],
    [
        "as an application/octet-stream; otherwise, str(value) will be sent.",
        "as an application/octet-stream; otherwise, str(value) will be"
    ],
    [
        "\"Cannot encode None for key '%s' as POST data. Did you mean \"",
        "\"Cannot encode None for key '%s' as POST data. Did you"
    ],
    [
        "\"to pass an empty string or omit the value?\" % key",
        "\"to pass an empty string or omit the value?\""
    ],
    [
        "elif not isinstance(value, str) and isinstance(value, Iterable):",
        "elif not isinstance(value, str) and"
    ],
    [
        "file_has_string_name = hasattr(file, \"name\") and isinstance(file.name, str)",
        "file_has_string_name = hasattr(file, \"name\") and"
    ],
    [
        "filename = os.path.basename(file.name) if file_has_string_name else \"\"",
        "filename = os.path.basename(file.name) if file_has_string_name"
    ],
    [
        "'Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' % (key, filename)",
        "'Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"'"
    ],
    [
        "Class that lets you create mock Request objects for use in testing.",
        "Class that lets you create mock Request objects for"
    ],
    [
        "Once you have a request object you can pass it to any view function,",
        "Once you have a request object you can pass it to"
    ],
    [
        "just as if that view had been hooked up using a URLconf.",
        "just as if that view had"
    ],
    [
        "The base environment for a request.",
        "The base environment for"
    ],
    [
        "Return encoded JSON if data is a dict, list, or tuple and content_type",
        "Return encoded JSON if data is a"
    ],
    [
        "return json.dumps(data, cls=self.json_encoder) if should_encode else data",
        "return json.dumps(data, cls=self.json_encoder) if"
    ],
    [
        "self, path, data=None, secure=False, *, headers=None, query_params=None, **extra",
        "self, path, data=None, secure=False,"
    ],
    [
        "raise ValueError(\"query_params and data arguments are mutually exclusive.\")",
        "raise ValueError(\"query_params and data arguments are"
    ],
    [
        "query_params = {} if query_params is None else query_params",
        "query_params = {} if query_params"
    ],
    [
        "data = self._encode_json({} if data is None else data, content_type)",
        "data = self._encode_json({} if data is"
    ],
    [
        "self, path, data=None, secure=False, *, headers=None, query_params=None, **extra",
        "self, path, data=None, secure=False, *, headers=None,"
    ],
    [
        "raise ValueError(\"query_params and data arguments are mutually exclusive.\")",
        "raise ValueError(\"query_params and data"
    ],
    [
        "query_params = {} if query_params is None else query_params",
        "query_params = {} if query_params is None else"
    ],
    [
        "def trace(self, path, secure=False, *, headers=None, query_params=None, **extra):",
        "def trace(self, path, secure=False,"
    ],
    [
        "\"wsgi.url_scheme\": \"https\" if secure else \"http\",",
        "\"wsgi.url_scheme\": \"https\" if secure"
    ],
    [
        "Class that lets you create mock ASGI-like Request objects for use in",
        "Class that lets you create mock ASGI-like"
    ],
    [
        "Once you have a request object you can pass it to any view function,",
        "Once you have a request object you can"
    ],
    [
        "including synchronous ones. The reason we have a separate class here is:",
        "including synchronous ones. The reason we have a separate class here"
    ],
    [
        "a) this makes ASGIRequest subclasses, and",
        "a) this makes ASGIRequest subclasses,"
    ],
    [
        "\"\"\"The base scope for a request.\"\"\"",
        "\"\"\"The base scope for"
    ],
    [
        "\"scheme\": \"https\" if secure else \"http\",",
        "\"scheme\": \"https\" if secure else"
    ],
    [
        "Mixin with common methods between Client and AsyncClient.",
        "Mixin with common methods between Client"
    ],
    [
        "\"\"\"Store exceptions when they are generated by a view.\"\"\"",
        "\"\"\"Store exceptions when they are generated"
    ],
    [
        "Look for a signaled exception, clear the current context exception",
        "Look for a signaled exception, clear the current"
    ],
    [
        "data, re-raise the signaled exception, and clear the signaled exception",
        "data, re-raise the signaled exception, and clear the signaled"
    ],
    [
        "Set the Factory to appear as if it has successfully logged into a site.",
        "Set the Factory to appear as if it"
    ],
    [
        "Return True if login is possible or False if the provided credentials",
        "Return True if login is possible or False"
    ],
    [
        "\"\"\"Log out the user by removing the cookies and session object.\"\"\"",
        "\"\"\"Log out the user by removing the cookies and"
    ],
    [
        "'Content-Type header is \"%s\", not \"application/json\"'",
        "'Content-Type header is"
    ],
    [
        "\"\"\"Follow a single redirect contained in response using GET.\"\"\"",
        "\"\"\"Follow a single redirect contained in response using"
    ],
    [
        "if request_method not in (\"get\", \"head\"):",
        "if request_method not"
    ],
    [
        "Raise a RedirectCycleError if response contains too many redirects.",
        "Raise a RedirectCycleError if response contains too"
    ],
    [
        "A class that can act as a client for testing purposes.",
        "A class that can act as a client for testing"
    ],
    [
        "It allows the user to compose GET and POST requests, and",
        "It allows the user to compose GET and"
    ],
    [
        "obtain the response that the server gave to those requests.",
        "obtain the response that the server gave"
    ],
    [
        "The server Response objects are annotated with the details",
        "The server Response objects are annotated with the"
    ],
    [
        "of the contexts and templates that were rendered during the",
        "of the contexts and templates that"
    ],
    [
        "Client objects are stateful - they will retain cookie (and",
        "Client objects are stateful -"
    ],
    [
        "thus session) details for the lifetime of the Client instance.",
        "thus session) details for the lifetime of the Client"
    ],
    [
        "This is not intended as a replacement for Twill/Selenium or",
        "This is not intended as a"
    ],
    [
        "the like - it is here to allow testing against the",
        "the like - it is here"
    ],
    [
        "contexts and templates produced by a view, rather than the",
        "contexts and templates produced by a view,"
    ],
    [
        "Make a generic request. Compose the environment dictionary and pass",
        "Make a generic request. Compose the environment dictionary"
    ],
    [
        "to the handler, return the result of the handler. Assume defaults for",
        "to the handler, return the result of the"
    ],
    [
        "the query environment, which can be overridden using the arguments to",
        "the query environment, which can be overridden using the"
    ],
    [
        "\"\"\"Request a response from the server using GET.\"\"\"",
        "\"\"\"Request a response from the"
    ],
    [
        "\"\"\"Request a response from the server using POST.\"\"\"",
        "\"\"\"Request a response from the server using"
    ],
    [
        "\"\"\"Request a response from the server using HEAD.\"\"\"",
        "\"\"\"Request a response from the server using"
    ],
    [
        "\"\"\"Request a response from the server using OPTIONS.\"\"\"",
        "\"\"\"Request a response from the server"
    ],
    [
        "\"\"\"Send a resource to the server using PUT.\"\"\"",
        "\"\"\"Send a resource to"
    ],
    [
        "\"\"\"Send a resource to the server using PATCH.\"\"\"",
        "\"\"\"Send a resource to the"
    ],
    [
        "\"\"\"Send a DELETE request to the server.\"\"\"",
        "\"\"\"Send a DELETE request to the"
    ],
    [
        "\"\"\"Send a TRACE request to the server.\"\"\"",
        "\"\"\"Send a TRACE request to"
    ],
    [
        "Follow any redirects by requesting responses from the server using GET.",
        "Follow any redirects by requesting responses from the"
    ],
    [
        "An async version of Client that creates ASGIRequests and calls through an",
        "An async version of Client that creates ASGIRequests and calls"
    ],
    [
        "Does not currently support \"follow\" on its methods.",
        "Does not currently support \"follow\" on"
    ],
    [
        "Make a generic request. Compose the scope dictionary and pass to the",
        "Make a generic request. Compose the scope dictionary and pass"
    ],
    [
        "handler, return the result of the handler. Assume defaults for the",
        "handler, return the result of the"
    ],
    [
        "query environment, which can be overridden using the arguments to the",
        "query environment, which can be overridden using the"
    ],
    [
        "\"\"\"Request a response from the server using GET.\"\"\"",
        "\"\"\"Request a response from the"
    ],
    [
        "\"\"\"Request a response from the server using POST.\"\"\"",
        "\"\"\"Request a response from the server using"
    ],
    [
        "\"\"\"Request a response from the server using HEAD.\"\"\"",
        "\"\"\"Request a response from the"
    ],
    [
        "\"\"\"Request a response from the server using OPTIONS.\"\"\"",
        "\"\"\"Request a response from the server using"
    ],
    [
        "\"\"\"Send a resource to the server using PUT.\"\"\"",
        "\"\"\"Send a resource to"
    ],
    [
        "\"\"\"Send a resource to the server using PATCH.\"\"\"",
        "\"\"\"Send a resource to the server using"
    ],
    [
        "\"\"\"Send a DELETE request to the server.\"\"\"",
        "\"\"\"Send a DELETE request to"
    ],
    [
        "\"\"\"Send a TRACE request to the server.\"\"\"",
        "\"\"\"Send a TRACE request"
    ],
    [
        "Follow any redirects by requesting responses from the server using GET.",
        "Follow any redirects by requesting responses from the"
    ],
    [
        "if name == \"class\" and value:",
        "if name == \"class\""
    ],
    [
        "sorted(value for value in ASCII_WHITESPACE.split(value) if value)",
        "sorted(value for value in"
    ],
    [
        "if not value or value == name:",
        "if not value or value =="
    ],
    [
        "if not hasattr(element, \"name\") or self.name != element.name:",
        "if not hasattr(element, \"name\")"
    ],
    [
        "if not isinstance(element, str) and self == element:",
        "if not isinstance(element, str) and self =="
    ],
    [
        "if isinstance(element, RootElement) and self.children == element.children:",
        "if isinstance(element, RootElement) and self.children"
    ],
    [
        "output += ' %s=\"%s\"' % (key, value)",
        "output += ' %s=\"%s\"' % (key,"
    ],
    [
        "output += \" %s\" % key",
        "output += \""
    ],
    [
        "html.escape(c) if isinstance(c, str) else str(c)",
        "html.escape(c) if isinstance(c, str)"
    ],
    [
        "[html.escape(c) if isinstance(c, str) else str(c) for c in self.children]",
        "[html.escape(c) if isinstance(c, str) else"
    ],
    [
        "return \"Line %d, Column %d\" % position",
        "return \"Line %d, Column"
    ],
    [
        "self.error(\"Unexpected end tag `%s` (%s)\" % (tag, self.format_position()))",
        "self.error(\"Unexpected end tag `%s`"
    ],
    [
        "\"Unexpected end tag `%s` (%s)\" % (tag, self.format_position())",
        "\"Unexpected end tag `%s` (%s)\" % (tag,"
    ],
    [
        "Take a string that contains HTML and turn it into a Python object structure",
        "Take a string that contains HTML and turn it"
    ],
    [
        "that can be easily compared against other HTML on semantic equivalence.",
        "that can be easily compared against other HTML on"
    ],
    [
        "Syntactical differences like which quotation is used on arguments will be",
        "Syntactical differences like which quotation is used on arguments"
    ],
    [
        "from django.test.client import AsyncClient, AsyncRequestFactory, Client, RequestFactory",
        "from django.test.client import AsyncClient, AsyncRequestFactory,"
    ],
    [
        "from django.test import LiveServerTestCase, override_settings, tag",
        "from django.test import LiveServerTestCase, override_settings,"
    ],
    [
        "Dynamically create new classes and add them to the test module when",
        "Dynamically create new classes and add them to the"
    ],
    [
        "multiple browsers specs are provided (e.g. --selenium=firefox,chrome).",
        "multiple browsers specs are provided (e.g."
    ],
    [
        "test_class = super().__new__(cls, name, bases, attrs)",
        "test_class = super().__new__(cls,"
    ],
    [
        "name.startswith(\"test\") and callable(value) for name, value in attrs.items()",
        "name.startswith(\"test\") and callable(value) for name, value in"
    ],
    [
        "def test(self, *args, _func=func, _case=screenshot_case, **kwargs):",
        "def test(self, *args, _func=func,"
    ],
    [
        "return \"http://%s:%s\" % (cls.external_host or cls.host, cls.server_thread.port)",
        "return \"http://%s:%s\" % (cls.external_host or cls.host,"
    ],
    [
        "if self.browser not in {\"chrome\", \"edge\"}:",
        "if self.browser not"
    ],
    [
        "\"Emulation.setEmulatedMedia is only supported on Chromium and \"",
        "\"Emulation.setEmulatedMedia is only supported on"
    ],
    [
        "path = Path.cwd() / \"screenshots\" / filename",
        "path = Path.cwd() /"
    ],
    [
        "from unittest import TestCase, skipIf, skipUnless",
        "from unittest import TestCase,"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connections, reset_queries",
        "from django.db import"
    ],
    [
        "A wrapper that provides direct key access to context items contained",
        "A wrapper that provides direct key access to"
    ],
    [
        "in a list of context objects.",
        "in a list"
    ],
    [
        "return set(chain.from_iterable(d for subcontext in self for d in subcontext))",
        "return set(chain.from_iterable(d for subcontext in"
    ],
    [
        "An instrumented Template render method, providing a signal that can be",
        "An instrumented Template render method, providing a"
    ],
    [
        "Perform global pre-test setup, such as installing the instrumented template",
        "Perform global pre-test setup, such as installing the"
    ],
    [
        "renderer and setting the email backend to the locmem email backend.",
        "renderer and setting the email backend to the locmem"
    ],
    [
        "\"setup_test_environment() was already called and can't be called \"",
        "\"setup_test_environment() was already called and can't be called"
    ],
    [
        "Perform any global post-test teardown, such as restoring the original",
        "Perform any global post-test teardown, such as restoring the"
    ],
    [
        "template renderer and restoring the email sending functions.",
        "template renderer and restoring the email"
    ],
    [
        "with time_keeper.timed(\"  Creating '%s'\" % alias):",
        "with time_keeper.timed(\" Creating"
    ],
    [
        "serialized_aliases is None or alias in serialized_aliases",
        "serialized_aliases is None or alias"
    ],
    [
        "with time_keeper.timed(\"  Cloning '%s'\" % alias):",
        "with time_keeper.timed(\" Cloning '%s'\" %"
    ],
    [
        "Return an iterator over a test suite's unittest.TestCase objects.",
        "Return an iterator over a test suite's"
    ],
    [
        "The tests argument can also be an iterable of TestCase objects.",
        "The tests argument can also be an iterable of TestCase"
    ],
    [
        "f\"Test {test!r} must be a test case or test suite not string \"",
        "f\"Test {test!r} must be a test case or test"
    ],
    [
        "Reorder test_databases into an order that honors the dependencies",
        "Reorder test_databases into an order"
    ],
    [
        "for sig, (_, aliases) in test_databases:",
        "for sig, (_, aliases)"
    ],
    [
        "\"Circular dependency: databases %r depend on each other, \"",
        "\"Circular dependency: databases %r depend on"
    ],
    [
        "for signature, (db_name, aliases) in test_databases:",
        "for signature, (db_name, aliases) in"
    ],
    [
        "Figure out which databases actually need to be created.",
        "Figure out which databases actually need to be"
    ],
    [
        "Deduplicate entries in DATABASES that correspond the same database or are",
        "Deduplicate entries in DATABASES that correspond the same database"
    ],
    [
        "- test_databases: ordered mapping of signatures to (name, list of aliases)",
        "- test_databases: ordered mapping of signatures to"
    ],
    [
        "where all aliases share the same underlying database.",
        "where all aliases share the"
    ],
    [
        "- mirrored_aliases: mapping of mirror aliases to original aliases.",
        "- mirrored_aliases: mapping of mirror aliases to original"
    ],
    [
        "for connection, old_name, destroy in old_config:",
        "for connection, old_name,"
    ],
    [
        "A base class that can either be used as a context manager during tests",
        "A base class that can either be used as a context"
    ],
    [
        "or as a test function or unittest.TestCase subclass decorator to perform",
        "or as a test function or unittest.TestCase subclass decorator"
    ],
    [
        "`attr_name`: attribute assigned the return value of enable() if used as",
        "`attr_name`: attribute assigned the return value of enable() if used"
    ],
    [
        "`kwarg_name`: keyword argument passing the return value of enable() if",
        "`kwarg_name`: keyword argument passing the return value of"
    ],
    [
        "raise TypeError(\"Can only decorate subclasses of unittest.TestCase\")",
        "raise TypeError(\"Can only decorate subclasses of"
    ],
    [
        "raise TypeError(\"Cannot decorate object of type %s\" % type(decorated))",
        "raise TypeError(\"Cannot decorate object of type %s\""
    ],
    [
        "Act as either a decorator or a context manager. If it's a decorator, take a",
        "Act as either a decorator or a context manager."
    ],
    [
        "function and return a wrapped function. If it's a contextmanager, use it",
        "function and return a wrapped function. If it's a"
    ],
    [
        "with the ``with`` statement. In either event, entering/exiting are called",
        "with the ``with`` statement. In either event, entering/exiting"
    ],
    [
        "before and after, respectively, the function/block is executed.",
        "before and after, respectively, the"
    ],
    [
        "\"Only subclasses of Django SimpleTestCase can be decorated \"",
        "\"Only subclasses of Django SimpleTestCase can"
    ],
    [
        "Like override_settings, but makes it possible to append, prepend, or remove",
        "Like override_settings, but makes it possible to append, prepend,"
    ],
    [
        "items instead of redefining the entire list.",
        "items instead of redefining the entire"
    ],
    [
        "value += [item for item in items if item not in value]",
        "value += [item for item in items if item not in"
    ],
    [
        "value = [item for item in items if item not in value] + value",
        "value = [item for item in items if item"
    ],
    [
        "value = [item for item in value if item not in items]",
        "value = [item for item in value"
    ],
    [
        "raise ValueError(\"Unsupported action: %s\" % action)",
        "raise ValueError(\"Unsupported action: %s\""
    ],
    [
        "Act as a decorator. Override list of registered system checks.",
        "Act as a decorator. Override list of registered"
    ],
    [
        "Useful when you override `INSTALLED_APPS`, e.g. if you exclude `auth` app,",
        "Useful when you override `INSTALLED_APPS`, e.g. if you exclude `auth`"
    ],
    [
        "you also need to exclude its system checks.",
        "you also need to exclude its"
    ],
    [
        "Try to do a 'xml-comparison' of want and got. Plain string comparison",
        "Try to do a 'xml-comparison' of want and got. Plain string"
    ],
    [
        "doesn't always work because, for example, attribute ordering should not be",
        "doesn't always work because, for example, attribute"
    ],
    [
        "important. Ignore comment nodes, processing instructions, document type",
        "important. Ignore comment nodes,"
    ],
    [
        "node, and leading and trailing whitespaces.",
        "node, and leading"
    ],
    [
        "c.data for c in element.childNodes if c.nodeType == Node.TEXT_NODE",
        "c.data for c in element.childNodes if"
    ],
    [
        "return [c for c in element.childNodes if c.nodeType == Node.ELEMENT_NODE]",
        "return [c for c in"
    ],
    [
        "check_element(want, got) for want, got in zip(want_children, got_children)",
        "check_element(want, got) for want,"
    ],
    [
        "Context manager that captures queries executed by the specified connection.",
        "Context manager that captures queries"
    ],
    [
        "if \"message\" in self.ignore_kwargs or \"module\" in self.ignore_kwargs:",
        "if \"message\" in self.ignore_kwargs or \"module\""
    ],
    [
        "\"This test relies on the ability to run a program in an arbitrary \"",
        "\"This test relies on the ability to run a program in an"
    ],
    [
        "\"time zone, but your operating system isn't able to do that.\",",
        "\"time zone, but your operating system isn't able to do"
    ],
    [
        "\"\"\"Context manager to temporarily add paths to sys.path.\"\"\"",
        "\"\"\"Context manager to temporarily add paths"
    ],
    [
        "\"\"\"Clear the cache of an LRU cache object on entering and exiting.\"\"\"",
        "\"\"\"Clear the cache of an LRU"
    ],
    [
        "\"\"\"Return a context manager used by captured_stdout/stdin/stderr",
        "\"\"\"Return a context manager used"
    ],
    [
        "that temporarily replaces the sys stream *stream_name* with a StringIO.",
        "that temporarily replaces the sys stream"
    ],
    [
        "Note: This function and the following ``captured_std*`` are copied",
        "Note: This function and the"
    ],
    [
        "Context manager to temporarily freeze time.time(). This temporarily",
        "Context manager to temporarily freeze"
    ],
    [
        "modifies the time function of the time module. Modules which import the",
        "modifies the time function of the time module. Modules which import"
    ],
    [
        "time function directly (e.g. `from time import time`) won't be affected",
        "time function directly (e.g. `from time import time`)"
    ],
    [
        "This isn't meant as a public API, but helps reduce some repetitive code in",
        "This isn't meant as a public API, but helps reduce"
    ],
    [
        "\"\"\"Decorator or context manager to temporary override the script prefix.\"\"\"",
        "\"\"\"Decorator or context manager to temporary override the"
    ],
    [
        "Capture the output from the 'django' logger and store it on the class's",
        "Capture the output from the 'django' logger and"
    ],
    [
        "Act as either a decorator or a context manager to register models defined",
        "Act as either a decorator or a context manager"
    ],
    [
        "in its wrapped context to an isolated registry.",
        "in its wrapped context to an isolated"
    ],
    [
        "The list of installed apps the isolated registry should contain must be",
        "The list of installed apps the isolated registry should contain"
    ],
    [
        "Two optional keyword arguments can be specified:",
        "Two optional keyword arguments"
    ],
    [
        "`attr_name`: attribute assigned the isolated registry if used as a class",
        "`attr_name`: attribute assigned the isolated registry if used"
    ],
    [
        "`kwarg_name`: keyword argument passing the isolated registry if used as a",
        "`kwarg_name`: keyword argument passing the isolated registry if used as"
    ],
    [
        "\"\"\"Decorator to add tags to a test class or method.\"\"\"",
        "\"\"\"Decorator to add tags to a test"
    ],
    [
        "Context manager to temporarily register lookups on a model field using",
        "Context manager to temporarily register lookups on a model field"
    ],
    [
        "lookup_name (or the lookup's lookup_name if not provided).",
        "lookup_name (or the lookup's"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connection, connections, transaction",
        "from django.db import DEFAULT_DB_ALIAS, connection, connections,"
    ],
    [
        "\"\"\"Put value into a list if it's not already one.\"\"\"",
        "\"\"\"Put value into a list if it's not already"
    ],
    [
        "Returns true if the object can be dumped and loaded through the pickle",
        "Returns true if the object can be dumped"
    ],
    [
        "standardMsg = \"%s\\n%s\" % (msg, e)",
        "standardMsg = \"%s\\n%s\""
    ],
    [
        "\"%d queries executed, %d expected\\nCaptured queries were:\\n%s\"",
        "\"%d queries executed, %d expected\\nCaptured"
    ],
    [
        "def __init__(self, test_case, template_name, msg_prefix=\"\", count=None):",
        "def __init__(self, test_case,"
    ],
    [
        "def on_template_render(self, sender, signal, template, context, **kwargs):",
        "def on_template_render(self, sender, signal, template, context,"
    ],
    [
        "[t.name for t in self.rendered_templates if t.name is not None],",
        "[t.name for t in self.rendered_templates if t.name is not"
    ],
    [
        "t.name for t in self.rendered_templates if t.name is not None",
        "t.name for t in self.rendered_templates if t.name is not"
    ],
    [
        "\"Database %(operation)s to %(alias)r are not allowed in SimpleTestCase \"",
        "\"Database %(operation)s to %(alias)r are not"
    ],
    [
        "\"subclasses. Either subclass TestCase or TransactionTestCase to ensure \"",
        "\"subclasses. Either subclass TestCase or TransactionTestCase"
    ],
    [
        "\"proper test isolation or add %(alias)r to %(test)s.databases to silence \"",
        "\"proper test isolation or add %(alias)r to %(test)s.databases"
    ],
    [
        "\"%s.%s.databases refers to %r which is not defined in \"",
        "\"%s.%s.databases refers to %r which is not"
    ],
    [
        "Wrapper around default __call__ method to perform common Django test",
        "Wrapper around default __call__ method"
    ],
    [
        "set up. This means that user-defined TestCases aren't required to",
        "set up. This means that"
    ],
    [
        "Make SimpleTestCase picklable for parallel tests using subtests.",
        "Make SimpleTestCase picklable for parallel tests using"
    ],
    [
        "pickable_state = {\"_outcome\": None, \"_subtest\": None}",
        "pickable_state = {\"_outcome\": None, \"_subtest\":"
    ],
    [
        "if key in pickable_state or not is_pickable(value):",
        "if key in pickable_state or not"
    ],
    [
        "\"\"\"Perform the same as __call__(), without catching the exception.\"\"\"",
        "\"\"\"Perform the same as __call__(), without"
    ],
    [
        "Perform the following in order: pre-setup, run test, post-teardown,",
        "Perform the following in order:"
    ],
    [
        "skipping pre/post hooks if test is set to be skipped.",
        "skipping pre/post hooks if test is set to be"
    ],
    [
        "If debug=True, reraise any errors in setup and use super().debug()",
        "If debug=True, reraise any errors in setup"
    ],
    [
        "instead of __call__() to run the test.",
        "instead of __call__() to run the"
    ],
    [
        "skipped = getattr(self.__class__, \"__unittest_skip__\", False) or getattr(",
        "skipped = getattr(self.__class__, \"__unittest_skip__\", False) or"
    ],
    [
        "* Clear the mail test outbox.",
        "* Clear the mail"
    ],
    [
        "A context manager that temporarily sets a setting and reverts to the",
        "A context manager that temporarily sets"
    ],
    [
        "original value when exiting the context.",
        "original value when"
    ],
    [
        "A context manager that temporarily applies changes to a list setting",
        "A context manager that temporarily applies changes to a list"
    ],
    [
        "and reverts back to the original value when exiting the context.",
        "and reverts back to the original value when exiting the"
    ],
    [
        "Assert that a response redirected to a specific URL and that the",
        "Assert that a response redirected to a specific URL and"
    ],
    [
        "Won't work for external links since it uses the test client to do a",
        "Won't work for external links since it uses the"
    ],
    [
        "request (use fetch_redirect_response=False to check such links without",
        "request (use fetch_redirect_response=False to check such links"
    ],
    [
        "\"Response didn't redirect as expected: Response code was %d \"",
        "\"Response didn't redirect as expected:"
    ],
    [
        "\"Initial response didn't redirect as expected: Response code was \"",
        "\"Initial response didn't redirect as expected: Response code"
    ],
    [
        "\"Response didn't redirect as expected: Final Response code was %d \"",
        "\"Response didn't redirect as expected: Final Response code was"
    ],
    [
        "\"Response didn't redirect as expected: Response code was %d \"",
        "\"Response didn't redirect as expected: Response code"
    ],
    [
        "scheme, netloc, path, query, fragment = urlsplit(url)",
        "scheme, netloc, path, query, fragment ="
    ],
    [
        "if domain and not validate_host(domain, settings.ALLOWED_HOSTS):",
        "if domain and"
    ],
    [
        "\"The test client is unable to fetch remote URLs (got %s). \"",
        "\"The test client is unable to fetch remote URLs"
    ],
    [
        "\"If the host is served by Django, add '%s' to ALLOWED_HOSTS. \"",
        "\"If the host is served by Django, add '%s' to"
    ],
    [
        "\"Couldn't retrieve redirection page '%s': response code was %d \"",
        "\"Couldn't retrieve redirection page '%s': response"
    ],
    [
        "+ \"Response redirected to '%s', expected '%s'\" % (url, expected_url),",
        "+ \"Response redirected to '%s', expected"
    ],
    [
        "Assert that two URLs are the same, ignoring the order of query string",
        "Assert that two URLs are the same, ignoring the order"
    ],
    [
        "parameters except for parameters with the same name.",
        "parameters except for parameters with"
    ],
    [
        "\"\"\"Sort the URL's query string parameters.\"\"\"",
        "\"\"\"Sort the URL's"
    ],
    [
        "scheme, netloc, path, query, fragment = urlsplit(url)",
        "scheme, netloc, path, query,"
    ],
    [
        "return urlunsplit((scheme, netloc, path, urlencode(query_parts), fragment))",
        "return urlunsplit((scheme, netloc,"
    ],
    [
        "def _assert_contains(self, response, text, status_code, msg_prefix, html):",
        "def _assert_contains(self, response, text, status_code,"
    ],
    [
        "msg_prefix + \"Couldn't retrieve content: Response code was %d\"",
        "msg_prefix + \"Couldn't retrieve content:"
    ],
    [
        "\" (expected %d)\" % (response.status_code, status_code),",
        "\" (expected %d)\" %"
    ],
    [
        "if not isinstance(text, bytes) or html:",
        "if not isinstance(text,"
    ],
    [
        "self, content, None, \"Response's content is not valid HTML:\"",
        "self, content, None, \"Response's content"
    ],
    [
        "self, text, None, \"Second argument is not valid HTML:\"",
        "self, text, None, \"Second argument is"
    ],
    [
        "Assert that a response indicates that some content was retrieved",
        "Assert that a response indicates that some content"
    ],
    [
        "successfully, (i.e., the HTTP status code was as expected) and that",
        "successfully, (i.e., the HTTP status code"
    ],
    [
        "``text`` occurs ``count`` times in the content of the response.",
        "``text`` occurs ``count`` times in the content of"
    ],
    [
        "If ``count`` is None, the count doesn't matter - the assertion is true",
        "If ``count`` is None, the count doesn't matter - the assertion is"
    ],
    [
        "if the text occurs at least once in the response.",
        "if the text occurs at least once in"
    ],
    [
        "text_repr, real_count, msg_prefix, content_repr = self._assert_contains(",
        "text_repr, real_count, msg_prefix, content_repr ="
    ],
    [
        "f\"{msg_prefix}Found {real_count} instances of {text_repr} \"",
        "f\"{msg_prefix}Found {real_count} instances"
    ],
    [
        "f\"(expected {count}) in the following response\\n{content_repr}\"",
        "f\"(expected {count}) in"
    ],
    [
        "f\"{msg_prefix}Couldn't find {text_repr} in the following response\\n\"",
        "f\"{msg_prefix}Couldn't find {text_repr} in"
    ],
    [
        "Assert that a response indicates that some content was retrieved",
        "Assert that a response indicates that"
    ],
    [
        "successfully, (i.e., the HTTP status code was as expected) and that",
        "successfully, (i.e., the HTTP status code was"
    ],
    [
        "``text`` doesn't occur in the content of the response.",
        "``text`` doesn't occur in the"
    ],
    [
        "text_repr, real_count, msg_prefix, content_repr = self._assert_contains(",
        "text_repr, real_count, msg_prefix, content_repr ="
    ],
    [
        "f\"{msg_prefix}{text_repr} unexpectedly found in the following response\"",
        "f\"{msg_prefix}{text_repr} unexpectedly found in"
    ],
    [
        "Raise a ValueError if the given response doesn't have the required",
        "Raise a ValueError if the given response doesn't have"
    ],
    [
        "f\"{method_name}() is only usable on responses fetched using \"",
        "f\"{method_name}() is only usable on responses fetched"
    ],
    [
        "def _assert_form_error(self, form, field, errors, msg_prefix, form_repr):",
        "def _assert_form_error(self, form, field, errors, msg_prefix,"
    ],
    [
        "f\"{msg_prefix}The {form_repr} is not bound, it will never have any \"",
        "f\"{msg_prefix}The {form_repr} is not bound, it will never have any"
    ],
    [
        "if field is not None and field not in form.fields:",
        "if field is not None and"
    ],
    [
        "f\"{msg_prefix}The {form_repr} does not contain the field {field!r}.\"",
        "f\"{msg_prefix}The {form_repr} does not contain the field"
    ],
    [
        "failure_message = f\"The non-field errors of {form_repr} don't match.\"",
        "failure_message = f\"The non-field errors of {form_repr}"
    ],
    [
        "f\"The errors of field {field!r} on {form_repr} don't match.\"",
        "f\"The errors of field {field!r}"
    ],
    [
        "def assertFormError(self, form, field, errors, msg_prefix=\"\"):",
        "def assertFormError(self, form, field, errors,"
    ],
    [
        "Assert that a field named \"field\" on the given form object has specific",
        "Assert that a field named \"field\" on the"
    ],
    [
        "errors can be either a single error message or a list of errors",
        "errors can be either a single error message or a list of"
    ],
    [
        "messages. Using errors=[] test that the field has no errors.",
        "messages. Using errors=[] test that the"
    ],
    [
        "You can pass field=None to check the form's non-field errors.",
        "You can pass field=None to check"
    ],
    [
        "self._assert_form_error(form, field, errors, msg_prefix, f\"form {form!r}\")",
        "self._assert_form_error(form, field, errors, msg_prefix,"
    ],
    [
        "def assertFormSetError(self, formset, form_index, field, errors, msg_prefix=\"\"):",
        "def assertFormSetError(self, formset, form_index,"
    ],
    [
        "Similar to assertFormError() but for formsets.",
        "Similar to assertFormError()"
    ],
    [
        "Use form_index=None to check the formset's non-form errors (in that",
        "Use form_index=None to check the formset's non-form errors (in"
    ],
    [
        "case, you must also use field=None).",
        "case, you must also use"
    ],
    [
        "Otherwise use an integer to check the formset's n-th form for errors.",
        "Otherwise use an integer to check the"
    ],
    [
        "Other parameters are the same as assertFormError().",
        "Other parameters are the same"
    ],
    [
        "if form_index is None and field is not None:",
        "if form_index is None and field is"
    ],
    [
        "raise ValueError(\"You must use field=None with form_index=None.\")",
        "raise ValueError(\"You must use field=None"
    ],
    [
        "f\"{msg_prefix}The formset {formset!r} is not bound, it will never have \"",
        "f\"{msg_prefix}The formset {formset!r} is not bound, it will never have"
    ],
    [
        "if form_index is not None and form_index >= formset.total_form_count():",
        "if form_index is not None"
    ],
    [
        "f\"{msg_prefix}The formset {formset!r} only has {form_count} \"",
        "f\"{msg_prefix}The formset {formset!r} only has"
    ],
    [
        "form_repr = f\"form {form_index} of formset {formset!r}\"",
        "form_repr = f\"form {form_index} of"
    ],
    [
        "failure_message = f\"The non-form errors of formset {formset!r} don't match.\"",
        "failure_message = f\"The non-form errors of formset {formset!r} don't"
    ],
    [
        "def _get_template_used(self, response, template_name, msg_prefix, method_name):",
        "def _get_template_used(self, response,"
    ],
    [
        "if response is None and template_name is None:",
        "if response is None and template_name"
    ],
    [
        "raise TypeError(\"response and/or template_name argument must be provided\")",
        "raise TypeError(\"response and/or template_name argument must be"
    ],
    [
        "if template_name is not None and response is not None:",
        "if template_name is not None and"
    ],
    [
        "if not hasattr(response, \"templates\") or (response is None and template_name):",
        "if not hasattr(response, \"templates\") or (response"
    ],
    [
        "template_names = [t.name for t in response.templates if t.name is not None]",
        "template_names = [t.name for t in"
    ],
    [
        "def _assert_template_used(self, template_name, template_names, msg_prefix, count):",
        "def _assert_template_used(self, template_name,"
    ],
    [
        "self.fail(msg_prefix + \"No templates used to render the response\")",
        "self.fail(msg_prefix + \"No templates used to render"
    ],
    [
        "msg_prefix + \"Template '%s' was not a template used to render\"",
        "msg_prefix + \"Template '%s' was not a template used to"
    ],
    [
        "\" the response. Actual template(s) used: %s\"",
        "\" the response. Actual"
    ],
    [
        "msg_prefix + \"Template '%s' was expected to be rendered %d \"",
        "msg_prefix + \"Template '%s' was expected to be"
    ],
    [
        "\"time(s) but was actually rendered %d time(s).\"",
        "\"time(s) but was actually rendered"
    ],
    [
        "Assert that the template with the provided name was used in rendering",
        "Assert that the template with the provided name was used in"
    ],
    [
        "the response. Also usable as context manager.",
        "the response. Also usable"
    ],
    [
        "Assert that the template with the provided name was NOT used in",
        "Assert that the template with the provided name was NOT"
    ],
    [
        "rendering the response. Also usable as context manager.",
        "rendering the response. Also usable as"
    ],
    [
        "+ \"Template '%s' was used unexpectedly in rendering the response\"",
        "+ \"Template '%s' was used"
    ],
    [
        "self, func, cm_attr, expected_exception, expected_message, *args, **kwargs",
        "self, func, cm_attr, expected_exception, expected_message, *args,"
    ],
    [
        "Assert that expected_message is found in the message of a raised",
        "Assert that expected_message is found in the message of"
    ],
    [
        "expected_exception: Exception class expected to be raised.",
        "expected_exception: Exception class expected to"
    ],
    [
        "expected_message: expected error message string value.",
        "expected_message: expected error message string"
    ],
    [
        "args: Function to be called and extra positional args.",
        "args: Function to be called and extra"
    ],
    [
        "def assertWarnsMessage(self, expected_warning, expected_message, *args, **kwargs):",
        "def assertWarnsMessage(self, expected_warning, expected_message,"
    ],
    [
        "Same as assertRaisesMessage but for assertWarns() instead of",
        "Same as assertRaisesMessage but for"
    ],
    [
        "Assert that a form field behaves correctly with various inputs.",
        "Assert that a form field behaves"
    ],
    [
        "fieldclass: the class of the field to be tested.",
        "fieldclass: the class of the field to be"
    ],
    [
        "valid: a dictionary mapping valid inputs to their expected",
        "valid: a dictionary mapping valid inputs to their"
    ],
    [
        "invalid: a dictionary mapping invalid inputs to one or more",
        "invalid: a dictionary mapping invalid inputs"
    ],
    [
        "field_args: the args passed to instantiate the field",
        "field_args: the args passed to"
    ],
    [
        "field_kwargs: the kwargs passed to instantiate the field",
        "field_kwargs: the kwargs passed to instantiate"
    ],
    [
        "empty_value: the expected clean output for inputs in empty_values",
        "empty_value: the expected clean output for inputs"
    ],
    [
        "optional = fieldclass(*field_args, **{**field_kwargs, \"required\": False})",
        "optional = fieldclass(*field_args, **{**field_kwargs,"
    ],
    [
        "Assert that two HTML snippets are semantically the same.",
        "Assert that two HTML snippets are semantically the"
    ],
    [
        "Whitespace in most cases is ignored, and attribute ordering is not",
        "Whitespace in most cases is ignored, and attribute ordering is"
    ],
    [
        "significant. The arguments must be valid HTML.",
        "significant. The arguments must"
    ],
    [
        "\"\"\"Assert that two HTML snippets are not semantically equivalent.\"\"\"",
        "\"\"\"Assert that two HTML snippets are not"
    ],
    [
        "def assertInHTML(self, needle, haystack, count=None, msg_prefix=\"\"):",
        "def assertInHTML(self, needle, haystack,"
    ],
    [
        "self, needle, None, \"First argument is not valid HTML:\"",
        "self, needle, None, \"First argument"
    ],
    [
        "self, haystack, None, \"Second argument is not valid HTML:\"",
        "self, haystack, None, \"Second argument is not valid"
    ],
    [
        "f\"{needle!r} unexpectedly found in the following response\\n\"",
        "f\"{needle!r} unexpectedly found in the following"
    ],
    [
        "f\"Found {real_count} instances of {needle!r} (expected {count}) in \"",
        "f\"Found {real_count} instances of {needle!r} (expected {count})"
    ],
    [
        "f\"{msg_prefix}Couldn't find {needle!r} in the following response\\n\"",
        "f\"{msg_prefix}Couldn't find {needle!r} in the following"
    ],
    [
        "Assert that the JSON fragments raw and expected_data are equal.",
        "Assert that the JSON fragments"
    ],
    [
        "Usual JSON non-significant whitespace rules apply as the heavyweight",
        "Usual JSON non-significant whitespace rules"
    ],
    [
        "is delegated to the json library.",
        "is delegated to the json"
    ],
    [
        "self.fail(\"First argument is not valid JSON: %r\" % raw)",
        "self.fail(\"First argument is not valid JSON: %r\""
    ],
    [
        "self.fail(\"Second argument is not valid JSON: %r\" % expected_data)",
        "self.fail(\"Second argument is not valid JSON: %r\" %"
    ],
    [
        "Assert that the JSON fragments raw and expected_data are not equal.",
        "Assert that the JSON fragments raw and"
    ],
    [
        "Usual JSON non-significant whitespace rules apply as the heavyweight",
        "Usual JSON non-significant whitespace rules apply"
    ],
    [
        "is delegated to the json library.",
        "is delegated to the"
    ],
    [
        "self.fail(\"First argument is not valid JSON: %r\" % raw)",
        "self.fail(\"First argument is not valid"
    ],
    [
        "self.fail(\"Second argument is not valid JSON: %r\" % expected_data)",
        "self.fail(\"Second argument is not valid JSON: %r\""
    ],
    [
        "Assert that two XML snippets are semantically the same.",
        "Assert that two XML snippets"
    ],
    [
        "Whitespace in most cases is ignored and attribute ordering is not",
        "Whitespace in most cases is ignored and"
    ],
    [
        "significant. The arguments must be valid XML.",
        "significant. The arguments must be valid"
    ],
    [
        "standardMsg = \"First or second argument is not valid XML\\n%s\" % e",
        "standardMsg = \"First or second argument"
    ],
    [
        "standardMsg = \"%s != %s\" % (",
        "standardMsg = \"%s != %s\""
    ],
    [
        "Assert that two XML snippets are not semantically equivalent.",
        "Assert that two XML snippets are"
    ],
    [
        "Whitespace in most cases is ignored and attribute ordering is not",
        "Whitespace in most cases is ignored"
    ],
    [
        "significant. The arguments must be valid XML.",
        "significant. The arguments must"
    ],
    [
        "standardMsg = \"First or second argument is not valid XML\\n%s\" % e",
        "standardMsg = \"First or second argument is not valid XML\\n%s\" %"
    ],
    [
        "standardMsg = \"%s == %s\" % (",
        "standardMsg = \"%s == %s\" %"
    ],
    [
        "\"Database %(operation)s to %(alias)r are not allowed in this test. \"",
        "\"Database %(operation)s to %(alias)r are not allowed in"
    ],
    [
        "\"Add %(alias)r to %(test)s.databases to ensure proper test isolation \"",
        "\"Add %(alias)r to %(test)s.databases to ensure proper test isolation"
    ],
    [
        "* If the class has an 'available_apps' attribute, restrict the app",
        "* If the class has an 'available_apps' attribute, restrict"
    ],
    [
        "registry to these applications, then fire the post_migrate signal --",
        "registry to these applications, then fire the post_migrate"
    ],
    [
        "it must run with the correct set of applications for the test case.",
        "it must run with the correct set of applications for the"
    ],
    [
        "* If the class has a 'fixtures' attribute, install those fixtures.",
        "* If the class has a 'fixtures'"
    ],
    [
        "* Flush the contents of the database to leave a clean slate. If the",
        "* Flush the contents of the database to"
    ],
    [
        "class has an 'available_apps' attribute, don't fire post_migrate.",
        "class has an 'available_apps' attribute, don't fire"
    ],
    [
        "* Force-close the connection so the next test gets a clean cursor.",
        "* Force-close the connection so the next test"
    ],
    [
        "def assertQuerySetEqual(self, qs, values, transform=None, ordered=True, msg=None):",
        "def assertQuerySetEqual(self, qs, values,"
    ],
    [
        "\"Trying to compare non-ordered queryset against more than one \"",
        "\"Trying to compare non-ordered queryset against more than one"
    ],
    [
        "def assertNumQueries(self, num, func=None, *args, using=DEFAULT_DB_ALIAS, **kwargs):",
        "def assertNumQueries(self, num, func=None,"
    ],
    [
        "Return whether or not all (or specified) connections support",
        "Return whether or not all (or specified)"
    ],
    [
        "else (connections[alias] for alias in aliases)",
        "else (connections[alias] for alias in"
    ],
    [
        "return all(conn.features.supports_transactions for conn in conns)",
        "return all(conn.features.supports_transactions for conn in"
    ],
    [
        "Return whether or not all (or specified) connections support savepoints.",
        "Return whether or not all (or"
    ],
    [
        "else (connections[alias] for alias in aliases)",
        "else (connections[alias] for alias"
    ],
    [
        "return all(conn.features.uses_savepoints for conn in conns)",
        "return all(conn.features.uses_savepoints for conn"
    ],
    [
        "Descriptor to provide TestCase instance isolation for attributes assigned",
        "Descriptor to provide TestCase instance isolation for"
    ],
    [
        "Allow safe alteration of objects assigned in setUpTestData() by test",
        "Allow safe alteration of objects assigned"
    ],
    [
        "methods by exposing deep copies instead of the original objects.",
        "methods by exposing deep copies instead of the"
    ],
    [
        "Objects are deep copied using a memo kept on the test case instance in",
        "Objects are deep copied using a memo kept on the"
    ],
    [
        "order to maintain their original relationships.",
        "order to maintain"
    ],
    [
        "return \"<TestData: name=%r, data=%r>\" % (self.name, self.data)",
        "return \"<TestData: name=%r, data=%r>\""
    ],
    [
        "Similar to TransactionTestCase, but use `transaction.atomic()` to achieve",
        "Similar to TransactionTestCase, but use `transaction.atomic()` to"
    ],
    [
        "In most situations, TestCase should be preferred to TransactionTestCase as",
        "In most situations, TestCase should"
    ],
    [
        "it allows faster execution. However, there are some situations where using",
        "it allows faster execution. However, there are some situations where"
    ],
    [
        "TransactionTestCase might be necessary (e.g. testing some transactional",
        "TransactionTestCase might be necessary (e.g. testing some"
    ],
    [
        "On database backends with no transaction support, TestCase behaves as",
        "On database backends with no transaction support,"
    ],
    [
        "\"\"\"Open atomic blocks for multiple databases.\"\"\"",
        "\"\"\"Open atomic blocks"
    ],
    [
        "\"\"\"Rollback atomic blocks opened by the previous method.\"\"\"",
        "\"\"\"Rollback atomic blocks opened by the previous"
    ],
    [
        "\"\"\"Load initial data for the TestCase.\"\"\"",
        "\"\"\"Load initial data"
    ],
    [
        "raise TypeError(\"reset_sequences cannot be used on TestCase instances\")",
        "raise TypeError(\"reset_sequences cannot be used on TestCase"
    ],
    [
        "\"\"\"Context manager to capture transaction.on_commit() callbacks.\"\"\"",
        "\"\"\"Context manager to capture transaction.on_commit()"
    ],
    [
        "for _, callback, robust in connections[using].run_on_commit[",
        "for _, callback, robust in"
    ],
    [
        "\"\"\"Descriptor class for deferred condition checking.\"\"\"",
        "\"\"\"Descriptor class for deferred"
    ],
    [
        "if any(getattr(base, \"__unittest_skip__\", False) for base in cls.__bases__):",
        "if any(getattr(base, \"__unittest_skip__\", False) for base in"
    ],
    [
        "\"%s cannot be used on %s as %s doesn't allow queries \"",
        "\"%s cannot be used on %s as %s doesn't allow"
    ],
    [
        "if not databases or connection.alias not in databases:",
        "if not databases or connection.alias not in"
    ],
    [
        "\"%s cannot be used on %s as it doesn't allow queries \"",
        "\"%s cannot be used on %s as it doesn't allow"
    ],
    [
        "\"\"\"Skip a test if a database has at least one of the named features.\"\"\"",
        "\"\"\"Skip a test if a database has at least one of the"
    ],
    [
        "getattr(connection.features, feature, False) for feature in features",
        "getattr(connection.features, feature, False) for feature"
    ],
    [
        "\"Database has feature(s) %s\" % \", \".join(features),",
        "\"Database has feature(s) %s\""
    ],
    [
        "\"\"\"Skip a test unless a database has all the named features.\"\"\"",
        "\"\"\"Skip a test unless a database has"
    ],
    [
        "getattr(connection.features, feature, False) for feature in features",
        "getattr(connection.features, feature, False) for"
    ],
    [
        "\"Database doesn't support feature(s): %s\" % \", \".join(features),",
        "\"Database doesn't support feature(s): %s\" % \","
    ],
    [
        "\"\"\"Skip a test unless a database has any of the named features.\"\"\"",
        "\"\"\"Skip a test unless a database has any"
    ],
    [
        "getattr(connection.features, feature, False) for feature in features",
        "getattr(connection.features, feature, False) for feature in"
    ],
    [
        "\"Database doesn't support any of the feature(s): %s\" % \", \".join(features),",
        "\"Database doesn't support any of the"
    ],
    [
        "A WSGIRequestHandler that doesn't log to standard output any of the",
        "A WSGIRequestHandler that doesn't log to standard output"
    ],
    [
        "requests received, so as to not clutter the test result output.",
        "requests received, so as to not clutter the"
    ],
    [
        "WSGI middleware that intercepts calls to a directory, as defined by one of",
        "WSGI middleware that intercepts calls to a"
    ],
    [
        "the *_ROOT settings, and serves those files, publishing them under *_URL.",
        "the *_ROOT settings, and serves those files, publishing them under"
    ],
    [
        "Check if the path should be handled. Ignore the path if:",
        "Check if the path should be handled. Ignore the path"
    ],
    [
        "* the host is provided as part of the base_url",
        "* the host is provided as"
    ],
    [
        "* the request's path isn't under the media path (or equal)",
        "* the request's path isn't under the"
    ],
    [
        "\"\"\"Return the relative path to the file on disk for the given URL.\"\"\"",
        "\"\"\"Return the relative path to the file on disk for the"
    ],
    [
        "Handler for serving static files. A private class that is meant to be used",
        "Handler for serving static files. A private class that is meant to"
    ],
    [
        "solely as a convenience by LiveServerThread.",
        "solely as a convenience by"
    ],
    [
        "Handler for serving the media files. A private class that is meant to be",
        "Handler for serving the media files. A private class"
    ],
    [
        "used solely as a convenience by LiveServerThread.",
        "used solely as a convenience by"
    ],
    [
        "\"\"\"Thread for running a live HTTP server while the tests are running.\"\"\"",
        "\"\"\"Thread for running a live HTTP server while the tests"
    ],
    [
        "Set up the live server and databases, and then loop over handling",
        "Set up the live server and databases, and"
    ],
    [
        "Do basically the same as TransactionTestCase but also launch a live HTTP",
        "Do basically the same as TransactionTestCase but also"
    ],
    [
        "server in a separate thread so that the tests may use another testing",
        "server in a separate thread so that the tests may use"
    ],
    [
        "framework, such as Selenium for example, instead of the built-in dummy",
        "framework, such as Selenium for example,"
    ],
    [
        "It inherits from TransactionTestCase instead of TestCase because the",
        "It inherits from TransactionTestCase instead of TestCase"
    ],
    [
        "threads don't share the same transactions (unless if using in-memory sqlite)",
        "threads don't share the same transactions (unless if using in-memory"
    ],
    [
        "and each thread needs to commit all their transactions so that the other",
        "and each thread needs to commit all their transactions so"
    ],
    [
        "if conn.vendor == \"sqlite\" and conn.is_in_memory_db():",
        "if conn.vendor =="
    ],
    [
        "Enforce serialization of TestCases that share a common resource.",
        "Enforce serialization of TestCases that"
    ],
    [
        "Define a common 'lockfile' for each set of TestCases to serialize. This",
        "Define a common 'lockfile' for each set of TestCases to"
    ],
    [
        "file must exist on the filesystem.",
        "file must exist on the"
    ],
    [
        "Place it early in the MRO in order to isolate setUpClass()/tearDownClass().",
        "Place it early in the MRO in order"
    ],
    [
        "\"{}.lockfile isn't set. Set it to a unique value \"",
        "\"{}.lockfile isn't set. Set it"
    ],
    [
        "from asgiref.sync import async_to_sync, iscoroutinefunction, sync_to_async",
        "from asgiref.sync import async_to_sync,"
    ],
    [
        "{ receiverkey (id) : weakref(receiver) }",
        "{ receiverkey (id) : weakref(receiver)"
    ],
    [
        "self.sender_receivers_cache = weakref.WeakKeyDictionary() if use_caching else {}",
        "self.sender_receivers_cache = weakref.WeakKeyDictionary() if"
    ],
    [
        "def connect(self, receiver, sender=None, weak=True, dispatch_uid=None):",
        "def connect(self, receiver,"
    ],
    [
        "Connect receiver to sender for signal.",
        "Connect receiver to"
    ],
    [
        "A function or an instance method which is to receive signals.",
        "A function or an instance method which is to"
    ],
    [
        "Receivers must be hashable objects. Receivers can be",
        "Receivers must be hashable objects."
    ],
    [
        "If weak is True, then receiver must be weak referenceable.",
        "If weak is True, then receiver must be weak"
    ],
    [
        "Receivers must be able to accept keyword arguments.",
        "Receivers must be able to"
    ],
    [
        "If a receiver is connected with a dispatch_uid argument, it",
        "If a receiver is connected with a dispatch_uid argument,"
    ],
    [
        "will not be added if another receiver was already connected",
        "will not be added if another receiver was already"
    ],
    [
        "The sender to which the receiver should respond. Must either be",
        "The sender to which the receiver should respond. Must either"
    ],
    [
        "a Python object, or None to receive events from any sender.",
        "a Python object, or None to receive events from"
    ],
    [
        "Whether to use weak references to the receiver. By default, the",
        "Whether to use weak references to the receiver. By"
    ],
    [
        "module will attempt to use weak references to the receiver",
        "module will attempt to use weak"
    ],
    [
        "objects. If this parameter is false, then strong references will",
        "objects. If this parameter is false, then strong"
    ],
    [
        "An identifier used to uniquely identify a particular instance of",
        "An identifier used to uniquely identify a"
    ],
    [
        "a receiver. This will usually be a string, though it may be",
        "a receiver. This will usually be"
    ],
    [
        "raise TypeError(\"Signal receivers must be callable.\")",
        "raise TypeError(\"Signal receivers"
    ],
    [
        "\"Signal receivers must accept keyword arguments (**kwargs).\"",
        "\"Signal receivers must accept"
    ],
    [
        "if hasattr(receiver, \"__self__\") and hasattr(receiver, \"__func__\"):",
        "if hasattr(receiver, \"__self__\") and"
    ],
    [
        "if not any(r_key == lookup_key for r_key, _, _ in self.receivers):",
        "if not any(r_key == lookup_key for r_key, _, _"
    ],
    [
        "Disconnect receiver from sender for signal.",
        "Disconnect receiver from"
    ],
    [
        "If weak references are used, disconnect need not be called. The receiver",
        "If weak references are used, disconnect need not be"
    ],
    [
        "will be removed from dispatch automatically.",
        "will be removed from"
    ],
    [
        "The registered receiver to disconnect. May be none if",
        "The registered receiver to disconnect."
    ],
    [
        "the unique identifier of the receiver to disconnect",
        "the unique identifier of the receiver to"
    ],
    [
        "Send signal from sender to all connected receivers.",
        "Send signal from sender to all connected"
    ],
    [
        "If any receiver raises an error, the error propagates back through send,",
        "If any receiver raises an error, the error propagates"
    ],
    [
        "terminating the dispatch loop. So it's possible that all receivers",
        "terminating the dispatch loop. So it's possible that"
    ],
    [
        "won't be called if an error is raised.",
        "won't be called if an error"
    ],
    [
        "If any receivers are asynchronous, they are called after all the",
        "If any receivers are asynchronous, they are"
    ],
    [
        "synchronous receivers via a single call to async_to_sync(). They are",
        "synchronous receivers via a single"
    ],
    [
        "The sender of the signal. Either a specific object or None.",
        "The sender of the signal. Either"
    ],
    [
        "Named arguments which will be passed to receivers.",
        "Named arguments which will be passed to"
    ],
    [
        "Return a list of tuple pairs [(receiver, response), ... ].",
        "Return a list of tuple pairs [(receiver,"
    ],
    [
        "Send signal from sender to all connected receivers in async mode.",
        "Send signal from sender to all connected"
    ],
    [
        "All sync receivers will be wrapped by sync_to_async()",
        "All sync receivers will"
    ],
    [
        "If any receiver raises an error, the error propagates back through",
        "If any receiver raises an error, the error propagates back"
    ],
    [
        "send, terminating the dispatch loop. So it's possible that all",
        "send, terminating the dispatch loop."
    ],
    [
        "receivers won't be called if an error is raised.",
        "receivers won't be called if an error is"
    ],
    [
        "If any receivers are synchronous, they are grouped and called behind a",
        "If any receivers are synchronous, they are grouped and called behind"
    ],
    [
        "sync_to_async() adaption before executing any asynchronous receivers.",
        "sync_to_async() adaption before executing"
    ],
    [
        "If any receivers are asynchronous, they are grouped and executed",
        "If any receivers are asynchronous,"
    ],
    [
        "The sender of the signal. Either a specific object or None.",
        "The sender of the signal. Either a"
    ],
    [
        "Named arguments which will be passed to receivers.",
        "Named arguments which will be passed"
    ],
    [
        "Return a list of tuple pairs [(receiver, response), ...].",
        "Return a list of tuple pairs [(receiver,"
    ],
    [
        "\"Error calling %s in Signal.send_robust() (%s)\",",
        "\"Error calling %s in"
    ],
    [
        "Send signal from sender to all connected receivers catching errors.",
        "Send signal from sender to all"
    ],
    [
        "If any receivers are asynchronous, they are called after all the",
        "If any receivers are asynchronous, they are called after all"
    ],
    [
        "synchronous receivers via a single call to async_to_sync(). They are",
        "synchronous receivers via a single call to async_to_sync()."
    ],
    [
        "The sender of the signal. Can be any Python object (normally one",
        "The sender of the signal. Can be any Python object"
    ],
    [
        "registered with a connect if you actually want something to",
        "registered with a connect if you actually want"
    ],
    [
        "Named arguments which will be passed to receivers.",
        "Named arguments which will be"
    ],
    [
        "Return a list of tuple pairs [(receiver, response), ... ].",
        "Return a list of tuple pairs [(receiver, response), ..."
    ],
    [
        "If any receiver raises an error (specifically any subclass of",
        "If any receiver raises an error (specifically any subclass"
    ],
    [
        "Exception), return the error instance as the result for that receiver.",
        "Exception), return the error instance as"
    ],
    [
        "response = await receiver(signal=self, sender=sender, **named)",
        "response = await receiver(signal=self,"
    ],
    [
        "Send signal from sender to all connected receivers catching errors.",
        "Send signal from sender to all connected receivers catching"
    ],
    [
        "If any receivers are synchronous, they are grouped and called behind a",
        "If any receivers are synchronous, they are"
    ],
    [
        "sync_to_async() adaption before executing any asynchronous receivers.",
        "sync_to_async() adaption before executing"
    ],
    [
        "If any receivers are asynchronous, they are grouped and executed",
        "If any receivers are asynchronous, they are grouped"
    ],
    [
        "The sender of the signal. Can be any Python object (normally one",
        "The sender of the signal. Can be any Python object (normally"
    ],
    [
        "registered with a connect if you actually want something to",
        "registered with a connect if you actually want"
    ],
    [
        "Named arguments which will be passed to receivers.",
        "Named arguments which will be passed to"
    ],
    [
        "Return a list of tuple pairs [(receiver, response), ... ].",
        "Return a list of tuple"
    ],
    [
        "If any receiver raises an error (specifically any subclass of",
        "If any receiver raises an error (specifically any"
    ],
    [
        "Exception), return the error instance as the result for that receiver.",
        "Exception), return the error instance as the"
    ],
    [
        "response = await receiver(signal=self, sender=sender, **named)",
        "response = await receiver(signal=self, sender=sender,"
    ],
    [
        "Filter sequence of receivers to get resolved, live receivers.",
        "Filter sequence of receivers to"
    ],
    [
        "This checks for weak references and resolves them, then returning only",
        "This checks for weak references and resolves them, then"
    ],
    [
        "for (_receiverkey, r_senderkey), receiver, is_async in self.receivers:",
        "for (_receiverkey, r_senderkey), receiver, is_async in"
    ],
    [
        "if r_senderkey == NONE_ID or r_senderkey == senderkey:",
        "if r_senderkey == NONE_ID or"
    ],
    [
        "A decorator for connecting receivers to signals. Used by passing in the",
        "A decorator for connecting receivers to"
    ],
    [
        "signal (or list of signals) and keyword arguments to connect::",
        "signal (or list of signals) and keyword arguments to"
    ],
    [
        "from .base import Node, Template, token_kwargs",
        "from .base import Node,"
    ],
    [
        "A class for registering template tags and filters. Compiled filter and",
        "A class for registering template tags"
    ],
    [
        "template tag functions are stored in the filters and tags attributes.",
        "template tag functions are stored in the filters and"
    ],
    [
        "The filter, simple_tag, and inclusion_tag methods provide a convenient",
        "The filter, simple_tag, and inclusion_tag methods provide"
    ],
    [
        "way to register callables as tags.",
        "way to register callables as"
    ],
    [
        "if name is None and compile_function is None:",
        "if name is None and compile_function"
    ],
    [
        "elif name is not None and compile_function is None:",
        "elif name is not None and"
    ],
    [
        "elif name is not None and compile_function is not None:",
        "elif name is not None and compile_function is not"
    ],
    [
        "\"Unsupported arguments to Library.tag: (%r, %r)\"",
        "\"Unsupported arguments to Library.tag: (%r,"
    ],
    [
        "Register a callable as a template filter. Example:",
        "Register a callable as"
    ],
    [
        "if name is None and filter_func is None:",
        "if name is None and"
    ],
    [
        "elif name is not None and filter_func is None:",
        "elif name is not None"
    ],
    [
        "elif name is not None and filter_func is not None:",
        "elif name is not None and filter_func is"
    ],
    [
        "for attr in (\"expects_localtime\", \"is_safe\", \"needs_autoescape\"):",
        "for attr in (\"expects_localtime\","
    ],
    [
        "\"Unsupported arguments to Library.filter: (%r, %r)\"",
        "\"Unsupported arguments to"
    ],
    [
        "Register a callable as a compiled template tag. Example:",
        "Register a callable as a compiled"
    ],
    [
        "return SimpleNode(func, takes_context, args, kwargs, target_var)",
        "return SimpleNode(func, takes_context, args,"
    ],
    [
        "raise ValueError(\"Invalid arguments provided to simple_tag\")",
        "raise ValueError(\"Invalid arguments provided to"
    ],
    [
        "def simple_block_tag(self, func=None, takes_context=None, name=None, end_name=None):",
        "def simple_block_tag(self, func=None,"
    ],
    [
        "Register a callable as a compiled block template tag. Example:",
        "Register a callable as a compiled block"
    ],
    [
        "f\"{function_name!r} is decorated with takes_context=True so\"",
        "f\"{function_name!r} is decorated with takes_context=True"
    ],
    [
        "\" it must have a first argument of 'context' and a second \"",
        "\" it must have a first argument of 'context'"
    ],
    [
        "f\"'{function_name}' must have a first argument of 'content'\"",
        "f\"'{function_name}' must have a"
    ],
    [
        "nodelist, func, takes_context, args, kwargs, target_var",
        "nodelist, func, takes_context,"
    ],
    [
        "raise ValueError(\"Invalid arguments provided to simple_block_tag\")",
        "raise ValueError(\"Invalid arguments provided"
    ],
    [
        "def inclusion_tag(self, filename, func=None, takes_context=None, name=None):",
        "def inclusion_tag(self, filename, func=None,"
    ],
    [
        "Register a callable as an inclusion tag:",
        "Register a callable as an inclusion"
    ],
    [
        "Base class for tag helper nodes such as SimpleNode and InclusionNode.",
        "Base class for tag helper nodes such as"
    ],
    [
        "Manages the positional and keyword arguments to be passed to the decorated",
        "Manages the positional and keyword arguments to be"
    ],
    [
        "def __init__(self, func, takes_context, args, kwargs):",
        "def __init__(self, func, takes_context,"
    ],
    [
        "resolved_args = [var.resolve(context) for var in self.args]",
        "resolved_args = [var.resolve(context) for var in"
    ],
    [
        "resolved_kwargs = {k: v.resolve(context) for k, v in self.kwargs.items()}",
        "resolved_kwargs = {k: v.resolve(context) for k, v"
    ],
    [
        "def __init__(self, func, takes_context, args, kwargs, target_var):",
        "def __init__(self, func, takes_context,"
    ],
    [
        "def __init__(self, func, takes_context, args, kwargs, filename):",
        "def __init__(self, func, takes_context, args, kwargs,"
    ],
    [
        "Render the specified template and context. Cache the template object",
        "Render the specified template and"
    ],
    [
        "in render_context to avoid reparsing and loading when used in a for",
        "in render_context to avoid reparsing and loading when"
    ],
    [
        "elif not isinstance(self.filename, str) and isinstance(",
        "elif not isinstance(self.filename, str)"
    ],
    [
        "Parse bits for template tag helpers simple_tag and inclusion_tag, in",
        "Parse bits for template tag helpers simple_tag and inclusion_tag,"
    ],
    [
        "particular by detecting syntax errors and by extracting positional and",
        "particular by detecting syntax errors and by extracting positional"
    ],
    [
        "\"'%s' is decorated with takes_context=True so it must \"",
        "\"'%s' is decorated with takes_context=True so it must"
    ],
    [
        "\"have a first argument of 'context'\" % name",
        "\"have a first argument"
    ],
    [
        "kwarg for kwarg in kwonly if not kwonly_defaults or kwarg not in kwonly_defaults",
        "kwarg for kwarg in kwonly if not kwonly_defaults or kwarg"
    ],
    [
        "if param not in params and param not in kwonly and varkw is None:",
        "if param not in params and param not in kwonly and"
    ],
    [
        "\"'%s' received unexpected keyword argument '%s'\" % (name, param)",
        "\"'%s' received unexpected keyword argument '%s'\" %"
    ],
    [
        "\"'%s' received multiple values for keyword argument '%s'\"",
        "\"'%s' received multiple values for keyword argument"
    ],
    [
        "\"'%s' received some positional argument(s) after some \"",
        "\"'%s' received some positional argument(s)"
    ],
    [
        "\"'%s' received too many positional arguments\" % name",
        "\"'%s' received too many"
    ],
    [
        "\"'%s' did not receive value(s) for the argument(s): %s\"",
        "\"'%s' did not receive value(s) for the"
    ],
    [
        "% (name, \", \".join(\"'%s'\" % p for p in unhandled_params + unhandled_kwargs))",
        "% (name, \", \".join(\"'%s'\" % p for p in"
    ],
    [
        "Load a Library object from a template tag module.",
        "Load a Library object from a template tag"
    ],
    [
        "\"Invalid template library specified. ImportError raised when \"",
        "\"Invalid template library specified. ImportError"
    ],
    [
        "\"trying to load '%s': %s\" % (name, e)",
        "\"trying to load '%s': %s\" % (name,"
    ],
    [
        "\"Module  %s does not have a variable named 'register'\" % name,",
        "\"Module %s does not have a"
    ],
    [
        "The django.template namespace contains two independent subsystems:",
        "The django.template namespace contains"
    ],
    [
        "built-in loaders, context processors, tags and filters.",
        "built-in loaders, context processors, tags"
    ],
    [
        "Ideally these subsystems would be implemented in distinct packages. However",
        "Ideally these subsystems would be implemented"
    ],
    [
        "keeping them together made the implementation of Multiple Template Engines",
        "keeping them together made the implementation"
    ],
    [
        "Here's a breakdown of which modules belong to which subsystem.",
        "Here's a breakdown of which"
    ],
    [
        "Raise an exception if trying to pickle an unrendered response. Pickle",
        "Raise an exception if trying to pickle an unrendered response."
    ],
    [
        "only rendered data, not the data used to construct the response.",
        "only rendered data, not the data"
    ],
    [
        "\"The response content must be rendered before it can be pickled.\"",
        "\"The response content must be rendered before it can"
    ],
    [
        "\"\"\"Accept a template object, path-to-template, or list of paths.\"\"\"",
        "\"\"\"Accept a template object, path-to-template, or list of"
    ],
    [
        "\"\"\"Return the freshly rendered content for the template and context",
        "\"\"\"Return the freshly rendered content for the"
    ],
    [
        "This *does not* set the final content of the response. To set the",
        "This *does not* set the final content of the response. To"
    ],
    [
        "response content, you must either call render(), or set the",
        "response content, you must either call render(), or set"
    ],
    [
        "content explicitly using the value of this property.",
        "content explicitly using the value"
    ],
    [
        "If the response has already been rendered,",
        "If the response has already"
    ],
    [
        "\"\"\"Render (thereby finalizing) the content of the response.",
        "\"\"\"Render (thereby finalizing) the"
    ],
    [
        "If the content has already been rendered, this is a no-op.",
        "If the content has already been rendered, this is"
    ],
    [
        "\"The response content must be rendered before it can be iterated over.\"",
        "\"The response content must be rendered before"
    ],
    [
        "\"The response content must be rendered before it can be accessed.\"",
        "\"The response content must be rendered before it can be"
    ],
    [
        "\"\"\"Set the content for the response.\"\"\"",
        "\"\"\"Set the content for"
    ],
    [
        "template, context, content_type, status, charset, using, headers=headers",
        "template, context, content_type, status,"
    ],
    [
        "Parser and utilities for the smart 'if' tag",
        "Parser and utilities for the"
    ],
    [
        "Base class for operators and literals, mainly for debugging and for throwing",
        "Base class for operators and literals, mainly for debugging and for"
    ],
    [
        "\"Not expecting '%s' in this position in if tag.\" % self.id",
        "\"Not expecting '%s' in this position in"
    ],
    [
        "\"Not expecting '%s' as infix operator in if tag.\" % self.id",
        "\"Not expecting '%s' as infix operator in if tag.\""
    ],
    [
        "Return what to display in error messages for this node",
        "Return what to display in"
    ],
    [
        "out = [str(x) for x in [self.id, self.first, self.second] if x is not None]",
        "out = [str(x) for x in [self.id, self.first, self.second]"
    ],
    [
        "return \"(\" + \" \".join(out) + \")\"",
        "return \"(\" + \" \".join(out)"
    ],
    [
        "Create an infix operator, given a binding power and a function that",
        "Create an infix operator, given a binding power and"
    ],
    [
        "Create a prefix operator, given a binding power and a function that",
        "Create a prefix operator, given a"
    ],
    [
        "A basic self-resolvable object similar to a Django template variable.",
        "A basic self-resolvable object similar to a Django"
    ],
    [
        "return \"(%s %r)\" % (self.id, self.value)",
        "return \"(%s %r)\" % (self.id,"
    ],
    [
        "raise parser.error_class(\"Unexpected end of expression in if tag.\")",
        "raise parser.error_class(\"Unexpected end of expression"
    ],
    [
        "\"Unused '%s' at end of if expression.\" % self.current_token.display()",
        "\"Unused '%s' at end of if"
    ],
    [
        "A set of request processors that return dictionaries to be merged into a",
        "A set of request processors that return dictionaries to be merged into"
    ],
    [
        "template context. Each function takes the request object as its only parameter",
        "template context. Each function takes the request object"
    ],
    [
        "and returns a dictionary to add to the context.",
        "and returns a dictionary to add to"
    ],
    [
        "These are referenced from the 'context_processors' option of the configuration",
        "These are referenced from the 'context_processors'"
    ],
    [
        "of a DjangoTemplates backend and used by RequestContext.",
        "of a DjangoTemplates backend"
    ],
    [
        "Context processor that provides a CSRF token, or the string 'NOTPROVIDED' if",
        "Context processor that provides a CSRF token, or"
    ],
    [
        "it has not been provided by either a view decorator or the middleware",
        "it has not been provided by either a view decorator or the"
    ],
    [
        "Return context variables helpful for debugging.",
        "Return context variables helpful"
    ],
    [
        "if settings.DEBUG and request.META.get(\"REMOTE_ADDR\") in settings.INTERNAL_IPS:",
        "if settings.DEBUG and"
    ],
    [
        "Add static-related context variables to the context.",
        "Add static-related context variables"
    ],
    [
        "Add media-related context variables to the context.",
        "Add media-related context variables"
    ],
    [
        "from decimal import ROUND_HALF_UP, Context, Decimal, InvalidOperation, getcontext",
        "from decimal import ROUND_HALF_UP, Context, Decimal, InvalidOperation,"
    ],
    [
        "from django.utils.html import avoid_wrapping, conditional_escape, escape, escapejs",
        "from django.utils.html import avoid_wrapping, conditional_escape, escape,"
    ],
    [
        "from django.utils.html import json_script as _json_script",
        "from django.utils.html import json_script as"
    ],
    [
        "from django.utils.html import urlize as _urlize",
        "from django.utils.html import urlize"
    ],
    [
        "from django.utils.text import slugify as _slugify",
        "from django.utils.text import slugify"
    ],
    [
        "Decorator for filters which should only receive strings. The object",
        "Decorator for filters which should only receive strings."
    ],
    [
        "passed as the first positional argument will be converted to a string.",
        "passed as the first positional argument will be"
    ],
    [
        "if isinstance(first, SafeData) and getattr(unwrap(func), \"is_safe\", False):",
        "if isinstance(first, SafeData) and getattr(unwrap(func), \"is_safe\","
    ],
    [
        "Add slashes before quotes. Useful for escaping strings in CSV, for",
        "Add slashes before quotes. Useful for escaping strings"
    ],
    [
        "example. Less useful for escaping JavaScript; use the ``escapejs``",
        "example. Less useful for escaping JavaScript; use the"
    ],
    [
        "\"\"\"Capitalize the first character of the value.\"\"\"",
        "\"\"\"Capitalize the first character"
    ],
    [
        "\"\"\"Hex encode characters for use in JavaScript strings.\"\"\"",
        "\"\"\"Hex encode characters for"
    ],
    [
        "Output value JSON-encoded, wrapped in a <script type=\"application/json\">",
        "Output value JSON-encoded, wrapped in a"
    ],
    [
        "Display a float to a specified number of decimal places.",
        "Display a float to a"
    ],
    [
        "If called without an argument, display the floating point number with one",
        "If called without an argument, display the floating"
    ],
    [
        "decimal place -- but only if there's a decimal place to be displayed:",
        "decimal place -- but only if there's a decimal place"
    ],
    [
        "If arg is positive, always display exactly arg number of decimal places:",
        "If arg is positive, always display exactly"
    ],
    [
        "If arg is negative, display arg number of decimal places -- but only if",
        "If arg is negative, display arg number of decimal"
    ],
    [
        "there are places to be displayed:",
        "there are places"
    ],
    [
        "If arg has the 'g' suffix, force the result to be grouped by the",
        "If arg has the 'g' suffix, force the result to be grouped"
    ],
    [
        "THOUSAND_SEPARATOR for the active locale. When the active locale is",
        "THOUSAND_SEPARATOR for the active locale. When"
    ],
    [
        "If arg has the 'u' suffix, force the result to be unlocalized. When the",
        "If arg has the 'u' suffix, force the result to be unlocalized."
    ],
    [
        "If the input float is infinity or NaN, display the string representation",
        "If the input float is infinity or NaN,"
    ],
    [
        "digits = [str(digit) for digit in reversed(digits)]",
        "digits = [str(digit) for digit in"
    ],
    [
        "\"\"\"Escape an IRI value for use in a URL.\"\"\"",
        "\"\"\"Escape an IRI value for use"
    ],
    [
        "if not autoescape or isinstance(value, SafeData):",
        "if not autoescape or isinstance(value,"
    ],
    [
        "\"\"\"Convert a string into all lowercase.\"\"\"",
        "\"\"\"Convert a string into all"
    ],
    [
        "Return the value turned into a list.",
        "Return the value turned into"
    ],
    [
        "For an integer, it's a list of digits.",
        "For an integer, it's a list of"
    ],
    [
        "For a string, it's a list of characters.",
        "For a string, it's a"
    ],
    [
        "Convert to ASCII. Convert spaces to hyphens. Remove characters that aren't",
        "Convert to ASCII. Convert spaces to"
    ],
    [
        "alphanumerics, underscores, or hyphens. Convert to lowercase. Also strip",
        "alphanumerics, underscores, or hyphens. Convert to lowercase. Also"
    ],
    [
        "Format the variable according to the arg, a string formatting specifier.",
        "Format the variable according to the arg, a string"
    ],
    [
        "This specifier uses Python string formatting syntax, with the exception",
        "This specifier uses Python string"
    ],
    [
        "that the leading \"%\" is dropped.",
        "that the leading \"%\""
    ],
    [
        "for documentation of Python string formatting.",
        "for documentation of"
    ],
    [
        "return (\"%\" + str(arg)) % value",
        "return (\"%\" + str(arg)) %"
    ],
    [
        "\"\"\"Truncate a string after `arg` number of characters.\"\"\"",
        "\"\"\"Truncate a string after `arg`"
    ],
    [
        "Truncate HTML after `arg` number of chars.",
        "Truncate HTML after `arg`"
    ],
    [
        "Truncate a string after `arg` number of words.",
        "Truncate a string after `arg` number"
    ],
    [
        "Truncate HTML after `arg` number of words.",
        "Truncate HTML after `arg`"
    ],
    [
        "\"\"\"Convert a string into all uppercase.\"\"\"",
        "\"\"\"Convert a string"
    ],
    [
        "Escape a value for use in a URL.",
        "Escape a value for use"
    ],
    [
        "The ``safe`` parameter determines the characters which should not be",
        "The ``safe`` parameter determines the characters"
    ],
    [
        "escaped by Python's quote() function. If not provided, use the default safe",
        "escaped by Python's quote() function. If not provided, use"
    ],
    [
        "characters (but an empty string can be provided when *all* characters",
        "characters (but an empty string can be"
    ],
    [
        "\"\"\"Convert URLs in plain text into clickable links.\"\"\"",
        "\"\"\"Convert URLs in plain text into clickable"
    ],
    [
        "Convert URLs into clickable links, truncating URLs to the given character",
        "Convert URLs into clickable links, truncating URLs to"
    ],
    [
        "limit, and adding 'rel=nofollow' attribute to discourage spamming.",
        "limit, and adding 'rel=nofollow'"
    ],
    [
        "Argument: Length to truncate URLs to.",
        "Argument: Length to truncate URLs"
    ],
    [
        "\"\"\"Wrap words at `arg` line length.\"\"\"",
        "\"\"\"Wrap words at"
    ],
    [
        "\"\"\"Left-align the value in a field of a given width.\"\"\"",
        "\"\"\"Left-align the value in a field of a"
    ],
    [
        "\"\"\"Right-align the value in a field of a given width.\"\"\"",
        "\"\"\"Right-align the value in a field of a given"
    ],
    [
        "\"\"\"Center the value in a field of a given width.\"\"\"",
        "\"\"\"Center the value in a"
    ],
    [
        "\"\"\"Remove all values of arg from the given string.\"\"\"",
        "\"\"\"Remove all values of arg from the given"
    ],
    [
        "if safe and arg != \";\":",
        "if safe and"
    ],
    [
        "\"\"\"Mark the value as a string that should be auto-escaped.\"\"\"",
        "\"\"\"Mark the value as a string that should"
    ],
    [
        "An \"escape\" filter for sequences. Mark each element in the sequence,",
        "An \"escape\" filter for sequences. Mark each"
    ],
    [
        "individually, as a string that should be auto-escaped. Return a list with",
        "individually, as a string that should be"
    ],
    [
        "return [conditional_escape(obj) for obj in value]",
        "return [conditional_escape(obj) for"
    ],
    [
        "Escape a string's HTML. Return a new string containing the escaped",
        "Escape a string's HTML. Return a new string containing the"
    ],
    [
        "characters (as opposed to \"escape\", which marks the content for later",
        "characters (as opposed to \"escape\", which marks the"
    ],
    [
        "Replace line breaks in plain text with appropriate HTML; a single",
        "Replace line breaks in plain text with appropriate HTML; a"
    ],
    [
        "newline becomes an HTML line break (``<br>``) and a new line",
        "newline becomes an HTML line break (``<br>``)"
    ],
    [
        "followed by a blank line becomes a paragraph break (``</p>``).",
        "followed by a blank line"
    ],
    [
        "autoescape = autoescape and not isinstance(value, SafeData)",
        "autoescape = autoescape and"
    ],
    [
        "Convert all newlines in a piece of plain text to HTML line breaks",
        "Convert all newlines in a piece of plain text to HTML"
    ],
    [
        "autoescape = autoescape and not isinstance(value, SafeData)",
        "autoescape = autoescape and not isinstance(value,"
    ],
    [
        "\"\"\"Mark the value as a string that should not be auto-escaped.\"\"\"",
        "\"\"\"Mark the value as a string that should not"
    ],
    [
        "A \"safe\" filter for sequences. Mark each element in the sequence,",
        "A \"safe\" filter for sequences. Mark"
    ],
    [
        "individually, as safe, after converting them to strings. Return a list",
        "individually, as safe, after converting them to strings. Return"
    ],
    [
        "return [mark_safe(obj) for obj in value]",
        "return [mark_safe(obj) for"
    ],
    [
        "When arg is convertible to float, behave like operator.itemgetter(arg)",
        "When arg is convertible to float,"
    ],
    [
        "TypeError: string indices must be integers",
        "TypeError: string indices must"
    ],
    [
        "raise AttributeError(\"Access to private variables is forbidden.\")",
        "raise AttributeError(\"Access to private variables is"
    ],
    [
        "except (AttributeError, IndexError, KeyError, TypeError, ValueError):",
        "except (AttributeError, IndexError, KeyError, TypeError,"
    ],
    [
        "Given a list of dicts, return that list sorted by the property given in",
        "Given a list of dicts, return that list sorted by the property"
    ],
    [
        "Given a list of dicts, return that list sorted in reverse order by the",
        "Given a list of dicts, return that list sorted in"
    ],
    [
        "\"\"\"Return the first item in a list.\"\"\"",
        "\"\"\"Return the first item"
    ],
    [
        "\"\"\"Join a list with a string, like Python's ``str.join(list)``.\"\"\"",
        "\"\"\"Join a list with a string, like Python's"
    ],
    [
        "data = conditional_escape(arg).join([conditional_escape(v) for v in value])",
        "data = conditional_escape(arg).join([conditional_escape(v) for"
    ],
    [
        "\"\"\"Return the last item in a list.\"\"\"",
        "\"\"\"Return the last item in"
    ],
    [
        "\"\"\"Return the length of the value - useful for lists.\"\"\"",
        "\"\"\"Return the length of the value - useful"
    ],
    [
        "\"\"\"Return a random item from the list.\"\"\"",
        "\"\"\"Return a random item from the"
    ],
    [
        "Return a slice of the list using the same syntax as Python's list slicing.",
        "Return a slice of the list using the"
    ],
    [
        "Recursively take a self-nested list and return an HTML unordered list --",
        "Recursively take a self-nested list and return an"
    ],
    [
        "WITHOUT opening and closing <ul> tags.",
        "WITHOUT opening and closing"
    ],
    [
        "Assume the list is in the proper format. For example, if ``var`` contains:",
        "Assume the list is in the proper format. For example, if"
    ],
    [
        "``['States', ['Kansas', ['Lawrence', 'Topeka'], 'Illinois']]``, then",
        "``['States', ['Kansas', ['Lawrence', 'Topeka'], 'Illinois']]``,"
    ],
    [
        "\"\"\"Add the arg to the value.\"\"\"",
        "\"\"\"Add the arg to"
    ],
    [
        "original value for invalid input (if input or argument is not an integer,",
        "original value for invalid input (if input or argument"
    ],
    [
        "\"\"\"Format a date according to the given format.\"\"\"",
        "\"\"\"Format a date according to"
    ],
    [
        "\"\"\"Format a time according to the given format.\"\"\"",
        "\"\"\"Format a time according to the"
    ],
    [
        "\"\"\"If value is unavailable, use given default.\"\"\"",
        "\"\"\"If value is unavailable, use"
    ],
    [
        "\"\"\"If value is None, use given default.\"\"\"",
        "\"\"\"If value is None, use"
    ],
    [
        "\"\"\"Return True if the value is divisible by the argument.\"\"\"",
        "\"\"\"Return True if the value is divisible by the"
    ],
    [
        "Given a string mapping values for true, false, and (optionally) None,",
        "Given a string mapping values for true, false, and"
    ],
    [
        "return one of those strings according to the value:",
        "return one of those strings"
    ],
    [
        "``None``    ``\"yeah,no\"``           ``\"no\"`` (converts None to False",
        "``None`` ``\"yeah,no\"`` ``\"no\"`` (converts None to"
    ],
    [
        "if no mapping for None is given.",
        "if no mapping for"
    ],
    [
        "value = ngettext(\"%(size)d byte\", \"%(size)d bytes\", bytes_) % {\"size\": bytes_}",
        "value = ngettext(\"%(size)d byte\", \"%(size)d bytes\", bytes_)"
    ],
    [
        "value = gettext(\"%s KB\") % filesize_number_format(bytes_ / KB)",
        "value = gettext(\"%s KB\") % filesize_number_format(bytes_"
    ],
    [
        "value = gettext(\"%s MB\") % filesize_number_format(bytes_ / MB)",
        "value = gettext(\"%s MB\") %"
    ],
    [
        "value = gettext(\"%s GB\") % filesize_number_format(bytes_ / GB)",
        "value = gettext(\"%s GB\")"
    ],
    [
        "value = gettext(\"%s TB\") % filesize_number_format(bytes_ / TB)",
        "value = gettext(\"%s TB\") % filesize_number_format(bytes_"
    ],
    [
        "value = gettext(\"%s PB\") % filesize_number_format(bytes_ / PB)",
        "value = gettext(\"%s PB\") % filesize_number_format(bytes_ /"
    ],
    [
        "If an argument is provided, use that string instead:",
        "If an argument is provided, use"
    ],
    [
        "If the provided argument contains a comma, use the text before the comma",
        "If the provided argument contains a comma, use the"
    ],
    [
        "for the singular case and the text after the comma for the plural case:",
        "for the singular case and the text after the"
    ],
    [
        "\"\"\"Take a phone number and converts it in to its numerical equivalent.\"\"\"",
        "\"\"\"Take a phone number and converts it in to its numerical"
    ],
    [
        "\"\"\"A wrapper around pprint.pprint -- for debugging, really.\"\"\"",
        "\"\"\"A wrapper around pprint.pprint --"
    ],
    [
        "return \"Error in formatting: %s: %s\" % (e.__class__.__name__, e)",
        "return \"Error in formatting: %s: %s\" %"
    ],
    [
        "\"app_dirs must not be set when loaders is defined.\"",
        "\"app_dirs must not be set"
    ],
    [
        "\"<%s:%s app_dirs=%s%s debug=%s loaders=%s string_if_invalid=%s \"",
        "\"<%s:%s app_dirs=%s%s debug=%s"
    ],
    [
        "\"\" if not self.dirs else \" dirs=%s\" % repr(self.dirs),",
        "\"\" if not self.dirs else \""
    ],
    [
        "\"\" if not self.libraries else \" libraries=%s\" % repr(self.libraries),",
        "\"\" if not self.libraries else"
    ],
    [
        "\"\" if not self.builtins else \" builtins=%s\" % repr(self.builtins),",
        "\"\" if not self.builtins else \" builtins=%s\""
    ],
    [
        "Return the first DjangoTemplates backend that's configured, or raise",
        "Return the first DjangoTemplates backend that's configured, or"
    ],
    [
        "This is required for preserving historical APIs that rely on a",
        "This is required for preserving historical APIs that"
    ],
    [
        "globally available, implicitly configured engine such as:",
        "globally available, implicitly configured engine such"
    ],
    [
        ">>> from django.template import Context, Template",
        ">>> from django.template"
    ],
    [
        ">>> template = Template(\"Hello {{ name }}!\")",
        ">>> template = Template(\"Hello {{ name"
    ],
    [
        "raise ImproperlyConfigured(\"No DjangoTemplates backend is configured.\")",
        "raise ImproperlyConfigured(\"No DjangoTemplates backend"
    ],
    [
        "return tuple(import_string(path) for path in context_processors)",
        "return tuple(import_string(path) for"
    ],
    [
        "return [import_library(x) for x in builtins]",
        "return [import_library(x) for x"
    ],
    [
        "\"Invalid value in template loaders configuration: %r\" % loader",
        "\"Invalid value in template loaders configuration: %r\" %"
    ],
    [
        "Return a compiled Template object for the given template code,",
        "Return a compiled Template object for"
    ],
    [
        "Return a compiled Template object for the given template name,",
        "Return a compiled Template object"
    ],
    [
        "template = Template(template, origin, template_name, engine=self)",
        "template = Template(template, origin,"
    ],
    [
        "Render the template specified by template_name with the given context.",
        "Render the template specified by"
    ],
    [
        "For use in Django's test suite.",
        "For use in Django's test"
    ],
    [
        "Given a list of template names, return the first that can be loaded.",
        "Given a list of template names, return the first"
    ],
    [
        "\"pop() has been called more times than push()\"",
        "\"pop() has been called more times than"
    ],
    [
        "builtins = {\"True\": True, \"False\": False, \"None\": None}",
        "builtins = {\"True\": True, \"False\": False,"
    ],
    [
        "\"Set a variable in the current context\"",
        "\"Set a variable in the current"
    ],
    [
        "Set a variable in one of the higher contexts if it exists there,",
        "Set a variable in one of the"
    ],
    [
        "\"Get a variable's value, starting at the current context and going upward\"",
        "\"Get a variable's value, starting at"
    ],
    [
        "\"Delete a variable from the current context\"",
        "\"Delete a variable from the"
    ],
    [
        "return any(key in d for d in self.dicts)",
        "return any(key in d for"
    ],
    [
        "Return a new context with the same properties, but with only the",
        "Return a new context with the"
    ],
    [
        "Compare two contexts by comparing theirs 'dicts' attributes.",
        "Compare two contexts by comparing theirs 'dicts'"
    ],
    [
        "\"A stack container for variable context\"",
        "\"A stack container"
    ],
    [
        "raise RuntimeError(\"Context is already bound to a template\")",
        "raise RuntimeError(\"Context is already bound"
    ],
    [
        "\"Push other_dict to the stack of dictionaries in the Context\"",
        "\"Push other_dict to the stack of dictionaries in"
    ],
    [
        "raise TypeError(\"other_dict must be a mapping (dictionary-like) object.\")",
        "raise TypeError(\"other_dict must be a mapping"
    ],
    [
        "A stack container for storing Template state.",
        "A stack container for"
    ],
    [
        "RenderContext simplifies the implementation of template Nodes by providing a",
        "RenderContext simplifies the implementation of template"
    ],
    [
        "safe place to store state between invocations of a node's `render` method.",
        "safe place to store state between"
    ],
    [
        "The RenderContext also provides scoping rules that are more sensible for",
        "The RenderContext also provides scoping rules that are"
    ],
    [
        "'template local' variables. The render context stack is pushed before each",
        "'template local' variables. The render context"
    ],
    [
        "template is rendered, creating a fresh scope with nothing in it. Name",
        "template is rendered, creating a fresh"
    ],
    [
        "resolution fails if a variable is not found at the top of the RequestContext",
        "resolution fails if a variable is not found at"
    ],
    [
        "stack. Thus, variables are local to a specific template and don't affect the",
        "stack. Thus, variables are local to a"
    ],
    [
        "rendering of other templates as they would if they were stored in the normal",
        "rendering of other templates as they would if they"
    ],
    [
        "This subclass of template.Context automatically populates itself using",
        "This subclass of template.Context automatically populates"
    ],
    [
        "the processors defined in the engine's configuration.",
        "the processors defined in"
    ],
    [
        "Additional processors can be specified as a list of callables",
        "Additional processors can be specified"
    ],
    [
        "self._processors = () if processors is None else tuple(processors)",
        "self._processors = () if processors"
    ],
    [
        "raise RuntimeError(\"Context is already bound to a template\")",
        "raise RuntimeError(\"Context is already"
    ],
    [
        "f\"Context processor {processor.__qualname__} didn't return a \"",
        "f\"Context processor {processor.__qualname__} didn't return"
    ],
    [
        "Create a suitable Context from a plain dict and optionally an HttpRequest.",
        "Create a suitable Context from a plain dict and optionally an"
    ],
    [
        "if context is not None and not isinstance(context, dict):",
        "if context is not None and not isinstance(context,"
    ],
    [
        "\"context must be a dict rather than %s.\" % context.__class__.__name__",
        "\"context must be a dict rather than"
    ],
    [
        "templates is an optional list of template engine definitions",
        "templates is an optional list of template engine"
    ],
    [
        "\"Invalid BACKEND for a template engine: {}. Check \"",
        "\"Invalid BACKEND for a template engine: {}. Check"
    ],
    [
        "\"Template engine aliases aren't unique, duplicates: {}. \"",
        "\"Template engine aliases aren't unique, duplicates:"
    ],
    [
        "\"Set a unique NAME for each engine in settings.TEMPLATES.\".format(",
        "\"Set a unique NAME for each"
    ],
    [
        "\"Could not find config for '{}' \"",
        "\"Could not find config for"
    ],
    [
        "return [self[alias] for alias in self]",
        "return [self[alias] for"
    ],
    [
        "Return an iterable of paths of directories to load app templates from.",
        "Return an iterable of paths of directories"
    ],
    [
        "dirname is the name of the subdirectory containing templates inside",
        "dirname is the name of"
    ],
    [
        "if app_config.path and (path := Path(app_config.path) / dirname).is_dir()",
        "if app_config.path and (path := Path(app_config.path)"
    ],
    [
        "Load and return a template for the given name.",
        "Load and return a template for the given"
    ],
    [
        "Raise TemplateDoesNotExist if no such template exists.",
        "Raise TemplateDoesNotExist if no such template"
    ],
    [
        "Load and return a template for one of the given names.",
        "Load and return a template for"
    ],
    [
        "Try names in order and return the first template found.",
        "Try names in order and return the first"
    ],
    [
        "Raise TemplateDoesNotExist if no such template exists.",
        "Raise TemplateDoesNotExist if no such template"
    ],
    [
        "\"select_template() takes an iterable of template names but got a \"",
        "\"select_template() takes an iterable of template names"
    ],
    [
        "\"string: %r. Use get_template() if you want to load a single \"",
        "\"string: %r. Use get_template() if you want to load"
    ],
    [
        "Load a template and render it with a context. Return a string.",
        "Load a template and render it"
    ],
    [
        "template_name may be a string or a list of strings.",
        "template_name may be a string or a list of"
    ],
    [
        "return engines.all() if using is None else [engines[using]]",
        "return engines.all() if using is"
    ],
    [
        "from .base import Node, Template, TemplateSyntaxError, TextNode, Variable, token_kwargs",
        "from .base import Node, Template,"
    ],
    [
        "return \"<Block Node: %s. Contents: %r>\" % (self.name, self.nodelist)",
        "return \"<Block Node: %s. Contents: %r>\" % (self.name,"
    ],
    [
        "\"'%s' object has no attribute 'context'. Did you use \"",
        "\"'%s' object has no attribute 'context'. Did you use"
    ],
    [
        "\"{{ block.super }} in a base template?\" % self.__class__.__name__",
        "\"{{ block.super }} in a base"
    ],
    [
        "self.blocks = {n.name: n for n in nodelist.get_nodes_by_type(BlockNode)}",
        "self.blocks = {n.name: n for"
    ],
    [
        "return \"<%s: extends %s>\" % (self.__class__.__name__, self.parent_name.token)",
        "return \"<%s: extends %s>\" % (self.__class__.__name__,"
    ],
    [
        "This is a wrapper around engine.find_template(). A history is kept in",
        "This is a wrapper around engine.find_template(). A history is"
    ],
    [
        "the render_context attribute between successive extends calls and",
        "the render_context attribute between successive extends"
    ],
    [
        "passed as the skip argument. This enables extends to work recursively",
        "passed as the skip argument. This enables extends to work"
    ],
    [
        "without extending the same template twice.",
        "without extending the"
    ],
    [
        "error_msg = \"Invalid template name in 'extends' tag: %r.\" % parent",
        "error_msg = \"Invalid template name in 'extends'"
    ],
    [
        "\" Got this from the '%s' variable.\" % self.parent_name.token",
        "\" Got this from the '%s'"
    ],
    [
        "self, template, *args, extra_context=None, isolated_context=False, **kwargs",
        "self, template, *args, extra_context=None,"
    ],
    [
        "Render the specified template and context. Cache the template object",
        "Render the specified template and"
    ],
    [
        "in render_context to avoid reparsing and loading when used in a for",
        "in render_context to avoid reparsing and loading when"
    ],
    [
        "name: var.resolve(context) for name, var in self.extra_context.items()",
        "name: var.resolve(context) for name, var"
    ],
    [
        "Define a block that can be overridden by child templates.",
        "Define a block that can be overridden"
    ],
    [
        "acceptable_endblocks = (\"endblock\", \"endblock %s\" % block_name)",
        "acceptable_endblocks = (\"endblock\", \"endblock %s\""
    ],
    [
        "Convert a relative path (starting with './' or '../') to the full template",
        "Convert a relative path (starting with './' or '../') to the full"
    ],
    [
        "\"The relative path '%s' points outside the file hierarchy that \"",
        "\"The relative path '%s' points outside the"
    ],
    [
        "\"template '%s' is in.\" % (relative_name, current_template_name)",
        "\"template '%s' is in.\" %"
    ],
    [
        "if not allow_recursion and current_template_name.lstrip(\"/\") == new_name:",
        "if not allow_recursion and"
    ],
    [
        "\"The relative path '%s' was translated to template name '%s', the \"",
        "\"The relative path '%s' was translated to template"
    ],
    [
        "\"same template in which the tag appears.\"",
        "\"same template in which the tag"
    ],
    [
        "return f'\"{new_name}\"' if has_quotes else new_name",
        "return f'\"{new_name}\"' if"
    ],
    [
        "Signal that this template extends a parent template.",
        "Signal that this template"
    ],
    [
        "This tag may be used in two ways: ``{% extends \"base\" %}`` (with quotes)",
        "This tag may be used in two ways: ``{%"
    ],
    [
        "uses the literal value \"base\" as the name of the parent template to extend,",
        "uses the literal value \"base\" as the name of the parent"
    ],
    [
        "or ``{% extends variable %}`` uses the value of ``variable`` as either the",
        "or ``{% extends variable %}`` uses the value of ``variable``"
    ],
    [
        "name of the parent template to extend (if it evaluates to a string) or as",
        "name of the parent template to extend (if it evaluates to"
    ],
    [
        "the parent template itself (if it evaluates to a Template object).",
        "the parent template itself (if it"
    ],
    [
        "Load a template and render it with the current context. You can pass",
        "Load a template and render it with the current context."
    ],
    [
        "{% include \"foo/some_include\" with bar=\"BAZZ!\" baz=\"BING!\" %}",
        "{% include \"foo/some_include\" with"
    ],
    [
        "Use the ``only`` argument to exclude the current context when rendering",
        "Use the ``only`` argument to exclude the"
    ],
    [
        "\"%r tag takes at least one argument: the name of the template to \"",
        "\"%r tag takes at least one argument: the name of the template to"
    ],
    [
        "\"The %r option was specified more than once.\" % option",
        "\"The %r option was specified"
    ],
    [
        "This module contains generic exceptions used by template backends. Although,",
        "This module contains generic exceptions used by template"
    ],
    [
        "due to historical reasons, the Django template language also internally uses",
        "due to historical reasons, the Django template"
    ],
    [
        "these exceptions, other exceptions specific to the DTL should not be added",
        "these exceptions, other exceptions specific to the DTL"
    ],
    [
        "The exception used when a template does not exist. Optional arguments:",
        "The exception used when a template does not exist."
    ],
    [
        "The template backend class used when raising this exception.",
        "The template backend class used"
    ],
    [
        "A list of sources that were tried when finding the template. This",
        "A list of sources that were tried"
    ],
    [
        "is formatted as a list of tuples containing (origin, status), where",
        "is formatted as a list of tuples containing (origin,"
    ],
    [
        "origin is an Origin object or duck type and status is a string with the",
        "origin is an Origin object or duck type and status is a string"
    ],
    [
        "A list of intermediate TemplateDoesNotExist exceptions. This is used to",
        "A list of intermediate TemplateDoesNotExist exceptions. This is used"
    ],
    [
        "encapsulate multiple exceptions when loading templates from multiple",
        "encapsulate multiple exceptions when loading templates"
    ],
    [
        "def __init__(self, msg, tried=None, backend=None, chain=None):",
        "def __init__(self, msg, tried=None,"
    ],
    [
        "The exception used for syntax errors during parsing or rendering.",
        "The exception used for syntax errors during parsing"
    ],
    [
        "from django.utils.autoreload import autoreload_started, file_changed, is_django_path",
        "from django.utils.autoreload import autoreload_started, file_changed,"
    ],
    [
        "items.update(cwd / to_path(dir) for dir in backend.engine.dirs if dir)",
        "items.update(cwd / to_path(dir) for dir in backend.engine.dirs if"
    ],
    [
        "This is the Django template system.",
        "This is the"
    ],
    [
        "The Lexer.tokenize() method converts a template string (i.e., a string",
        "The Lexer.tokenize() method converts a"
    ],
    [
        "containing markup with custom template tags) to tokens, which can be either",
        "containing markup with custom template tags) to tokens,"
    ],
    [
        "plain text (TokenType.TEXT), variables (TokenType.VAR), or block statements",
        "plain text (TokenType.TEXT), variables"
    ],
    [
        "The Parser() class takes a list of tokens in its constructor, and its parse()",
        "The Parser() class takes a list of tokens in its constructor,"
    ],
    [
        "method returns a compiled template -- which is, under the hood, a list of",
        "method returns a compiled template -- which is, under the hood, a"
    ],
    [
        "Each Node is responsible for creating some sort of output -- e.g. simple text",
        "Each Node is responsible for creating some sort of output -- e.g."
    ],
    [
        "(TextNode), variable values in a given context (VariableNode), results of basic",
        "(TextNode), variable values in a given context (VariableNode),"
    ],
    [
        "logic (IfNode), results of looping (ForNode), or anything else. The core Node",
        "logic (IfNode), results of looping (ForNode), or anything else."
    ],
    [
        "types are TextNode, VariableNode, IfNode and ForNode, but plugin modules can",
        "types are TextNode, VariableNode, IfNode and ForNode, but"
    ],
    [
        "define their own custom node types.",
        "define their own custom node"
    ],
    [
        "Each Node has a render() method, which takes a Context and returns a string of",
        "Each Node has a render() method, which takes a Context and returns a string"
    ],
    [
        "the rendered node. For example, the render() method of a Variable Node returns",
        "the rendered node. For example, the render() method of"
    ],
    [
        "the variable's value as a string. The render() method of a ForNode returns the",
        "the variable's value as a string. The render()"
    ],
    [
        "rendered output of whatever was inside the loop, recursively.",
        "rendered output of whatever was inside the"
    ],
    [
        "The Template class is a convenient wrapper that takes care of template",
        "The Template class is a convenient wrapper that takes care of"
    ],
    [
        "The only thing you should ever use directly in this file is the Template class.",
        "The only thing you should ever use directly"
    ],
    [
        "Create a compiled template object with a template_string, then call render()",
        "Create a compiled template object with a template_string,"
    ],
    [
        "with a context. In the compilation stage, the TemplateSyntaxError exception",
        "with a context. In the compilation"
    ],
    [
        "will be raised if the template doesn't have proper syntax.",
        "will be raised if the template doesn't have proper"
    ],
    [
        "(t is now a compiled template, and its render() method can be called multiple",
        "(t is now a compiled template, and its render()"
    ],
    [
        ">>> c = template.Context({'test':True, 'varvalue': 'Hello'})",
        ">>> c = template.Context({'test':True, 'varvalue':"
    ],
    [
        ">>> c = template.Context({'test':False, 'varvalue': 'Hello'})",
        ">>> c = template.Context({'test':False, 'varvalue':"
    ],
    [
        "from django.utils.safestring import SafeData, SafeString, mark_safe",
        "from django.utils.safestring import SafeData, SafeString,"
    ],
    [
        "from django.utils.text import get_text_list, smart_split, unescape_string_literal",
        "from django.utils.text import"
    ],
    [
        "return \"<%s name=%r>\" % (self.__class__.__qualname__, self.name)",
        "return \"<%s name=%r>\" % (self.__class__.__qualname__,"
    ],
    [
        "def __init__(self, template_string, origin=None, name=None, engine=None):",
        "def __init__(self, template_string, origin=None, name=None,"
    ],
    [
        "\"Display stage -- can be called many times\"",
        "\"Display stage -- can be called"
    ],
    [
        "Parse and compile the template source into a nodelist. If debug",
        "Parse and compile the template source into a"
    ],
    [
        "is True and an exception occurs during parsing, the exception is",
        "is True and an exception occurs during parsing,"
    ],
    [
        "annotated with contextual line information where it occurred in the",
        "annotated with contextual line information where it occurred in"
    ],
    [
        "Return a dictionary containing contextual line information of where",
        "Return a dictionary containing contextual line information"
    ],
    [
        "the exception occurred in the template. The following information is",
        "the exception occurred in the template. The following"
    ],
    [
        "The message of the exception raised.",
        "The message of the"
    ],
    [
        "The lines before, after, and including the line the exception",
        "The lines before, after, and including the"
    ],
    [
        "The line number the exception occurred on.",
        "The line number the exception"
    ],
    [
        "The line the exception occurred on split into three parts:",
        "The line the exception occurred on split into three"
    ],
    [
        "The number of lines in source_lines.",
        "The number of"
    ],
    [
        "The line number where source_lines starts.",
        "The line number where source_lines"
    ],
    [
        "The line number where source_lines ends.",
        "The line number where source_lines"
    ],
    [
        "The start position of the token in the template source.",
        "The start position of the token"
    ],
    [
        "The end position of the token in the template source.",
        "The end position of the token in"
    ],
    [
        "before = during = after = \"\"",
        "before = during = after"
    ],
    [
        "if start >= upto and end <= next:",
        "if start >= upto and"
    ],
    [
        "message = \"(Could not get exception message)\"",
        "message = \"(Could not"
    ],
    [
        "def __init__(self, token_type, contents, position=None, lineno=None):",
        "def __init__(self, token_type, contents,"
    ],
    [
        "A token representing a string from the template.",
        "A token representing a string from the"
    ],
    [
        "A TokenType, either .TEXT, .VAR, .BLOCK, or .COMMENT.",
        "A TokenType, either .TEXT,"
    ],
    [
        "An optional tuple containing the start and end index of the token",
        "An optional tuple containing the start and end"
    ],
    [
        "in the template source. This is used for traceback information",
        "in the template source. This is used"
    ],
    [
        "The line number the token appears on in the template source.",
        "The line number the token appears"
    ],
    [
        "This is used for traceback information and gettext files.",
        "This is used for traceback information"
    ],
    [
        "return '<%s token: \"%s...\">' % (",
        "return '<%s token: \"%s...\">'"
    ],
    [
        "return '<%s template_string=\"%s...\", verbatim=%s>' % (",
        "return '<%s template_string=\"%s...\", verbatim=%s>' %"
    ],
    [
        "Return a list of tokens from a given template_string.",
        "Return a list of tokens from a"
    ],
    [
        "def create_token(self, token_string, position, lineno, in_tag):",
        "def create_token(self, token_string, position, lineno,"
    ],
    [
        "Convert the given token string into a new Token object and return it.",
        "Convert the given token string into a new Token"
    ],
    [
        "If in_tag is True, we are processing something that matched a tag,",
        "If in_tag is True, we are processing something that matched"
    ],
    [
        "otherwise it should be treated as a literal string.",
        "otherwise it should be treated"
    ],
    [
        "Split a template string into tokens and annotates each token with its",
        "Split a template string into tokens and annotates each"
    ],
    [
        "start and end position in the source. This is slower than the default",
        "start and end position in the source. This is slower than the"
    ],
    [
        "lexer so only use it when debug is True.",
        "lexer so only use it when"
    ],
    [
        "def __init__(self, tokens, libraries=None, builtins=None, origin=None):",
        "def __init__(self, tokens, libraries=None,"
    ],
    [
        "return \"<%s tokens=%r>\" % (self.__class__.__qualname__, self.tokens)",
        "return \"<%s tokens=%r>\" % (self.__class__.__qualname__,"
    ],
    [
        "Iterate through the parser tokens and compiles each one into a node.",
        "Iterate through the parser tokens and compiles"
    ],
    [
        "If parse_until is provided, parsing will stop once one of the",
        "If parse_until is provided, parsing will stop once one of"
    ],
    [
        "specified tokens has been reached. This is formatted as a list of",
        "specified tokens has been reached. This"
    ],
    [
        "tokens, e.g. ['elif', 'else', 'endif']. If no matching token is",
        "tokens, e.g. ['elif', 'else', 'endif']. If no matching token"
    ],
    [
        "reached, raise an exception with the unclosed block tag details.",
        "reached, raise an exception with the unclosed block"
    ],
    [
        "token, \"Empty variable tag on line %d\" % token.lineno",
        "token, \"Empty variable tag on line %d\" %"
    ],
    [
        "raise self.error(token, \"Empty block tag on line %d\" % token.lineno)",
        "raise self.error(token, \"Empty block tag on line"
    ],
    [
        "if token.token_type == TokenType.BLOCK and token.contents == endtag:",
        "if token.token_type == TokenType.BLOCK and token.contents =="
    ],
    [
        "\"{%% %s %%} must be the first tag in %s.\" % (token.contents, origin),",
        "\"{%% %s %%} must be the first tag in"
    ],
    [
        "Return an exception annotated with the originating token. Since the",
        "Return an exception annotated with the originating"
    ],
    [
        "parser can be called recursively, check if a token is already set. This",
        "parser can be called recursively, check if a"
    ],
    [
        "ensures the innermost token is highlighted if an exception occurs,",
        "ensures the innermost token is highlighted if an exception"
    ],
    [
        "e.g. a compile error within the body of an if statement.",
        "e.g. a compile error within the body of"
    ],
    [
        "\"Invalid block tag on line %d: '%s', expected %s. Did you \"",
        "\"Invalid block tag on line %d: '%s', expected %s."
    ],
    [
        "\"forget to register or load this tag?\"",
        "\"forget to register or load this"
    ],
    [
        "get_text_list([\"'%s'\" % p for p in parse_until], \"or\"),",
        "get_text_list([\"'%s'\" % p for p in"
    ],
    [
        "\"Invalid block tag on line %d: '%s'. Did you forget to register \"",
        "\"Invalid block tag on line %d: '%s'. Did you forget"
    ],
    [
        "\"or load this tag?\" % (token.lineno, command),",
        "\"or load this tag?\" % (token.lineno,"
    ],
    [
        "msg = \"Unclosed tag on line %d: '%s'. Looking for one of: %s.\" % (",
        "msg = \"Unclosed tag on line %d: '%s'. Looking for one of: %s.\" %"
    ],
    [
        "raise TemplateSyntaxError(\"Invalid filter: '%s'\" % filter_name)",
        "raise TemplateSyntaxError(\"Invalid filter: '%s'\" %"
    ],
    [
        "Parse a variable token and its optional filters (all as a single string),",
        "Parse a variable token and its optional filters (all"
    ],
    [
        "and return a list of tuples of the filter name and arguments.",
        "and return a list of tuples of"
    ],
    [
        "__slots__ = (\"token\", \"filters\", \"var\", \"is_var\")",
        "__slots__ = (\"token\","
    ],
    [
        "\"Could not parse some characters: \"",
        "\"Could not parse some"
    ],
    [
        "elif (var := match[\"var\"]) is None:",
        "elif (var :="
    ],
    [
        "\"Could not find variable at start of %s.\" % token",
        "\"Could not find variable at start of %s.\""
    ],
    [
        "\"Could not parse the remainder: '%s' \"",
        "\"Could not parse the remainder: '%s'"
    ],
    [
        "if getattr(func, \"is_safe\", False) and isinstance(obj, SafeData):",
        "if getattr(func, \"is_safe\", False)"
    ],
    [
        "args, _, _, defaults, _, _, _ = inspect.getfullargspec(func)",
        "args, _, _, defaults, _, _, _ ="
    ],
    [
        "if plen < (alen - dlen) or plen > alen:",
        "if plen < (alen -"
    ],
    [
        "\"%s requires %d arguments, %d provided\" % (name, alen - dlen, plen)",
        "\"%s requires %d arguments, %d provided\" %"
    ],
    [
        "return \"<%s %r>\" % (self.__class__.__qualname__, self.token)",
        "return \"<%s %r>\""
    ],
    [
        "A template variable, resolvable against a given context. The variable may",
        "A template variable, resolvable against a given context. The"
    ],
    [
        "be a hard-coded string (if it begins and ends with single or double quote",
        "be a hard-coded string (if it begins"
    ],
    [
        "(The example assumes VARIABLE_ATTRIBUTE_SEPARATOR is '.')",
        "(The example assumes VARIABLE_ATTRIBUTE_SEPARATOR is"
    ],
    [
        "__slots__ = (\"var\", \"literal\", \"lookups\", \"translate\", \"message_context\")",
        "__slots__ = (\"var\", \"literal\","
    ],
    [
        "raise TypeError(\"Variable must be a string or number, got %s\" % type(var))",
        "raise TypeError(\"Variable must be a string or number, got %s\" %"
    ],
    [
        "if \".\" in var or \"e\" in var.lower():",
        "if \".\" in var"
    ],
    [
        "\"not begin with underscores: '%s'\" % var",
        "\"not begin with underscores: '%s'\" %"
    ],
    [
        "\"\"\"Resolve this variable against a given context.\"\"\"",
        "\"\"\"Resolve this variable against a given"
    ],
    [
        "msgid = mark_safe(msgid) if is_safe else msgid",
        "msgid = mark_safe(msgid) if"
    ],
    [
        "return \"<%s: %r>\" % (self.__class__.__name__, self.var)",
        "return \"<%s: %r>\" % (self.__class__.__name__,"
    ],
    [
        "Perform resolution of a real variable (i.e. not a literal) against the",
        "Perform resolution of a real variable (i.e."
    ],
    [
        "As indicated by the method's name, this method is an implementation",
        "As indicated by the method's name, this method"
    ],
    [
        "detail and shouldn't be called by external code. Use Variable.resolve()",
        "detail and shouldn't be called by"
    ],
    [
        "except (TypeError, AttributeError, KeyError, ValueError, IndexError):",
        "except (TypeError, AttributeError,"
    ],
    [
        "if not isinstance(current, BaseContext) and bit in dir(current):",
        "if not isinstance(current, BaseContext) and bit"
    ],
    [
        "\"Failed lookup for key [%s] in %r\",",
        "\"Failed lookup for key"
    ],
    [
        "template_name = getattr(context, \"template_name\", None) or \"unknown\"",
        "template_name = getattr(context, \"template_name\", None) or"
    ],
    [
        "\"Exception while resolving variable '%s' in template '%s'.\",",
        "\"Exception while resolving variable"
    ],
    [
        "Return the node rendered as a string.",
        "Return the node rendered as a"
    ],
    [
        "Render the node. If debug is True and an exception occurs during",
        "Render the node. If debug is True"
    ],
    [
        "rendering, the exception is annotated with contextual line information",
        "rendering, the exception is annotated with"
    ],
    [
        "where it occurred in the template. For internal usage this method is",
        "where it occurred in the template. For internal usage this"
    ],
    [
        "preferred over using the render method directly.",
        "preferred over using the"
    ],
    [
        "Return a list of all nodes (within this node and its nodelist)",
        "Return a list of all nodes (within this node and"
    ],
    [
        "return SafeString(\"\".join([node.render_annotated(context) for node in self]))",
        "return SafeString(\"\".join([node.render_annotated(context) for node"
    ],
    [
        "\"Return a list of all nodes of the given type\"",
        "\"Return a list of all"
    ],
    [
        "The default implementation of this method handles exceptions raised",
        "The default implementation of this method handles exceptions"
    ],
    [
        "during rendering, which is not necessary for text nodes.",
        "during rendering, which is not necessary"
    ],
    [
        "Convert any value to a string to become part of a rendered template. This",
        "Convert any value to a string to"
    ],
    [
        "means escaping, if required, and conversion to a string. If value is a",
        "means escaping, if required, and conversion to a string. If value is"
    ],
    [
        "string, it's expected to already be translated.",
        "string, it's expected to already be"
    ],
    [
        "return \"<Variable Node: %s>\" % self.filter_expression",
        "return \"<Variable Node: %s>\" %"
    ],
    [
        "Parse token keyword arguments and return a dictionary of the arguments",
        "Parse token keyword arguments and return a dictionary of"
    ],
    [
        "retrieved from the ``bits`` token list.",
        "retrieved from the"
    ],
    [
        "`bits` is a list containing the remainder of the token (split by spaces)",
        "`bits` is a list containing the remainder"
    ],
    [
        "that is to be checked for arguments. Valid arguments are removed from this",
        "that is to be checked for arguments."
    ],
    [
        "There is no requirement for all remaining token ``bits`` to be keyword",
        "There is no requirement for all remaining"
    ],
    [
        "arguments, so return the dictionary as soon as an invalid argument format",
        "arguments, so return the dictionary as soon as an invalid"
    ],
    [
        "\"\"\"Default tags used by the template system, available to all templates.\"\"\"",
        "\"\"\"Default tags used by the template system,"
    ],
    [
        "from itertools import cycle as itertools_cycle",
        "from itertools import"
    ],
    [
        "from django.utils.html import conditional_escape, escape, format_html",
        "from django.utils.html import conditional_escape,"
    ],
    [
        "\"\"\"Implement the actions of the autoescape tag.\"\"\"",
        "\"\"\"Implement the actions of"
    ],
    [
        "\"A {% csrf_token %} was used in a template, but the context \"",
        "\"A {% csrf_token %} was used in a template,"
    ],
    [
        "\"did not provide the value.  This is usually caused by not \"",
        "\"did not provide the value. This is usually caused by"
    ],
    [
        "Reset the cycle iteration back to the beginning.",
        "Reset the cycle iteration back"
    ],
    [
        "output = [escape(pformat(val)) for val in context]",
        "output = [escape(pformat(val)) for val"
    ],
    [
        "self, loopvars, sequence, is_reversed, nodelist_loop, nodelist_empty=None",
        "self, loopvars, sequence,"
    ],
    [
        "reversed_text = \" reversed\" if self.is_reversed else \"\"",
        "reversed_text = \" reversed\" if"
    ],
    [
        "return \"<%s: for %s in %s, tail_len: %d%s>\" % (",
        "return \"<%s: for %s in %s, tail_len:"
    ],
    [
        "loop_dict = context[\"forloop\"] = {\"parentloop\": parentloop}",
        "loop_dict = context[\"forloop\"] ="
    ],
    [
        "\"Need {} values to unpack in for loop; got {}. \".format(",
        "\"Need {} values to unpack in for loop; got"
    ],
    [
        "var.resolve(context, ignore_failures=True) for var in self._varlist",
        "var.resolve(context, ignore_failures=True) for var"
    ],
    [
        "paras = [\"<p>%s</p>\" % p for p in paras]",
        "paras = [\"<p>%s</p>\" % p for p"
    ],
    [
        "tzinfo = timezone.get_current_timezone() if settings.USE_TZ else None",
        "tzinfo = timezone.get_current_timezone() if"
    ],
    [
        "def __init__(self, view_name, args, kwargs, asvar):",
        "def __init__(self, view_name,"
    ],
    [
        "return \"<%s view_name='%s' args=%s kwargs=%s as=%s>\" % (",
        "return \"<%s view_name='%s' args=%s kwargs=%s as=%s>\" %"
    ],
    [
        "args = [arg.resolve(context) for arg in self.args]",
        "args = [arg.resolve(context) for"
    ],
    [
        "kwargs = {k: v.resolve(context) for k, v in self.kwargs.items()}",
        "kwargs = {k: v.resolve(context) for k, v"
    ],
    [
        "url = reverse(view_name, args=args, kwargs=kwargs, current_app=current_app)",
        "url = reverse(view_name, args=args, kwargs=kwargs,"
    ],
    [
        "def __init__(self, val_expr, max_expr, max_width, asvar=None):",
        "def __init__(self, val_expr, max_expr,"
    ],
    [
        "raise TemplateSyntaxError(\"widthratio final argument must be a number\")",
        "raise TemplateSyntaxError(\"widthratio final argument must"
    ],
    [
        "ratio = (value / max_value) * max_width",
        "ratio = (value / max_value) *"
    ],
    [
        "def __init__(self, var, name, nodelist, extra_context=None):",
        "def __init__(self, var, name,"
    ],
    [
        "values = {key: val.resolve(context) for key, val in self.extra_context.items()}",
        "values = {key: val.resolve(context) for key, val in"
    ],
    [
        "Force autoescape behavior for this block.",
        "Force autoescape behavior"
    ],
    [
        "raise TemplateSyntaxError(\"'autoescape' tag requires exactly one argument.\")",
        "raise TemplateSyntaxError(\"'autoescape' tag requires exactly"
    ],
    [
        "if arg not in (\"on\", \"off\"):",
        "if arg not in (\"on\","
    ],
    [
        "raise TemplateSyntaxError(\"'autoescape' argument should be 'on' or 'off'\")",
        "raise TemplateSyntaxError(\"'autoescape' argument should be 'on'"
    ],
    [
        "Ignore everything between ``{% comment %}`` and ``{% endcomment %}``.",
        "Ignore everything between ``{% comment %}`` and"
    ],
    [
        "Cycle among the given strings each time this tag is encountered.",
        "Cycle among the given strings each"
    ],
    [
        "Within a loop, cycles among the given strings each time through",
        "Within a loop, cycles among the given strings each"
    ],
    [
        "{% for o in some_list %}",
        "{% for o in some_list"
    ],
    [
        "Outside of a loop, give the values a unique name the first time you call",
        "Outside of a loop, give the values a unique name"
    ],
    [
        "it, then use that name each successive time through::",
        "it, then use that name"
    ],
    [
        "You can use any number of values, separated by spaces. Commas can also",
        "You can use any number of values,"
    ],
    [
        "be used to separate values; if a comma is used, the cycle values are",
        "be used to separate values; if a comma is used, the cycle values"
    ],
    [
        "The optional flag \"silent\" can be used to prevent the cycle declaration",
        "The optional flag \"silent\" can be used to prevent the cycle"
    ],
    [
        "{% for o in some_list %}",
        "{% for o"
    ],
    [
        "<tr class=\"{{ rowcolors }}\">{% include \"subtemplate.html \" %}</tr>",
        "<tr class=\"{{ rowcolors }}\">{%"
    ],
    [
        "raise TemplateSyntaxError(\"'cycle' tag requires at least two arguments\")",
        "raise TemplateSyntaxError(\"'cycle' tag requires at least two"
    ],
    [
        "\"No named cycles in template. '%s' is not defined\" % name",
        "\"No named cycles in template. '%s'"
    ],
    [
        "raise TemplateSyntaxError(\"Named cycle '%s' does not exist\" % name)",
        "raise TemplateSyntaxError(\"Named cycle '%s' does"
    ],
    [
        "\"Only 'silent' flag is allowed after cycle's name, not '%s'.\"",
        "\"Only 'silent' flag is allowed after cycle's name,"
    ],
    [
        "Output a whole load of debugging information, including the current",
        "Output a whole load of debugging information, including the"
    ],
    [
        "Filter the contents of the block through variable filters.",
        "Filter the contents of the block"
    ],
    [
        "Filters can also be piped through each other, and they can have",
        "Filters can also be piped through each other, and"
    ],
    [
        "arguments -- just like in variable syntax.",
        "arguments -- just like"
    ],
    [
        "This text will be HTML-escaped, and will appear in lowercase.",
        "This text will be HTML-escaped, and will appear"
    ],
    [
        "Note that the ``escape`` and ``safe`` filters are not acceptable arguments.",
        "Note that the ``escape`` and ``safe`` filters are not"
    ],
    [
        "Instead, use the ``autoescape`` tag to manage autoescaping for blocks of",
        "Instead, use the ``autoescape`` tag to manage autoescaping for blocks"
    ],
    [
        "'\"filter %s\" is not permitted.  Use the \"autoescape\" tag instead.'",
        "'\"filter %s\" is not permitted. Use the \"autoescape\" tag"
    ],
    [
        "Output the first variable passed that is not False.",
        "Output the first variable passed that"
    ],
    [
        "Output nothing if all the passed variables are False.",
        "Output nothing if all the passed variables"
    ],
    [
        "You can also use a literal string as a fallback value in case all",
        "You can also use a literal string as a"
    ],
    [
        "If you want to disable auto-escaping of variables you can use::",
        "If you want to disable auto-escaping of variables"
    ],
    [
        "Or if only some variables should be escaped, you can use::",
        "Or if only some variables should be escaped,"
    ],
    [
        "raise TemplateSyntaxError(\"'firstof' statement requires at least one argument\")",
        "raise TemplateSyntaxError(\"'firstof' statement requires at"
    ],
    [
        "return FirstOfNode([parser.compile_filter(bit) for bit in bits], asvar)",
        "return FirstOfNode([parser.compile_filter(bit) for bit"
    ],
    [
        "Loop over each item in an array.",
        "Loop over each item in an"
    ],
    [
        "For example, to display a list of athletes given ``athlete_list``::",
        "For example, to display a list"
    ],
    [
        "{% for athlete in athlete_list %}",
        "{% for athlete in"
    ],
    [
        "You can loop over a list in reverse by using",
        "You can loop over a list"
    ],
    [
        "``{% for obj in list reversed %}``.",
        "``{% for obj in"
    ],
    [
        "You can also unpack multiple values from a two-dimensional array::",
        "You can also unpack multiple values from"
    ],
    [
        "{% for key,value in dict.items %}",
        "{% for key,value in"
    ],
    [
        "{{ key }}: {{ value }}",
        "{{ key }}: {{"
    ],
    [
        "The ``for`` tag can take an optional ``{% empty %}`` clause that will",
        "The ``for`` tag can take an optional ``{% empty %}`` clause that"
    ],
    [
        "be displayed if the given array is empty or could not be found::",
        "be displayed if the given array is empty or"
    ],
    [
        "{% for athlete in athlete_list %}",
        "{% for athlete in athlete_list"
    ],
    [
        "<li>Sorry, no athletes in this list.</li>",
        "<li>Sorry, no athletes in"
    ],
    [
        "The above is equivalent to -- but shorter, cleaner, and possibly faster",
        "The above is equivalent to -- but shorter,"
    ],
    [
        "{% for athlete in athlete_list %}",
        "{% for athlete in athlete_list"
    ],
    [
        "<li>Sorry, no athletes in this list.</li>",
        "<li>Sorry, no athletes in this"
    ],
    [
        "The for loop sets a number of variables available within the loop:",
        "The for loop sets a number of variables available within"
    ],
    [
        "``forloop.revcounter``      The number of iterations from the end of the",
        "``forloop.revcounter`` The number of iterations from the end"
    ],
    [
        "``forloop.first``           True if this is the first time through the loop",
        "``forloop.first`` True if this is the first"
    ],
    [
        "``forloop.last``            True if this is the last time through the loop",
        "``forloop.last`` True if this is the last time through the"
    ],
    [
        "``forloop.parentloop``      For nested loops, this is the loop \"above\" the",
        "``forloop.parentloop`` For nested loops, this is the loop \"above\""
    ],
    [
        "\"'for' statements should have at least four words: %s\" % token.contents",
        "\"'for' statements should have at least four words: %s\""
    ],
    [
        "\"'for' statements should use the format\"",
        "\"'for' statements should use the"
    ],
    [
        "\" 'for x in y': %s\" % token.contents",
        "\" 'for x in y': %s\" %"
    ],
    [
        "invalid_chars = frozenset((\" \", '\"', \"'\", FILTER_SEPARATOR))",
        "invalid_chars = frozenset((\" \","
    ],
    [
        "if not var or not invalid_chars.isdisjoint(var):",
        "if not var or not"
    ],
    [
        "\"'for' tag received an invalid argument: %s\" % token.contents",
        "\"'for' tag received an invalid argument: %s\""
    ],
    [
        "return ForNode(loopvars, sequence, is_reversed, nodelist_loop, nodelist_empty)",
        "return ForNode(loopvars, sequence, is_reversed,"
    ],
    [
        "Evaluate a variable, and if that variable is \"true\" (i.e., exists, is not",
        "Evaluate a variable, and if that variable is \"true\""
    ],
    [
        "empty, and is not a false boolean value), output the contents of the block:",
        "empty, and is not a false boolean value), output the contents of the"
    ],
    [
        "Number of athletes: {{ athlete_list|count }}",
        "Number of athletes:"
    ],
    [
        "Athletes should be out of the locker room soon!",
        "Athletes should be out of the"
    ],
    [
        "In the above, if ``athlete_list`` is not empty, the number of athletes will",
        "In the above, if ``athlete_list`` is not empty, the number of"
    ],
    [
        "be displayed by the ``{{ athlete_list|count }}`` variable.",
        "be displayed by the ``{{ athlete_list|count"
    ],
    [
        "The ``if`` tag may take one or several `` {% elif %}`` clauses, as well as",
        "The ``if`` tag may take one or several `` {%"
    ],
    [
        "an ``{% else %}`` clause that will be displayed if all previous conditions",
        "an ``{% else %}`` clause that will"
    ],
    [
        "``if`` tags may use ``or``, ``and`` or ``not`` to test a number of",
        "``if`` tags may use ``or``, ``and`` or ``not`` to test a number"
    ],
    [
        "variables or to negate a given variable::",
        "variables or to negate"
    ],
    [
        "{% if athlete_list or coach_list %}",
        "{% if athlete_list or"
    ],
    [
        "There are some athletes or some coaches.",
        "There are some athletes"
    ],
    [
        "{% if athlete_list and coach_list %}",
        "{% if athlete_list"
    ],
    [
        "Both athletes and coaches are available.",
        "Both athletes and"
    ],
    [
        "{% if not athlete_list or coach_list %}",
        "{% if not athlete_list or coach_list"
    ],
    [
        "There are no athletes, or there are some coaches.",
        "There are no athletes, or there"
    ],
    [
        "{% if athlete_list and not coach_list %}",
        "{% if athlete_list and"
    ],
    [
        "There are some athletes and absolutely no coaches.",
        "There are some athletes and"
    ],
    [
        "Comparison operators are also available, and the use of filters is also",
        "Comparison operators are also available, and the use of"
    ],
    [
        "Arguments and operators _must_ have a space between them, so",
        "Arguments and operators _must_ have a space between them,"
    ],
    [
        "All supported operators are: ``or``, ``and``, ``in``, ``not in``",
        "All supported operators are: ``or``, ``and``,"
    ],
    [
        "``==``, ``!=``, ``>``, ``>=``, ``<`` and ``<=``.",
        "``==``, ``!=``, ``>``, ``>=``,"
    ],
    [
        "'Malformed template tag at line {}: \"{}\"'.format(",
        "'Malformed template tag at"
    ],
    [
        "Check if a value has changed from the last iteration of a loop.",
        "Check if a value has changed from the"
    ],
    [
        "The ``{% ifchanged %}`` block tag is used within a loop. It has two",
        "The ``{% ifchanged %}`` block tag is used within"
    ],
    [
        "displays the content if it has changed. For example, this displays a",
        "displays the content if it has changed. For"
    ],
    [
        "list of days, only displaying the month if it changes::",
        "list of days, only displaying the"
    ],
    [
        "{% for date in days %}",
        "{% for date in"
    ],
    [
        "<a href=\"{{ date|date:\"M/d\"|lower }}/\">{{ date|date:\"j\" }}</a>",
        "<a href=\"{{ date|date:\"M/d\"|lower }}/\">{{ date|date:\"j\""
    ],
    [
        "For example, the following shows the date every time it changes, while",
        "For example, the following shows the"
    ],
    [
        "showing the hour if either the hour or the date has changed::",
        "showing the hour if either the hour or"
    ],
    [
        "{% for date in days %}",
        "{% for date"
    ],
    [
        "{% ifchanged date.date %} {{ date.date }} {% endifchanged %}",
        "{% ifchanged date.date %} {{ date.date }} {% endifchanged"
    ],
    [
        "\"'%s' is not a registered tag library. Must be one of:\\n%s\"",
        "\"'%s' is not a registered tag library. Must be one"
    ],
    [
        "Return a subset of tags and filters from a library.",
        "Return a subset of tags and"
    ],
    [
        "\"'%s' is not a valid tag or filter in tag library '%s'\"",
        "\"'%s' is not a valid tag or filter in tag"
    ],
    [
        "Load a custom template tag library into the parser.",
        "Load a custom template tag library into"
    ],
    [
        "For example, to load the template tags in",
        "For example, to load the template tags"
    ],
    [
        "Can also be used to load an individual tag/filter from",
        "Can also be used to load an"
    ],
    [
        "{% load byline from news %}",
        "{% load byline"
    ],
    [
        "Create random Latin text useful for providing test data in templates.",
        "Create random Latin text useful for providing test"
    ],
    [
        "{% lorem [count] [method] [random] %}",
        "{% lorem [count] [method]"
    ],
    [
        "``count`` is a number (or variable) containing the number of paragraphs or",
        "``count`` is a number (or variable) containing"
    ],
    [
        "``method`` is either ``w`` for words, ``p`` for HTML paragraphs, ``b`` for",
        "``method`` is either ``w`` for words,"
    ],
    [
        "plain-text paragraph blocks (default is ``b``).",
        "plain-text paragraph blocks (default"
    ],
    [
        "``random`` is the word ``random``, which if given, does not use the common",
        "``random`` is the word ``random``, which if"
    ],
    [
        "paragraph (starting \"Lorem ipsum dolor sit amet, consectetuer...\").",
        "paragraph (starting \"Lorem ipsum dolor sit"
    ],
    [
        "* ``{% lorem %}`` outputs the common \"lorem ipsum\" paragraph",
        "* ``{% lorem %}`` outputs the common"
    ],
    [
        "and two random paragraphs each wrapped in HTML ``<p>`` tags",
        "and two random paragraphs each"
    ],
    [
        "raise TemplateSyntaxError(\"Incorrect format for %r tag\" % tagname)",
        "raise TemplateSyntaxError(\"Incorrect format for"
    ],
    [
        "Display the date, formatted according to the given string.",
        "Display the date, formatted according to the given"
    ],
    [
        "Use the same format as PHP's ``date()`` function; see https://php.net/date",
        "Use the same format as PHP's ``date()`` function;"
    ],
    [
        "It is {% now \"jS F Y H:i\" %}",
        "It is {% now \"jS F"
    ],
    [
        "raise TemplateSyntaxError(\"'now' statement takes one argument\")",
        "raise TemplateSyntaxError(\"'now' statement"
    ],
    [
        "Add, remove, and change parameters of a ``QueryDict`` and return the result",
        "Add, remove, and change parameters of a ``QueryDict`` and return"
    ],
    [
        "as a query string. If the ``query_dict`` argument is not provided, default",
        "as a query string. If the ``query_dict``"
    ],
    [
        "A custom ``QueryDict`` can also be used::",
        "A custom ``QueryDict`` can also be"
    ],
    [
        "elif isinstance(value, Iterable) and not isinstance(value, str):",
        "elif isinstance(value, Iterable) and not"
    ],
    [
        "if not params and not query_dict:",
        "if not params and not"
    ],
    [
        "Regroup a list of alike objects by a common attribute.",
        "Regroup a list of alike objects by"
    ],
    [
        "This complex tag is best illustrated by use of an example: say that",
        "This complex tag is best illustrated by use of an example: say"
    ],
    [
        "``musicians`` is a list of ``Musician`` objects that have ``name`` and",
        "``musicians`` is a list of ``Musician`` objects"
    ],
    [
        "``instrument`` attributes, and you'd like to display a list that",
        "``instrument`` attributes, and you'd like"
    ],
    [
        "The following snippet of template code would accomplish this dubious task::",
        "The following snippet of template code would accomplish"
    ],
    [
        "{% regroup musicians by instrument as grouped %}",
        "{% regroup musicians by instrument as"
    ],
    [
        "{% for group in grouped %}",
        "{% for group in grouped"
    ],
    [
        "{% for musician in group.list %}",
        "{% for musician in"
    ],
    [
        "As you can see, ``{% regroup %}`` populates a variable with a list of",
        "As you can see, ``{% regroup %}`` populates a"
    ],
    [
        "objects with ``grouper`` and ``list`` attributes. ``grouper`` contains the",
        "objects with ``grouper`` and ``list`` attributes. ``grouper`` contains"
    ],
    [
        "item that was grouped by; ``list`` contains the list of objects that share",
        "item that was grouped by; ``list`` contains the list of objects"
    ],
    [
        "that ``grouper``. In this case, ``grouper`` would be ``Guitar``, ``Piano``",
        "that ``grouper``. In this case, ``grouper`` would be ``Guitar``,"
    ],
    [
        "and ``Trumpet``, and ``list`` is the list of musicians who play this",
        "and ``Trumpet``, and ``list`` is the"
    ],
    [
        "Note that ``{% regroup %}`` does not work when the list to be grouped is not",
        "Note that ``{% regroup %}`` does not work when"
    ],
    [
        "sorted by the key you are grouping by! This means that if your list of",
        "sorted by the key you are grouping by! This means that if your"
    ],
    [
        "musicians was not sorted by instrument, you'd need to make sure it is sorted",
        "musicians was not sorted by instrument, you'd need"
    ],
    [
        "{% regroup musicians|dictsort:\"instrument\" by instrument as grouped %}",
        "{% regroup musicians|dictsort:\"instrument\" by instrument as grouped"
    ],
    [
        "raise TemplateSyntaxError(\"'regroup' tag takes five arguments\")",
        "raise TemplateSyntaxError(\"'regroup' tag takes five"
    ],
    [
        "raise TemplateSyntaxError(\"second argument to 'regroup' tag must be 'by'\")",
        "raise TemplateSyntaxError(\"second argument to 'regroup' tag must be"
    ],
    [
        "raise TemplateSyntaxError(\"next-to-last argument to 'regroup' tag must be 'as'\")",
        "raise TemplateSyntaxError(\"next-to-last argument to 'regroup' tag must"
    ],
    [
        "If an argument is given, reset the last rendered cycle tag whose name",
        "If an argument is given, reset the last rendered"
    ],
    [
        "matches the argument, else reset the last rendered cycle tag (named or",
        "matches the argument, else reset the"
    ],
    [
        "raise TemplateSyntaxError(\"Named cycle '%s' does not exist.\" % name)",
        "raise TemplateSyntaxError(\"Named cycle '%s' does not exist.\" %"
    ],
    [
        "Remove whitespace between HTML tags, including tab and newline characters.",
        "Remove whitespace between HTML tags, including"
    ],
    [
        "Only space between *tags* is normalized -- not space between tags and text.",
        "Only space between *tags* is normalized -- not space between"
    ],
    [
        "In this example, the space around ``Hello`` isn't stripped::",
        "In this example, the space around ``Hello``"
    ],
    [
        "Output one of the bits used to compose template tags.",
        "Output one of the bits"
    ],
    [
        "Since the template system has no concept of \"escaping\", to display one of",
        "Since the template system has no concept of \"escaping\","
    ],
    [
        "the bits used in template tags, you must use the ``{% templatetag %}`` tag.",
        "the bits used in template tags, you must"
    ],
    [
        "The argument tells which template bit to output:",
        "The argument tells which"
    ],
    [
        "raise TemplateSyntaxError(\"'templatetag' statement takes one argument\")",
        "raise TemplateSyntaxError(\"'templatetag' statement takes"
    ],
    [
        "\" Must be one of: %s\" % (tag, list(TemplateTagNode.mapping))",
        "\" Must be one of: %s\" % (tag,"
    ],
    [
        "Return an absolute URL matching the given view with its parameters.",
        "Return an absolute URL matching the given view"
    ],
    [
        "This is a way to define links that aren't tied to a particular URL",
        "This is a way to define links"
    ],
    [
        "The first argument is a URL pattern name. Other arguments are",
        "The first argument is a URL"
    ],
    [
        "space-separated values that will be filled in place of positional and",
        "space-separated values that will be filled in place"
    ],
    [
        "keyword arguments in the URL. Don't mix positional and keyword arguments.",
        "keyword arguments in the URL. Don't mix positional and keyword"
    ],
    [
        "All arguments for the URL must be present.",
        "All arguments for the URL must be"
    ],
    [
        "For example, if you have a view ``app_name.views.client_details`` taking",
        "For example, if you have a"
    ],
    [
        "the client's id and the corresponding line in a URLconf looks like this::",
        "the client's id and the corresponding line in a URLconf looks"
    ],
    [
        "and this app's URLconf is included into the project's URLconf under some",
        "and this app's URLconf is included into the project's"
    ],
    [
        "then in a template you can create a link for a certain client like this::",
        "then in a template you can create a link for a certain client"
    ],
    [
        "The first argument may also be the name of a template variable that will be",
        "The first argument may also be the name"
    ],
    [
        "evaluated to obtain the view name or the URL name, e.g.::",
        "evaluated to obtain the view name or the"
    ],
    [
        "raise TemplateSyntaxError(\"Malformed arguments to url tag\")",
        "raise TemplateSyntaxError(\"Malformed arguments"
    ],
    [
        "Stop the template engine from rendering the contents of this block tag.",
        "Stop the template engine from rendering the contents of this"
    ],
    [
        "You can also designate a specific closing tag block (allowing the",
        "You can also designate a specific closing"
    ],
    [
        "unrendered use of ``{% endverbatim %}``)::",
        "unrendered use of ``{%"
    ],
    [
        "For creating bar charts and such. Calculate the ratio of a given value to a",
        "For creating bar charts and such. Calculate the ratio of a given"
    ],
    [
        "maximum value, and then apply that ratio to a constant.",
        "maximum value, and then apply that ratio to"
    ],
    [
        "In some cases you might want to capture the result of widthratio in a",
        "In some cases you might want to capture the result"
    ],
    [
        "variable. It can be useful for instance in a blocktranslate like this::",
        "variable. It can be useful for instance"
    ],
    [
        "{% widthratio this_value max_value max_width as width %}",
        "{% widthratio this_value max_value max_width"
    ],
    [
        "{% blocktranslate %}The width is: {{ width }}{% endblocktranslate %}",
        "{% blocktranslate %}The width is: {{"
    ],
    [
        "tag, this_value_expr, max_value_expr, max_width = bits",
        "tag, this_value_expr, max_value_expr,"
    ],
    [
        "tag, this_value_expr, max_value_expr, max_width, as_, asvar = bits",
        "tag, this_value_expr, max_value_expr, max_width, as_,"
    ],
    [
        "\"Invalid syntax in widthratio tag. Expecting 'as' keyword\"",
        "\"Invalid syntax in widthratio"
    ],
    [
        "raise TemplateSyntaxError(\"widthratio takes at least three arguments\")",
        "raise TemplateSyntaxError(\"widthratio takes at least"
    ],
    [
        "Add one or more values to the context (inside of this block) for caching",
        "Add one or more values to the context (inside of"
    ],
    [
        "{{ total }} object{{ total|pluralize }}",
        "{{ total }} object{{"
    ],
    [
        "Multiple values can be added to the context::",
        "Multiple values can be"
    ],
    [
        "The legacy format of ``{% with person.some_sql_method as total %}`` is",
        "The legacy format of ``{% with person.some_sql_method as total %}``"
    ],
    [
        "\"'string_if_invalid' in TEMPLATES OPTIONS must be a string but \"",
        "\"'string_if_invalid' in TEMPLATES OPTIONS must be a"
    ],
    [
        "\"got: %r (%s).\" % (value, type(value)),",
        "\"got: %r (%s).\" % (value,"
    ],
    [
        "items = \", \".join(repr(item) for item in sorted(items))",
        "items = \", \".join(repr(item)"
    ],
    [
        "f\"{library_name!r} is used for multiple template tag modules: \"",
        "f\"{library_name!r} is used for multiple template tag modules:"
    ],
    [
        "Return a collation of template tag libraries from installed",
        "Return a collation of template"
    ],
    [
        "applications and the supplied custom_libraries argument.",
        "applications and the"
    ],
    [
        "Create a new TemplateDoesNotExist. Preserve its declared attributes and",
        "Create a new TemplateDoesNotExist. Preserve"
    ],
    [
        "template debug data but discard __traceback__, __context__, and __cause__",
        "template debug data but discard __traceback__, __context__, and"
    ],
    [
        "to make this object suitable for keeping around (in a cache, for example).",
        "to make this object suitable for keeping around (in"
    ],
    [
        "new = exc.__class__(*exc.args, tried=exc.tried, backend=backend, chain=exc.chain)",
        "new = exc.__class__(*exc.args, tried=exc.tried,"
    ],
    [
        "Reraise TemplateDoesNotExist while maintaining template debug information.",
        "Reraise TemplateDoesNotExist while maintaining"
    ],
    [
        "Yield (module_name, module_path) pairs for all installed template tag",
        "Yield (module_name, module_path) pairs for all installed template"
    ],
    [
        "Return the built-in template tag libraries and those from installed",
        "Return the built-in template tag libraries and those"
    ],
    [
        "applications. Libraries are stored in a dictionary where keys are the",
        "applications. Libraries are stored in a dictionary where keys are"
    ],
    [
        "individual module names, not the full module paths. Example:",
        "individual module names, not the full module paths."
    ],
    [
        "module_name: full_name for module_name, full_name in get_template_tag_modules()",
        "module_name: full_name for module_name,"
    ],
    [
        "Recursively yield template tag libraries defined in submodules of a",
        "Recursively yield template tag libraries defined in"
    ],
    [
        "for entry in walk_packages(pkg.__path__, pkg.__name__ + \".\"):",
        "for entry in walk_packages(pkg.__path__,"
    ],
    [
        "\"Invalid template library specified. ImportError raised when \"",
        "\"Invalid template library specified. ImportError"
    ],
    [
        "return [import_string(path) for path in self.context_processors]",
        "return [import_string(path) for path"
    ],
    [
        "A container to hold debug information as described in the template API",
        "A container to hold debug information as"
    ],
    [
        "Format exception information for display on the debug page using the",
        "Format exception information for display on the debug page"
    ],
    [
        "structure described in the template API documentation.",
        "structure described in the template API"
    ],
    [
        "bottom = min(total, lineno + context_lines)",
        "bottom = min(total,"
    ],
    [
        "context = {k: conditional_escape(v) for k, v in context.items()}",
        "context = {k: conditional_escape(v) for k, v"
    ],
    [
        "`params` is a dict of configuration settings.",
        "`params` is a dict"
    ],
    [
        "\"{} doesn't support loading templates from installed \"",
        "\"{} doesn't support loading templates from installed"
    ],
    [
        "Create and return a template for the given source code.",
        "Create and return a template for the"
    ],
    [
        "\"subclasses of BaseEngine should provide a from_string() method\"",
        "\"subclasses of BaseEngine should provide a"
    ],
    [
        "Load and return a template for the given name.",
        "Load and return a template for the given"
    ],
    [
        "Raise TemplateDoesNotExist if no such template exists.",
        "Raise TemplateDoesNotExist if no such"
    ],
    [
        "\"subclasses of BaseEngine must provide a get_template() method\"",
        "\"subclasses of BaseEngine must provide a get_template()"
    ],
    [
        "Return a list of directories to search for templates.",
        "Return a list of directories to"
    ],
    [
        "Iterate over candidate files for template_name.",
        "Iterate over candidate files for"
    ],
    [
        "Ignore files that don't lie inside configured template dirs to avoid",
        "Ignore files that don't lie inside"
    ],
    [
        "Wrapper for loading templates from the filesystem.",
        "Wrapper for loading templates"
    ],
    [
        "from .base import Loader as BaseLoader",
        "from .base import"
    ],
    [
        "return self.dirs if self.dirs is not None else self.engine.dirs",
        "return self.dirs if self.dirs is not None else"
    ],
    [
        "Return an Origin object pointing to an absolute path in each directory",
        "Return an Origin object pointing to an absolute path in each"
    ],
    [
        "in template_dirs. For security reasons, if a path doesn't lie inside",
        "in template_dirs. For security reasons, if a path doesn't lie"
    ],
    [
        "one of the template_dirs it is excluded from the result set.",
        "one of the template_dirs it is excluded"
    ],
    [
        "Wrapper class that takes a list of template loaders as an argument and attempts",
        "Wrapper class that takes a list of template loaders as an argument and"
    ],
    [
        "to load templates from them in order, caching the result.",
        "to load templates from them in"
    ],
    [
        "from .base import Loader as BaseLoader",
        "from .base import Loader"
    ],
    [
        "Perform the caching that gives this loader its name. Often many of the",
        "Perform the caching that gives this loader its name. Often"
    ],
    [
        "templates attempted will be missing, so memory use is of concern here.",
        "templates attempted will be missing, so memory use"
    ],
    [
        "To keep it in check, caching behavior is a little complicated when a",
        "To keep it in check, caching behavior is"
    ],
    [
        "With template debugging disabled, cache the TemplateDoesNotExist class",
        "With template debugging disabled, cache the"
    ],
    [
        "for every missing template and raise a new instance of it after",
        "for every missing template and raise"
    ],
    [
        "With template debugging enabled, a unique TemplateDoesNotExist object",
        "With template debugging enabled, a"
    ],
    [
        "is cached for each missing template to preserve debug data. When",
        "is cached for each missing template to preserve debug"
    ],
    [
        "raising an exception, Python sets __traceback__, __context__, and",
        "raising an exception, Python"
    ],
    [
        "__cause__ attributes on it. Those attributes can contain references to",
        "__cause__ attributes on it. Those attributes can"
    ],
    [
        "all sorts of objects up the call chain and caching them creates a",
        "all sorts of objects up the call chain and caching them"
    ],
    [
        "memory leak. Thus, unraised copies of the exceptions are cached and",
        "memory leak. Thus, unraised copies of"
    ],
    [
        "copies of those copies are raised after they're fetched from the cache.",
        "copies of those copies are raised after they're fetched"
    ],
    [
        "if isinstance(cached, type) and issubclass(cached, TemplateDoesNotExist):",
        "if isinstance(cached, type) and issubclass(cached,"
    ],
    [
        "Generate a cache key for the template name and skip.",
        "Generate a cache key for the template name"
    ],
    [
        "If skip is provided, only origins that match template_name are included",
        "If skip is provided, only origins that match"
    ],
    [
        "in the cache key. This ensures each template is only parsed and cached",
        "in the cache key. This ensures each template is"
    ],
    [
        "once if contained in different extend chains like:",
        "once if contained in different extend"
    ],
    [
        "origin.name for origin in skip if origin.template_name == template_name",
        "origin.name for origin in skip if origin.template_name =="
    ],
    [
        "return \"-\".join(s for s in (str(template_name), skip_prefix) if s)",
        "return \"-\".join(s for s in (str(template_name),"
    ],
    [
        "Wrapper for loading templates from \"templates\" directories in INSTALLED_APPS",
        "Wrapper for loading templates from"
    ],
    [
        "from .filesystem import Loader as FilesystemLoader",
        "from .filesystem import Loader"
    ],
    [
        "Call self.get_template_sources() and return a Template object for",
        "Call self.get_template_sources() and return a Template object"
    ],
    [
        "the first template matching template_name. If skip is provided, ignore",
        "the first template matching template_name. If skip is"
    ],
    [
        "template origins in skip. This is used to avoid recursion during",
        "template origins in skip. This is"
    ],
    [
        "if skip is not None and origin in skip:",
        "if skip is not None and"
    ],
    [
        "An iterator that yields possible matching template paths for a",
        "An iterator that yields possible matching"
    ],
    [
        "\"subclasses of Loader must provide a get_template_sources() method\"",
        "\"subclasses of Loader must provide a"
    ],
    [
        "Reset any state maintained by the loader instance (e.g. cached",
        "Reset any state maintained by"
    ],
    [
        "Wrapper for loading templates from a plain Python dict.",
        "Wrapper for loading templates from"
    ],
    [
        "from .base import Loader as BaseLoader",
        "from .base import Loader as"
    ],
    [
        "from os.path import abspath, dirname, join, normcase, sep",
        "from os.path import abspath,"
    ],
    [
        "Join one or more path components to the base path component intelligently.",
        "Join one or more path components to the base path"
    ],
    [
        "Return a normalized, absolute version of the final path.",
        "Return a normalized, absolute version of the final"
    ],
    [
        "Raise SuspiciousFileOperation if the final path isn't located inside of the",
        "Raise SuspiciousFileOperation if the final path isn't located inside of"
    ],
    [
        "\"The joined path ({}) is located outside of the base path \"",
        "\"The joined path ({}) is located outside of the base"
    ],
    [
        "Return whether or not creating symlinks are supported in the host platform",
        "Return whether or not creating symlinks are supported in"
    ],
    [
        "and/or if they are allowed to be created (e.g. on Windows it requires admin",
        "and/or if they are allowed to be created"
    ],
    [
        "\"\"\"Convert value to a pathlib.Path instance, if not already a Path.\"\"\"",
        "\"\"\"Convert value to a pathlib.Path instance, if not already a"
    ],
    [
        "raise TypeError(\"Invalid path type: %s\" % type(value).__name__)",
        "raise TypeError(\"Invalid path type: %s\" %"
    ],
    [
        "color_names = (\"black\", \"red\", \"green\", \"yellow\", \"blue\", \"magenta\", \"cyan\", \"white\")",
        "color_names = (\"black\", \"red\", \"green\","
    ],
    [
        "Return your text, enclosed in ANSI graphics codes.",
        "Return your text, enclosed in ANSI"
    ],
    [
        "Depends on the keyword arguments 'fg' and 'bg', and the contents of",
        "Depends on the keyword arguments 'fg' and 'bg',"
    ],
    [
        "Return the RESET code if no parameters are given.",
        "Return the RESET code if no parameters"
    ],
    [
        "'black', 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white'",
        "'black', 'red', 'green', 'yellow', 'blue',"
    ],
    [
        "'noreset' - string will not be auto-terminated with the RESET code",
        "'noreset' - string will not be auto-terminated with"
    ],
    [
        "Return a function with default parameters for colorize()",
        "Return a function with default"
    ],
    [
        "return lambda text: colorize(text, opts, **kwargs)",
        "return lambda text:"
    ],
    [
        "\"\"\"Parse a DJANGO_COLORS environment variable to produce the system palette",
        "\"\"\"Parse a DJANGO_COLORS environment variable to produce"
    ],
    [
        "The general form of a palette definition is:",
        "The general form of a"
    ],
    [
        "palette is a named palette; one of 'light', 'dark', or 'nocolor'.",
        "palette is a named palette; one of 'light', 'dark', or"
    ],
    [
        "role is a named style used by Django",
        "role is a named style"
    ],
    [
        "Specifying a named palette is the same as manually specifying the individual",
        "Specifying a named palette is the same as manually specifying"
    ],
    [
        "definitions for each role. Any individual definitions following the palette",
        "definitions for each role. Any individual definitions"
    ],
    [
        "definition will augment the base palette definition.",
        "definition will augment the base palette"
    ],
    [
        "'error', 'success', 'warning', 'notice', 'sql_field', 'sql_coltype',",
        "'error', 'success', 'warning', 'notice',"
    ],
    [
        "'black', 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white'",
        "'black', 'red', 'green', 'yellow', 'blue',"
    ],
    [
        "'bold', 'underscore', 'blink', 'reverse', 'conceal', 'noreset'",
        "'bold', 'underscore', 'blink', 'reverse', 'conceal',"
    ],
    [
        "opts = tuple(s for s in styles if s in opt_dict)",
        "opts = tuple(s for s in"
    ],
    [
        "if role in PALETTES[NOCOLOR_PALETTE] and definition:",
        "if role in PALETTES[NOCOLOR_PALETTE]"
    ],
    [
        "A class for storing a tree graph. Primarily used for filter constructs in the",
        "A class for storing a tree graph. Primarily"
    ],
    [
        "A single internal node in the tree graph. A Node should be viewed as a",
        "A single internal node in the tree graph. A Node should be viewed"
    ],
    [
        "connection (the root) with the children being either leaf nodes or other",
        "connection (the root) with the children being"
    ],
    [
        "\"\"\"Construct a new Node. If no connector is given, use the default.\"\"\"",
        "\"\"\"Construct a new Node. If no connector is given, use the"
    ],
    [
        "self.children = children[:] if children else []",
        "self.children = children[:] if"
    ],
    [
        "Create a new instance using Node() instead of __init__() as some",
        "Create a new instance using Node()"
    ],
    [
        "subclasses, e.g. django.db.models.query_utils.Q, may implement a custom",
        "subclasses, e.g. django.db.models.query_utils.Q, may"
    ],
    [
        "__init__() with a signature that conflicts with the one defined in",
        "__init__() with a signature that conflicts with the"
    ],
    [
        "obj = Node(children, connector or cls.default, negated)",
        "obj = Node(children, connector"
    ],
    [
        "template = \"(NOT (%s: %s))\" if self.negated else \"(%s: %s)\"",
        "template = \"(NOT (%s: %s))\" if self.negated"
    ],
    [
        "return template % (self.connector, \", \".join(str(c) for c in self.children))",
        "return template % (self.connector, \","
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self)",
        "return \"<%s: %s>\" % (self.__class__.__name__,"
    ],
    [
        "\"\"\"Return the number of children this node has.\"\"\"",
        "\"\"\"Return the number of children this node"
    ],
    [
        "\"\"\"Return whether or not this node has children.\"\"\"",
        "\"\"\"Return whether or not this node has"
    ],
    [
        "\"\"\"Return True if 'other' is a direct child of this instance.\"\"\"",
        "\"\"\"Return True if 'other' is a direct"
    ],
    [
        "Combine this tree and the data represented by data using the",
        "Combine this tree and the data represented by"
    ],
    [
        "connector conn_type. The combine is done by squashing the node other",
        "connector conn_type. The combine is done by squashing"
    ],
    [
        "This tree (self) will never be pushed to a child node of the",
        "This tree (self) will never be pushed"
    ],
    [
        "combined tree, nor will the connector or negated properties change.",
        "combined tree, nor will the connector or"
    ],
    [
        "Return a node which can be used in place of data regardless if the",
        "Return a node which can be used in place of data regardless if"
    ],
    [
        "node other got squashed or not.",
        "node other got squashed"
    ],
    [
        "\"\"\"Negate the sense of the root connector.\"\"\"",
        "\"\"\"Negate the sense of the root"
    ],
    [
        "Attempt to make value hashable or raise a TypeError if it fails.",
        "Attempt to make value hashable or raise a TypeError if"
    ],
    [
        "The returned value should generate the same hash for equal values.",
        "The returned value should generate the same hash for"
    ],
    [
        "mapping = {\"alpha\": \"a\", \"beta\": \"b\", \"rc\": \"rc\"}",
        "mapping = {\"alpha\": \"a\", \"beta\": \"b\","
    ],
    [
        "\"\"\"Return main version (X.Y[.Z]) from VERSION.\"\"\"",
        "\"\"\"Return main version (X.Y[.Z])"
    ],
    [
        "return \".\".join(str(x) for x in version[:parts])",
        "return \".\".join(str(x) for x"
    ],
    [
        "Return a tuple of the django version. If version argument is non-empty,",
        "Return a tuple of the django version. If"
    ],
    [
        "check for correctness of the tuple provided.",
        "check for correctness of"
    ],
    [
        "from django import VERSION as version",
        "from django import"
    ],
    [
        "\"\"\"Return a numeric identifier of the latest git changeset.",
        "\"\"\"Return a numeric identifier of the"
    ],
    [
        "The result is the UTC timestamp of the changeset in YYYYMMDDHHMMSS format.",
        "The result is the UTC timestamp of the changeset in"
    ],
    [
        "This value isn't guaranteed to be unique, but collisions are very unlikely,",
        "This value isn't guaranteed to be"
    ],
    [
        "so it's sufficient for generating the development version numbers.",
        "so it's sufficient for generating the development version"
    ],
    [
        "if item and item != \".\":",
        "if item and item"
    ],
    [
        "return \"%s. You passed in %r (%s)\" % (",
        "return \"%s. You passed in %r"
    ],
    [
        "Return a string representing 's'. Treat bytestrings using the 'encoding'",
        "Return a string representing 's'. Treat bytestrings using the"
    ],
    [
        "If strings_only is True, don't convert (some) non-string-like objects.",
        "If strings_only is True, don't convert (some)"
    ],
    [
        "\"\"\"Determine if the object instance is of a protected type.",
        "\"\"\"Determine if the object instance is"
    ],
    [
        "Objects of protected types are preserved as-is when passed to",
        "Objects of protected types are preserved as-is"
    ],
    [
        "Similar to smart_str(), except that lazy instances are resolved to",
        "Similar to smart_str(), except that lazy instances are"
    ],
    [
        "strings, rather than kept as lazy objects.",
        "strings, rather than kept as"
    ],
    [
        "If strings_only is True, don't convert (some) non-string-like objects.",
        "If strings_only is True, don't convert (some)"
    ],
    [
        "Return a bytestring version of 's', encoded as specified in 'encoding'.",
        "Return a bytestring version of 's', encoded"
    ],
    [
        "If strings_only is True, don't convert (some) non-string-like objects.",
        "If strings_only is True, don't convert (some) non-string-like"
    ],
    [
        "Similar to smart_bytes, except that lazy instances are resolved to",
        "Similar to smart_bytes, except that lazy instances"
    ],
    [
        "strings, rather than kept as lazy objects.",
        "strings, rather than kept as lazy"
    ],
    [
        "If strings_only is True, don't convert (some) non-string-like objects.",
        "If strings_only is True, don't convert (some) non-string-like"
    ],
    [
        "Convert an Internationalized Resource Identifier (IRI) portion to a URI",
        "Convert an Internationalized Resource Identifier (IRI)"
    ],
    [
        "portion that is suitable for inclusion in a URL.",
        "portion that is suitable for inclusion in"
    ],
    [
        "the input is assumed to be a string rather than an arbitrary byte stream.",
        "the input is assumed to be a string rather than"
    ],
    [
        "Convert a Uniform Resource Identifier(URI) into an Internationalized",
        "Convert a Uniform Resource Identifier(URI)"
    ],
    [
        "Escape the unsafe characters from the path portion of a Uniform Resource",
        "Escape the unsafe characters from the path portion of"
    ],
    [
        "\"\"\"Return the Punycode of the given domain if it's non-ASCII.\"\"\"",
        "\"\"\"Return the Punycode of the given domain if it's"
    ],
    [
        "repercent-encode any octet produced that is not part of a strictly legal",
        "repercent-encode any octet produced that is not"
    ],
    [
        "\"\"\"Convert a file system path to a URI portion that is suitable for",
        "\"\"\"Convert a file system path to a URI portion that is suitable"
    ],
    [
        "Encode certain chars that would normally be recognized as special chars",
        "Encode certain chars that would normally be recognized"
    ],
    [
        "for URIs. Do not encode the ' character, as it is a valid character",
        "for URIs. Do not encode the ' character, as it is a valid"
    ],
    [
        "within URIs. See the encodeURIComponent() JavaScript function for details.",
        "within URIs. See the encodeURIComponent() JavaScript function"
    ],
    [
        "The encoding for the character type functions. Fallback to 'ascii' if the",
        "The encoding for the character type functions. Fallback to 'ascii' if"
    ],
    [
        "\"\"\"An exception log handler that emails log entries to site admins.",
        "\"\"\"An exception log handler that emails"
    ],
    [
        "If the request is passed as the first argument to the log record,",
        "If the request is passed as the"
    ],
    [
        "request data will be provided in the email report.",
        "request data will be provided in the"
    ],
    [
        "subject = \"%s (%s IP): %s\" % (",
        "subject = \"%s (%s IP): %s\""
    ],
    [
        "subject = \"%s: %s\" % (record.levelname, record.getMessage())",
        "subject = \"%s: %s\""
    ],
    [
        "html_message = reporter.get_traceback_html() if self.include_html else None",
        "html_message = reporter.get_traceback_html() if self.include_html else"
    ],
    [
        "def send_mail(self, subject, message, *args, **kwargs):",
        "def send_mail(self, subject,"
    ],
    [
        "A logging filter that checks the return value of a given callable (which",
        "A logging filter that checks the return value of a given"
    ],
    [
        "takes the record-to-be-logged as its only parameter) to decide whether to",
        "takes the record-to-be-logged as its only parameter) to decide"
    ],
    [
        "if self.uses_server_time() and not hasattr(record, \"server_time\"):",
        "if self.uses_server_time() and not hasattr(record,"
    ],
    [
        "Log errors based on HttpResponse status.",
        "Log errors based on HttpResponse"
    ],
    [
        "is given as a keyword argument). The HttpResponse status_code and the",
        "is given as a keyword argument). The"
    ],
    [
        "request are passed to the logger's extra parameter.",
        "request are passed to the logger's extra"
    ],
    [
        "from asgiref.sync import iscoroutinefunction, markcoroutinefunction, sync_to_async",
        "from asgiref.sync import iscoroutinefunction,"
    ],
    [
        "\"`%s.%s` is deprecated, use `%s` instead.\"",
        "\"`%s.%s` is deprecated, use"
    ],
    [
        "Handles the deprecation paths when renaming a method.",
        "Handles the deprecation paths when renaming a"
    ],
    [
        "new_class = super().__new__(cls, name, bases, attrs)",
        "new_class = super().__new__(cls, name,"
    ],
    [
        "\"`%s.%s` method should be renamed `%s`.\"",
        "\"`%s.%s` method should be renamed"
    ],
    [
        "Async version of __call__ that is swapped in when an async request",
        "Async version of __call__ that is swapped"
    ],
    [
        "response = response or await self.get_response(request)",
        "response = response or await"
    ],
    [
        "\"year\": ngettext_lazy(\"%(num)d year\", \"%(num)d years\", \"num\"),",
        "\"year\": ngettext_lazy(\"%(num)d year\", \"%(num)d years\","
    ],
    [
        "\"month\": ngettext_lazy(\"%(num)d month\", \"%(num)d months\", \"num\"),",
        "\"month\": ngettext_lazy(\"%(num)d month\","
    ],
    [
        "\"week\": ngettext_lazy(\"%(num)d week\", \"%(num)d weeks\", \"num\"),",
        "\"week\": ngettext_lazy(\"%(num)d week\", \"%(num)d"
    ],
    [
        "\"day\": ngettext_lazy(\"%(num)d day\", \"%(num)d days\", \"num\"),",
        "\"day\": ngettext_lazy(\"%(num)d day\","
    ],
    [
        "\"hour\": ngettext_lazy(\"%(num)d hour\", \"%(num)d hours\", \"num\"),",
        "\"hour\": ngettext_lazy(\"%(num)d hour\", \"%(num)d"
    ],
    [
        "\"minute\": ngettext_lazy(\"%(num)d minute\", \"%(num)d minutes\", \"num\"),",
        "\"minute\": ngettext_lazy(\"%(num)d minute\", \"%(num)d"
    ],
    [
        "Take two datetime objects and return the time between d and now as a nicely",
        "Take two datetime objects and return the time between d and now"
    ],
    [
        "Units used are years, months, weeks, days, hours, and minutes.",
        "Units used are years, months, weeks, days, hours, and"
    ],
    [
        "The algorithm takes into account the varying duration of years and months.",
        "The algorithm takes into account the varying"
    ],
    [
        "Up to `depth` adjacent units will be displayed.  For example,",
        "Up to `depth` adjacent units will be displayed."
    ],
    [
        "`time_strings` is an optional dict of strings to replace the default",
        "`time_strings` is an optional dict of"
    ],
    [
        "`depth` is an optional integer to control the number of adjacent time",
        "`depth` is an optional integer to control the"
    ],
    [
        "Modified to improve results for years and months.",
        "Modified to improve results for years"
    ],
    [
        "if now and not isinstance(now, datetime.datetime):",
        "if now and not"
    ],
    [
        "now = datetime.datetime.now(d.tzinfo if is_aware(d) else None)",
        "now = datetime.datetime.now(d.tzinfo if"
    ],
    [
        "if d.day > now.day or (d.day == now.day and d.time() > now.time()):",
        "if d.day > now.day or (d.day == now.day and d.time()"
    ],
    [
        "while i < len(TIME_STRINGS_KEYS) and current_depth < depth:",
        "while i < len(TIME_STRINGS_KEYS) and current_depth"
    ],
    [
        "Like timesince, but return a string measuring the time until the given time.",
        "Like timesince, but return a string measuring the time until the given"
    ],
    [
        "return timesince(d, now, reversed=True, time_strings=time_strings, depth=depth)",
        "return timesince(d, now, reversed=True,"
    ],
    [
        "Get a number (as a number or string), and return it as a string,",
        "Get a number (as a number or"
    ],
    [
        "* decimal_sep: Decimal separator symbol (for example \".\")",
        "* decimal_sep: Decimal separator symbol (for"
    ],
    [
        "* decimal_pos: Number of decimal positions",
        "* decimal_pos: Number"
    ],
    [
        "* grouping: Number of digits in every group limited by thousand separator.",
        "* grouping: Number of digits in every group limited by thousand"
    ],
    [
        "For non-uniform digit grouping, it can be a sequence with the number",
        "For non-uniform digit grouping, it can be"
    ],
    [
        "of digit group sizes following the format used by the Python locale",
        "of digit group sizes following the format used by the"
    ],
    [
        "* thousand_sep: Thousand separator symbol (for example \",\")",
        "* thousand_sep: Thousand separator"
    ],
    [
        "if number is None or number == \"\":",
        "if number is None or"
    ],
    [
        "if isinstance(number, int) and not use_grouping and not decimal_pos:",
        "if isinstance(number, int) and not use_grouping and"
    ],
    [
        "if isinstance(number, float) and \"e\" in str(number).lower():",
        "if isinstance(number, float) and \"e\""
    ],
    [
        "dec_part = dec_part and decimal_sep + dec_part",
        "dec_part = dec_part and decimal_sep"
    ],
    [
        "if cnt and cnt == active_interval:",
        "if cnt and cnt"
    ],
    [
        "return sign + int_part + dec_part",
        "return sign + int_part +"
    ],
    [
        "Decorator to mark functions as async-unsafe. Someone trying to access",
        "Decorator to mark functions as async-unsafe."
    ],
    [
        "the function while in an async context will get an error message.",
        "the function while in an async context will get an"
    ],
    [
        "\"You cannot call this from an async context - use a thread or \"",
        "\"You cannot call this from an async context - use a thread"
    ],
    [
        "\"\"\"HTML utilities suitable for global use.\"\"\"",
        "\"\"\"HTML utilities suitable for global"
    ],
    [
        "from urllib.parse import parse_qsl, quote, unquote, urlencode, urlsplit, urlunsplit",
        "from urllib.parse import parse_qsl, quote, unquote,"
    ],
    [
        "from django.utils.functional import Promise, cached_property, keep_lazy, keep_lazy_text",
        "from django.utils.functional import Promise,"
    ],
    [
        "from django.utils.safestring import SafeData, SafeString, mark_safe",
        "from django.utils.safestring import SafeData,"
    ],
    [
        "Return the given text with ampersands, quotes and angle brackets encoded",
        "Return the given text with ampersands, quotes and"
    ],
    [
        "Always escape input, even if it's already escaped and marked as such.",
        "Always escape input, even if it's already escaped and"
    ],
    [
        "This may result in double-escaping. If this is a concern, use",
        "This may result in double-escaping. If this"
    ],
    [
        "\"\"\"Hex encode characters for use in JavaScript strings.\"\"\"",
        "\"\"\"Hex encode characters for use"
    ],
    [
        "Escape all the HTML/XML special characters with their unicode escapes, so",
        "Escape all the HTML/XML special characters with their unicode"
    ],
    [
        "value is safe to be output anywhere except for inside a tag attribute. Wrap",
        "value is safe to be output anywhere except for"
    ],
    [
        "the escaped JSON in a script tag.",
        "the escaped JSON in"
    ],
    [
        "json_str = json.dumps(value, cls=encoder or DjangoJSONEncoder).translate(",
        "json_str = json.dumps(value,"
    ],
    [
        "Similar to escape(), except that it doesn't operate on pre-escaped strings.",
        "Similar to escape(), except that it doesn't operate on"
    ],
    [
        "This function relies on the __html__ convention used both by Django's",
        "This function relies on the __html__ convention used both"
    ],
    [
        "SafeData class and by third-party libraries like markupsafe.",
        "SafeData class and by third-party libraries like"
    ],
    [
        "Similar to str.format, but pass all arguments through conditional_escape(),",
        "Similar to str.format, but pass all arguments through"
    ],
    [
        "and call mark_safe() on the result. This function should be used instead",
        "and call mark_safe() on the result. This"
    ],
    [
        "of str.format or % interpolation to build up small HTML fragments.",
        "of str.format or % interpolation to build"
    ],
    [
        "raise TypeError(\"args or kwargs must be provided.\")",
        "raise TypeError(\"args or kwargs"
    ],
    [
        "kwargs_safe = {k: conditional_escape(v) for (k, v) in kwargs.items()}",
        "kwargs_safe = {k: conditional_escape(v) for (k,"
    ],
    [
        "A wrapper of format_html, for the common case of a group of arguments that",
        "A wrapper of format_html, for the common case of a"
    ],
    [
        "need to be formatted using the same format string, and then joined using",
        "need to be formatted using the same format string, and"
    ],
    [
        "'sep'. 'sep' is also passed through conditional_escape.",
        "'sep'. 'sep' is also passed through"
    ],
    [
        "'args_generator' should be an iterator that returns the sequence of 'args'",
        "'args_generator' should be an iterator that"
    ],
    [
        "that will be passed to format_html.",
        "that will be"
    ],
    [
        "\"\"\"Convert newlines into <p> and <br>s.\"\"\"",
        "\"\"\"Convert newlines into <p> and"
    ],
    [
        "paras = [\"<p>%s</p>\" % escape(p).replace(\"\\n\", \"<br>\") for p in paras]",
        "paras = [\"<p>%s</p>\" % escape(p).replace(\"\\n\","
    ],
    [
        "paras = [\"<p>%s</p>\" % p.replace(\"\\n\", \"<br>\") for p in paras]",
        "paras = [\"<p>%s</p>\" % p.replace(\"\\n\", \"<br>\") for p in"
    ],
    [
        "Internal tag stripping utility used by strip_tags.",
        "Internal tag stripping utility used by"
    ],
    [
        "\"\"\"Return the given HTML with all tags stripped.\"\"\"",
        "\"\"\"Return the given HTML"
    ],
    [
        "while \"<\" in value and \">\" in value:",
        "while \"<\" in value and \">\" in"
    ],
    [
        "\"\"\"Return the given HTML with spaces between tags removed.\"\"\"",
        "\"\"\"Return the given HTML with spaces between tags"
    ],
    [
        "\"\"\"Quote a URL if it isn't already quoted.\"\"\"",
        "\"\"\"Quote a URL if it isn't"
    ],
    [
        "scheme, netloc, path, query, fragment = urlsplit(url)",
        "scheme, netloc, path, query, fragment ="
    ],
    [
        "return urlunsplit((scheme, netloc, path, query, fragment))",
        "return urlunsplit((scheme, netloc,"
    ],
    [
        "Convert any URLs in text into clickable links.",
        "Convert any URLs in text"
    ],
    [
        "Work on http://, https://, www. links, and also on links ending in one of",
        "Work on http://, https://, www. links, and"
    ],
    [
        "the original seven gTLDs (.com, .edu, .gov, .int, .mil, .net, and .org).",
        "the original seven gTLDs (.com, .edu,"
    ],
    [
        "Links can have trailing punctuation (periods, commas, close-parens) and",
        "Links can have trailing punctuation (periods, commas,"
    ],
    [
        "leading punctuation (opening parens) and it'll still do the right thing.",
        "leading punctuation (opening parens) and it'll still do the right"
    ],
    [
        "wrapping_punctuation = [(\"(\", \")\"), (\"[\", \"]\")]",
        "wrapping_punctuation = [(\"(\", \")\"),"
    ],
    [
        "def __call__(self, text, trim_url_limit=None, nofollow=False, autoescape=False):",
        "def __call__(self, text,"
    ],
    [
        "If trim_url_limit is not None, truncate the URLs in the link text",
        "If trim_url_limit is not None, truncate the URLs"
    ],
    [
        "If nofollow is True, give the links a rel=\"nofollow\" attribute.",
        "If nofollow is True, give the links"
    ],
    [
        "If autoescape is True, autoescape the link text and URLs.",
        "If autoescape is True, autoescape the link"
    ],
    [
        "if (urlized_word := local_cache.get(word)) is None:",
        "if (urlized_word := local_cache.get(word))"
    ],
    [
        "if \".\" in word or \"@\" in word or \":\" in word:",
        "if \".\" in word or \"@\""
    ],
    [
        "nofollow_attr = ' rel=\"nofollow\"' if nofollow else \"\"",
        "nofollow_attr = ' rel=\"nofollow\"' if nofollow else"
    ],
    [
        "if len(middle) <= MAX_URL_LENGTH and self.simple_url_re.match(middle):",
        "if len(middle) <= MAX_URL_LENGTH and"
    ],
    [
        "elif \":\" not in middle and self.is_email_simple(middle):",
        "elif \":\" not in middle"
    ],
    [
        "if limit is None or len(x) <= limit:",
        "if limit is None or len(x)"
    ],
    [
        "Trim trailing and wrapping punctuation from `word`. Return the items of",
        "Trim trailing and wrapping punctuation from `word`. Return the items"
    ],
    [
        "lead = word[: len(word) - len(middle)]",
        "lead = word[:"
    ],
    [
        "trail = middle[len(rstripped) :] + trail",
        "trail = middle[len(rstripped) :]"
    ],
    [
        "if escaped == potential_entity or escaped.endswith(\";\"):",
        "if escaped == potential_entity"
    ],
    [
        "\"\"\"Return True if value looks like an email address.\"\"\"",
        "\"\"\"Return True if value looks like"
    ],
    [
        "Avoid text wrapping in the middle of a phrase by adding non-breaking",
        "Avoid text wrapping in the middle of a phrase by adding"
    ],
    [
        "spaces where there previously were normal spaces.",
        "spaces where there previously were"
    ],
    [
        "A decorator that defines the __html__ method. This helps non-Django",
        "A decorator that defines the __html__"
    ],
    [
        "templates to detect classes whose __str__ methods return SafeString.",
        "templates to detect classes whose"
    ],
    [
        "\"can't apply @html_safe to %s because it defines \"",
        "\"can't apply @html_safe to %s because"
    ],
    [
        "\"can't apply @html_safe to %s because it doesn't \"",
        "\"can't apply @html_safe to %s because it doesn't"
    ],
    [
        "return days, hours, minutes, seconds, microseconds",
        "return days, hours,"
    ],
    [
        "\"\"\"Version of str(timedelta) which is not English specific.\"\"\"",
        "\"\"\"Version of str(timedelta) which is not English"
    ],
    [
        "days, hours, minutes, seconds, microseconds = _get_duration_components(duration)",
        "days, hours, minutes, seconds, microseconds"
    ],
    [
        "string = \"{} \".format(days) + string",
        "string = \"{} \".format(days) +"
    ],
    [
        "days, hours, minutes, seconds, microseconds = _get_duration_components(duration)",
        "days, hours, minutes, seconds, microseconds"
    ],
    [
        "sign, days, hours, minutes, seconds, ms",
        "sign, days, hours, minutes, seconds,"
    ],
    [
        "This module contains helper functions for controlling caching. It does so by",
        "This module contains helper functions for controlling"
    ],
    [
        "managing the \"Vary\" header of responses. It includes functions to patch the",
        "managing the \"Vary\" header of responses. It"
    ],
    [
        "header of response objects directly and decorators that change functions to do",
        "header of response objects directly and decorators"
    ],
    [
        "Essentially, the \"Vary\" HTTP header defines which headers a cache should take",
        "Essentially, the \"Vary\" HTTP header defines which"
    ],
    [
        "into account when building its cache key. Requests with the same path but",
        "into account when building its cache key. Requests with"
    ],
    [
        "different header content for headers named in \"Vary\" need to get different",
        "different header content for headers named in \"Vary\" need to"
    ],
    [
        "cache keys to prevent delivery of wrong content.",
        "cache keys to prevent delivery"
    ],
    [
        "from django.utils.http import http_date, parse_etags, parse_http_date_safe, quote_etag",
        "from django.utils.http import http_date,"
    ],
    [
        "Patch the Cache-Control header by adding all keyword arguments to it.",
        "Patch the Cache-Control header by adding all keyword arguments to"
    ],
    [
        "* All keyword parameter names are turned to lowercase, and underscores",
        "* All keyword parameter names are turned to"
    ],
    [
        "* If the value of a parameter is True (exactly True, not just a",
        "* If the value of a parameter"
    ],
    [
        "true value), only the parameter name is added to the header.",
        "true value), only the parameter name is added to"
    ],
    [
        "* All other parameters are added with their value, after applying",
        "* All other parameters are added with their"
    ],
    [
        "if \"max-age\" in cc and \"max_age\" in kwargs:",
        "if \"max-age\" in cc and \"max_age\" in"
    ],
    [
        "if \"private\" in cc and \"public\" in kwargs:",
        "if \"private\" in cc and \"public\""
    ],
    [
        "elif \"public\" in cc and \"private\" in kwargs:",
        "elif \"public\" in cc and \"private\""
    ],
    [
        "directives.extend([dictvalue(directive, value) for value in values])",
        "directives.extend([dictvalue(directive, value) for value"
    ],
    [
        "Return the max-age from the response Cache-Control header as an integer,",
        "Return the max-age from the response"
    ],
    [
        "or None if it wasn't found or wasn't an integer.",
        "or None if it wasn't found or wasn't"
    ],
    [
        "if if_match_etags and not _if_match_passes(etag, if_match_etags):",
        "if if_match_etags and not _if_match_passes(etag,"
    ],
    [
        "if if_none_match_etags and not _if_none_match_passes(etag, if_none_match_etags):",
        "if if_none_match_etags and not _if_none_match_passes(etag,"
    ],
    [
        "return last_modified and last_modified <= if_unmodified_since",
        "return last_modified and"
    ],
    [
        "etags = (etag.strip(\"W/\") for etag in etags)",
        "etags = (etag.strip(\"W/\") for"
    ],
    [
        "return not last_modified or last_modified > if_modified_since",
        "return not last_modified or last_modified >"
    ],
    [
        "Add HTTP caching headers to the given HttpResponse: Expires and",
        "Add HTTP caching headers to the given HttpResponse: Expires"
    ],
    [
        "Each header is only added if it isn't already set.",
        "Each header is only added if it isn't already"
    ],
    [
        "cache_timeout is in seconds. The CACHE_MIDDLEWARE_SECONDS setting is used",
        "cache_timeout is in seconds. The"
    ],
    [
        "Add headers to a response to indicate that a page should never be cached.",
        "Add headers to a response to indicate that a page should never"
    ],
    [
        "Add (or update) the \"Vary\" header in the given HttpResponse object.",
        "Add (or update) the \"Vary\" header in the given HttpResponse"
    ],
    [
        "newheaders is a list of header names that should be in \"Vary\". If headers",
        "newheaders is a list of header names that should be in \"Vary\"."
    ],
    [
        "contains an asterisk, then \"Vary\" header will consist of a single asterisk",
        "contains an asterisk, then \"Vary\" header will consist of"
    ],
    [
        "'*'. Otherwise, existing headers in \"Vary\" aren't removed.",
        "'*'. Otherwise, existing headers"
    ],
    [
        "existing_headers = {header.lower() for header in vary_headers}",
        "existing_headers = {header.lower() for header"
    ],
    [
        "Check to see if the response has a given header name in its Vary header.",
        "Check to see if the response has a given header name"
    ],
    [
        "existing_headers = {header.lower() for header in vary_headers}",
        "existing_headers = {header.lower() for header"
    ],
    [
        "\"\"\"If necessary, add the current locale or time zone to the cache key.\"\"\"",
        "\"\"\"If necessary, add the current locale or"
    ],
    [
        "cache_key += \".%s\" % getattr(request, \"LANGUAGE_CODE\", get_language())",
        "cache_key += \".%s\" % getattr(request,"
    ],
    [
        "\"\"\"Return a cache key from the headers given in the header list.\"\"\"",
        "\"\"\"Return a cache key from the"
    ],
    [
        "\"\"\"Return a cache key for the header cache.\"\"\"",
        "\"\"\"Return a cache key for the"
    ],
    [
        "Return a cache key based on the request URL and query. It can be used",
        "Return a cache key based on the request URL"
    ],
    [
        "in the request phase because it pulls the list of headers to take into",
        "in the request phase because it pulls the list"
    ],
    [
        "account from the global URL registry and uses those to build a cache key",
        "account from the global URL registry and uses those to build a cache"
    ],
    [
        "If there isn't a headerlist stored, return None, indicating that the page",
        "If there isn't a headerlist stored, return None, indicating that"
    ],
    [
        "def learn_cache_key(request, response, cache_timeout=None, key_prefix=None, cache=None):",
        "def learn_cache_key(request, response,"
    ],
    [
        "Learn what headers to take into account for some request URL from the",
        "Learn what headers to take into account for some"
    ],
    [
        "response object. Store those headers in a global URL registry so that",
        "response object. Store those headers in a global"
    ],
    [
        "later access to that URL will know what headers to take into account",
        "later access to that URL will know what headers"
    ],
    [
        "without building the response object itself. The headers are named in the",
        "without building the response object itself. The headers are named"
    ],
    [
        "Vary header of the response, but we want to prevent response generation.",
        "Vary header of the response, but"
    ],
    [
        "The list of headers to use for cache key generation is stored in the same",
        "The list of headers to use for cache key generation is stored in"
    ],
    [
        "cache as the pages themselves. If the cache ages some data out of the",
        "cache as the pages themselves. If the cache ages some data"
    ],
    [
        "cache, this just means that we have to build the response once to get at",
        "cache, this just means that we have to build the"
    ],
    [
        "the Vary header and so at the list of headers to use for the cache key.",
        "the Vary header and so at the list of headers to"
    ],
    [
        "if header != \"ACCEPT_LANGUAGE\" or not is_accept_language_redundant:",
        "if header != \"ACCEPT_LANGUAGE\" or"
    ],
    [
        "Class decorator that allows the decorated class to be serialized",
        "Class decorator that allows the"
    ],
    [
        "The `path` kwarg specifies the import path.",
        "The `path` kwarg specifies the"
    ],
    [
        "if path and type(obj) is klass:",
        "if path and type(obj) is"
    ],
    [
        "\"Could not find object %s in %s.\\n\"",
        "\"Could not find object %s in"
    ],
    [
        "\"Please note that you cannot serialize things like inner \"",
        "\"Please note that you cannot serialize"
    ],
    [
        "\"classes. Please move the object into the main module \"",
        "\"classes. Please move the object into the main module"
    ],
    [
        "if path and type(obj) is klass",
        "if path and"
    ],
    [
        "from django.conf import settings as django_settings",
        "from django.conf import settings"
    ],
    [
        "\"\"\"Proxy for accessing a connection object's attributes.\"\"\"",
        "\"\"\"Proxy for accessing a"
    ],
    [
        "raise self.exception_class(f\"The connection '{alias}' doesn't exist.\")",
        "raise self.exception_class(f\"The connection '{alias}' doesn't"
    ],
    [
        "if not initialized_only or hasattr(self._connections, alias)",
        "if not initialized_only or"
    ],
    [
        "func = meth_or_func.__func__ if is_method else meth_or_func",
        "func = meth_or_func.__func__ if"
    ],
    [
        "return [param.name for param in params if param.kind in ARG_KINDS]",
        "return [param.name for param in"
    ],
    [
        "Return a list of (argument name, default value) tuples. If the argument",
        "Return a list of (argument name, default value) tuples. If"
    ],
    [
        "does not have a default value, omit it in the tuple. Arguments such as",
        "does not have a default value, omit it in the tuple. Arguments"
    ],
    [
        "*args and **kwargs are also included.",
        "*args and **kwargs are also"
    ],
    [
        "\"\"\"Return True if function 'func' accepts keyword arguments **kwargs.\"\"\"",
        "\"\"\"Return True if function 'func' accepts"
    ],
    [
        "return any(p for p in _get_callable_parameters(func) if p.kind == p.VAR_KEYWORD)",
        "return any(p for p in _get_callable_parameters(func) if p.kind"
    ],
    [
        "Return True if function 'func' accepts positional arguments *args.",
        "Return True if function 'func'"
    ],
    [
        "return any(p for p in _get_callable_parameters(func) if p.kind == p.VAR_POSITIONAL)",
        "return any(p for p in"
    ],
    [
        "\"\"\"Return True if a method only accepts 'self'.\"\"\"",
        "\"\"\"Return True if a method only"
    ],
    [
        "count = len([p for p in _get_callable_parameters(meth) if p.kind in ARG_KINDS])",
        "count = len([p for p in _get_callable_parameters(meth) if p.kind"
    ],
    [
        "return any(param.name == name for param in _get_callable_parameters(func))",
        "return any(param.name == name for param in"
    ],
    [
        "Decorator that converts a method with a single self argument into a",
        "Decorator that converts a method with a single self argument"
    ],
    [
        "A cached property can be made out of an existing method:",
        "A cached property can be made"
    ],
    [
        "\"Cannot use cached_property instance without calling \"",
        "\"Cannot use cached_property instance without"
    ],
    [
        "\"Cannot assign the same cached_property to two different names \"",
        "\"Cannot assign the same cached_property to two different"
    ],
    [
        "\"(%r and %r).\" % (self.name, name)",
        "\"(%r and %r).\" % (self.name,"
    ],
    [
        "Call the function and put the return value in instance.__dict__ so that",
        "Call the function and put the return value in instance.__dict__"
    ],
    [
        "subsequent attribute access on the instance returns the cached value",
        "subsequent attribute access on the instance returns the cached"
    ],
    [
        "Decorator that converts a method with a single cls argument into a property",
        "Decorator that converts a method with a single cls argument into"
    ],
    [
        "that can be accessed directly from the class.",
        "that can be accessed directly from"
    ],
    [
        "Base class for the proxy class created in the closure of the lazy function.",
        "Base class for the proxy class created in the closure"
    ],
    [
        "It's used to recognize promises in code.",
        "It's used to recognize promises"
    ],
    [
        "Turn any callable into a lazy evaluated callable. result classes or types",
        "Turn any callable into a lazy evaluated callable."
    ],
    [
        "is required -- at least one is needed so that the automatic forcing of",
        "is required -- at least one is needed"
    ],
    [
        "the lazy evaluation code is triggered. Results are not memoized; the",
        "the lazy evaluation code is triggered. Results"
    ],
    [
        "function is evaluated on every access.",
        "function is evaluated on"
    ],
    [
        "Encapsulate a function call and act as a proxy for methods that are",
        "Encapsulate a function call and act as a proxy for methods"
    ],
    [
        "called on the result of that function. The function is not evaluated",
        "called on the result of that function. The function"
    ],
    [
        "until one of the methods on the result is called.",
        "until one of the methods on the result is"
    ],
    [
        "Shortcut for the common case of a lazy callable that returns str.",
        "Shortcut for the common case of a lazy callable"
    ],
    [
        "A decorator that allows a function to be called with one or more lazy",
        "A decorator that allows a function to be called with one or"
    ],
    [
        "arguments. If none of the args are lazy, the function is evaluated",
        "arguments. If none of the args are lazy,"
    ],
    [
        "immediately, otherwise a __proxy__ is returned that will evaluate the",
        "immediately, otherwise a __proxy__ is returned that will evaluate"
    ],
    [
        "raise TypeError(\"You must pass at least one argument to keep_lazy().\")",
        "raise TypeError(\"You must pass at least one argument"
    ],
    [
        "A decorator for functions that accept lazy arguments and return text.",
        "A decorator for functions that accept lazy arguments and return"
    ],
    [
        "if (_wrapped := self._wrapped) is empty:",
        "if (_wrapped :="
    ],
    [
        "A wrapper for another class that can be used to delay instantiation of the",
        "A wrapper for another class that can be used to delay"
    ],
    [
        "By subclassing, you have the opportunity to intercept and alter the",
        "By subclassing, you have the opportunity to intercept"
    ],
    [
        "instantiation. If you don't need to do that, use SimpleLazyObject.",
        "instantiation. If you don't need to do that, use"
    ],
    [
        "Must be implemented by subclasses to initialize the wrapped object.",
        "Must be implemented by subclasses"
    ],
    [
        "\"subclasses of LazyObject must provide a _setup() method\"",
        "\"subclasses of LazyObject must provide"
    ],
    [
        "Used to unpickle lazy objects. Just return its argument, which will be the",
        "Used to unpickle lazy objects. Just return its"
    ],
    [
        "A lazy object initialized from any function.",
        "A lazy object initialized from any"
    ],
    [
        "Designed for compound objects of unknown type. For builtins or objects of",
        "Designed for compound objects of unknown type. For builtins or"
    ],
    [
        "Pass in a callable that returns the object to be wrapped.",
        "Pass in a callable that returns the object to"
    ],
    [
        "If copies are made of the resulting SimpleLazyObject, which can happen",
        "If copies are made of the"
    ],
    [
        "in various circumstances within Django, then you must ensure that the",
        "in various circumstances within Django, then you must"
    ],
    [
        "callable can be safely run more than once and will return the same",
        "callable can be safely run more than once and will return the"
    ],
    [
        "return \"<%s: %r>\" % (type(self).__name__, repr_attr)",
        "return \"<%s: %r>\" % (type(self).__name__,"
    ],
    [
        "Split the values into two sets, based on the return value of the function",
        "Split the values into two sets, based on the return value of"
    ],
    [
        "Django's standard crypto functions and utilities.",
        "Django's standard crypto"
    ],
    [
        "\"\"\"Algorithm is not supported by hashlib.\"\"\"",
        "\"\"\"Algorithm is not supported"
    ],
    [
        "Return the HMAC of 'value', using a key generated from key_salt and a",
        "Return the HMAC of 'value', using a key generated from key_salt"
    ],
    [
        "but any algorithm name supported by hashlib can be passed.",
        "but any algorithm name supported"
    ],
    [
        "A different key_salt should be passed in for every application of HMAC.",
        "A different key_salt should be passed in for"
    ],
    [
        "\"%r is not an algorithm accepted by the hashlib module.\" % algorithm",
        "\"%r is not an algorithm accepted by the hashlib"
    ],
    [
        "Return a securely generated random string.",
        "Return a securely generated"
    ],
    [
        "The bit length of the returned value can be calculated with the formula:",
        "The bit length of the returned value can"
    ],
    [
        "return \"\".join(secrets.choice(allowed_chars) for i in range(length))",
        "return \"\".join(secrets.choice(allowed_chars) for"
    ],
    [
        "\"\"\"Return True if the two strings are equal, False otherwise.\"\"\"",
        "\"\"\"Return True if the two strings"
    ],
    [
        "Utility functions for generating \"lorem ipsum\" Latin text.",
        "Utility functions for generating \"lorem ipsum\" Latin"
    ],
    [
        "\"Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod \"",
        "\"Lorem ipsum dolor sit amet, consectetur adipisicing"
    ],
    [
        "\"tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim \"",
        "\"tempor incididunt ut labore et dolore magna aliqua. Ut enim ad"
    ],
    [
        "\"veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea \"",
        "\"veniam, quis nostrud exercitation ullamco laboris nisi ut"
    ],
    [
        "\"commodo consequat. Duis aute irure dolor in reprehenderit in voluptate \"",
        "\"commodo consequat. Duis aute irure dolor in reprehenderit in"
    ],
    [
        "\"velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint \"",
        "\"velit esse cillum dolore eu fugiat"
    ],
    [
        "\"occaecat cupidatat non proident, sunt in culpa qui officia deserunt \"",
        "\"occaecat cupidatat non proident, sunt in culpa qui officia"
    ],
    [
        "Return a randomly generated sentence of lorem ipsum text.",
        "Return a randomly generated sentence of lorem"
    ],
    [
        "The first word is capitalized, and the sentence ends in either a period or",
        "The first word is capitalized, and the sentence"
    ],
    [
        "question mark. Commas are added at random.",
        "question mark. Commas are added at"
    ],
    [
        "Return a randomly generated paragraph of lorem ipsum text.",
        "Return a randomly generated paragraph of lorem ipsum"
    ],
    [
        "Return a list of paragraphs as returned by paragraph().",
        "Return a list of paragraphs"
    ],
    [
        "If `common` is True, then the first paragraph will be the standard",
        "If `common` is True, then the first"
    ],
    [
        "'lorem ipsum' paragraph. Otherwise, the first paragraph will be random",
        "'lorem ipsum' paragraph. Otherwise, the"
    ],
    [
        "Latin text. Either way, subsequent paragraphs will be random Latin text.",
        "Latin text. Either way, subsequent paragraphs"
    ],
    [
        "Return a string of `count` lorem ipsum words separated by a single space.",
        "Return a string of `count` lorem ipsum words"
    ],
    [
        "'lorem ipsum' words. Otherwise, all words will be selected randomly.",
        "'lorem ipsum' words. Otherwise, all words"
    ],
    [
        "word_list = list(COMMON_WORDS) if common else []",
        "word_list = list(COMMON_WORDS) if"
    ],
    [
        "Functions for reversing a regular expression (used in reverse URL resolving).",
        "Functions for reversing a regular expression (used in reverse URL"
    ],
    [
        "Used internally by Django and not intended for external use.",
        "Used internally by Django and not intended"
    ],
    [
        "This is not, and is not intended to be, a complete reg-exp decompiler. It",
        "This is not, and is not intended to be, a complete reg-exp"
    ],
    [
        "should be good enough for a large class of URLS, however.",
        "should be good enough for a large class"
    ],
    [
        "\"\"\"Represent multiple possibilities at this point in a pattern string.\"\"\"",
        "\"\"\"Represent multiple possibilities at this point in a"
    ],
    [
        "\"\"\"Represent a capturing group in the pattern string.\"\"\"",
        "\"\"\"Represent a capturing group in"
    ],
    [
        "\"\"\"Represent a non-capturing group in the pattern string.\"\"\"",
        "\"\"\"Represent a non-capturing group in"
    ],
    [
        "Given a reg-exp pattern, normalize it to an iterable of forms that",
        "Given a reg-exp pattern, normalize it to an iterable of"
    ],
    [
        "suffice for reverse matching. This does the following:",
        "suffice for reverse matching. This does the"
    ],
    [
        "permitted (this means zero for optional groups).",
        "permitted (this means zero for"
    ],
    [
        "class. Select an arbitrary character for any unordered class (e.g. '.'",
        "class. Select an arbitrary character for"
    ],
    [
        "Django's URLs for forward resolving are either all positional arguments or",
        "Django's URLs for forward resolving are either"
    ],
    [
        "all keyword arguments. That is assumed here, as well. Although reverse",
        "all keyword arguments. That is assumed here, as well. Although"
    ],
    [
        "resolving can be done using positional args when keyword args are",
        "resolving can be done using positional args when keyword"
    ],
    [
        "specified, the two cannot be mixed in the same reverse() call.",
        "specified, the two cannot be mixed in the"
    ],
    [
        "while escaped or ch != \"]\":",
        "while escaped or ch"
    ],
    [
        "if ch != \"?\" or escaped:",
        "if ch != \"?\" or"
    ],
    [
        "raise ValueError(\"Non-reversible reg-exp portion: '(?%s'\" % ch)",
        "raise ValueError(\"Non-reversible reg-exp portion: '(?%s'\" %"
    ],
    [
        "if ch not in (\"<\", \"=\"):",
        "if ch not"
    ],
    [
        "\"Non-reversible reg-exp portion: '(?P%s'\" % ch",
        "\"Non-reversible reg-exp portion: '(?P%s'\" %"
    ],
    [
        "An iterator that yields the next character from \"pattern_iter\", respecting",
        "An iterator that yields the next character"
    ],
    [
        "escape sequences. An escaped character is replaced by a representative of",
        "escape sequences. An escaped character is replaced"
    ],
    [
        "its class (e.g. \\w -> \"x\"). If the escaped character is one that is",
        "its class (e.g. \\w -> \"x\"). If the escaped"
    ],
    [
        "skipped, it is not returned (the next character is returned instead).",
        "skipped, it is not returned (the next character is"
    ],
    [
        "Yield the next character, along with a boolean indicating whether it is a",
        "Yield the next character, along with a boolean indicating"
    ],
    [
        "The iterator is currently inside a capturing group. Walk to the close of",
        "The iterator is currently inside a capturing group. Walk to the"
    ],
    [
        "this group, skipping over any nested groups and handling escaped",
        "this group, skipping over any nested groups and handling"
    ],
    [
        "Parse a quantifier from the input, where \"ch\" is the first character in the",
        "Parse a quantifier from the input, where \"ch\" is the first character"
    ],
    [
        "Return the minimum number of occurrences permitted by the quantifier and",
        "Return the minimum number of occurrences permitted by the quantifier"
    ],
    [
        "either None or the next character from the input_iter if the next character",
        "either None or the next character from the input_iter if the"
    ],
    [
        "is not part of the quantifier.",
        "is not part of"
    ],
    [
        "Return True if the \"source\" contains an instance of \"inst\". False,",
        "Return True if the \"source\" contains an instance of \"inst\"."
    ],
    [
        "Turn the given source sequence into a list of reg-exp possibilities and",
        "Turn the given source sequence into a"
    ],
    [
        "their arguments. Return a list of strings and a list of argument lists.",
        "their arguments. Return a list of strings and a list of argument"
    ],
    [
        "Each of the two lists will be of the same length.",
        "Each of the two lists will be of the"
    ],
    [
        "for item, args in zip(result, result_args):",
        "for item, args in zip(result,"
    ],
    [
        "for i_item, i_args in zip(inner_result, inner_args):",
        "for i_item, i_args"
    ],
    [
        "\"\"\"Lazily compile a regex with flags.\"\"\"",
        "\"\"\"Lazily compile a"
    ],
    [
        "assert not flags, \"flags must be empty if regex is passed pre-compiled\"",
        "assert not flags, \"flags must be empty if regex is"
    ],
    [
        "from binascii import Error as BinasciiError",
        "from binascii import Error"
    ],
    [
        "from urllib.parse import urlencode as original_urlencode",
        "from urllib.parse import urlencode as"
    ],
    [
        "MONTHS = \"jan feb mar apr may jun jul aug sep oct nov dec\".split()",
        "MONTHS = \"jan feb mar apr may"
    ],
    [
        "A version of Python's urllib.parse.urlencode() function that can operate on",
        "A version of Python's urllib.parse.urlencode() function that can"
    ],
    [
        "\"Cannot encode None for key '%s' in a query string. Did you \"",
        "\"Cannot encode None for key '%s' in"
    ],
    [
        "\"mean to pass an empty string or omit the value?\" % key",
        "\"mean to pass an empty string"
    ],
    [
        "elif not doseq or isinstance(value, (str, bytes)):",
        "elif not doseq or isinstance(value, (str,"
    ],
    [
        "\"Cannot encode None for key '%s' in a query \"",
        "\"Cannot encode None for key '%s' in a"
    ],
    [
        "\"string. Did you mean to pass an empty string or \"",
        "\"string. Did you mean to pass an empty string"
    ],
    [
        "`epoch_seconds` is a floating point number expressed in seconds since the",
        "`epoch_seconds` is a floating point number expressed"
    ],
    [
        "epoch, in UTC - such as that outputted by time.time(). If set to None, it",
        "epoch, in UTC - such as that outputted"
    ],
    [
        "Output a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.",
        "Output a string in the format 'Wdy,"
    ],
    [
        "The three formats allowed by the RFC are accepted, even if only the first",
        "The three formats allowed by the RFC are"
    ],
    [
        "one is still in widespread use.",
        "one is still"
    ],
    [
        "Return an integer expressed in seconds since the epoch, in UTC.",
        "Return an integer expressed in seconds since"
    ],
    [
        "raise ValueError(\"%r is not in a valid HTTP date format\" % date)",
        "raise ValueError(\"%r is not in a valid HTTP date format\" %"
    ],
    [
        "result = datetime(year, month, day, hour, min, sec, tzinfo=timezone.utc)",
        "result = datetime(year, month, day, hour,"
    ],
    [
        "raise ValueError(\"%r is not a valid date\" % date) from exc",
        "raise ValueError(\"%r is not a valid date\""
    ],
    [
        "Same as parse_http_date, but return None if the input is invalid.",
        "Same as parse_http_date, but return None if the input is"
    ],
    [
        "Parse a string of ETags given in an If-None-Match or If-Match header as",
        "Parse a string of ETags given in an If-None-Match or If-Match"
    ],
    [
        "etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(\",\"))",
        "etag_matches = (ETAG_MATCH.match(etag.strip()) for"
    ],
    [
        "If the provided string is already a quoted ETag, return it. Otherwise, wrap",
        "If the provided string is already a quoted"
    ],
    [
        "the string in quotes, making it a strong ETag.",
        "the string in quotes, making it"
    ],
    [
        "Return ``True`` if the host is either an exact match or a match",
        "Return ``True`` if the host is either an exact match or a"
    ],
    [
        "Any pattern beginning with a period matches a domain and all of its",
        "Any pattern beginning with a period matches a"
    ],
    [
        "subdomains. (e.g. ``.example.com`` matches ``example.com`` and",
        "subdomains. (e.g. ``.example.com``"
    ],
    [
        "``foo.example.com``). Anything else is an exact string match.",
        "``foo.example.com``). Anything else is an"
    ],
    [
        "Return ``True`` if the url uses an allowed host and a safe scheme.",
        "Return ``True`` if the url uses an allowed host and a"
    ],
    [
        "Always return ``False`` on an empty url.",
        "Always return ``False`` on"
    ],
    [
        "If ``require_https`` is ``True``, only 'https' will be considered a valid",
        "If ``require_https`` is ``True``, only 'https' will"
    ],
    [
        "scheme, as opposed to 'http' and 'https' with the default, ``False``.",
        "scheme, as opposed to 'http' and 'https' with the default,"
    ],
    [
        "Note: \"True\" doesn't entail that a URL is \"safe\". It may still be e.g.",
        "Note: \"True\" doesn't entail that a URL is \"safe\". It may still"
    ],
    [
        "quoted incorrectly. Ensure to also use django.utils.encoding.iri_to_uri()",
        "quoted incorrectly. Ensure to also use"
    ],
    [
        "on the path component of untrusted URLs.",
        "on the path component of untrusted"
    ],
    [
        "valid_schemes = [\"https\"] if require_https else [\"http\", \"https\"]",
        "valid_schemes = [\"https\"] if"
    ],
    [
        "return (not url_info.netloc or url_info.netloc in allowed_hosts) and (",
        "return (not url_info.netloc or url_info.netloc"
    ],
    [
        "not scheme or scheme in valid_schemes",
        "not scheme or scheme in"
    ],
    [
        "If redirecting to an absolute path (two leading slashes), a slash must be",
        "If redirecting to an absolute path (two leading slashes), a slash must"
    ],
    [
        "escaped to prevent browsers from handling the path as schemaless and",
        "escaped to prevent browsers from handling the"
    ],
    [
        "Return the main content-type and a dictionary of options.",
        "Return the main content-type and a dictionary"
    ],
    [
        "Construct a Content-Disposition HTTP header value from the given filename",
        "Construct a Content-Disposition HTTP header value from the"
    ],
    [
        "disposition = \"attachment\" if as_attachment else \"inline\"",
        "disposition = \"attachment\" if as_attachment"
    ],
    [
        "from django.utils.translation import check_for_language, get_language, to_locale",
        "from django.utils.translation import"
    ],
    [
        "This method is provided primarily for testing purposes,",
        "This method is provided primarily for testing"
    ],
    [
        "so that the effects of cached formats can be removed.",
        "so that the effects of"
    ],
    [
        "yield import_module(\"%s.formats\" % (location % loc))",
        "yield import_module(\"%s.formats\" %"
    ],
    [
        "\"\"\"Return a list of the format modules found.\"\"\"",
        "\"\"\"Return a list of"
    ],
    [
        "For a specific format type, return the format for the current",
        "For a specific format type, return the"
    ],
    [
        "language (locale). Default to the format in the settings.",
        "language (locale). Default to the format in the"
    ],
    [
        "format_type is the name of the format, e.g. 'DATE_FORMAT'.",
        "format_type is the name of the format,"
    ],
    [
        "be localized (or not), otherwise it's always localized.",
        "be localized (or not), otherwise it's always"
    ],
    [
        "get_format_lazy = lazy(get_format, str, list, tuple)",
        "get_format_lazy = lazy(get_format, str, list,"
    ],
    [
        "Format a datetime.date or datetime.datetime object using a",
        "Format a datetime.date or datetime.datetime"
    ],
    [
        "be localized (or not), otherwise it's always localized.",
        "be localized (or not),"
    ],
    [
        "Format a datetime.time object using a localizable format.",
        "Format a datetime.time object using"
    ],
    [
        "be localized (or not), otherwise it's always localized.",
        "be localized (or not), otherwise it's always"
    ],
    [
        "Format a numeric value using localization settings.",
        "Format a numeric value using"
    ],
    [
        "be localized (or not), otherwise it's always localized.",
        "be localized (or not), otherwise"
    ],
    [
        "Check if value is a localizable type (date, number...) and return it",
        "Check if value is a localizable type (date,"
    ],
    [
        "formatted as a string using current locale format.",
        "formatted as a string using current"
    ],
    [
        "be localized (or not), otherwise it's always localized.",
        "be localized (or not), otherwise it's always"
    ],
    [
        "Check if an input value is a localizable type and return it",
        "Check if an input value is a localizable"
    ],
    [
        "formatted with the appropriate formatting string of the current locale.",
        "formatted with the appropriate formatting string of the current"
    ],
    [
        "Ensure that certain specifiers are correctly padded with leading zeros.",
        "Ensure that certain specifiers are correctly padded"
    ],
    [
        "strftime provided by glibc on Linux as they don't pad the year or century",
        "strftime provided by glibc on Linux as"
    ],
    [
        "with leading zeros. Support for specifying the padding explicitly is",
        "with leading zeros. Support for specifying the padding explicitly"
    ],
    [
        "available, however, which can be used to fix this issue.",
        "available, however, which can be"
    ],
    [
        "FreeBSD, macOS, and Windows do not support explicitly specifying the",
        "FreeBSD, macOS, and Windows do"
    ],
    [
        "padding, but return four digit years (with leading zeros) as expected.",
        "padding, but return four digit years (with"
    ],
    [
        "This function checks whether the %Y produces a correctly padded string and,",
        "This function checks whether the %Y produces"
    ],
    [
        "if not, makes the following substitutions:",
        "if not, makes"
    ],
    [
        "Sanitize a value according to the current decimal and",
        "Sanitize a value according to the current decimal"
    ],
    [
        "thousand separator setting. Used with form field input.",
        "thousand separator setting. Used"
    ],
    [
        "from gzip import compress as gzip_compress",
        "from gzip import compress as"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "\"\"\"Capitalize the first letter of a string.\"\"\"",
        "\"\"\"Capitalize the first letter of"
    ],
    [
        "A word-wrap function that preserves existing line breaks. Expects that",
        "A word-wrap function that preserves existing"
    ],
    [
        "existing line breaks are posix newlines.",
        "existing line breaks"
    ],
    [
        "Preserve all white space except added line breaks consume the space on",
        "Preserve all white space except added line breaks consume the space"
    ],
    [
        "Don't wrap long words, thus the output text may have lines longer than",
        "Don't wrap long words, thus the output text may have lines"
    ],
    [
        "\"String to return when truncating text\", \"%(truncated_text)s…\"",
        "\"String to return when truncating text\","
    ],
    [
        "def __init__(self, *, length, replacement, convert_charrefs=True):",
        "def __init__(self, *, length,"
    ],
    [
        "self.output += \"\".join([f\"</{tag}>\" for tag in self.tags])",
        "self.output += \"\".join([f\"</{tag}>\" for"
    ],
    [
        "def __init__(self, *, length, replacement, convert_charrefs=True):",
        "def __init__(self, *,"
    ],
    [
        "if (self.processed_chars == self.length) and (",
        "if (self.processed_chars =="
    ],
    [
        "An object used to truncate text, either by characters or words.",
        "An object used to truncate text,"
    ],
    [
        "When truncating HTML text (either chars or words), input will be limited to",
        "When truncating HTML text (either chars or words), input"
    ],
    [
        "Return the text truncated to be no longer than the specified number",
        "Return the text truncated to be no longer than the"
    ],
    [
        "`truncate` specifies what should be used to notify that the string has",
        "`truncate` specifies what should be used to notify"
    ],
    [
        "been truncated, defaulting to a translatable string of an ellipsis.",
        "been truncated, defaulting to a translatable string of an"
    ],
    [
        "\"\"\"Truncate a string after a certain number of chars.\"\"\"",
        "\"\"\"Truncate a string after a"
    ],
    [
        "if end_index is None and s_len > truncate_len:",
        "if end_index is None"
    ],
    [
        "Truncate a string after a certain number of words. `truncate` specifies",
        "Truncate a string after a certain number of"
    ],
    [
        "what should be used to notify that the string has been truncated,",
        "what should be used to notify that the"
    ],
    [
        "Truncate a string after a certain number of words.",
        "Truncate a string after a certain number of"
    ],
    [
        "Return the given string converted to a string that can be used for a clean",
        "Return the given string converted to a string that can be used"
    ],
    [
        "filename. Remove leading and trailing spaces; convert other spaces to",
        "filename. Remove leading and trailing spaces; convert other spaces"
    ],
    [
        "underscores; and remove anything that is not an alphanumeric, dash,",
        "underscores; and remove anything that is not an alphanumeric,"
    ],
    [
        "if s in {\"\", \".\", \"..\"}:",
        "if s in"
    ],
    [
        "raise SuspiciousFileOperation(\"Could not derive file name from '%s'\" % name)",
        "raise SuspiciousFileOperation(\"Could not derive file name from '%s'\""
    ],
    [
        "return \"%s %s %s\" % (",
        "return \"%s %s %s\" %"
    ],
    [
        "\"\"\"Normalize CRLF and CR newlines to just LF.\"\"\"",
        "\"\"\"Normalize CRLF and CR newlines to just"
    ],
    [
        "\"\"\"Convert a phone number with letters into its numeric equivalent.\"\"\"",
        "\"\"\"Convert a phone number with letters into its"
    ],
    [
        "filename = _get_random_filename(max_random_bytes) if max_random_bytes else None",
        "filename = _get_random_filename(max_random_bytes) if max_random_bytes else"
    ],
    [
        "Generator that splits a string by spaces, leaving quoted phrases together.",
        "Generator that splits a string by spaces, leaving quoted"
    ],
    [
        "Supports both single and double quotes, and supports escaping quotes with",
        "Supports both single and double quotes, and supports escaping quotes"
    ],
    [
        "backslashes. In the output, strings will keep their initial and trailing",
        "backslashes. In the output, strings will keep"
    ],
    [
        "quote marks and escaped quotes will remain escaped (the results can then",
        "quote marks and escaped quotes will remain escaped (the results"
    ],
    [
        ">>> list(smart_split(r'This is \"a person\\'s\" test.'))",
        ">>> list(smart_split(r'This is \"a person\\'s\""
    ],
    [
        "Convert quoted string literals to unquoted strings with escaped quotes and",
        "Convert quoted string literals to unquoted strings"
    ],
    [
        "raise ValueError(\"Not a string literal: %r\" % s)",
        "raise ValueError(\"Not a string literal:"
    ],
    [
        "Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated",
        "Convert to ASCII if 'allow_unicode' is"
    ],
    [
        "dashes to single dashes. Remove characters that aren't alphanumerics,",
        "dashes to single dashes. Remove characters"
    ],
    [
        "underscores, or hyphens. Convert to lowercase. Also strip leading and",
        "underscores, or hyphens. Convert to lowercase."
    ],
    [
        "Split CamelCase and convert to lowercase. Strip surrounding whitespace.",
        "Split CamelCase and convert to lowercase. Strip"
    ],
    [
        "Apply str.format() on 'format_string' where format_string, args,",
        "Apply str.format() on 'format_string'"
    ],
    [
        "Permission is hereby granted, free of charge, to any person obtaining a copy",
        "Permission is hereby granted, free of charge, to any"
    ],
    [
        "of this software and associated documentation files (the \"Software\"), to deal",
        "of this software and associated documentation files"
    ],
    [
        "in the Software without restriction, including without limitation the rights",
        "in the Software without restriction, including without"
    ],
    [
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell",
        "to use, copy, modify, merge,"
    ],
    [
        "copies of the Software, and to permit persons to whom the Software is",
        "copies of the Software, and to permit persons to"
    ],
    [
        "furnished to do so, subject to the following conditions:",
        "furnished to do so, subject to"
    ],
    [
        "The above copyright notice and this permission notice shall be included in",
        "The above copyright notice and this"
    ],
    [
        "all copies or substantial portions of the Software.",
        "all copies or substantial"
    ],
    [
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF"
    ],
    [
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,",
        "IMPLIED, INCLUDING BUT NOT LIMITED"
    ],
    [
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT."
    ],
    [
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES"
    ],
    [
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,"
    ],
    [
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE"
    ],
    [
        "Base exception class for all archive errors.",
        "Base exception class for all archive"
    ],
    [
        "Error raised when passed file is not a recognized archive format.",
        "Error raised when passed file is not a recognized"
    ],
    [
        "Unpack the tar or zip file at the specified path to the directory",
        "Unpack the tar or zip file at the"
    ],
    [
        "The external API class that encapsulates an archive implementation.",
        "The external API class that encapsulates an archive"
    ],
    [
        "\"File object not a recognized archive format.\"",
        "\"File object not a recognized"
    ],
    [
        "\"Path not a recognized archive format: %s\" % filename",
        "\"Path not a recognized archive format:"
    ],
    [
        "Base Archive class.  Implementations should inherit this class.",
        "Base Archive class. Implementations should"
    ],
    [
        "If the file in the archive has some permissions (this assumes a file",
        "If the file in the archive has"
    ],
    [
        "won't be writable/executable without being readable), apply those",
        "won't be writable/executable without"
    ],
    [
        "if \"/\" in path and (",
        "if \"/\" in path and"
    ],
    [
        "(\"\\\\\" in path and path.find(\"/\") < path.find(\"\\\\\")) or \"\\\\\" not in path",
        "(\"\\\\\" in path and path.find(\"/\") < path.find(\"\\\\\")) or \"\\\\\""
    ],
    [
        "Return True if all the paths have the same leading path name",
        "Return True if all the paths have the same leading"
    ],
    [
        "(i.e., everything is in one subdirectory in an archive).",
        "(i.e., everything is in one subdirectory in an"
    ],
    [
        "raise SuspiciousOperation(\"Archive contains invalid path: '%s'\" % name)",
        "raise SuspiciousOperation(\"Archive contains invalid"
    ],
    [
        "\"subclasses of BaseArchive must provide an extract() method\"",
        "\"subclasses of BaseArchive must provide"
    ],
    [
        "\"subclasses of BaseArchive must provide a list() method\"",
        "\"subclasses of BaseArchive must"
    ],
    [
        "leading = self.has_leading_dir(x.name for x in members)",
        "leading = self.has_leading_dir(x.name for x"
    ],
    [
        "\"In the tar file %s the member %s is invalid: %s\"",
        "\"In the tar file %s the"
    ],
    [
        "Functions for working with \"safe strings\": strings that can be displayed safely",
        "Functions for working with \"safe strings\": strings that"
    ],
    [
        "without further escaping in HTML. Marking something as a \"safe string\" means",
        "without further escaping in HTML. Marking something as a \"safe"
    ],
    [
        "that the producer of the string has already turned characters that should not",
        "that the producer of the string has already turned characters that should"
    ],
    [
        "be interpreted by the HTML engine (e.g. '<') into the appropriate entities.",
        "be interpreted by the HTML engine"
    ],
    [
        "Return the html representation of a string for interoperability.",
        "Return the html representation of a string"
    ],
    [
        "This allows other template engines to understand Django's SafeData.",
        "This allows other template engines to understand"
    ],
    [
        "A str subclass that has been specifically marked as \"safe\" for HTML output",
        "A str subclass that has been specifically marked"
    ],
    [
        "Concatenating a safe string with another safe bytestring or",
        "Concatenating a safe string with"
    ],
    [
        "safe string is safe. Otherwise, the result is no longer safe.",
        "safe string is safe. Otherwise, the"
    ],
    [
        "Explicitly mark a string as safe for (HTML) output purposes. The returned",
        "Explicitly mark a string as safe"
    ],
    [
        "object can be used everywhere a string is appropriate.",
        "object can be used everywhere a string is"
    ],
    [
        "If used on a method as a decorator, mark the returned data as safe.",
        "If used on a method as a"
    ],
    [
        "Can be called multiple times on a single string.",
        "Can be called multiple times on a"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "from collections.abc import Callable, Iterable, Iterator, Mapping",
        "from collections.abc import Callable,"
    ],
    [
        "from itertools import islice, tee, zip_longest",
        "from itertools import islice,"
    ],
    [
        "\"\"\"Base class for lazy iterators for choices.\"\"\"",
        "\"\"\"Base class for lazy iterators for"
    ],
    [
        "return all(a == b for a, b in zip_longest(self, other, fillvalue=object()))",
        "return all(a == b for a, b in zip_longest(self, other,"
    ],
    [
        "raise IndexError(\"index out of range\") from None",
        "raise IndexError(\"index out of"
    ],
    [
        "\"\"\"Iterator to lazily inject a blank choice.\"\"\"",
        "\"\"\"Iterator to lazily inject"
    ],
    [
        "if not any(value in (\"\", None) for value, _ in flatten_choices(other)):",
        "if not any(value in (\"\", None)"
    ],
    [
        "\"\"\"Iterator to lazily normalize choices generated by a callable.\"\"\"",
        "\"\"\"Iterator to lazily normalize choices generated by a"
    ],
    [
        "\"\"\"Flatten choices by removing nested values.\"\"\"",
        "\"\"\"Flatten choices by removing"
    ],
    [
        "for value_or_group, label_or_nested in choices or ():",
        "for value_or_group, label_or_nested in choices or"
    ],
    [
        "\"\"\"Normalize choices values consistently for fields and widgets.\"\"\"",
        "\"\"\"Normalize choices values consistently for fields and"
    ],
    [
        "case BaseChoiceIterator() | Promise() | bytes() | str():",
        "case BaseChoiceIterator() | Promise() | bytes()"
    ],
    [
        "isinstance(x, (Promise, bytes, str)) for x in value",
        "isinstance(x, (Promise, bytes, str)) for"
    ],
    [
        "Syndication feed generation library -- used for generating RSS, etc.",
        "Syndication feed generation library --"
    ],
    [
        "...     description=\"A group blog by the sharpest minds in online journalism.\",",
        "... description=\"A group blog by the sharpest minds in"
    ],
    [
        ">>> with open('test.rss', 'w') as fp:",
        ">>> with open('test.rss',"
    ],
    [
        "For definitions of the different versions of RSS, see:",
        "For definitions of the different versions of RSS,"
    ],
    [
        "return date.isoformat() + (\"Z\" if date.utcoffset() is None else \"\")",
        "return date.isoformat() + (\"Z\" if date.utcoffset() is"
    ],
    [
        "return \"tag:%s%s:%s/%s\" % (bits.hostname, d, bits.path, bits.fragment)",
        "return \"tag:%s%s:%s/%s\" % (bits.hostname, d, bits.path,"
    ],
    [
        "Return the given stylesheet's mimetype tuple, using a slightly custom",
        "Return the given stylesheet's mimetype"
    ],
    [
        "\"Base class for all syndication feeds. Subclasses should provide write()\"",
        "\"Base class for all syndication feeds. Subclasses should provide"
    ],
    [
        "return str(s) if s is not None else s",
        "return str(s) if s is not None else"
    ],
    [
        "return s if isinstance(s, Stylesheet) else Stylesheet(s)",
        "return s if isinstance(s,"
    ],
    [
        "categories = categories and [str(c) for c in categories]",
        "categories = categories and [str(c) for c in"
    ],
    [
        "f\"stylesheets should be a list, not {stylesheets.__class__}\"",
        "f\"stylesheets should be a list,"
    ],
    [
        "stylesheets = [to_stylesheet(s) for s in stylesheets]",
        "stylesheets = [to_stylesheet(s) for s in"
    ],
    [
        "Add an item to the feed. All args are expected to be strings except",
        "Add an item to the feed. All"
    ],
    [
        "pubdate and updateddate, which are datetime.datetime objects, and",
        "pubdate and updateddate, which are datetime.datetime"
    ],
    [
        "enclosures, which is an iterable of instances of the Enclosure class.",
        "enclosures, which is an iterable of instances of"
    ],
    [
        "return str(s) if s is not None else s",
        "return str(s) if s is not None else"
    ],
    [
        "categories = categories and [to_str(c) for c in categories]",
        "categories = categories and [to_str(c)"
    ],
    [
        "Return extra attributes to place on the root (i.e. feed/channel) element.",
        "Return extra attributes to place on the"
    ],
    [
        "Add elements in the root (i.e. feed/channel) element. Called",
        "Add elements in the root (i.e. feed/channel) element."
    ],
    [
        "Add stylesheet(s) to the feed. Called from write().",
        "Add stylesheet(s) to the"
    ],
    [
        "Return extra attributes to place on each item (i.e. item/entry) element.",
        "Return extra attributes to place on each item (i.e."
    ],
    [
        "Add elements on each item (i.e. item/entry) element.",
        "Add elements on each item (i.e."
    ],
    [
        "Output the feed in the given encoding to outfile, which is a file-like",
        "Output the feed in the given encoding to"
    ],
    [
        "\"subclasses of SyndicationFeed must provide a write() method\"",
        "\"subclasses of SyndicationFeed must"
    ],
    [
        "Return the feed in the given encoding as a string.",
        "Return the feed in the"
    ],
    [
        "Return the latest item's pubdate or updateddate. If no items",
        "Return the latest item's pubdate or updateddate. If"
    ],
    [
        "have either of these attributes this return the current UTC date/time.",
        "have either of these attributes this return the"
    ],
    [
        "if latest_date is None or item_date > latest_date:",
        "if latest_date is None"
    ],
    [
        "\"All args are expected to be strings\"",
        "\"All args are expected"
    ],
    [
        "for stylesheet in self.feed[\"stylesheets\"] or []:",
        "for stylesheet in"
    ],
    [
        "\"atom:link\", None, {\"rel\": \"self\", \"href\": self.feed[\"feed_url\"]}",
        "\"atom:link\", None, {\"rel\": \"self\","
    ],
    [
        "\"author\", \"%s (%s)\" % (item[\"author_email\"], item[\"author_name\"])",
        "\"author\", \"%s (%s)\""
    ],
    [
        "\"RSS feed items may only have one enclosure, see \"",
        "\"RSS feed items may only have one enclosure, see"
    ],
    [
        "\"link\", \"\", {\"rel\": \"alternate\", \"href\": self.feed[\"link\"]}",
        "\"link\", \"\", {\"rel\":"
    ],
    [
        "\"link\", \"\", {\"rel\": \"self\", \"href\": self.feed[\"feed_url\"]}",
        "\"link\", \"\", {\"rel\": \"self\","
    ],
    [
        "handler.addQuickElement(\"link\", \"\", {\"href\": item[\"link\"], \"rel\": \"alternate\"})",
        "handler.addQuickElement(\"link\", \"\", {\"href\": item[\"link\"],"
    ],
    [
        "\"\"\"Return True if the given module is nested under Django.\"\"\"",
        "\"\"\"Return True if the given module"
    ],
    [
        "\"\"\"Return True if the given file path is nested under Django.\"\"\"",
        "\"\"\"Return True if the given file path is"
    ],
    [
        "if getattr(ev, \"filename\", None) is None:",
        "if getattr(ev, \"filename\","
    ],
    [
        "Ensure that echo mode is enabled. Some tools such as PDB disable",
        "Ensure that echo mode is enabled."
    ],
    [
        "it which causes usability issues after reload.",
        "it which causes usability issues"
    ],
    [
        "if not termios or not sys.stdin.isatty():",
        "if not termios"
    ],
    [
        "\"\"\"Iterate through all modules needed to be watched.\"\"\"",
        "\"\"\"Iterate through all modules needed"
    ],
    [
        "if getattr(module, \"__spec__\", None) is None:",
        "if getattr(module, \"__spec__\", None) is"
    ],
    [
        "logger.debug('\"%s\" raised when resolving path: \"%s\"', e, path)",
        "logger.debug('\"%s\" raised when resolving"
    ],
    [
        "Return a tuple of common roots that are shared between the given paths.",
        "Return a tuple of common roots that"
    ],
    [
        "File system watchers operate on directories and aren't cheap to create.",
        "File system watchers operate on directories and aren't cheap"
    ],
    [
        "Try to find the minimum set of directories to watch that encompass all of",
        "Try to find the minimum set of directories to watch that encompass all"
    ],
    [
        "the files that need to be watched.",
        "the files that need"
    ],
    [
        "path_parts = sorted([x.parts for x in paths], key=len, reverse=True)",
        "path_parts = sorted([x.parts for x in"
    ],
    [
        "yield from _walk(child, path + (prefix,))",
        "yield from _walk(child,"
    ],
    [
        "Yield absolute directories from sys.path, ignoring entries that don't",
        "Yield absolute directories from sys.path, ignoring entries that"
    ],
    [
        "Return the executable. This contains a workaround for Windows if the",
        "Return the executable. This contains a workaround for"
    ],
    [
        "executable is reported to not have the .exe extension which can cause bugs",
        "executable is reported to not have the .exe"
    ],
    [
        "args = [sys.executable] + [\"-W%s\" % o for o in sys.warnoptions]",
        "args = [sys.executable] + [\"-W%s\" % o for o in"
    ],
    [
        "f\"-X{key}\" if value is True else f\"-X{key}={value}\"",
        "f\"-X{key}\" if value is True else"
    ],
    [
        "if getattr(__main__, \"__spec__\", None) is not None and not exe_entrypoint.exists():",
        "if getattr(__main__, \"__spec__\", None) is not None and not"
    ],
    [
        "if (spec.name == \"__main__\" or spec.name.endswith(\".__main__\")) and spec.parent:",
        "if (spec.name == \"__main__\" or spec.name.endswith(\".__main__\"))"
    ],
    [
        "raise RuntimeError(\"Script %s does not exist.\" % py_script)",
        "raise RuntimeError(\"Script %s does"
    ],
    [
        "\"Unable to watch directory %s as it cannot be resolved.\",",
        "\"Unable to watch directory %s as it"
    ],
    [
        "logger.debug(\"Watching dir %s with glob %s.\", path, glob)",
        "logger.debug(\"Watching dir %s with"
    ],
    [
        "Yield all files that need to be watched, including module files and",
        "Yield all files that need to be watched, including"
    ],
    [
        "Wait until Django reports that the apps have been loaded. If the given",
        "Wait until Django reports that the apps have"
    ],
    [
        "thread has terminated before the apps are ready, then a SyntaxError or",
        "thread has terminated before the apps are ready, then a"
    ],
    [
        "other non-recoverable error has been raised. In that case, stop waiting",
        "other non-recoverable error has been raised. In that case, stop"
    ],
    [
        "for the apps_ready event and continue processing.",
        "for the apps_ready event and continue"
    ],
    [
        "Return True if the thread is alive and the ready event has been",
        "Return True if the thread is alive and"
    ],
    [
        "triggered, or False if the thread is terminated while waiting for the",
        "triggered, or False if the thread is terminated"
    ],
    [
        "logger.debug(\"Main Django thread has terminated before apps are ready.\")",
        "logger.debug(\"Main Django thread has terminated before apps"
    ],
    [
        "logger.debug(\"Apps ready_event triggered. Sending autoreload_started signal.\")",
        "logger.debug(\"Apps ready_event triggered. Sending autoreload_started"
    ],
    [
        "This generator is called in a loop from run_loop. It's important that",
        "This generator is called in a loop from"
    ],
    [
        "the method takes care of pausing or otherwise waiting for a period of",
        "the method takes care of pausing or otherwise waiting for"
    ],
    [
        "time. This split between run_loop() and tick() is to improve the",
        "time. This split between run_loop() and tick() is"
    ],
    [
        "testability of the reloader implementations by decoupling the work they",
        "testability of the reloader implementations by decoupling the work"
    ],
    [
        "logger.debug(\"%s notified as changed. Signal results: %s.\", path, results)",
        "logger.debug(\"%s notified as changed. Signal"
    ],
    [
        "logger.debug(\"File %s first seen with mtime %s\", filepath, mtime)",
        "logger.debug(\"File %s first seen with"
    ],
    [
        "\"File %s previous mtime: %s, current mtime: %s\",",
        "\"File %s previous mtime: %s, current"
    ],
    [
        "\"Unable to watch root dir %s as neither it or its parent exist.\",",
        "\"Unable to watch root dir %s as"
    ],
    [
        "\"Issuing watchman subscription %s, for root %s. Query: %s\",",
        "\"Issuing watchman subscription %s, for"
    ],
    [
        "\"Unable to watch directory %s as neither it or its parent exist.\",",
        "\"Unable to watch directory %s as neither"
    ],
    [
        "filenames = [\"%s/%s\" % (directory.name, filename) for filename in filenames]",
        "filenames = [\"%s/%s\" % (directory.name, filename) for filename in"
    ],
    [
        "self._subscribe(directory, \"%s:%s\" % (prefix, directory), expression)",
        "self._subscribe(directory, \"%s:%s\" % (prefix, directory),"
    ],
    [
        "Watch a directory with a specific glob. If the directory doesn't yet",
        "Watch a directory with a specific"
    ],
    [
        "exist, attempt to watch the parent directory and amend the patterns to",
        "exist, attempt to watch the parent directory and"
    ],
    [
        "include this. It's important this method isn't called more than one per",
        "include this. It's important this method isn't"
    ],
    [
        "directory when updating all subscriptions. Subsequent calls will",
        "directory when updating all"
    ],
    [
        "overwrite the named subscription, so it must include all possible glob",
        "overwrite the named subscription, so it must include all"
    ],
    [
        "\"Unable to watch directory %s as neither it or its parent exist.\",",
        "\"Unable to watch directory %s as neither it or its parent"
    ],
    [
        "patterns = [\"%s/%s\" % (directory.name, pattern) for pattern in patterns]",
        "patterns = [\"%s/%s\" % (directory.name, pattern) for pattern"
    ],
    [
        "self._subscribe(directory, \"%s:%s\" % (prefix, directory), expression)",
        "self._subscribe(directory, \"%s:%s\" % (prefix, directory),"
    ],
    [
        "watched_file_dirs = [f.parent for f in watched_files]",
        "watched_file_dirs = [f.parent for"
    ],
    [
        "sorted_files = sorted(watched_files, key=lambda p: p.parent)",
        "sorted_files = sorted(watched_files, key=lambda p:"
    ],
    [
        "for directory, group in itertools.groupby(sorted_files, key=lambda p: p.parent):",
        "for directory, group in itertools.groupby(sorted_files, key=lambda"
    ],
    [
        "directory, [str(p.relative_to(directory)) for p in group]",
        "directory, [str(p.relative_to(directory)) for"
    ],
    [
        "logger.debug(\"Watchman subscription %s has results.\", sub)",
        "logger.debug(\"Watchman subscription %s has"
    ],
    [
        "logger.debug(\"Watchman error: %s, checking server status.\", ex)",
        "logger.debug(\"Watchman error: %s, checking server"
    ],
    [
        "\"\"\"Return True if the server is available.\"\"\"",
        "\"\"\"Return True if the server is"
    ],
    [
        "raise WatchmanUnavailable(\"Cannot connect to the watchman service.\")",
        "raise WatchmanUnavailable(\"Cannot connect to the"
    ],
    [
        "\"\"\"Return the most suitable reloader for this environment.\"\"\"",
        "\"\"\"Return the most suitable reloader for this"
    ],
    [
        "\"Watching for file changes with %s\", reloader.__class__.__name__",
        "\"Watching for file changes with"
    ],
    [
        "A set which keeps the ordering of the inserted items.",
        "A set which keeps the"
    ],
    [
        "data = repr(list(self.dict)) if self.dict else \"\"",
        "data = repr(list(self.dict)) if"
    ],
    [
        "A subclass of dictionary customized to handle multiple values for the",
        "A subclass of dictionary customized to handle"
    ],
    [
        ">>> d = MultiValueDict({'name': ['Adrian', 'Simon'], 'position': ['Developer']})",
        ">>> d = MultiValueDict({'name': ['Adrian',"
    ],
    [
        "This class exists to solve the irritating problem raised by cgi.parse_qs,",
        "This class exists to solve the irritating problem"
    ],
    [
        "which returns a list for every key, even though most web forms submit",
        "which returns a list for every key, even though most web forms"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, super().__repr__())",
        "return \"<%s: %s>\" %"
    ],
    [
        "Return the last data value for this key, or [] if it's an empty list;",
        "Return the last data value for this key, or"
    ],
    [
        "return self.__class__([(k, v[:]) for k, v in self.lists()])",
        "return self.__class__([(k, v[:]) for"
    ],
    [
        "return {**self.__dict__, \"_data\": {k: self._getlist(k) for k in self}}",
        "return {**self.__dict__, \"_data\": {k: self._getlist(k)"
    ],
    [
        "Return the last data value for the passed key. If key doesn't exist",
        "Return the last data value for the passed key. If key doesn't"
    ],
    [
        "or value is an empty list, return `default`.",
        "or value is an empty"
    ],
    [
        "Return a list of values for the key.",
        "Return a list of values"
    ],
    [
        "Used internally to manipulate values list. If force_list is True,",
        "Used internally to manipulate values list. If force_list"
    ],
    [
        "return a new copy of values.",
        "return a new"
    ],
    [
        "values = list(values) if values is not None else None",
        "values = list(values) if values is not None else"
    ],
    [
        "Return the list of values for the key. If key doesn't exist, return a",
        "Return the list of values for the key. If key doesn't exist, return"
    ],
    [
        "\"\"\"Append an item to the internal list associated with key.\"\"\"",
        "\"\"\"Append an item to the internal list"
    ],
    [
        "Yield (key, value) pairs, where value is the last item in the list",
        "Yield (key, value) pairs, where value is the last item in"
    ],
    [
        "\"\"\"Yield the last value on every key list.\"\"\"",
        "\"\"\"Yield the last value on every"
    ],
    [
        "\"\"\"Return a shallow copy of this object.\"\"\"",
        "\"\"\"Return a shallow copy of this"
    ],
    [
        "\"\"\"Extend rather than replace existing key lists.\"\"\"",
        "\"\"\"Extend rather than replace existing key"
    ],
    [
        "\"\"\"Return current object as a dict with singular values.\"\"\"",
        "\"\"\"Return current object as a dict with"
    ],
    [
        "return {key: self[key] for key in self}",
        "return {key: self[key] for key"
    ],
    [
        "A tuple-like object that raises useful errors when it is asked to mutate.",
        "A tuple-like object that raises useful errors"
    ],
    [
        "def __new__(cls, *args, warning=\"ImmutableList object is immutable.\", **kwargs):",
        "def __new__(cls, *args, warning=\"ImmutableList object"
    ],
    [
        "Wrap accesses to a dictionary so that certain values (those starting with",
        "Wrap accesses to a dictionary so that"
    ],
    [
        "the specified prefix) are passed through a function before being returned.",
        "the specified prefix) are passed through a"
    ],
    [
        "The prefix is removed before looking up the real value.",
        "The prefix is removed before looking up the"
    ],
    [
        "Used by the SQL construction code to ensure that values are correctly",
        "Used by the SQL construction code to ensure that values"
    ],
    [
        "Retrieve the real value after stripping the prefix string (if",
        "Retrieve the real value after stripping"
    ],
    [
        "present). If the prefix is present, pass the value through self.func",
        "present). If the prefix is present, pass the"
    ],
    [
        "before returning, otherwise return the raw value.",
        "before returning, otherwise return"
    ],
    [
        "Mapping allowing case-insensitive key lookups. Original case of keys is",
        "Mapping allowing case-insensitive key lookups. Original case of keys"
    ],
    [
        "preserved for iteration and string representation.",
        "preserved for iteration"
    ],
    [
        "self._store = {k.lower(): (k, v) for k, v in self._unpack_items(data)}",
        "self._store = {k.lower(): (k, v)"
    ],
    [
        "k.lower(): v for k, v in self.items()",
        "k.lower(): v for k, v in"
    ],
    [
        "} == {k.lower(): v for k, v in other.items()}",
        "} == {k.lower(): v for k,"
    ],
    [
        "return (original_key for original_key, value in self._store.values())",
        "return (original_key for original_key, value in"
    ],
    [
        "return repr({key: value for key, value in self._store.values()})",
        "return repr({key: value for"
    ],
    [
        "from datetime import date, datetime, time",
        "from datetime import date,"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "if type(self.data) is date and hasattr(TimeFormat, piece):",
        "if type(self.data) is date and hasattr(TimeFormat,"
    ],
    [
        "\"The format for date objects may not contain \"",
        "\"The format for date objects may not contain"
    ],
    [
        "\"time-related format specifiers (found '%s').\" % piece",
        "\"time-related format specifiers (found '%s').\" %"
    ],
    [
        "If timezone information is not available, return an empty string.",
        "If timezone information is not available, return an"
    ],
    [
        "If timezone information is not available, return an empty string.",
        "If timezone information is not available, return an"
    ],
    [
        "if they're zero and the strings 'midnight' and 'noon' if appropriate.",
        "if they're zero and the strings 'midnight' and 'noon'"
    ],
    [
        "return \"%s %s\" % (self.f(), self.a())",
        "return \"%s %s\" %"
    ],
    [
        "Time zone of this machine; e.g. 'EST' or 'MDT'.",
        "Time zone of this machine;"
    ],
    [
        "If timezone information is not available, return an empty string.",
        "If timezone information is not"
    ],
    [
        "timezones west of UTC is always negative, and for those east of UTC is",
        "timezones west of UTC is always negative, and for those east"
    ],
    [
        "If timezone information is not available, return an empty string.",
        "If timezone information is not available, return"
    ],
    [
        "\"Alternative month names as required by some locales. Proprietary extension.\"",
        "\"Alternative month names as required"
    ],
    [
        "\"Day of the week, textual, long; e.g. 'Friday'\"",
        "\"Day of the week, textual, long;"
    ],
    [
        "\"Boolean for whether it is a leap year; i.e. True or False\"",
        "\"Boolean for whether it is a leap"
    ],
    [
        "\"Month abbreviation in Associated Press style. Proprietary extension.\"",
        "\"Month abbreviation in Associated Press"
    ],
    [
        "from datetime import datetime, timedelta, timezone, tzinfo",
        "from datetime import datetime,"
    ],
    [
        "\"\"\"Return a tzinfo instance with a fixed offset from UTC.\"\"\"",
        "\"\"\"Return a tzinfo instance with a fixed"
    ],
    [
        "Return the default time zone as a tzinfo instance.",
        "Return the default time zone as"
    ],
    [
        "This is the time zone defined by settings.TIME_ZONE.",
        "This is the time"
    ],
    [
        "\"\"\"Return the name of the default time zone.\"\"\"",
        "\"\"\"Return the name of the default time"
    ],
    [
        "\"\"\"Return the currently active time zone as a tzinfo instance.\"\"\"",
        "\"\"\"Return the currently active time zone as a tzinfo"
    ],
    [
        "\"\"\"Return the name of the currently active time zone.\"\"\"",
        "\"\"\"Return the name of the currently active"
    ],
    [
        "Return the offset for fixed offset timezones, or the name of timezone if",
        "Return the offset for fixed offset timezones, or the name of timezone"
    ],
    [
        "Set the time zone for the current thread.",
        "Set the time zone"
    ],
    [
        "The ``timezone`` argument must be an instance of a tzinfo subclass or a",
        "The ``timezone`` argument must be an instance of"
    ],
    [
        "raise ValueError(\"Invalid timezone: %r\" % timezone)",
        "raise ValueError(\"Invalid timezone: %r\" %"
    ],
    [
        "Unset the time zone for the current thread.",
        "Unset the time zone for"
    ],
    [
        "Django will then use the time zone defined by settings.TIME_ZONE.",
        "Django will then use the time zone"
    ],
    [
        "Temporarily set the time zone for the current thread.",
        "Temporarily set the time zone for the current"
    ],
    [
        "This is a context manager that uses django.utils.timezone.activate()",
        "This is a context"
    ],
    [
        "to set the timezone on entry and restores the previously active timezone",
        "to set the timezone on entry and restores"
    ],
    [
        "The ``timezone`` argument must be an instance of a ``tzinfo`` subclass, a",
        "The ``timezone`` argument must be an instance"
    ],
    [
        "time zone name, or ``None``. If it is ``None``, Django enables the default",
        "time zone name, or ``None``. If it is"
    ],
    [
        "Check if value is a datetime and converts it to local time if necessary.",
        "Check if value is a datetime and"
    ],
    [
        "If use_tz is provided and is not None, that will force the value to",
        "If use_tz is provided and is not None,"
    ],
    [
        "be converted (or not), overriding the value of settings.USE_TZ.",
        "be converted (or not), overriding the value of"
    ],
    [
        "This function is designed for use by the template engine.",
        "This function is designed for use by the"
    ],
    [
        "and (settings.USE_TZ if use_tz is None else use_tz)",
        "and (settings.USE_TZ if use_tz is"
    ],
    [
        "return localtime(value) if should_convert else value",
        "return localtime(value) if should_convert"
    ],
    [
        "Convert an aware datetime.datetime to local time.",
        "Convert an aware datetime.datetime to"
    ],
    [
        "Only aware datetimes are allowed. When value is omitted, it defaults to",
        "Only aware datetimes are allowed. When value is omitted, it defaults"
    ],
    [
        "Local time is defined by the current time zone, unless another time zone",
        "Local time is defined by the current time zone, unless another time"
    ],
    [
        "raise ValueError(\"localtime() cannot be applied to a naive datetime\")",
        "raise ValueError(\"localtime() cannot be applied to"
    ],
    [
        "Convert an aware datetime to local time and return the value's date.",
        "Convert an aware datetime to local time and return the"
    ],
    [
        "Only aware datetimes are allowed. When value is omitted, it defaults to",
        "Only aware datetimes are allowed. When value is omitted, it defaults"
    ],
    [
        "Local time is defined by the current time zone, unless another time zone is",
        "Local time is defined by the current time zone, unless another"
    ],
    [
        "Return an aware or naive datetime.datetime, depending on settings.USE_TZ.",
        "Return an aware or naive datetime.datetime, depending on"
    ],
    [
        "return datetime.now(tz=timezone.utc if settings.USE_TZ else None)",
        "return datetime.now(tz=timezone.utc if"
    ],
    [
        "Determine if a given datetime.datetime is aware.",
        "Determine if a given datetime.datetime is"
    ],
    [
        "The concept is defined in Python's docs:",
        "The concept is defined in Python's"
    ],
    [
        "Assuming value.tzinfo is either None or a proper datetime.tzinfo,",
        "Assuming value.tzinfo is either None"
    ],
    [
        "Determine if a given datetime.datetime is naive.",
        "Determine if a given"
    ],
    [
        "The concept is defined in Python's docs:",
        "The concept is defined in"
    ],
    [
        "Assuming value.tzinfo is either None or a proper datetime.tzinfo,",
        "Assuming value.tzinfo is either None or a proper"
    ],
    [
        "\"\"\"Make a naive datetime.datetime in a given time zone aware.\"\"\"",
        "\"\"\"Make a naive datetime.datetime in a given time zone"
    ],
    [
        "raise ValueError(\"make_aware expects a naive datetime, got %s\" % value)",
        "raise ValueError(\"make_aware expects a naive datetime, got"
    ],
    [
        "\"\"\"Make an aware datetime.datetime naive in a given time zone.\"\"\"",
        "\"\"\"Make an aware datetime.datetime naive in"
    ],
    [
        "raise ValueError(\"make_naive() cannot be applied to a naive datetime\")",
        "raise ValueError(\"make_naive() cannot be applied to a"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "Raise ValidationError if the address is invalid.",
        "Raise ValidationError if the address is"
    ],
    [
        "Replace the longest continuous zero-sequence with \"::\", remove leading",
        "Replace the longest continuous zero-sequence with \"::\","
    ],
    [
        "zeroes, and make sure all hextets are lowercase.",
        "zeroes, and make sure all hextets are"
    ],
    [
        "error_message: An error message used in the ValidationError.",
        "error_message: An error message used in the"
    ],
    [
        "from importlib.util import find_spec as importlib_find",
        "from importlib.util import find_spec as"
    ],
    [
        "and (spec := getattr(module, \"__spec__\", None))",
        "and (spec :="
    ],
    [
        "and getattr(spec, \"_initializing\", False) is False",
        "and getattr(spec, \"_initializing\","
    ],
    [
        "Import a dotted module path and return the attribute/class designated by the",
        "Import a dotted module path and return the"
    ],
    [
        "last name in the path. Raise ImportError if the import failed.",
        "last name in the path. Raise ImportError if the import"
    ],
    [
        "raise ImportError(\"%s doesn't look like a module path\" % dotted_path) from err",
        "raise ImportError(\"%s doesn't look like a module path\" % dotted_path) from"
    ],
    [
        "'Module \"%s\" does not define a \"%s\" attribute/class'",
        "'Module \"%s\" does not define"
    ],
    [
        "Auto-discover INSTALLED_APPS modules and fail silently when",
        "Auto-discover INSTALLED_APPS modules and fail"
    ],
    [
        "not present. This forces an import on them to register any admin bits they",
        "not present. This forces an import on them to register"
    ],
    [
        "You may provide a register_to keyword parameter as a way to access a",
        "You may provide a register_to keyword parameter as a way to"
    ],
    [
        "registry. This register_to object must have a _registry instance variable",
        "registry. This register_to object must"
    ],
    [
        "\"\"\"See if 'module' is in 'package'.\"\"\"",
        "\"\"\"See if 'module' is in"
    ],
    [
        "full_module_name = package_name + \".\" + module_name",
        "full_module_name = package_name +"
    ],
    [
        "return importlib_find(full_module_name, package_path) is not None",
        "return importlib_find(full_module_name, package_path) is not"
    ],
    [
        "Find the name of the directory that contains a module, if possible.",
        "Find the name of the directory that"
    ],
    [
        "Raise ValueError otherwise, e.g. for namespace packages that are split",
        "Raise ValueError otherwise, e.g. for namespace packages that are"
    ],
    [
        "raise ValueError(\"Cannot determine directory containing %s\" % module)",
        "raise ValueError(\"Cannot determine directory containing"
    ],
    [
        "\"\"\"Parse a string and return a datetime.date.",
        "\"\"\"Parse a string and return a"
    ],
    [
        "Raise ValueError if the input is well formatted but not a valid date.",
        "Raise ValueError if the input is well formatted but not a"
    ],
    [
        "Return None if the input isn't well formatted.",
        "Return None if the input isn't"
    ],
    [
        "kw = {k: int(v) for k, v in match.groupdict().items()}",
        "kw = {k: int(v) for k,"
    ],
    [
        "\"\"\"Parse a string and return a datetime.time.",
        "\"\"\"Parse a string and return a"
    ],
    [
        "This function doesn't support time zone offsets.",
        "This function doesn't support time zone"
    ],
    [
        "Raise ValueError if the input is well formatted but not a valid time.",
        "Raise ValueError if the input is well formatted but not a"
    ],
    [
        "Return None if the input isn't well formatted, in particular if it",
        "Return None if the input isn't well formatted, in"
    ],
    [
        "kw = {k: int(v) for k, v in kw.items() if v is not None}",
        "kw = {k: int(v) for k, v"
    ],
    [
        "\"\"\"Parse a string and return a datetime.datetime.",
        "\"\"\"Parse a string and return a"
    ],
    [
        "This function supports time zone offsets. When the input contains one,",
        "This function supports time zone offsets. When the input contains"
    ],
    [
        "the output uses a timezone with a fixed offset from UTC.",
        "the output uses a timezone with a fixed offset from"
    ],
    [
        "Raise ValueError if the input is well formatted but not a valid datetime.",
        "Raise ValueError if the input is well"
    ],
    [
        "Return None if the input isn't well formatted.",
        "Return None if the input"
    ],
    [
        "kw = {k: int(v) for k, v in kw.items() if v is not None}",
        "kw = {k: int(v) for k, v in"
    ],
    [
        "\"\"\"Parse a duration string and return a datetime.timedelta.",
        "\"\"\"Parse a duration string and"
    ],
    [
        "The preferred format for durations in Django is '%d %H:%M:%S.%f'.",
        "The preferred format for durations in Django"
    ],
    [
        "kw = {k: float(v.replace(\",\", \".\")) for k, v in kw.items() if v is not None}",
        "kw = {k: float(v.replace(\",\", \".\")) for k, v in kw.items() if"
    ],
    [
        "return days + sign * datetime.timedelta(**kw)",
        "return days + sign"
    ],
    [
        "\"Convenience method for adding an element with no children\"",
        "\"Convenience method for adding an element with no"
    ],
    [
        "sorted_attrs = dict(sorted(attrs.items())) if attrs else attrs",
        "sorted_attrs = dict(sorted(attrs.items())) if attrs else"
    ],
    [
        "\"Functions that help with dynamically creating decorators for views.\"",
        "\"Functions that help with dynamically creating decorators"
    ],
    [
        "from functools import partial, update_wrapper, wraps",
        "from functools import partial, update_wrapper,"
    ],
    [
        "\"This method is available only on the class, not on instances.\"",
        "\"This method is available only on"
    ],
    [
        "Decorate `method` with one or more function decorators. `decorators` can be",
        "Decorate `method` with one or more function decorators. `decorators`"
    ],
    [
        "a single decorator or an iterable of decorators.",
        "a single decorator or an iterable of"
    ],
    [
        "Convert a function decorator into a method decorator",
        "Convert a function decorator into a method"
    ],
    [
        "if not (name and hasattr(obj, name)):",
        "if not (name and hasattr(obj,"
    ],
    [
        "\"The keyword argument `name` must be the name of a method \"",
        "\"The keyword argument `name` must be the name of a"
    ],
    [
        "\"of the decorated class: %s. Got '%s' instead.\" % (obj, name)",
        "\"of the decorated class: %s. Got '%s' instead.\""
    ],
    [
        "\"Cannot decorate '%s' as it isn't a callable attribute of \"",
        "\"Cannot decorate '%s' as it isn't a callable attribute"
    ],
    [
        "\"%s (%s).\" % (name, obj, method)",
        "\"%s (%s).\" %"
    ],
    [
        "obj = decorator if hasattr(decorator, \"__name__\") else decorator.__class__",
        "obj = decorator if"
    ],
    [
        "Like decorator_from_middleware, but return a function",
        "Like decorator_from_middleware, but return"
    ],
    [
        "that accepts the arguments to be passed to the middleware_class.",
        "that accepts the arguments to be"
    ],
    [
        "Given a middleware class (not an instance), return a view decorator. This",
        "Given a middleware class (not an instance), return"
    ],
    [
        "lets you use middleware functionality on a per-view basis. The middleware",
        "lets you use middleware functionality on"
    ],
    [
        "is created with no params passed.",
        "is created with no"
    ],
    [
        "result = middleware.process_view(request, view_func, args, kwargs)",
        "result = middleware.process_view(request, view_func,"
    ],
    [
        "response = await view_func(request, *args, **kwargs)",
        "response = await"
    ],
    [
        "Mark a middleware factory as returning a hybrid middleware supporting both",
        "Mark a middleware factory as returning"
    ],
    [
        "Mark a middleware factory as returning a sync middleware.",
        "Mark a middleware factory as returning a sync"
    ],
    [
        "\"\"\"Mark a middleware factory as returning an async middleware.\"\"\"",
        "\"\"\"Mark a middleware factory as returning an"
    ],
    [
        "Reset global state when LANGUAGES setting has been changed, as some",
        "Reset global state when LANGUAGES setting"
    ],
    [
        "languages should no longer be accepted.",
        "languages should no"
    ],
    [
        "Simulate a dict for DjangoTranslation._catalog so as multiple catalogs",
        "Simulate a dict for DjangoTranslation._catalog so"
    ],
    [
        "with different plural equations are kept separate.",
        "with different plural equations"
    ],
    [
        "self._catalogs = [trans._catalog.copy()] if trans else [{}]",
        "self._catalogs = [trans._catalog.copy()] if trans"
    ],
    [
        "return any(key in cat for cat in self._catalogs)",
        "return any(key in cat for cat in"
    ],
    [
        "for cat, plural in zip(self._catalogs, self._plurals):",
        "for cat, plural in zip(self._catalogs,"
    ],
    [
        "Set up the GNUTranslations context with regard to output charset.",
        "Set up the GNUTranslations context with regard"
    ],
    [
        "This translation object will be constructed out of multiple GNUTranslations",
        "This translation object will be constructed"
    ],
    [
        "objects by merging their catalogs. It will construct an object for the",
        "objects by merging their catalogs. It will construct an"
    ],
    [
        "requested language and add a fallback to the default language, if it's",
        "requested language and add a fallback to the default"
    ],
    [
        "\"\"\"Create a GNUTranslations() using many locale directories\"\"\"",
        "\"\"\"Create a GNUTranslations() using many"
    ],
    [
        "\"localedirs is ignored when domain is 'django'.\", RuntimeWarning",
        "\"localedirs is ignored when"
    ],
    [
        "\"No translation files found for default language %s.\"",
        "\"No translation files found for default"
    ],
    [
        "A convenience wrapper. By default gettext uses 'fallback=False'.",
        "A convenience wrapper. By default gettext uses"
    ],
    [
        "Using param `use_null_fallback` to avoid confusion with any other",
        "Using param `use_null_fallback` to avoid confusion with"
    ],
    [
        "\"\"\"Create a base catalog using global django translations.\"\"\"",
        "\"\"\"Create a base catalog using global django"
    ],
    [
        "\"\"\"Merge translations from each installed app.\"\"\"",
        "\"\"\"Merge translations from each installed"
    ],
    [
        "\"The translation infrastructure cannot be initialized before the \"",
        "\"The translation infrastructure cannot be"
    ],
    [
        "\"apps registry is ready. Check that you don't make non-lazy \"",
        "\"apps registry is ready. Check that you don't make"
    ],
    [
        "\"\"\"Set the GNUTranslations() fallback with the default language.\"\"\"",
        "\"\"\"Set the GNUTranslations() fallback with"
    ],
    [
        "if self.__language == settings.LANGUAGE_CODE or self.__language.startswith(",
        "if self.__language =="
    ],
    [
        "\"\"\"Merge another translation into this catalog.\"\"\"",
        "\"\"\"Merge another translation into"
    ],
    [
        "Return a translation object in the default 'django' domain.",
        "Return a translation object in the default"
    ],
    [
        "Fetch the translation object for a given language and install it as the",
        "Fetch the translation object for a given language and install"
    ],
    [
        "current translation object for the current thread.",
        "current translation object for the current"
    ],
    [
        "Uninstall the active translation object so that further _() calls resolve",
        "Uninstall the active translation object so that further"
    ],
    [
        "Make the active translation object a NullTranslations() instance. This is",
        "Make the active translation object a NullTranslations() instance. This"
    ],
    [
        "useful when we want delayed translations to appear as the original string",
        "useful when we want delayed translations to appear as the original"
    ],
    [
        "Return the current active catalog for further processing.",
        "Return the current active catalog"
    ],
    [
        "This can be used if you need to modify the catalog or want to access the",
        "This can be used if you need to modify the catalog or want"
    ],
    [
        "whole message catalog instead of just translating one string.",
        "whole message catalog instead of just translating"
    ],
    [
        "Translate the 'message' string. It uses the current thread to find the",
        "Translate the 'message' string. It uses the current thread to"
    ],
    [
        "translation object to use. If no current translation is activated, the",
        "translation object to use. If no current translation"
    ],
    [
        "message will be run through the default translation object.",
        "message will be run through the default"
    ],
    [
        "msg_with_ctxt = \"%s%s%s\" % (context, CONTEXT_SEPARATOR, message)",
        "msg_with_ctxt = \"%s%s%s\" %"
    ],
    [
        "Mark strings for translation but don't translate them now. This can be",
        "Mark strings for translation but don't"
    ],
    [
        "used to store strings in global variables that should stay in the base",
        "used to store strings in global variables that"
    ],
    [
        "language (because they might be used externally) and will be translated",
        "language (because they might be used externally) and"
    ],
    [
        "Return a string of the translation of either the singular or plural,",
        "Return a string of the translation of either the singular"
    ],
    [
        "Return a list of paths to user-provides languages files.",
        "Return a list of paths to user-provides"
    ],
    [
        "Check whether there is a global language file for the given language",
        "Check whether there is a global language file"
    ],
    [
        "code. This is used to decide whether a user-provided language is",
        "code. This is used to decide"
    ],
    [
        "lru_cache should have a maxsize to prevent from memory exhaustion attacks,",
        "lru_cache should have a maxsize to prevent from memory"
    ],
    [
        "as the provided language codes are taken from the HTTP request. See also",
        "as the provided language codes are taken from"
    ],
    [
        "if lang_code is None or not language_code_re.search(lang_code):",
        "if lang_code is None or"
    ],
    [
        "gettext_module.find(\"django\", path, [to_locale(lang_code)]) is not None",
        "gettext_module.find(\"django\", path, [to_locale(lang_code)]) is not"
    ],
    [
        "Cache of settings.LANGUAGES in a dictionary for easy lookups by key.",
        "Cache of settings.LANGUAGES in a dictionary"
    ],
    [
        "Convert keys to lowercase as they should be treated as case-insensitive.",
        "Convert keys to lowercase as they should be"
    ],
    [
        "return {key.lower(): value for key, value in dict(settings.LANGUAGES).items()}",
        "return {key.lower(): value for key,"
    ],
    [
        "Return the language code that's listed in supported languages, possibly",
        "Return the language code that's listed"
    ],
    [
        "selecting a more generic variant. Raise LookupError if nothing is found.",
        "selecting a more generic variant. Raise"
    ],
    [
        "If `strict` is False (the default), look for a country-specific variant",
        "If `strict` is False (the default), look for"
    ],
    [
        "when neither the language code nor its generic variant is found.",
        "when neither the language code nor"
    ],
    [
        "The language code is truncated to a maximum length to avoid potential",
        "The language code is truncated to a maximum length"
    ],
    [
        "lru_cache should have a maxsize to prevent from memory exhaustion attacks,",
        "lru_cache should have a maxsize to prevent"
    ],
    [
        "as the provided language codes are taken from the HTTP request. See also",
        "as the provided language codes are taken"
    ],
    [
        "if code.lower() in supported_lang_codes and check_for_language(code):",
        "if code.lower() in supported_lang_codes and"
    ],
    [
        "Return the language code if there's a valid language code found in `path`.",
        "Return the language code if there's a valid language code"
    ],
    [
        "If `strict` is False (the default), look for a country-specific variant",
        "If `strict` is False (the default), look"
    ],
    [
        "when neither the language code nor its generic variant is found.",
        "when neither the language code nor"
    ],
    [
        "Analyze the request to find what language the user wants the system to",
        "Analyze the request to find what language the user wants the system"
    ],
    [
        "show. Only languages listed in settings.LANGUAGES are taken into account.",
        "show. Only languages listed in settings.LANGUAGES are"
    ],
    [
        "If the user requests a sublanguage where we have a main language, we send",
        "If the user requests a sublanguage where we have a main"
    ],
    [
        "If check_path is True, the URL path prefix will be checked for a language",
        "If check_path is True, the URL path prefix"
    ],
    [
        "code, otherwise this is skipped for backwards compatibility.",
        "code, otherwise this is skipped"
    ],
    [
        "Parse the lang_string, which is the body of an HTTP Accept-Language",
        "Parse the lang_string, which is the body of"
    ],
    [
        "header, and return a tuple of (lang, q-value), ordered by 'q' values.",
        "header, and return a tuple of (lang, q-value),"
    ],
    [
        "Return an empty tuple if there are any format errors in lang_string.",
        "Return an empty tuple if there"
    ],
    [
        "Parse the value of the Accept-Language header up to a maximum length.",
        "Parse the value of the Accept-Language header up to a maximum"
    ],
    [
        "The value of the header is truncated to a maximum length to avoid potential",
        "The value of the header is truncated to a maximum length to avoid"
    ],
    [
        "denial of service and memory exhaustion attacks. Excessive memory could be",
        "denial of service and memory exhaustion attacks. Excessive memory could"
    ],
    [
        "used if the raw value is very large as it would be cached due to the use of",
        "used if the raw value is very large as it would"
    ],
    [
        "functools.lru_cache() to avoid repetitive parsing of common header values.",
        "functools.lru_cache() to avoid repetitive parsing of common header"
    ],
    [
        "\"\"\"Register file watchers for .mo files in potential locale paths.\"\"\"",
        "\"\"\"Register file watchers for .mo files in potential locale"
    ],
    [
        "\"\"\"Clear the internal translations cache if a .mo file is modified.\"\"\"",
        "\"\"\"Clear the internal translations cache if a .mo file is"
    ],
    [
        "gettext_noop = gettext_lazy = _ = gettext",
        "gettext_noop = gettext_lazy = _"
    ],
    [
        "if lang_code and lang_code.lower() == settings.LANGUAGE_CODE.lower():",
        "if lang_code and lang_code.lower() =="
    ],
    [
        "The purpose of this class is to store the actual translation function upon",
        "The purpose of this class is to store the actual translation"
    ],
    [
        "receiving the first call to that function. After this is done, changes to",
        "receiving the first call to that function. After this is"
    ],
    [
        "Note that storing the function with setattr will have a noticeable",
        "Note that storing the function with"
    ],
    [
        "performance effect, as access to the function goes the normal path,",
        "performance effect, as access to the function goes the normal"
    ],
    [
        "from django.utils.translation import trans_real as trans",
        "from django.utils.translation import"
    ],
    [
        "from django.utils.translation import trans_null as trans",
        "from django.utils.translation import trans_null as"
    ],
    [
        "\"Your dictionary lacks key '%s'. Please provide \"",
        "\"Your dictionary lacks key '%s'. Please"
    ],
    [
        "\"it, because it is required to determine whether \"",
        "\"it, because it is required to determine"
    ],
    [
        "\"string is singular or plural.\" % number",
        "\"string is singular or plural.\""
    ],
    [
        "proxy = lazy(lambda **kwargs: NumberAwareString(), NumberAwareString)(**kwargs)",
        "proxy = lazy(lambda **kwargs:"
    ],
    [
        "return lazy_number(ngettext, str, singular=singular, plural=plural, number=number)",
        "return lazy_number(ngettext, str, singular=singular,"
    ],
    [
        "npgettext, str, context=context, singular=singular, plural=plural, number=number",
        "npgettext, str, context=context, singular=singular, plural=plural,"
    ],
    [
        "\"\"\"Turn a locale name (en_US) into a language name (en-us).\"\"\"",
        "\"\"\"Turn a locale name (en_US)"
    ],
    [
        "\"\"\"Turn a language name (en-us) into a locale name (en_US).\"\"\"",
        "\"\"\"Turn a language name (en-us) into a"
    ],
    [
        "return lang + \"_\" + country",
        "return lang + \"_\""
    ],
    [
        "if \"fallback\" in lang_info and \"name\" not in lang_info:",
        "if \"fallback\" in lang_info and \"name\""
    ],
    [
        "raise KeyError(\"Unknown language code %s.\" % lang_code)",
        "raise KeyError(\"Unknown language code %s.\""
    ],
    [
        "\"Unknown language code %s and %s.\" % (lang_code, generic_lang_code)",
        "\"Unknown language code %s and %s.\" % (lang_code,"
    ],
    [
        "Change every non-whitespace character to the given char.",
        "Change every non-whitespace character"
    ],
    [
        "Turn a Django template into something that is understood by xgettext. It",
        "Turn a Django template into something that is understood by xgettext."
    ],
    [
        "does so by translating the Django translation tags into standard gettext",
        "does so by translating the Django"
    ],
    [
        "if t.token_type == TokenType.BLOCK and t.contents == \"endcomment\":",
        "if t.token_type == TokenType.BLOCK and"
    ],
    [
        "filemsg = \"file %s, \" % origin",
        "filemsg = \"file %s,"
    ],
    [
        "\"Translation blocks must not include other block tags: \"",
        "\"Translation blocks must not include other block"
    ],
    [
        "\"%s (%sline %d)\" % (t.contents, filemsg, t.lineno)",
        "\"%s (%sline %d)\" % (t.contents,"
    ],
    [
        "filemsg = \"file %s, \" % origin",
        "filemsg = \"file %s,"
    ],
    [
        "\"(%sline %d) was ignored, because it wasn't \"",
        "\"(%sline %d) was ignored, because"
    ],
    [
        "\"the last item on the line.\"",
        "\"the last item"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "from django.utils.timezone import get_default_timezone, is_naive, make_aware",
        "from django.utils.timezone import get_default_timezone,"
    ],
    [
        "protocol = \"https\" if secure else \"http\"",
        "protocol = \"https\" if secure"
    ],
    [
        "url = \"%s:%s\" % (protocol, url)",
        "url = \"%s:%s\" % (protocol,"
    ],
    [
        "url = iri_to_uri(\"%s://%s%s\" % (protocol, domain, url))",
        "url = iri_to_uri(\"%s://%s%s\" %"
    ],
    [
        "if hasattr(self, \"item_pubdate\") or hasattr(self, \"item_updateddate\"):",
        "if hasattr(self, \"item_pubdate\") or"
    ],
    [
        "\"Give your %s class a get_absolute_url() method, or define an \"",
        "\"Give your %s class a get_absolute_url() method, or define an"
    ],
    [
        "\"item_link() method in your Feed class.\" % item.__class__.__name__",
        "\"item_link() method in your Feed class.\" %"
    ],
    [
        "if not code.co_argcount and not isinstance(",
        "if not code.co_argcount and"
    ],
    [
        "f\"Feed method {attname!r} decorated by {func.__name__!r} needs to \"",
        "f\"Feed method {attname!r} decorated by {func.__name__!r} needs to"
    ],
    [
        "Return an extra keyword arguments dictionary that is used when",
        "Return an extra keyword arguments dictionary"
    ],
    [
        "Return an extra keyword arguments dictionary that is used with",
        "Return an extra keyword arguments dictionary that is"
    ],
    [
        "the `add_item` call of the feed generator.",
        "the `add_item` call of the"
    ],
    [
        "Return a dictionary to use as extra context if either",
        "Return a dictionary to use as extra"
    ],
    [
        "Default implementation preserves the old behavior",
        "Default implementation preserves the"
    ],
    [
        "of using {'obj': item, 'site': current_site} as the context.",
        "of using {'obj': item, 'site': current_site} as the"
    ],
    [
        "Return a feedgenerator.DefaultFeed object, fully populated, for",
        "Return a feedgenerator.DefaultFeed object,"
    ],
    [
        "this feed. Raise FeedDoesNotExist for invalid parameters.",
        "this feed. Raise FeedDoesNotExist"
    ],
    [
        "def assertMessages(self, response, expected_messages, *, ordered=True):",
        "def assertMessages(self, response,"
    ],
    [
        "assertion = self.assertEqual if ordered else self.assertCountEqual",
        "assertion = self.assertEqual if ordered else"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "def add_message(request, level, message, extra_tags=\"\", fail_silently=False):",
        "def add_message(request, level, message, extra_tags=\"\","
    ],
    [
        "Attempt to add a message to the request using the 'messages' app.",
        "Attempt to add a message to"
    ],
    [
        "\"add_message() argument must be an HttpRequest object, not \"",
        "\"add_message() argument must be an"
    ],
    [
        "\"You cannot add messages without installing \"",
        "\"You cannot add messages without"
    ],
    [
        "Return the message storage on the request if it exists, otherwise return",
        "Return the message storage on the request if it"
    ],
    [
        "Return the minimum level of messages to be recorded.",
        "Return the minimum level of messages to be"
    ],
    [
        "The default level is the ``MESSAGE_LEVEL`` setting. If this is not found,",
        "The default level is the ``MESSAGE_LEVEL`` setting. If this is not"
    ],
    [
        "Set the minimum level of messages to be recorded, and return ``True`` if",
        "Set the minimum level of messages to be recorded, and return ``True``"
    ],
    [
        "If set to ``None``, use the default level (see the get_level() function).",
        "If set to ``None``, use the default level (see the get_level()"
    ],
    [
        "\"\"\"Add a message with the ``DEBUG`` level.\"\"\"",
        "\"\"\"Add a message with the ``DEBUG``"
    ],
    [
        "\"\"\"Add a message with the ``INFO`` level.\"\"\"",
        "\"\"\"Add a message with the"
    ],
    [
        "\"\"\"Add a message with the ``SUCCESS`` level.\"\"\"",
        "\"\"\"Add a message with"
    ],
    [
        "\"\"\"Add a message with the ``WARNING`` level.\"\"\"",
        "\"\"\"Add a message with the ``WARNING``"
    ],
    [
        "\"\"\"Add a message with the ``ERROR`` level.\"\"\"",
        "\"\"\"Add a message with the"
    ],
    [
        "Return a lazy 'messages' context variable as well as",
        "Return a lazy 'messages' context variable"
    ],
    [
        "Update the storage backend (i.e., save the messages).",
        "Update the storage backend"
    ],
    [
        "Raise ValueError if not all messages could be stored and DEBUG is True.",
        "Raise ValueError if not all messages could be stored and"
    ],
    [
        "raise ValueError(\"Not all temporary messages could be stored.\")",
        "raise ValueError(\"Not all temporary"
    ],
    [
        "Add a success message on successful form submission.",
        "Add a success message on successful"
    ],
    [
        "Store messages in the session (that is, django.contrib.sessions).",
        "Store messages in the session (that is,"
    ],
    [
        "\"The session-based temporary message storage requires session \"",
        "\"The session-based temporary message storage requires"
    ],
    [
        "\"middleware to be installed, and come before the message \"",
        "\"middleware to be installed, and"
    ],
    [
        "Retrieve a list of messages from the request's session. This storage",
        "Retrieve a list of messages from the request's session."
    ],
    [
        "always stores everything it is given, so return True for the",
        "always stores everything it is given, so return True for"
    ],
    [
        "def _store(self, messages, response, *args, **kwargs):",
        "def _store(self, messages, response,"
    ],
    [
        "Store a list of messages to the request's session.",
        "Store a list of messages to"
    ],
    [
        "Callable with the same interface as the storage classes.",
        "Callable with the same interface as"
    ],
    [
        "This isn't just default_storage = import_string(settings.MESSAGE_STORAGE)",
        "This isn't just default_storage ="
    ],
    [
        "to avoid accessing the settings at the module level.",
        "to avoid accessing the settings"
    ],
    [
        "Compactly serialize instances of the ``Message`` class as JSON.",
        "Compactly serialize instances of the"
    ],
    [
        "message = [self.message_key, is_safedata, obj.level, obj.message]",
        "message = [self.message_key,"
    ],
    [
        "Decode JSON that includes serialized ``Message`` instances.",
        "Decode JSON that includes"
    ],
    [
        "return [self.process_messages(item) for item in obj]",
        "return [self.process_messages(item) for item in"
    ],
    [
        "return {key: self.process_messages(value) for key, value in obj.items()}",
        "return {key: self.process_messages(value) for key, value in"
    ],
    [
        "The parameter is an already serialized list of Message objects. No need",
        "The parameter is an already serialized list of"
    ],
    [
        "to serialize it again, only join the list together and encode it.",
        "to serialize it again, only join"
    ],
    [
        "Retrieve a list of messages from the messages cookie. If the",
        "Retrieve a list of messages from the messages"
    ],
    [
        "not_finished sentinel value is found at the end of the message list,",
        "not_finished sentinel value is found at the end"
    ],
    [
        "remove it and return a result indicating that not all messages were",
        "remove it and return a result indicating that"
    ],
    [
        "Either set the cookie with the encoded data if there is any data to",
        "Either set the cookie with the encoded data if there is any data"
    ],
    [
        "def _store(self, messages, response, remove_oldest=True, *args, **kwargs):",
        "def _store(self, messages, response, remove_oldest=True,"
    ],
    [
        "Store the messages to a cookie and return a list of any messages which",
        "Store the messages to a cookie and return a list of any"
    ],
    [
        "If the encoded data is larger than ``max_cookie_size``, remove",
        "If the encoded data is larger"
    ],
    [
        "messages until the data fits (these are the messages which are",
        "messages until the data fits (these are the messages"
    ],
    [
        "returned), and add the not_finished sentinel value to indicate as much.",
        "returned), and add the not_finished sentinel value to indicate as"
    ],
    [
        "Return an encoded version of the serialized messages list which can be",
        "Return an encoded version of the serialized"
    ],
    [
        "Since the data will be retrieved from the client-side, the encoded data",
        "Since the data will be retrieved from"
    ],
    [
        "also contains a hash to ensure that the data was not tampered with.",
        "also contains a hash to ensure that the data"
    ],
    [
        "Return an encoded version of the messages list which can be stored as",
        "Return an encoded version of the messages list which can"
    ],
    [
        "Safely decode an encoded text stream back into a list of messages.",
        "Safely decode an encoded text stream"
    ],
    [
        "If the encoded text stream contained an invalid hash or was in an",
        "If the encoded text stream contained an invalid hash"
    ],
    [
        "Find the index of the first element from the start of the array that",
        "Find the index of the first element from the start of the"
    ],
    [
        "The function is applied from the start of the array to the pivot.",
        "The function is applied from the start of the"
    ],
    [
        "Find the index of the first element from the end of the array that verifies",
        "Find the index of the first element from the end of the array"
    ],
    [
        "The function is applied from the pivot to the end of array.",
        "The function is applied from the"
    ],
    [
        "Try to store all messages in the first backend. Store any unstored",
        "Try to store all messages in the first backend."
    ],
    [
        "storage_class(*args, **kwargs) for storage_class in self.storage_classes",
        "storage_class(*args, **kwargs) for storage_class in"
    ],
    [
        "Get a single list of messages from all storage backends.",
        "Get a single list of messages from"
    ],
    [
        "def _store(self, messages, response, *args, **kwargs):",
        "def _store(self, messages, response, *args,"
    ],
    [
        "Store the messages and return any unstored messages after trying all",
        "Store the messages and return any"
    ],
    [
        "For each storage backend, any messages not stored are passed on to the",
        "For each storage backend, any messages not"
    ],
    [
        "Represent an actual message that can be stored in any of the supported",
        "Represent an actual message that can be stored in any of"
    ],
    [
        "storage classes (typically session- or cookie-based) and rendered in a view",
        "storage classes (typically session- or cookie-based) and rendered in"
    ],
    [
        "Prepare the message for serialization by forcing the ``message``",
        "Prepare the message for serialization by forcing"
    ],
    [
        "and ``extra_tags`` to str in case they are lazy translations.",
        "and ``extra_tags`` to str in case they are lazy"
    ],
    [
        "self.extra_tags = str(self.extra_tags) if self.extra_tags is not None else None",
        "self.extra_tags = str(self.extra_tags) if self.extra_tags is not"
    ],
    [
        "return self.level == other.level and self.message == other.message",
        "return self.level == other.level and self.message =="
    ],
    [
        "extra_tags = f\", extra_tags={self.extra_tags!r}\" if self.extra_tags else \"\"",
        "extra_tags = f\", extra_tags={self.extra_tags!r}\" if self.extra_tags else"
    ],
    [
        "return \" \".join(tag for tag in [self.extra_tags, self.level_tag] if tag)",
        "return \" \".join(tag for tag in [self.extra_tags,"
    ],
    [
        "This is the base backend for temporary message storage.",
        "This is the base backend for temporary"
    ],
    [
        "This is not a complete class; to be a usable storage backend, it must be",
        "This is not a complete class; to be"
    ],
    [
        "subclassed and the two methods ``_get`` and ``_store`` overridden.",
        "subclassed and the two methods ``_get`` and"
    ],
    [
        "return item in self._loaded_messages or item in self._queued_messages",
        "return item in self._loaded_messages or item"
    ],
    [
        "Return a list of loaded messages, retrieving them first if they have",
        "Return a list of loaded messages, retrieving them first"
    ],
    [
        "Retrieve a list of stored messages. Return a tuple of the messages",
        "Retrieve a list of stored messages. Return a tuple"
    ],
    [
        "and a flag indicating whether or not all the messages originally",
        "and a flag indicating whether or not all"
    ],
    [
        "intended to be stored in this storage were, in fact, stored and",
        "intended to be stored in this storage were, in fact,"
    ],
    [
        "**This method must be implemented by a subclass.**",
        "**This method must be implemented"
    ],
    [
        "If it is possible to tell if the backend was not used (as opposed to",
        "If it is possible to tell if the backend was not used (as opposed"
    ],
    [
        "just containing no messages) then ``None`` should be returned in",
        "just containing no messages) then ``None``"
    ],
    [
        "\"subclasses of BaseStorage must provide a _get() method\"",
        "\"subclasses of BaseStorage must provide"
    ],
    [
        "def _store(self, messages, response, *args, **kwargs):",
        "def _store(self, messages,"
    ],
    [
        "Store a list of messages and return a list of any messages which could",
        "Store a list of messages and return a list of any messages which"
    ],
    [
        "One type of object must be able to be stored, ``Message``.",
        "One type of object must be able to be"
    ],
    [
        "**This method must be implemented by a subclass.**",
        "**This method must be implemented by"
    ],
    [
        "\"subclasses of BaseStorage must provide a _store() method\"",
        "\"subclasses of BaseStorage must provide a _store()"
    ],
    [
        "Prepare a list of messages for storage.",
        "Prepare a list of"
    ],
    [
        "If the backend has yet to be iterated, store previously stored messages",
        "If the backend has yet to be"
    ],
    [
        "again. Otherwise, only store messages added after the last iteration.",
        "again. Otherwise, only store messages added after"
    ],
    [
        "Queue a message to be stored.",
        "Queue a message to be"
    ],
    [
        "The message is only queued if it contained something and its level is",
        "The message is only queued if it contained"
    ],
    [
        "not less than the recording level (``self.level``).",
        "not less than the"
    ],
    [
        "The default level is the ``MESSAGE_LEVEL`` setting. If this is",
        "The default level is the ``MESSAGE_LEVEL``"
    ],
    [
        "not found, the ``INFO`` level is used.",
        "not found, the ``INFO``"
    ],
    [
        "Set a custom minimum recorded level.",
        "Set a custom"
    ],
    [
        "If set to ``None``, the default level will be used (see the",
        "If set to ``None``, the default level"
    ],
    [
        "if value is None and hasattr(self, \"_level\"):",
        "if value is None and"
    ],
    [
        "Abstract CBV mixin that gives access mixins the same customizable",
        "Abstract CBV mixin that gives access"
    ],
    [
        "Override this method to override the login_url attribute.",
        "Override this method to override the"
    ],
    [
        "f\"{self.__class__.__name__} is missing the login_url attribute. Define \"",
        "f\"{self.__class__.__name__} is missing the login_url attribute."
    ],
    [
        "Override this method to override the permission_denied_message attribute.",
        "Override this method to override the permission_denied_message"
    ],
    [
        "Override this method to override the redirect_field_name attribute.",
        "Override this method to override the"
    ],
    [
        "if (not login_scheme or login_scheme == current_scheme) and (",
        "if (not login_scheme or login_scheme"
    ],
    [
        "not login_netloc or login_netloc == current_netloc",
        "not login_netloc or login_netloc =="
    ],
    [
        "\"\"\"Verify that the current user is authenticated.\"\"\"",
        "\"\"\"Verify that the current user"
    ],
    [
        "\"\"\"Verify that the current user has all specified permissions.\"\"\"",
        "\"\"\"Verify that the current user has all specified"
    ],
    [
        "Override this method to override the permission_required attribute.",
        "Override this method to override"
    ],
    [
        "Override this method to customize the way permissions are checked.",
        "Override this method to customize"
    ],
    [
        "Deny a request with a permission error if the test_func() method returns",
        "Deny a request with a permission error if the"
    ],
    [
        "\"{} is missing the implementation of the test_func() method.\".format(",
        "\"{} is missing the implementation of the test_func()"
    ],
    [
        "Override this method to use a different test_func method.",
        "Override this method to use"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "\"The module in NAME could not be imported: %s. Check your \"",
        "\"The module in NAME could not"
    ],
    [
        "Validate that the password meets all validator requirements.",
        "Validate that the password"
    ],
    [
        "If the password is valid, return ``None``.",
        "If the password is valid,"
    ],
    [
        "If the password is invalid, raise ValidationError with all error messages.",
        "If the password is invalid, raise ValidationError with"
    ],
    [
        "Inform all validators that have implemented a password_changed() method",
        "Inform all validators that have"
    ],
    [
        "that the password has been changed.",
        "that the password"
    ],
    [
        "password_changed = getattr(validator, \"password_changed\", lambda *a: None)",
        "password_changed = getattr(validator, \"password_changed\", lambda"
    ],
    [
        "Return a list of all help texts of all configured validators.",
        "Return a list of all help texts of"
    ],
    [
        "Return an HTML string with all help texts of all configured validators",
        "Return an HTML string with all help texts of"
    ],
    [
        "\"\", \"<li>{}</li>\", ((help_text,) for help_text in help_texts)",
        "\"\", \"<li>{}</li>\", ((help_text,) for"
    ],
    [
        "return format_html(\"<ul>{}</ul>\", help_items) if help_items else \"\"",
        "return format_html(\"<ul>{}</ul>\", help_items) if help_items"
    ],
    [
        "Validate that the password is of a minimum length.",
        "Validate that the password is of a"
    ],
    [
        "\"This password is too short. It must contain at least %d character.\"",
        "\"This password is too short. It must"
    ],
    [
        "\"This password is too short. It must contain at least %d characters.\"",
        "\"This password is too short. It must contain at least %d"
    ],
    [
        "\"Your password must contain at least %(min_length)d character.\",",
        "\"Your password must contain"
    ],
    [
        "\"Your password must contain at least %(min_length)d characters.\",",
        "\"Your password must contain at"
    ],
    [
        "Test that value is within a reasonable range of password.",
        "Test that value is within a"
    ],
    [
        "The following ratio calculations are based on testing SequenceMatcher like",
        "The following ratio calculations are"
    ],
    [
        "Validate that the password is sufficiently different from the user's",
        "Validate that the password is sufficiently"
    ],
    [
        "If no specific attributes are provided, look at a sensible list of",
        "If no specific attributes are provided, look at a sensible list"
    ],
    [
        "defaults. Attributes that don't exist are ignored. Comparison is made to",
        "defaults. Attributes that don't exist are ignored. Comparison"
    ],
    [
        "not only the full attribute value, but also its components, so that, for",
        "not only the full attribute value, but also its components,"
    ],
    [
        "example, a password is validated against either part of an email address,",
        "example, a password is validated against either part"
    ],
    [
        "as well as the full address.",
        "as well as"
    ],
    [
        "DEFAULT_USER_ATTRIBUTES = (\"username\", \"first_name\", \"last_name\", \"email\")",
        "DEFAULT_USER_ATTRIBUTES = (\"username\", \"first_name\","
    ],
    [
        "if not value or not isinstance(value, str):",
        "if not value or not isinstance(value,"
    ],
    [
        "value_parts = re.split(r\"\\W+\", value_lower) + [value_lower]",
        "value_parts = re.split(r\"\\W+\", value_lower)"
    ],
    [
        "return _(\"The password is too similar to the %(verbose_name)s.\")",
        "return _(\"The password is too similar to the"
    ],
    [
        "\"Your password can’t be too similar to your other personal information.\"",
        "\"Your password can’t be too similar to your other"
    ],
    [
        "Validate that the password is not a common password.",
        "Validate that the password is not a common"
    ],
    [
        "The password is rejected if it occurs in a provided list of passwords,",
        "The password is rejected if it occurs in a provided"
    ],
    [
        "passwords (lowercased and deduplicated), created by Royce Williams:",
        "passwords (lowercased and deduplicated), created by"
    ],
    [
        "The password list must be lowercased to match the comparison in validate().",
        "The password list must be lowercased to match the"
    ],
    [
        "self.passwords = {x.strip() for x in f}",
        "self.passwords = {x.strip() for"
    ],
    [
        "self.passwords = {x.strip() for x in f}",
        "self.passwords = {x.strip() for x in"
    ],
    [
        "return _(\"This password is too common.\")",
        "return _(\"This password"
    ],
    [
        "return _(\"Your password can’t be a commonly used password.\")",
        "return _(\"Your password can’t be a commonly used"
    ],
    [
        "Validate that the password is not entirely numeric.",
        "Validate that the password is not entirely"
    ],
    [
        "return _(\"This password is entirely numeric.\")",
        "return _(\"This password"
    ],
    [
        "return _(\"Your password can’t be entirely numeric.\")",
        "return _(\"Your password can’t be entirely"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "A signal receiver which updates the last_login date for",
        "A signal receiver which updates"
    ],
    [
        "The permissions system provides a way to assign permissions to specific",
        "The permissions system provides a way to"
    ],
    [
        "The permission system is used by the Django admin site, but may also be",
        "The permission system is used by the Django admin site, but"
    ],
    [
        "useful in your own code. The Django admin site uses permissions as follows:",
        "useful in your own code. The Django admin site uses permissions as"
    ],
    [
        "- The \"add\" permission limits the user's ability to view the \"add\" form",
        "- The \"add\" permission limits the user's ability"
    ],
    [
        "- The \"change\" permission limits a user's ability to view the change",
        "- The \"change\" permission limits a user's ability to view"
    ],
    [
        "list, view the \"change\" form and change an object.",
        "list, view the \"change\" form and"
    ],
    [
        "- The \"delete\" permission limits the ability to delete an object.",
        "- The \"delete\" permission limits the"
    ],
    [
        "- The \"view\" permission limits the ability to view an object.",
        "- The \"view\" permission limits the ability to view an"
    ],
    [
        "Permissions are set globally per type of object, not per specific object",
        "Permissions are set globally per type of object, not per specific"
    ],
    [
        "instance. It is possible to say \"Mary may change news stories,\" but it's",
        "instance. It is possible to say \"Mary may change news stories,\""
    ],
    [
        "not currently possible to say \"Mary may change news stories, but only the",
        "not currently possible to say \"Mary may change"
    ],
    [
        "ones she created herself\" or \"Mary may only change news stories that have a",
        "ones she created herself\" or \"Mary may only change"
    ],
    [
        "The permissions listed above are automatically created for each model.",
        "The permissions listed above are automatically created"
    ],
    [
        "return \"%s | %s\" % (self.content_type, self.name)",
        "return \"%s | %s\""
    ],
    [
        "The manager for the auth's Group model.",
        "The manager for the auth's"
    ],
    [
        "Groups are a generic way of categorizing users to apply permissions, or",
        "Groups are a generic way of categorizing users to apply permissions,"
    ],
    [
        "some other label, to those users. A user can belong to any number of",
        "some other label, to those users. A user can belong"
    ],
    [
        "A user in a group automatically has all the permissions granted to that",
        "A user in a group automatically has all the"
    ],
    [
        "group. For example, if the group 'Site editors' has the permission",
        "group. For example, if the group"
    ],
    [
        "can_edit_home_page, any user in that group will have that permission.",
        "can_edit_home_page, any user in that"
    ],
    [
        "Beyond permissions, groups are a convenient way to categorize users to",
        "Beyond permissions, groups are a convenient way to"
    ],
    [
        "apply some label, or extended functionality, to them. For example, you",
        "apply some label, or extended functionality, to them. For example,"
    ],
    [
        "could create a group 'Special users', and you could write code that would",
        "could create a group 'Special users', and you could write code"
    ],
    [
        "do special things to those users -- such as giving them access to a",
        "do special things to those users -- such as giving them access to"
    ],
    [
        "members-only portion of your site, or sending them members-only email",
        "members-only portion of your site,"
    ],
    [
        "def _create_user_object(self, username, email, password, **extra_fields):",
        "def _create_user_object(self, username, email, password,"
    ],
    [
        "raise ValueError(\"The given username must be set\")",
        "raise ValueError(\"The given username must"
    ],
    [
        "def _create_user(self, username, email, password, **extra_fields):",
        "def _create_user(self, username, email,"
    ],
    [
        "Create and save a user with the given username, email, and password.",
        "Create and save a user with"
    ],
    [
        "user = self._create_user_object(username, email, password, **extra_fields)",
        "user = self._create_user_object(username, email, password,"
    ],
    [
        "async def _acreate_user(self, username, email, password, **extra_fields):",
        "async def _acreate_user(self, username,"
    ],
    [
        "user = self._create_user_object(username, email, password, **extra_fields)",
        "user = self._create_user_object(username,"
    ],
    [
        "def create_user(self, username, email=None, password=None, **extra_fields):",
        "def create_user(self, username, email=None, password=None,"
    ],
    [
        "async def acreate_user(self, username, email=None, password=None, **extra_fields):",
        "async def acreate_user(self, username,"
    ],
    [
        "return await self._acreate_user(username, email, password, **extra_fields)",
        "return await self._acreate_user(username,"
    ],
    [
        "def create_superuser(self, username, email=None, password=None, **extra_fields):",
        "def create_superuser(self, username,"
    ],
    [
        "return await self._acreate_user(username, email, password, **extra_fields)",
        "return await self._acreate_user(username, email,"
    ],
    [
        "self, perm, is_active=True, include_superusers=True, backend=None, obj=None",
        "self, perm, is_active=True, include_superusers=True, backend=None,"
    ],
    [
        "\"You have multiple authentication backends configured and \"",
        "\"You have multiple authentication backends configured"
    ],
    [
        "\"therefore must provide the `backend` argument.\"",
        "\"therefore must provide the `backend`"
    ],
    [
        "\"backend must be a dotted import path string (got %r).\" % backend",
        "\"backend must be a dotted import path string (got %r).\" %"
    ],
    [
        "A backend can raise `PermissionDenied` to short-circuit permission checking.",
        "A backend can raise `PermissionDenied` to short-circuit permission"
    ],
    [
        "A backend can raise `PermissionDenied` to short-circuit permission checking.",
        "A backend can raise `PermissionDenied`"
    ],
    [
        "Add the fields and methods necessary to support the Group and Permission",
        "Add the fields and methods necessary to support the"
    ],
    [
        "\"Designates that this user has all permissions without \"",
        "\"Designates that this user has all"
    ],
    [
        "\"The groups this user belongs to. A user will get all permissions \"",
        "\"The groups this user belongs to. A user will"
    ],
    [
        "\"granted to each of their groups.\"",
        "\"granted to each"
    ],
    [
        "Return a list of permission strings that this user has directly.",
        "Return a list of permission strings that this user has"
    ],
    [
        "Query all available auth backends. If an object is passed in,",
        "Query all available auth backends. If an"
    ],
    [
        "return only permissions matching this object.",
        "return only permissions"
    ],
    [
        "Return a list of permission strings that this user has through their",
        "Return a list of permission strings that this user has"
    ],
    [
        "groups. Query all available auth backends. If an object is passed in,",
        "groups. Query all available auth backends. If an object is"
    ],
    [
        "return only permissions matching this object.",
        "return only permissions matching this"
    ],
    [
        "Return True if the user has the specified permission. Query all",
        "Return True if the user has the specified permission. Query"
    ],
    [
        "available auth backends, but return immediately if any backend returns",
        "available auth backends, but return immediately if any backend"
    ],
    [
        "True. Thus, a user who has permission from a single auth backend is",
        "True. Thus, a user who has permission from a single auth"
    ],
    [
        "assumed to have permission in general. If an object is provided, check",
        "assumed to have permission in general. If an object"
    ],
    [
        "Return True if the user has each of the specified permissions. If",
        "Return True if the user has"
    ],
    [
        "object is passed, check if the user has all required perms for it.",
        "object is passed, check if the user has all required"
    ],
    [
        "if not isinstance(perm_list, Iterable) or isinstance(perm_list, str):",
        "if not isinstance(perm_list, Iterable)"
    ],
    [
        "raise ValueError(\"perm_list must be an iterable of permissions.\")",
        "raise ValueError(\"perm_list must be"
    ],
    [
        "return all(self.has_perm(perm, obj) for perm in perm_list)",
        "return all(self.has_perm(perm, obj) for perm"
    ],
    [
        "if not isinstance(perm_list, Iterable) or isinstance(perm_list, str):",
        "if not isinstance(perm_list, Iterable) or isinstance(perm_list,"
    ],
    [
        "raise ValueError(\"perm_list must be an iterable of permissions.\")",
        "raise ValueError(\"perm_list must be"
    ],
    [
        "Return True if the user has any permissions in the given app label.",
        "Return True if the user has any permissions in the given"
    ],
    [
        "Use similar logic as has_perm(), above.",
        "Use similar logic"
    ],
    [
        "An abstract base class implementing a fully featured User model with",
        "An abstract base class implementing a fully featured"
    ],
    [
        "Username and password are required. Other fields are optional.",
        "Username and password are required. Other fields are"
    ],
    [
        "\"unique\": _(\"A user with that username already exists.\"),",
        "\"unique\": _(\"A user with"
    ],
    [
        "help_text=_(\"Designates whether the user can log into this admin site.\"),",
        "help_text=_(\"Designates whether the user can log into this"
    ],
    [
        "\"Designates whether this user should be treated as active. \"",
        "\"Designates whether this user should be"
    ],
    [
        "\"Unselect this instead of deleting accounts.\"",
        "\"Unselect this instead of"
    ],
    [
        "Return the first_name plus the last_name, with a space in between.",
        "Return the first_name plus the last_name, with"
    ],
    [
        "full_name = \"%s %s\" % (self.first_name, self.last_name)",
        "full_name = \"%s %s\""
    ],
    [
        "\"\"\"Return the short name for the user.\"\"\"",
        "\"\"\"Return the short name"
    ],
    [
        "def email_user(self, subject, message, from_email=None, **kwargs):",
        "def email_user(self, subject,"
    ],
    [
        "\"\"\"Send an email to this user.\"\"\"",
        "\"\"\"Send an email to this"
    ],
    [
        "Users within the Django authentication system are represented by this",
        "Users within the Django authentication"
    ],
    [
        "Username and password are required. Other fields are optional.",
        "Username and password are required. Other"
    ],
    [
        "\"Cannot cast AnonymousUser to int. Are you trying to use it in place of \"",
        "\"Cannot cast AnonymousUser to int. Are you trying to use it in place of"
    ],
    [
        "\"Django doesn't provide a DB representation for AnonymousUser.\"",
        "\"Django doesn't provide a DB"
    ],
    [
        "\"Django doesn't provide a DB representation for AnonymousUser.\"",
        "\"Django doesn't provide a DB representation"
    ],
    [
        "\"Django doesn't provide a DB representation for AnonymousUser.\"",
        "\"Django doesn't provide a DB representation"
    ],
    [
        "\"Django doesn't provide a DB representation for AnonymousUser.\"",
        "\"Django doesn't provide a"
    ],
    [
        "if not isinstance(perm_list, Iterable) or isinstance(perm_list, str):",
        "if not isinstance(perm_list, Iterable)"
    ],
    [
        "raise ValueError(\"perm_list must be an iterable of permissions.\")",
        "raise ValueError(\"perm_list must be"
    ],
    [
        "return all(self.has_perm(perm, obj) for perm in perm_list)",
        "return all(self.has_perm(perm, obj) for"
    ],
    [
        "if not isinstance(perm_list, Iterable) or isinstance(perm_list, str):",
        "if not isinstance(perm_list, Iterable)"
    ],
    [
        "raise ValueError(\"perm_list must be an iterable of permissions.\")",
        "raise ValueError(\"perm_list must be an iterable"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"Enter a valid username. This value may contain only unaccented lowercase a-z \"",
        "\"Enter a valid username. This value may contain only"
    ],
    [
        "\"and uppercase A-Z letters, numbers, and @/./+/-/_ characters.\"",
        "\"and uppercase A-Z letters, numbers,"
    ],
    [
        "\"Enter a valid username. This value may contain only letters, \"",
        "\"Enter a valid username. This value"
    ],
    [
        "Return the index of dotted class path (or a subclass of that class) in a",
        "Return the index of dotted class path (or a subclass"
    ],
    [
        "\"'REQUIRED_FIELDS' must be a list or tuple.\",",
        "\"'REQUIRED_FIELDS' must be a list"
    ],
    [
        "\"The field named as the 'USERNAME_FIELD' \"",
        "\"The field named as"
    ],
    [
        "\"for a custom user model must not be included in 'REQUIRED_FIELDS'.\",",
        "\"for a custom user model must"
    ],
    [
        "\"The 'USERNAME_FIELD' is currently set to '%s', you \"",
        "\"The 'USERNAME_FIELD' is currently set to '%s',"
    ],
    [
        "\"should remove '%s' from the 'REQUIRED_FIELDS'.\"",
        "\"should remove '%s' from"
    ],
    [
        "if not cls._meta.get_field(cls.USERNAME_FIELD).unique and not any(",
        "if not cls._meta.get_field(cls.USERNAME_FIELD).unique and not"
    ],
    [
        "\"'%s.%s' must be unique because it is named as the \"",
        "\"'%s.%s' must be unique because it is named as"
    ],
    [
        "\"'%s.%s' is named as the 'USERNAME_FIELD', but it is not unique.\"",
        "\"'%s.%s' is named as the 'USERNAME_FIELD',"
    ],
    [
        "\"Ensure that your authentication backend(s) can handle \"",
        "\"Ensure that your authentication backend(s)"
    ],
    [
        "\"%s.is_anonymous must be an attribute or property rather than \"",
        "\"%s.is_anonymous must be an attribute or property rather"
    ],
    [
        "\"a method. Ignoring this is a security issue as anonymous \"",
        "\"a method. Ignoring this is a security"
    ],
    [
        "\"users will be treated as authenticated!\" % cls,",
        "\"users will be treated as"
    ],
    [
        "\"%s.is_authenticated must be an attribute or property rather \"",
        "\"%s.is_authenticated must be an attribute"
    ],
    [
        "\"than a method. Ignoring this is a security issue as anonymous \"",
        "\"than a method. Ignoring this is a security"
    ],
    [
        "\"users will be treated as authenticated!\" % cls,",
        "\"users will be treated as"
    ],
    [
        "\"The verbose_name of model '%s' must be at most %d \"",
        "\"The verbose_name of model '%s' must be at most %d"
    ],
    [
        "\"characters for its builtin permission names to be at \"",
        "\"characters for its builtin permission names to"
    ],
    [
        "\"The name of model '%s' must be at most %d characters \"",
        "\"The name of model '%s' must be at most %d characters"
    ],
    [
        "\"for its builtin permission codenames to be at most %d \"",
        "\"for its builtin permission codenames to be at most"
    ],
    [
        "\"The permission named '%s' of model '%s' is longer \"",
        "\"The permission named '%s' of model '%s'"
    ],
    [
        "\"The permission codenamed '%s' of model '%s' is \"",
        "\"The permission codenamed '%s' of model"
    ],
    [
        "\"The permission codenamed '%s' clashes with a builtin \"",
        "\"The permission codenamed '%s' clashes"
    ],
    [
        "\"permission for model '%s'.\" % (codename, opts.label),",
        "\"permission for model '%s'.\""
    ],
    [
        "\"The permission codenamed '%s' is duplicated for \"",
        "\"The permission codenamed '%s' is duplicated"
    ],
    [
        "\"AuthenticationMiddleware must be defined before it in MIDDLEWARE.\",",
        "\"AuthenticationMiddleware must be defined before it"
    ],
    [
        "This module allows importing AbstractBaseUser even when django.contrib.auth is",
        "This module allows importing AbstractBaseUser even when"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "Normalize the email address by lowercasing the domain part of it.",
        "Normalize the email address by lowercasing"
    ],
    [
        "email = email_name + \"@\" + domain_part.lower()",
        "email = email_name + \"@\" +"
    ],
    [
        "last_login = models.DateTimeField(_(\"last login\"), blank=True, null=True)",
        "last_login = models.DateTimeField(_(\"last login\"),"
    ],
    [
        "\"\"\"Return the username for this User.\"\"\"",
        "\"\"\"Return the username for this"
    ],
    [
        "Always return False. This is a way of comparing User objects to",
        "Always return False. This is a"
    ],
    [
        "Always return True. This is a way to tell if the user has been",
        "Always return True. This is a way to tell if the user has"
    ],
    [
        "Return a boolean of whether the raw_password was correct. Handles",
        "Return a boolean of whether the raw_password was correct."
    ],
    [
        "Return False if set_unusable_password() has been called for this user.",
        "Return False if set_unusable_password() has been called for"
    ],
    [
        "Return an HMAC of the password field.",
        "Return an HMAC of"
    ],
    [
        "from django.apps import apps as django_apps",
        "from django.apps import apps as"
    ],
    [
        "from .signals import user_logged_in, user_logged_out, user_login_failed",
        "from .signals import user_logged_in, user_logged_out,"
    ],
    [
        "backends.append((backend, backend_path) if return_tuples else backend)",
        "backends.append((backend, backend_path) if"
    ],
    [
        "\"No authentication backends have been defined. Does \"",
        "\"No authentication backends have been defined. Does"
    ],
    [
        "\"You have multiple authentication backends configured and \"",
        "\"You have multiple authentication backends configured and"
    ],
    [
        "\"therefore must provide the `backend` argument or set the \"",
        "\"therefore must provide the `backend` argument"
    ],
    [
        "\"backend must be a dotted import path string (got %r).\" % backend",
        "\"backend must be a dotted import path"
    ],
    [
        "Clean a dictionary of credentials of potentially sensitive info before",
        "Clean a dictionary of credentials"
    ],
    [
        "Not comprehensive - intended for user_login_failed signal",
        "Not comprehensive - intended for"
    ],
    [
        "If the given credentials are valid, return a User object.",
        "If the given credentials are valid, return a User"
    ],
    [
        "for backend, backend_path in _get_compatible_backends(request, **credentials):",
        "for backend, backend_path"
    ],
    [
        "for backend, backend_path in _get_compatible_backends(request, **credentials):",
        "for backend, backend_path in"
    ],
    [
        "Persist a user id and a backend in the request. This way a user doesn't",
        "Persist a user id and a backend in the request. This way"
    ],
    [
        "have to reauthenticate on every request. Note that data set during",
        "have to reauthenticate on every request. Note that"
    ],
    [
        "the anonymous session is retained when the user logs in.",
        "the anonymous session is retained when the"
    ],
    [
        "\"Fallback to request.user when user is None will be removed.\",",
        "\"Fallback to request.user when user is None will be"
    ],
    [
        "if _get_user_session_key(request) != user.pk or (",
        "if _get_user_session_key(request) != user.pk"
    ],
    [
        "\"Fallback to request.user when user is None will be removed.\",",
        "\"Fallback to request.user when user is None will"
    ],
    [
        "if await _aget_user_session_key(request) != user.pk or (",
        "if await _aget_user_session_key(request) != user.pk"
    ],
    [
        "Remove the authenticated user's ID from the request and flush their session",
        "Remove the authenticated user's ID from the request and flush"
    ],
    [
        "Return the User model that is active in this project.",
        "Return the User model that is"
    ],
    [
        "\"AUTH_USER_MODEL must be of the form 'app_label.model_name'\"",
        "\"AUTH_USER_MODEL must be of the form"
    ],
    [
        "\"AUTH_USER_MODEL refers to model '%s' that has not been installed\"",
        "\"AUTH_USER_MODEL refers to model '%s' that has not"
    ],
    [
        "Return the user model instance associated with the given request session.",
        "Return the user model instance associated with the given"
    ],
    [
        "If no user is retrieved, return an instance of `AnonymousUser`.",
        "If no user is retrieved, return an instance of"
    ],
    [
        "Return the codename of the permission for the specified action.",
        "Return the codename of the"
    ],
    [
        "Updating a user's password logs out all sessions for the user.",
        "Updating a user's password logs out all sessions"
    ],
    [
        "Take the current request and the updated user object from which the new",
        "Take the current request and the updated user object from"
    ],
    [
        "session hash will be derived and update the session hash appropriately to",
        "session hash will be derived and update the session hash appropriately"
    ],
    [
        "prevent a password change from logging out the session from which the",
        "prevent a password change from logging out the session from"
    ],
    [
        "if hasattr(user, \"get_session_auth_hash\") and request.user == user:",
        "if hasattr(user, \"get_session_auth_hash\") and"
    ],
    [
        "if hasattr(user, \"get_session_auth_hash\") and request.user == user:",
        "if hasattr(user, \"get_session_auth_hash\") and request.user =="
    ],
    [
        "Strategy object used to generate and check tokens for the password",
        "Strategy object used to generate and check tokens"
    ],
    [
        "Return a token that can be used once to do a password reset",
        "Return a token that can be used once to"
    ],
    [
        "Check that a password reset token is correct for a given user.",
        "Check that a password reset token is correct for"
    ],
    [
        "if (self._num_seconds(self._now()) - ts) > settings.PASSWORD_RESET_TIMEOUT:",
        "if (self._num_seconds(self._now()) - ts)"
    ],
    [
        "Hash the user's primary key, email (if available), and some user state",
        "Hash the user's primary key, email (if"
    ],
    [
        "that's sure to change after a password reset to produce a token that is",
        "that's sure to change after a password reset to produce a token that"
    ],
    [
        "same password is chosen, due to password salting).",
        "same password is chosen, due"
    ],
    [
        "Running this data through salted_hmac() prevents password cracking",
        "Running this data through salted_hmac()"
    ],
    [
        "attempts using the reset token, provided the secret isn't compromised.",
        "attempts using the reset token,"
    ],
    [
        "email = getattr(user, email_field, \"\") or \"\"",
        "email = getattr(user, email_field,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "from .checks import check_middleware, check_models_permissions, check_user_model",
        "from .checks import check_middleware,"
    ],
    [
        "from django.contrib.auth import authenticate, get_user_model, password_validation",
        "from django.contrib.auth import authenticate,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "Perform case-insensitive comparison of two identifiers, using the",
        "Perform case-insensitive comparison of two"
    ],
    [
        "usable_password = value and not value.startswith(UNUSABLE_PASSWORD_PREFIX)",
        "usable_password = value and not"
    ],
    [
        "\"Invalid password format or unknown hashing algorithm.\"",
        "\"Invalid password format or unknown hashing"
    ],
    [
        "_(\"Reset password\") if usable_password else _(\"Set password\")",
        "_(\"Reset password\") if usable_password"
    ],
    [
        "if self.max_length is not None and len(value) > self.max_length:",
        "if self.max_length is not None"
    ],
    [
        "Form mixin that validates and sets a password for a user.",
        "Form mixin that validates and sets a"
    ],
    [
        "\"password_mismatch\": _(\"The two password fields didn’t match.\"),",
        "\"password_mismatch\": _(\"The two password fields didn’t"
    ],
    [
        "help_text=_(\"Enter the same password as before, for verification.\"),",
        "help_text=_(\"Enter the same password as before, for"
    ],
    [
        "Form mixin that allows setting an unusable password for a user.",
        "Form mixin that allows setting an unusable password"
    ],
    [
        "This mixin should be used in combination with `SetPasswordMixin`.",
        "This mixin should be used"
    ],
    [
        "\"Whether the user will be able to authenticate using a password or not. \"",
        "\"Whether the user will be able to authenticate using"
    ],
    [
        "\"If disabled, they may still be able to authenticate using other backends, \"",
        "\"If disabled, they may still be able to authenticate using"
    ],
    [
        "\"such as Single Sign-On or LDAP.\"",
        "\"such as Single"
    ],
    [
        "A form that creates a user, with no privileges, from the given username and",
        "A form that creates a user, with no privileges, from the given username"
    ],
    [
        "This is the documented base class for customizing the user creation form.",
        "This is the documented base class for"
    ],
    [
        "It should be kept mostly unchanged to ensure consistency and compatibility.",
        "It should be kept mostly unchanged to ensure consistency"
    ],
    [
        "\"\"\"Reject usernames that differ only in case.\"\"\"",
        "\"\"\"Reject usernames that differ"
    ],
    [
        "\"Raw passwords are not stored, so there is no way to see \"",
        "\"Raw passwords are not stored, so there"
    ],
    [
        "\"Enable password-based authentication for this user by setting a \"",
        "\"Enable password-based authentication for this user by"
    ],
    [
        "Base class for authenticating users. Extend this to get a form that accepts",
        "Base class for authenticating users. Extend this to get a form"
    ],
    [
        "\"Please enter a correct %(username)s and password. Note that both \"",
        "\"Please enter a correct %(username)s and password. Note"
    ],
    [
        "The 'request' parameter is set for custom auth use by subclasses.",
        "The 'request' parameter is set for custom auth"
    ],
    [
        "The form data comes in via the standard 'data' kwarg.",
        "The form data comes in via the standard 'data'"
    ],
    [
        "if username is not None and password:",
        "if username is not"
    ],
    [
        "Controls whether the given User may log in. This is a policy setting,",
        "Controls whether the given User may log in. This is a policy"
    ],
    [
        "independent of end-user authentication. This default behavior is to",
        "independent of end-user authentication. This default behavior"
    ],
    [
        "allow login by active users, and reject login by inactive users.",
        "allow login by active users, and reject login"
    ],
    [
        "If the given user cannot log in, this method should raise a",
        "If the given user cannot log in, this method"
    ],
    [
        "If the given user may log in, this method should return None.",
        "If the given user may log in, this method should"
    ],
    [
        "email_message = EmailMultiAlternatives(subject, body, from_email, [to_email])",
        "email_message = EmailMultiAlternatives(subject, body, from_email,"
    ],
    [
        "\"Failed to send password reset email to %s\", context[\"user\"].pk",
        "\"Failed to send password reset email"
    ],
    [
        "\"\"\"Given an email, return matching user(s) who should receive a reset.",
        "\"\"\"Given an email, return matching user(s) who should"
    ],
    [
        "This allows subclasses to more easily customize the default policies",
        "This allows subclasses to more easily"
    ],
    [
        "that prevent inactive users and users with unusable passwords from",
        "that prevent inactive users and users with unusable passwords"
    ],
    [
        "Generate a one-use only link for resetting password and send it to the",
        "Generate a one-use only link for resetting password and"
    ],
    [
        "\"protocol\": \"https\" if use_https else \"http\",",
        "\"protocol\": \"https\" if use_https"
    ],
    [
        "A form that lets a user set their password without entering the old",
        "A form that lets a user set their password without"
    ],
    [
        "A form that lets a user change their password by entering their old",
        "A form that lets a user change their password by entering"
    ],
    [
        "\"Your old password was entered incorrectly. Please enter it again.\"",
        "\"Your old password was entered incorrectly. Please enter it"
    ],
    [
        "Validate that the old_password field is correct.",
        "Validate that the old_password"
    ],
    [
        "A form used to change the password of a user in the admin interface.",
        "A form used to change the password of a user in"
    ],
    [
        "\"If disabled, the current password for this user will be lost.</li></ul>\"",
        "\"If disabled, the current password for"
    ],
    [
        "from django.db.models import Exists, OuterRef, Q",
        "from django.db.models import"
    ],
    [
        "async def ahas_perm(self, user_obj, perm, obj=None):",
        "async def ahas_perm(self, user_obj,"
    ],
    [
        "return perm in await self.aget_all_permissions(user_obj, obj)",
        "return perm in await self.aget_all_permissions(user_obj,"
    ],
    [
        "def authenticate(self, request, username=None, password=None, **kwargs):",
        "def authenticate(self, request, username=None, password=None,"
    ],
    [
        "if username is None or password is None:",
        "if username is None or password"
    ],
    [
        "async def aauthenticate(self, request, username=None, password=None, **kwargs):",
        "async def aauthenticate(self, request,"
    ],
    [
        "if username is None or password is None:",
        "if username is None or password is"
    ],
    [
        "Reject users with is_active=False. Custom user models that don't have",
        "Reject users with is_active=False. Custom user models that don't"
    ],
    [
        "Return the permissions of `user_obj` from `from_name`. `from_name` can",
        "Return the permissions of `user_obj` from `from_name`."
    ],
    [
        "be either \"group\" or \"user\" to return permissions from",
        "be either \"group\" or \"user\""
    ],
    [
        "if not user_obj.is_active or user_obj.is_anonymous or obj is not None:",
        "if not user_obj.is_active or user_obj.is_anonymous or obj is not"
    ],
    [
        "perms = getattr(self, \"_get_%s_permissions\" % from_name)(user_obj)",
        "perms = getattr(self,"
    ],
    [
        "user_obj, perm_cache_name, {\"%s.%s\" % (ct, name) for ct, name in perms}",
        "user_obj, perm_cache_name, {\"%s.%s\" % (ct, name) for"
    ],
    [
        "async def _aget_permissions(self, user_obj, obj, from_name):",
        "async def _aget_permissions(self, user_obj, obj,"
    ],
    [
        "if not user_obj.is_active or user_obj.is_anonymous or obj is not None:",
        "if not user_obj.is_active or user_obj.is_anonymous or obj is"
    ],
    [
        "perms = getattr(self, \"_get_%s_permissions\" % from_name)(user_obj)",
        "perms = getattr(self,"
    ],
    [
        "{\"%s.%s\" % (ct, name) async for ct, name in perms},",
        "{\"%s.%s\" % (ct, name) async"
    ],
    [
        "Return a set of permission strings the user `user_obj` has from their",
        "Return a set of permission strings the user `user_obj` has from"
    ],
    [
        "Return a set of permission strings the user `user_obj` has from the",
        "Return a set of permission strings"
    ],
    [
        "if not user_obj.is_active or user_obj.is_anonymous or obj is not None:",
        "if not user_obj.is_active or user_obj.is_anonymous or obj is"
    ],
    [
        "return user_obj.is_active and super().has_perm(user_obj, perm, obj=obj)",
        "return user_obj.is_active and"
    ],
    [
        "async def ahas_perm(self, user_obj, perm, obj=None):",
        "async def ahas_perm(self, user_obj,"
    ],
    [
        "return user_obj.is_active and await super().ahas_perm(user_obj, perm, obj=obj)",
        "return user_obj.is_active and await super().ahas_perm(user_obj, perm,"
    ],
    [
        "Return True if user_obj has any permissions in the given app_label.",
        "Return True if user_obj has any permissions"
    ],
    [
        "def with_perm(self, perm, is_active=True, include_superusers=True, obj=None):",
        "def with_perm(self, perm,"
    ],
    [
        "Return users that have permission \"perm\". By default, filter out",
        "Return users that have permission"
    ],
    [
        "\"Permission name should be in the form \"",
        "\"Permission name should be in the form"
    ],
    [
        "\"The `perm` argument must be a string or a permission instance.\"",
        "\"The `perm` argument must be a string or a permission"
    ],
    [
        "return user if self.user_can_authenticate(user) else None",
        "return user if self.user_can_authenticate(user)"
    ],
    [
        "return user if self.user_can_authenticate(user) else None",
        "return user if self.user_can_authenticate(user) else"
    ],
    [
        "This backend is to be used in conjunction with the ``RemoteUserMiddleware``",
        "This backend is to be used in conjunction"
    ],
    [
        "found in the middleware module of this package, and is used when the server",
        "found in the middleware module of this package, and"
    ],
    [
        "is handling authentication outside of Django.",
        "is handling authentication outside"
    ],
    [
        "By default, the ``authenticate`` method creates ``User`` objects for",
        "By default, the ``authenticate`` method creates"
    ],
    [
        "usernames that don't already exist in the database.  Subclasses can disable",
        "usernames that don't already exist in the"
    ],
    [
        "this behavior by setting the ``create_unknown_user`` attribute to",
        "this behavior by setting the"
    ],
    [
        "The username passed as ``remote_user`` is considered trusted. Return",
        "The username passed as ``remote_user`` is"
    ],
    [
        "the ``User`` object with the given username. Create a new ``User``",
        "the ``User`` object with the given username. Create a new"
    ],
    [
        "Return None if ``create_unknown_user`` is ``False`` and a ``User``",
        "Return None if ``create_unknown_user`` is ``False`` and a"
    ],
    [
        "object with the given username is not found in the database.",
        "object with the given username is not found in"
    ],
    [
        "return user if self.user_can_authenticate(user) else None",
        "return user if self.user_can_authenticate(user) else"
    ],
    [
        "user = await self.aconfigure_user(request, user, created=created)",
        "user = await self.aconfigure_user(request,"
    ],
    [
        "return user if self.user_can_authenticate(user) else None",
        "return user if self.user_can_authenticate(user) else"
    ],
    [
        "Perform any cleaning on the \"username\" prior to using it to get or",
        "Perform any cleaning on the \"username\" prior"
    ],
    [
        "create the user object.  Return the cleaned username.",
        "create the user object."
    ],
    [
        "By default, return the username unchanged.",
        "By default, return the username"
    ],
    [
        "Configure a user and return the updated user.",
        "Configure a user and return the"
    ],
    [
        "By default, return the user unmodified.",
        "By default, return"
    ],
    [
        "async def aconfigure_user(self, request, user, created=True):",
        "async def aconfigure_user(self, request,"
    ],
    [
        "Lookup by \"someapp\" or \"someapp.someperm\" in perms.",
        "Lookup by \"someapp\" or"
    ],
    [
        "Return context variables required by apps that use Django's authentication",
        "Return context variables required by apps"
    ],
    [
        "If there is no 'user' attribute in the request, use AnonymousUser (from",
        "If there is no 'user' attribute"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "(_(\"Personal info\"), {\"fields\": (\"first_name\", \"last_name\", \"email\")}),",
        "(_(\"Personal info\"), {\"fields\": (\"first_name\", \"last_name\","
    ],
    [
        "list_display = (\"username\", \"email\", \"first_name\", \"last_name\", \"is_staff\")",
        "list_display = (\"username\", \"email\", \"first_name\", \"last_name\","
    ],
    [
        "list_filter = (\"is_staff\", \"is_superuser\", \"is_active\", \"groups\")",
        "list_filter = (\"is_staff\","
    ],
    [
        "search_fields = (\"username\", \"first_name\", \"last_name\", \"email\")",
        "search_fields = (\"username\", \"first_name\", \"last_name\","
    ],
    [
        "Use special form during user creation",
        "Use special form during"
    ],
    [
        "if request.method in (\"GET\", \"HEAD\", \"OPTIONS\", \"TRACE\"):",
        "if request.method in (\"GET\", \"HEAD\","
    ],
    [
        "'Your user does not have the \"Change user\" permission. In '",
        "'Your user does not have the \"Change user\" permission."
    ],
    [
        "\"order to add users, Django requires that your user \"",
        "\"order to add users, Django requires that your"
    ],
    [
        "'account have both the \"Add user\" and \"Change user\" '",
        "'account have both the \"Add user\" and \"Change"
    ],
    [
        "_(\"%(name)s object with primary key %(key)r does not exist.\")",
        "_(\"%(name)s object with primary key %(key)r does"
    ],
    [
        "msg = gettext(\"Conflicting form data submitted. Please try again.\")",
        "msg = gettext(\"Conflicting form data submitted."
    ],
    [
        "msg = gettext(\"Password-based authentication was disabled.\")",
        "msg = gettext(\"Password-based authentication was"
    ],
    [
        "\"is_popup\": (IS_POPUP_VAR in request.POST or IS_POPUP_VAR in request.GET),",
        "\"is_popup\": (IS_POPUP_VAR in request.POST or IS_POPUP_VAR in"
    ],
    [
        "Determine the HttpResponse for the add_view stage. It mostly defers to",
        "Determine the HttpResponse for the add_view stage. It"
    ],
    [
        "its superclass implementation but is customized because the User model",
        "its superclass implementation but is customized because the"
    ],
    [
        "if \"_addanother\" not in request.POST and IS_POPUP_VAR not in request.POST:",
        "if \"_addanother\" not in request.POST and IS_POPUP_VAR not in"
    ],
    [
        "from django.utils.translation import gettext_noop as _",
        "from django.utils.translation import gettext_noop"
    ],
    [
        "Return True if this password wasn't generated by",
        "Return True if this"
    ],
    [
        "return encoded is None or not encoded.startswith(UNUSABLE_PASSWORD_PREFIX)",
        "return encoded is None or not"
    ],
    [
        "Return two booleans. The first is whether the raw password matches the",
        "Return two booleans. The first is whether the raw"
    ],
    [
        "three part encoded digest, and the second whether to regenerate the",
        "three part encoded digest, and the second"
    ],
    [
        "fake_runtime = password is None or not is_password_usable(encoded)",
        "fake_runtime = password is None"
    ],
    [
        "if not is_correct and not hasher_changed and must_update:",
        "if not is_correct and not hasher_changed and"
    ],
    [
        "Return a boolean of whether the raw password matches the three part encoded",
        "Return a boolean of whether the raw password matches the"
    ],
    [
        "If setter is specified, it'll be called when you need to regenerate the",
        "If setter is specified, it'll be called when"
    ],
    [
        "is_correct, must_update = verify_password(password, encoded, preferred=preferred)",
        "is_correct, must_update = verify_password(password, encoded,"
    ],
    [
        "if setter and is_correct and must_update:",
        "if setter and is_correct"
    ],
    [
        "async def acheck_password(password, encoded, setter=None, preferred=\"default\"):",
        "async def acheck_password(password, encoded, setter=None,"
    ],
    [
        "is_correct, must_update = verify_password(password, encoded, preferred=preferred)",
        "is_correct, must_update ="
    ],
    [
        "if setter and is_correct and must_update:",
        "if setter and"
    ],
    [
        "Turn a plain-text password into a hash for database storage",
        "Turn a plain-text password into a hash"
    ],
    [
        "Same as encode() but generate a new random salt. If password is None then",
        "Same as encode() but generate a new"
    ],
    [
        "return a concatenation of UNUSABLE_PASSWORD_PREFIX and a random string,",
        "return a concatenation of UNUSABLE_PASSWORD_PREFIX and"
    ],
    [
        "which disallows logins. Additional random string reduces chances of gaining",
        "which disallows logins. Additional random string reduces"
    ],
    [
        "\"Password must be a string or bytes, got %s.\" % type(password).__qualname__",
        "\"Password must be a string or bytes,"
    ],
    [
        "\"hasher doesn't specify an algorithm name: %s\" % hasher_path",
        "\"hasher doesn't specify an algorithm name: %s\""
    ],
    [
        "return {hasher.algorithm: hasher for hasher in get_hashers()}",
        "return {hasher.algorithm: hasher for hasher in"
    ],
    [
        "Return an instance of a loaded password hasher.",
        "Return an instance of a loaded password"
    ],
    [
        "If algorithm is 'default', return the default hasher. Lazily import hashers",
        "If algorithm is 'default', return the default hasher. Lazily"
    ],
    [
        "specified in the project's settings file if needed.",
        "specified in the project's settings"
    ],
    [
        "\"Unknown password hashing algorithm '%s'. \"",
        "\"Unknown password hashing algorithm '%s'."
    ],
    [
        "\"Did you specify it in the PASSWORD_HASHERS \"",
        "\"Did you specify it in the"
    ],
    [
        "Return an instance of a loaded password hasher.",
        "Return an instance of a loaded"
    ],
    [
        "Identify hasher algorithm by examining encoded hash, and call",
        "Identify hasher algorithm by examining"
    ],
    [
        "get_hasher() to return hasher. Raise ValueError if",
        "get_hasher() to return hasher."
    ],
    [
        "algorithm cannot be identified, or if hasher is not loaded.",
        "algorithm cannot be identified, or if"
    ],
    [
        "Return the given hash, with only the first ``show`` number shown. The",
        "Return the given hash, with only the first ``show`` number shown."
    ],
    [
        "rest are masked with ``char`` for security reasons.",
        "rest are masked with"
    ],
    [
        "Abstract base class for password hashers",
        "Abstract base class for"
    ],
    [
        "When creating your own hasher, you need to override algorithm,",
        "When creating your own hasher, you need to override"
    ],
    [
        "\"Couldn't load %r algorithm library: %s\"",
        "\"Couldn't load %r algorithm"
    ],
    [
        "\"Hasher %r doesn't specify a library attribute\" % self.__class__.__name__",
        "\"Hasher %r doesn't specify a library attribute\""
    ],
    [
        "Generate a cryptographically secure nonce salt in ASCII with an entropy",
        "Generate a cryptographically secure nonce salt"
    ],
    [
        "\"\"\"Check if the given password is correct.\"\"\"",
        "\"\"\"Check if the given password is"
    ],
    [
        "\"subclasses of BasePasswordHasher must provide a verify() method\"",
        "\"subclasses of BasePasswordHasher must provide a verify()"
    ],
    [
        "if not salt or \"$\" in salt:",
        "if not salt or \"$\" in"
    ],
    [
        "raise ValueError(\"salt must be provided and cannot contain $.\")",
        "raise ValueError(\"salt must be provided and cannot contain"
    ],
    [
        "The result is normally formatted as \"algorithm$salt$hash\" and",
        "The result is normally formatted as"
    ],
    [
        "\"subclasses of BasePasswordHasher must provide an encode() method\"",
        "\"subclasses of BasePasswordHasher must provide an encode()"
    ],
    [
        "The result is a dictionary and should contain `algorithm`, `hash`, and",
        "The result is a dictionary and should contain `algorithm`,"
    ],
    [
        "`salt`. Extra keys can be algorithm specific like `iterations` or",
        "`salt`. Extra keys can be algorithm specific"
    ],
    [
        "\"subclasses of BasePasswordHasher must provide a decode() method.\"",
        "\"subclasses of BasePasswordHasher must provide a decode()"
    ],
    [
        "Return a summary of safe values.",
        "Return a summary of"
    ],
    [
        "The result is a dictionary and will be used where the password field",
        "The result is a dictionary and will"
    ],
    [
        "must be displayed to construct a safe representation of the password.",
        "must be displayed to construct a safe representation of"
    ],
    [
        "\"subclasses of BasePasswordHasher must provide a safe_summary() method\"",
        "\"subclasses of BasePasswordHasher must provide"
    ],
    [
        "Bridge the runtime gap between the work factor supplied in `encoded`",
        "Bridge the runtime gap between the work factor supplied in"
    ],
    [
        "and the work factor suggested by this hasher.",
        "and the work factor suggested by this"
    ],
    [
        "for any hasher that has a work factor. If not, this method should be",
        "for any hasher that has a work factor. If not,"
    ],
    [
        "defined as a no-op to silence the warning.",
        "defined as a no-op to silence"
    ],
    [
        "\"subclasses of BasePasswordHasher should provide a harden_runtime() method\"",
        "\"subclasses of BasePasswordHasher should provide a"
    ],
    [
        "return \"%s$%d$%s$%s\" % (self.algorithm, iterations, salt, hash)",
        "return \"%s$%d$%s$%s\" % (self.algorithm,"
    ],
    [
        "return (decoded[\"iterations\"] != self.iterations) or update_salt",
        "return (decoded[\"iterations\"] !="
    ],
    [
        "depends on native C code and might cause portability issues.",
        "depends on native C code and might cause portability"
    ],
    [
        "return (current_params != new_params) or update_salt",
        "return (current_params != new_params) or"
    ],
    [
        "Secure password hashing using the bcrypt algorithm (recommended)",
        "Secure password hashing using the bcrypt algorithm"
    ],
    [
        "This is considered by many to be the most secure algorithm but you",
        "This is considered by many to be the most"
    ],
    [
        "must first install the bcrypt library.  Please be warned that",
        "must first install the bcrypt library. Please be"
    ],
    [
        "this library depends on native C code and might cause portability",
        "this library depends on native C code and might cause"
    ],
    [
        "Secure password hashing using the bcrypt algorithm",
        "Secure password hashing using the"
    ],
    [
        "This is considered by many to be the most secure algorithm but you",
        "This is considered by many to be the"
    ],
    [
        "must first install the bcrypt library.  Please be warned that",
        "must first install the bcrypt library. Please be"
    ],
    [
        "this library depends on native C code and might cause portability",
        "this library depends on native C"
    ],
    [
        "This hasher does not first hash the password which means it is subject to",
        "This hasher does not first hash the password which means it is subject"
    ],
    [
        "Secure password hashing using the Scrypt algorithm.",
        "Secure password hashing using"
    ],
    [
        "def encode(self, password, salt, n=None, r=None, p=None):",
        "def encode(self, password, salt,"
    ],
    [
        "return \"%s$%d$%s$%d$%d$%s\" % (self.algorithm, n, salt, r, p, hash_)",
        "return \"%s$%d$%s$%d$%d$%s\" % (self.algorithm, n,"
    ],
    [
        "algorithm, work_factor, salt, block_size, parallelism, hash_ = encoded.split(",
        "algorithm, work_factor, salt, block_size, parallelism,"
    ],
    [
        "return \"%s$%s$%s\" % (self.algorithm, salt, hash)",
        "return \"%s$%s$%s\" % (self.algorithm,"
    ],
    [
        "\"The Django authentication middleware requires session \"",
        "\"The Django authentication middleware requires"
    ],
    [
        "\"middleware to be installed. Edit your MIDDLEWARE setting to \"",
        "\"middleware to be installed. Edit your MIDDLEWARE"
    ],
    [
        "Middleware that redirects all unauthenticated requests to a login page.",
        "Middleware that redirects all unauthenticated requests to a"
    ],
    [
        "Views using the login_not_required decorator will not be redirected.",
        "Views using the login_not_required decorator"
    ],
    [
        "def process_view(self, request, view_func, view_args, view_kwargs):",
        "def process_view(self, request,"
    ],
    [
        "login_url = getattr(view_func, \"login_url\", None) or settings.LOGIN_URL",
        "login_url = getattr(view_func, \"login_url\","
    ],
    [
        "\"No login URL to redirect to. Define settings.LOGIN_URL or \"",
        "\"No login URL to redirect"
    ],
    [
        "\"provide a login_url via the 'django.contrib.auth.decorators.\"",
        "\"provide a login_url via"
    ],
    [
        "if (not login_scheme or login_scheme == current_scheme) and (",
        "if (not login_scheme or login_scheme == current_scheme) and"
    ],
    [
        "not login_netloc or login_netloc == current_netloc",
        "not login_netloc or"
    ],
    [
        "If request.user is not authenticated, then this middleware attempts to",
        "If request.user is not authenticated, then this middleware"
    ],
    [
        "authenticate the username from the ``REMOTE_USER`` key in ``request.META``,",
        "authenticate the username from the ``REMOTE_USER`` key in"
    ],
    [
        "an environment variable commonly set by the webserver.",
        "an environment variable commonly"
    ],
    [
        "If authentication is successful, the user is automatically logged in to",
        "If authentication is successful, the user is automatically"
    ],
    [
        "persist the user in the session.",
        "persist the user in the"
    ],
    [
        "The ``request.META`` key is configurable and defaults to ``REMOTE_USER``.",
        "The ``request.META`` key is configurable and defaults"
    ],
    [
        "Subclass this class and change the ``header`` attribute if you need to",
        "Subclass this class and change the ``header`` attribute if you"
    ],
    [
        "use a different key from ``request.META``, for example a HTTP request",
        "use a different key from ``request.META``, for"
    ],
    [
        "\"The Django remote user auth middleware requires the\"",
        "\"The Django remote user auth"
    ],
    [
        "\" authentication middleware to be installed.  Edit your\"",
        "\" authentication middleware to be"
    ],
    [
        "\"The Django remote user auth middleware requires the\"",
        "\"The Django remote user auth"
    ],
    [
        "\" authentication middleware to be installed.  Edit your\"",
        "\" authentication middleware to be installed. Edit"
    ],
    [
        "Allow the backend to clean the username, if the backend defines a",
        "Allow the backend to clean the username,"
    ],
    [
        "Remove the current authenticated user in the request which is invalid",
        "Remove the current authenticated user in the request which"
    ],
    [
        "but only if the user is authenticated via the RemoteUserBackend.",
        "but only if the user is authenticated via"
    ],
    [
        "Remove the current authenticated user in the request which is invalid",
        "Remove the current authenticated user in the request which is"
    ],
    [
        "but only if the user is authenticated via the RemoteUserBackend.",
        "but only if the user"
    ],
    [
        "Middleware for web-server provided authentication on logon pages.",
        "Middleware for web-server provided authentication"
    ],
    [
        "Like RemoteUserMiddleware but keeps the user authenticated even if",
        "Like RemoteUserMiddleware but keeps the user"
    ],
    [
        "the ``request.META`` key is not found in the request. Useful for",
        "the ``request.META`` key is not found in"
    ],
    [
        "setups when the external authentication is only expected to happen",
        "setups when the external authentication is only expected"
    ],
    [
        "on some \"logon\" URL and the rest of the application wants to use",
        "on some \"logon\" URL and the rest of"
    ],
    [
        "from django.contrib.auth import login as auth_login",
        "from django.contrib.auth import login as"
    ],
    [
        "from django.contrib.auth import logout as auth_logout",
        "from django.contrib.auth import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"\"\"Return the user-originating redirect URL if it's safe.\"\"\"",
        "\"\"\"Return the user-originating redirect URL if it's"
    ],
    [
        "return redirect_to if url_is_safe else \"\"",
        "return redirect_to if"
    ],
    [
        "raise ImproperlyConfigured(\"No URL to redirect to. Provide a next_page.\")",
        "raise ImproperlyConfigured(\"No URL to redirect to. Provide"
    ],
    [
        "Display the login form and handle the login action.",
        "Display the login form and handle the login"
    ],
    [
        "\"Redirection loop for authenticated user detected. Check that \"",
        "\"Redirection loop for authenticated user detected. Check that"
    ],
    [
        "\"your LOGIN_REDIRECT_URL doesn't point to a login page.\"",
        "\"your LOGIN_REDIRECT_URL doesn't point to"
    ],
    [
        "\"\"\"Security check complete. Log the user in.\"\"\"",
        "\"\"\"Security check complete. Log the user"
    ],
    [
        "Log out the user and display the 'You are logged out' message.",
        "Log out the user and display the 'You"
    ],
    [
        "\"\"\"Logout may be done via POST.\"\"\"",
        "\"\"\"Logout may be done"
    ],
    [
        "Log out the user if they are logged in. Then redirect to the login page.",
        "Log out the user if they are logged in. Then redirect to the"
    ],
    [
        "Redirect the user to the login page, passing the given 'next' page.",
        "Redirect the user to the login page, passing the given 'next'"
    ],
    [
        "{\"title\": self.title, \"subtitle\": None, **(self.extra_context or {})}",
        "{\"title\": self.title, \"subtitle\": None,"
    ],
    [
        "from asgiref.sync import async_to_sync, iscoroutinefunction, sync_to_async",
        "from asgiref.sync import async_to_sync,"
    ],
    [
        "Decorator for views that checks that the user passes the given test,",
        "Decorator for views that checks that"
    ],
    [
        "redirecting to the log-in page if necessary. The test should be a callable",
        "redirecting to the log-in page if necessary. The test should be"
    ],
    [
        "that takes the user object and returns True if the user passes.",
        "that takes the user object and returns True if"
    ],
    [
        "if (not login_scheme or login_scheme == current_scheme) and (",
        "if (not login_scheme or login_scheme == current_scheme) and"
    ],
    [
        "not login_netloc or login_netloc == current_netloc",
        "not login_netloc or login_netloc"
    ],
    [
        "Decorator for views that checks that the user is logged in, redirecting",
        "Decorator for views that checks that the"
    ],
    [
        "to the log-in page if necessary.",
        "to the log-in page if"
    ],
    [
        "Decorator for views that allows access to unauthenticated requests.",
        "Decorator for views that allows access"
    ],
    [
        "Decorator for views that checks whether a user has a particular permission",
        "Decorator for views that checks whether a user has a particular"
    ],
    [
        "enabled, redirecting to the log-in page if necessary.",
        "enabled, redirecting to the log-in page"
    ],
    [
        "If the raise_exception parameter is given the PermissionDenied exception",
        "If the raise_exception parameter is given"
    ],
    [
        "error_messages={\"unique\": \"A user with that username already exists.\"},",
        "error_messages={\"unique\": \"A user with that username already"
    ],
    [
        "error_messages={\"unique\": \"A user with that username already exists.\"},",
        "error_messages={\"unique\": \"A user with that username"
    ],
    [
        "from django.db import IntegrityError, migrations, transaction",
        "from django.db import"
    ],
    [
        "A problem arose migrating proxy model permissions for {old} to {new}.",
        "A problem arose migrating proxy model permissions for"
    ],
    [
        "Ensure to audit ALL permissions for {old} and {new}.",
        "Ensure to audit ALL permissions for {old}"
    ],
    [
        "Update the content_type of proxy model permissions to use the ContentType",
        "Update the content_type of proxy model"
    ],
    [
        "\"%s_%s\" % (action, opts.model_name) for action in opts.default_permissions",
        "\"%s_%s\" % (action, opts.model_name) for action in"
    ],
    [
        "old_content_type = proxy_content_type if reverse else concrete_content_type",
        "old_content_type = proxy_content_type if"
    ],
    [
        "new_content_type = concrete_content_type if reverse else proxy_content_type",
        "new_content_type = concrete_content_type if"
    ],
    [
        "Update the content_type of proxy model permissions to use the ContentType",
        "Update the content_type of proxy model"
    ],
    [
        "\"Designates that this user has all permissions without \"",
        "\"Designates that this user has"
    ],
    [
        "\"Designates whether the user can log into this admin site.\"",
        "\"Designates whether the user can log into"
    ],
    [
        "\"Designates whether this user should be treated as active. \"",
        "\"Designates whether this user should be treated"
    ],
    [
        "\"Unselect this instead of deleting accounts.\"",
        "\"Unselect this instead"
    ],
    [
        "\"The groups this user belongs to. A user will get all \"",
        "\"The groups this user belongs to. A user"
    ],
    [
        "\"permissions granted to each of their groups.\"",
        "\"permissions granted to each of their"
    ],
    [
        "error_messages={\"unique\": \"A user with that username already exists.\"},",
        "error_messages={\"unique\": \"A user with that username"
    ],
    [
        "Creates permissions for all installed apps that need permissions.",
        "Creates permissions for all installed apps that"
    ],
    [
        "from django.apps import apps as global_apps",
        "from django.apps import"
    ],
    [
        "Return (codename, name) for all permissions in the given opts.",
        "Return (codename, name) for all permissions in the"
    ],
    [
        "Return (codename, name) for all autogenerated permissions.",
        "Return (codename, name) for all autogenerated"
    ],
    [
        "By default, this is ('add', 'change', 'delete', 'view')",
        "By default, this is ('add',"
    ],
    [
        "\"Can %s %s\" % (action, opts.verbose_name_raw),",
        "\"Can %s %s\" %"
    ],
    [
        "if (ctype.pk, codename) not in all_perms:",
        "if (ctype.pk, codename) not in"
    ],
    [
        "Return the current system user's username, or an empty string if the",
        "Return the current system user's username, or an empty string if"
    ],
    [
        "Try to determine the current system user's username to use as a default.",
        "Try to determine the current system user's username to use as"
    ],
    [
        ":param check_db: If ``True``, requires that the username does not match an",
        ":param check_db: If ``True``, requires that the username does not"
    ],
    [
        "existing ``auth.User`` (otherwise returns an empty string).",
        "existing ``auth.User`` (otherwise returns an"
    ],
    [
        ":param database: The database where the unique check will be performed.",
        ":param database: The database where the unique"
    ],
    [
        ":returns: The username, or an empty string if no username can be",
        ":returns: The username, or an empty string"
    ],
    [
        "determined or the suggested username is already taken.",
        "determined or the suggested username is already"
    ],
    [
        "from django.contrib.auth import models as auth_app",
        "from django.contrib.auth import models"
    ],
    [
        "help = \"Used to create a superuser.\"",
        "help = \"Used to create a"
    ],
    [
        "help=\"Specifies the login for the superuser.\",",
        "help=\"Specifies the login"
    ],
    [
        "\"Tells Django to NOT prompt the user for input of any kind. \"",
        "\"Tells Django to NOT prompt the user for"
    ],
    [
        "\"You must use --%s with --noinput, along with an option for \"",
        "\"You must use --%s with --noinput, along with an"
    ],
    [
        "\"any other required field. Superusers created with --noinput will \"",
        "\"any other required field. Superusers created with"
    ],
    [
        "\"not be able to log in until they're given a valid password.\"",
        "\"not be able to log in until they're"
    ],
    [
        "help='Specifies the database to use. Default is \"default\".',",
        "help='Specifies the database to use."
    ],
    [
        "\"Required field '%s' specifies a many-to-many \"",
        "\"Required field '%s' specifies a many-to-many"
    ],
    [
        "\"relation through model, which is not supported.\" % field_name",
        "\"relation through model, which is not"
    ],
    [
        "\"Specifies the %s for the superuser. Can be used \"",
        "\"Specifies the %s for the superuser."
    ],
    [
        "help=\"Specifies the %s for the superuser.\" % field_name,",
        "help=\"Specifies the %s for the superuser.\" %"
    ],
    [
        "if hasattr(self.stdin, \"isatty\") and not self.stdin.isatty():",
        "if hasattr(self.stdin, \"isatty\")"
    ],
    [
        "\"%s cannot be blank.\" % capfirst(verbose_field_name)",
        "\"%s cannot be blank.\" %"
    ],
    [
        "self.stderr.write(\"Error: This field cannot be blank.\")",
        "self.stderr.write(\"Error: This field cannot be"
    ],
    [
        "while PASSWORD_FIELD in user_data and user_data[PASSWORD_FIELD] is None:",
        "while PASSWORD_FIELD in user_data"
    ],
    [
        "\"Bypass password validation and create user anyway? [y/N]: \"",
        "\"Bypass password validation and create"
    ],
    [
        "\"You must use --%s with --noinput.\"",
        "\"You must use"
    ],
    [
        "options[field_name] == \"\" or os.environ.get(env_var) == \"\"",
        "options[field_name] == \"\" or os.environ.get(env_var) =="
    ],
    [
        "\"You must use --%s with --noinput.\" % field_name",
        "\"You must use --%s with --noinput.\" %"
    ],
    [
        "\"Superuser creation skipped due to not running in a TTY. \"",
        "\"Superuser creation skipped due to not running in a"
    ],
    [
        "\"You can run `manage.py createsuperuser` in your project \"",
        "\"You can run `manage.py createsuperuser` in your project"
    ],
    [
        "Override this method if you want to customize data inputs or",
        "Override this method if you want"
    ],
    [
        "if default and raw_value == \"\":",
        "if default and raw_value"
    ],
    [
        "\" (leave blank to use '%s')\" % default if default else \"\",",
        "\" (leave blank to use '%s')\" % default if default else"
    ],
    [
        "\"\"\"Validate username. If invalid, return a string error message.\"\"\"",
        "\"\"\"Validate username. If invalid, return"
    ],
    [
        "return \"Error: That %s is already taken.\" % verbose_field_name",
        "return \"Error: That %s is already"
    ],
    [
        "return \"%s cannot be blank.\" % capfirst(verbose_field_name)",
        "return \"%s cannot be blank.\" %"
    ],
    [
        "help = \"Change a user's password for django.contrib.auth.\"",
        "help = \"Change a user's"
    ],
    [
        "\"Username to change password for; by default, it's the current \"",
        "\"Username to change password for; by default, it's the current"
    ],
    [
        "help='Specifies the database to use. Default is \"default\".',",
        "help='Specifies the database to use."
    ],
    [
        "raise CommandError(\"user '%s' does not exist\" % username)",
        "raise CommandError(\"user '%s' does"
    ],
    [
        "self.stdout.write(\"Changing password for user '%s'\" % u)",
        "self.stdout.write(\"Changing password for user '%s'\" %"
    ],
    [
        "self.stdout.write(\"Passwords do not match. Please try again.\")",
        "self.stdout.write(\"Passwords do not match."
    ],
    [
        "\"Aborting password change for user '%s' after %s attempts\" % (u, count)",
        "\"Aborting password change for user '%s' after"
    ],
    [
        "return \"Password changed successfully for user '%s'\" % u",
        "return \"Password changed successfully for user '%s'\""
    ],
    [
        "mod_wsgi docs specify None, True, False as return value depending",
        "mod_wsgi docs specify None, True, False"
    ],
    [
        "on whether the user exists and authenticates.",
        "on whether the user"
    ],
    [
        "Authorize a user based on groups",
        "Authorize a user"
    ],
    [
        "return [group.name.encode() for group in user.groups.all()]",
        "return [group.name.encode() for group in"
    ],
    [
        "from urllib.parse import quote as urlquote",
        "from urllib.parse import"
    ],
    [
        "from django.db import models, router, transaction",
        "from django.db import"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "return \"radiolist\" if radio_style == VERTICAL else \"radiolist inline\"",
        "return \"radiolist\" if radio_style == VERTICAL else \"radiolist"
    ],
    [
        "\"\"\"Functionality common to both ModelAdmin and InlineAdmin.\"\"\"",
        "\"\"\"Functionality common to both"
    ],
    [
        "Hook for specifying the form Field instance for a given database Field",
        "Hook for specifying the form Field instance for a"
    ],
    [
        "If kwargs are given, they're passed to the form Field's constructor.",
        "If kwargs are given, they're passed to"
    ],
    [
        "if formfield and db_field.name not in self.raw_id_fields:",
        "if formfield and db_field.name not"
    ],
    [
        "Get a form Field for a database Field that has declared choices.",
        "Get a form Field for a database Field"
    ],
    [
        "If the ModelAdmin specifies ordering, the queryset should respect that",
        "If the ModelAdmin specifies ordering, the"
    ],
    [
        "ordering.  Otherwise don't specify the queryset, let the field decide",
        "ordering. Otherwise don't specify the queryset,"
    ],
    [
        "if ordering is not None and ordering != ():",
        "if ordering is not None"
    ],
    [
        "Get a form Field for a ForeignKey.",
        "Get a form Field for"
    ],
    [
        "kwargs.get(\"empty_label\", _(\"None\")) if db_field.blank else None",
        "kwargs.get(\"empty_label\", _(\"None\")) if db_field.blank else"
    ],
    [
        "Get a form Field for a ManyToManyField.",
        "Get a form Field"
    ],
    [
        "\"Hold down “Control”, or “Command” on a Mac, to select more than one.\"",
        "\"Hold down “Control”, or “Command” on a Mac,"
    ],
    [
        "format_lazy(\"{} {}\", help_text, msg) if help_text else msg",
        "format_lazy(\"{} {}\", help_text, msg) if help_text"
    ],
    [
        "Return a list of ForeignKey and/or ManyToMany fields which should use",
        "Return a list of ForeignKey and/or ManyToMany fields which"
    ],
    [
        "if obj is None or not self.view_on_site:",
        "if obj is None or not"
    ],
    [
        "Return the empty_value_display set on ModelAdmin or AdminSite.",
        "Return the empty_value_display set on"
    ],
    [
        "Hook for specifying custom readonly fields.",
        "Hook for specifying custom"
    ],
    [
        "Hook for specifying custom prepopulated fields.",
        "Hook for specifying"
    ],
    [
        "Return a QuerySet of all model instances that can be edited by the",
        "Return a QuerySet of all model instances that"
    ],
    [
        "admin site. This is used by changelist_view.",
        "admin site. This is used"
    ],
    [
        "\"\"\"Hook for specifying which fields can be sorted in the changelist.\"\"\"",
        "\"\"\"Hook for specifying which fields can be sorted in the"
    ],
    [
        "or part not in getattr(prev_field, \"to_fields\", [])",
        "or part not in getattr(prev_field, \"to_fields\","
    ],
    [
        "Return True if the model associated with this admin should be",
        "Return True if the model associated with"
    ],
    [
        "allowed to be referenced by the specified field.",
        "allowed to be referenced by the specified"
    ],
    [
        "any(issubclass(model, related_model) for model in registered_models)",
        "any(issubclass(model, related_model) for"
    ],
    [
        "Return True if the given request has permission to add an object.",
        "Return True if the given request has permission"
    ],
    [
        "Can be overridden by the user in subclasses.",
        "Can be overridden by the user"
    ],
    [
        "Return True if the given request has permission to change the given",
        "Return True if the given request has permission to change"
    ],
    [
        "Django model instance, the default implementation doesn't examine the",
        "Django model instance, the default implementation doesn't"
    ],
    [
        "Can be overridden by the user in subclasses. In such case it should",
        "Can be overridden by the user in subclasses."
    ],
    [
        "return True if the given request has permission to change the `obj`",
        "return True if the given request has permission"
    ],
    [
        "model instance. If `obj` is None, this should return True if the given",
        "model instance. If `obj` is None, this should return True"
    ],
    [
        "request has permission to change *any* object of the given type.",
        "request has permission to change *any* object of"
    ],
    [
        "Return True if the given request has permission to delete the given",
        "Return True if the given request has permission to delete the"
    ],
    [
        "Django model instance, the default implementation doesn't examine the",
        "Django model instance, the default"
    ],
    [
        "Can be overridden by the user in subclasses. In such case it should",
        "Can be overridden by the user in subclasses. In such case"
    ],
    [
        "return True if the given request has permission to delete the `obj`",
        "return True if the given request"
    ],
    [
        "model instance. If `obj` is None, this should return True if the given",
        "model instance. If `obj` is None, this should return"
    ],
    [
        "request has permission to delete *any* object of the given type.",
        "request has permission to delete *any* object of the"
    ],
    [
        "Return True if the given request has permission to view the given",
        "Return True if the given request has permission to view"
    ],
    [
        "Django model instance. The default implementation doesn't examine the",
        "Django model instance. The default implementation"
    ],
    [
        "If overridden by the user in subclasses, it should return True if the",
        "If overridden by the user in subclasses, it should return True"
    ],
    [
        "given request has permission to view the `obj` model instance. If `obj`",
        "given request has permission to view the `obj` model instance. If"
    ],
    [
        "is None, it should return True if the request has permission to view",
        "is None, it should return True if the"
    ],
    [
        "any object of the given type.",
        "any object of the"
    ],
    [
        ") or request.user.has_perm(\"%s.%s\" % (opts.app_label, codename_change))",
        ") or request.user.has_perm(\"%s.%s\""
    ],
    [
        "Return True if the given request has any permission in the given",
        "Return True if the given request has any"
    ],
    [
        "Can be overridden by the user in subclasses. In such case it should",
        "Can be overridden by the user in subclasses. In such case it"
    ],
    [
        "return True if the given request has permission to view the module on",
        "return True if the given request has permission to view the module"
    ],
    [
        "the admin index page and access the module's index page. Overriding it",
        "the admin index page and access the"
    ],
    [
        "does not restrict access to the add, change or delete views. Use",
        "does not restrict access to the add, change or delete"
    ],
    [
        "\"\"\"Encapsulate all admin options and functionality for a given model.\"\"\"",
        "\"\"\"Encapsulate all admin options and"
    ],
    [
        "extra = \"\" if settings.DEBUG else \".min\"",
        "extra = \"\" if"
    ],
    [
        "return forms.Media(js=[\"admin/js/%s\" % url for url in js])",
        "return forms.Media(js=[\"admin/js/%s\" % url for url in"
    ],
    [
        "Return a dict of all perms for this model. This dict has the keys",
        "Return a dict of all perms for this model. This dict has"
    ],
    [
        "``add``, ``change``, ``delete``, and ``view`` mapping to the True/False",
        "``add``, ``change``, ``delete``, and ``view`` mapping"
    ],
    [
        "def get_form(self, request, obj=None, change=False, **kwargs):",
        "def get_form(self, request,"
    ],
    [
        "Return a Form class for use in the admin add view. This is used by",
        "Return a Form class for use in the admin add view."
    ],
    [
        "exclude = [] if excluded is None else list(excluded)",
        "exclude = [] if excluded is None"
    ],
    [
        "if excluded is None and hasattr(self.form, \"_meta\") and self.form._meta.exclude:",
        "if excluded is None and hasattr(self.form, \"_meta\") and"
    ],
    [
        "f for f in readonly_fields if f in self.form.declared_fields",
        "f for f in readonly_fields if"
    ],
    [
        "if defaults[\"fields\"] is None and not modelform_defines_fields(",
        "if defaults[\"fields\"] is None and not"
    ],
    [
        "\"%s. Check fields/fieldsets/exclude attributes of class %s.\"",
        "\"%s. Check fields/fieldsets/exclude attributes of"
    ],
    [
        "Return the ChangeList class for use on the changelist page.",
        "Return the ChangeList class for"
    ],
    [
        "Return a `ChangeList` instance based on `request`. May raise",
        "Return a `ChangeList` instance based on `request`."
    ],
    [
        "Return an instance matching the field and value provided, the primary",
        "Return an instance matching the field and value"
    ],
    [
        "key is used if no field is provided. Return ``None`` if no match is",
        "key is used if no field is provided. Return ``None``"
    ],
    [
        "found or the object_id fails validation.",
        "found or the"
    ],
    [
        "model._meta.pk if from_field is None else model._meta.get_field(from_field)",
        "model._meta.pk if from_field is"
    ],
    [
        "Return a Form class for use in the Formset on the changelist page.",
        "Return a Form class for use in the Formset on the changelist"
    ],
    [
        "if defaults.get(\"fields\") is None and not modelform_defines_fields(",
        "if defaults.get(\"fields\") is None and"
    ],
    [
        "Return a FormSet class for use on the changelist page if list_editable",
        "Return a FormSet class for use on the"
    ],
    [
        "Yield formsets and the corresponding inlines.",
        "Yield formsets and the corresponding"
    ],
    [
        "Log that an object has been successfully added.",
        "Log that an object"
    ],
    [
        "The default implementation creates an admin LogEntry object.",
        "The default implementation creates an admin"
    ],
    [
        "Log that an object has been successfully changed.",
        "Log that an object has been"
    ],
    [
        "The default implementation creates an admin LogEntry object.",
        "The default implementation creates an admin LogEntry"
    ],
    [
        "Log that objects will be deleted. Note that this method must be called",
        "Log that objects will be deleted. Note that"
    ],
    [
        "The default implementation creates admin LogEntry objects.",
        "The default implementation creates admin"
    ],
    [
        "A list_display column containing a checkbox widget.",
        "A list_display column containing"
    ],
    [
        "_(\"Select this object for an action - {}\"), str(obj)",
        "_(\"Select this object for an action"
    ],
    [
        "checkbox = forms.CheckboxInput(attrs, lambda value: False)",
        "checkbox = forms.CheckboxInput(attrs,"
    ],
    [
        "\"\"\"Return the list of actions, prior to any request-based filtering.\"\"\"",
        "\"\"\"Return the list of actions, prior to"
    ],
    [
        "base_actions = (self.get_action(action) for action in self.actions or [])",
        "base_actions = (self.get_action(action) for action in self.actions or"
    ],
    [
        "base_actions = [action for action in base_actions if action]",
        "base_actions = [action for action in base_actions if"
    ],
    [
        "base_action_names = {name for _, name, _ in base_actions}",
        "base_action_names = {name for _,"
    ],
    [
        "\"\"\"Filter out any actions that the user doesn't have access to.\"\"\"",
        "\"\"\"Filter out any actions that the user doesn't have access"
    ],
    [
        "if any(has_permission(request) for has_permission in permission_checks):",
        "if any(has_permission(request) for has_permission"
    ],
    [
        "Return a dictionary mapping the names of all actions for this",
        "Return a dictionary mapping the names of all actions"
    ],
    [
        "ModelAdmin to a tuple of (callable, name, description) for each action.",
        "ModelAdmin to a tuple of (callable, name, description) for"
    ],
    [
        "if self.actions is None or IS_POPUP_VAR in request.GET:",
        "if self.actions is None or IS_POPUP_VAR in"
    ],
    [
        "return {name: (func, name, desc) for func, name, desc in actions}",
        "return {name: (func, name, desc) for func, name,"
    ],
    [
        "Return a list of choices for use in a form object.  Each choice is a",
        "Return a list of choices for use in a form object. Each choice is"
    ],
    [
        "for func, name, description in self.get_actions(request).values():",
        "for func, name,"
    ],
    [
        "choice = (name, description % model_format_dict(self.opts))",
        "choice = (name, description %"
    ],
    [
        "Return a given action from a parameter, which can either be a callable,",
        "Return a given action from a parameter, which can"
    ],
    [
        "or the name of a method on the ModelAdmin.  Return is a tuple of",
        "or the name of a method on the ModelAdmin."
    ],
    [
        "Return a sequence containing the fields to be displayed on the",
        "Return a sequence containing the fields"
    ],
    [
        "Return a sequence containing the fields to be displayed as links",
        "Return a sequence containing the fields to be displayed"
    ],
    [
        "on the changelist. The list_display parameter is the list of fields",
        "on the changelist. The list_display parameter"
    ],
    [
        "Return a sequence containing the fields to be displayed as filters in",
        "Return a sequence containing the fields to be displayed"
    ],
    [
        "the right sidebar of the changelist page.",
        "the right sidebar of"
    ],
    [
        "Return a list of fields to add to the select_related() part of the",
        "Return a list of fields to add to the select_related() part of"
    ],
    [
        "Return a sequence containing the fields to be searched whenever",
        "Return a sequence containing the fields to"
    ],
    [
        "Return a tuple containing a queryset to implement the search",
        "Return a tuple containing a"
    ],
    [
        "and a boolean indicating if the results may contain duplicates.",
        "and a boolean indicating if the"
    ],
    [
        "if path_part == \"exact\" and not isinstance(",
        "if path_part == \"exact\" and"
    ],
    [
        "[(orm_lookup, bit) for orm_lookup in orm_lookups],",
        "[(orm_lookup, bit) for orm_lookup in"
    ],
    [
        "current_url = \"%s:%s\" % (match.app_name, match.url_name)",
        "current_url = \"%s:%s\""
    ],
    [
        "def construct_change_message(self, request, form, formsets, add=False):",
        "def construct_change_message(self, request, form,"
    ],
    [
        "Construct a JSON structure describing changes from a changed object.",
        "Construct a JSON structure describing changes from a"
    ],
    [
        "self, request, message, level=messages.INFO, extra_tags=\"\", fail_silently=False",
        "self, request, message, level=messages.INFO, extra_tags=\"\","
    ],
    [
        "Send a message to the user. The default implementation",
        "Send a message to the user. The default"
    ],
    [
        "posts a message using the django.contrib.messages backend.",
        "posts a message using the"
    ],
    [
        "Exposes almost the same API as messages.add_message(), but accepts the",
        "Exposes almost the same API as messages.add_message(), but"
    ],
    [
        "positional arguments in a different order to maintain backwards",
        "positional arguments in a different order"
    ],
    [
        "compatibility. For convenience, it accepts the `level` argument as",
        "compatibility. For convenience, it accepts the `level`"
    ],
    [
        "a string rather than the usual level number.",
        "a string rather than the usual"
    ],
    [
        "levels_repr = \", \".join(\"`%s`\" % level for level in levels)",
        "levels_repr = \", \".join(\"`%s`\" % level for"
    ],
    [
        "\"Bad message level string: `%s`. Possible values are: %s\"",
        "\"Bad message level string: `%s`."
    ],
    [
        "Given a ModelForm return an unsaved instance. ``change`` is True if",
        "Given a ModelForm return an unsaved instance."
    ],
    [
        "the object is being changed, and False if it's being added.",
        "the object is being changed, and False if it's"
    ],
    [
        "def save_model(self, request, obj, form, change):",
        "def save_model(self, request, obj,"
    ],
    [
        "Given a model instance save it to the database.",
        "Given a model instance save it"
    ],
    [
        "Given a model instance delete it from the database.",
        "Given a model instance delete"
    ],
    [
        "\"\"\"Given a queryset, delete it from the database.\"\"\"",
        "\"\"\"Given a queryset, delete"
    ],
    [
        "def save_formset(self, request, form, formset, change):",
        "def save_formset(self, request, form, formset,"
    ],
    [
        "Given an inline formset save it to the database.",
        "Given an inline formset save it to the"
    ],
    [
        "def save_related(self, request, form, formsets, change):",
        "def save_related(self, request,"
    ],
    [
        "Given the ``HttpRequest``, the parent ``ModelForm`` instance, the",
        "Given the ``HttpRequest``, the parent ``ModelForm``"
    ],
    [
        "list of inline formsets and a boolean value based on whether the",
        "list of inline formsets and a boolean value based"
    ],
    [
        "parent is being added or changed, save the related objects to the",
        "parent is being added or changed, save the related"
    ],
    [
        "database. Note that at this point save_form() and save_model() have",
        "database. Note that at this point save_form() and save_model()"
    ],
    [
        "self, request, context, add=False, change=False, form_url=\"\", obj=None",
        "self, request, context, add=False,"
    ],
    [
        "if add and self.add_form_template is not None:",
        "if add and self.add_form_template is not"
    ],
    [
        "Determine the HttpResponse for the add_view stage.",
        "Determine the HttpResponse for the add_view"
    ],
    [
        "obj_repr = format_html('<a href=\"{}\">{}</a>', urlquote(obj_url), obj)",
        "obj_repr = format_html('<a"
    ],
    [
        "elif \"_continue\" in request.POST or (",
        "elif \"_continue\" in request.POST"
    ],
    [
        "msg = _(\"The {name} “{obj}” was added successfully.\")",
        "msg = _(\"The {name} “{obj}”"
    ],
    [
        "msg += \" \" + _(\"You may edit it again below.\")",
        "msg += \" \" + _(\"You"
    ],
    [
        "\"The {name} “{obj}” was added successfully. You may add another \"",
        "\"The {name} “{obj}” was added successfully. You may add"
    ],
    [
        "_(\"The {name} “{obj}” was added successfully.\"), **msg_dict",
        "_(\"The {name} “{obj}” was"
    ],
    [
        "Determine the HttpResponse for the change_view stage.",
        "Determine the HttpResponse for the change_view"
    ],
    [
        "attr = str(to_field) if to_field else opts.pk.attname",
        "attr = str(to_field) if to_field"
    ],
    [
        "\"The {name} “{obj}” was changed successfully. You may edit it \"",
        "\"The {name} “{obj}” was changed successfully. You"
    ],
    [
        "\"The {name} “{obj}” was changed successfully. You may add another \"",
        "\"The {name} “{obj}” was changed successfully. You may"
    ],
    [
        "_(\"The {name} “{obj}” was changed successfully.\"), **msg_dict",
        "_(\"The {name} “{obj}” was"
    ],
    [
        "Figure out where to redirect after the 'Save' button has been pressed",
        "Figure out where to redirect after the 'Save' button has been"
    ],
    [
        "Figure out where to redirect after the 'Save' button has been pressed",
        "Figure out where to redirect after the 'Save' button has been"
    ],
    [
        "Handle an admin action. This is called if a request is POSTed to the",
        "Handle an admin action. This is called if a request is POSTed to"
    ],
    [
        "changelist; it returns an HttpResponse if the action was handled, and",
        "changelist; it returns an HttpResponse if the action was"
    ],
    [
        "if not selected and not select_across:",
        "if not selected"
    ],
    [
        "\"Items must be selected in order to perform \"",
        "\"Items must be selected in"
    ],
    [
        "\"actions on them. No items have been changed.\"",
        "\"actions on them. No items have"
    ],
    [
        "Determine the HttpResponse for the delete_view stage.",
        "Determine the HttpResponse for the"
    ],
    [
        "_(\"The %(name)s “%(obj)s” was deleted successfully.\")",
        "_(\"The %(name)s “%(obj)s” was deleted"
    ],
    [
        "def get_inline_formsets(self, request, formsets, inline_instances, obj=None):",
        "def get_inline_formsets(self, request, formsets,"
    ],
    [
        "for inline, formset in zip(inline_instances, formsets):",
        "for inline, formset"
    ],
    [
        "has_add_permission = has_change_permission = has_delete_permission = (",
        "has_add_permission = has_change_permission = has_delete_permission ="
    ],
    [
        "Get the initial form data from the request's GET params.",
        "Get the initial form data from"
    ],
    [
        "Create a message informing the user that the object doesn't exist",
        "Create a message informing the user that"
    ],
    [
        "and return a redirect to the admin index page.",
        "and return a redirect to the admin index"
    ],
    [
        "msg = _(\"%(name)s with ID “%(key)s” doesn’t exist. Perhaps it was deleted?\") % {",
        "msg = _(\"%(name)s with ID “%(key)s” doesn’t exist. Perhaps it was deleted?\")"
    ],
    [
        "def changeform_view(self, request, object_id=None, form_url=\"\", extra_context=None):",
        "def changeform_view(self, request, object_id=None, form_url=\"\","
    ],
    [
        "if request.method in (\"GET\", \"HEAD\", \"OPTIONS\", \"TRACE\"):",
        "if request.method in (\"GET\", \"HEAD\","
    ],
    [
        "def _changeform_view(self, request, object_id, form_url, extra_context):",
        "def _changeform_view(self, request,"
    ],
    [
        "if to_field and not self.to_field_allowed(request, to_field):",
        "if to_field and not"
    ],
    [
        "\"The field %s cannot be referenced.\" % to_field",
        "\"The field %s cannot"
    ],
    [
        "if request.method == \"POST\" and \"_saveasnew\" in request.POST:",
        "if request.method == \"POST\" and"
    ],
    [
        "new_object = self.save_form(request, form, change=not add)",
        "new_object = self.save_form(request,"
    ],
    [
        "if not add and not self.has_change_permission(request, obj):",
        "if not add and not self.has_change_permission(request,"
    ],
    [
        "\"subtitle\": str(obj) if obj else None,",
        "\"subtitle\": str(obj) if obj else"
    ],
    [
        "\"is_popup\": IS_POPUP_VAR in request.POST or IS_POPUP_VAR in request.GET,",
        "\"is_popup\": IS_POPUP_VAR in request.POST"
    ],
    [
        "request, context, add=add, change=not add, obj=obj, form_url=form_url",
        "request, context, add=add, change=not add,"
    ],
    [
        "def change_view(self, request, object_id, form_url=\"\", extra_context=None):",
        "def change_view(self, request, object_id, form_url=\"\","
    ],
    [
        "\"\"\"Return POST data values of list_editable primary keys.\"\"\"",
        "\"\"\"Return POST data values of list_editable"
    ],
    [
        "return [value for key, value in request.POST.items() if pk_pattern.match(key)]",
        "return [value for key, value in request.POST.items() if"
    ],
    [
        "Based on POST data, return a queryset of the objects that were edited",
        "Based on POST data, return a queryset of"
    ],
    [
        "The 'change list' admin view for this model.",
        "The 'change list' admin view"
    ],
    [
        "\"Items must be selected in order to perform \"",
        "\"Items must be selected in"
    ],
    [
        "\"actions on them. No items have been changed.\"",
        "\"actions on them. No"
    ],
    [
        "if request.method == \"POST\" and cl.list_editable and \"_save\" in request.POST:",
        "if request.method == \"POST\" and cl.list_editable and \"_save\""
    ],
    [
        "\"%(total_count)s selected\", \"All %(total_count)s selected\", cl.result_count",
        "\"%(total_count)s selected\", \"All %(total_count)s selected\","
    ],
    [
        "Hook for customizing the delete process for the delete view and the",
        "Hook for customizing the delete process for"
    ],
    [
        "if request.method in (\"GET\", \"HEAD\", \"OPTIONS\", \"TRACE\"):",
        "if request.method in (\"GET\","
    ],
    [
        "\"The 'delete' admin view for this model.\"",
        "\"The 'delete' admin view"
    ],
    [
        "if to_field and not self.to_field_allowed(request, to_field):",
        "if to_field and not"
    ],
    [
        "\"The field %s cannot be referenced.\" % to_field",
        "\"The field %s cannot be referenced.\" %"
    ],
    [
        "attr = str(to_field) if to_field else self.opts.pk.attname",
        "attr = str(to_field) if to_field else"
    ],
    [
        "title = _(\"Cannot delete %(name)s\") % {\"name\": object_name}",
        "title = _(\"Cannot delete"
    ],
    [
        "\"is_popup\": IS_POPUP_VAR in request.POST or IS_POPUP_VAR in request.GET,",
        "\"is_popup\": IS_POPUP_VAR in request.POST or IS_POPUP_VAR"
    ],
    [
        "\"The 'history' admin view for this model.\"",
        "\"The 'history' admin view"
    ],
    [
        "\"title\": _(\"Change history: %s\") % obj,",
        "\"title\": _(\"Change history: %s\") %"
    ],
    [
        "def get_formset_kwargs(self, request, obj, inline, prefix):",
        "def get_formset_kwargs(self, request,"
    ],
    [
        "\"Helper function to generate formsets for add/change_view.\"",
        "\"Helper function to generate"
    ],
    [
        "prefix = \"%s-%s\" % (prefix, prefixes[prefix])",
        "prefix = \"%s-%s\" % (prefix,"
    ],
    [
        "formset_params = self.get_formset_kwargs(request, obj, inline, prefix)",
        "formset_params = self.get_formset_kwargs(request, obj,"
    ],
    [
        "def user_deleted_form(request, obj, formset, index, inline):",
        "def user_deleted_form(request, obj, formset, index,"
    ],
    [
        "\"\"\"Return whether or not the user deleted the form.\"\"\"",
        "\"\"\"Return whether or not the"
    ],
    [
        "if not inline.has_change_permission(request, obj if change else None):",
        "if not inline.has_change_permission(request, obj if change"
    ],
    [
        "if user_deleted_form(request, obj, formset, index, inline):",
        "if user_deleted_form(request, obj,"
    ],
    [
        "Options for inline editing of ``model`` instances.",
        "Options for inline editing of"
    ],
    [
        "Provide ``fk_name`` to specify the attribute name of the ``ForeignKey``",
        "Provide ``fk_name`` to specify the"
    ],
    [
        "from ``model`` to its parent. This is required if ``model`` has more than",
        "from ``model`` to its parent. This is required if ``model`` has more"
    ],
    [
        "extra = \"\" if settings.DEBUG else \".min\"",
        "extra = \"\" if"
    ],
    [
        "js = [\"vendor/jquery/jquery%s.js\" % extra, \"jquery.init.js\", \"inlines.js\"]",
        "js = [\"vendor/jquery/jquery%s.js\" % extra,"
    ],
    [
        "return forms.Media(js=[\"admin/js/%s\" % url for url in js])",
        "return forms.Media(js=[\"admin/js/%s\" % url for"
    ],
    [
        "\"\"\"Hook for customizing the number of extra inline forms.\"\"\"",
        "\"\"\"Hook for customizing the number of extra inline"
    ],
    [
        "\"\"\"Hook for customizing the min number of inline forms.\"\"\"",
        "\"\"\"Hook for customizing the min number"
    ],
    [
        "\"\"\"Hook for customizing the max number of extra inline forms.\"\"\"",
        "\"\"\"Hook for customizing the max number of extra"
    ],
    [
        "\"\"\"Return a BaseInlineFormSet class for use in admin add/change views.\"\"\"",
        "\"\"\"Return a BaseInlineFormSet class for use"
    ],
    [
        "exclude = [] if excluded is None else list(excluded)",
        "exclude = [] if excluded"
    ],
    [
        "if excluded is None and hasattr(self.form, \"_meta\") and self.form._meta.exclude:",
        "if excluded is None and"
    ],
    [
        "can_delete = self.can_delete and self.has_delete_permission(request, obj)",
        "can_delete = self.can_delete and"
    ],
    [
        "can_change = self.has_change_permission(request, obj) if request else True",
        "can_change = self.has_change_permission(request, obj) if request"
    ],
    [
        "can_add = self.has_add_permission(request, obj) if request else True",
        "can_add = self.has_add_permission(request, obj) if request"
    ],
    [
        "We don't validate the 'DELETE' field itself because on",
        "We don't validate the 'DELETE' field"
    ],
    [
        "templates it's not rendered using the field information, but",
        "templates it's not rendered using the field"
    ],
    [
        "just using a generic \"deletion_field\" of the InlineModelAdmin.",
        "just using a generic"
    ],
    [
        "\"Deleting %(class_name)s %(instance)s would require \"",
        "\"Deleting %(class_name)s %(instance)s"
    ],
    [
        "\"deleting the following protected related objects: \"",
        "\"deleting the following protected"
    ],
    [
        "if not can_change and not self.instance._state.adding:",
        "if not can_change and"
    ],
    [
        "if defaults[\"fields\"] is None and not modelform_defines_fields(",
        "if defaults[\"fields\"] is None and"
    ],
    [
        "This method is called only when the ModelAdmin's model is for an",
        "This method is called only when the ModelAdmin's model is"
    ],
    [
        "ManyToManyField's implicit through model (if self.opts.auto_created).",
        "ManyToManyField's implicit through"
    ],
    [
        "Return True if the user has any of the given permissions ('add',",
        "Return True if the user has any of the given"
    ],
    [
        "'change', etc.) for the model that points to the through model.",
        "'change', etc.) for the model that"
    ],
    [
        "if field.remote_field and field.remote_field.model != self.parent_model:",
        "if field.remote_field and field.remote_field.model"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "self, user_id, queryset, action_flag, change_message=\"\", *, single_object=False",
        "self, user_id, queryset, action_flag,"
    ],
    [
        "object_id = models.TextField(_(\"object id\"), blank=True, null=True)",
        "object_id = models.TextField(_(\"object"
    ],
    [
        "return gettext(\"Added “%(object)s”.\") % {\"object\": self.object_repr}",
        "return gettext(\"Added “%(object)s”.\") % {\"object\":"
    ],
    [
        "return gettext(\"Changed “%(object)s” — %(changes)s\") % {",
        "return gettext(\"Changed “%(object)s” — %(changes)s\") %"
    ],
    [
        "return gettext(\"Deleted “%(object)s.”\") % {\"object\": self.object_repr}",
        "return gettext(\"Deleted “%(object)s.”\") % {\"object\":"
    ],
    [
        "If self.change_message is a JSON structure, interpret it as a change",
        "If self.change_message is a JSON structure, interpret it as"
    ],
    [
        "return change_message or gettext(\"No fields changed.\")",
        "return change_message or gettext(\"No fields"
    ],
    [
        "\"\"\"Return the edited object represented by this log entry.\"\"\"",
        "\"\"\"Return the edited object represented by this log"
    ],
    [
        "Return the admin URL to edit the object represented by this log entry.",
        "Return the admin URL to edit the"
    ],
    [
        "from django.contrib.admin.utils import NotRelationField, flatten, get_fields_from_path",
        "from django.contrib.admin.utils import NotRelationField, flatten,"
    ],
    [
        "from django.forms.models import BaseModelForm, BaseModelFormSet, _get_foreign_key",
        "from django.forms.models import BaseModelForm, BaseModelFormSet,"
    ],
    [
        "issubclass() variant that doesn't raise an exception if cls isn't a",
        "issubclass() variant that doesn't raise an exception if cls isn't"
    ],
    [
        "Return whether or not a dotted class path (or a subclass of that class) is",
        "Return whether or not a dotted class path (or a"
    ],
    [
        "found in a list of candidate paths.",
        "found in a list"
    ],
    [
        "Check that the admin's dependencies are correctly installed.",
        "Check that the admin's dependencies"
    ],
    [
        "\"'%s' must be in INSTALLED_APPS in order to use the admin \"",
        "\"'%s' must be in INSTALLED_APPS in order to"
    ],
    [
        "\"must be configured in TEMPLATES in order to use the admin \"",
        "\"must be configured in TEMPLATES in order to use"
    ],
    [
        "\"enabled in DjangoTemplates (TEMPLATES) if using the default \"",
        "\"enabled in DjangoTemplates (TEMPLATES) if using"
    ],
    [
        "\"auth backend in order to use the admin application.\",",
        "\"auth backend in order to"
    ],
    [
        "\"be enabled in DjangoTemplates (TEMPLATES) in order to use \"",
        "\"be enabled in DjangoTemplates (TEMPLATES)"
    ],
    [
        "sidebar_enabled = any(site.enable_nav_sidebar for site in all_sites)",
        "sidebar_enabled = any(site.enable_nav_sidebar for site in"
    ],
    [
        "\"in DjangoTemplates (TEMPLATES) in order to use the admin \"",
        "\"in DjangoTemplates (TEMPLATES) in order to use the admin"
    ],
    [
        "\"be in MIDDLEWARE in order to use the admin application.\",",
        "\"be in MIDDLEWARE in order to use"
    ],
    [
        "\"be in MIDDLEWARE in order to use the admin application.\",",
        "\"be in MIDDLEWARE in order to"
    ],
    [
        "\"be in MIDDLEWARE in order to use the admin application.\",",
        "\"be in MIDDLEWARE in order to use the"
    ],
    [
        "Check that `autocomplete_fields` is a list or tuple of model fields.",
        "Check that `autocomplete_fields` is a list or tuple of"
    ],
    [
        "Check that an item in `autocomplete_fields` is a ForeignKey or a",
        "Check that an item in `autocomplete_fields` is a ForeignKey"
    ],
    [
        "ManyToManyField and that the item has a related ModelAdmin with",
        "ManyToManyField and that the item has"
    ],
    [
        "if not field.many_to_many and not isinstance(field, models.ForeignKey):",
        "if not field.many_to_many and not"
    ],
    [
        "\"a foreign key or a many-to-many field\",",
        "\"a foreign key or"
    ],
    [
        "'An admin for model \"%s\" has to be registered '",
        "'An admin for model \"%s\" has to"
    ],
    [
        "'%s must define \"search_fields\", because it\\'s '",
        "'%s must define \"search_fields\", because"
    ],
    [
        "\"\"\"Check that `raw_id_fields` only contains field names that are listed",
        "\"\"\"Check that `raw_id_fields` only contains"
    ],
    [
        "\"\"\"Check an item of `raw_id_fields`, i.e. check that field named",
        "\"\"\"Check an item of `raw_id_fields`, i.e."
    ],
    [
        "`field_name` exists in model `model` and is a ForeignKey or a",
        "`field_name` exists in model `model` and is a ForeignKey"
    ],
    [
        "if not field.many_to_many and not isinstance(field, models.ForeignKey):",
        "if not field.many_to_many and not"
    ],
    [
        "\"a foreign key or a many-to-many field\",",
        "\"a foreign key or a many-to-many"
    ],
    [
        "\"\"\"Check that `fields` only refer to existing fields, doesn't contain",
        "\"\"\"Check that `fields` only refer to existing"
    ],
    [
        "duplicates. Check if at most one of `fields` and `fieldsets` is defined.",
        "duplicates. Check if at most one of"
    ],
    [
        "\"Both 'fieldsets' and 'fields' are specified.\",",
        "\"Both 'fieldsets' and 'fields'"
    ],
    [
        "\"The value of 'fields' contains duplicate field(s).\",",
        "\"The value of 'fields'"
    ],
    [
        "\"\"\"Check that fieldsets is properly formatted and doesn't contain",
        "\"\"\"Check that fieldsets is properly"
    ],
    [
        "obj, fieldset, \"fieldsets[%d]\" % index, seen_fields",
        "obj, fieldset, \"fieldsets[%d]\" %"
    ],
    [
        "def _check_fieldsets_item(self, obj, fieldset, label, seen_fields):",
        "def _check_fieldsets_item(self, obj, fieldset,"
    ],
    [
        "\"\"\"Check an item of `fieldsets`, i.e. check that this is a pair of a",
        "\"\"\"Check an item of `fieldsets`, i.e. check"
    ],
    [
        "set name and a dictionary containing \"fields\" key.\"\"\"",
        "set name and a dictionary"
    ],
    [
        "\"\"\"`fields` should be an item of `fields` or an item of",
        "\"\"\"`fields` should be an item of `fields`"
    ],
    [
        "field name or a tuple of field names.\"\"\"",
        "field name or a tuple of field"
    ],
    [
        "obj, field_name, \"%s[%d]\" % (label, index)",
        "obj, field_name, \"%s[%d]\""
    ],
    [
        "\"The value of '%s' cannot include the ManyToManyField \"",
        "\"The value of '%s' cannot include the"
    ],
    [
        "\"'%s', because that field manually specifies a \"",
        "\"'%s', because that field"
    ],
    [
        "\"\"\"Check that exclude is a sequence without duplicates.\"\"\"",
        "\"\"\"Check that exclude is a sequence without"
    ],
    [
        "\"The value of 'exclude' contains duplicate field(s).\",",
        "\"The value of 'exclude' contains duplicate"
    ],
    [
        "\"\"\"Check that filter_vertical is a sequence of field names.\"\"\"",
        "\"\"\"Check that filter_vertical is a sequence"
    ],
    [
        "\"\"\"Check that filter_horizontal is a sequence of field names.\"\"\"",
        "\"\"\"Check that filter_horizontal is a"
    ],
    [
        "\"\"\"Check one item of `filter_vertical` or `filter_horizontal`, i.e.",
        "\"\"\"Check one item of `filter_vertical`"
    ],
    [
        "check that given field exists and is a ManyToManyField.\"\"\"",
        "check that given field exists and is"
    ],
    [
        "if not field.many_to_many or isinstance(field, models.ManyToManyRel):",
        "if not field.many_to_many or"
    ],
    [
        "f\"The value of '{label}' cannot include the ManyToManyField \"",
        "f\"The value of '{label}' cannot include the"
    ],
    [
        "f\"'{field_name}', because that field manually specifies a \"",
        "f\"'{field_name}', because that field manually"
    ],
    [
        "\"\"\"Check that `radio_fields` is a dictionary.\"\"\"",
        "\"\"\"Check that `radio_fields` is a"
    ],
    [
        "\"\"\"Check that a key of `radio_fields` dictionary is name of existing",
        "\"\"\"Check that a key of `radio_fields`"
    ],
    [
        "field and that the field is a ForeignKey or has `choices` defined.\"\"\"",
        "field and that the field is a ForeignKey"
    ],
    [
        "if not (isinstance(field, models.ForeignKey) or field.choices):",
        "if not (isinstance(field, models.ForeignKey) or"
    ],
    [
        "\"The value of '%s' refers to '%s', which is not an \"",
        "\"The value of '%s' refers to '%s',"
    ],
    [
        "\"instance of ForeignKey, and does not have a 'choices' \"",
        "\"instance of ForeignKey, and does not have"
    ],
    [
        "\"\"\"Check type of a value of `radio_fields` dictionary.\"\"\"",
        "\"\"\"Check type of a value of `radio_fields`"
    ],
    [
        "if val not in (HORIZONTAL, VERTICAL):",
        "if val not in"
    ],
    [
        "\"The value of '%s' must be either admin.HORIZONTAL or \"",
        "\"The value of '%s' must be either"
    ],
    [
        "if not callable(obj.view_on_site) and not isinstance(obj.view_on_site, bool):",
        "if not callable(obj.view_on_site) and not"
    ],
    [
        "\"The value of 'view_on_site' must be a callable or a boolean \"",
        "\"The value of 'view_on_site' must be a"
    ],
    [
        "\"\"\"Check that `prepopulated_fields` is a dictionary containing allowed",
        "\"\"\"Check that `prepopulated_fields` is a dictionary"
    ],
    [
        "\"\"\"Check a key of `prepopulated_fields` dictionary, i.e. check that it",
        "\"\"\"Check a key of `prepopulated_fields` dictionary, i.e. check"
    ],
    [
        "is a name of existing field and the field is one of the allowed types.",
        "is a name of existing field and the field"
    ],
    [
        "\"The value of '%s' refers to '%s', which must not be a \"",
        "\"The value of '%s' refers to '%s', which must not"
    ],
    [
        "\"DateTimeField, a ForeignKey, a OneToOneField, or a \"",
        "\"DateTimeField, a ForeignKey, a OneToOneField, or"
    ],
    [
        "\"\"\"Check a value of `prepopulated_fields` dictionary, i.e. it's an",
        "\"\"\"Check a value of `prepopulated_fields` dictionary,"
    ],
    [
        "obj, subfield_name, \"%s[%r]\" % (label, index)",
        "obj, subfield_name, \"%s[%r]\" % (label,"
    ],
    [
        "\"\"\"For `prepopulated_fields` equal to {\"slug\": (\"title\",)},",
        "\"\"\"For `prepopulated_fields` equal to {\"slug\":"
    ],
    [
        "\"\"\"Check that ordering refers to existing fields or is random.\"\"\"",
        "\"\"\"Check that ordering refers to existing fields or is"
    ],
    [
        "\"\"\"Check that `ordering` refers to existing fields.\"\"\"",
        "\"\"\"Check that `ordering` refers"
    ],
    [
        "\"The value of 'ordering' has the random ordering marker '?', \"",
        "\"The value of 'ordering' has the random"
    ],
    [
        "\"but contains other fields as well.\",",
        "\"but contains other fields"
    ],
    [
        "hint='Either remove the \"?\", or remove the other fields.',",
        "hint='Either remove the \"?\", or remove"
    ],
    [
        "\"\"\"Check that readonly_fields refers to proper attribute or field.\"\"\"",
        "\"\"\"Check that readonly_fields refers to proper"
    ],
    [
        "\"The value of '%s' refers to '%s', which is not a callable, \"",
        "\"The value of '%s' refers to '%s', which is"
    ],
    [
        "\"an attribute of '%s', or an attribute of '%s'.\"",
        "\"an attribute of '%s', or an attribute"
    ],
    [
        "\"\"\"Check all inline model admin classes.\"\"\"",
        "\"\"\"Check all inline"
    ],
    [
        "inline_label = inline.__module__ + \".\" + inline.__name__",
        "inline_label = inline.__module__ + \".\""
    ],
    [
        "\"'%s' must inherit from 'InlineModelAdmin'.\" % obj,",
        "\"'%s' must inherit from 'InlineModelAdmin'.\" %"
    ],
    [
        "\"'%s' must inherit from 'InlineModelAdmin'.\" % inline_label,",
        "\"'%s' must inherit from 'InlineModelAdmin'.\" %"
    ],
    [
        "\"'%s' must have a 'model' attribute.\" % inline_label,",
        "\"'%s' must have a 'model' attribute.\""
    ],
    [
        "\"\"\"Check that list_display only contains fields or usable attributes.\"\"\"",
        "\"\"\"Check that list_display only contains"
    ],
    [
        "f\"The value of '{label}' refers to '{item}', which is not \"",
        "f\"The value of '{label}' refers to '{item}', which is"
    ],
    [
        "f\"a callable or attribute of '{obj.__class__.__name__}', \"",
        "f\"a callable or attribute"
    ],
    [
        "\"or an attribute, method, or field on \"",
        "\"or an attribute, method, or field"
    ],
    [
        ") or (getattr(field, \"rel\", None) and field.rel.field.many_to_one):",
        ") or (getattr(field, \"rel\", None)"
    ],
    [
        "f\"The value of '{label}' must not be a many-to-many field or a \"",
        "f\"The value of '{label}' must not be a"
    ],
    [
        "\"\"\"Check that list_display_links is a unique subset of list_display.\"\"\"",
        "\"\"\"Check that list_display_links is a unique subset of"
    ],
    [
        "\"a list, a tuple, or None\",",
        "\"a list, a tuple, or"
    ],
    [
        "\"The value of '%s' refers to '%s', which is not defined in \"",
        "\"The value of '%s' refers to '%s', which is not defined"
    ],
    [
        "Check one item of `list_filter`, i.e. check if it is one of three options:",
        "Check one item of `list_filter`, i.e. check if it is"
    ],
    [
        "if callable(item) and not isinstance(item, models.Field):",
        "if callable(item) and not"
    ],
    [
        "\"The value of '%s' must not inherit from 'FieldListFilter'.\"",
        "\"The value of '%s' must not"
    ],
    [
        "\"The value of '%s' refers to '%s', which does not refer to a \"",
        "\"The value of '%s' refers to '%s', which does not refer to a"
    ],
    [
        "\"\"\"Check that list_select_related is a boolean, a list or a tuple.\"\"\"",
        "\"\"\"Check that list_select_related is a boolean, a list or a"
    ],
    [
        "if not isinstance(obj.list_select_related, (bool, list, tuple)):",
        "if not isinstance(obj.list_select_related, (bool,"
    ],
    [
        "\"\"\"Check that list_per_page is an integer.\"\"\"",
        "\"\"\"Check that list_per_page"
    ],
    [
        "\"\"\"Check that list_max_show_all is an integer.\"\"\"",
        "\"\"\"Check that list_max_show_all is"
    ],
    [
        "\"\"\"Check that list_editable is a sequence of editable fields from",
        "\"\"\"Check that list_editable is a sequence of"
    ],
    [
        "\"The value of '%s' refers to '%s', which is not \"",
        "\"The value of '%s' refers to '%s', which is not"
    ],
    [
        "\"contained in 'list_display'.\" % (label, field_name),",
        "\"contained in 'list_display'.\" %"
    ],
    [
        "elif obj.list_display_links and field_name in obj.list_display_links:",
        "elif obj.list_display_links and"
    ],
    [
        "\"The value of '%s' cannot be in both 'list_editable' and \"",
        "\"The value of '%s' cannot be"
    ],
    [
        "\"The value of '%s' refers to the first field in 'list_display' \"",
        "\"The value of '%s' refers to the"
    ],
    [
        "\"('%s'), which cannot be used unless 'list_display_links' is \"",
        "\"('%s'), which cannot be used unless 'list_display_links' is"
    ],
    [
        "\"The value of '%s' refers to '%s', which is not editable \"",
        "\"The value of '%s' refers to '%s', which is"
    ],
    [
        "\"through the admin.\" % (label, field_name),",
        "\"through the admin.\" % (label,"
    ],
    [
        "\"\"\"Check that date_hierarchy refers to DateField or DateTimeField.\"\"\"",
        "\"\"\"Check that date_hierarchy refers to DateField or"
    ],
    [
        "\"The value of 'date_hierarchy' refers to '%s', which \"",
        "\"The value of 'date_hierarchy' refers"
    ],
    [
        "\"does not refer to a Field.\" % obj.date_hierarchy,",
        "\"does not refer to a"
    ],
    [
        "if field.get_internal_type() not in {\"DateField\", \"DateTimeField\"}:",
        "if field.get_internal_type() not in {\"DateField\","
    ],
    [
        "for func, name, _ in actions:",
        "for func, name, _ in"
    ],
    [
        "\"%s must define a %s() method for the %s action.\"",
        "\"%s must define a %s()"
    ],
    [
        "names = collections.Counter(name for _, name, _ in actions)",
        "names = collections.Counter(name for _, name, _ in"
    ],
    [
        "\"__name__ attributes of actions defined in %s must be \"",
        "\"__name__ attributes of actions defined"
    ],
    [
        "\"unique. Name %r is not unique.\"",
        "\"unique. Name %r"
    ],
    [
        "\"Cannot exclude the field '%s', because it is the foreign key \"",
        "\"Cannot exclude the field '%s', because it is"
    ],
    [
        "\"\"\"Check that extra is an integer.\"\"\"",
        "\"\"\"Check that extra"
    ],
    [
        "\"\"\"Check that max_num is an integer.\"\"\"",
        "\"\"\"Check that max_num is an"
    ],
    [
        "\"\"\"Check that min_num is an integer.\"\"\"",
        "\"\"\"Check that min_num"
    ],
    [
        "\"\"\"Check formset is a subclass of BaseModelFormSet.\"\"\"",
        "\"\"\"Check formset is a"
    ],
    [
        "\"The value of '%s' must be %s.\" % (option, type),",
        "\"The value of '%s' must be %s.\" % (option,"
    ],
    [
        "\"The value of '%s' must inherit from '%s'.\" % (option, parent),",
        "\"The value of '%s' must inherit"
    ],
    [
        "\"The value of '%s' refers to '%s', which is not a field of '%s'.\"",
        "\"The value of '%s' refers to '%s', which"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "Default action which deletes the selected objects.",
        "Default action which deletes the selected"
    ],
    [
        "This action first displays a confirmation page which shows all the",
        "This action first displays a confirmation"
    ],
    [
        "deletable objects, or, if the user has no permission one of the related",
        "deletable objects, or, if the user has no permission one of"
    ],
    [
        "childs (foreignkeys), a \"permission denied\" message.",
        "childs (foreignkeys), a \"permission denied\""
    ],
    [
        "Next, it deletes all selected objects and redirects back to the change list.",
        "Next, it deletes all selected objects and"
    ],
    [
        "% {\"count\": n, \"items\": model_ngettext(modeladmin.opts, n)},",
        "% {\"count\": n,"
    ],
    [
        "title = _(\"Cannot delete %(name)s\") % {\"name\": objects_name}",
        "title = _(\"Cannot delete %(name)s\") % {\"name\":"
    ],
    [
        "from django.contrib.admin.decorators import action, display, register",
        "from django.contrib.admin.decorators import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "\"\"\"Simple AppConfig which does not do automatic discovery.\"\"\"",
        "\"\"\"Simple AppConfig which does not do"
    ],
    [
        "\"\"\"The default AppConfig for admin which does autodiscovery.\"\"\"",
        "\"\"\"The default AppConfig for admin which does"
    ],
    [
        "Form Widget classes specific to the Django admin site.",
        "Form Widget classes specific to the Django"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "A SelectMultiple with a JavaScript filter interface.",
        "A SelectMultiple with a"
    ],
    [
        "catalog has been loaded in the page",
        "catalog has been loaded in"
    ],
    [
        "def __init__(self, verbose_name, is_stacked, attrs=None, choices=()):",
        "def __init__(self, verbose_name, is_stacked, attrs=None,"
    ],
    [
        "A SplitDateTime Widget that has some admin-specific styling.",
        "A SplitDateTime Widget that has some"
    ],
    [
        "Convert the type of lookups specified in a ForeignKey limit_choices_to",
        "Convert the type of lookups specified in"
    ],
    [
        "attribute to a dictionary of query parameters",
        "attribute to a dictionary of query"
    ],
    [
        "v = \",\".join(str(x) for x in v)",
        "v = \",\".join(str(x) for x"
    ],
    [
        "A Widget for displaying ForeignKeys in the \"raw_id\" interface rather than",
        "A Widget for displaying ForeignKeys in"
    ],
    [
        "def __init__(self, rel, admin_site, attrs=None, using=None):",
        "def __init__(self, rel, admin_site,"
    ],
    [
        "A Widget for displaying ManyToMany ids in the \"raw_id\" interface rather than",
        "A Widget for displaying ManyToMany ids in the \"raw_id\" interface rather"
    ],
    [
        "return \",\".join(str(v) for v in value) if value else \"\"",
        "return \",\".join(str(v) for v in value) if"
    ],
    [
        "This class is a wrapper to a given widget to add the add icon for the",
        "This class is a wrapper to a given widget to add the add icon"
    ],
    [
        "self.can_change_related = not multiple and can_change_related",
        "self.can_change_related = not multiple"
    ],
    [
        "cascade = getattr(rel, \"on_delete\", None) is CASCADE",
        "cascade = getattr(rel, \"on_delete\","
    ],
    [
        "self.can_delete_related = not multiple and not cascade and can_delete_related",
        "self.can_delete_related = not multiple and not cascade and"
    ],
    [
        "self.can_view_related = not multiple and can_view_related",
        "self.can_view_related = not multiple"
    ],
    [
        "if supported_code is None and lang_code is not None:",
        "if supported_code is None and lang_code is"
    ],
    [
        "Select widget mixin that loads options from AutocompleteJsonView via AJAX.",
        "Select widget mixin that loads"
    ],
    [
        "def __init__(self, field, admin_site, attrs=None, choices=(), using=None):",
        "def __init__(self, field, admin_site,"
    ],
    [
        "self.attrs = {} if attrs is None else attrs.copy()",
        "self.attrs = {} if attrs"
    ],
    [
        "Nested attributes require a double dash as per",
        "Nested attributes require a double dash as"
    ],
    [
        "+ (\" \" if attrs[\"class\"] else \"\")",
        "+ (\" \" if"
    ],
    [
        "\"\"\"Return selected options based on the ModelChoiceIterator.\"\"\"",
        "\"\"\"Return selected options based on"
    ],
    [
        "str(v) for v in value if str(v) not in self.choices.field.empty_values",
        "str(v) for v in value"
    ],
    [
        "if not self.is_required and not self.allow_multiple_selected:",
        "if not self.is_required and"
    ],
    [
        "selected = str(option_value) in value and (",
        "selected = str(option_value) in value"
    ],
    [
        "extra = \"\" if settings.DEBUG else \".min\"",
        "extra = \"\" if"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "A custom authentication form used in the admin app.",
        "A custom authentication form used in the"
    ],
    [
        "\"Please enter the correct %(username)s and password for a staff \"",
        "\"Please enter the correct %(username)s and password for a"
    ],
    [
        "\"account. Note that both fields may be case-sensitive.\"",
        "\"account. Note that both fields may be"
    ],
    [
        "from django.utils.translation import override as translation_override",
        "from django.utils.translation import"
    ],
    [
        "UNQUOTE_MAP = {v: chr(k) for k, v in QUOTE_MAP.items()}",
        "UNQUOTE_MAP = {v: chr(k) for k,"
    ],
    [
        "\"\"\"A field is a foreign key attname, i.e. <FK>_id.\"\"\"",
        "\"\"\"A field is a foreign key attname,"
    ],
    [
        "Return True if the given lookup path spawns duplicates.",
        "Return True if the given lookup path"
    ],
    [
        "Return a lookup value prepared to be used in queryset filtering.",
        "Return a lookup value prepared to be used"
    ],
    [
        "return [prepare_lookup_value(key, v, separator=separator) for v in value]",
        "return [prepare_lookup_value(key, v, separator=separator) for"
    ],
    [
        "q_object &= reduce(or_, (models.Q((param, item)) for item in param_item_list))",
        "q_object &= reduce(or_, (models.Q((param, item)) for item in"
    ],
    [
        "Ensure that primary key values do not confuse the admin URLs by escaping",
        "Ensure that primary key values do not confuse the admin"
    ],
    [
        "any '/', '_' and ':' and similarly problematic characters.",
        "any '/', '_' and ':' and similarly"
    ],
    [
        "Similar to urllib.parse.quote(), except that the quoting is slightly",
        "Similar to urllib.parse.quote(), except that"
    ],
    [
        "different so that it doesn't get automatically unquoted by the web browser.",
        "different so that it doesn't get automatically unquoted by the"
    ],
    [
        "return s.translate(QUOTE_MAP) if isinstance(s, str) else s",
        "return s.translate(QUOTE_MAP) if isinstance(s, str) else"
    ],
    [
        "Return a list which is a single level of flattening of the original list.",
        "Return a list which is a single level of"
    ],
    [
        "\"\"\"Return a list of field names from an admin fieldsets structure.\"\"\"",
        "\"\"\"Return a list of field names"
    ],
    [
        "Find all objects related to ``objs`` that should also be deleted. ``objs``",
        "Find all objects related to ``objs`` that"
    ],
    [
        "must be a homogeneous iterable of objects (e.g. a QuerySet).",
        "must be a homogeneous iterable of objects"
    ],
    [
        "Return a nested list of strings suitable for display in the",
        "Return a nested list of strings suitable for display in"
    ],
    [
        "no_edit_link = \"%s: %s\" % (capfirst(opts.verbose_name), obj)",
        "no_edit_link = \"%s: %s\" %"
    ],
    [
        "'{}: <a href=\"{}\">{}</a>', capfirst(opts.verbose_name), admin_url, obj",
        "'{}: <a href=\"{}\">{}</a>',"
    ],
    [
        "protected = [format_callback(obj) for obj in collector.protected]",
        "protected = [format_callback(obj) for obj in"
    ],
    [
        "def collect(self, objs, source=None, source_attr=None, **kwargs):",
        "def collect(self, objs, source=None, source_attr=None,"
    ],
    [
        "Return the graph as a nested list.",
        "Return the graph as a"
    ],
    [
        "We always want to load the objects into memory so that we can display",
        "We always want to load the objects into memory so that we"
    ],
    [
        "them to the user in confirm page.",
        "them to the user"
    ],
    [
        "Return a `dict` with keys 'verbose_name' and 'verbose_name_plural',",
        "Return a `dict` with keys"
    ],
    [
        "typically for use with string formatting.",
        "typically for use with"
    ],
    [
        "`obj` may be a `Model` instance, `Model` subclass, or `QuerySet` instance.",
        "`obj` may be a `Model` instance, `Model` subclass, or"
    ],
    [
        "Return the appropriate `verbose_name` or `verbose_name_plural` value for",
        "Return the appropriate `verbose_name` or `verbose_name_plural` value"
    ],
    [
        "`obj` depending on the count `n`.",
        "`obj` depending on"
    ],
    [
        "`obj` may be a `Model` instance, `Model` subclass, or `QuerySet` instance.",
        "`obj` may be a `Model` instance, `Model` subclass, or"
    ],
    [
        "If `obj` is a `QuerySet` instance, `n` is optional and the length of the",
        "If `obj` is a `QuerySet` instance, `n` is optional and the"
    ],
    [
        "elif hasattr(model_admin, name) and name != \"__str__\":",
        "elif hasattr(model_admin, name) and"
    ],
    [
        "if hasattr(model_admin, \"model\") and hasattr(model_admin.model, name):",
        "if hasattr(model_admin, \"model\")"
    ],
    [
        "For historical reasons, the admin app relies on GenericForeignKeys as being",
        "For historical reasons, the admin app relies on GenericForeignKeys"
    ],
    [
        "\"not found\" by get_field(). This could likely be cleaned up.",
        "\"not found\" by get_field(). This could likely be cleaned"
    ],
    [
        "Reverse relations should also be excluded as these aren't attributes of the",
        "Reverse relations should also be excluded as these aren't attributes"
    ],
    [
        "((field.many_to_one and not field.related_model) or field.one_to_many)",
        "((field.many_to_one and not field.related_model) or"
    ],
    [
        "def label_for_field(name, model, model_admin=None, return_attr=False, form=None):",
        "def label_for_field(name, model, model_admin=None,"
    ],
    [
        "Return a sensible label for a field name. The name can be a callable,",
        "Return a sensible label for a field name. The name"
    ],
    [
        "property (but not created with @property decorator), or the name of an",
        "property (but not created with @property decorator), or the name of"
    ],
    [
        "object's attribute, as well as a model field, including across related",
        "object's attribute, as well as a model"
    ],
    [
        "objects. If return_attr is True, also return the resolved attribute",
        "objects. If return_attr is True, also return"
    ],
    [
        "(which could be a callable). This will be None if (and only if) the name",
        "(which could be a callable). This will be None if (and only if) the"
    ],
    [
        "elif form and name in form.fields:",
        "elif form and"
    ],
    [
        "message = f\"Unable to lookup '{name}' on {model._meta.object_name}\"",
        "message = f\"Unable to lookup '{name}'"
    ],
    [
        "elif isinstance(field, models.FileField) and value and not avoid_link:",
        "elif isinstance(field, models.FileField) and value"
    ],
    [
        "elif isinstance(field, models.URLField) and value and not avoid_link:",
        "elif isinstance(field, models.URLField) and"
    ],
    [
        "return \", \".join(str(v) for v in value)",
        "return \", \".join(str(v) for v"
    ],
    [
        "Final field must be a related model, not a data field.",
        "Final field must be a related"
    ],
    [
        "if field.is_relation and not (field.auto_created and not field.concrete):",
        "if field.is_relation and not (field.auto_created and"
    ],
    [
        "\"\"\"Return list of Fields given path relative to model.",
        "\"\"\"Return list of Fields given"
    ],
    [
        "Construct a JSON structure describing changes from a changed object.",
        "Construct a JSON structure describing changes from"
    ],
    [
        "Translations are deactivated so that strings are stored untranslated.",
        "Translations are deactivated so that strings are stored"
    ],
    [
        "Translation happens later on LogEntry access.",
        "Translation happens later on LogEntry"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "An AdminSite object encapsulates an instance of the Django admin application, ready",
        "An AdminSite object encapsulates an instance of the Django admin"
    ],
    [
        "to be hooked in to your URLconf. Models are registered with the AdminSite using the",
        "to be hooked in to your URLconf. Models are registered with"
    ],
    [
        "register() method, and the get_urls() method can then be used to access Django view",
        "register() method, and the get_urls() method can then be"
    ],
    [
        "functions that present a full admin interface for the collection of registered",
        "functions that present a full admin interface for the"
    ],
    [
        "Run the system checks on all ModelAdmins, except if they aren't",
        "Run the system checks on all ModelAdmins, except if they"
    ],
    [
        "o for o in self._registry.values() if o.__class__ is not ModelAdmin",
        "o for o in self._registry.values()"
    ],
    [
        "Register the given model(s) with the given admin class.",
        "Register the given model(s) with the"
    ],
    [
        "The model(s) should be Model classes, not instances.",
        "The model(s) should be Model classes, not"
    ],
    [
        "If an admin class isn't given, use ModelAdmin (the default admin",
        "If an admin class isn't given, use ModelAdmin"
    ],
    [
        "options). If keyword arguments are given -- e.g., list_display --",
        "options). If keyword arguments are"
    ],
    [
        "apply them as options to the admin class.",
        "apply them as options to the"
    ],
    [
        "If a model is already registered, raise AlreadyRegistered.",
        "If a model is already registered, raise"
    ],
    [
        "If a model is abstract, raise ImproperlyConfigured.",
        "If a model is"
    ],
    [
        "\"The model %s is abstract, so it cannot be registered with admin.\"",
        "\"The model %s is abstract, so it"
    ],
    [
        "\"The model %s has a composite primary key, so it cannot be \"",
        "\"The model %s has a composite primary key, so"
    ],
    [
        "msg = \"The model %s is already registered \" % model.__name__",
        "msg = \"The model %s is already registered \""
    ],
    [
        "msg += \"in app %r.\" % registered_admin.removesuffix(\".ModelAdmin\")",
        "msg += \"in app %r.\" %"
    ],
    [
        "msg += \"with %r.\" % registered_admin",
        "msg += \"with %r.\""
    ],
    [
        "If a model isn't already registered, raise NotRegistered.",
        "If a model isn't already"
    ],
    [
        "raise NotRegistered(\"The model %s is not registered\" % model.__name__)",
        "raise NotRegistered(\"The model %s is not registered\" %"
    ],
    [
        "Check if a model class is registered with this `AdminSite`.",
        "Check if a model class is registered"
    ],
    [
        "raise NotRegistered(f\"The model {model.__name__} is not registered.\")",
        "raise NotRegistered(f\"The model {model.__name__}"
    ],
    [
        "Register an action to be available globally.",
        "Register an action to"
    ],
    [
        "Disable a globally-registered action. Raise KeyError for invalid names.",
        "Disable a globally-registered action. Raise KeyError"
    ],
    [
        "Explicitly get a registered global action whether it's enabled or",
        "Explicitly get a registered global"
    ],
    [
        "not. Raise KeyError for invalid names.",
        "not. Raise KeyError for"
    ],
    [
        "Get all the enabled actions as an iterable of (name, func).",
        "Get all the enabled actions as"
    ],
    [
        "Return True if the given HttpRequest has permission to view",
        "Return True if the given HttpRequest has permission to"
    ],
    [
        "*at least one* page in the admin site.",
        "*at least one* page in the admin"
    ],
    [
        "Decorator to create an admin view attached to this ``AdminSite``. This",
        "Decorator to create an admin view attached"
    ],
    [
        "wraps the view and provides permission checking by calling",
        "wraps the view and provides permission checking by"
    ],
    [
        "You'll want to use this from within ``AdminSite.get_urls()``:",
        "You'll want to use"
    ],
    [
        "By default, admin_views are marked non-cacheable using the",
        "By default, admin_views are marked non-cacheable"
    ],
    [
        "``never_cache`` decorator. If the view can be safely cached, set",
        "``never_cache`` decorator. If the view can be safely"
    ],
    [
        "from django.contrib.contenttypes import views as contenttype_views",
        "from django.contrib.contenttypes import views"
    ],
    [
        "from django.urls import include, path, re_path",
        "from django.urls import include,"
    ],
    [
        "regex = r\"^(?P<app_label>\" + \"|\".join(valid_app_labels) + \")/$\"",
        "regex = r\"^(?P<app_label>\" + \"|\".join(valid_app_labels)"
    ],
    [
        "Return a dictionary of variables to put in the template context for",
        "Return a dictionary of variables to put in the"
    ],
    [
        "*every* page in the admin site.",
        "*every* page in"
    ],
    [
        "For sites running on a subpath, use the SCRIPT_NAME value if site_url",
        "For sites running on a subpath, use the SCRIPT_NAME"
    ],
    [
        "script_name if self.site_url == \"/\" and script_name else self.site_url",
        "script_name if self.site_url == \"/\""
    ],
    [
        "Handle the \"change password\" task -- both form display and validation.",
        "Handle the \"change password\" task -- both"
    ],
    [
        "Display the \"success\" page after a password change.",
        "Display the \"success\" page after"
    ],
    [
        "`extra_context` is unused but present for consistency with the other",
        "`extra_context` is unused but present for consistency with"
    ],
    [
        "Log out the user for the given HttpRequest.",
        "Log out the user for"
    ],
    [
        "This should *not* assume the user is already logged in.",
        "This should *not* assume the user is"
    ],
    [
        "Display the login form for the given HttpRequest.",
        "Display the login form"
    ],
    [
        "if request.method == \"GET\" and self.has_permission(request):",
        "if request.method == \"GET\" and"
    ],
    [
        "match = resolve(\"%s/\" % request.path_info, urlconf)",
        "match = resolve(\"%s/\" % request.path_info,"
    ],
    [
        "Build the app dictionary. The optional `label` parameter filters models",
        "Build the app dictionary. The optional"
    ],
    [
        "Return a sorted list of all the installed apps that have been",
        "Return a sorted list of all the installed apps that have"
    ],
    [
        "app_list = sorted(app_dict.values(), key=lambda x: x[\"name\"].lower())",
        "app_list = sorted(app_dict.values(), key=lambda x:"
    ],
    [
        "Display the main admin index page, which lists all of the installed",
        "Display the main admin index page, which lists all of the"
    ],
    [
        "apps that have been registered in this site.",
        "apps that have been registered in this"
    ],
    [
        "\"\"\"Invalid filter was passed to admin view via URL querystring\"\"\"",
        "\"\"\"Invalid filter was passed to admin"
    ],
    [
        "\"\"\"Invalid to_field was passed to admin view via URL query string\"\"\"",
        "\"\"\"Invalid to_field was passed to admin view"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "\"\"\"The admin's JavaScript should be compatible with CSP.\"\"\"",
        "\"\"\"The admin's JavaScript should be"
    ],
    [
        "Block the execution of the tests until the specified callback returns a",
        "Block the execution of the tests until the specified callback"
    ],
    [
        "value that is not falsy. This method can be called, for example, after",
        "value that is not falsy. This method"
    ],
    [
        "clicking a link or submitting a form. See the other public methods that",
        "clicking a link or submitting a form. See the other public methods"
    ],
    [
        "call this function for more details.",
        "call this function for"
    ],
    [
        "be overridden in the case of pop-ups opening other pop-ups). Switch the",
        "be overridden in the case of"
    ],
    [
        "current window to the new pop-up.",
        "current window to"
    ],
    [
        "self.wait_until(lambda d: len(d.window_handles) == num_windows, timeout)",
        "self.wait_until(lambda d: len(d.window_handles) =="
    ],
    [
        "Block until a CSS selector is found on the page.",
        "Block until a CSS selector is"
    ],
    [
        "from selenium.webdriver.support import expected_conditions as ec",
        "from selenium.webdriver.support import expected_conditions as"
    ],
    [
        "Block until the text is found in the CSS selector.",
        "Block until the text is found in the CSS"
    ],
    [
        "from selenium.webdriver.support import expected_conditions as ec",
        "from selenium.webdriver.support import"
    ],
    [
        "Block until the value is found in the CSS selector.",
        "Block until the value is"
    ],
    [
        "from selenium.webdriver.support import expected_conditions as ec",
        "from selenium.webdriver.support import expected_conditions"
    ],
    [
        "Block until the element described by the CSS selector is visible.",
        "Block until the element described by the CSS"
    ],
    [
        "from selenium.webdriver.support import expected_conditions as ec",
        "from selenium.webdriver.support import expected_conditions"
    ],
    [
        "Block until the element described by the CSS selector is invisible.",
        "Block until the element described by the CSS selector is"
    ],
    [
        "from selenium.webdriver.support import expected_conditions as ec",
        "from selenium.webdriver.support import"
    ],
    [
        "Block until the  page is ready.",
        "Block until the page is"
    ],
    [
        "Block until a new page has loaded and is ready.",
        "Block until a new page"
    ],
    [
        "from selenium.webdriver.support import expected_conditions as ec",
        "from selenium.webdriver.support import expected_conditions as"
    ],
    [
        "Select the <OPTION> with the value `value` inside the <SELECT> widget",
        "Select the <OPTION> with the value"
    ],
    [
        "identified by the CSS selector `selector`.",
        "identified by the"
    ],
    [
        "Deselect the <OPTION> with the value `value` inside the <SELECT> widget",
        "Deselect the <OPTION> with the value `value` inside the <SELECT>"
    ],
    [
        "identified by the CSS selector `selector`.",
        "identified by the CSS"
    ],
    [
        "Assert number of matches for a CSS selector.",
        "Assert number of matches"
    ],
    [
        "`root_element` allow restriction to a pre-selected node.",
        "`root_element` allow restriction to"
    ],
    [
        "Assert that the <SELECT> widget identified by `selector` has the",
        "Assert that the <SELECT> widget identified by"
    ],
    [
        "self._assertOptionsValues(\"%s > option\" % selector, values)",
        "self._assertOptionsValues(\"%s > option\""
    ],
    [
        "Assert that the <SELECT> widget identified by `selector` has the",
        "Assert that the <SELECT> widget identified by `selector`"
    ],
    [
        "selected options with the given `values`.",
        "selected options with the given"
    ],
    [
        "self._assertOptionsValues(\"%s > option:checked\" % selector, values)",
        "self._assertOptionsValues(\"%s > option:checked\" % selector,"
    ],
    [
        "Return True if the element identified by `selector` has the `disabled`",
        "Return True if the element identified by `selector` has"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "{\"field\": form[field_name], \"dependencies\": [form[f] for f in dependencies]}",
        "{\"field\": form[field_name], \"dependencies\": [form[f] for"
    ],
    [
        "if any(field in self.fields for field in self.form.errors):",
        "if any(field in self.fields"
    ],
    [
        "def __init__(self, form, field, readonly_fields=None, model_admin=None):",
        "def __init__(self, form, field,"
    ],
    [
        "if not hasattr(field, \"__iter__\") or isinstance(field, str):",
        "if not hasattr(field, \"__iter__\") or isinstance(field,"
    ],
    [
        "attrs = {\"class\": \" \".join(classes)} if classes else {}",
        "attrs = {\"class\": \" \".join(classes)} if"
    ],
    [
        "def __init__(self, form, field, is_first, model_admin=None):",
        "def __init__(self, form, field, is_first,"
    ],
    [
        "class_name = field.__name__ if field.__name__ != \"<lambda>\" else \"\"",
        "class_name = field.__name__ if field.__name__ != \"<lambda>\""
    ],
    [
        "if form._meta.labels and class_name in form._meta.labels:",
        "if form._meta.labels and class_name"
    ],
    [
        "label = label_for_field(field, form._meta.model, model_admin, form=form)",
        "label = label_for_field(field, form._meta.model, model_admin,"
    ],
    [
        "if form._meta.help_texts and class_name in form._meta.help_texts:",
        "if form._meta.help_texts and class_name"
    ],
    [
        "f, attr, value = lookup_field(field, obj, model_admin)",
        "f, attr, value = lookup_field(field,"
    ],
    [
        "if isinstance(f.remote_field, ManyToManyRel) and value is not None:",
        "if isinstance(f.remote_field, ManyToManyRel) and value is not"
    ],
    [
        "A wrapper around an inline formset for use in the admin system.",
        "A wrapper around an inline formset"
    ],
    [
        "self.classes = \" \".join(inline.classes) if inline.classes else \"\"",
        "self.classes = \" \".join(inline.classes) if inline.classes"
    ],
    [
        "if fk and fk.name == field_name:",
        "if fk and"
    ],
    [
        "if not self.has_change_permission or field_name in self.readonly_fields:",
        "if not self.has_change_permission or field_name in"
    ],
    [
        "A wrapper around an inline form for use in the admin system.",
        "A wrapper around an inline form"
    ],
    [
        "self.show_url = original and view_on_site_url is not None",
        "self.show_url = original and view_on_site_url"
    ],
    [
        "if not fk or fk.name != field:",
        "if not fk or fk.name"
    ],
    [
        "\"\"\"Store errors for the form/formsets in an add/change view.\"\"\"",
        "\"\"\"Store errors for the form/formsets"
    ],
    [
        "This encapsulates the logic for displaying filters in the Django admin.",
        "This encapsulates the logic for displaying filters in"
    ],
    [
        "Filters are specified in models with the \"list_filter\" option.",
        "Filters are specified in models"
    ],
    [
        "Each filter subclass knows how to display a filter for a field that passes a",
        "Each filter subclass knows how to display a filter for a field that"
    ],
    [
        "certain test -- e.g. being a DateField or ForeignKey.",
        "certain test -- e.g. being a DateField"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "def __init__(self, request, params, model, model_admin):",
        "def __init__(self, request,"
    ],
    [
        "\"The list filter '%s' does not specify a 'title'.\"",
        "\"The list filter '%s' does"
    ],
    [
        "Return True if some choices would be output for this filter.",
        "Return True if some choices would"
    ],
    [
        "\"subclasses of ListFilter must provide a has_output() method\"",
        "\"subclasses of ListFilter must provide a"
    ],
    [
        "Return choices ready to be output in the template.",
        "Return choices ready to be output in the"
    ],
    [
        "`changelist` is the ChangeList to be displayed.",
        "`changelist` is the ChangeList"
    ],
    [
        "\"subclasses of ListFilter must provide a choices() method\"",
        "\"subclasses of ListFilter must provide"
    ],
    [
        "\"subclasses of ListFilter must provide a queryset() method\"",
        "\"subclasses of ListFilter must"
    ],
    [
        "Return the list of parameter names that are expected from the",
        "Return the list of parameter names that"
    ],
    [
        "request's query string and that will be used by this filter.",
        "request's query string and that will be used by"
    ],
    [
        "\"subclasses of ListFilter must provide an expected_parameters() method\"",
        "\"subclasses of ListFilter must provide an expected_parameters()"
    ],
    [
        "\"subclasses of FacetsMixin must provide a get_facet_counts() method.\"",
        "\"subclasses of FacetsMixin must provide a"
    ],
    [
        "def __init__(self, request, params, model, model_admin):",
        "def __init__(self, request, params, model,"
    ],
    [
        "\"The list filter '%s' does not specify a 'parameter_name'.\"",
        "\"The list filter '%s' does not specify a"
    ],
    [
        "Return the value (in string format) provided in the request's",
        "Return the value (in string format) provided in"
    ],
    [
        "query string for this filter, if any, or None if the value wasn't",
        "query string for this filter, if any, or None if"
    ],
    [
        "Must be overridden to return a list of tuples (value, verbose value)",
        "Must be overridden to return a"
    ],
    [
        "\"The SimpleListFilter.lookups() method must be overridden to \"",
        "\"The SimpleListFilter.lookups() method must be overridden to"
    ],
    [
        "\"return a list of tuples (value, verbose value).\"",
        "\"return a list of tuples (value,"
    ],
    [
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else None",
        "facet_counts = self.get_facet_queryset(changelist) if"
    ],
    [
        "for i, (lookup, title) in enumerate(self.lookup_choices):",
        "for i, (lookup, title)"
    ],
    [
        "def __init__(self, field, request, params, model, model_admin, field_path):",
        "def __init__(self, field, request,"
    ],
    [
        "def create(cls, field, request, params, model, model_admin, field_path):",
        "def create(cls, field, request,"
    ],
    [
        "field, request, params, model, model_admin, field_path=field_path",
        "field, request, params, model,"
    ],
    [
        "def __init__(self, field, request, params, model, model_admin, field_path):",
        "def __init__(self, field, request, params,"
    ],
    [
        "self.lookup_kwarg = \"%s__%s__exact\" % (field_path, field.target_field.name)",
        "self.lookup_kwarg = \"%s__%s__exact\" % (field_path,"
    ],
    [
        "super().__init__(field, request, params, model, model_admin, field_path)",
        "super().__init__(field, request, params,"
    ],
    [
        "Return True if a \"(None)\" choice should be included, which filters",
        "Return True if a \"(None)\" choice should be included, which"
    ],
    [
        "return self.field.null or (self.field.is_relation and self.field.many_to_many)",
        "return self.field.null or (self.field.is_relation"
    ],
    [
        "Return the model admin's ordering for related field, if provided.",
        "Return the model admin's ordering for"
    ],
    [
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else None",
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else"
    ],
    [
        "\"selected\": self.lookup_val is None and not self.lookup_val_isnull,",
        "\"selected\": self.lookup_val is None and not"
    ],
    [
        "def __init__(self, field, request, params, model, model_admin, field_path):",
        "def __init__(self, field, request, params, model,"
    ],
    [
        "super().__init__(field, request, params, model, model_admin, field_path)",
        "super().__init__(field, request, params, model,"
    ],
    [
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else None",
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else"
    ],
    [
        "for lookup, title, count_field in (",
        "for lookup, title, count_field in"
    ],
    [
        "def __init__(self, field, request, params, model, model_admin, field_path):",
        "def __init__(self, field, request, params,"
    ],
    [
        "super().__init__(field, request, params, model, model_admin, field_path)",
        "super().__init__(field, request, params, model,"
    ],
    [
        "for i, (value, _) in enumerate(self.field.flatchoices)",
        "for i, (value, _) in"
    ],
    [
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else None",
        "facet_counts = self.get_facet_queryset(changelist) if add_facets"
    ],
    [
        "for i, (lookup, title) in enumerate(self.field.flatchoices):",
        "for i, (lookup, title)"
    ],
    [
        "def __init__(self, field, request, params, model, model_admin, field_path):",
        "def __init__(self, field, request,"
    ],
    [
        "(_(\"No date\"), {self.field_generic + \"isnull\": True}),",
        "(_(\"No date\"), {self.field_generic + \"isnull\":"
    ],
    [
        "(_(\"Has date\"), {self.field_generic + \"isnull\": False}),",
        "(_(\"Has date\"), {self.field_generic"
    ],
    [
        "super().__init__(field, request, params, model, model_admin, field_path)",
        "super().__init__(field, request, params,"
    ],
    [
        "for i, (_, param_dict) in enumerate(self.links)",
        "for i, (_, param_dict)"
    ],
    [
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else None",
        "facet_counts = self.get_facet_queryset(changelist) if"
    ],
    [
        "for i, (title, param_dict) in enumerate(self.links):",
        "for i, (title, param_dict) in"
    ],
    [
        "param_dict_str = {key: str(value) for key, value in param_dict.items()}",
        "param_dict_str = {key: str(value) for key,"
    ],
    [
        "def __init__(self, field, request, params, model, model_admin, field_path):",
        "def __init__(self, field, request, params, model, model_admin,"
    ],
    [
        "super().__init__(field, request, params, model, model_admin, field_path)",
        "super().__init__(field, request, params, model,"
    ],
    [
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else None",
        "facet_counts = self.get_facet_queryset(changelist) if"
    ],
    [
        "\"selected\": self.lookup_val is None and self.lookup_val_isnull is None,",
        "\"selected\": self.lookup_val is None"
    ],
    [
        "empty_title = f\"{empty_title} ({count})\" if add_facets else empty_title",
        "empty_title = f\"{empty_title} ({count})\" if"
    ],
    [
        "\"selected\": self.lookup_val is not None and val in self.lookup_val,",
        "\"selected\": self.lookup_val is not None and val"
    ],
    [
        "\"display\": f\"{val} ({count})\" if add_facets else val,",
        "\"display\": f\"{val} ({count})\" if add_facets else"
    ],
    [
        "def __init__(self, field, request, params, model, model_admin, field_path):",
        "def __init__(self, field, request, params, model,"
    ],
    [
        "if not field.empty_strings_allowed and not field.null:",
        "if not field.empty_strings_allowed and not"
    ],
    [
        "\"The list filter '%s' cannot be used with field '%s' which \"",
        "\"The list filter '%s' cannot be used"
    ],
    [
        "\"doesn't allow empty strings and nulls.\"",
        "\"doesn't allow empty"
    ],
    [
        "super().__init__(field, request, params, model, model_admin, field_path)",
        "super().__init__(field, request, params, model, model_admin,"
    ],
    [
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else None",
        "facet_counts = self.get_facet_queryset(changelist) if add_facets else"
    ],
    [
        "for lookup, title, count_field in (",
        "for lookup, title, count_field in"
    ],
    [
        "Conveniently add attributes to an action function::",
        "Conveniently add attributes to an"
    ],
    [
        "This is equivalent to setting some attributes (with the original, longer",
        "This is equivalent to setting some"
    ],
    [
        "make_published.short_description = 'Mark selected stories as published'",
        "make_published.short_description = 'Mark selected stories as"
    ],
    [
        "function=None, *, boolean=None, ordering=None, description=None, empty_value=None",
        "function=None, *, boolean=None,"
    ],
    [
        "Conveniently add attributes to a display function::",
        "Conveniently add attributes to"
    ],
    [
        "This is equivalent to setting some attributes (with the original, longer",
        "This is equivalent to setting some attributes (with the"
    ],
    [
        "if boolean is not None and empty_value is not None:",
        "if boolean is not None and"
    ],
    [
        "\"The boolean and empty_value arguments to the @display \"",
        "\"The boolean and empty_value arguments to the @display"
    ],
    [
        "Register the given model(s) classes and wrapped ModelAdmin class with",
        "Register the given model(s) classes and"
    ],
    [
        "The `site` kwarg is an admin site to use instead of the default admin site.",
        "The `site` kwarg is an admin site to use instead"
    ],
    [
        "from django.contrib.admin.sites import site as default_site",
        "from django.contrib.admin.sites import site as"
    ],
    [
        "raise ValueError(\"At least one model must be passed to register.\")",
        "raise ValueError(\"At least one model"
    ],
    [
        "raise ValueError(\"Wrapped class must subclass ModelAdmin.\")",
        "raise ValueError(\"Wrapped class must subclass"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "Generate an individual page index link in a paginated list.",
        "Generate an individual page index link in a"
    ],
    [
        "mark_safe(' class=\"end\"' if i == cl.paginator.num_pages else \"\"),",
        "mark_safe(' class=\"end\"' if i == cl.paginator.num_pages else"
    ],
    [
        "Generate the series of links to the pages in a paginated list.",
        "Generate the series of links to the"
    ],
    [
        "pagination_required = (not cl.show_all or not cl.can_show_all) and cl.multi_page",
        "pagination_required = (not cl.show_all or not cl.can_show_all) and"
    ],
    [
        "need_show_all_link = cl.can_show_all and not cl.show_all and cl.multi_page",
        "need_show_all_link = cl.can_show_all and not cl.show_all and"
    ],
    [
        "is_field_sortable = cl.sortable_by is None or field_name in cl.sortable_by",
        "is_field_sortable = cl.sortable_by is None or"
    ],
    [
        "aria_label = _(\"Select all objects on this page for an action\")",
        "aria_label = _(\"Select all objects on this page for an"
    ],
    [
        "if isinstance(attr, property) and hasattr(attr, \"fget\"):",
        "if isinstance(attr, property) and hasattr(attr,"
    ],
    [
        "if not admin_order_field and LOOKUP_SEP not in field_name:",
        "if not admin_order_field and LOOKUP_SEP not in"
    ],
    [
        "new_order_type = {\"asc\": \"desc\", \"desc\": \"asc\"}[order_type]",
        "new_order_type = {\"asc\": \"desc\","
    ],
    [
        "return (\"-\" if t == \"desc\" else \"\") + str(n)",
        "return (\"-\" if t == \"desc\" else \"\")"
    ],
    [
        "format_html(' class=\"{}\"', \" \".join(th_classes)) if th_classes else \"\"",
        "format_html(' class=\"{}\"', \" \".join(th_classes)) if th_classes else"
    ],
    [
        "\"admin/img/icon-%s.svg\" % {True: \"yes\", False: \"no\", None: \"unknown\"}[field_val]",
        "\"admin/img/icon-%s.svg\" % {True: \"yes\", False: \"no\","
    ],
    [
        "return format_html('<img src=\"{}\" alt=\"{}\">', icon_url, field_val)",
        "return format_html('<img src=\"{}\" alt=\"{}\">', icon_url,"
    ],
    [
        "Coerce a field_name (which may be a callable) to a string.",
        "Coerce a field_name (which may be a"
    ],
    [
        "Generate the actual list of data.",
        "Generate the actual list"
    ],
    [
        "row_classes = [\"field-%s\" % _coerce_field_name(field_name, field_index)]",
        "row_classes = [\"field-%s\" %"
    ],
    [
        "f, attr, value = lookup_field(field_name, result, cl.model_admin)",
        "f, attr, value ="
    ],
    [
        "if isinstance(value, str) and value.strip() == \"\":",
        "if isinstance(value, str) and"
    ],
    [
        "if f is None or f.auto_created:",
        "if f is None or"
    ],
    [
        "if isinstance(attr, property) and hasattr(attr, \"fget\"):",
        "if isinstance(attr, property)"
    ],
    [
        "row_class = mark_safe(' class=\"%s\"' % \" \".join(row_classes))",
        "row_class = mark_safe(' class=\"%s\"' %"
    ],
    [
        "table_tag = \"th\" if first else \"td\"",
        "table_tag = \"th\" if first else"
    ],
    [
        "Wrapper class used to return items in a list_editable changelist, annotated",
        "Wrapper class used to return items in a"
    ],
    [
        "with the form object for error reporting purposes. Needed to maintain",
        "with the form object for error"
    ],
    [
        "backwards compatibility with existing admin templates.",
        "backwards compatibility with existing"
    ],
    [
        "for res, form in zip(cl.result_list, cl.formset.forms):",
        "for res, form in"
    ],
    [
        "for res, form in zip(cl.result_list, cl.formset.forms):",
        "for res, form in zip(cl.result_list,"
    ],
    [
        "Display the headers and data list together.",
        "Display the headers and data list"
    ],
    [
        "Display the date hierarchy for date drill-down functionality.",
        "Display the date hierarchy"
    ],
    [
        "if not (year_lookup or month_lookup or day_lookup):",
        "if not (year_lookup or month_lookup or"
    ],
    [
        "k: timezone.localtime(v) if timezone.is_aware(v) else v",
        "k: timezone.localtime(v) if"
    ],
    [
        "if year_lookup and month_lookup and day_lookup:",
        "if year_lookup and"
    ],
    [
        "\"back\": {\"link\": link({}), \"title\": _(\"All dates\")},",
        "\"back\": {\"link\": link({}), \"title\": _(\"All"
    ],
    [
        "Display a search form for searching the list.",
        "Display a search form for searching"
    ],
    [
        "Track the number of times the action field has been rendered on the page,",
        "Track the number of times the action field has been rendered"
    ],
    [
        "so we know which value to use.",
        "so we know which value to"
    ],
    [
        "\"\"\"Display the row of change list object tools.\"\"\"",
        "\"\"\"Display the row of change list"
    ],
    [
        "Populate a template variable with the admin log for the given criteria.",
        "Populate a template variable with the admin log"
    ],
    [
        "{% get_admin_log [limit] as [varname] for_user [context_var_with_user_obj] %}",
        "{% get_admin_log [limit] as [varname]"
    ],
    [
        "Note that ``context_var_containing_user_obj`` can be a hard-coded integer",
        "Note that ``context_var_containing_user_obj`` can be a"
    ],
    [
        "(user ID) or the name of a template context variable containing the user",
        "(user ID) or the name of a template context variable containing"
    ],
    [
        "\"First argument to 'get_admin_log' must be an integer\"",
        "\"First argument to 'get_admin_log' must"
    ],
    [
        "\"Second argument to 'get_admin_log' must be 'as'\"",
        "\"Second argument to 'get_admin_log' must"
    ],
    [
        "\"Fourth argument to 'get_admin_log' must be 'for_user'\"",
        "\"Fourth argument to 'get_admin_log'"
    ],
    [
        "Create a list of prepopulated_fields that should render JavaScript for",
        "Create a list of prepopulated_fields that"
    ],
    [
        "the prepopulated fields for both the admin form and inlines.",
        "the prepopulated fields for both the"
    ],
    [
        "Display the row of buttons for delete and save.",
        "Display the row of buttons for"
    ],
    [
        "not is_popup and can_save and has_view_permission and show_save_and_continue",
        "not is_popup and can_save and has_view_permission"
    ],
    [
        "\"\"\"Display the row of change form object tools.\"\"\"",
        "\"\"\"Display the row of change form"
    ],
    [
        "\"\"\"Return the number of cells used in a tabular inline.\"\"\"",
        "\"\"\"Return the number of cells used"
    ],
    [
        "Template tag that allows its template to be overridden per model, per app,",
        "Template tag that allows its template to be overridden per model, per"
    ],
    [
        "def __init__(self, parser, token, func, template_name, takes_context=True):",
        "def __init__(self, parser, token,"
    ],
    [
        "params, varargs, varkw, defaults, kwonly, kwonly_defaults, _ = getfullargspec(",
        "params, varargs, varkw, defaults, kwonly, kwonly_defaults, _ ="
    ],
    [
        "from urllib.parse import parse_qsl, unquote, urlsplit, urlunsplit",
        "from urllib.parse import parse_qsl, unquote, urlsplit,"
    ],
    [
        "return \"admin:%s_%s_%s\" % (value.app_label, value.model_name, arg)",
        "return \"admin:%s_%s_%s\" %"
    ],
    [
        "current_url = \"%s:%s\" % (match.app_name, match.url_name)",
        "current_url = \"%s:%s\" %"
    ],
    [
        "\"\"\"Handle AutocompleteWidget's AJAX requests for data.\"\"\"",
        "\"\"\"Handle AutocompleteWidget's AJAX requests for"
    ],
    [
        "Return a JsonResponse with search results as defined in",
        "Return a JsonResponse with search"
    ],
    [
        "Convert the provided model object to a dictionary that is added to the",
        "Convert the provided model object to a"
    ],
    [
        "return {\"id\": str(getattr(obj, to_field_name)), \"text\": str(obj)}",
        "return {\"id\": str(getattr(obj, to_field_name)), \"text\":"
    ],
    [
        "Validate request integrity, extract and return request parameters.",
        "Validate request integrity, extract and return request"
    ],
    [
        "Since the subsequent view permission check requires the target model",
        "Since the subsequent view permission check"
    ],
    [
        "admin, which is determined here, raise PermissionDenied if the",
        "admin, which is determined here, raise"
    ],
    [
        "requested app, model or field are malformed.",
        "requested app, model or field are"
    ],
    [
        "\"%s must have search_fields for the autocomplete_view.\"",
        "\"%s must have search_fields"
    ],
    [
        "\"\"\"Check if user has permission to access the related model.\"\"\"",
        "\"\"\"Check if user has permission"
    ],
    [
        "from django.db.models import F, Field, ManyToOneRel, OrderBy",
        "from django.db.models import F,"
    ],
    [
        "self.add_facets = model_admin.show_facets is ShowFacets.ALWAYS or (",
        "self.add_facets = model_admin.show_facets is ShowFacets.ALWAYS"
    ],
    [
        "model_admin.show_facets is ShowFacets.ALLOW and IS_FACETS_VAR in request.GET",
        "model_admin.show_facets is ShowFacets.ALLOW and IS_FACETS_VAR"
    ],
    [
        "if to_field and not model_admin.to_field_allowed(request, to_field):",
        "if to_field and"
    ],
    [
        "\"The field %s cannot be referenced.\" % to_field",
        "\"The field %s cannot be"
    ],
    [
        "title = gettext(\"Select %s to change\")",
        "title = gettext(\"Select %s"
    ],
    [
        "title = gettext(\"Select %s to view\")",
        "title = gettext(\"Select %s"
    ],
    [
        "return \"<%s: model=%s model_admin=%s>\" % (",
        "return \"<%s: model=%s model_admin=%s>\""
    ],
    [
        "raise DisallowedModelAdminLookup(f\"Filtering by {key} not allowed\")",
        "raise DisallowedModelAdminLookup(f\"Filtering by"
    ],
    [
        "spec = list_filter(request, lookup_params, self.model, self.model_admin)",
        "spec = list_filter(request, lookup_params, self.model,"
    ],
    [
        "year = lookup_params.pop(\"%s__year\" % self.date_hierarchy, None)",
        "year = lookup_params.pop(\"%s__year\" % self.date_hierarchy,"
    ],
    [
        "month = lookup_params.pop(\"%s__month\" % self.date_hierarchy, None)",
        "month = lookup_params.pop(\"%s__month\" %"
    ],
    [
        "day = lookup_params.pop(\"%s__day\" % self.date_hierarchy, None)",
        "day = lookup_params.pop(\"%s__day\" %"
    ],
    [
        "if (self.show_all and can_show_all) or not multi_page:",
        "if (self.show_all and can_show_all)"
    ],
    [
        "self.show_admin_actions = not self.show_full_result_count or bool(",
        "self.show_admin_actions = not self.show_full_result_count"
    ],
    [
        "Return the proper model field name corresponding to the given",
        "Return the proper model field name"
    ],
    [
        "field_name to use for ordering. field_name may either be the name of a",
        "field_name to use for ordering. field_name may either be"
    ],
    [
        "proper model field, possibly across relations, or the name of a method",
        "proper model field, possibly across relations, or the name"
    ],
    [
        "(on the admin or model) or a callable with the 'admin_order_field'",
        "(on the admin or model) or a callable with"
    ],
    [
        "attribute. Return None if no proper model field name can be matched.",
        "attribute. Return None if no proper model field name can"
    ],
    [
        "if isinstance(attr, property) and hasattr(attr, \"fget\"):",
        "if isinstance(attr, property)"
    ],
    [
        "Return the list of ordering fields for the change list.",
        "Return the list of ordering fields for the change"
    ],
    [
        "First check the get_ordering() method in model admin, then check",
        "First check the get_ordering() method in model admin, then"
    ],
    [
        "the object's default ordering. Then, any manually-specified ordering",
        "the object's default ordering. Then, any manually-specified"
    ],
    [
        "from the query string overrides anything. Finally, a deterministic",
        "from the query string overrides anything."
    ],
    [
        "order is guaranteed by calling _get_deterministic_ordering() with the",
        "order is guaranteed by"
    ],
    [
        "order_field.desc() if pfx == \"-\" else order_field.asc()",
        "order_field.desc() if pfx =="
    ],
    [
        "elif pfx == \"-\" and order_field.startswith(pfx):",
        "elif pfx == \"-\""
    ],
    [
        "Ensure a deterministic order across all database backends. Search for a",
        "Ensure a deterministic order across all database"
    ],
    [
        "single field or unique together set of fields providing a total",
        "single field or unique together set of fields"
    ],
    [
        "ordering. If these are missing, augment the ordering with a descendant",
        "ordering. If these are missing, augment the"
    ],
    [
        "elif isinstance(part, OrderBy) and isinstance(part.expression, F):",
        "elif isinstance(part, OrderBy) and"
    ],
    [
        "if field.remote_field and field_name == field.name:",
        "if field.remote_field and field_name"
    ],
    [
        "if any(field.null for field in fields):",
        "if any(field.null for field"
    ],
    [
        "if ordering_fields.issuperset(field.attname for field in fields):",
        "if ordering_fields.issuperset(field.attname for field in"
    ],
    [
        "Return a dictionary of ordering field column numbers and asc/desc.",
        "Return a dictionary of ordering"
    ],
    [
        "order_type = \"desc\" if field.descending else \"asc\"",
        "order_type = \"desc\" if field.descending else"
    ],
    [
        "ordering_fields[idx] = \"desc\" if pfx == \"-\" else \"asc\"",
        "ordering_fields[idx] = \"desc\" if pfx == \"-\" else"
    ],
    [
        "Decorator for views that checks that the user is logged in and is a staff",
        "Decorator for views that checks that the user is logged in and is a"
    ],
    [
        "member, redirecting to the login page if necessary.",
        "member, redirecting to the login page if"
    ],
    [
        "from django.core.files.storage import FileSystemStorage, Storage, default_storage",
        "from django.core.files.storage import FileSystemStorage,"
    ],
    [
        "method_name = \"find\" if not class_name else f\"{class_name}.find\"",
        "method_name = \"find\" if not class_name"
    ],
    [
        "\"Passing the `all` argument to find() is deprecated. Use `find_all` \"",
        "\"Passing the `all` argument to find()"
    ],
    [
        "f\"{method_name}() got multiple values for argument 'find_all'\"",
        "f\"{method_name}() got multiple values"
    ],
    [
        "raise TypeError(f\"{method_name}() got an unexpected keyword argument '{first}'\")",
        "raise TypeError(f\"{method_name}() got an unexpected keyword argument"
    ],
    [
        "A base file finder to be used for custom staticfiles finder classes.",
        "A base file finder to be used for custom staticfiles finder"
    ],
    [
        "\"subclasses may provide a check() method to verify the finder is \"",
        "\"subclasses may provide a check() method"
    ],
    [
        "Given a relative file path, find an absolute file path.",
        "Given a relative file path,"
    ],
    [
        "If the ``find_all`` parameter is False (default) return only the first",
        "If the ``find_all`` parameter is False (default) return only the"
    ],
    [
        "found file path; if True, return a list of all found files paths.",
        "found file path; if True, return a list of"
    ],
    [
        "\"subclasses of BaseFinder must provide a find() method\"",
        "\"subclasses of BaseFinder must provide a"
    ],
    [
        "Given an optional list of paths to ignore, return a two item iterable",
        "Given an optional list of paths to ignore, return a two item"
    ],
    [
        "consisting of the relative path and storage instance.",
        "consisting of the relative"
    ],
    [
        "\"subclasses of BaseFinder must provide a list() method\"",
        "\"subclasses of BaseFinder must provide"
    ],
    [
        "A static files finder that uses the ``STATICFILES_DIRS`` setting",
        "A static files finder that"
    ],
    [
        "if (prefix, root) not in self.locations:",
        "if (prefix, root) not in"
    ],
    [
        "\"The STATICFILES_DIRS setting is not a tuple or list.\",",
        "\"The STATICFILES_DIRS setting is not a"
    ],
    [
        "hint=\"Perhaps you forgot a trailing comma?\",",
        "hint=\"Perhaps you forgot a"
    ],
    [
        "\"The prefix %r in the STATICFILES_DIRS setting must \"",
        "\"The prefix %r in the STATICFILES_DIRS"
    ],
    [
        "\"not end with a slash.\" % prefix,",
        "\"not end with a"
    ],
    [
        "\"The STATICFILES_DIRS setting should not contain the \"",
        "\"The STATICFILES_DIRS setting should not contain the"
    ],
    [
        "f\"The directory '{root}' in the STATICFILES_DIRS setting \"",
        "f\"The directory '{root}' in the STATICFILES_DIRS"
    ],
    [
        "Look for files in the extra locations as defined in STATICFILES_DIRS.",
        "Look for files in the extra locations as"
    ],
    [
        "Find a requested static file in a location and return the found",
        "Find a requested static file in a location"
    ],
    [
        "absolute path (or ``None`` if no match).",
        "absolute path (or ``None`` if"
    ],
    [
        "prefix = \"%s%s\" % (prefix, os.sep)",
        "prefix = \"%s%s\""
    ],
    [
        "List all files in all locations.",
        "List all files in all"
    ],
    [
        "A static files finder that looks in the directory of each app as",
        "A static files finder that looks in the directory of each"
    ],
    [
        "app_configs = [ac for ac in app_configs if ac.name in app_names]",
        "app_configs = [ac for ac in app_configs if ac.name in"
    ],
    [
        "List all files in all app storages.",
        "List all files in"
    ],
    [
        "Look for files in the app directories.",
        "Look for files in"
    ],
    [
        "Find a requested static file in an app's static locations.",
        "Find a requested static file in"
    ],
    [
        "A base static files finder to be used to extended",
        "A base static files finder"
    ],
    [
        "\"The staticfiles storage finder %r \"",
        "\"The staticfiles storage finder"
    ],
    [
        "\"doesn't have a storage class \"",
        "\"doesn't have a"
    ],
    [
        "Look for files in the default file storage, if it's local.",
        "Look for files in the default file storage,"
    ],
    [
        "List all files of the storage.",
        "List all files of the"
    ],
    [
        "A static files finder that uses the default storage backend.",
        "A static files finder that"
    ],
    [
        "\"The storage backend of the \"",
        "\"The storage backend of the"
    ],
    [
        "\"staticfiles finder %r doesn't have \"",
        "\"staticfiles finder %r"
    ],
    [
        "Find a static file with the given path using all enabled finders.",
        "Find a static file with the given"
    ],
    [
        "If ``find_all`` is ``False`` (default), return the first matching",
        "If ``find_all`` is ``False`` (default),"
    ],
    [
        "absolute path (or ``None`` if no match). Otherwise return a list.",
        "absolute path (or ``None`` if no"
    ],
    [
        "return [] if find_all else None",
        "return [] if"
    ],
    [
        "Import the staticfiles finder class described by import_path, where",
        "Import the staticfiles finder class described by import_path,"
    ],
    [
        "import_path is the full Python path to the class.",
        "import_path is the full Python path"
    ],
    [
        "'Finder \"%s\" is not a subclass of \"%s\"' % (Finder, BaseFinder)",
        "'Finder \"%s\" is not a subclass of \"%s\"' %"
    ],
    [
        "f\"The STORAGES setting must define a '{STATICFILES_STORAGE_ALIAS}' storage.\",",
        "f\"The STORAGES setting must define a '{STATICFILES_STORAGE_ALIAS}'"
    ],
    [
        "\"\"\"Ensure staticfiles is defined in STORAGES setting.\"\"\"",
        "\"\"\"Ensure staticfiles is defined"
    ],
    [
        "Common methods used by WSGI and ASGI handlers.",
        "Common methods used by WSGI"
    ],
    [
        "Check if the path should be handled. Ignore the path if:",
        "Check if the path should be handled. Ignore the"
    ],
    [
        "* the host is provided as part of the base_url",
        "* the host is provided as part"
    ],
    [
        "* the request's path isn't under the media path (or equal)",
        "* the request's path isn't under the media"
    ],
    [
        "Return the relative path to the media file on disk for the given URL.",
        "Return the relative path to the media file on disk"
    ],
    [
        "WSGI middleware that intercepts calls to the static files directory, as",
        "WSGI middleware that intercepts calls to the static files"
    ],
    [
        "defined by the STATIC_URL setting, and serves those files.",
        "defined by the STATIC_URL setting,"
    ],
    [
        "ASGI application which wraps another and intercepts requests for static",
        "ASGI application which wraps another and"
    ],
    [
        "files, passing them off to Django's static file serving.",
        "files, passing them off to Django's static"
    ],
    [
        "async def __call__(self, scope, receive, send):",
        "async def __call__(self, scope, receive,"
    ],
    [
        "if scope[\"type\"] == \"http\" and self._should_handle(scope[\"path\"]):",
        "if scope[\"type\"] =="
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "Return True or False depending on whether the ``path`` should be",
        "Return True or False depending on whether the ``path``"
    ],
    [
        "ignored (if it matches any pattern in ``ignore_patterns``).",
        "ignored (if it matches any pattern in"
    ],
    [
        "return any(fnmatch.fnmatchcase(path, pattern) for pattern in patterns)",
        "return any(fnmatch.fnmatchcase(path, pattern) for pattern in"
    ],
    [
        "Recursively walk the storage directories yielding the paths",
        "Recursively walk the storage directories yielding the"
    ],
    [
        "of all files that should be copied.",
        "of all files that should be"
    ],
    [
        "Check if the staticfiles settings have sane values.",
        "Check if the staticfiles"
    ],
    [
        "\"You're using the staticfiles app \"",
        "\"You're using the staticfiles"
    ],
    [
        "\"without having set the required STATIC_URL setting.\"",
        "\"without having set the required"
    ],
    [
        "\"The MEDIA_URL and STATIC_URL settings must have different values\"",
        "\"The MEDIA_URL and STATIC_URL settings must have different"
    ],
    [
        "\"runserver can't serve media if MEDIA_URL is within STATIC_URL.\"",
        "\"runserver can't serve media if MEDIA_URL"
    ],
    [
        "if (settings.MEDIA_ROOT and settings.STATIC_ROOT) and (",
        "if (settings.MEDIA_ROOT and"
    ],
    [
        "\"The MEDIA_ROOT and STATIC_ROOT settings must have different values\"",
        "\"The MEDIA_ROOT and STATIC_ROOT settings"
    ],
    [
        "from urllib.parse import unquote, urldefrag, urlsplit, urlunsplit",
        "from urllib.parse import unquote,"
    ],
    [
        "Standard file system storage for static files.",
        "Standard file system storage"
    ],
    [
        "The defaults for ``location`` and ``base_url`` are",
        "The defaults for ``location`` and"
    ],
    [
        "def __init__(self, location=None, base_url=None, *args, **kwargs):",
        "def __init__(self, location=None, base_url=None, *args,"
    ],
    [
        "\"You're using the staticfiles app \"",
        "\"You're using the"
    ],
    [
        "\"without having set the STATIC_ROOT \"",
        "\"without having set"
    ],
    [
        "Return a hash of the file with the given name and optional content.",
        "Return a hash of the file with the"
    ],
    [
        "filename = (filename and urlsplit(unquote(filename)).path.strip()) or clean_name",
        "filename = (filename and urlsplit(unquote(filename)).path.strip())"
    ],
    [
        "\"The file '%s' could not be found with %r.\" % (filename, self)",
        "\"The file '%s' could not be"
    ],
    [
        "file_hash = (\".%s\" % file_hash) if file_hash else \"\"",
        "file_hash = (\".%s\" % file_hash)"
    ],
    [
        "hashed_name = os.path.join(path, \"%s%s%s\" % (root, file_hash, ext))",
        "hashed_name = os.path.join(path, \"%s%s%s\" % (root, file_hash,"
    ],
    [
        "def _url(self, hashed_name_func, name, force=False, hashed_files=None):",
        "def _url(self, hashed_name_func,"
    ],
    [
        "Return the non-hashed URL in DEBUG mode.",
        "Return the non-hashed URL in DEBUG"
    ],
    [
        "Return the non-hashed URL in DEBUG mode.",
        "Return the non-hashed URL in"
    ],
    [
        "Return the custom URL converter for the given file name.",
        "Return the custom URL converter for the given file"
    ],
    [
        "Convert the matched URL to a normalized and hashed URL.",
        "Convert the matched URL to a normalized"
    ],
    [
        "This requires figuring out which files the matched URL resolves",
        "This requires figuring out which"
    ],
    [
        "to and calling the url() method of the storage.",
        "to and calling the url() method of the"
    ],
    [
        "source_name = name if os.sep == \"/\" else name.replace(os.sep, \"/\")",
        "source_name = name if os.sep == \"/\""
    ],
    [
        "Post process the given dictionary of files (called from collectstatic).",
        "Post process the given dictionary of files"
    ],
    [
        "Processing is actually two separate operations:",
        "Processing is actually"
    ],
    [
        "and copying those files to the target storage.",
        "and copying those files to"
    ],
    [
        "If either of these are performed on a file, then that file is considered",
        "If either of these are performed on a file,"
    ],
    [
        "path for path in paths if matches_patterns(path, self._patterns)",
        "path for path in paths if matches_patterns(path,"
    ],
    [
        "for name, hashed_name, processed, _ in self._post_process(",
        "for name, hashed_name, processed, _ in"
    ],
    [
        "if name not in adjustable_paths or isinstance(processed, Exception):",
        "if name not in"
    ],
    [
        "paths = {path: paths[path] for path in adjustable_paths}",
        "paths = {path: paths[path]"
    ],
    [
        "for name, hashed_name, processed, subst in self._post_process(",
        "for name, hashed_name, processed, subst"
    ],
    [
        "yield problem_paths, None, RuntimeError(\"Max post-process passes exceeded.\")",
        "yield problem_paths, None, RuntimeError(\"Max"
    ],
    [
        "for name in sorted(paths, key=path_level, reverse=True):",
        "for name in"
    ],
    [
        "raise ValueError(\"The name '%s' could not be hashed with %r.\" % (name, self))",
        "raise ValueError(\"The name '%s' could not be hashed with %r.\" %"
    ],
    [
        "\"Couldn't load manifest '%s' (version %s)\"",
        "\"Couldn't load manifest '%s'"
    ],
    [
        "\"Missing staticfiles manifest entry for '%s'\" % clean_name",
        "\"Missing staticfiles manifest entry for '%s'\" %"
    ],
    [
        "A static file system storage backend which also saves",
        "A static file system storage backend which also"
    ],
    [
        "hashed copies of the files it saves.",
        "hashed copies of the"
    ],
    [
        "Extend django.test.LiveServerTestCase to transparently overlay at test",
        "Extend django.test.LiveServerTestCase to transparently overlay"
    ],
    [
        "execution-time the assets provided by the staticfiles app finders. This",
        "execution-time the assets provided by the staticfiles app"
    ],
    [
        "means you don't need to run collectstatic before or as a part of your tests",
        "means you don't need to run collectstatic before or as"
    ],
    [
        "Helper function to return a URL pattern for serving static files.",
        "Helper function to return a URL pattern for serving"
    ],
    [
        "Views and functions for serving static files. These are only to be used during",
        "Views and functions for serving static files."
    ],
    [
        "development, and SHOULD NOT be used in a production setting.",
        "development, and SHOULD NOT be"
    ],
    [
        "Serve static files below a given point in the directory structure or",
        "Serve static files below a given point in the directory"
    ],
    [
        "from locations inferred from the staticfiles finders.",
        "from locations inferred from"
    ],
    [
        "To use, put a URL pattern such as::",
        "To use, put a URL pattern such"
    ],
    [
        "It uses the django.views.static.serve() view to serve the found files.",
        "It uses the django.views.static.serve() view"
    ],
    [
        "if not settings.DEBUG and not insecure:",
        "if not settings.DEBUG and"
    ],
    [
        "if path.endswith(\"/\") or path == \"\":",
        "if path.endswith(\"/\") or"
    ],
    [
        "help = \"Finds the absolute paths for the given static file(s).\"",
        "help = \"Finds the absolute paths for the given static"
    ],
    [
        "help=\"Only return the first match for each static file.\",",
        "help=\"Only return the first match for each"
    ],
    [
        "\"\\nLooking in the following locations:\\n  %s\"",
        "\"\\nLooking in the"
    ],
    [
        "% \"\\n  \".join([str(loc) for loc in finders.searched_locations])",
        "% \"\\n \".join([str(loc) for loc in"
    ],
    [
        "result = (os.path.realpath(path) for path in result)",
        "result = (os.path.realpath(path) for"
    ],
    [
        "return \"Found '%s' here:\\n  %s%s\" % (",
        "return \"Found '%s' here:\\n"
    ],
    [
        "message = [\"No matching file found for '%s'.\" % path]",
        "message = [\"No matching file"
    ],
    [
        "from django.core.management.commands.runserver import Command as RunserverCommand",
        "from django.core.management.commands.runserver import"
    ],
    [
        "\"Starts a lightweight web server for development and also serves static files.\"",
        "\"Starts a lightweight web server for development and"
    ],
    [
        "help=\"Tells Django to NOT automatically serve static files at STATIC_URL.\",",
        "help=\"Tells Django to NOT automatically serve static files at"
    ],
    [
        "help=\"Allows serving static files even if DEBUG is False.\",",
        "help=\"Allows serving static files even"
    ],
    [
        "Return the static files serving handler wrapping the default handler,",
        "Return the static files serving handler wrapping"
    ],
    [
        "if static files should be served. Otherwise return the default handler.",
        "if static files should be served. Otherwise return"
    ],
    [
        "if use_static_handler and (settings.DEBUG or insecure_serving):",
        "if use_static_handler and (settings.DEBUG"
    ],
    [
        "Copies or symlinks static files from different locations to the",
        "Copies or symlinks static files from different locations to"
    ],
    [
        "help = \"Collect static files in a single location.\"",
        "help = \"Collect static files in"
    ],
    [
        "help=\"Do NOT prompt the user for input of any kind.\",",
        "help=\"Do NOT prompt the user for"
    ],
    [
        "help=\"Do NOT post process collected files.\",",
        "help=\"Do NOT post"
    ],
    [
        "help=\"Ignore files or directories matching this glob-style \"",
        "help=\"Ignore files or directories matching"
    ],
    [
        "\"pattern. Use multiple times to ignore more.\",",
        "\"pattern. Use multiple times"
    ],
    [
        "help=\"Do everything except modify the filesystem.\",",
        "help=\"Do everything except modify"
    ],
    [
        "help=\"Clear the existing files using the storage \"",
        "help=\"Clear the existing files using the"
    ],
    [
        "\"before trying to copy or link the original file.\",",
        "\"before trying to copy or link the"
    ],
    [
        "help=\"Create a symbolic link to each file instead of copying.\",",
        "help=\"Create a symbolic link to each file instead of"
    ],
    [
        "\"Don't ignore the common private glob-style patterns (defaults to \"",
        "\"Don't ignore the common private glob-style"
    ],
    [
        "Set instance variables based on an options dict",
        "Set instance variables based"
    ],
    [
        "self.ignore_patterns = list({os.path.normpath(p) for p in ignore_patterns})",
        "self.ignore_patterns = list({os.path.normpath(p) for p in"
    ],
    [
        "Perform the bulk of the work of collectstatic.",
        "Perform the bulk of the work"
    ],
    [
        "Split off from handle() to facilitate testing.",
        "Split off from handle()"
    ],
    [
        "raise CommandError(\"Can't symlink to a remote destination.\")",
        "raise CommandError(\"Can't symlink to a"
    ],
    [
        "\"Found another file with the destination path '%s'. It \"",
        "\"Found another file with the"
    ],
    [
        "\"will be ignored since only the first encountered file \"",
        "\"will be ignored since only the first"
    ],
    [
        "\"is collected. If this is not what you want, make sure \"",
        "\"is collected. If this is not"
    ],
    [
        "\"every static file has a unique path.\" % prefixed_path,",
        "\"every static file has a unique path.\" %"
    ],
    [
        "for original_path, processed_path, processed in processor:",
        "for original_path, processed_path, processed"
    ],
    [
        "\"Post-processed '%s' as '%s'\" % (original_path, processed_path),",
        "\"Post-processed '%s' as '%s'\""
    ],
    [
        "\"You have activated the --dry-run option so no files will be \"",
        "\"You have activated the --dry-run option so no files"
    ],
    [
        "\"You have requested to collect static files at the destination\\n\"",
        "\"You have requested to collect static files at the"
    ],
    [
        "\"location as specified in your settings\"",
        "\"location as specified in your"
    ],
    [
        "message.append(\"This will DELETE ALL FILES in this location!\\n\")",
        "message.append(\"This will DELETE ALL FILES"
    ],
    [
        "\"Are you sure you want to do this?\\n\\n\"",
        "\"Are you sure you want to do"
    ],
    [
        "\"Type 'yes' to continue, or 'no' to cancel: \"",
        "\"Type 'yes' to continue, or 'no'"
    ],
    [
        "\"action\": \"symlinked\" if self.symlink else \"copied\",",
        "\"action\": \"symlinked\" if self.symlink"
    ],
    [
        "\" to '%s'\" % destination_path if destination_path else \"\"",
        "\" to '%s'\" % destination_path if"
    ],
    [
        "and \", %s post-processed\" % post_processed_count",
        "and \", %s"
    ],
    [
        "Delete the given relative path using the destination storage backend.",
        "Delete the given relative path using"
    ],
    [
        "Check if the target file should be deleted if it already exists.",
        "Check if the target file should be deleted if it already"
    ],
    [
        "self.log(\"Skipping '%s' (not modified)\" % path)",
        "self.log(\"Skipping '%s' (not modified)\" %"
    ],
    [
        "self.log(\"Pretending to delete '%s'\" % path)",
        "self.log(\"Pretending to delete"
    ],
    [
        "return self.log(\"Skipping '%s' (already linked earlier)\" % path)",
        "return self.log(\"Skipping '%s' (already"
    ],
    [
        "\"Symlinking is not supported in this \"",
        "\"Symlinking is not supported in this"
    ],
    [
        "Attempt to copy ``path`` with storage",
        "Attempt to copy ``path`` with"
    ],
    [
        "return self.log(\"Skipping '%s' (already copied earlier)\" % path)",
        "return self.log(\"Skipping '%s' (already copied earlier)\""
    ],
    [
        "from django.urls import NoReverseMatch, get_script_prefix, reverse",
        "from django.urls import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "\"Example: “flatpages/contact_page.html”. If this isn’t provided, \"",
        "\"Example: “flatpages/contact_page.html”. If this isn’t"
    ],
    [
        "\"If this is checked, only logged-in users will be able to view the page.\"",
        "\"If this is checked, only logged-in users will be able to view the"
    ],
    [
        "return \"%s -- %s\" % (self.url, self.title)",
        "return \"%s -- %s\" % (self.url,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "\"Example: “/about/contact/”. Make sure to have leading and trailing \"",
        "\"Example: “/about/contact/”. Make sure to have leading and trailing"
    ],
    [
        "\"This value must contain only letters, numbers, dots, \"",
        "\"This value must contain only letters,"
    ],
    [
        "\"Example: “/about/contact”. Make sure to have a leading slash.\"",
        "\"Example: “/about/contact”. Make sure to have"
    ],
    [
        "gettext(\"URL is missing a leading slash.\"),",
        "gettext(\"URL is missing a"
    ],
    [
        "gettext(\"URL is missing a trailing slash.\"),",
        "gettext(\"URL is missing a"
    ],
    [
        "_(\"Flatpage with url %(url)s already exists for site %(site)s\"),",
        "_(\"Flatpage with url %(url)s already"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "(None, {\"fields\": (\"url\", \"title\", \"content\", \"sites\")}),",
        "(None, {\"fields\": (\"url\", \"title\", \"content\","
    ],
    [
        "from django.apps import apps as django_apps",
        "from django.apps import"
    ],
    [
        "\"FlatPageSitemap requires django.contrib.sites, which isn't installed.\"",
        "\"FlatPageSitemap requires django.contrib.sites, which"
    ],
    [
        "Public interface to the flat page view.",
        "Public interface to the"
    ],
    [
        "Templates: Uses the template defined by the ``template_name`` field,",
        "Templates: Uses the template defined"
    ],
    [
        "or :template:`flatpages/default.html` if template_name is not defined.",
        "or :template:`flatpages/default.html` if template_name"
    ],
    [
        "Internal interface to the flat page view.",
        "Internal interface to the"
    ],
    [
        "Retrieve all flatpage objects available for the current site and",
        "Retrieve all flatpage objects available for"
    ],
    [
        "visible to the specific user (or visible to all users if no user is",
        "visible to the specific user (or visible to all"
    ],
    [
        "specified). Populate the template context with them in a variable",
        "specified). Populate the template context with"
    ],
    [
        "whose name is defined by the ``as`` clause.",
        "whose name is defined by the"
    ],
    [
        "An optional ``for`` clause controls the user whose permissions are used in",
        "An optional ``for`` clause controls the"
    ],
    [
        "An optional argument, ``starts_with``, limits the returned flatpages to",
        "An optional argument, ``starts_with``, limits"
    ],
    [
        "those beginning with a particular base URL. This argument can be a variable",
        "those beginning with a particular base URL. This"
    ],
    [
        "or a string, as it resolves from the template context.",
        "or a string, as it resolves from the"
    ],
    [
        "{% get_flatpages ['url_starts_with'] [for user] as context_name %}",
        "{% get_flatpages ['url_starts_with'] [for"
    ],
    [
        "{% get_flatpages for someuser as flatpages %}",
        "{% get_flatpages for someuser"
    ],
    [
        "{% get_flatpages '/about/' as about_pages %}",
        "{% get_flatpages '/about/' as"
    ],
    [
        "{% get_flatpages prefix as about_pages %}",
        "{% get_flatpages prefix as about_pages"
    ],
    [
        "{% get_flatpages '/about/' for someuser as about_pages %}",
        "{% get_flatpages '/about/' for"
    ],
    [
        "\"%(tag_name)s expects a syntax of %(tag_name)s \"",
        "\"%(tag_name)s expects a syntax"
    ],
    [
        "\"Example: “flatpages/contact_page.html”. If this isn’t \"",
        "\"Example: “flatpages/contact_page.html”. If"
    ],
    [
        "\"provided, the system will use “flatpages/default.html”.\"",
        "\"provided, the system will use"
    ],
    [
        "\"If this is checked, only logged-in users will be able to \"",
        "\"If this is checked, only logged-in users will be able"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "Validate that the given value contains no whitespaces to prevent common",
        "Validate that the given value contains no whitespaces"
    ],
    [
        "checks = ((s in value) for s in string.whitespace)",
        "checks = ((s in value) for"
    ],
    [
        "_(\"The domain name cannot contain any spaces or tabs.\"),",
        "_(\"The domain name cannot contain any spaces"
    ],
    [
        "Return the current Site based on the SITE_ID in the project's settings.",
        "Return the current Site based on the SITE_ID"
    ],
    [
        "If SITE_ID isn't defined, return the site with domain matching",
        "If SITE_ID isn't defined, return the site with"
    ],
    [
        "request.get_host(). The ``Site`` object is cached the first time it's",
        "request.get_host(). The ``Site`` object is cached the first time"
    ],
    [
        "'You\\'re using the Django \"sites framework\" without having '",
        "'You\\'re using the Django \"sites"
    ],
    [
        "\"set the SITE_ID setting. Create a site in your database and \"",
        "\"set the SITE_ID setting. Create a site"
    ],
    [
        "\"set the SITE_ID setting or pass a request to \"",
        "\"set the SITE_ID setting or"
    ],
    [
        "Clear the cache (if primed) each time a site is saved or deleted.",
        "Clear the cache (if primed) each time a site is saved or"
    ],
    [
        "Check if contrib.sites is installed and return either the current",
        "Check if contrib.sites is installed"
    ],
    [
        "``Site`` object or a ``RequestSite`` object based on the request.",
        "``Site`` object or a ``RequestSite``"
    ],
    [
        "if hasattr(settings, \"SITE_ID\") and not isinstance(",
        "if hasattr(settings, \"SITE_ID\") and"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "from django.apps import apps as global_apps",
        "from django.apps import apps as"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connections, router",
        "from django.db import DEFAULT_DB_ALIAS, connections,"
    ],
    [
        "A class that shares the primary interface of Site (i.e., it has ``domain``",
        "A class that shares the primary interface of Site (i.e., it"
    ],
    [
        "and ``name`` attributes) but gets its data from an HttpRequest object",
        "and ``name`` attributes) but gets its data from an"
    ],
    [
        "The save() and delete() methods raise NotImplementedError.",
        "The save() and delete() methods raise"
    ],
    [
        "Middleware that sets `site` attribute to request object.",
        "Middleware that sets `site` attribute to"
    ],
    [
        "\"Use this to limit objects to those associated with the current site.\"",
        "\"Use this to limit objects to"
    ],
    [
        "\"CurrentSiteManager could not find a field named '%s'.\"",
        "\"CurrentSiteManager could not find"
    ],
    [
        "if not field.many_to_many and not isinstance(field, (models.ForeignKey)):",
        "if not field.many_to_many and not"
    ],
    [
        "\"CurrentSiteManager cannot use '%s.%s' as it is not a foreign key \"",
        "\"CurrentSiteManager cannot use '%s.%s' as it is not a foreign key"
    ],
    [
        "\"\"\"Return self.__field_name or 'site' or 'sites'.\"\"\"",
        "\"\"\"Return self.__field_name or"
    ],
    [
        "from django.db.models import DateTimeField, Func, UUIDField",
        "from django.db.models import DateTimeField,"
    ],
    [
        "\"SELECT oid, typarray FROM pg_type WHERE typname = %s\", (type_name,)",
        "\"SELECT oid, typarray FROM pg_type WHERE typname ="
    ],
    [
        "\"\"\"Return hstore and hstore array OIDs.\"\"\"",
        "\"\"\"Return hstore and hstore"
    ],
    [
        "\"\"\"Return citext and citext array OIDs.\"\"\"",
        "\"\"\"Return citext and"
    ],
    [
        "if connection.vendor != \"postgresql\" or connection.alias == NO_DB_ALIAS:",
        "if connection.vendor != \"postgresql\" or"
    ],
    [
        "for oid, array_oid in zip(oids, array_oids):",
        "for oid, array_oid in"
    ],
    [
        "if connection.vendor != \"postgresql\" or connection.alias == NO_DB_ALIAS:",
        "if connection.vendor != \"postgresql\" or"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"List contains %(show_value)d item, it should contain no more than \"",
        "\"List contains %(show_value)d item, it should contain no more than"
    ],
    [
        "\"List contains %(show_value)d items, it should contain no more than \"",
        "\"List contains %(show_value)d items, it should contain no more"
    ],
    [
        "\"List contains %(show_value)d item, it should contain no fewer than \"",
        "\"List contains %(show_value)d item, it should contain no fewer than"
    ],
    [
        "\"List contains %(show_value)d items, it should contain no fewer than \"",
        "\"List contains %(show_value)d items, it should contain no fewer than"
    ],
    [
        "\"\"\"A validator designed for HStore to require/restrict keys.\"\"\"",
        "\"\"\"A validator designed for HStore to"
    ],
    [
        "\"missing_keys\": _(\"Some keys were missing: %(keys)s\"),",
        "\"missing_keys\": _(\"Some keys were missing:"
    ],
    [
        "\"extra_keys\": _(\"Some unknown keys were provided: %(keys)s\"),",
        "\"extra_keys\": _(\"Some unknown keys were provided:"
    ],
    [
        "return a.upper is None or a.upper > b",
        "return a.upper is None"
    ],
    [
        "\"Ensure that the upper bound of the range is not greater than %(limit_value)s.\"",
        "\"Ensure that the upper bound of the range is not"
    ],
    [
        "return a.lower is None or a.lower < b",
        "return a.lower is None or a.lower <"
    ],
    [
        "\"Ensure that the lower bound of the range is not less than %(limit_value)s.\"",
        "\"Ensure that the lower bound of the range is"
    ],
    [
        "return \"%s.%r\" % (module, self.value), {\"import %s\" % module}",
        "return \"%s.%r\" % (module, self.value), {\"import %s\""
    ],
    [
        "from .search import SearchVector, SearchVectorExact, SearchVectorField",
        "from .search import SearchVector, SearchVectorExact,"
    ],
    [
        "return [str(item) for item in self.rhs]",
        "return [str(item) for item in"
    ],
    [
        "from django.db.models import CharField, OrderBy, TextField",
        "from django.db.models import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "Undo the effects of PostgresConfig.ready() when django.contrib.postgres",
        "Undo the effects of"
    ],
    [
        "from django.db.migrations import AddConstraint, AddIndex, RemoveIndex",
        "from django.db.migrations import AddConstraint,"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "if schema_editor.connection.vendor != \"postgresql\" or not router.allow_migrate(",
        "if schema_editor.connection.vendor != \"postgresql\" or"
    ],
    [
        "\"CREATE EXTENSION IF NOT EXISTS %s\"",
        "\"CREATE EXTENSION IF NOT"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "\"DROP EXTENSION IF EXISTS %s\" % schema_editor.quote_name(self.name)",
        "\"DROP EXTENSION IF EXISTS %s\" %"
    ],
    [
        "return \"Creates extension %s\" % self.name",
        "return \"Creates extension %s\""
    ],
    [
        "\"The %s operation cannot be executed inside a transaction \"",
        "\"The %s operation cannot be executed inside a transaction"
    ],
    [
        "\"(set atomic = False on the migration).\" % self.__class__.__name__",
        "\"(set atomic = False on the"
    ],
    [
        "\"\"\"Create an index using PostgreSQL's CREATE INDEX CONCURRENTLY syntax.\"\"\"",
        "\"\"\"Create an index using PostgreSQL's CREATE"
    ],
    [
        "return \"Concurrently create index %s on field(s) %s of model %s\" % (",
        "return \"Concurrently create index %s on field(s) %s of model %s\""
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label,"
    ],
    [
        "\"\"\"Remove an index using PostgreSQL's DROP INDEX CONCURRENTLY syntax.\"\"\"",
        "\"\"\"Remove an index using PostgreSQL's DROP INDEX CONCURRENTLY"
    ],
    [
        "return \"Concurrently remove index %s from %s\" % (self.name, self.model_name)",
        "return \"Concurrently remove index %s from"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label,"
    ],
    [
        "def __init__(self, name, locale, *, provider=\"libc\", deterministic=True):",
        "def __init__(self, name, locale,"
    ],
    [
        "kwargs = {\"name\": self.name, \"locale\": self.locale}",
        "kwargs = {\"name\": self.name, \"locale\":"
    ],
    [
        "if self.provider and self.provider != \"libc\":",
        "if self.provider and self.provider"
    ],
    [
        "f\"{option}={value}\" for option, value in args.items()",
        "f\"{option}={value}\" for option, value"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "if schema_editor.connection.vendor != \"postgresql\" or not router.allow_migrate(",
        "if schema_editor.connection.vendor != \"postgresql\" or"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label,"
    ],
    [
        "if isinstance(operation, RemoveCollation) and self.name == operation.name:",
        "if isinstance(operation, RemoveCollation) and self.name =="
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "if schema_editor.connection.vendor != \"postgresql\" or not router.allow_migrate(",
        "if schema_editor.connection.vendor != \"postgresql\""
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "Add a table constraint without enforcing validation, using PostgreSQL's",
        "Add a table constraint without enforcing"
    ],
    [
        "\"AddConstraintNotValid.constraint must be a check constraint.\"",
        "\"AddConstraintNotValid.constraint must be a check"
    ],
    [
        "return \"Create not valid constraint %s on model %s\" % (",
        "return \"Create not valid constraint %s"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "schema_editor.execute(str(constraint_sql) + \" NOT VALID\", params=None)",
        "schema_editor.execute(str(constraint_sql) + \" NOT VALID\","
    ],
    [
        "\"\"\"Validate a table NOT VALID constraint.\"\"\"",
        "\"\"\"Validate a table"
    ],
    [
        "return \"Validate constraint %s on model %s\" % (self.name, self.model_name)",
        "return \"Validate constraint %s on model"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "\"ALTER TABLE %s VALIDATE CONSTRAINT %s\"",
        "\"ALTER TABLE %s VALIDATE"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "return Index.max_name_length - len(Index.suffix) + len(self.suffix)",
        "return Index.max_name_length - len(Index.suffix) +"
    ],
    [
        "def create_sql(self, model, schema_editor, using=\"\", **kwargs):",
        "def create_sql(self, model, schema_editor,"
    ],
    [
        "model, schema_editor, using=\" USING %s\" % (using or self.suffix), **kwargs",
        "model, schema_editor, using=\" USING %s\""
    ],
    [
        "statement.parts[\"extra\"] = \" WITH (%s)%s\" % (",
        "statement.parts[\"extra\"] = \" WITH"
    ],
    [
        "def __init__(self, *expressions, length=None, columns=(), **kwargs):",
        "def __init__(self, *expressions,"
    ],
    [
        "raise ValueError(\"BloomIndex.columns must be a list or tuple.\")",
        "raise ValueError(\"BloomIndex.columns must be"
    ],
    [
        "raise ValueError(\"BloomIndex.columns cannot have more values than fields.\")",
        "raise ValueError(\"BloomIndex.columns cannot have more values than"
    ],
    [
        "raise ValueError(\"pages_per_range must be None or a positive integer\")",
        "raise ValueError(\"pages_per_range must be None or"
    ],
    [
        "\"autosummarize = %s\" % (\"on\" if self.autosummarize else \"off\")",
        "\"autosummarize = %s\" % (\"on\" if self.autosummarize else"
    ],
    [
        "def __init__(self, *expressions, fillfactor=None, deduplicate_items=None, **kwargs):",
        "def __init__(self, *expressions, fillfactor=None,"
    ],
    [
        "\"deduplicate_items = %s\" % (\"on\" if self.deduplicate_items else \"off\")",
        "\"deduplicate_items = %s\" % (\"on\""
    ],
    [
        "with_params.append(\"fastupdate = %s\" % (\"on\" if self.fastupdate else \"off\"))",
        "with_params.append(\"fastupdate = %s\" % (\"on\" if self.fastupdate"
    ],
    [
        "def __init__(self, *expressions, buffering=None, fillfactor=None, **kwargs):",
        "def __init__(self, *expressions,"
    ],
    [
        "with_params.append(\"buffering = %s\" % (\"on\" if self.buffering else \"off\"))",
        "with_params.append(\"buffering = %s\" % (\"on\""
    ],
    [
        "Prefix a validation error message while maintaining the existing",
        "Prefix a validation error message while maintaining the"
    ],
    [
        "[prefix_validation_error(e, prefix, code, params) for e in error.error_list]",
        "[prefix_validation_error(e, prefix, code, params) for"
    ],
    [
        "return \"%s @@ %s\" % (lhs, rhs), params",
        "return \"%s @@ %s\" %"
    ],
    [
        "if config is None or isinstance(config, cls):",
        "if config is None"
    ],
    [
        "\"SearchVector can only be combined with other SearchVector \"",
        "\"SearchVector can only be combined with"
    ],
    [
        "arg_joiner = \" || ' ' || \"",
        "arg_joiner = \" || ' ' ||"
    ],
    [
        "if weight is not None and not hasattr(weight, \"resolve_expression\"):",
        "if weight is not None and not"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None, summarize=False,"
    ],
    [
        "def as_sql(self, compiler, connection, function=None, template=None):",
        "def as_sql(self, compiler,"
    ],
    [
        "return sql, config_params + params + extra_params",
        "return sql, config_params +"
    ],
    [
        "def __init__(self, lhs, connector, rhs, config, output_field=None):",
        "def __init__(self, lhs, connector,"
    ],
    [
        "\"SearchQuery can only be combined with other SearchQuery \"",
        "\"SearchQuery can only be combined"
    ],
    [
        "raise ValueError(\"Unknown search_type argument '%s'.\" % search_type)",
        "raise ValueError(\"Unknown search_type argument"
    ],
    [
        "def as_sql(self, compiler, connection, function=None, template=None):",
        "def as_sql(self, compiler, connection,"
    ],
    [
        "sql, params = super().as_sql(compiler, connection, function, template)",
        "sql, params = super().as_sql(compiler,"
    ],
    [
        "return (\"~%s\" % result) if self.invert else result",
        "return (\"~%s\" % result) if self.invert"
    ],
    [
        "def __init__(self, lhs, connector, rhs, config, output_field=None):",
        "def __init__(self, lhs, connector,"
    ],
    [
        "option: value for option, value in options.items() if value is not None",
        "option: value for option, value in"
    ],
    [
        "def as_sql(self, compiler, connection, function=None, template=None):",
        "def as_sql(self, compiler,"
    ],
    [
        "from django.db.backends.ddl_references import Expressions, Statement, Table",
        "from django.db.backends.ddl_references import"
    ],
    [
        "from django.db.models import BaseConstraint, Deferrable, F, Q",
        "from django.db.models import BaseConstraint, Deferrable, F,"
    ],
    [
        "\"CONSTRAINT %(name)s EXCLUDE USING %(index_type)s \"",
        "\"CONSTRAINT %(name)s EXCLUDE"
    ],
    [
        "if index_type and index_type.lower() not in {\"gist\", \"spgist\"}:",
        "if index_type and index_type.lower() not in {\"gist\","
    ],
    [
        "\"Exclusion constraints only support GiST or SP-GiST indexes.\"",
        "\"Exclusion constraints only support"
    ],
    [
        "\"At least one expression is required to define an exclusion \"",
        "\"At least one expression is required to define"
    ],
    [
        "raise ValueError(\"ExclusionConstraint.condition must be a Q instance.\")",
        "raise ValueError(\"ExclusionConstraint.condition must be a"
    ],
    [
        "\"ExclusionConstraint.deferrable must be a Deferrable instance.\"",
        "\"ExclusionConstraint.deferrable must be a Deferrable"
    ],
    [
        "if not isinstance(include, (NoneType, list, tuple)):",
        "if not isinstance(include, (NoneType,"
    ],
    [
        "raise ValueError(\"ExclusionConstraint.include must be a list or tuple.\")",
        "raise ValueError(\"ExclusionConstraint.include must be a list"
    ],
    [
        "self.include = tuple(include) if include else ()",
        "self.include = tuple(include) if"
    ],
    [
        "for idx, (expression, operator) in enumerate(self.expressions):",
        "for idx, (expression, operator) in"
    ],
    [
        "return sql % tuple(schema_editor.quote_value(p) for p in params)",
        "return sql % tuple(schema_editor.quote_value(p) for p"
    ],
    [
        "where=\" WHERE (%s)\" % condition if condition else \"\",",
        "where=\" WHERE (%s)\" % condition if"
    ],
    [
        "return \"<%s: index_type=%s expressions=%s name=%s%s%s%s%s%s>\" % (",
        "return \"<%s: index_type=%s expressions=%s name=%s%s%s%s%s%s>\""
    ],
    [
        "\"\" if self.condition is None else \" condition=%s\" % self.condition,",
        "\"\" if self.condition is None else \" condition=%s\" %"
    ],
    [
        "\"\" if self.deferrable is None else \" deferrable=%r\" % self.deferrable,",
        "\"\" if self.deferrable is None else \""
    ],
    [
        "\"\" if not self.include else \" include=%s\" % repr(self.include),",
        "\"\" if not self.include else \" include=%s\" %"
    ],
    [
        "def validate(self, model, instance, exclude=None, using=DEFAULT_DB_ALIAS):",
        "def validate(self, model, instance, exclude=None,"
    ],
    [
        "replacements = {F(field): value for field, value in replacement_map.items()}",
        "replacements = {F(field): value for field,"
    ],
    [
        "if exclude and self._expression_refs_exclude(model, expression, exclude):",
        "if exclude and self._expression_refs_exclude(model, expression,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"\"\"A widget that splits input into two <input type=\"hidden\"> inputs.\"\"\"",
        "\"\"\"A widget that splits input into two <input type=\"hidden\">"
    ],
    [
        "\"The start of the range must not exceed the end of the range.\"",
        "\"The start of the range must not exceed"
    ],
    [
        "if lower is not None and upper is not None and lower > upper:",
        "if lower is not None and upper is not None and lower >"
    ],
    [
        "default_error_messages = {\"invalid\": _(\"Enter two whole numbers.\")}",
        "default_error_messages = {\"invalid\": _(\"Enter two whole"
    ],
    [
        "default_error_messages = {\"invalid\": _(\"Enter two numbers.\")}",
        "default_error_messages = {\"invalid\": _(\"Enter"
    ],
    [
        "default_error_messages = {\"invalid\": _(\"Enter two valid date/times.\")}",
        "default_error_messages = {\"invalid\": _(\"Enter two valid"
    ],
    [
        "default_error_messages = {\"invalid\": _(\"Enter two valid dates.\")}",
        "default_error_messages = {\"invalid\": _(\"Enter"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"item_invalid\": _(\"Item %(nth)s in the array did not validate:\"),",
        "\"item_invalid\": _(\"Item %(nth)s in the array did"
    ],
    [
        "self, base_field, *, delimiter=\",\", max_length=None, min_length=None, **kwargs",
        "self, base_field, *, delimiter=\",\", max_length=None, min_length=None,"
    ],
    [
        "return [self.base_field.clean(val) for val in value]",
        "return [self.base_field.clean(val) for"
    ],
    [
        "if initial in self.empty_values and value in self.empty_values:",
        "if initial in self.empty_values and"
    ],
    [
        "self.widget = widget() if isinstance(widget, type) else widget",
        "self.widget = widget() if"
    ],
    [
        "self.widget.value_from_datadict(data, files, \"%s_%s\" % (name, index))",
        "self.widget.value_from_datadict(data, files, \"%s_%s\" % (name,"
    ],
    [
        "self.widget.value_omitted_from_data(data, files, \"%s_%s\" % (name, index))",
        "self.widget.value_omitted_from_data(data, files, \"%s_%s\""
    ],
    [
        "attrs = {} if attrs is None else attrs",
        "attrs = {} if attrs"
    ],
    [
        "final_attrs = {**final_attrs, \"id\": \"%s_%s\" % (id_, i)}",
        "final_attrs = {**final_attrs, \"id\": \"%s_%s\" %"
    ],
    [
        "self.widget.get_context(name + \"_%s\" % i, widget_value, final_attrs)[",
        "self.widget.get_context(name + \"_%s\" %"
    ],
    [
        "\"item_invalid\": _(\"Item %(nth)s in the array did not validate:\"),",
        "\"item_invalid\": _(\"Item %(nth)s in the array did not"
    ],
    [
        "def __init__(self, base_field, size, *, remove_trailing_nulls=False, **kwargs):",
        "def __init__(self, base_field, size, *,"
    ],
    [
        "return [self.base_field.to_python(item) for item in value]",
        "return [self.base_field.to_python(item) for"
    ],
    [
        "if initial in self.empty_values and data in self.empty_values:",
        "if initial in self.empty_values and data"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "A field for HStore data which accepts dictionary JSON input.",
        "A field for HStore data"
    ],
    [
        "\"invalid_json\": _(\"Could not load JSON data.\"),",
        "\"invalid_json\": _(\"Could not load JSON"
    ],
    [
        "\"invalid_format\": _(\"Input must be a JSON dictionary.\"),",
        "\"invalid_format\": _(\"Input must be a"
    ],
    [
        "Return True if data differs from initial.",
        "Return True if data differs from"
    ],
    [
        "def __init__(self, *expressions, ordering=(), order_by=(), **extra):",
        "def __init__(self, *expressions,"
    ],
    [
        "\"The ordering argument is deprecated. Use order_by instead.\",",
        "\"The ordering argument is deprecated. Use"
    ],
    [
        "raise TypeError(\"Cannot specify both order_by and ordering.\")",
        "raise TypeError(\"Cannot specify both order_by"
    ],
    [
        "sql, _ = super().as_sql(compiler, connection, order_by=order_by_sql)",
        "sql, _ = super().as_sql(compiler, connection,"
    ],
    [
        "from django.db.models import Aggregate, FloatField, IntegerField",
        "from django.db.models import Aggregate,"
    ],
    [
        "def __init__(self, y, x, output_field=None, filter=None, default=None):",
        "def __init__(self, y, x, output_field=None, filter=None,"
    ],
    [
        "if not x or not y:",
        "if not x or not"
    ],
    [
        "raise ValueError(\"Both y and x must be provided.\")",
        "raise ValueError(\"Both y and"
    ],
    [
        "def __init__(self, y, x, sample=False, filter=None, default=None):",
        "def __init__(self, y, x, sample=False, filter=None,"
    ],
    [
        "self.function = \"COVAR_SAMP\" if sample else \"COVAR_POP\"",
        "self.function = \"COVAR_SAMP\" if sample else"
    ],
    [
        "from django.db.models import Aggregate, BooleanField, JSONField, TextField, Value",
        "from django.db.models import Aggregate,"
    ],
    [
        "from django.db.models import CharField, EmailField, TextField",
        "from django.db.models import CharField, EmailField,"
    ],
    [
        "\"django.contrib.postgres.fields.CICharField is removed except for support \"",
        "\"django.contrib.postgres.fields.CICharField is removed except for"
    ],
    [
        "'Use CharField(db_collation=\"…\") with a case-insensitive non-deterministic '",
        "'Use CharField(db_collation=\"…\") with a"
    ],
    [
        "\"django.contrib.postgres.fields.CIEmailField is removed except for support \"",
        "\"django.contrib.postgres.fields.CIEmailField is removed except"
    ],
    [
        "'Use EmailField(db_collation=\"…\") with a case-insensitive '",
        "'Use EmailField(db_collation=\"…\") with a"
    ],
    [
        "\"django.contrib.postgres.fields.CITextField is removed except for support \"",
        "\"django.contrib.postgres.fields.CITextField is removed except for"
    ],
    [
        "'Use TextField(db_collation=\"…\") with a case-insensitive non-deterministic '",
        "'Use TextField(db_collation=\"…\") with a case-insensitive"
    ],
    [
        "\"\"\"A class that represents range boundaries.\"\"\"",
        "\"\"\"A class that"
    ],
    [
        "self.lower = \"[\" if inclusive_lower else \"(\"",
        "self.lower = \"[\" if inclusive_lower else"
    ],
    [
        "self.upper = \"]\" if inclusive_upper else \")\"",
        "self.upper = \"]\" if"
    ],
    [
        "return \"'%s%s'\" % (self.lower, self.upper), []",
        "return \"'%s%s'\" % (self.lower, self.upper),"
    ],
    [
        "\"'%s' object has no attribute 'model'\" % self.__class__.__name__",
        "\"'%s' object has no attribute"
    ],
    [
        "return isinstance(value, (list, tuple)) or super()._choices_is_value(value)",
        "return isinstance(value, (list,"
    ],
    [
        "Continuous range field. It allows specifying default bounds for list and",
        "Continuous range field. It allows specifying default bounds for"
    ],
    [
        "if default_bounds not in (\"[)\", \"(]\", \"()\", \"[]\"):",
        "if default_bounds not in"
    ],
    [
        "raise ValueError(\"default_bounds must be one of '[)', '(]', '()', or '[]'.\")",
        "raise ValueError(\"default_bounds must be one of"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "if self.default_bounds and self.default_bounds != CANONICAL_RANGE_BOUNDS:",
        "if self.default_bounds and self.default_bounds !="
    ],
    [
        "if not isinstance(self.rhs, (list, tuple, Range)):",
        "if not isinstance(self.rhs, (list, tuple,"
    ],
    [
        "Lookup for Date/DateTimeRange containment to cast the rhs to the correct",
        "Lookup for Date/DateTimeRange containment to cast the rhs"
    ],
    [
        "return \"%s%s\" % (sql, cast_sql), params",
        "return \"%s%s\" % (sql,"
    ],
    [
        "return \"%s::%s\" % (rhs, cast_type), rhs_params",
        "return \"%s::%s\" % (rhs, cast_type),"
    ],
    [
        "from django.db.models import JSONField as BuiltinJSONField",
        "from django.db.models import JSONField as"
    ],
    [
        "\"django.contrib.postgres.fields.JSONField is removed except for \"",
        "\"django.contrib.postgres.fields.JSONField is removed except"
    ],
    [
        "from django.db.models import Field, Func, IntegerField, Transform, Value",
        "from django.db.models import Field,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"item_invalid\": _(\"Item %(nth)s in the array did not validate:\"),",
        "\"item_invalid\": _(\"Item %(nth)s in the array did"
    ],
    [
        "\"nested_array_mismatch\": _(\"Nested arrays must have the same length.\"),",
        "\"nested_array_mismatch\": _(\"Nested arrays must have the same"
    ],
    [
        "\"'%s' object has no attribute 'model'\" % self.__class__.__name__",
        "\"'%s' object has no attribute 'model'\" %"
    ],
    [
        "return isinstance(value, (list, tuple)) or super()._choices_is_value(value)",
        "return isinstance(value, (list,"
    ],
    [
        "\"Base field for array cannot be a related field.\",",
        "\"Base field for array cannot be a"
    ],
    [
        "\"Base field for array has errors:\\n    %s\" % error_messages,",
        "\"Base field for array has errors:\\n %s\""
    ],
    [
        "\"Base field for array has warnings:\\n    %s\"",
        "\"Base field for array has warnings:\\n"
    ],
    [
        "return \"Array of %s\" % self.base_field.description",
        "return \"Array of"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "value = [self.base_field.to_python(val) for val in vals]",
        "value = [self.base_field.to_python(val) for val in"
    ],
    [
        "if isinstance(rhs, (tuple, list)) and any(self._rhs_not_none_values(rhs)):",
        "if isinstance(rhs, (tuple,"
    ],
    [
        "return \"%s::%s\" % (rhs, cast_type), rhs_params",
        "return \"%s::%s\" % (rhs, cast_type),"
    ],
    [
        "\"CASE WHEN %(lhs)s IS NULL THEN NULL ELSE \"",
        "\"CASE WHEN %(lhs)s IS NULL THEN"
    ],
    [
        "def __init__(self, index, base_field, *args, **kwargs):",
        "def __init__(self, index, base_field,"
    ],
    [
        "return \"%s[%%s]\" % lhs, (*params, self.index)",
        "return \"%s[%%s]\" %"
    ],
    [
        "def __init__(self, start, end, *args, **kwargs):",
        "def __init__(self, start, end, *args,"
    ],
    [
        "from django.db.models import Field, TextField, Transform",
        "from django.db.models import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "description = _(\"Map of strings to strings/nulls\")",
        "description = _(\"Map of strings"
    ],
    [
        "\"not_a_string\": _(\"The value of “%(key)s” is not a string or null.\"),",
        "\"not_a_string\": _(\"The value of “%(key)s” is not a string or"
    ],
    [
        "if not isinstance(val, str) and val is not None:",
        "if not isinstance(val, str) and val is not"
    ],
    [
        "value = [str(item) for item in value]",
        "value = [str(item) for item"
    ],
    [
        "return \"(%s -> %%s)\" % lhs, tuple(params) + (self.key_name,)",
        "return \"(%s -> %%s)\" %"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"This should be an absolute path, excluding the domain name. Example: \"",
        "\"This should be an absolute path, excluding"
    ],
    [
        "\"This can be either an absolute path (as above) or a full URL \"",
        "\"This can be either an absolute path (as above) or a"
    ],
    [
        "\"starting with a scheme such as “https://”.\"",
        "\"starting with a scheme such as"
    ],
    [
        "return \"%s ---> %s\" % (self.old_path, self.new_path)",
        "return \"%s ---> %s\" % (self.old_path,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "\"You cannot use RedirectFallbackMiddleware when \"",
        "\"You cannot use RedirectFallbackMiddleware when"
    ],
    [
        "if r is None and settings.APPEND_SLASH and not request.path.endswith(\"/\"):",
        "if r is None and settings.APPEND_SLASH"
    ],
    [
        "\"This can be either an absolute path (as above) or a full \"",
        "\"This can be either an absolute path (as above)"
    ],
    [
        "\"URL starting with a scheme such as “https://”.\"",
        "\"URL starting with a"
    ],
    [
        "\"This should be an absolute path, excluding the domain \"",
        "\"This should be an absolute path,"
    ],
    [
        "\"This can be either an absolute path (as above) or a full \"",
        "\"This can be either an absolute path (as above)"
    ],
    [
        "Django provides full support for anonymous sessions. The session",
        "Django provides full support for"
    ],
    [
        "framework lets you store and retrieve arbitrary data on a",
        "framework lets you store and retrieve arbitrary data on"
    ],
    [
        "per-site-visitor basis. It stores data on the server side and",
        "per-site-visitor basis. It stores data on"
    ],
    [
        "abstracts the sending and receiving of cookies. Cookies contain a",
        "abstracts the sending and receiving of cookies. Cookies"
    ],
    [
        "session ID -- not the data itself.",
        "session ID -- not the data"
    ],
    [
        "The Django sessions framework is entirely cookie-based. It does",
        "The Django sessions framework is entirely"
    ],
    [
        "not fall back to putting session IDs in URLs. This is an intentional",
        "not fall back to putting session IDs in"
    ],
    [
        "design decision. Not only does that behavior make URLs ugly, it makes",
        "design decision. Not only does that behavior make URLs ugly,"
    ],
    [
        "your site vulnerable to session-ID theft via the \"Referer\" header.",
        "your site vulnerable to session-ID theft via the \"Referer\""
    ],
    [
        "For complete documentation on using Sessions in your code, consult",
        "For complete documentation on using Sessions"
    ],
    [
        "the sessions documentation that is shipped with Django (also available",
        "the sessions documentation that is shipped with"
    ],
    [
        "from django.core.signing import JSONSerializer as BaseJSONSerializer",
        "from django.core.signing import JSONSerializer"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"\"\"The session may be tampered with\"\"\"",
        "\"\"\"The session may be"
    ],
    [
        "This module allows importing AbstractBaseSession even",
        "This module allows importing AbstractBaseSession"
    ],
    [
        "when django.contrib.sessions is not in INSTALLED_APPS.",
        "when django.contrib.sessions is"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "Return the given session dictionary serialized and encoded as a string.",
        "Return the given session dictionary serialized"
    ],
    [
        "If request.session was modified, or if the configuration is to save the",
        "If request.session was modified, or if the configuration is"
    ],
    [
        "session every time, save the changes and set a session cookie or delete",
        "session every time, save the changes and set"
    ],
    [
        "the session cookie if the session has been emptied.",
        "the session cookie if the session has been"
    ],
    [
        "if settings.SESSION_COOKIE_NAME in request.COOKIES and empty:",
        "if settings.SESSION_COOKIE_NAME in request.COOKIES and"
    ],
    [
        "if (modified or settings.SESSION_SAVE_EVERY_REQUEST) and not empty:",
        "if (modified or settings.SESSION_SAVE_EVERY_REQUEST) and not"
    ],
    [
        "\"The request's session was deleted before the \"",
        "\"The request's session was deleted before the"
    ],
    [
        "\"request completed. The user may have logged \"",
        "\"request completed. The user may have"
    ],
    [
        "\"out in a concurrent request, for example.\"",
        "\"out in a concurrent request, for"
    ],
    [
        "Load the data from the key itself instead of fetching from some",
        "Load the data from the key itself instead of fetching"
    ],
    [
        "external data store. Opposite of _get_session_key(), raise BadSignature",
        "external data store. Opposite of _get_session_key(),"
    ],
    [
        "To create a new key, set the modified flag so that the cookie is set",
        "To create a new key, set the modified flag so that the cookie"
    ],
    [
        "on the client for the current request.",
        "on the client for"
    ],
    [
        "To save, get the session key as a securely signed string and then set",
        "To save, get the session key as"
    ],
    [
        "the modified flag so that the cookie is set on the client for the",
        "the modified flag so that the cookie is set"
    ],
    [
        "This method makes sense when you're talking to a shared resource, but",
        "This method makes sense when you're talking"
    ],
    [
        "it doesn't matter when you're storing the information in the client's",
        "it doesn't matter when you're storing the information in"
    ],
    [
        "To delete, clear the session key and the underlying data structure",
        "To delete, clear the session key"
    ],
    [
        "and set the modified flag so that the cookie is set on the client for",
        "and set the modified flag so that the cookie is set"
    ],
    [
        "Keep the same data but with a new key. Call save() and it will",
        "Keep the same data but with a new key. Call"
    ],
    [
        "automatically save a cookie with a new key at the end of the request.",
        "automatically save a cookie with a new key at the"
    ],
    [
        "Instead of generating a random string, generate a secure url-safe",
        "Instead of generating a random string, generate a secure"
    ],
    [
        "from django.contrib.sessions.backends.base import CreateError, SessionBase, UpdateError",
        "from django.contrib.sessions.backends.base import CreateError,"
    ],
    [
        "from django.db import DatabaseError, IntegrityError, router, transaction",
        "from django.db import DatabaseError,"
    ],
    [
        "return self.decode(s.session_data) if s else {}",
        "return self.decode(s.session_data) if s else"
    ],
    [
        "return self.decode(s.session_data) if s else {}",
        "return self.decode(s.session_data) if s else"
    ],
    [
        "Return a new instance of the session model object, which represents the",
        "Return a new instance of the session model object,"
    ],
    [
        "current session state. Intended to be used for saving the session data",
        "current session state. Intended to be"
    ],
    [
        "Save the current session data to the database. If 'must_create' is",
        "Save the current session data to the database."
    ],
    [
        "True, raise a database error if the saving operation doesn't create a",
        "True, raise a database error if the saving"
    ],
    [
        "new entry (as opposed to possibly updating an existing entry).",
        "new entry (as opposed to possibly updating"
    ],
    [
        "from django.contrib.sessions.backends.db import SessionStore as DBStore",
        "from django.contrib.sessions.backends.db import"
    ],
    [
        "and (self.cache_key_prefix + session_key) in self._cache",
        "and (self.cache_key_prefix +"
    ],
    [
        "and (self.cache_key_prefix + session_key) in self._cache",
        "and (self.cache_key_prefix +"
    ],
    [
        "logger.exception(\"Error saving to cache (%s)\", self._cache)",
        "logger.exception(\"Error saving to"
    ],
    [
        "logger.exception(\"Error saving to cache (%s)\", self._cache)",
        "logger.exception(\"Error saving to cache (%s)\","
    ],
    [
        "Remove the current session data from the database and regenerate the",
        "Remove the current session data from the"
    ],
    [
        "from django.contrib.sessions.backends.base import CreateError, SessionBase, UpdateError",
        "from django.contrib.sessions.backends.base import CreateError,"
    ],
    [
        "\"Unable to create a new session key. \"",
        "\"Unable to create a new session key."
    ],
    [
        "\"It is likely that the cache is unavailable.\"",
        "\"It is likely that the cache is"
    ],
    [
        "\"Unable to create a new session key. \"",
        "\"Unable to create a new session key."
    ],
    [
        "\"It is likely that the cache is unavailable.\"",
        "\"It is likely that the cache is"
    ],
    [
        "elif await self._cache.aget(await self.acache_key()) is not None:",
        "elif await self._cache.aget(await self.acache_key()) is"
    ],
    [
        "bool(session_key) and (self.cache_key_prefix + session_key) in self._cache",
        "bool(session_key) and (self.cache_key_prefix + session_key) in"
    ],
    [
        "Implement a file based session store.",
        "Implement a file based"
    ],
    [
        "\"The session storage path %r doesn't exist. Please set your\"",
        "\"The session storage path %r"
    ],
    [
        "\" SESSION_FILE_PATH setting to an existing directory in which\"",
        "\" SESSION_FILE_PATH setting to an existing directory"
    ],
    [
        "\" Django can store session data.\" % storage_path",
        "\" Django can store session"
    ],
    [
        "Get the file associated with this session key.",
        "Get the file associated with this"
    ],
    [
        "raise InvalidSessionKey(\"Invalid characters in session key\")",
        "raise InvalidSessionKey(\"Invalid characters in"
    ],
    [
        "Return the modification time of the file storing the session's content.",
        "Return the modification time of the file storing the session's"
    ],
    [
        "tz = datetime.timezone.utc if settings.USE_TZ else None",
        "tz = datetime.timezone.utc if settings.USE_TZ else"
    ],
    [
        "Return the expiry time of the file storing the session's content.",
        "Return the expiry time of the"
    ],
    [
        "Used internally as a consistent exception type to catch from save (see the",
        "Used internally as a consistent exception type to catch from save"
    ],
    [
        "Occurs if Django tries to update a session that was deleted.",
        "Occurs if Django tries to update a session"
    ],
    [
        "Base class for all Session classes.",
        "Base class for all"
    ],
    [
        "self.modified = self.modified or key in self._session",
        "self.modified = self.modified or key"
    ],
    [
        "args = () if default is self.__not_given else (default,)",
        "args = () if default is self.__not_given"
    ],
    [
        "self.modified = self.modified or key in (await self._aget_session())",
        "self.modified = self.modified or key in (await"
    ],
    [
        "args = () if default is self.__not_given else (default,)",
        "args = () if default is self.__not_given"
    ],
    [
        "\"Return the given session dictionary serialized and encoded as a string.\"",
        "\"Return the given session dictionary serialized and encoded"
    ],
    [
        "\"Return True when there is no session_key and the session is empty.\"",
        "\"Return True when there is no session_key and the session is"
    ],
    [
        "return not self._session_key and not self._session_cache",
        "return not self._session_key and not"
    ],
    [
        "\"Return session key that isn't being used.\"",
        "\"Return session key that"
    ],
    [
        "arbitrary lower bound for some minimal key security.",
        "arbitrary lower bound for some minimal key"
    ],
    [
        "Validate session key on assignment. Invalid values will set to None.",
        "Validate session key on assignment. Invalid values will"
    ],
    [
        "Lazily load session from storage (unless \"no_load\" is True, when only",
        "Lazily load session from storage (unless"
    ],
    [
        "an empty dict is stored) and store it in the current instance.",
        "an empty dict is stored) and store it in the"
    ],
    [
        "if self.session_key is None or no_load:",
        "if self.session_key is None"
    ],
    [
        "if self.session_key is None or no_load:",
        "if self.session_key is"
    ],
    [
        "\"\"\"Get the number of seconds until the session expires.",
        "\"\"\"Get the number of seconds until the session"
    ],
    [
        "Optionally, this function accepts `modification` and `expiry` keyword",
        "Optionally, this function accepts"
    ],
    [
        "arguments specifying the modification and expiry of the session.",
        "arguments specifying the modification and expiry of the"
    ],
    [
        "\"\"\"Get session the expiry date (as a datetime object).",
        "\"\"\"Get session the expiry date (as a datetime"
    ],
    [
        "Optionally, this function accepts `modification` and `expiry` keyword",
        "Optionally, this function accepts"
    ],
    [
        "arguments specifying the modification and expiry of the session.",
        "arguments specifying the modification and expiry"
    ],
    [
        "Set a custom expiration for the session. ``value`` can be an integer,",
        "Set a custom expiration for the session."
    ],
    [
        "a Python ``datetime`` or ``timedelta`` object or ``None``.",
        "a Python ``datetime`` or ``timedelta``"
    ],
    [
        "If ``value`` is an integer, the session will expire after that many",
        "If ``value`` is an integer, the"
    ],
    [
        "If ``value`` is a ``datetime`` or ``timedelta`` object, the session",
        "If ``value`` is a ``datetime`` or ``timedelta`` object,"
    ],
    [
        "will expire at that specific future time.",
        "will expire at that specific"
    ],
    [
        "If ``value`` is ``None``, the session uses the global session expiry",
        "If ``value`` is ``None``, the session"
    ],
    [
        "Return ``True`` if the session is set to expire when the browser",
        "Return ``True`` if the session is set to expire when"
    ],
    [
        "closes, and ``False`` if there's an expiry date. Use",
        "closes, and ``False`` if there's an expiry date."
    ],
    [
        "``get_expiry_date()`` or ``get_expiry_age()`` to find the actual expiry",
        "``get_expiry_date()`` or ``get_expiry_age()`` to"
    ],
    [
        "if (expiry := self.get(\"_session_expiry\")) is None:",
        "if (expiry := self.get(\"_session_expiry\"))"
    ],
    [
        "if (expiry := await self.aget(\"_session_expiry\")) is None:",
        "if (expiry := await self.aget(\"_session_expiry\"))"
    ],
    [
        "Remove the current session data from the database and regenerate the",
        "Remove the current session data from the database and"
    ],
    [
        "Create a new session key, while retaining the current session data.",
        "Create a new session key, while retaining the current session"
    ],
    [
        "Create a new session key, while retaining the current session data.",
        "Create a new session key, while retaining the current"
    ],
    [
        "Return True if the given session_key already exists.",
        "Return True if the"
    ],
    [
        "\"subclasses of SessionBase must provide an exists() method\"",
        "\"subclasses of SessionBase must provide"
    ],
    [
        "Create a new session instance. Guaranteed to create a new object with",
        "Create a new session instance. Guaranteed to create a new object"
    ],
    [
        "a unique key and will have saved the result once (with empty data)",
        "a unique key and will have saved the result once (with empty"
    ],
    [
        "\"subclasses of SessionBase must provide a create() method\"",
        "\"subclasses of SessionBase must provide"
    ],
    [
        "Save the session data. If 'must_create' is True, create a new session",
        "Save the session data. If 'must_create' is True, create"
    ],
    [
        "object (or raise CreateError). Otherwise, only update an existing",
        "object (or raise CreateError). Otherwise, only update an"
    ],
    [
        "object and don't create one (raise UpdateError if needed).",
        "object and don't create one"
    ],
    [
        "\"subclasses of SessionBase must provide a save() method\"",
        "\"subclasses of SessionBase must provide a"
    ],
    [
        "Delete the session data under this key. If the key is None, use the",
        "Delete the session data under this key. If"
    ],
    [
        "\"subclasses of SessionBase must provide a delete() method\"",
        "\"subclasses of SessionBase must"
    ],
    [
        "Load the session data and return a dictionary.",
        "Load the session data"
    ],
    [
        "\"subclasses of SessionBase must provide a load() method\"",
        "\"subclasses of SessionBase must"
    ],
    [
        "Remove expired sessions from the session store.",
        "Remove expired sessions from the"
    ],
    [
        "If this operation isn't possible on a given backend, it should raise",
        "If this operation isn't possible on a given backend, it should"
    ],
    [
        "NotImplementedError. If it isn't necessary, because the backend has",
        "NotImplementedError. If it isn't necessary, because the backend"
    ],
    [
        "a built-in expiration mechanism, it should be a no-op.",
        "a built-in expiration mechanism, it"
    ],
    [
        "raise NotImplementedError(\"This backend does not support clear_expired().\")",
        "raise NotImplementedError(\"This backend does not"
    ],
    [
        "\"Can be run as a cronjob or directly to clean out expired sessions \"",
        "\"Can be run as a cronjob or directly to"
    ],
    [
        "\"Session engine '%s' doesn't support clearing expired \"",
        "\"Session engine '%s' doesn't support clearing expired"
    ],
    [
        "from django.apps import apps as django_apps",
        "from django.apps import apps"
    ],
    [
        "\"\"\"Languages for which this item is displayed.\"\"\"",
        "\"\"\"Languages for which this item"
    ],
    [
        "return [lang_code for lang_code, _ in settings.LANGUAGES]",
        "return [lang_code for lang_code, _ in"
    ],
    [
        "return self.protocol or protocol or \"https\"",
        "return self.protocol or protocol or"
    ],
    [
        "\"To use sitemaps, either enable the sites framework or pass \"",
        "\"To use sitemaps, either enable the sites"
    ],
    [
        "\"a Site/RequestSite object in your view.\"",
        "\"a Site/RequestSite object in your"
    ],
    [
        "return max([self.lastmod(item) for item in self.items()], default=None)",
        "return max([self.lastmod(item) for item in"
    ],
    [
        "all_items_lastmod = lastmod is not None",
        "all_items_lastmod = lastmod"
    ],
    [
        "latest_lastmod is None or lastmod > latest_lastmod",
        "latest_lastmod is None or"
    ],
    [
        "\"priority\": str(priority if priority is not None else \"\"),",
        "\"priority\": str(priority if priority is not"
    ],
    [
        "if self.x_default and settings.LANGUAGE_CODE in item_languages:",
        "if self.x_default and settings.LANGUAGE_CODE"
    ],
    [
        "def __init__(self, info_dict, priority=None, changefreq=None, protocol=None):",
        "def __init__(self, info_dict, priority=None,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "Returns the latest `lastmod` where `lastmod` can be either a date or a",
        "Returns the latest `lastmod` where `lastmod` can be either"
    ],
    [
        "return new_lastmod if current_lastmod is None else max(current_lastmod, new_lastmod)",
        "return new_lastmod if current_lastmod is None else max(current_lastmod,"
    ],
    [
        "protocol = req_protocol if site.protocol is None else site.protocol",
        "protocol = req_protocol if site.protocol"
    ],
    [
        "absolute_url = \"%s://%s%s\" % (protocol, req_site.domain, sitemap_url)",
        "absolute_url = \"%s://%s%s\" %"
    ],
    [
        "headers = {\"Last-Modified\": http_date(lastmod.timestamp())} if lastmod else None",
        "headers = {\"Last-Modified\": http_date(lastmod.timestamp())}"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "from datetime import date, datetime, timezone",
        "from datetime import date,"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "Convert an integer to a string containing commas every three digits.",
        "Convert an integer to a string containing commas every"
    ],
    [
        "result = prefix_with_commas + result[len(prefix) :]",
        "result = prefix_with_commas"
    ],
    [
        "lambda number: ngettext(\"%(value)s sextillion\", \"%(value)s sextillion\", number),",
        "lambda number: ngettext(\"%(value)s sextillion\","
    ],
    [
        "lambda number: ngettext(\"%(value)s septillion\", \"%(value)s septillion\", number),",
        "lambda number: ngettext(\"%(value)s septillion\", \"%(value)s septillion\","
    ],
    [
        "Convert a large integer to a friendly text representation. Works best",
        "Convert a large integer to a"
    ],
    [
        "number. This follows Associated Press style.",
        "number. This follows Associated"
    ],
    [
        "For date values that are tomorrow, today or yesterday compared to",
        "For date values that are tomorrow, today"
    ],
    [
        "present day return representing string. Otherwise, return a string",
        "present day return representing string. Otherwise,"
    ],
    [
        "For date and time values show how many seconds, minutes, or hours ago",
        "For date and time values show how many seconds,"
    ],
    [
        "compared to current timestamp return representing string.",
        "compared to current timestamp"
    ],
    [
        "\"past-hour\": ngettext_lazy(\"an hour ago\", \"%(count)s hours ago\", \"count\"),",
        "\"past-hour\": ngettext_lazy(\"an hour ago\", \"%(count)s hours ago\","
    ],
    [
        "\"past-minute\": ngettext_lazy(\"a minute ago\", \"%(count)s minutes ago\", \"count\"),",
        "\"past-minute\": ngettext_lazy(\"a minute ago\","
    ],
    [
        "\"past-second\": ngettext_lazy(\"a second ago\", \"%(count)s seconds ago\", \"count\"),",
        "\"past-second\": ngettext_lazy(\"a second ago\","
    ],
    [
        "\"a second from now\", \"%(count)s seconds from now\", \"count\"",
        "\"a second from now\", \"%(count)s seconds from now\","
    ],
    [
        "\"a minute from now\", \"%(count)s minutes from now\", \"count\"",
        "\"a minute from now\", \"%(count)s minutes"
    ],
    [
        "\"an hour from now\", \"%(count)s hours from now\", \"count\"",
        "\"an hour from now\", \"%(count)s"
    ],
    [
        "\"naturaltime-past\", \"%(num)d year\", \"%(num)d years\", \"num\"",
        "\"naturaltime-past\", \"%(num)d year\", \"%(num)d years\","
    ],
    [
        "\"naturaltime-past\", \"%(num)d month\", \"%(num)d months\", \"num\"",
        "\"naturaltime-past\", \"%(num)d month\","
    ],
    [
        "\"naturaltime-past\", \"%(num)d week\", \"%(num)d weeks\", \"num\"",
        "\"naturaltime-past\", \"%(num)d week\", \"%(num)d"
    ],
    [
        "\"day\": npgettext_lazy(\"naturaltime-past\", \"%(num)d day\", \"%(num)d days\", \"num\"),",
        "\"day\": npgettext_lazy(\"naturaltime-past\", \"%(num)d day\", \"%(num)d days\","
    ],
    [
        "\"naturaltime-past\", \"%(num)d hour\", \"%(num)d hours\", \"num\"",
        "\"naturaltime-past\", \"%(num)d hour\", \"%(num)d"
    ],
    [
        "\"naturaltime-past\", \"%(num)d minute\", \"%(num)d minutes\", \"num\"",
        "\"naturaltime-past\", \"%(num)d minute\", \"%(num)d minutes\","
    ],
    [
        "\"naturaltime-future\", \"%(num)d year\", \"%(num)d years\", \"num\"",
        "\"naturaltime-future\", \"%(num)d year\", \"%(num)d"
    ],
    [
        "\"naturaltime-future\", \"%(num)d month\", \"%(num)d months\", \"num\"",
        "\"naturaltime-future\", \"%(num)d month\", \"%(num)d months\","
    ],
    [
        "\"naturaltime-future\", \"%(num)d week\", \"%(num)d weeks\", \"num\"",
        "\"naturaltime-future\", \"%(num)d week\","
    ],
    [
        "\"naturaltime-future\", \"%(num)d day\", \"%(num)d days\", \"num\"",
        "\"naturaltime-future\", \"%(num)d day\", \"%(num)d"
    ],
    [
        "\"naturaltime-future\", \"%(num)d hour\", \"%(num)d hours\", \"num\"",
        "\"naturaltime-future\", \"%(num)d hour\","
    ],
    [
        "\"naturaltime-future\", \"%(num)d minute\", \"%(num)d minutes\", \"num\"",
        "\"naturaltime-future\", \"%(num)d minute\", \"%(num)d"
    ],
    [
        "now = datetime.now(timezone.utc if is_aware(value) else None)",
        "now = datetime.now(timezone.utc if is_aware(value)"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "Return the ContentType object for a given model, creating the",
        "Return the ContentType object for a given model, creating"
    ],
    [
        "ContentType if necessary. Lookups are cached so that subsequent lookups",
        "ContentType if necessary. Lookups are cached so"
    ],
    [
        "for the same model don't hit the database.",
        "for the same model"
    ],
    [
        "Given *models, return a dictionary mapping {model: content_type}.",
        "Given *models, return a dictionary mapping"
    ],
    [
        "for (app_label, model_name), opts_models in needed_opts.items():",
        "for (app_label, model_name), opts_models in"
    ],
    [
        "Lookup a ContentType by ID. Use the same shared cache as get_for_model",
        "Lookup a ContentType by ID. Use"
    ],
    [
        "(though ContentTypes are not created on-the-fly by get_by_id).",
        "(though ContentTypes are not"
    ],
    [
        "\"\"\"Insert a ContentType into the cache.\"\"\"",
        "\"\"\"Insert a ContentType into"
    ],
    [
        "return \"%s | %s\" % (",
        "return \"%s | %s\" %"
    ],
    [
        "\"\"\"Return the model class for this type of content.\"\"\"",
        "\"\"\"Return the model class for"
    ],
    [
        "Return an object of this type for the keyword arguments given.",
        "Return an object of this type for the keyword"
    ],
    [
        "Basically, this is a proxy around this object_type's get_object() model",
        "Basically, this is a proxy around this"
    ],
    [
        "method. The ObjectNotExist exception, if thrown, will not be caught,",
        "method. The ObjectNotExist exception, if thrown,"
    ],
    [
        "so code that calls this method should catch it.",
        "so code that calls this"
    ],
    [
        "Return all objects of this type for the keyword arguments given.",
        "Return all objects of this type for the"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, models, router, transaction",
        "from django.db import DEFAULT_DB_ALIAS, models, router,"
    ],
    [
        "from django.db.models import DO_NOTHING, ForeignObject, ForeignObjectRel",
        "from django.db.models import"
    ],
    [
        "Provide a generic many-to-one relation through the ``content_type`` and",
        "Provide a generic many-to-one relation"
    ],
    [
        "This class also doubles as an accessor to the related object (similar to",
        "This class also doubles as an accessor to the related object (similar"
    ],
    [
        "ForwardManyToOneDescriptor) by adding itself as a model attribute.",
        "ForwardManyToOneDescriptor) by adding itself"
    ],
    [
        "\"The GenericForeignKey object ID references the \"",
        "\"The GenericForeignKey object ID references"
    ],
    [
        "Check if field named `field_name` in model `model` exists and is a",
        "Check if field named `field_name` in model `model` exists and"
    ],
    [
        "valid content_type field (is a ForeignKey to ContentType).",
        "valid content_type field (is a ForeignKey to"
    ],
    [
        "\"The GenericForeignKey content type references the \"",
        "\"The GenericForeignKey content type references"
    ],
    [
        "\"GenericForeignKeys must use a ForeignKey to \"",
        "\"GenericForeignKeys must use a ForeignKey to"
    ],
    [
        "\"'%s.%s' is not a ForeignKey to 'contenttypes.ContentType'.\"",
        "\"'%s.%s' is not a ForeignKey"
    ],
    [
        "\"GenericForeignKeys must use a ForeignKey to \"",
        "\"GenericForeignKeys must use a ForeignKey"
    ],
    [
        "def get_content_type(self, obj=None, id=None, using=None, model=None):",
        "def get_content_type(self, obj=None,"
    ],
    [
        "\"Only one queryset is allowed for each content type.\"",
        "\"Only one queryset is allowed for each"
    ],
    [
        "if rel_obj is None and self.is_cached(instance):",
        "if rel_obj is None"
    ],
    [
        "pk_match = ct_match and rel_obj._meta.pk.to_python(pk_val) == rel_obj.pk",
        "pk_match = ct_match and"
    ],
    [
        "Used by GenericRelation to store information about the relation.",
        "Used by GenericRelation to store information about"
    ],
    [
        "Provide a reverse to a relation created by a GenericForeignKey.",
        "Provide a reverse to a"
    ],
    [
        "Return True if field is a GenericForeignKey whose content type and",
        "Return True if field is a GenericForeignKey whose"
    ],
    [
        "object id fields correspond to the equivalent attributes on this",
        "object id fields correspond to the equivalent"
    ],
    [
        "if any(self._is_matching_generic_foreign_key(field) for field in fields):",
        "if any(self._is_matching_generic_foreign_key(field) for field in"
    ],
    [
        "\"The GenericRelation defines a relation with the model \"",
        "\"The GenericRelation defines a relation with the"
    ],
    [
        "\"'%s', but that model does not have a GenericForeignKey.\"",
        "\"'%s', but that model does not have a"
    ],
    [
        "Return the path that joins the current model through any parent models.",
        "Return the path that joins the"
    ],
    [
        "The idea is that if you have a GFK defined on a parent model then we",
        "The idea is that if you have a"
    ],
    [
        "need to join the parent model first, then the child model.",
        "need to join the parent model first, then"
    ],
    [
        "return str([instance.pk for instance in qs])",
        "return str([instance.pk for instance"
    ],
    [
        "Return the content type associated with this field's model.",
        "Return the content type associated with"
    ],
    [
        "Return all objects related to ``objs`` via this ``GenericRelation``.",
        "Return all objects related to"
    ],
    [
        "\"%s__in\" % self.object_id_field_name: [obj.pk for obj in objs],",
        "\"%s__in\" % self.object_id_field_name: [obj.pk for"
    ],
    [
        "Accessor to the related objects manager on the one-to-many relation created",
        "Accessor to the related objects manager on the one-to-many"
    ],
    [
        "Factory function to create a manager that subclasses another manager",
        "Factory function to create a manager"
    ],
    [
        "(generally the default manager of a given model) and adds behaviors",
        "(generally the default manager of a"
    ],
    [
        "Filter the queryset for the instance this manager is bound to.",
        "Filter the queryset for the instance this manager is"
    ],
    [
        "db = self._db or router.db_for_read(self.model, instance=self.instance)",
        "db = self._db or"
    ],
    [
        "\"querysets argument of get_prefetch_querysets() should have a \"",
        "\"querysets argument of get_prefetch_querysets() should have a"
    ],
    [
        "(f\"{self.object_id_field_name}__in\", {obj.pk for obj in objs}),",
        "(f\"{self.object_id_field_name}__in\", {obj.pk for obj"
    ],
    [
        "if obj._state.adding or obj._state.db != db:",
        "if obj._state.adding or obj._state.db !="
    ],
    [
        "\"%r instance isn't saved. Use bulk=False or save \"",
        "\"%r instance isn't saved. Use bulk=False or"
    ],
    [
        "self._clear(self.filter(pk__in=[o.pk for o in objs]), bulk)",
        "self._clear(self.filter(pk__in=[o.pk for o in objs]),"
    ],
    [
        "def set(self, objs, *, bulk=True, clear=False):",
        "def set(self, objs,"
    ],
    [
        "async def aset(self, objs, *, bulk=True, clear=False):",
        "async def aset(self, objs, *,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "A formset for generic inline objects to a parent.",
        "A formset for generic inline"
    ],
    [
        "if self.instance is None or not self.instance._is_pk_set():",
        "if self.instance is None or"
    ],
    [
        "Return a ``GenericInlineFormSet`` for the given kwargs.",
        "Return a ``GenericInlineFormSet`` for the given"
    ],
    [
        "You must provide ``ct_field`` and ``fk_field`` if they are different from",
        "You must provide ``ct_field`` and ``fk_field`` if they are"
    ],
    [
        "the defaults ``content_type`` and ``object_id`` respectively.",
        "the defaults ``content_type`` and"
    ],
    [
        "raise Exception(\"fk_name '%s' is not a ForeignKey to ContentType\" % ct_field)",
        "raise Exception(\"fk_name '%s' is not a ForeignKey to ContentType\""
    ],
    [
        "exclude = [*(exclude or []), ct_field.name, fk_field.name]",
        "exclude = [*(exclude or []),"
    ],
    [
        "\"'%s' has no GenericForeignKey.\" % obj.model._meta.label,",
        "\"'%s' has no"
    ],
    [
        "\"'ct_field' references '%s', which is not a field on '%s'.\"",
        "\"'ct_field' references '%s', which is not a field on"
    ],
    [
        "\"'ct_fk_field' references '%s', which is not a field on '%s'.\"",
        "\"'ct_fk_field' references '%s', which is not"
    ],
    [
        "if gfk.ct_field == obj.ct_field and gfk.fk_field == obj.ct_fk_field:",
        "if gfk.ct_field == obj.ct_field and gfk.fk_field =="
    ],
    [
        "\"'%s' has no GenericForeignKey using content type field '%s' and \"",
        "\"'%s' has no GenericForeignKey using content type field '%s'"
    ],
    [
        "exclude = [*(self.exclude or []), *self.get_readonly_fields(request, obj)]",
        "exclude = [*(self.exclude or"
    ],
    [
        "can_delete = self.can_delete and self.has_delete_permission(request, obj)",
        "can_delete = self.can_delete and"
    ],
    [
        "if defaults[\"fields\"] is None and not modelform_defines_fields(",
        "if defaults[\"fields\"] is None and not"
    ],
    [
        "if queryset is not None and (",
        "if queryset is not None"
    ],
    [
        "\"Prefetch querysets cannot use raw(), values(), and values_list().\"",
        "\"Prefetch querysets cannot use"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "Redirect to an object's page based on a content-type ID and an object ID.",
        "Redirect to an object's page based on a content-type ID and an"
    ],
    [
        "_(\"Content type %(ct_id)s object has no associated model\")",
        "_(\"Content type %(ct_id)s object"
    ],
    [
        "_(\"Content type %(ct_id)s object %(obj_id)s doesn’t exist\")",
        "_(\"Content type %(ct_id)s object %(obj_id)s"
    ],
    [
        "_(\"%(ct_name)s objects don’t have a get_absolute_url() method\")",
        "_(\"%(ct_name)s objects don’t have a get_absolute_url()"
    ],
    [
        "if field.remote_field and field.remote_field.model is Site:",
        "if field.remote_field and"
    ],
    [
        "return HttpResponseRedirect(\"%s://%s%s\" % (protocol, object_domain, absurl))",
        "return HttpResponseRedirect(\"%s://%s%s\" %"
    ],
    [
        "from django.apps import apps as global_apps",
        "from django.apps import apps as"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, IntegrityError, migrations, router, transaction",
        "from django.db import DEFAULT_DB_ALIAS,"
    ],
    [
        "def _rename(self, apps, schema_editor, old_model, new_model):",
        "def _rename(self, apps, schema_editor, old_model,"
    ],
    [
        "Insert a `RenameContentType` operation after every planned `RenameModel`",
        "Insert a `RenameContentType` operation after"
    ],
    [
        "for inserted, (index, operation) in enumerate(inserts):",
        "for inserted, (index, operation)"
    ],
    [
        "app_models = {model._meta.model_name: model for model in app_config.get_models()}",
        "app_models = {model._meta.model_name: model"
    ],
    [
        "Create content types for models in the given app.",
        "Create content types for models"
    ],
    [
        "print(\"Adding content type '%s | %s'\" % (ct.app_label, ct.model))",
        "print(\"Adding content type '%s |"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, connections, router",
        "from django.db import DEFAULT_DB_ALIAS,"
    ],
    [
        "help = \"Deletes stale content types in the database.\"",
        "help = \"Deletes stale content"
    ],
    [
        "help=\"Tells Django to NOT prompt the user for input of any kind.\",",
        "help=\"Tells Django to NOT prompt the user"
    ],
    [
        "help='Nominates the database to use. Defaults to the \"default\" database.',",
        "help='Nominates the database to use. Defaults to the \"default\""
    ],
    [
        "\"Deletes stale content types including ones from previously \"",
        "\"Deletes stale content types including ones from previously"
    ],
    [
        "\"installed apps that have been removed from INSTALLED_APPS.\"",
        "\"installed apps that have"
    ],
    [
        "if not include_stale_apps and app_label not in apps.app_configs:",
        "if not include_stale_apps and app_label"
    ],
    [
        "to_remove = [ct for ct in content_types if ct.model_class() is None]",
        "to_remove = [ct for ct in"
    ],
    [
        "\"    - Content type for %s.%s\" % (ct.app_label, ct.model)",
        "\" - Content type for %s.%s\" %"
    ],
    [
        "\"Some content types in your database are stale and can be \"",
        "\"Some content types in your database are stale"
    ],
    [
        "\"Any objects that depend on these content types will also be \"",
        "\"Any objects that depend on these content"
    ],
    [
        "\"The content types and dependent objects that would be deleted \"",
        "\"The content types and dependent objects that would"
    ],
    [
        "\"This list doesn't include any cascade deletions to data \"",
        "\"This list doesn't include any"
    ],
    [
        "\"Are you sure you want to delete these content types?\\n\"",
        "\"Are you sure you want to delete"
    ],
    [
        "ok_to_delete = input(\"Type 'yes' to continue, or 'no' to cancel: \")",
        "ok_to_delete = input(\"Type 'yes' to continue, or 'no' to"
    ],
    [
        "\"Deleting stale content type '%s | %s'\"",
        "\"Deleting stale content type '%s"
    ],
    [
        "Always load related objects to display them when showing confirmation.",
        "Always load related objects to display"
    ],
    [
        "Distance and Area objects to allow for sensible and convenient calculation",
        "Distance and Area objects to allow for sensible and convenient"
    ],
    [
        "Authors: Robert Coup, Justin Bronn, Riccardo Di Virgilio",
        "Authors: Robert Coup, Justin Bronn, Riccardo"
    ],
    [
        "and Geoff Biggs' PhD work on dimensioned units for robotics.",
        "and Geoff Biggs' PhD work"
    ],
    [
        "__all__ = [\"A\", \"Area\", \"D\", \"Distance\"]",
        "__all__ = [\"A\", \"Area\", \"D\","
    ],
    [
        "return obj.__name__ if obj.__class__ == type else obj.__class__.__name__",
        "return obj.__name__ if obj.__class__ == type else"
    ],
    [
        "raise AttributeError(\"Unknown unit type: %s\" % name)",
        "raise AttributeError(\"Unknown unit type: %s\" %"
    ],
    [
        "return \"%s %s\" % (getattr(self, self._default_unit), self._default_unit)",
        "return \"%s %s\" %"
    ],
    [
        "\"%(class)s must be added with %(class)s\" % {\"class\": pretty_name(self)}",
        "\"%(class)s must be added with"
    ],
    [
        "\"%(class)s must be added with %(class)s\" % {\"class\": pretty_name(self)}",
        "\"%(class)s must be added with %(class)s\""
    ],
    [
        "\"%(class)s must be subtracted from %(class)s\"",
        "\"%(class)s must be"
    ],
    [
        "\"%(class)s must be subtracted from %(class)s\"",
        "\"%(class)s must be subtracted"
    ],
    [
        "\"%(class)s must be multiplied with number\"",
        "\"%(class)s must be multiplied"
    ],
    [
        "\"%(class)s must be multiplied with number\"",
        "\"%(class)s must be multiplied with"
    ],
    [
        "\"%(class)s must be divided with number or %(class)s\"",
        "\"%(class)s must be divided"
    ],
    [
        "\"%(class)s must be divided with number\" % {\"class\": pretty_name(self)}",
        "\"%(class)s must be divided with"
    ],
    [
        "Return the unit value and the default units specified",
        "Return the unit value and the default"
    ],
    [
        "from the given keyword arguments dictionary.",
        "from the given"
    ],
    [
        "raise AttributeError(\"Unknown unit type: %s\" % unit)",
        "raise AttributeError(\"Unknown unit type: %s\""
    ],
    [
        "Retrieve the unit attribute name for the given unit string.",
        "Retrieve the unit attribute name"
    ],
    [
        "For example, if the given unit string is 'metre', return 'm'.",
        "For example, if the given unit string is 'metre', return"
    ],
    [
        "Raise an AttributeError if an attribute cannot be found.",
        "Raise an AttributeError if an attribute"
    ],
    [
        "LALIAS = {k.lower(): v for k, v in ALIAS.items()}",
        "LALIAS = {k.lower(): v for k, v"
    ],
    [
        "**{AREA_PREFIX + self.STANDARD_UNIT: (self.standard * other.standard)},",
        "**{AREA_PREFIX + self.STANDARD_UNIT:"
    ],
    [
        "\"%(distance)s must be multiplied with number or %(distance)s\"",
        "\"%(distance)s must be multiplied with"
    ],
    [
        "ALIAS = {k: \"%s%s\" % (AREA_PREFIX, v) for k, v in Distance.ALIAS.items()} | {",
        "ALIAS = {k: \"%s%s\" % (AREA_PREFIX, v)"
    ],
    [
        "LALIAS = {k.lower(): v for k, v in ALIAS.items()}",
        "LALIAS = {k.lower(): v for k,"
    ],
    [
        "\"%(class)s must be divided by a number\" % {\"class\": pretty_name(self)}",
        "\"%(class)s must be divided by a number\" %"
    ],
    [
        "GeoIP(R) is a registered trademark of MaxMind, Inc.",
        "GeoIP(R) is a registered trademark of"
    ],
    [
        "datasets, in binary format (CSV will not work!). The datasets may be",
        "datasets, in binary format (CSV will not work!). The datasets may"
    ],
    [
        "Initialize the GeoIP object. No parameters are required to use default",
        "Initialize the GeoIP object. No parameters are required to"
    ],
    [
        "settings. Keyword arguments may be passed in to customize the locations",
        "settings. Keyword arguments may be passed"
    ],
    [
        "* path: Base directory to where GeoIP data is located or the full path",
        "* path: Base directory to where GeoIP data"
    ],
    [
        "to where the city or country data files (*.mmdb) are located.",
        "to where the city or country data files (*.mmdb)"
    ],
    [
        "Assumes that both the city and country data sets are located in",
        "Assumes that both the city and country data sets are"
    ],
    [
        "this directory; overrides the GEOIP_PATH setting.",
        "this directory; overrides the"
    ],
    [
        "* cache: The cache settings when opening up the GeoIP datasets. May be",
        "* cache: The cache settings when opening up the GeoIP datasets. May"
    ],
    [
        "* country: The name of the GeoIP country data file. Defaults to",
        "* country: The name of the"
    ],
    [
        "* city: The name of the GeoIP city data file. Defaults to",
        "* city: The name of the GeoIP city"
    ],
    [
        "path = path or getattr(settings, \"GEOIP_PATH\", None)",
        "path = path or"
    ],
    [
        "\"GeoIP path must be provided via parameter or the GEOIP_PATH setting.\"",
        "\"GeoIP path must be provided via parameter or the GEOIP_PATH"
    ],
    [
        "for path in (path, path / city, path / country):",
        "for path in (path, path /"
    ],
    [
        "\"Path must be a valid database or directory containing databases.\"",
        "\"Path must be a valid database or"
    ],
    [
        "function = self._reader.city if self.is_city else self._reader.country",
        "function = self._reader.city if"
    ],
    [
        "Return a dictionary of city information for the given IP address or",
        "Return a dictionary of city information for the given"
    ],
    [
        "Fully Qualified Domain Name (FQDN). Some information in the dictionary",
        "Fully Qualified Domain Name (FQDN). Some"
    ],
    [
        "\"region_code\": region.iso_code if region else None,",
        "\"region_code\": region.iso_code if region"
    ],
    [
        "\"region_name\": region.name if region else None,",
        "\"region_name\": region.name if region"
    ],
    [
        "\"region\": region.iso_code if region else None,",
        "\"region\": region.iso_code if region"
    ],
    [
        "\"Return the country code for the given IP Address or FQDN.\"",
        "\"Return the country code for the given IP Address"
    ],
    [
        "\"Return the country name for the given IP Address or FQDN.\"",
        "\"Return the country name for the given IP Address"
    ],
    [
        "Return a dictionary with the country code and name when given an",
        "Return a dictionary with the country"
    ],
    [
        "IP address or a Fully Qualified Domain Name (FQDN). For example, both",
        "IP address or a Fully Qualified Domain"
    ],
    [
        "\"Return a tuple of the (longitude, latitude) for the given query.\"",
        "\"Return a tuple of the (longitude, latitude)"
    ],
    [
        "\"Return a tuple of the (latitude, longitude) for the given query.\"",
        "\"Return a tuple of the (latitude, longitude) for the given"
    ],
    [
        "\"Return a GEOS Point object for the given query.\"",
        "\"Return a GEOS Point object for the given"
    ],
    [
        "\"Return compressed KMZ from the given KML string.\"",
        "\"Return compressed KMZ from the given KML"
    ],
    [
        "with zipfile.ZipFile(kmz, \"a\", zipfile.ZIP_DEFLATED) as zf:",
        "with zipfile.ZipFile(kmz, \"a\","
    ],
    [
        "\"Render the response as KML (using the correct MIME type).\"",
        "\"Render the response as KML"
    ],
    [
        "Compress the KML content and return as KMZ (using the correct",
        "Compress the KML content and return"
    ],
    [
        "from django.contrib.syndication.views import Feed as BaseFeed",
        "from django.contrib.syndication.views import Feed as"
    ],
    [
        "This mixin provides the necessary routines for SyndicationFeed subclasses",
        "This mixin provides the necessary routines"
    ],
    [
        "In GeoRSS coordinate pairs are ordered by lat/lon and separated by",
        "In GeoRSS coordinate pairs are ordered"
    ],
    [
        "a single white space. Given a tuple of coordinates, return a string",
        "a single white space. Given a tuple of coordinates,"
    ],
    [
        "Adds a GeoRSS point with the given coords using the given handler.",
        "Adds a GeoRSS point with the given coords using"
    ],
    [
        "Handles the differences between simple GeoRSS and the more popular",
        "Handles the differences between simple GeoRSS"
    ],
    [
        "\"\"\"Add a GeoRSS XML element using the given item and handler.\"\"\"",
        "\"\"\"Add a GeoRSS XML element using the given"
    ],
    [
        "raise ValueError(\"Only should be two sets of coordinates.\")",
        "raise ValueError(\"Only should be two"
    ],
    [
        "'Geometry type \"%s\" not supported.' % geom.geom_type",
        "'Geometry type \"%s\" not"
    ],
    [
        "This is a subclass of the `Feed` from `django.contrib.syndication`.",
        "This is a subclass of the"
    ],
    [
        "This allows users to define a `geometry(obj)` and/or `item_geometry(item)`",
        "This allows users to define a `geometry(obj)` and/or"
    ],
    [
        "methods on their own subclasses so that geo-referenced information may",
        "methods on their own subclasses so that geo-referenced information"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "Base class for objects that have a pointer access property",
        "Base class for objects that have a"
    ],
    [
        "that controls access to the underlying C pointer.",
        "that controls access to the"
    ],
    [
        "\"NULL %s pointer encountered.\" % self.__class__.__name__",
        "\"NULL %s pointer"
    ],
    [
        "if not (ptr is None or isinstance(ptr, self.ptr_type)):",
        "if not (ptr is None or"
    ],
    [
        "raise TypeError(\"Incompatible pointer type: %s.\" % type(ptr))",
        "raise TypeError(\"Incompatible pointer type: %s.\""
    ],
    [
        "Free the memory used by the C++ object.",
        "Free the memory used by the"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "instance.feed_url = getattr(f, \"feed_url\", None) or request.path",
        "instance.feed_url = getattr(f, \"feed_url\", None)"
    ],
    [
        "instance.title_template = f.title_template or (\"feeds/%s_title.html\" % slug)",
        "instance.title_template = f.title_template or (\"feeds/%s_title.html\""
    ],
    [
        "This module contains a base type which provides list-style mutations",
        "This module contains a base type"
    ],
    [
        "A base class which provides complete list interface.",
        "A base class which provides complete list"
    ],
    [
        "Derived classes must call ListMixin's __init__() function",
        "Derived classes must call ListMixin's"
    ],
    [
        "Return single item with index i for general use.",
        "Return single item with index i for general"
    ],
    [
        "Same as above, but for use within the class [Optional]",
        "Same as above, but for use within the class"
    ],
    [
        "Note that if _get_single_internal and _get_single_internal return",
        "Note that if _get_single_internal and"
    ],
    [
        "different types of objects, _set_list must distinguish",
        "different types of objects,"
    ],
    [
        "between the two and handle each appropriately.",
        "between the two and handle each"
    ],
    [
        "NOTE: items may be a generator which calls _get_single_internal.",
        "NOTE: items may be a"
    ],
    [
        "Therefore, it is necessary to cache the values in a temporary:",
        "Therefore, it is necessary to cache the values"
    ],
    [
        "Set the single item at index i to value [Optional]",
        "Set the single item at"
    ],
    [
        "If left undefined, all mutations will result in rebuilding",
        "If left undefined, all mutations will result"
    ],
    [
        "A type or tuple of allowed item types [Optional]",
        "A type or tuple of"
    ],
    [
        "\"Get the item(s) at the specified index/slice.\"",
        "\"Get the item(s) at"
    ],
    [
        "\"Delete the item(s) at the specified index/slice.\"",
        "\"Delete the item(s) at"
    ],
    [
        "raise TypeError(\"%s is not a legal index\" % index)",
        "raise TypeError(\"%s is not a legal index\" %"
    ],
    [
        "self._get_single_internal(i) for i in range(origLen) if i not in indexRange",
        "self._get_single_internal(i) for i in range(origLen)"
    ],
    [
        "\"Set the item(s) at the specified index/slice.\"",
        "\"Set the item(s) at the specified"
    ],
    [
        "\"add another list-like object to self\"",
        "\"add another list-like object"
    ],
    [
        "raise ValueError(\"%s not found in object\" % val)",
        "raise ValueError(\"%s not found"
    ],
    [
        "raise TypeError(\"%s is not a legal index\" % index)",
        "raise TypeError(\"%s is not a"
    ],
    [
        "if newLen and newLen < self._minlength:",
        "if newLen and newLen <"
    ],
    [
        "raise ValueError(\"Must have at least %d items\" % self._minlength)",
        "raise ValueError(\"Must have at least %d items\""
    ],
    [
        "if self._maxlength is not None and newLen > self._maxlength:",
        "if self._maxlength is not None and"
    ],
    [
        "raise ValueError(\"Cannot have more than %d items\" % self._maxlength)",
        "raise ValueError(\"Cannot have more than %d items\" %"
    ],
    [
        "raise IndexError(\"invalid index: %s\" % index)",
        "raise IndexError(\"invalid index:"
    ],
    [
        "if False in [isinstance(val, self._allowed) for val in items]:",
        "if False in [isinstance(val, self._allowed) for val"
    ],
    [
        "raise TypeError(\"Invalid type encountered in the arguments.\")",
        "raise TypeError(\"Invalid type encountered"
    ],
    [
        "\"Assign values to a slice of the object\"",
        "\"Assign values to a slice of the"
    ],
    [
        "raise TypeError(\"can only assign an iterable to a slice\")",
        "raise TypeError(\"can only assign an iterable"
    ],
    [
        "def _assign_extended_slice_rebuild(self, start, stop, step, valueList):",
        "def _assign_extended_slice_rebuild(self, start, stop,"
    ],
    [
        "\"Assign an extended slice by rebuilding entire list\"",
        "\"Assign an extended slice by"
    ],
    [
        "\"attempt to assign sequence of size %d \"",
        "\"attempt to assign sequence"
    ],
    [
        "\"to extended slice of size %d\" % (len(valueList), len(indexList))",
        "\"to extended slice of size %d\" % (len(valueList),"
    ],
    [
        "def _assign_extended_slice(self, start, stop, step, valueList):",
        "def _assign_extended_slice(self, start, stop,"
    ],
    [
        "\"Assign an extended slice by re-assigning individual items\"",
        "\"Assign an extended slice by"
    ],
    [
        "\"attempt to assign sequence of size %d \"",
        "\"attempt to assign sequence of size"
    ],
    [
        "\"to extended slice of size %d\" % (len(valueList), len(indexList))",
        "\"to extended slice of size %d\" %"
    ],
    [
        "for i, val in zip(indexList, valueList):",
        "for i, val in zip(indexList,"
    ],
    [
        "\"Assign a simple slice; Can assign slice of any length\"",
        "\"Assign a simple slice; Can assign slice"
    ],
    [
        "newLen = origLen - stop + start + len(valueList)",
        "newLen = origLen - stop"
    ],
    [
        "if i < start or i >= stop:",
        "if i < start or"
    ],
    [
        "\"The base GEOS exception, indicates a GEOS-related error.\"",
        "\"The base GEOS exception, indicates"
    ],
    [
        "from .prototypes import prepared as capi",
        "from .prototypes import prepared"
    ],
    [
        "A geometry that is prepared for performing certain operations.",
        "A geometry that is prepared for"
    ],
    [
        "At the moment this includes the contains covers, and intersects",
        "At the moment this includes the contains covers,"
    ],
    [
        "from django.contrib.gis.geos import prototypes as capi",
        "from django.contrib.gis.geos import"
    ],
    [
        "Initialize on an exterior ring and a sequence of holes (both",
        "Initialize on an exterior ring and a sequence of"
    ],
    [
        "instances may be either LinearRing instances, or a tuple/list",
        "instances may be either LinearRing instances, or a"
    ],
    [
        "that may be constructed into a LinearRing).",
        "that may be constructed into a"
    ],
    [
        ">>> from django.contrib.gis.geos import LinearRing, Polygon",
        ">>> from django.contrib.gis.geos"
    ],
    [
        "\"Iterate over each ring in the polygon.\"",
        "\"Iterate over each ring in"
    ],
    [
        "\"Return the number of rings in this Polygon.\"",
        "\"Return the number of rings in"
    ],
    [
        "\"POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))\"",
        "\"POLYGON((%s %s, %s %s, %s %s, %s %s, %s"
    ],
    [
        "holes_param = (GEOM_PTR * n_holes)(*[self._clone(r) for r in rings])",
        "holes_param = (GEOM_PTR * n_holes)(*[self._clone(r) for r in"
    ],
    [
        "\"Parameter must be a sequence of LinearRings or objects that can \"",
        "\"Parameter must be a sequence of LinearRings or objects that"
    ],
    [
        "\"Try to construct a ring from the given parameter.\"",
        "\"Try to construct a ring from"
    ],
    [
        "return the first and second interior ring, respectively).",
        "return the first and"
    ],
    [
        "CAREFUL: Internal/External are not the same as Interior/Exterior!",
        "CAREFUL: Internal/External are not the same"
    ],
    [
        "Return a pointer from the existing geometries for use internally by the",
        "Return a pointer from the existing geometries for use internally by"
    ],
    [
        "object's methods. _get_single_external() returns a clone of the same",
        "object's methods. _get_single_external() returns a clone"
    ],
    [
        "geometry for use by external code.",
        "geometry for use"
    ],
    [
        "\"Return the number of interior rings.\"",
        "\"Return the number of interior"
    ],
    [
        "\"Get the exterior ring of the Polygon.\"",
        "\"Get the exterior ring of the"
    ],
    [
        "\"Set the exterior ring of the Polygon.\"",
        "\"Set the exterior ring of"
    ],
    [
        "\"Get the tuple for each ring in this Polygon.\"",
        "\"Get the tuple for each ring"
    ],
    [
        "return tuple(self[i].tuple for i in range(len(self)))",
        "return tuple(self[i].tuple for"
    ],
    [
        "\"Return the KML representation of this Polygon.\"",
        "\"Return the KML representation"
    ],
    [
        "Module that holds classes for performing I/O operations on GEOS geometry",
        "Module that holds classes for performing I/O operations on"
    ],
    [
        "objects.  Specifically, this has Python implementations of WKB/WKT",
        "objects. Specifically, this has"
    ],
    [
        "__all__ = [\"WKBWriter\", \"WKTWriter\", \"WKBReader\", \"WKTReader\"]",
        "__all__ = [\"WKBWriter\","
    ],
    [
        "\"Return a GEOSGeometry for the given WKB buffer.\"",
        "\"Return a GEOSGeometry for"
    ],
    [
        "\"Return a GEOSGeometry for the given WKT string.\"",
        "\"Return a GEOSGeometry for the given WKT"
    ],
    [
        "from django.contrib.gis.geos import prototypes as capi",
        "from django.contrib.gis.geos import"
    ],
    [
        "Initialize on the given sequence -- may take lists, tuples, NumPy arrays",
        "Initialize on the given sequence --"
    ],
    [
        "of X,Y pairs, or Point objects.  If Point objects are used, ownership is",
        "of X,Y pairs, or Point objects. If Point objects are used,"
    ],
    [
        "_not_ transferred to the LineString object.",
        "_not_ transferred to the"
    ],
    [
        "raise TypeError(\"Invalid initialization input for LineStrings.\")",
        "raise TypeError(\"Invalid initialization input"
    ],
    [
        "\"%s requires at least %d points, got %s.\"",
        "\"%s requires at least %d points,"
    ],
    [
        "numpy_coords = not isinstance(coords, (tuple, list))",
        "numpy_coords = not isinstance(coords, (tuple,"
    ],
    [
        "if not isinstance(coord, (tuple, list, Point)):",
        "if not isinstance(coord, (tuple,"
    ],
    [
        "\"Each coordinate should be a sequence (list or tuple)\"",
        "\"Each coordinate should be a sequence"
    ],
    [
        "\"Return the number of points in this LineString.\"",
        "\"Return the number of points in this"
    ],
    [
        "raise GEOSException(\"Geometry resulting from slice deletion was invalid.\")",
        "raise GEOSException(\"Geometry resulting from"
    ],
    [
        "\"Return a tuple version of the geometry from the coordinate sequence.\"",
        "\"Return a tuple version of the geometry from the coordinate"
    ],
    [
        "Return a sequence (list) corresponding with the given function.",
        "Return a sequence (list) corresponding with the given"
    ],
    [
        "Return a numpy array if possible.",
        "Return a numpy"
    ],
    [
        "lst = [func(i) for i in range(len(self))]",
        "lst = [func(i) for"
    ],
    [
        "\"Return a numpy array for the LineString.\"",
        "\"Return a numpy array for the"
    ],
    [
        "\"Return a list or numpy array of the X variable.\"",
        "\"Return a list or numpy array of the X"
    ],
    [
        "\"Return a list or numpy array of the Y variable.\"",
        "\"Return a list or numpy"
    ],
    [
        "\"Return a list or numpy array of the Z variable.\"",
        "\"Return a list or numpy array"
    ],
    [
        "raise ValueError(\"Orientation of an empty LinearRing cannot be determined.\")",
        "raise ValueError(\"Orientation of an empty LinearRing cannot"
    ],
    [
        "The GeoDjango GEOS module.  Please consult the GeoDjango documentation",
        "The GeoDjango GEOS module. Please"
    ],
    [
        "from django.contrib.gis.geos.geometry import GEOSGeometry, hex_regex, wkt_regex",
        "from django.contrib.gis.geos.geometry import GEOSGeometry,"
    ],
    [
        "Given a string file name, returns a GEOSGeometry. The file may contain WKB,",
        "Given a string file name, returns a GEOSGeometry. The file may contain"
    ],
    [
        "\"Given a string value, return a GEOSGeometry object.\"",
        "\"Given a string value,"
    ],
    [
        "This module houses the GEOSCoordSeq object, which is used internally",
        "This module houses the GEOSCoordSeq object, which is"
    ],
    [
        "by GEOSGeometry to house the actual coordinates of the Point,",
        "by GEOSGeometry to house the actual coordinates of the"
    ],
    [
        "from ctypes import byref, c_byte, c_double, c_uint",
        "from ctypes import byref, c_byte,"
    ],
    [
        "from django.contrib.gis.geos import prototypes as capi",
        "from django.contrib.gis.geos import prototypes as"
    ],
    [
        "\"The internal representation of a list of coordinates inside a Geometry.\"",
        "\"The internal representation of a list of"
    ],
    [
        "raise TypeError(\"Coordinate sequence should initialize with a CS_PTR.\")",
        "raise TypeError(\"Coordinate sequence should initialize"
    ],
    [
        "\"Iterate over each point in the coordinate sequence.\"",
        "\"Iterate over each point"
    ],
    [
        "\"Return the number of points in the coordinate sequence.\"",
        "\"Return the number of points in"
    ],
    [
        "\"Return the string representation of the coordinate sequence.\"",
        "\"Return the string representation of"
    ],
    [
        "\"Return the coordinate sequence value at the given index.\"",
        "\"Return the coordinate sequence value"
    ],
    [
        "\"Set the coordinate sequence value at the given index.\"",
        "\"Set the coordinate sequence value"
    ],
    [
        "\"Must set coordinate with a sequence (list, tuple, or numpy array).\"",
        "\"Must set coordinate with a sequence (list,"
    ],
    [
        "raise TypeError(\"Dimension of value does not match.\")",
        "raise TypeError(\"Dimension of value"
    ],
    [
        "raise IndexError(\"invalid GEOS Geometry index: %s\" % index)",
        "raise IndexError(\"invalid GEOS Geometry index: %s\""
    ],
    [
        "raise GEOSException('invalid ordinate dimension \"%d\"' % dim)",
        "raise GEOSException('invalid ordinate dimension \"%d\"'"
    ],
    [
        "\"Return the value for the given dimension and index.\"",
        "\"Return the value for the given"
    ],
    [
        "\"Set the value for the given dimension and index.\"",
        "\"Set the value for the given dimension and"
    ],
    [
        "\"Get the X value at the index.\"",
        "\"Get the X value at"
    ],
    [
        "\"Set X with the value at the given index.\"",
        "\"Set X with the value at the"
    ],
    [
        "\"Get the Y value at the given index.\"",
        "\"Get the Y value at the"
    ],
    [
        "\"Set Y with the value at the given index.\"",
        "\"Set Y with the value at the given"
    ],
    [
        "\"Get Z with the value at the given index.\"",
        "\"Get Z with the value at"
    ],
    [
        "\"Set Z with the value at the given index.\"",
        "\"Set Z with the value at the given"
    ],
    [
        "\"Return the size of this coordinate sequence.\"",
        "\"Return the size of this"
    ],
    [
        "\"Return the dimensions of this coordinate sequence.\"",
        "\"Return the dimensions of this"
    ],
    [
        "\"Return the KML representation for the coordinates.\"",
        "\"Return the KML representation for"
    ],
    [
        "% \"\".join(substr % self[i] for i in range(len(self))).strip()",
        "% \"\".join(substr % self[i] for"
    ],
    [
        "\"Return a tuple version of this coordinate sequence.\"",
        "\"Return a tuple version"
    ],
    [
        "return tuple(get_point(i) for i in range(n))",
        "return tuple(get_point(i) for i"
    ],
    [
        "\"\"\"Return whether this coordinate sequence is counterclockwise.\"\"\"",
        "\"\"\"Return whether this coordinate sequence is"
    ],
    [
        "'Error encountered in GEOS C function \"%s\".' % capi.cs_is_ccw.func_name",
        "'Error encountered in GEOS C function \"%s\".' %"
    ],
    [
        "from django.contrib.gis.geos import prototypes as capi",
        "from django.contrib.gis.geos import"
    ],
    [
        "def __init__(self, x=None, y=None, z=None, srid=None):",
        "def __init__(self, x=None, y=None, z=None,"
    ],
    [
        "The Point object may be initialized with either a tuple, or individual",
        "The Point object may be initialized with either a tuple,"
    ],
    [
        "elif isinstance(x, (float, int)) and isinstance(y, (float, int)):",
        "elif isinstance(x, (float, int)) and"
    ],
    [
        "raise TypeError(\"Invalid parameters given for Point initialization.\")",
        "raise TypeError(\"Invalid parameters given"
    ],
    [
        "return None if self.empty else super()._to_pickle_wkb()",
        "return None if self.empty else"
    ],
    [
        "return self._create_empty() if wkb is None else super()._from_pickle_wkb(wkb)",
        "return self._create_empty() if wkb is None else"
    ],
    [
        "Create a coordinate sequence, set X, Y, [Z], and create point",
        "Create a coordinate sequence, set X, Y, [Z], and"
    ],
    [
        "raise TypeError(\"Invalid point dimension: %s\" % ndim)",
        "raise TypeError(\"Invalid point dimension: %s\" %"
    ],
    [
        "raise GEOSException(\"Geometry resulting from slice deletion was invalid.\")",
        "raise GEOSException(\"Geometry resulting from"
    ],
    [
        "\"Iterate over coordinates of this Point.\"",
        "\"Iterate over coordinates of this"
    ],
    [
        "\"Return the X component of the Point.\"",
        "\"Return the X component"
    ],
    [
        "\"Set the X component of the Point.\"",
        "\"Set the X component of the"
    ],
    [
        "\"Return the Y component of the Point.\"",
        "\"Return the Y component of"
    ],
    [
        "\"Set the Y component of the Point.\"",
        "\"Set the Y component of"
    ],
    [
        "\"Return the Z component of the Point.\"",
        "\"Return the Z component of"
    ],
    [
        "\"Set the Z component of the Point.\"",
        "\"Set the Z component of"
    ],
    [
        "\"Return a tuple of the point.\"",
        "\"Return a tuple of"
    ],
    [
        "\"Set the coordinates of the point with the given tuple.\"",
        "\"Set the coordinates of the point with"
    ],
    [
        "This module houses the Geometry Collection objects:",
        "This module houses the Geometry Collection"
    ],
    [
        "from django.contrib.gis.geos import prototypes as capi",
        "from django.contrib.gis.geos import"
    ],
    [
        "\"Initialize a Geometry Collection from a sequence of Geometry objects.\"",
        "\"Initialize a Geometry Collection from a sequence of"
    ],
    [
        "\"Iterate over each Geometry in the Collection.\"",
        "\"Iterate over each Geometry"
    ],
    [
        "\"Return the number of geometries in this Collection.\"",
        "\"Return the number of geometries in this"
    ],
    [
        "\"Create a new collection, and destroy the contents of the previous pointer.\"",
        "\"Create a new collection, and destroy the contents of"
    ],
    [
        "\"Return the KML for this Geometry Collection.\"",
        "\"Return the KML for"
    ],
    [
        "return \"<MultiGeometry>%s</MultiGeometry>\" % \"\".join(g.kml for g in self)",
        "return \"<MultiGeometry>%s</MultiGeometry>\" % \"\".join(g.kml for g in"
    ],
    [
        "\"Return a tuple of all the coordinates in this Geometry Collection\"",
        "\"Return a tuple of all the coordinates in this"
    ],
    [
        "return tuple(g.tuple for g in self)",
        "return tuple(g.tuple for"
    ],
    [
        "This module contains the 'base' GEOSGeometry object -- all GEOS Geometries",
        "This module contains the 'base' GEOSGeometry object"
    ],
    [
        "from ctypes import addressof, byref, c_double",
        "from ctypes import addressof, byref,"
    ],
    [
        "from django.contrib.gis.geometry import hex_regex, json_regex, wkt_regex",
        "from django.contrib.gis.geometry import hex_regex, json_regex,"
    ],
    [
        "from django.contrib.gis.geos import prototypes as capi",
        "from django.contrib.gis.geos import prototypes as"
    ],
    [
        "from django.contrib.gis.geos.prototypes.io import ewkb_w, wkb_r, wkb_w, wkt_r, wkt_w",
        "from django.contrib.gis.geos.prototypes.io import ewkb_w, wkb_r,"
    ],
    [
        "GEOSCoordSeq(capi.get_cs(self.ptr), self.hasz) if self.has_cs else None",
        "GEOSCoordSeq(capi.get_cs(self.ptr), self.hasz) if self.has_cs else"
    ],
    [
        "Return a clone because the copy of a GEOSGeometry may contain an",
        "Return a clone because the copy of a GEOSGeometry may contain"
    ],
    [
        "invalid pointer location if the original is garbage collected.",
        "invalid pointer location if the original is"
    ],
    [
        "The `deepcopy` routine is used by the `Node` class of django.utils.tree;",
        "The `deepcopy` routine is used by the `Node`"
    ],
    [
        "thus, the protocol routine needs to be implemented to return correct",
        "thus, the protocol routine needs to be implemented to return"
    ],
    [
        "copies (clones) of these GEOS objects, which use C pointers.",
        "copies (clones) of these GEOS objects,"
    ],
    [
        "\"EWKT is used for the string representation.\"",
        "\"EWKT is used for"
    ],
    [
        "\"Short-hand representation because WKT may be very large.\"",
        "\"Short-hand representation because WKT may be"
    ],
    [
        "return \"<%s object at %s>\" % (self.geom_type, hex(addressof(self.ptr)))",
        "return \"<%s object at"
    ],
    [
        "raise GEOSException(\"Invalid Geometry loaded from pickled state.\")",
        "raise GEOSException(\"Invalid Geometry loaded from pickled"
    ],
    [
        "raise ValueError(\"EWKT has invalid SRID part.\")",
        "raise ValueError(\"EWKT has invalid SRID"
    ],
    [
        "raise ValueError(\"Expected WKT but got an empty string.\")",
        "raise ValueError(\"Expected WKT but got an"
    ],
    [
        "Equivalence testing, a Geometry may be compared with another Geometry",
        "Equivalence testing, a Geometry may"
    ],
    [
        "\"Return the union of this Geometry and the other.\"",
        "\"Return the union of this"
    ],
    [
        "\"Return the intersection of this Geometry and the other.\"",
        "\"Return the intersection of this Geometry and"
    ],
    [
        "\"Return the difference this Geometry and the other.\"",
        "\"Return the difference this Geometry and"
    ],
    [
        "\"Return the symmetric difference of this Geometry and the other.\"",
        "\"Return the symmetric difference of this"
    ],
    [
        "\"Return a clone of the coordinate sequence for this Geometry.\"",
        "\"Return a clone of the coordinate"
    ],
    [
        "\"Return a string representing the Geometry type, e.g. 'Polygon'\"",
        "\"Return a string representing the"
    ],
    [
        "\"Return an integer representing the Geometry type.\"",
        "\"Return an integer representing the"
    ],
    [
        "\"Return the number of geometries in the Geometry.\"",
        "\"Return the number of"
    ],
    [
        "\"Return the number of coordinates in the Geometry.\"",
        "\"Return the number of"
    ],
    [
        "\"Return the number points, or coordinates, in the Geometry.\"",
        "\"Return the number points, or coordinates,"
    ],
    [
        "Convert this Geometry to normal form (or canonical form).",
        "Convert this Geometry to normal form (or canonical"
    ],
    [
        "If the `clone` keyword is set, then the geometry is not modified and a",
        "If the `clone` keyword is set, then the"
    ],
    [
        "normalized clone of the geometry is returned instead.",
        "normalized clone of the geometry is"
    ],
    [
        "Attempt to create a valid representation of a given invalid geometry",
        "Attempt to create a valid representation of a given invalid"
    ],
    [
        "without losing any of the input vertices.",
        "without losing any of the"
    ],
    [
        "Return a boolean indicating whether the set of points in this Geometry",
        "Return a boolean indicating whether the set of points in"
    ],
    [
        "\"Return whether the geometry has a Z dimension.\"",
        "\"Return whether the geometry has a Z"
    ],
    [
        "\"Return whether the geometry has a M dimension.\"",
        "\"Return whether the geometry has a M"
    ],
    [
        "\"Return whether or not the geometry is a ring.\"",
        "\"Return whether or not the"
    ],
    [
        "\"Return false if the Geometry isn't simple.\"",
        "\"Return false if the"
    ],
    [
        "\"Test the validity of this Geometry.\"",
        "\"Test the validity"
    ],
    [
        "Return a string containing the reason for any invalidity.",
        "Return a string containing the"
    ],
    [
        "\"Return true if other.within(this) returns true.\"",
        "\"Return true if other.within(this)"
    ],
    [
        "T*****FF*, *T****FF*, ***T**FF*, or ****T*FF*. If either geometry is",
        "T*****FF*, *T****FF*, ***T**FF*, or ****T*FF*. If either geometry"
    ],
    [
        "is T*T****** (for a point and a curve,a point and an area or a line and",
        "is T*T****** (for a point and a curve,a point"
    ],
    [
        "Return true if the two Geometries are exactly equal, up to a",
        "Return true if the two Geometries are exactly equal, up to"
    ],
    [
        "Return true if the two Geometries are point-wise equivalent.",
        "Return true if the two Geometries are point-wise"
    ],
    [
        "\"Return true if disjoint return false.\"",
        "\"Return true if"
    ],
    [
        "two Geometries match the elements in pattern.",
        "two Geometries match the elements"
    ],
    [
        "\"Get the SRID for the geometry. Return None if no SRID is set.\"",
        "\"Get the SRID for the geometry. Return None"
    ],
    [
        "\"Set the SRID for the geometry.\"",
        "\"Set the SRID for the"
    ],
    [
        "Return the EWKT (SRID + WKT) of the Geometry.",
        "Return the EWKT (SRID + WKT) of"
    ],
    [
        "return \"SRID=%s;%s\" % (srid, self.wkt) if srid else self.wkt",
        "return \"SRID=%s;%s\" % (srid, self.wkt) if"
    ],
    [
        "\"Return the WKT (Well-Known Text) representation of this Geometry.\"",
        "\"Return the WKT (Well-Known Text) representation of"
    ],
    [
        "Return the WKB of this Geometry in hexadecimal form. Please note",
        "Return the WKB of this Geometry"
    ],
    [
        "that the SRID is not included in this representation because it is not",
        "that the SRID is not included in this representation because it is"
    ],
    [
        "a part of the OGC specification (use the `hexewkb` property instead).",
        "a part of the OGC specification (use"
    ],
    [
        "Return the EWKB of this Geometry in hexadecimal form. This is an",
        "Return the EWKB of this Geometry"
    ],
    [
        "extension of the WKB specification that includes SRID value that are",
        "extension of the WKB specification that includes SRID value that"
    ],
    [
        "Return GeoJSON representation of this Geometry.",
        "Return GeoJSON representation of"
    ],
    [
        "Return the WKB (Well-Known Binary) representation of this Geometry",
        "Return the WKB (Well-Known Binary) representation of this"
    ],
    [
        "as a Python memoryview. SRID and Z values are not included, use the",
        "as a Python memoryview. SRID and Z values are not"
    ],
    [
        "Return the EWKB representation of this Geometry as a Python memoryview.",
        "Return the EWKB representation of this"
    ],
    [
        "This is an extension of the WKB specification that includes any SRID",
        "This is an extension of the WKB"
    ],
    [
        "value that are a part of this geometry.",
        "value that are a part"
    ],
    [
        "\"Return the KML representation of this Geometry.\"",
        "\"Return the KML representation of this"
    ],
    [
        "return \"<%s>%s</%s>\" % (gtype, self.coord_seq.kml, gtype)",
        "return \"<%s>%s</%s>\" %"
    ],
    [
        "Return a PreparedGeometry corresponding to this geometry -- it is",
        "Return a PreparedGeometry corresponding to"
    ],
    [
        "optimized for the contains, intersects, and covers operations.",
        "optimized for the contains,"
    ],
    [
        "\"Return the OGR Geometry for this Geometry.\"",
        "\"Return the OGR Geometry for"
    ],
    [
        "\"Return the OSR SpatialReference for SRID of this Geometry.\"",
        "\"Return the OSR SpatialReference for SRID"
    ],
    [
        "Requires GDAL. Transform the geometry according to the given",
        "Requires GDAL. Transform the geometry according"
    ],
    [
        "transformation object, which may be an integer SRID, and WKT or",
        "transformation object, which may be an integer SRID,"
    ],
    [
        "PROJ string. By default, transform the geometry in-place and return",
        "PROJ string. By default, transform the"
    ],
    [
        "nothing. However if the `clone` keyword is set, don't modify the",
        "nothing. However if the `clone` keyword"
    ],
    [
        "geometry and return a transformed clone instead.",
        "geometry and return a transformed"
    ],
    [
        "raise GEOSException(\"Calling transform() with no SRID set is not supported\")",
        "raise GEOSException(\"Calling transform() with no SRID set is"
    ],
    [
        "\"Return Geometry from the given pointer.\"",
        "\"Return Geometry from the given"
    ],
    [
        "\"Return the boundary as a newly allocated Geometry object.\"",
        "\"Return the boundary as a newly allocated"
    ],
    [
        "Return a geometry that represents all points whose distance from this",
        "Return a geometry that represents all points whose distance"
    ],
    [
        "Geometry is less than or equal to distance. Calculations are in the",
        "Geometry is less than or equal to distance. Calculations are"
    ],
    [
        "Spatial Reference System of this Geometry. The optional third parameter sets",
        "Spatial Reference System of this Geometry. The optional third parameter"
    ],
    [
        "Same as buffer() but allows customizing the style of the memoryview.",
        "Same as buffer() but allows customizing"
    ],
    [
        "Mitre ratio limit only affects mitered join style.",
        "Mitre ratio limit only affects mitered"
    ],
    [
        "self.ptr, width, quadsegs, end_cap_style, join_style, mitre_limit",
        "self.ptr, width, quadsegs,"
    ],
    [
        "The centroid is equal to the centroid of the set of component Geometries",
        "The centroid is equal to the centroid"
    ],
    [
        "of highest dimension (since the lower-dimension geometries contribute zero",
        "of highest dimension (since the"
    ],
    [
        "Return the smallest convex Polygon that contains all the points",
        "Return the smallest convex Polygon that contains all"
    ],
    [
        "Return a Geometry representing the points making up this Geometry",
        "Return a Geometry representing the points making up this"
    ],
    [
        "that do not make up other.",
        "that do not make"
    ],
    [
        "\"Return the envelope for this geometry (a polygon).\"",
        "\"Return the envelope for this"
    ],
    [
        "\"Return a Geometry representing the points shared by this Geometry and other.\"",
        "\"Return a Geometry representing the points shared by this Geometry"
    ],
    [
        "\"Compute an interior point of this Geometry.\"",
        "\"Compute an interior point of this"
    ],
    [
        "Return the Geometry, simplified using the Douglas-Peucker algorithm",
        "Return the Geometry, simplified using"
    ],
    [
        "to the specified tolerance (higher tolerance => less points).  If no",
        "to the specified tolerance (higher tolerance => less points). If"
    ],
    [
        "By default, don't preserve topology - e.g. polygons can be split,",
        "By default, don't preserve topology - e.g. polygons can"
    ],
    [
        "collapse to lines or disappear holes can be created or disappear, and",
        "collapse to lines or disappear holes"
    ],
    [
        "lines can cross. By specifying preserve_topology=True, the result will",
        "lines can cross. By specifying preserve_topology=True, the result"
    ],
    [
        "have the same dimension and number of components as the input. This is",
        "have the same dimension and number of components as"
    ],
    [
        "Return a set combining the points in this Geometry not in other,",
        "Return a set combining the points in this"
    ],
    [
        "and the points in other not in this Geometry.",
        "and the points in other not in this"
    ],
    [
        "\"Return the union of all the elements of this geometry.\"",
        "\"Return the union of all the elements of this"
    ],
    [
        "\"Return a Geometry representing all the points in this Geometry and other.\"",
        "\"Return a Geometry representing all the points in this Geometry"
    ],
    [
        "\"Return the area of the Geometry.\"",
        "\"Return the area"
    ],
    [
        "Return the distance between the closest points on this Geometry",
        "Return the distance between the closest points"
    ],
    [
        "and the other. Units will be in those of the coordinate system of",
        "and the other. Units will be in those of"
    ],
    [
        "raise TypeError(\"distance() works only on other GEOS Geometries.\")",
        "raise TypeError(\"distance() works only on"
    ],
    [
        "raise TypeError(\"locate_point argument must be a Point\")",
        "raise TypeError(\"locate_point argument must"
    ],
    [
        "raise TypeError(\"locate_point argument must be a Point\")",
        "raise TypeError(\"locate_point argument must be a"
    ],
    [
        "Return the line merge of this Geometry.",
        "Return the line merge"
    ],
    [
        "Return whether or not this Geometry is closed.",
        "Return whether or not this Geometry is"
    ],
    [
        "\"A class that, generally, encapsulates a GEOS geometry.\"",
        "\"A class that, generally, encapsulates a GEOS"
    ],
    [
        "The base constructor for GEOS geometry objects. It may take the",
        "The base constructor for GEOS geometry objects. It may take"
    ],
    [
        "- HEXEWKB (a PostGIS-specific canonical form)",
        "- HEXEWKB (a PostGIS-specific"
    ],
    [
        "The `srid` keyword specifies the Source Reference Identifier (SRID)",
        "The `srid` keyword specifies the Source Reference"
    ],
    [
        "number for this Geometry. If not provided, it defaults to None.",
        "number for this Geometry. If not provided, it"
    ],
    [
        "raise ValueError(\"String input unrecognized as WKT EWKT, and HEXEWKB.\")",
        "raise ValueError(\"String input unrecognized as WKT"
    ],
    [
        "raise TypeError(\"Improper geometry input type: %s\" % type(geo_input))",
        "raise TypeError(\"Improper geometry input type: %s\""
    ],
    [
        "raise GEOSException(\"Could not initialize GEOS Geometry with given input.\")",
        "raise GEOSException(\"Could not initialize GEOS Geometry"
    ],
    [
        "input_srid = input_srid or capi.geos_get_srid(g) or None",
        "input_srid = input_srid or capi.geos_get_srid(g)"
    ],
    [
        "if input_srid and srid and input_srid != srid:",
        "if input_srid and srid and input_srid"
    ],
    [
        "raise ValueError(\"Input geometry already has SRID: %d.\" % input_srid)",
        "raise ValueError(\"Input geometry already has SRID: %d.\""
    ],
    [
        "This module houses the ctypes initialization procedures, as well",
        "This module houses the ctypes"
    ],
    [
        "as the notice and error handler function callbacks (get called",
        "as the notice and error handler function"
    ],
    [
        "when an error occurs in GEOS).",
        "when an error"
    ],
    [
        "This module also houses GEOS Pointer utilities, including",
        "This module also houses GEOS Pointer"
    ],
    [
        "from ctypes import CDLL, CFUNCTYPE, POINTER, Structure, c_char_p",
        "from ctypes import CDLL, CFUNCTYPE, POINTER, Structure,"
    ],
    [
        "raise ImportError('Unsupported OS \"%s\"' % os.name)",
        "raise ImportError('Unsupported OS"
    ],
    [
        "'Could not find the GEOS library (tried \"%s\"). '",
        "'Could not find the GEOS library"
    ],
    [
        "\"Try setting GEOS_LIBRARY_PATH in your settings.\" % '\", \"'.join(lib_names)",
        "\"Try setting GEOS_LIBRARY_PATH in your settings.\" %"
    ],
    [
        "def __init__(self, func_name, *, restype=None, errcheck=None, argtypes=None):",
        "def __init__(self, func_name, *, restype=None, errcheck=None,"
    ],
    [
        "\"\"\"Return the string version of the GEOS library.\"\"\"",
        "\"\"\"Return the string version of the"
    ],
    [
        "\"\"\"Return the GEOS version as a tuple (major, minor, subminor).\"\"\"",
        "\"\"\"Return the GEOS version as a tuple (major,"
    ],
    [
        "This module is for the miscellaneous GEOS routines, particularly the",
        "This module is for the"
    ],
    [
        "ones that return the area, distance, and length.",
        "ones that return the"
    ],
    [
        "from ctypes import POINTER, c_double, c_int",
        "from ctypes import"
    ],
    [
        "__all__ = [\"geos_area\", \"geos_distance\", \"geos_length\", \"geos_isvalidreason\"]",
        "__all__ = [\"geos_area\", \"geos_distance\", \"geos_length\","
    ],
    [
        "Argument is a Geometry, return type is double that is passed",
        "Argument is a Geometry, return type is double that is"
    ],
    [
        "in by reference as the last argument.",
        "in by reference as the last"
    ],
    [
        "This module houses the GEOS ctypes prototype functions for the",
        "This module houses the GEOS ctypes prototype functions for"
    ],
    [
        "unary and binary predicate operations on geometries.",
        "unary and binary predicate operations on"
    ],
    [
        "from ctypes import c_byte, c_char_p, c_double",
        "from ctypes import c_byte,"
    ],
    [
        "from django.contrib.gis.geos.libgeos import GEOM_PTR, PREPGEOM_PTR, GEOSFuncFactory",
        "from django.contrib.gis.geos.libgeos import"
    ],
    [
        "from ctypes import POINTER, c_char_p, c_int, c_ubyte, c_uint",
        "from ctypes import POINTER, c_char_p, c_int,"
    ],
    [
        "from django.contrib.gis.geos.libgeos import CS_PTR, GEOM_PTR, GEOSFuncFactory",
        "from django.contrib.gis.geos.libgeos import"
    ],
    [
        "\"For GEOS routines that return a geometry.\"",
        "\"For GEOS routines that return a"
    ],
    [
        "\"Argument is a geometry, return type is an integer.\"",
        "\"Argument is a geometry, return type is an"
    ],
    [
        "\"Argument is a Geometry, return type is a string.\"",
        "\"Argument is a Geometry, return"
    ],
    [
        "from ctypes import POINTER, Structure, byref, c_byte, c_char_p, c_int, c_size_t",
        "from ctypes import POINTER, Structure, byref, c_byte,"
    ],
    [
        "\"Base class for GEOS I/O objects.\"",
        "\"Base class for GEOS I/O"
    ],
    [
        "\"Return a _pointer_ to C GEOS Geometry object from the given WKB.\"",
        "\"Return a _pointer_ to C GEOS Geometry object"
    ],
    [
        "\"Return the WKT representation of the given geometry.\"",
        "\"Return the WKT representation"
    ],
    [
        "\"WKT output rounding precision must be non-negative integer or None.\"",
        "\"WKT output rounding precision must be"
    ],
    [
        "raise ValueError(\"Empty point is not representable in WKB.\")",
        "raise ValueError(\"Empty point is"
    ],
    [
        "\"Return the WKB representation of the given geometry.\"",
        "\"Return the WKB representation of the given"
    ],
    [
        "\"Return the HEXEWKB representation of the given geometry.\"",
        "\"Return the HEXEWKB representation of the"
    ],
    [
        "This module contains all of the GEOS ctypes function prototypes. Each",
        "This module contains all of the"
    ],
    [
        "prototype handles the interaction between the GEOS library and Python",
        "prototype handles the interaction between the"
    ],
    [
        "from ctypes import POINTER, c_byte, c_double, c_int, c_uint",
        "from ctypes import POINTER, c_byte, c_double,"
    ],
    [
        "from django.contrib.gis.geos.libgeos import CS_PTR, GEOM_PTR, GEOSFuncFactory",
        "from django.contrib.gis.geos.libgeos import"
    ],
    [
        "\"Check the status code of a coordinate sequence operation.\"",
        "\"Check the status code of a coordinate sequence"
    ],
    [
        "raise GEOSException(\"Could not set value on coordinate sequence\")",
        "raise GEOSException(\"Could not set value"
    ],
    [
        "\"For coordinate sequence routines that return an integer.\"",
        "\"For coordinate sequence routines"
    ],
    [
        "def __init__(self, *args, ordinate=False, get=False, **kwargs):",
        "def __init__(self, *args, ordinate=False,"
    ],
    [
        "argtypes = [CS_PTR, c_uint, c_uint, dbl_param]",
        "argtypes = [CS_PTR, c_uint,"
    ],
    [
        "*args, **{**kwargs, \"errcheck\": errcheck, \"argtypes\": argtypes}",
        "*args, **{**kwargs, \"errcheck\": errcheck, \"argtypes\":"
    ],
    [
        "\"Error encountered checking Coordinate Sequence returned from GEOS \"",
        "\"Error encountered checking Coordinate Sequence returned from GEOS"
    ],
    [
        "This module houses the GEOS ctypes prototype functions for the",
        "This module houses the GEOS ctypes prototype functions for"
    ],
    [
        "geos_buffer = Topology(\"GEOSBuffer\", argtypes=[GEOM_PTR, c_double, c_int])",
        "geos_buffer = Topology(\"GEOSBuffer\","
    ],
    [
        "\"GEOSBufferWithStyle\", argtypes=[GEOM_PTR, c_double, c_int, c_int, c_int, c_double]",
        "\"GEOSBufferWithStyle\", argtypes=[GEOM_PTR, c_double, c_int, c_int, c_int,"
    ],
    [
        "from django.contrib.gis.geos.libgeos import CONTEXT_PTR, error_h, lgeos, notice_h",
        "from django.contrib.gis.geos.libgeos import CONTEXT_PTR, error_h, lgeos,"
    ],
    [
        "Serve as a wrapper for GEOS C Functions. Use thread-safe function",
        "Serve as a wrapper for GEOS C Functions."
    ],
    [
        "self.cfunc = getattr(lgeos, func_name + \"_r\")",
        "self.cfunc = getattr(lgeos,"
    ],
    [
        "Error checking functions for GEOS ctypes prototype functions.",
        "Error checking functions for GEOS"
    ],
    [
        "\"Return the last C argument's value by reference.\"",
        "\"Return the last C argument's value by"
    ],
    [
        "\"Check the status code and returns the double value passed in by reference.\"",
        "\"Check the status code and returns the double value"
    ],
    [
        "\"Error checking on routines that return Geometries.\"",
        "\"Error checking on routines that return"
    ],
    [
        "'Error encountered checking Geometry returned from GEOS C function \"%s\".'",
        "'Error encountered checking Geometry returned from GEOS"
    ],
    [
        "'Error encountered in GEOS C function \"%s\".' % func.__name__",
        "'Error encountered in GEOS C function"
    ],
    [
        "\"Error checking for unary/binary predicate functions.\"",
        "\"Error checking for unary/binary"
    ],
    [
        "'Error encountered on GEOS C predicate function \"%s\".' % func.__name__",
        "'Error encountered on GEOS C"
    ],
    [
        "Error checking for routines that return explicitly sized strings.",
        "Error checking for routines that return"
    ],
    [
        "This frees the memory allocated by GEOS at the result pointer.",
        "This frees the memory allocated by GEOS at the result"
    ],
    [
        "'Invalid string pointer returned by GEOS C function \"%s\"' % func.__name__",
        "'Invalid string pointer returned by GEOS C function \"%s\"' %"
    ],
    [
        "Error checking for routines that return strings.",
        "Error checking for routines that return"
    ],
    [
        "This frees the memory allocated by GEOS at the result pointer.",
        "This frees the memory allocated by GEOS at"
    ],
    [
        "'Error encountered checking string return value in GEOS C function \"%s\".'",
        "'Error encountered checking string return value in GEOS"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "This is the basic form field for a Geometry.  Any textual input that is",
        "This is the basic form field for a Geometry."
    ],
    [
        "accepted by GEOSGeometry is accepted by this form.  By default,",
        "accepted by GEOSGeometry is accepted"
    ],
    [
        "this includes WKT, HEXEWKB, WKB (in a buffer), and GeoJSON.",
        "this includes WKT, HEXEWKB, WKB"
    ],
    [
        "\"An error occurred when transforming the geometry \"",
        "\"An error occurred when transforming"
    ],
    [
        "\"to the SRID of the geometry form field.\"",
        "\"to the SRID of the geometry form"
    ],
    [
        "def __init__(self, *, srid=None, geom_type=None, **kwargs):",
        "def __init__(self, *, srid=None,"
    ],
    [
        "\"\"\"Transform the value to a Geometry object.\"\"\"",
        "\"\"\"Transform the value to a"
    ],
    [
        "Validate that the input value can be converted to a Geometry object",
        "Validate that the input value can"
    ],
    [
        "and return it. Raise a ValidationError if the value cannot be",
        "and return it. Raise a ValidationError if"
    ],
    [
        "\"\"\"Compare geographic value of data with its initial value.\"\"\"",
        "\"\"\"Compare geographic value of data"
    ],
    [
        "The base class for rich geometry widgets.",
        "The base class for"
    ],
    [
        "Render a map using the WKT of the geometry.",
        "Render a map using the"
    ],
    [
        "for key in (\"geom_type\", \"map_srid\", \"display_raw\"):",
        "for key in"
    ],
    [
        "return value.wkt if value else \"\"",
        "return value.wkt if value else"
    ],
    [
        "except (GEOSException, ValueError, TypeError) as err:",
        "except (GEOSException, ValueError, TypeError)"
    ],
    [
        "logger.error(\"Error creating geometry from value '%s' (%s)\", value, err)",
        "logger.error(\"Error creating geometry from value"
    ],
    [
        "if value.srid and value.srid != self.map_srid:",
        "if value.srid and"
    ],
    [
        "\"Error transforming geometry from srid '%s' to srid '%s' (%s)\",",
        "\"Error transforming geometry from srid '%s' to srid"
    ],
    [
        "\"geom_type\": \"Geometry\" if geom_type == \"Unknown\" else geom_type,",
        "\"geom_type\": \"Geometry\" if geom_type"
    ],
    [
        "return value.json if value else \"\"",
        "return value.json if value else"
    ],
    [
        "for key in (\"default_lon\", \"default_lat\", \"default_zoom\"):",
        "for key in (\"default_lon\","
    ],
    [
        "from datetime import date, datetime, time",
        "from datetime import date,"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import ds as capi",
        "from django.contrib.gis.gdal.prototypes import ds"
    ],
    [
        "Wrap an OGR Field. Needs to be instantiated from a Feature object.",
        "Wrap an OGR Field. Needs to be instantiated from a Feature"
    ],
    [
        "Initialize on the feature object and the integer index of",
        "Initialize on the feature object"
    ],
    [
        "raise GDALException(\"Cannot create OGR Field, invalid pointer given.\")",
        "raise GDALException(\"Cannot create OGR Field,"
    ],
    [
        "\"Return the string representation of the Field.\"",
        "\"Return the string representation of the"
    ],
    [
        "\"Retrieve the Field's value as a double (float).\"",
        "\"Retrieve the Field's value as a double"
    ],
    [
        "\"Retrieve the Field's value as an integer.\"",
        "\"Retrieve the Field's value as"
    ],
    [
        "\"Retrieve the Field's value as a string.\"",
        "\"Retrieve the Field's value as a"
    ],
    [
        "\"Retrieve the Field's value as a tuple of date & time components.\"",
        "\"Retrieve the Field's value as a tuple of date & time"
    ],
    [
        "return (yy, mm, dd, hh, mn, ss, tz)",
        "return (yy, mm, dd,"
    ],
    [
        "\"Unable to retrieve date & time information from the field.\"",
        "\"Unable to retrieve date & time information from the"
    ],
    [
        "\"Return True if the value of this field isn't null, False otherwise.\"",
        "\"Return True if the value of"
    ],
    [
        "\"Return the name of this Field.\"",
        "\"Return the name of this"
    ],
    [
        "\"Return the precision of this Field.\"",
        "\"Return the precision of"
    ],
    [
        "\"Return the OGR type of this Field.\"",
        "\"Return the OGR type"
    ],
    [
        "\"Return the OGR field type name for this Field.\"",
        "\"Return the OGR field type name for"
    ],
    [
        "\"Return the value of this Field.\"",
        "\"Return the value of this"
    ],
    [
        "\"Return the width of this Field.\"",
        "\"Return the width of"
    ],
    [
        "\"Return an integer contained in this field.\"",
        "\"Return an integer contained"
    ],
    [
        "GDAL uses OFTReals to represent OFTIntegers in created",
        "GDAL uses OFTReals to represent OFTIntegers in"
    ],
    [
        "shapefiles -- forcing the type here since the underlying field",
        "shapefiles -- forcing the type here since the underlying"
    ],
    [
        "\"Return a float contained in this field.\"",
        "\"Return a float contained in"
    ],
    [
        "\"Return a Python `date` object for the OFTDate field.\"",
        "\"Return a Python `date` object for the OFTDate"
    ],
    [
        "yy, mm, dd, hh, mn, ss, tz = self.as_datetime()",
        "yy, mm, dd, hh, mn,"
    ],
    [
        "\"Return a Python `datetime` object for this OFTDateTime field.\"",
        "\"Return a Python `datetime` object for"
    ],
    [
        "yy, mm, dd, hh, mn, ss, tz = self.as_datetime()",
        "yy, mm, dd, hh, mn,"
    ],
    [
        "return datetime(yy.value, mm.value, dd.value, hh.value, mn.value, ss.value)",
        "return datetime(yy.value, mm.value, dd.value,"
    ],
    [
        "\"Return a Python `time` object for this OFTTime field.\"",
        "\"Return a Python `time` object"
    ],
    [
        "yy, mm, dd, hh, mn, ss, tz = self.as_datetime()",
        "yy, mm, dd, hh, mn, ss, tz"
    ],
    [
        "ROGRFieldTypes = {cls: num for num, cls in OGRFieldTypes.items()}",
        "ROGRFieldTypes = {cls: num for num, cls in"
    ],
    [
        "The Spatial Reference class, represents OGR Spatial Reference objects.",
        "The Spatial Reference class, represents OGR"
    ],
    [
        "from ctypes import byref, c_char_p, c_int",
        "from ctypes import byref,"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import srs as capi",
        "from django.contrib.gis.gdal.prototypes import srs"
    ],
    [
        "A wrapper for the OGRSpatialReference object. According to the GDAL web site,",
        "A wrapper for the OGRSpatialReference object. According to the GDAL web"
    ],
    [
        "the SpatialReference object \"provide[s] services to represent coordinate",
        "the SpatialReference object \"provide[s] services"
    ],
    [
        "systems (projections and datums) and to transform between them.\"",
        "systems (projections and datums) and to transform between"
    ],
    [
        "Create a GDAL OSR Spatial Reference object from the given input.",
        "Create a GDAL OSR Spatial Reference object from the given"
    ],
    [
        "The input may be string of OGC Well Known Text (WKT), an integer",
        "The input may be string of OGC Well Known"
    ],
    [
        "EPSG code, a PROJ string, and/or a projection \"well known\" shorthand",
        "EPSG code, a PROJ string, and/or a projection \"well"
    ],
    [
        "\"SpatialReference.axis_order must be an AxisOrder instance.\"",
        "\"SpatialReference.axis_order must be an AxisOrder"
    ],
    [
        "raise TypeError('Invalid SRS type \"%s\"' % srs_type)",
        "raise TypeError('Invalid SRS type \"%s\"'"
    ],
    [
        "\"Could not create spatial reference from: %s\" % srs_input",
        "\"Could not create spatial reference from: %s\" %"
    ],
    [
        "Return the value of the given string attribute node, None if the node",
        "Return the value of the given string"
    ],
    [
        "doesn't exist.  Can also take a tuple as a parameter, (target, child),",
        "doesn't exist. Can also take a tuple as a parameter, (target,"
    ],
    [
        "where child is the index of the attribute in the WKT.  For example:",
        "where child is the index of the attribute in"
    ],
    [
        "The attribute value for the given target node (e.g. 'PROJCS'). The index",
        "The attribute value for the given target node (e.g. 'PROJCS'). The"
    ],
    [
        "keyword specifies an index of the child node to return.",
        "keyword specifies an index of the"
    ],
    [
        "if not isinstance(target, str) or not isinstance(index, int):",
        "if not isinstance(target, str) or not"
    ],
    [
        "\"Return the authority name for the given string target node.\"",
        "\"Return the authority name for the given string"
    ],
    [
        "self.ptr, target if target is None else force_bytes(target)",
        "self.ptr, target if target is None"
    ],
    [
        "\"Return the authority code for the given string target node.\"",
        "\"Return the authority code for the given string target"
    ],
    [
        "self.ptr, target if target is None else force_bytes(target)",
        "self.ptr, target if target"
    ],
    [
        "\"Return a clone of this SpatialReference object.\"",
        "\"Return a clone of"
    ],
    [
        "\"Morph this SpatialReference from ESRI's format to EPSG.\"",
        "\"Morph this SpatialReference from"
    ],
    [
        "This method inspects the WKT of this SpatialReference, and will",
        "This method inspects the WKT"
    ],
    [
        "add EPSG authority nodes where an EPSG identifier is applicable.",
        "add EPSG authority nodes where an EPSG identifier"
    ],
    [
        "\"Morph this SpatialReference to ESRI's format.\"",
        "\"Morph this SpatialReference"
    ],
    [
        "\"Check to see if the given spatial reference is valid.\"",
        "\"Check to see if the given spatial"
    ],
    [
        "\"Return the name of this Spatial Reference.\"",
        "\"Return the name of this Spatial"
    ],
    [
        "\"Return the SRID of top-level authority, or None if undefined.\"",
        "\"Return the SRID of top-level authority,"
    ],
    [
        "\"Return the name of the linear units.\"",
        "\"Return the name of the"
    ],
    [
        "\"Return the value of the linear units.\"",
        "\"Return the value of"
    ],
    [
        "\"Return the name of the angular units.\"",
        "\"Return the name of"
    ],
    [
        "\"Return the value of the angular units.\"",
        "\"Return the value of"
    ],
    [
        "determine whether to return the linear or angular units.",
        "determine whether to return the linear or angular"
    ],
    [
        "Return a tuple of the ellipsoid parameters:",
        "Return a tuple of the"
    ],
    [
        "(semimajor axis, semiminor axis, and inverse flattening)",
        "(semimajor axis, semiminor axis, and inverse"
    ],
    [
        "\"Return the Semi Major Axis for this Spatial Reference.\"",
        "\"Return the Semi Major Axis for this"
    ],
    [
        "\"Return the Semi Minor Axis for this Spatial Reference.\"",
        "\"Return the Semi Minor Axis"
    ],
    [
        "\"Return the Inverse Flattening for this Spatial Reference.\"",
        "\"Return the Inverse Flattening for this"
    ],
    [
        "Return True if this SpatialReference is geographic",
        "Return True if this"
    ],
    [
        "\"Return True if this SpatialReference is local (root node is LOCAL_CS).\"",
        "\"Return True if this SpatialReference is"
    ],
    [
        "Return True if this SpatialReference is a projected coordinate system",
        "Return True if this SpatialReference is a"
    ],
    [
        "\"Import the Spatial Reference from the EPSG code (an integer).\"",
        "\"Import the Spatial Reference from the EPSG"
    ],
    [
        "\"\"\"Import the Spatial Reference from a PROJ string.\"\"\"",
        "\"\"\"Import the Spatial Reference"
    ],
    [
        "\"Import the Spatial Reference from the given user input string.\"",
        "\"Import the Spatial Reference from the given user"
    ],
    [
        "\"Import the Spatial Reference from OGC WKT (string)\"",
        "\"Import the Spatial Reference from OGC WKT"
    ],
    [
        "\"Import the Spatial Reference from an XML string.\"",
        "\"Import the Spatial Reference from"
    ],
    [
        "\"Return the WKT representation of this Spatial Reference.\"",
        "\"Return the WKT representation of"
    ],
    [
        "\"Return the 'pretty' representation of the WKT.\"",
        "\"Return the 'pretty' representation of the"
    ],
    [
        "\"\"\"Return the PROJ representation for this Spatial Reference.\"\"\"",
        "\"\"\"Return the PROJ representation"
    ],
    [
        "\"Return the XML representation of this Spatial Reference.\"",
        "\"Return the XML representation"
    ],
    [
        "\"Initialize on a source and target SpatialReference objects.\"",
        "\"Initialize on a source and target SpatialReference"
    ],
    [
        "if not isinstance(source, SpatialReference) or not isinstance(",
        "if not isinstance(source, SpatialReference) or"
    ],
    [
        "raise TypeError(\"source and target must be of type SpatialReference\")",
        "raise TypeError(\"source and target must be of"
    ],
    [
        "This module houses the GDAL & SRS Exception objects, and the",
        "This module houses the GDAL & SRS Exception objects, and"
    ],
    [
        "check_err() routine which checks the status code returned by",
        "check_err() routine which checks the status code returned"
    ],
    [
        "Check the given CPL/OGRERR and raise an exception where appropriate.",
        "Check the given CPL/OGRERR and raise an exception where"
    ],
    [
        "err_dict = CPLERR_DICT if cpl else OGRERR_DICT",
        "err_dict = CPLERR_DICT if cpl"
    ],
    [
        "raise GDALException('Unknown error code: \"%s\"' % code)",
        "raise GDALException('Unknown error code: \"%s\"' %"
    ],
    [
        "_str_types = {v.lower(): k for k, v in _types.items()}",
        "_str_types = {v.lower(): k for k,"
    ],
    [
        "\"Figure out the correct OGR Type based upon the input.\"",
        "\"Figure out the correct OGR Type based upon"
    ],
    [
        "raise GDALException('Invalid OGR String Type \"%s\"' % type_input)",
        "raise GDALException('Invalid OGR String Type \"%s\"' %"
    ],
    [
        "raise GDALException(\"Invalid OGR Integer Type: %d\" % type_input)",
        "raise GDALException(\"Invalid OGR Integer Type: %d\""
    ],
    [
        "raise TypeError(\"Invalid OGR input type given.\")",
        "raise TypeError(\"Invalid OGR"
    ],
    [
        "\"Return the value of the name property.\"",
        "\"Return the value of the name"
    ],
    [
        "Do an equivalence test on the OGR type with the given",
        "Do an equivalence test on the OGR type"
    ],
    [
        "other OGRGeomType, the short-hand string, or the integer.",
        "other OGRGeomType, the short-hand"
    ],
    [
        "\"Return a short-hand string form of the OGR Geometry type.\"",
        "\"Return a short-hand string form"
    ],
    [
        "\"Return the Django GeometryField for this OGR Type.\"",
        "\"Return the Django GeometryField for this OGR"
    ],
    [
        "This module houses ctypes interfaces for GDAL objects.  The following GDAL",
        "This module houses ctypes interfaces for GDAL objects. The"
    ],
    [
        "CoordTransform: Used for coordinate transformations from one spatial",
        "CoordTransform: Used for coordinate"
    ],
    [
        "Driver: Wraps an OGR data source driver.",
        "Driver: Wraps an OGR"
    ],
    [
        "DataSource: Wrapper for the OGR data source object, supports",
        "DataSource: Wrapper for the OGR"
    ],
    [
        "Envelope: A ctypes structure for bounding boxes (GDAL library",
        "Envelope: A ctypes structure for"
    ],
    [
        "OGRGeometry: Object for accessing OGR Geometry functionality.",
        "OGRGeometry: Object for accessing"
    ],
    [
        "OGRGeomType: A class for representing the different OGR Geometry",
        "OGRGeomType: A class for representing the"
    ],
    [
        "SpatialReference: Represents OSR Spatial Reference objects.",
        "SpatialReference: Represents OSR Spatial"
    ],
    [
        "The GDAL library will be imported from the system path using the default",
        "The GDAL library will be imported from the system path"
    ],
    [
        "library name for the current OS. The default library path may be overridden",
        "library name for the current OS. The"
    ],
    [
        "by setting `GDAL_LIBRARY_PATH` in your settings with the path to the GDAL C",
        "by setting `GDAL_LIBRARY_PATH` in your settings with"
    ],
    [
        "from django.contrib.gis.gdal.error import GDALException, SRSException, check_err",
        "from django.contrib.gis.gdal.error import"
    ],
    [
        "from django.contrib.gis.gdal.srs import AxisOrder, CoordTransform, SpatialReference",
        "from django.contrib.gis.gdal.srs import"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import ds as capi",
        "from django.contrib.gis.gdal.prototypes import"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import geom as geom_api",
        "from django.contrib.gis.gdal.prototypes import"
    ],
    [
        "This class that wraps an OGR Feature, needs to be instantiated",
        "This class that wraps an OGR Feature, needs to"
    ],
    [
        "Initialize Feature from a pointer and its Layer object.",
        "Initialize Feature from a pointer and"
    ],
    [
        "raise GDALException(\"Cannot create OGR Feature, invalid pointer given.\")",
        "raise GDALException(\"Cannot create OGR"
    ],
    [
        "Get the Field object at the specified index, which may be either",
        "Get the Field object at the specified index, which"
    ],
    [
        "an integer or the Field's string label.  Note that the Field object",
        "an integer or the Field's string"
    ],
    [
        "is not the field's _value_ -- use the `get` method instead to",
        "is not the field's _value_ -- use the `get` method"
    ],
    [
        "retrieve the value (e.g. an integer) instead of a Field instance.",
        "retrieve the value (e.g. an integer) instead of a"
    ],
    [
        "\"Index out of range when accessing field in a feature: %s.\" % index",
        "\"Index out of range when accessing field in a feature: %s.\""
    ],
    [
        "\"Return the count of fields in this feature.\"",
        "\"Return the count of"
    ],
    [
        "\"The string name of the feature.\"",
        "\"The string name of"
    ],
    [
        "return \"Feature FID %d in Layer<%s>\" % (self.fid, self.layer_name)",
        "return \"Feature FID %d in Layer<%s>\" %"
    ],
    [
        "\"Do equivalence testing on the features.\"",
        "\"Do equivalence testing on the"
    ],
    [
        "\"Return the name of the layer for the feature.\"",
        "\"Return the name of the layer"
    ],
    [
        "\"Return the number of fields in the Feature.\"",
        "\"Return the number of fields"
    ],
    [
        "\"Return a list of fields in the Feature.\"",
        "\"Return a list of"
    ],
    [
        "\"Return the OGR Geometry for this Feature.\"",
        "\"Return the OGR Geometry for"
    ],
    [
        "\"Return the OGR Geometry Type for this Feature.\"",
        "\"Return the OGR Geometry Type for this"
    ],
    [
        "Return the value of the field, instead of an instance of the Field",
        "Return the value of the field, instead of an instance"
    ],
    [
        "object.  May take a string of the field name or a Field object as",
        "object. May take a string of the field"
    ],
    [
        "\"Return the index of the given field name.\"",
        "\"Return the index of"
    ],
    [
        "raise IndexError(\"Invalid OFT field name given: %s.\" % field_name)",
        "raise IndexError(\"Invalid OFT field name given: %s.\" %"
    ],
    [
        "DataSource is a wrapper for the OGR Data Source object, which provides",
        "DataSource is a wrapper for the OGR Data"
    ],
    [
        "an interface for reading vector geometry data from many different file",
        "an interface for reading vector geometry"
    ],
    [
        "When instantiating a DataSource object, use the filename of a",
        "When instantiating a DataSource object, use the filename"
    ],
    [
        "GDAL-supported data source.  For example, a SHP file or a",
        "GDAL-supported data source. For example,"
    ],
    [
        "The ds_driver keyword is used internally when a ctypes pointer",
        "The ds_driver keyword is used internally when a ctypes"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import ds as capi",
        "from django.contrib.gis.gdal.prototypes import ds as"
    ],
    [
        "\"Wraps an OGR Data Source object.\"",
        "\"Wraps an OGR"
    ],
    [
        "self._write = capi.GDAL_OF_UPDATE if write else capi.GDAL_OF_READONLY",
        "self._write = capi.GDAL_OF_UPDATE if write else"
    ],
    [
        "raise GDALException('Could not open the datasource at \"%s\"' % ds_input)",
        "raise GDALException('Could not open the datasource at \"%s\"' %"
    ],
    [
        "raise GDALException(\"Invalid data source input type: %s\" % type(ds_input))",
        "raise GDALException(\"Invalid data source input type:"
    ],
    [
        "raise GDALException('Invalid data source file \"%s\"' % ds_input)",
        "raise GDALException('Invalid data source"
    ],
    [
        "\"Allows use of the index [] operator to get a layer at the index.\"",
        "\"Allows use of the index [] operator to get a layer"
    ],
    [
        "raise IndexError(\"Invalid OGR layer name given: %s.\" % index)",
        "raise IndexError(\"Invalid OGR layer name given: %s.\""
    ],
    [
        "\"Index out of range when accessing layers in a datasource: %s.\"",
        "\"Index out of range when accessing layers in"
    ],
    [
        "raise TypeError(\"Invalid index type: %s\" % type(index))",
        "raise TypeError(\"Invalid index type:"
    ],
    [
        "\"Return the number of layers within the data source.\"",
        "\"Return the number of layers"
    ],
    [
        "\"Return OGR GetName and Driver for the Data Source.\"",
        "\"Return OGR GetName and Driver for the"
    ],
    [
        "return \"%s (%s)\" % (self.name, self.driver)",
        "return \"%s (%s)\" %"
    ],
    [
        "\"Return the number of layers in the data source.\"",
        "\"Return the number of layers"
    ],
    [
        "\"Return the name of the data source.\"",
        "\"Return the name of the data"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import ds as capi",
        "from django.contrib.gis.gdal.prototypes import ds as"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import geom as geom_api",
        "from django.contrib.gis.gdal.prototypes import"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import srs as srs_api",
        "from django.contrib.gis.gdal.prototypes import srs"
    ],
    [
        "A class that wraps an OGR Layer, needs to be instantiated from a DataSource",
        "A class that wraps an OGR Layer, needs to"
    ],
    [
        "Initialize on an OGR C pointer to the Layer and the `DataSource` object",
        "Initialize on an OGR C pointer to the Layer and the `DataSource`"
    ],
    [
        "that owns this layer.  The `DataSource` object is required so that a",
        "that owns this layer. The `DataSource` object is"
    ],
    [
        "reference to it is kept with this Layer.  This prevents garbage",
        "reference to it is kept with this Layer. This"
    ],
    [
        "collection of the `DataSource` while this Layer is still active.",
        "collection of the `DataSource` while this Layer"
    ],
    [
        "raise GDALException(\"Cannot create Layer, invalid pointer given\")",
        "raise GDALException(\"Cannot create Layer, invalid"
    ],
    [
        "\"Get the Feature at the specified index.\"",
        "\"Get the Feature at the specified"
    ],
    [
        "raise IndexError(\"Negative indices are not allowed on OGR Layers.\")",
        "raise IndexError(\"Negative indices are not allowed on OGR"
    ],
    [
        "return [self._make_feature(fid) for fid in range(start, stop, stride)]",
        "return [self._make_feature(fid) for fid in"
    ],
    [
        "\"Integers and slices may only be used when indexing OGR Layers.\"",
        "\"Integers and slices may only be used"
    ],
    [
        "\"Iterate over each Feature in the Layer.\"",
        "\"Iterate over each Feature"
    ],
    [
        "\"The length is the number of features.\"",
        "\"The length is the number"
    ],
    [
        "\"The string name of the layer.\"",
        "\"The string name of the"
    ],
    [
        "Helper routine for __getitem__ that constructs a Feature from the given",
        "Helper routine for __getitem__ that constructs a"
    ],
    [
        "Feature ID.  If the OGR Layer does not support random-access reading,",
        "Feature ID. If the OGR Layer does not"
    ],
    [
        "then each feature of the layer will be incremented through until the",
        "then each feature of the layer"
    ],
    [
        "a Feature is found matching the given feature ID.",
        "a Feature is found matching the"
    ],
    [
        "raise IndexError(\"Invalid feature id: %s.\" % feat_id)",
        "raise IndexError(\"Invalid feature id: %s.\""
    ],
    [
        "\"Return the extent (an Envelope) of this layer.\"",
        "\"Return the extent (an Envelope) of"
    ],
    [
        "\"Return the name of this layer in the Data Source.\"",
        "\"Return the name of this layer in the"
    ],
    [
        "\"Return the number of features in the Layer.\"",
        "\"Return the number of features in"
    ],
    [
        "\"Return the number of fields in the Layer.\"",
        "\"Return the number of"
    ],
    [
        "\"Return the geometry type (OGRGeomType) of the Layer.\"",
        "\"Return the geometry type (OGRGeomType) of"
    ],
    [
        "\"Return the Spatial Reference used in this Layer.\"",
        "\"Return the Spatial Reference used in"
    ],
    [
        "Return a list of string names corresponding to each of the Fields",
        "Return a list of string names corresponding to"
    ],
    [
        "Return a list of the types of fields in this Layer.  For example,",
        "Return a list of the types of fields in"
    ],
    [
        "return the list [OFTInteger, OFTReal, OFTString] for an OGR layer that",
        "return the list [OFTInteger, OFTReal, OFTString] for"
    ],
    [
        "has an integer, a floating-point, and string fields.",
        "has an integer, a"
    ],
    [
        "\"Return a list of the maximum field widths for the features.\"",
        "\"Return a list of the maximum field"
    ],
    [
        "\"Return the field precisions for the features.\"",
        "\"Return the field precisions for the"
    ],
    [
        "xmin, ymin, xmax, ymax = map(c_double, filter)",
        "xmin, ymin, xmax, ymax ="
    ],
    [
        "Return a list containing the given field name for every Feature",
        "Return a list containing the given"
    ],
    [
        "raise GDALException(\"invalid field name: %s\" % field_name)",
        "raise GDALException(\"invalid field name: %s\" %"
    ],
    [
        "return [feat.get(field_name) for feat in self]",
        "return [feat.get(field_name) for feat in"
    ],
    [
        "Return a list containing the OGRGeometry for every Feature in",
        "Return a list containing the OGRGeometry for every"
    ],
    [
        "return [GEOSGeometry(feat.geom.wkb) for feat in self]",
        "return [GEOSGeometry(feat.geom.wkb) for feat in"
    ],
    [
        "return [feat.geom for feat in self]",
        "return [feat.geom for feat in"
    ],
    [
        "Return a bool indicating whether the this Layer supports the given",
        "Return a bool indicating whether the this Layer supports"
    ],
    [
        "capability (a string).  Valid capability strings include:",
        "capability (a string). Valid capability"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import ds as capi",
        "from django.contrib.gis.gdal.prototypes import"
    ],
    [
        "Wrap a GDAL/OGR Data Source Driver.",
        "Wrap a GDAL/OGR Data"
    ],
    [
        "For more information, see the C API documentation:",
        "For more information, see the"
    ],
    [
        "Initialize an GDAL/OGR driver on either a string or integer input.",
        "Initialize an GDAL/OGR driver on either"
    ],
    [
        "\"Unrecognized input type for GDAL/OGR Driver: %s\" % type(dr_input)",
        "\"Unrecognized input type for GDAL/OGR Driver:"
    ],
    [
        "\"Could not initialize GDAL/OGR Driver on input: %s\" % dr_input",
        "\"Could not initialize GDAL/OGR Driver on input: %s\""
    ],
    [
        "Attempt to register all the data source drivers.",
        "Attempt to register all the"
    ],
    [
        "Return the number of GDAL/OGR data source drivers registered.",
        "Return the number of GDAL/OGR data source"
    ],
    [
        "Return description/name string for this driver.",
        "Return description/name string for"
    ],
    [
        "The OGRGeometry is a wrapper for using the OGR Geometry class",
        "The OGRGeometry is a wrapper for using the"
    ],
    [
        "OGRGeometry may be instantiated when reading geometries from OGR Data Sources",
        "OGRGeometry may be instantiated when reading geometries"
    ],
    [
        "(e.g. SHP files), or when given OGC WKT (a string).",
        "(e.g. SHP files), or when given OGC"
    ],
    [
        "While the 'full' API is not present yet, the API is \"pythonic\" unlike",
        "While the 'full' API is not present"
    ],
    [
        "the traditional and \"next-generation\" OGR Python bindings.  One major",
        "the traditional and \"next-generation\" OGR Python bindings."
    ],
    [
        "advantage OGR Geometries have over their GEOS counterparts is support",
        "advantage OGR Geometries have over their GEOS"
    ],
    [
        "for spatial reference systems and their transformation.",
        "for spatial reference systems and"
    ],
    [
        ">>> from django.contrib.gis.gdal import OGRGeometry, OGRGeomType, SpatialReference",
        ">>> from django.contrib.gis.gdal import"
    ],
    [
        "The OGRGeomType class is to make it easy to specify an OGR geometry type:",
        "The OGRGeomType class is to make it"
    ],
    [
        "from ctypes import byref, c_char_p, c_double, c_ubyte, c_void_p, string_at",
        "from ctypes import byref, c_char_p, c_double, c_ubyte,"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import geom as capi",
        "from django.contrib.gis.gdal.prototypes import geom"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import srs as srs_api",
        "from django.contrib.gis.gdal.prototypes import srs"
    ],
    [
        "from django.contrib.gis.geometry import hex_regex, json_regex, wkt_regex",
        "from django.contrib.gis.geometry import hex_regex,"
    ],
    [
        "\"\"\"Initialize Geometry on either WKT or an OGR pointer as input.\"\"\"",
        "\"\"\"Initialize Geometry on either WKT or an OGR"
    ],
    [
        "\"Invalid input type for OGR Geometry construction: %s\"",
        "\"Invalid input type for OGR Geometry"
    ],
    [
        "\"Cannot create OGR Geometry from input: %s\" % geom_input",
        "\"Cannot create OGR Geometry from input: %s\""
    ],
    [
        "if (geo_class := GEO_CLASSES.get(self.geom_type.num)) is None:",
        "if (geo_class :="
    ],
    [
        "ptr = capi.from_wkb(wkb, None, byref(c_void_p()), len(wkb))",
        "ptr = capi.from_wkb(wkb,"
    ],
    [
        "raise GDALException(\"Invalid OGRGeometry loaded from pickled state.\")",
        "raise GDALException(\"Invalid OGRGeometry loaded from pickled"
    ],
    [
        "\"POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))\"",
        "\"POLYGON((%s %s, %s %s, %s %s, %s"
    ],
    [
        "\"Return the union of the two geometries.\"",
        "\"Return the union of"
    ],
    [
        "\"Return the intersection of this Geometry and the other.\"",
        "\"Return the intersection of this Geometry and"
    ],
    [
        "\"Return the difference this Geometry and the other.\"",
        "\"Return the difference this Geometry and"
    ],
    [
        "\"Return the symmetric difference of this Geometry and the other.\"",
        "\"Return the symmetric difference of"
    ],
    [
        "\"Is this Geometry equal to the other?\"",
        "\"Is this Geometry equal to"
    ],
    [
        "\"WKT is used for the string representation.\"",
        "\"WKT is used for the"
    ],
    [
        "\"Return the coordinate dimension of the Geometry.\"",
        "\"Return the coordinate dimension of"
    ],
    [
        "\"Return the number of elements in this Geometry.\"",
        "\"Return the number of elements in this"
    ],
    [
        "\"Return the number of Points in this Geometry.\"",
        "\"Return the number of"
    ],
    [
        "\"Alias for `point_count` (same name method in GEOS API.)\"",
        "\"Alias for `point_count` (same name method in GEOS"
    ],
    [
        "\"Return the Type for this Geometry.\"",
        "\"Return the Type"
    ],
    [
        "\"Return the Name of this Geometry.\"",
        "\"Return the Name"
    ],
    [
        "\"Return the envelope for this Geometry.\"",
        "\"Return the envelope"
    ],
    [
        "\"\"\"Return True if the geometry has Z coordinates.\"\"\"",
        "\"\"\"Return True if the geometry has"
    ],
    [
        "\"\"\"Set if this geometry has Z coordinates.\"\"\"",
        "\"\"\"Set if this geometry"
    ],
    [
        "\"\"\"Return True if the geometry has M coordinates.\"\"\"",
        "\"\"\"Return True if the geometry"
    ],
    [
        "\"\"\"Set if this geometry has M coordinates.\"\"\"",
        "\"\"\"Set if this geometry has"
    ],
    [
        "f\"Input to 'set_measured' must be a boolean, got '{value!r}'.\"",
        "f\"Input to 'set_measured' must be a"
    ],
    [
        "\"\"\"Return True if the geometry is or has curve geometry.\"\"\"",
        "\"\"\"Return True if the geometry"
    ],
    [
        "\"\"\"Return a linear version of this geometry.\"\"\"",
        "\"\"\"Return a linear version of"
    ],
    [
        "\"\"\"Return a curve version of this geometry.\"\"\"",
        "\"\"\"Return a curve version"
    ],
    [
        "\"Return the Spatial Reference for this Geometry.\"",
        "\"Return the Spatial Reference for"
    ],
    [
        "\"Set the SpatialReference for this geometry.\"",
        "\"Set the SpatialReference for"
    ],
    [
        "\"Cannot assign spatial reference with object of type: %s\" % type(srs)",
        "\"Cannot assign spatial reference with object of type:"
    ],
    [
        "if isinstance(srid, int) or srid is None:",
        "if isinstance(srid, int) or"
    ],
    [
        "raise TypeError(\"SRID must be set with an integer.\")",
        "raise TypeError(\"SRID must be set with"
    ],
    [
        "\"Return a GEOSGeometry object from this OGRGeometry.\"",
        "\"Return a GEOSGeometry object from this"
    ],
    [
        "raise GEOSException(f\"GEOS does not support {self.__class__.__qualname__}.\")",
        "raise GEOSException(f\"GEOS does not"
    ],
    [
        "\"Return the GML representation of the Geometry.\"",
        "\"Return the GML representation of"
    ],
    [
        "\"Return the hexadecimal representation of the WKB (a string).\"",
        "\"Return the hexadecimal representation of"
    ],
    [
        "Return the GeoJSON representation of this Geometry.",
        "Return the GeoJSON representation of this"
    ],
    [
        "\"Return the KML representation of the Geometry.\"",
        "\"Return the KML representation"
    ],
    [
        "\"Return the size of the WKB buffer.\"",
        "\"Return the size of"
    ],
    [
        "\"Return the WKB representation of the Geometry.\"",
        "\"Return the WKB representation"
    ],
    [
        "to_wkb = capi.to_iso_wkb if self.is_measured else capi.to_wkb",
        "to_wkb = capi.to_iso_wkb if"
    ],
    [
        "\"Return the WKT representation of the Geometry.\"",
        "\"Return the WKT representation"
    ],
    [
        "to_wkt = capi.to_iso_wkt if self.is_measured else capi.to_wkt",
        "to_wkt = capi.to_iso_wkt if self.is_measured else"
    ],
    [
        "\"Return the EWKT representation of the Geometry.\"",
        "\"Return the EWKT representation of"
    ],
    [
        "If there are any rings within this geometry that have not been",
        "If there are any rings within"
    ],
    [
        "closed, this routine will do so by adding the starting point at the",
        "closed, this routine will do so by adding the"
    ],
    [
        "Transform this geometry to a different spatial reference system.",
        "Transform this geometry to a different"
    ],
    [
        "May take a CoordTransform object, a SpatialReference object, string",
        "May take a CoordTransform object, a SpatialReference object,"
    ],
    [
        "WKT or PROJ, and/or an integer SRID.  By default, return nothing",
        "WKT or PROJ, and/or an integer SRID."
    ],
    [
        "and transform the geometry in-place. However, if the `clone` keyword is",
        "and transform the geometry in-place. However, if the `clone`"
    ],
    [
        "set, return a transformed clone of this geometry.",
        "set, return a transformed clone of this"
    ],
    [
        "\"\"\"A generalized function for topology operations, takes a GDAL function and",
        "\"\"\"A generalized function for topology operations,"
    ],
    [
        "the other geometry to perform the operation on.\"\"\"",
        "the other geometry to perform"
    ],
    [
        "\"Must use another OGRGeometry object for topology operations!\"",
        "\"Must use another OGRGeometry object for topology"
    ],
    [
        "\"Return True if this geometry intersects with the other.\"",
        "\"Return True if this geometry intersects with"
    ],
    [
        "\"Return True if this geometry is equivalent to the other.\"",
        "\"Return True if this geometry is equivalent to the"
    ],
    [
        "\"Return True if this geometry and the other are spatially disjoint.\"",
        "\"Return True if this geometry and the other are spatially"
    ],
    [
        "\"Return True if this geometry touches the other.\"",
        "\"Return True if this geometry"
    ],
    [
        "\"Return True if this geometry crosses the other.\"",
        "\"Return True if this geometry crosses the"
    ],
    [
        "\"Return True if this geometry is within the other.\"",
        "\"Return True if this geometry is within"
    ],
    [
        "\"Return True if this geometry contains the other.\"",
        "\"Return True if this geometry contains the"
    ],
    [
        "\"Return True if this geometry overlaps the other.\"",
        "\"Return True if this geometry"
    ],
    [
        "\"A helper routine for the OGR routines that generate geometries.\"",
        "\"A helper routine for the OGR routines"
    ],
    [
        "\"Return the boundary of this geometry.\"",
        "\"Return the boundary"
    ],
    [
        "Return the smallest convex Polygon that contains all the points in",
        "Return the smallest convex Polygon that contains all the points"
    ],
    [
        "Return a new geometry consisting of the region which is the difference",
        "Return a new geometry consisting of the region which is the"
    ],
    [
        "of this geometry and the other.",
        "of this geometry and"
    ],
    [
        "Return a new geometry consisting of the region of intersection of this",
        "Return a new geometry consisting of the region of"
    ],
    [
        "Return a new geometry which is the symmetric difference of this",
        "Return a new geometry which is the symmetric"
    ],
    [
        "Return a new geometry consisting of the region which is the union of",
        "Return a new geometry consisting of the region"
    ],
    [
        "\"\"\"Return the centroid (a Point) of this Polygon.\"\"\"",
        "\"\"\"Return the centroid (a Point) of this"
    ],
    [
        "return geos.Point._create_empty() if self.empty else super()._geos_ptr()",
        "return geos.Point._create_empty() if self.empty"
    ],
    [
        "\"Return the X coordinate for this Point.\"",
        "\"Return the X coordinate for"
    ],
    [
        "\"Return the Y coordinate for this Point.\"",
        "\"Return the Y coordinate"
    ],
    [
        "\"Return the Z coordinate for this Point.\"",
        "\"Return the Z coordinate for"
    ],
    [
        "\"\"\"Return the M coordinate for this Point.\"\"\"",
        "\"\"\"Return the M coordinate"
    ],
    [
        "\"Return the tuple of this point.\"",
        "\"Return the tuple"
    ],
    [
        "\"Return the Point at the given index.\"",
        "\"Return the Point at the"
    ],
    [
        "x, y, z, m = c_double(), c_double(), c_double(), c_double()",
        "x, y, z, m ="
    ],
    [
        "capi.get_point(self.ptr, index, byref(x), byref(y), byref(z), byref(m))",
        "capi.get_point(self.ptr, index, byref(x),"
    ],
    [
        "\"Index out of range when accessing points of a line string: %s.\" % index",
        "\"Index out of range when accessing points of a line string:"
    ],
    [
        "\"Return the number of points in the LineString.\"",
        "\"Return the number of points in the"
    ],
    [
        "\"Return the tuple representation of this LineString.\"",
        "\"Return the tuple representation of"
    ],
    [
        "return tuple(self[i] for i in range(len(self)))",
        "return tuple(self[i] for i in"
    ],
    [
        "Internal routine that returns a sequence (list) corresponding with",
        "Internal routine that returns a"
    ],
    [
        "return [func(self.ptr, i) for i in range(len(self))]",
        "return [func(self.ptr, i) for"
    ],
    [
        "\"Return the X coordinates in a list.\"",
        "\"Return the X coordinates"
    ],
    [
        "\"Return the Y coordinates in a list.\"",
        "\"Return the Y coordinates"
    ],
    [
        "\"Return the Z coordinates in a list.\"",
        "\"Return the Z coordinates in"
    ],
    [
        "\"\"\"Return the M coordinates in a list.\"\"\"",
        "\"\"\"Return the M coordinates"
    ],
    [
        "\"Return the number of interior rings in this Polygon.\"",
        "\"Return the number of interior rings"
    ],
    [
        "\"Get the ring at the specified index.\"",
        "\"Get the ring at"
    ],
    [
        "\"Index out of range when accessing rings of a polygon: %s.\" % index",
        "\"Index out of range when accessing rings of a polygon: %s.\" %"
    ],
    [
        "\"Return the shell of this Polygon.\"",
        "\"Return the shell"
    ],
    [
        "\"Return a tuple of LinearRing coordinate tuples.\"",
        "\"Return a tuple of LinearRing"
    ],
    [
        "return tuple(self[i].tuple for i in range(self.geom_count))",
        "return tuple(self[i].tuple for i"
    ],
    [
        "\"Return the number of Points in this Polygon.\"",
        "\"Return the number of Points in this"
    ],
    [
        "return sum(self[i].point_count for i in range(self.geom_count))",
        "return sum(self[i].point_count for"
    ],
    [
        "\"Get the Geometry at the specified index.\"",
        "\"Get the Geometry at the"
    ],
    [
        "\"Index out of range when accessing geometry in a collection: %s.\"",
        "\"Index out of range when accessing geometry"
    ],
    [
        "\"Return the number of geometries in this Geometry Collection.\"",
        "\"Return the number of geometries in"
    ],
    [
        "\"Add the geometry to this Geometry Collection.\"",
        "\"Add the geometry to this"
    ],
    [
        "\"Return the number of Points in this Geometry Collection.\"",
        "\"Return the number of Points"
    ],
    [
        "return sum(self[i].point_count for i in range(self.geom_count))",
        "return sum(self[i].point_count for i"
    ],
    [
        "\"Return a tuple representation of this Geometry Collection.\"",
        "\"Return a tuple representation"
    ],
    [
        "return tuple(self[i].tuple for i in range(self.geom_count))",
        "return tuple(self[i].tuple for i"
    ],
    [
        "from ctypes import CDLL, CFUNCTYPE, c_char_p, c_int",
        "from ctypes import CDLL, CFUNCTYPE, c_char_p,"
    ],
    [
        "raise ImproperlyConfigured('GDAL is unsupported on OS \"%s\".' % os.name)",
        "raise ImproperlyConfigured('GDAL is unsupported on OS \"%s\".'"
    ],
    [
        "'Could not find the GDAL library (tried \"%s\"). Is GDAL installed? '",
        "'Could not find the GDAL library (tried"
    ],
    [
        "\"If it is, try setting GDAL_LIBRARY_PATH in your settings.\"",
        "\"If it is, try setting"
    ],
    [
        "\"Return only the GDAL version number information.\"",
        "\"Return only the GDAL version"
    ],
    [
        "\"Return the full GDAL version information.\"",
        "\"Return the full GDAL version"
    ],
    [
        "raise GDALException('Could not parse GDAL version string \"%s\"' % ver)",
        "raise GDALException('Could not parse GDAL version string"
    ],
    [
        "return (int(major), int(minor), subminor and int(subminor))",
        "return (int(major), int(minor),"
    ],
    [
        "CPLErrorHandler = CFUNCTYPE(None, c_int, c_int, c_char_p)",
        "CPLErrorHandler = CFUNCTYPE(None, c_int, c_int,"
    ],
    [
        "The GDAL/OGR library uses an Envelope structure to hold the bounding",
        "The GDAL/OGR library uses an Envelope structure"
    ],
    [
        "box information for a geometry.  The envelope (bounding box) contains",
        "box information for a geometry. The envelope"
    ],
    [
        "two pairs of coordinates, one for the lower left coordinate and one",
        "two pairs of coordinates, one for the"
    ],
    [
        "The Envelope object is a C structure that contains the minimum and",
        "The Envelope object is a C structure"
    ],
    [
        "maximum X, Y coordinates for a rectangle bounding box.  The naming",
        "maximum X, Y coordinates for a rectangle bounding box."
    ],
    [
        "of the variables is compatible with the OGR Envelope structure.",
        "of the variables is compatible with"
    ],
    [
        "raise GDALException(\"Incorrect number (%d) of arguments.\" % len(args))",
        "raise GDALException(\"Incorrect number (%d)"
    ],
    [
        "raise GDALException(\"Envelope minimum X > maximum X.\")",
        "raise GDALException(\"Envelope minimum X > maximum"
    ],
    [
        "raise GDALException(\"Envelope minimum Y > maximum Y.\")",
        "raise GDALException(\"Envelope minimum Y > maximum"
    ],
    [
        "Return True if the envelopes are equivalent; can compare against",
        "Return True if the envelopes are"
    ],
    [
        "raise GDALException(\"Equivalence testing only works with other Envelopes.\")",
        "raise GDALException(\"Equivalence testing only"
    ],
    [
        "\"Return a string representation of the tuple.\"",
        "\"Return a string representation of the"
    ],
    [
        "\"Initialize the C OGR Envelope structure from the given sequence.\"",
        "\"Initialize the C OGR Envelope"
    ],
    [
        "Modify the envelope to expand to include the boundaries of",
        "Modify the envelope to expand to"
    ],
    [
        "\"Return the value of the minimum X coordinate.\"",
        "\"Return the value of the"
    ],
    [
        "\"Return the value of the minimum Y coordinate.\"",
        "\"Return the value of the"
    ],
    [
        "\"Return the value of the maximum X coordinate.\"",
        "\"Return the value of the"
    ],
    [
        "\"Return the value of the maximum Y coordinate.\"",
        "\"Return the value of the maximum Y"
    ],
    [
        "\"Return a tuple representing the envelope.\"",
        "\"Return a tuple"
    ],
    [
        "\"Return WKT representing a Polygon for this envelope.\"",
        "\"Return WKT representing a Polygon for this"
    ],
    [
        "return \"POLYGON((%s %s,%s %s,%s %s,%s %s,%s %s))\" % (",
        "return \"POLYGON((%s %s,%s %s,%s %s,%s"
    ],
    [
        "from ctypes import POINTER, c_char_p, c_int, c_void_p",
        "from ctypes import POINTER,"
    ],
    [
        "Create a function prototype for the OSR routines that take",
        "Create a function prototype for the OSR routines that"
    ],
    [
        "the OSRSpatialReference object and return a double value.",
        "the OSRSpatialReference object and return"
    ],
    [
        "Create a ctypes function prototype for OSR units functions, e.g.,",
        "Create a ctypes function prototype for OSR units functions,"
    ],
    [
        "This module contains functions that generate ctypes prototypes for the",
        "This module contains functions that generate ctypes"
    ],
    [
        "\"\"\"Generate a ctypes function that returns a boolean value.\"\"\"",
        "\"\"\"Generate a ctypes function that"
    ],
    [
        "def double_output(func, argtypes, errcheck=False, strarg=False, cpl=False):",
        "def double_output(func, argtypes,"
    ],
    [
        "\"Generate a ctypes function that returns a double value.\"",
        "\"Generate a ctypes function that returns a"
    ],
    [
        "Generate a function that returns a Geometry either by reference",
        "Generate a function that returns a Geometry"
    ],
    [
        "or directly (if the return_geom keyword is set to True).",
        "or directly (if the return_geom keyword"
    ],
    [
        "\"Generate a ctypes function that returns an integer value.\"",
        "\"Generate a ctypes function that returns an"
    ],
    [
        "Generate a ctypes prototype for the given function with",
        "Generate a ctypes prototype for the given"
    ],
    [
        "the given C arguments that returns a pointer to an OGR",
        "the given C arguments that returns a pointer"
    ],
    [
        "def const_string_output(func, argtypes, offset=None, decoding=None, cpl=False):",
        "def const_string_output(func, argtypes, offset=None,"
    ],
    [
        "res = check_const_string(result, func, cargs, offset=offset, cpl=cpl)",
        "res = check_const_string(result, func, cargs,"
    ],
    [
        "Generate a ctypes prototype for the given function with the",
        "Generate a ctypes prototype for the given"
    ],
    [
        "given argument types that returns a string from a GDAL pointer.",
        "given argument types that returns a string from a"
    ],
    [
        "The `const` flag indicates whether the allocated pointer should",
        "The `const` flag indicates whether the"
    ],
    [
        "be freed via the GDAL library routine VSIFree -- but only applies",
        "be freed via the GDAL library routine VSIFree -- but"
    ],
    [
        "res = check_string(result, func, cargs, offset=offset, str_result=str_result)",
        "res = check_string(result, func, cargs,"
    ],
    [
        "For functions that don't only return an error code that needs to",
        "For functions that don't only return an"
    ],
    [
        "\"\"\"For functions that return a c_char_p array.\"\"\"",
        "\"\"\"For functions that return a"
    ],
    [
        "from ctypes import POINTER, c_char_p, c_double, c_int, c_void_p",
        "from ctypes import POINTER, c_char_p, c_double, c_int,"
    ],
    [
        "f.errcheck = lambda result, func, cargs: bool(result)",
        "f.errcheck = lambda result, func, cargs:"
    ],
    [
        "set_measured = void_output(lgdal.OGR_G_SetMeasured, [c_void_p, c_int], errcheck=False)",
        "set_measured = void_output(lgdal.OGR_G_SetMeasured, [c_void_p, c_int],"
    ],
    [
        "lgdal.OGR_G_IsEmpty, [c_void_p], errcheck=lambda result, func, cargs: bool(result)",
        "lgdal.OGR_G_IsEmpty, [c_void_p], errcheck=lambda result, func, cargs:"
    ],
    [
        "This module houses the ctypes function prototypes for OGR DataSource",
        "This module houses the ctypes function"
    ],
    [
        "related data structures. OGR_Dr_*, OGR_DS_*, OGR_L_*, OGR_F_*,",
        "related data structures. OGR_Dr_*, OGR_DS_*, OGR_L_*,"
    ],
    [
        "from ctypes import POINTER, c_char_p, c_double, c_int, c_long, c_uint, c_void_p",
        "from ctypes import POINTER, c_char_p, c_double, c_int, c_long, c_uint,"
    ],
    [
        "get_extent = void_output(lgdal.OGR_L_GetExtent, [c_void_p, POINTER(OGREnvelope), c_int])",
        "get_extent = void_output(lgdal.OGR_L_GetExtent, [c_void_p,"
    ],
    [
        "[c_void_p, c_int, c_int_p, c_int_p, c_int_p, c_int_p, c_int_p, c_int_p],",
        "[c_void_p, c_int, c_int_p, c_int_p, c_int_p,"
    ],
    [
        "This module houses the ctypes function prototypes for GDAL DataSource (raster)",
        "This module houses the ctypes function prototypes for GDAL"
    ],
    [
        "from ctypes import POINTER, c_bool, c_char_p, c_double, c_int, c_void_p",
        "from ctypes import POINTER, c_bool, c_char_p, c_double,"
    ],
    [
        "std_call(\"GDALCreate\"), [c_void_p, c_char_p, c_int, c_int, c_int, c_int, c_void_p]",
        "std_call(\"GDALCreate\"), [c_void_p, c_char_p, c_int,"
    ],
    [
        "[c_void_p, c_char_p, c_void_p, c_int, POINTER(c_char_p), c_void_p, c_void_p],",
        "[c_void_p, c_char_p, c_void_p, c_int, POINTER(c_char_p),"
    ],
    [
        "[c_void_p, c_char_p, c_char_p, c_int, c_double, c_void_p],",
        "[c_void_p, c_char_p, c_char_p, c_int,"
    ],
    [
        "This module houses the error-checking routines used by the GDAL",
        "This module houses the error-checking routines used by the"
    ],
    [
        "from django.contrib.gis.gdal.error import GDALException, SRSException, check_err",
        "from django.contrib.gis.gdal.error import GDALException,"
    ],
    [
        "\"Return the pointer argument's by-reference value.\"",
        "\"Return the pointer"
    ],
    [
        "\"Return the pointer argument passed in by-reference.\"",
        "\"Return the pointer argument passed in"
    ],
    [
        "def check_const_string(result, func, cargs, offset=None, cpl=False):",
        "def check_const_string(result, func,"
    ],
    [
        "Similar functionality to `check_string`, but does not free the pointer.",
        "Similar functionality to `check_string`, but does not"
    ],
    [
        "Check the string output returned from the given function, and free",
        "Check the string output returned from the given function, and"
    ],
    [
        "the string pointer allocated by OGR.  The `str_result` keyword",
        "the string pointer allocated by OGR. The"
    ],
    [
        "may be used when the result is the string pointer, otherwise",
        "may be used when the result is the"
    ],
    [
        "the OGR error code is assumed.  The `offset` keyword may be used",
        "the OGR error code is assumed. The `offset`"
    ],
    [
        "to extract the string pointer passed in by-reference at the given",
        "to extract the string pointer passed"
    ],
    [
        "slice offset in the function arguments.",
        "slice offset in the"
    ],
    [
        "\"Check a function that returns an OGR Envelope by reference.\"",
        "\"Check a function that returns an OGR"
    ],
    [
        "\"Check a function that returns a geometry.\"",
        "\"Check a function that"
    ],
    [
        "'Invalid geometry pointer returned from \"%s\".' % func.__name__",
        "'Invalid geometry pointer returned from"
    ],
    [
        "\"Check the geometry at the given offset in the C parameter list.\"",
        "\"Check the geometry at the given offset in the C"
    ],
    [
        "'Invalid spatial reference pointer returned from \"%s\".' % func.__name__",
        "'Invalid spatial reference pointer returned from \"%s\".' %"
    ],
    [
        "The error code is returned in the last argument, by reference.",
        "The error code is returned in"
    ],
    [
        "Check its value with `check_err` before returning the result.",
        "Check its value with `check_err` before returning the"
    ],
    [
        "Check the error code returned (c_int).",
        "Check the error code"
    ],
    [
        "\"Make sure the result pointer is valid.\"",
        "\"Make sure the result pointer"
    ],
    [
        "raise GDALException('Invalid pointer returned from \"%s\"' % func.__name__)",
        "raise GDALException('Invalid pointer returned from \"%s\"' %"
    ],
    [
        "This is for the OSRGet[Angular|Linear]Units functions, which",
        "This is for the OSRGet[Angular|Linear]Units"
    ],
    [
        "require that the returned string pointer not be freed.  This",
        "require that the returned string"
    ],
    [
        "returns both the double and string values.",
        "returns both the double"
    ],
    [
        "from ctypes import byref, c_double, c_int, c_void_p",
        "from ctypes import byref,"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import raster as capi",
        "from django.contrib.gis.gdal.prototypes import raster as"
    ],
    [
        "Wrap a GDAL raster band, needs to be obtained from a GDALRaster object.",
        "Wrap a GDAL raster band, needs to"
    ],
    [
        "Call the flush method on the Band's parent raster and force a refresh",
        "Call the flush method on the Band's parent"
    ],
    [
        "of the statistics attribute when requested the next time.",
        "of the statistics attribute when requested the"
    ],
    [
        "Return the description string of the band.",
        "Return the description string of the"
    ],
    [
        "Width (X axis) in pixels of the band.",
        "Width (X axis) in pixels of the"
    ],
    [
        "Height (Y axis) in pixels of the band.",
        "Height (Y axis) in pixels of"
    ],
    [
        "Return the total number of pixels in this band.",
        "Return the total number of pixels"
    ],
    [
        "Compute statistics on the pixel values of this band.",
        "Compute statistics on the pixel values of this"
    ],
    [
        "The return value is a tuple with the following structure:",
        "The return value is a"
    ],
    [
        "If approximate=True, the statistics may be computed based on overviews",
        "If approximate=True, the statistics may be computed based on"
    ],
    [
        "or a subset of image tiles.",
        "or a subset"
    ],
    [
        "If refresh=True, the statistics will be computed from the data directly,",
        "If refresh=True, the statistics will be"
    ],
    [
        "and the cache will be updated where applicable.",
        "and the cache will be"
    ],
    [
        "For empty bands (where all pixel values are nodata), all statistics",
        "For empty bands (where all pixel values"
    ],
    [
        "For raster formats using Persistent Auxiliary Metadata (PAM) services,",
        "For raster formats using Persistent"
    ],
    [
        "the statistics might be cached in an auxiliary file.",
        "the statistics might be cached"
    ],
    [
        "smin, smax, smean, sstd = c_double(), c_double(), c_double(), c_double()",
        "smin, smax, smean, sstd = c_double(), c_double(),"
    ],
    [
        "result = smin.value, smax.value, smean.value, sstd.value",
        "result = smin.value, smax.value, smean.value,"
    ],
    [
        "result = (None, None, None, None)",
        "result = (None, None, None,"
    ],
    [
        "Return the minimum pixel value for this band.",
        "Return the minimum pixel value for this"
    ],
    [
        "Return the maximum pixel value for this band.",
        "Return the maximum pixel value for"
    ],
    [
        "Return the mean of all pixel values of this band.",
        "Return the mean of all pixel values"
    ],
    [
        "Return the standard deviation of all pixel values of this band.",
        "Return the standard deviation of all"
    ],
    [
        "Return the nodata value for this band, or None if it isn't set.",
        "Return the nodata value for this band, or None if it"
    ],
    [
        "Set the nodata value for this band.",
        "Set the nodata value for this"
    ],
    [
        "raise ValueError(\"Nodata value must be numeric or None.\")",
        "raise ValueError(\"Nodata value must be numeric"
    ],
    [
        "Return the GDAL Pixel Datatype for this band.",
        "Return the GDAL Pixel Datatype for this"
    ],
    [
        "\"\"\"Return the GDAL color interpretation for this band.\"\"\"",
        "\"\"\"Return the GDAL color interpretation"
    ],
    [
        "def data(self, data=None, offset=None, size=None, shape=None, as_memoryview=False):",
        "def data(self, data=None, offset=None,"
    ],
    [
        "Read or writes pixel values for this band. Blocks of data can",
        "Read or writes pixel values for"
    ],
    [
        "be accessed by specifying the width, height and offset of the",
        "be accessed by specifying the width, height and offset of"
    ],
    [
        "desired block. The same specification can be used to update",
        "desired block. The same specification can be used to"
    ],
    [
        "parts of a raster by providing an array of values.",
        "parts of a raster by providing"
    ],
    [
        "Allowed input data types are bytes, memoryview, list, tuple, and array.",
        "Allowed input data types are bytes, memoryview, list,"
    ],
    [
        "raise ValueError(\"Offset too big for this raster.\")",
        "raise ValueError(\"Offset too big for"
    ],
    [
        "raise ValueError(\"Size is larger than raster.\")",
        "raise ValueError(\"Size is"
    ],
    [
        "if isinstance(data, (bytes, memoryview)) or (",
        "if isinstance(data, (bytes, memoryview))"
    ],
    [
        "raise GDALException(\"Unable to get band index %d\" % index)",
        "raise GDALException(\"Unable to get band"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import raster as capi",
        "from django.contrib.gis.gdal.prototypes import raster"
    ],
    [
        "Wrap a raster GDAL Data Source object.",
        "Wrap a raster GDAL Data Source"
    ],
    [
        "if not ds_input.startswith(VSI_FILESYSTEM_PREFIX) and not os.path.exists(",
        "if not ds_input.startswith(VSI_FILESYSTEM_PREFIX)"
    ],
    [
        "'Unable to read raster source input \"%s\".' % ds_input",
        "'Unable to read raster source input \"%s\".'"
    ],
    [
        "'Could not open the datasource at \"{}\" ({}).'.format(ds_input, err)",
        "'Could not open the datasource at"
    ],
    [
        "raise GDALException(\"Failed creating VSI raster from the input buffer.\")",
        "raise GDALException(\"Failed creating VSI raster from the input"
    ],
    [
        "if driver.name != \"MEM\" and \"name\" not in ds_input:",
        "if driver.name != \"MEM\" and \"name\""
    ],
    [
        "'Specify name for creation of raster with driver \"{}\".'.format(",
        "'Specify name for creation of raster with"
    ],
    [
        "if \"width\" not in ds_input or \"height\" not in ds_input:",
        "if \"width\" not in ds_input"
    ],
    [
        "\"Specify width and height attributes for JSON or dict input.\"",
        "\"Specify width and height attributes"
    ],
    [
        "raise GDALException(\"Specify srid for JSON or dict input.\")",
        "raise GDALException(\"Specify srid for"
    ],
    [
        "for key, val in ds_input.get(\"papsz_options\", {}).items():",
        "for key, val"
    ],
    [
        "for i, band_input in enumerate(ds_input.get(\"bands\", [])):",
        "for i, band_input in"
    ],
    [
        "if band.nodata_value is not None and (",
        "if band.nodata_value is not None and"
    ],
    [
        "'Invalid data source input type: \"{}\".'.format(type(ds_input))",
        "'Invalid data source"
    ],
    [
        "Short-hand representation because WKB may be very large.",
        "Short-hand representation because WKB may be"
    ],
    [
        "return \"<Raster object at %s>\" % hex(addressof(self._ptr))",
        "return \"<Raster object at %s>\" %"
    ],
    [
        "Flush all data from memory into the source file if it exists.",
        "Flush all data from memory into the source file"
    ],
    [
        "The data that needs flushing are geotransforms, coordinate systems,",
        "The data that needs flushing are"
    ],
    [
        "nodata_values and pixel values. This function will be called",
        "nodata_values and pixel values. This function will be"
    ],
    [
        "\"Raster needs to be opened in write mode to change values.\"",
        "\"Raster needs to be opened in write"
    ],
    [
        "Return the name of this raster. Corresponds to filename",
        "Return the name of this raster."
    ],
    [
        "Return the GDAL Driver used for this raster.",
        "Return the GDAL Driver"
    ],
    [
        "Return the SpatialReference used in this GDALRaster.",
        "Return the SpatialReference used"
    ],
    [
        "Set the spatial reference used in this GDALRaster. The input can be",
        "Set the spatial reference used in this GDALRaster. The input"
    ],
    [
        "a SpatialReference or any parameter accepted by the SpatialReference",
        "a SpatialReference or any parameter accepted by"
    ],
    [
        "raise ValueError(\"Could not create a SpatialReference from input.\")",
        "raise ValueError(\"Could not create a"
    ],
    [
        "Shortcut to access the srid of this GDALRaster.",
        "Shortcut to access the srid of"
    ],
    [
        "Shortcut to set this GDALRaster's srs from an srid.",
        "Shortcut to set this GDALRaster's srs from"
    ],
    [
        "Return the geotransform of the data source.",
        "Return the geotransform of"
    ],
    [
        "Return the default geotransform if it does not exist or has not been",
        "Return the default geotransform if it does not"
    ],
    [
        "\"Set the geotransform for the data source.\"",
        "\"Set the geotransform for"
    ],
    [
        "Pixel scale in units of the raster projection.",
        "Pixel scale in units"
    ],
    [
        "xval = self.origin.x + self.scale.x * self.width",
        "xval = self.origin.x + self.scale.x *"
    ],
    [
        "yval = self.origin.y + self.scale.y * self.height",
        "yval = self.origin.y + self.scale.y *"
    ],
    [
        "Return a warped GDALRaster with the given input characteristics.",
        "Return a warped GDALRaster with the given input"
    ],
    [
        "The input is expected to be a dictionary containing the parameters",
        "The input is expected to be a dictionary containing"
    ],
    [
        "of the target raster. Allowed values are width, height, SRID, origin,",
        "of the target raster. Allowed values are width, height, SRID,"
    ],
    [
        "scale, skew, datatype, driver, and name (filename).",
        "scale, skew, datatype, driver, and name"
    ],
    [
        "By default, the warp functions keeps all parameters equal to the values",
        "By default, the warp functions keeps all parameters equal to"
    ],
    [
        "of the original source raster. For the name of the target raster, the",
        "of the original source raster. For the name of the target"
    ],
    [
        "name of the source raster will be used and appended with",
        "name of the source raster will"
    ],
    [
        "In addition, the resampling algorithm can be specified with the \"resampling\"",
        "In addition, the resampling algorithm can be specified with the"
    ],
    [
        "input parameter. The default is NearestNeighbor. For a list of all options",
        "input parameter. The default is NearestNeighbor. For a list of all"
    ],
    [
        "ds_input[\"name\"] = self.name + \"_copy.\" + self.driver.name",
        "ds_input[\"name\"] = self.name +"
    ],
    [
        "ds_input[\"bands\"] = [{\"nodata_value\": bnd.nodata_value} for bnd in self.bands]",
        "ds_input[\"bands\"] = [{\"nodata_value\": bnd.nodata_value}"
    ],
    [
        "\"\"\"Return a clone of this GDALRaster.\"\"\"",
        "\"\"\"Return a clone of this"
    ],
    [
        "clone_name = self.name + \"_copy.\" + self.driver.name",
        "clone_name = self.name +"
    ],
    [
        "Return a copy of this raster reprojected into the given spatial",
        "Return a copy of this raster reprojected into the given"
    ],
    [
        "\"Transform only accepts SpatialReference, string, and integer \"",
        "\"Transform only accepts SpatialReference, string, and integer"
    ],
    [
        "if target_srs.srid == self.srid and (not driver or driver == self.driver.name):",
        "if target_srs.srid == self.srid and (not driver or driver"
    ],
    [
        "Return information about this raster in a string format equivalent",
        "Return information about this raster in a string"
    ],
    [
        "to the output of the gdalinfo command line utility.",
        "to the output of the gdalinfo"
    ],
    [
        "from django.contrib.gis.gdal.prototypes import raster as capi",
        "from django.contrib.gis.gdal.prototypes import"
    ],
    [
        "Attributes that exist on both GDALRaster and GDALBand.",
        "Attributes that exist on both"
    ],
    [
        "Return the metadata for this raster or band. The return value is a",
        "Return the metadata for this raster or band. The"
    ],
    [
        "nested dictionary, where the first-level key is the metadata domain and",
        "nested dictionary, where the first-level key"
    ],
    [
        "the second-level is the metadata item names and values for that domain.",
        "the second-level is the metadata item names"
    ],
    [
        "(None if domain == \"DEFAULT\" else domain.encode()),",
        "(None if domain == \"DEFAULT\""
    ],
    [
        "Set the metadata. Update only the domains that are contained in the",
        "Set the metadata. Update only the domains that"
    ],
    [
        "domain = None if domain == \"DEFAULT\" else domain.encode()",
        "domain = None if domain =="
    ],
    [
        "from django.core.management.commands.inspectdb import Command as InspectDBCommand",
        "from django.core.management.commands.inspectdb import Command"
    ],
    [
        "Custom argparse action for the `ogrinspect` `layer_key` keyword option",
        "Custom argparse action for the `ogrinspect` `layer_key` keyword"
    ],
    [
        "which may be an integer or a string.",
        "which may be an integer"
    ],
    [
        "def __call__(self, parser, namespace, value, option_string=None):",
        "def __call__(self, parser, namespace,"
    ],
    [
        "Custom argparse action for `ogrinspect` keywords that require",
        "Custom argparse action for"
    ],
    [
        "a string list. If the string is 'True'/'true' then the option",
        "a string list. If the string is 'True'/'true' then"
    ],
    [
        "value will be a boolean instead.",
        "value will be a"
    ],
    [
        "def __call__(self, parser, namespace, value, option_string=None):",
        "def __call__(self, parser, namespace,"
    ],
    [
        "\"Inspects the given OGR-compatible data source (e.g., a shapefile) and \"",
        "\"Inspects the given OGR-compatible data source (e.g., a"
    ],
    [
        "\"outputs\\na GeoDjango model with the given model name. For example:\\n\"",
        "\"outputs\\na GeoDjango model with the given"
    ],
    [
        "parser.add_argument(\"data_source\", help=\"Path to the data source.\")",
        "parser.add_argument(\"data_source\", help=\"Path to the data"
    ],
    [
        "parser.add_argument(\"model_name\", help=\"Name of the model to create.\")",
        "parser.add_argument(\"model_name\", help=\"Name of the model"
    ],
    [
        "help=\"Use a comma separated list of OGR field names to add \"",
        "help=\"Use a comma separated list of OGR field"
    ],
    [
        "\"the `blank=True` option to the field definition. Set to `true` \"",
        "\"the `blank=True` option to the field definition. Set to `true`"
    ],
    [
        "\"to apply to all applicable fields.\",",
        "\"to apply to all"
    ],
    [
        "help=\"Use a comma separated list of OGR float fields to \"",
        "help=\"Use a comma separated list of OGR float fields"
    ],
    [
        "\"generate `DecimalField` instead of the default \"",
        "\"generate `DecimalField` instead of"
    ],
    [
        "\"`FloatField`. Set to `true` to apply to all OGR float fields.\",",
        "\"`FloatField`. Set to `true` to apply to all"
    ],
    [
        "help=\"Specifies the model name for the Geometry Field (defaults to `geom`)\",",
        "help=\"Specifies the model name for the Geometry Field (defaults to"
    ],
    [
        "help=\"The key for specifying which layer in the OGR data \"",
        "help=\"The key for specifying which layer in the OGR data"
    ],
    [
        "\"an integer or a string identifier for the layer.\",",
        "\"an integer or a string identifier"
    ],
    [
        "help=\"Treat the geometry in the data source as a geometry collection.\",",
        "help=\"Treat the geometry in the data source"
    ],
    [
        "help=\"Specifies a field name to return for the __str__() method.\",",
        "help=\"Specifies a field name to return for the"
    ],
    [
        "help=\"Do not include `from django.contrib.gis.db import models` statement.\",",
        "help=\"Do not include `from django.contrib.gis.db import models`"
    ],
    [
        "help=\"Use a comma separated list of OGR field names to add \"",
        "help=\"Use a comma separated list of OGR"
    ],
    [
        "\"the `null=True` option to the field definition. Set to `true` \"",
        "\"the `null=True` option to the field definition."
    ],
    [
        "\"to apply to all applicable fields.\",",
        "\"to apply to all applicable"
    ],
    [
        "help=\"The SRID to use for the Geometry Field. If it can be \"",
        "help=\"The SRID to use for the Geometry"
    ],
    [
        "\"determined, the SRID of the data source is used.\",",
        "\"determined, the SRID of the data"
    ],
    [
        "help=\"Generate mapping dictionary for use with `LayerMapping`.\",",
        "help=\"Generate mapping dictionary for use with"
    ],
    [
        "if k in get_func_args(_ogrinspect) and v is not None",
        "if k in get_func_args(_ogrinspect) and v is"
    ],
    [
        "output = [s for s in _ogrinspect(ds, model_name, **ogr_options)]",
        "output = [s for s in _ogrinspect(ds,"
    ],
    [
        "rev_mapping = {v: k for k, v in mapping_dict.items()}",
        "rev_mapping = {v: k for"
    ],
    [
        "\"    '%s': '%s',\" % (rev_mapping[ogr_fld], ogr_fld)",
        "\" '%s': '%s',\" % (rev_mapping[ogr_fld],"
    ],
    [
        "Take a GDAL SpatialReference system and add its information to the",
        "Take a GDAL SpatialReference system and add its information to"
    ],
    [
        "`spatial_ref_sys` table of the spatial backend. Doing this enables",
        "`spatial_ref_sys` table of the spatial backend."
    ],
    [
        "database-level spatial transformations for the backend.  Thus, this utility",
        "database-level spatial transformations for the backend."
    ],
    [
        "is useful for adding spatial reference systems not included by default with",
        "is useful for adding spatial reference"
    ],
    [
        "This keyword may be customized with the value of the `auth_name` field.",
        "This keyword may be customized with the value of"
    ],
    [
        "This keyword may be customized with the value of the `auth_srid` field.",
        "This keyword may be customized with the value"
    ],
    [
        "Defaults to the SRID determined by GDAL.",
        "Defaults to the SRID"
    ],
    [
        "For SpatiaLite users only, sets the value of the `ref_sys_name` field.",
        "For SpatiaLite users only, sets the"
    ],
    [
        "Defaults to the name determined by GDAL.",
        "Defaults to the name determined by"
    ],
    [
        "The name of the database connection to use; the default is the value",
        "The name of the database connection to use; the"
    ],
    [
        "of `django.db.DEFAULT_DB_ALIAS` (at the time of this writing, its value",
        "of `django.db.DEFAULT_DB_ALIAS` (at the time of this writing,"
    ],
    [
        "raise Exception(\"The `add_srs_entry` utility only works with spatial backends.\")",
        "raise Exception(\"The `add_srs_entry` utility only works with spatial"
    ],
    [
        "raise Exception(\"This utility does not support your database backend.\")",
        "raise Exception(\"This utility does not support your"
    ],
    [
        "\"Spatial reference requires an SRID to be \"",
        "\"Spatial reference requires an"
    ],
    [
        "srs_field_names = {f.name for f in SpatialRefSys._meta.get_fields()}",
        "srs_field_names = {f.name for f in"
    ],
    [
        "This module is for inspecting OGR data sources and generating either",
        "This module is for inspecting OGR data sources"
    ],
    [
        "models for GeoDjango and/or mapping dictionaries for use with the",
        "models for GeoDjango and/or mapping dictionaries"
    ],
    [
        "Given a DataSource, generate a dictionary that may be used",
        "Given a DataSource, generate a dictionary that may"
    ],
    [
        "`geom_name` => The name of the geometry field to use for the model.",
        "`geom_name` => The name of the geometry field to use for the"
    ],
    [
        "`layer_key` => The key for specifying which layer in the DataSource to use;",
        "`layer_key` => The key for specifying which layer in the DataSource to"
    ],
    [
        "`multi_geom` => Boolean (default: False) - specify as multigeometry.",
        "`multi_geom` => Boolean (default: False) - specify as"
    ],
    [
        "\"Data source parameter must be a string or a DataSource object.\"",
        "\"Data source parameter must be a string or a DataSource"
    ],
    [
        "Given a data source (either a string or a DataSource object) and a string",
        "Given a data source (either a string or a DataSource object) and a"
    ],
    [
        "model name this function will generate a GeoDjango model.",
        "model name this function will generate a"
    ],
    [
        "...will print model definition to stout",
        "...will print model definition"
    ],
    [
        "or put this in a Python script and use to redirect the output to a new",
        "or put this in a Python script and use to redirect the output"
    ],
    [
        "`datasource` => string or DataSource object to file pointer",
        "`datasource` => string or DataSource object"
    ],
    [
        "`model name` => string of name of new model class to create",
        "`model name` => string of name"
    ],
    [
        "`geom_name` => For specifying the model name for the Geometry Field.",
        "`geom_name` => For specifying the model"
    ],
    [
        "`layer_key` => The key for specifying which layer in the DataSource to use;",
        "`layer_key` => The key for specifying which layer in"
    ],
    [
        "`srid` => The SRID to use for the Geometry Field.  If it can be determined,",
        "`srid` => The SRID to use for the Geometry Field."
    ],
    [
        "the SRID of the datasource is used.",
        "the SRID of the datasource is"
    ],
    [
        "`multi_geom` => Boolean (default: False) - specify as multigeometry.",
        "`multi_geom` => Boolean (default: False) -"
    ],
    [
        "`name_field` => String - specifies a field name to return for the",
        "`name_field` => String - specifies a field name to"
    ],
    [
        "__str__() method (which will be generated if specified).",
        "__str__() method (which will be generated"
    ],
    [
        "`imports` => Boolean (default: True) - set to False to omit the",
        "`imports` => Boolean (default: True) -"
    ],
    [
        "`from django.contrib.gis.db import models` code from the",
        "`from django.contrib.gis.db import models` code from"
    ],
    [
        "autogenerated models thus avoiding duplicated imports when building",
        "autogenerated models thus avoiding duplicated imports"
    ],
    [
        "more than one model by batching ogrinspect()",
        "more than one model by batching"
    ],
    [
        "`decimal` => Boolean or sequence (default: False).  When set to True",
        "`decimal` => Boolean or sequence (default: False)."
    ],
    [
        "all generated model fields corresponding to the `OFTReal` type will",
        "all generated model fields corresponding to"
    ],
    [
        "be `DecimalField` instead of `FloatField`.  A sequence of specific",
        "be `DecimalField` instead of `FloatField`. A sequence of"
    ],
    [
        "field names to generate as `DecimalField` may also be used.",
        "field names to generate as"
    ],
    [
        "`blank` => Boolean or sequence (default: False).  When set to True all",
        "`blank` => Boolean or sequence (default: False). When set"
    ],
    [
        "generated model fields will have `blank=True`.  If the user wants to",
        "generated model fields will have `blank=True`. If"
    ],
    [
        "give specific fields to have blank, then a list/tuple of OGR field",
        "give specific fields to have blank, then"
    ],
    [
        "`null` => Boolean (default: False) - When set to True all generated",
        "`null` => Boolean (default: False) -"
    ],
    [
        "model fields will have `null=True`.  If the user wants to specify",
        "model fields will have `null=True`. If the"
    ],
    [
        "give specific fields to have null, then a list/tuple of OGR field",
        "give specific fields to have null, then a list/tuple of"
    ],
    [
        "Note: Call the _ogrinspect() helper to do the heavy lifting.",
        "Note: Call the _ogrinspect() helper to do the heavy"
    ],
    [
        "Helper routine for `ogrinspect` that generates GeoDjango models corresponding",
        "Helper routine for `ogrinspect` that generates"
    ],
    [
        "to the given data source.  See the `ogrinspect` docstring for more details.",
        "to the given data source. See the `ogrinspect` docstring for"
    ],
    [
        "\"Data source parameter must be a string or a DataSource object.\"",
        "\"Data source parameter must be a string or"
    ],
    [
        "return [s.lower() for s in kwarg]",
        "return [s.lower() for s in"
    ],
    [
        "return [s.lower() for s in ogr_fields]",
        "return [s.lower() for"
    ],
    [
        "return \", \" + \", \".join(kwlist)",
        "return \", \" + \","
    ],
    [
        "for field_name, width, precision, field_type in zip(",
        "for field_name, width, precision, field_type"
    ],
    [
        "yield \"    %s = models.CharField(max_length=%s%s)\" % (",
        "yield \" %s = models.CharField(max_length=%s%s)\""
    ],
    [
        "raise TypeError(\"Unknown field type %s in %s\" % (field_type, mfield))",
        "raise TypeError(\"Unknown field type %s in"
    ],
    [
        "yield \"    %s = models.%s(%s)\" % (geom_name, geom_field, srid_str)",
        "yield \" %s = models.%s(%s)\" % (geom_name,"
    ],
    [
        "yield \"    def __str__(self): return self.%s\" % name_field",
        "yield \" def __str__(self): return self.%s\" %"
    ],
    [
        "This module contains useful utilities for GeoDjango.",
        "This module contains useful"
    ],
    [
        "The LayerMapping class provides a way to map the contents of OGR",
        "The LayerMapping class provides a way to"
    ],
    [
        "vector files (e.g. SHP files) to Geographic-enabled Django models.",
        "vector files (e.g. SHP files) to Geographic-enabled"
    ],
    [
        "For more information, please consult the GeoDjango documentation:",
        "For more information, please consult the"
    ],
    [
        "from decimal import InvalidOperation as DecimalInvalidOperation",
        "from decimal import InvalidOperation as"
    ],
    [
        "from django.db import connections, models, router, transaction",
        "from django.db import connections, models, router,"
    ],
    [
        "\"A class that maps OGR Layers to GeoDjango Models.\"",
        "\"A class that maps OGR Layers to GeoDjango"
    ],
    [
        "A LayerMapping object is initialized using the given Model (not an instance),",
        "A LayerMapping object is initialized using"
    ],
    [
        "a DataSource (or string path to an OGR-supported data file), and a mapping",
        "a DataSource (or string path to an OGR-supported data file),"
    ],
    [
        "dictionary.  See the module level docstring for more details and keyword",
        "dictionary. See the module level docstring for"
    ],
    [
        "self.using = using if using is not None else router.db_for_write(model)",
        "self.using = using if using"
    ],
    [
        "raise LayerMapError(\"Unrecognized transaction mode: %s\" % transaction_mode)",
        "raise LayerMapError(\"Unrecognized transaction mode:"
    ],
    [
        "Check the Layer metadata and ensure that it's compatible with the",
        "Check the Layer metadata and ensure that it's compatible with"
    ],
    [
        "mapping information and model. Unlike previous revisions, there is no",
        "mapping information and model. Unlike previous"
    ],
    [
        "need to increment through each feature in the Layer.",
        "need to increment through each"
    ],
    [
        "'Given mapping OGR field \"%s\" not found in OGR Layer.' % ogr_map_fld",
        "'Given mapping OGR field \"%s\" not found in OGR"
    ],
    [
        "'Given mapping field \"%s\" not in given Model fields.' % field_name",
        "'Given mapping field \"%s\" not in"
    ],
    [
        "\"LayerMapping does not support more than one GeometryField per \"",
        "\"LayerMapping does not support more than"
    ],
    [
        "'Invalid mapping for GeometryField \"%s\".' % field_name",
        "'Invalid mapping for GeometryField \"%s\".'"
    ],
    [
        "\"Invalid mapping geometry; model has %s%s, \"",
        "\"Invalid mapping geometry; model"
    ],
    [
        "'ForeignKey mapping field \"%s\" not in %s fields.'",
        "'ForeignKey mapping field \"%s\" not in %s"
    ],
    [
        "raise TypeError(\"ForeignKey mapping must be of dictionary type.\")",
        "raise TypeError(\"ForeignKey mapping must be of dictionary"
    ],
    [
        "'Django field type \"%s\" has no OGR mapping (yet).' % fld_name",
        "'Django field type \"%s\" has no OGR mapping (yet).' %"
    ],
    [
        "'OGR field \"%s\" (of type %s) cannot be mapped to Django %s.'",
        "'OGR field \"%s\" (of type %s) cannot be mapped to Django"
    ],
    [
        "\"Check the compatibility of the given spatial reference object.\"",
        "\"Check the compatibility of the given"
    ],
    [
        "raise LayerMapError(\"No source reference system defined.\")",
        "raise LayerMapError(\"No source reference system"
    ],
    [
        "\"Check the `unique` keyword parameter -- may be a sequence or string.\"",
        "\"Check the `unique` keyword parameter -- may be a"
    ],
    [
        "\"Unique keyword argument must be set with a tuple, list, or string.\"",
        "\"Unique keyword argument must be set with a tuple,"
    ],
    [
        "Given an OGR Feature, return a dictionary of keyword arguments for",
        "Given an OGR Feature, return a dictionary of keyword arguments"
    ],
    [
        "raise LayerMapError(\"Could not retrieve geometry from feature.\")",
        "raise LayerMapError(\"Could not retrieve geometry"
    ],
    [
        "Given the feature keyword arguments (from `feature_kwargs`), construct",
        "Given the feature keyword arguments (from `feature_kwargs`),"
    ],
    [
        "and return the uniqueness keyword arguments -- a subset of the feature",
        "and return the uniqueness keyword arguments -- a"
    ],
    [
        "return {fld: kwargs[fld] for fld in self.unique}",
        "return {fld: kwargs[fld] for fld"
    ],
    [
        "Verify if the OGR Field contents are acceptable to the model field. If",
        "Verify if the OGR Field contents are acceptable"
    ],
    [
        "they are, return the verified value, otherwise raise an exception.",
        "they are, return the verified value, otherwise raise an"
    ],
    [
        "if self.encoding and ogr_field.value is not None:",
        "if self.encoding and ogr_field.value"
    ],
    [
        "\"%s model field maximum string length is %s, given %s characters.\"",
        "\"%s model field maximum string length is %s, given"
    ],
    [
        "\"Could not construct decimal from: %s\" % ogr_field.value",
        "\"Could not construct decimal from:"
    ],
    [
        "\"A DecimalField with max_digits %d, decimal_places %d must \"",
        "\"A DecimalField with max_digits %d,"
    ],
    [
        "elif isinstance(ogr_field, (OFTReal, OFTString)) and isinstance(",
        "elif isinstance(ogr_field, (OFTReal, OFTString))"
    ],
    [
        "\"Could not construct integer from: %s\" % ogr_field.value",
        "\"Could not construct integer from: %s\" %"
    ],
    [
        "Given an OGR Feature, the related model and its dictionary mapping,",
        "Given an OGR Feature, the related"
    ],
    [
        "retrieve the related model for the ForeignKey mapping.",
        "retrieve the related model for the"
    ],
    [
        "\"No ForeignKey %s model found with keyword arguments: %s\"",
        "\"No ForeignKey %s model found"
    ],
    [
        "Verify the geometry -- construct and return a GeometryCollection",
        "Verify the geometry -- construct"
    ],
    [
        "if necessary (for example if the model field is MultiPolygonField while",
        "if necessary (for example if the"
    ],
    [
        "the mapped shapefile only contains Polygons).",
        "the mapped shapefile only contains"
    ],
    [
        "\"Could not translate between the data source and model geometry.\"",
        "\"Could not translate between the data source and"
    ],
    [
        "\"Return the GeometryField instance associated with the geographic column.\"",
        "\"Return the GeometryField instance associated with the"
    ],
    [
        "Given the OGRGeomType for a geometry and its associated GeometryField,",
        "Given the OGRGeomType for a geometry and"
    ],
    [
        "determine whether the geometry should be turned into a GeometryCollection.",
        "determine whether the geometry should"
    ],
    [
        "and model_field.__class__.__name__ == \"Multi%s\" % geom_type.django",
        "and model_field.__class__.__name__ == \"Multi%s\""
    ],
    [
        "Save the contents from the OGR DataSource Layer into the database",
        "Save the contents from the OGR"
    ],
    [
        "according to the mapping dictionary given at initialization.",
        "according to the mapping dictionary given"
    ],
    [
        "If set, information will be printed subsequent to each model save",
        "If set, information will be printed subsequent to each"
    ],
    [
        "May be set with a slice or tuple of (begin, end) feature ID's to map",
        "May be set with a slice or tuple of (begin,"
    ],
    [
        "from the data source.  In other words, this keyword enables the user",
        "from the data source. In other words, this keyword enables the"
    ],
    [
        "to selectively import a subset range of features in the geographic",
        "to selectively import a subset range of"
    ],
    [
        "If set with an integer, transactions will occur at every step",
        "If set with an integer, transactions will occur at"
    ],
    [
        "When this keyword is set, status information will be printed giving",
        "When this keyword is set, status information will be printed"
    ],
    [
        "the number of features processed and successfully saved.  By default,",
        "the number of features processed and successfully saved. By"
    ],
    [
        "however, this default may be overridden by setting this keyword with an",
        "however, this default may be overridden"
    ],
    [
        "Status information will be written to this file handle.  Defaults to",
        "Status information will be written to this file handle."
    ],
    [
        "using `sys.stdout`, but any object with a `write` method is supported.",
        "using `sys.stdout`, but any object with a `write` method is"
    ],
    [
        "By default, non-fatal error notifications are printed to stdout, but",
        "By default, non-fatal error notifications are"
    ],
    [
        "this keyword may be set to disable these notifications.",
        "this keyword may be set to"
    ],
    [
        "Execution of the model mapping will cease upon the first error",
        "Execution of the model mapping will cease"
    ],
    [
        "encountered.  The default behavior is to attempt to continue.",
        "encountered. The default behavior is to attempt"
    ],
    [
        "if progress is True or not isinstance(progress, int):",
        "if progress is True or not isinstance(progress,"
    ],
    [
        "\"Ignoring Feature ID %s because: %s\\n\" % (feat.fid, msg)",
        "\"Ignoring Feature ID %s because: %s\\n\" % (feat.fid,"
    ],
    [
        "\"%s: %s\\n\" % (\"Updated\" if is_update else \"Saved\", m)",
        "\"%s: %s\\n\" % (\"Updated\" if is_update"
    ],
    [
        "\"Failed to save the feature (id: %s) into the \"",
        "\"Failed to save the feature (id:"
    ],
    [
        "\"model with the keyword arguments:\\n\" % feat.fid",
        "\"model with the keyword arguments:\\n\" %"
    ],
    [
        "\"Failed to save %s:\\n %s\\nContinuing\\n\" % (kwargs, msg)",
        "\"Failed to save %s:\\n %s\\nContinuing\\n\" % (kwargs,"
    ],
    [
        "\"Processed %d features, saved %d ...\\n\" % (num_feat, num_saved)",
        "\"Processed %d features, saved %d ...\\n\""
    ],
    [
        "if step and isinstance(step, int) and step < nfeat:",
        "if step and isinstance(step, int) and step"
    ],
    [
        "\"The `step` keyword may not be used in conjunction with the \"",
        "\"The `step` keyword may not be"
    ],
    [
        "num_feat, num_saved = _save(step_slice, num_feat, num_saved)",
        "num_feat, num_saved = _save(step_slice, num_feat,"
    ],
    [
        "This module includes some utility functions for inspecting the layout",
        "This module includes some utility functions"
    ],
    [
        "of a GDAL data source -- the functionality is analogous to the output",
        "of a GDAL data source -- the functionality is analogous to"
    ],
    [
        "Walk the available layers in the supplied `data_source`, displaying",
        "Walk the available layers in the supplied"
    ],
    [
        "the fields for the first `num_features` features.",
        "the fields for the first `num_features`"
    ],
    [
        "\"Data source parameter must be a string or a DataSource object.\"",
        "\"Data source parameter must be a string"
    ],
    [
        "print(\"data source : %s\" % data_source.name)",
        "print(\"data source : %s\""
    ],
    [
        "print(\"  shape type: %s\" % GEO_CLASSES[layer.geom_type.num].__name__)",
        "print(\" shape type: %s\""
    ],
    [
        "print(\"Displaying the first %s features ====\" % num_features)",
        "print(\"Displaying the first %s features ====\" %"
    ],
    [
        "fmt = \" %%%ss: %%s\" % width",
        "fmt = \" %%%ss: %%s\" %"
    ],
    [
        "output = fmt % (fld_name, type_name)",
        "output = fmt"
    ],
    [
        "from django.core.serializers.json import Serializer as JSONSerializer",
        "from django.core.serializers.json import"
    ],
    [
        "Convert a queryset to GeoJSON, http://geojson.org/",
        "Convert a queryset"
    ],
    [
        "\"id\": obj.pk if self.id_field is None else getattr(obj, self.id_field),",
        "\"id\": obj.pk if self.id_field is None else getattr(obj,"
    ],
    [
        "self.selected_fields is None or \"pk\" in self.selected_fields",
        "self.selected_fields is None or \"pk\""
    ],
    [
        ") and \"pk\" not in data[\"properties\"]:",
        ") and \"pk\" not"
    ],
    [
        "raise SerializerDoesNotExist(\"geojson is a serialization-only serializer\")",
        "raise SerializerDoesNotExist(\"geojson is a"
    ],
    [
        "A minimal hook to produce KML sitemaps.",
        "A minimal hook to"
    ],
    [
        "label, module name, and field name of every GeometryField encountered",
        "label, module name, and field name"
    ],
    [
        "If no sources are provided, then all models.",
        "If no sources are provided, then all"
    ],
    [
        "This method is overridden so the appropriate `geo_format` attribute",
        "This method is overridden so the appropriate `geo_format`"
    ],
    [
        "is placed on each URL element.",
        "is placed on"
    ],
    [
        "urls = Sitemap.get_urls(self, page=page, site=site, protocol=protocol)",
        "urls = Sitemap.get_urls(self, page=page,"
    ],
    [
        "def kml(request, label, model, field_name=None, compress=False, using=DEFAULT_DB_ALIAS):",
        "def kml(request, label, model, field_name=None,"
    ],
    [
        "This view generates KML for the given app label, model, and field name.",
        "This view generates KML for the given app label, model, and field"
    ],
    [
        "The field name must be that of a geographic field.",
        "The field name must be that of"
    ],
    [
        "'You must supply a valid app label and module name.  Got \"%s.%s\"'",
        "'You must supply a valid app label and module"
    ],
    [
        "def kmz(request, label, model, field_name=None, using=DEFAULT_DB_ALIAS):",
        "def kmz(request, label, model, field_name=None,"
    ],
    [
        "Return KMZ for the given app label, model, and field name.",
        "Return KMZ for the given app"
    ],
    [
        "return kml(request, label, model, field_name, compress=True, using=using)",
        "return kml(request, label, model,"
    ],
    [
        "A collection of utility routines and classes used by the spatial",
        "A collection of utility routines and classes used"
    ],
    [
        "Class encapsulating the behavior specific to a GIS operation (used by lookups).",
        "Class encapsulating the behavior specific to"
    ],
    [
        "def as_sql(self, connection, lookup, template_params, sql_params):",
        "def as_sql(self, connection, lookup, template_params,"
    ],
    [
        "sql_template = self.sql_template or lookup.sql_template or self.default_template",
        "sql_template = self.sql_template or"
    ],
    [
        "The GeometryColumns and SpatialRefSys models for the Oracle spatial",
        "The GeometryColumns and SpatialRefSys models for the Oracle"
    ],
    [
        "It should be noted that Oracle Spatial does not have database tables",
        "It should be noted that Oracle Spatial does not"
    ],
    [
        "named according to the OGC standard, so the closest analogs are used.",
        "named according to the OGC standard, so the closest analogs"
    ],
    [
        "For example, the `USER_SDO_GEOM_METADATA` is used for the GeometryColumns",
        "For example, the `USER_SDO_GEOM_METADATA` is used for"
    ],
    [
        "model and the `SDO_COORD_REF_SYS` is used for the SpatialRefSys model.",
        "model and the `SDO_COORD_REF_SYS` is used for the SpatialRefSys"
    ],
    [
        "\"Maps to the Oracle USER_SDO_GEOM_METADATA table.\"",
        "\"Maps to the Oracle"
    ],
    [
        "return \"%s - %s (SRID: %s)\" % (self.table_name, self.column_name, self.srid)",
        "return \"%s - %s (SRID: %s)\""
    ],
    [
        "Return the name of the metadata column used to store the feature table",
        "Return the name of the metadata column used to store the"
    ],
    [
        "Return the name of the metadata column used to store the feature",
        "Return the name of the metadata column used"
    ],
    [
        "\"Maps to the Oracle MDSYS.CS_SRS table.\"",
        "\"Maps to the Oracle"
    ],
    [
        "Oracle requires that polygon rings are in proper orientation. This",
        "Oracle requires that polygon rings are in proper orientation."
    ],
    [
        "affects spatial operations and an invalid orientation may cause",
        "affects spatial operations and an invalid"
    ],
    [
        "* Outer ring - counter clockwise",
        "* Outer ring"
    ],
    [
        "isinstance(g, Polygon) and self._polygon_must_be_fixed(g) for g in geom",
        "isinstance(g, Polygon) and self._polygon_must_be_fixed(g) for"
    ],
    [
        "or any(x.is_counterclockwise for x in poly)",
        "or any(x.is_counterclockwise for x in"
    ],
    [
        "\"\"\"Fix single polygon orientation as described in __init__().\"\"\"",
        "\"\"\"Fix single polygon orientation as"
    ],
    [
        "Fix polygon orientations in geometry collections as described in",
        "Fix polygon orientations in geometry collections as"
    ],
    [
        "\"Oracle doesn't support spatial operators in constraints.\": {",
        "\"Oracle doesn't support spatial operators"
    ],
    [
        "This module contains the spatial lookup types, and the `get_geo_where_clause`",
        "This module contains the spatial lookup types, and"
    ],
    [
        "Please note that WKT support is broken on the XE version, and thus",
        "Please note that WKT support is broken on the XE version,"
    ],
    [
        "this backend will not work on such platforms.  Specifically, XE lacks",
        "this backend will not work on"
    ],
    [
        "support for an internal JVM, and Java libraries are required to use",
        "support for an internal JVM, and Java"
    ],
    [
        "sql_template = \"%(func)s(%(lhs)s, %(rhs)s) = 'TRUE'\"",
        "sql_template = \"%(func)s(%(lhs)s, %(rhs)s) ="
    ],
    [
        "sql_template = \"SDO_WITHIN_DISTANCE(%(lhs)s, %(rhs)s, %%s) = 'TRUE'\"",
        "sql_template = \"SDO_WITHIN_DISTANCE(%(lhs)s, %(rhs)s, %%s)"
    ],
    [
        "\"SDO_GEOM.RELATE(%%(lhs)s, 'DISJOINT', %%(rhs)s, %s) = 'DISJOINT'\"",
        "\"SDO_GEOM.RELATE(%%(lhs)s, 'DISJOINT', %%(rhs)s,"
    ],
    [
        "sql_template = \"SDO_RELATE(%(lhs)s, %(rhs)s, 'mask=%(mask)s') = 'TRUE'\"",
        "sql_template = \"SDO_RELATE(%(lhs)s, %(rhs)s, 'mask=%(mask)s')"
    ],
    [
        "mask_regex = re.compile(r\"^(%s)(\\+(%s))*$\" % (masks, masks), re.I)",
        "mask_regex = re.compile(r\"^(%s)(\\+(%s))*$\" % (masks,"
    ],
    [
        "if not isinstance(arg, str) or not mask_regex.match(arg):",
        "if not isinstance(arg, str) or"
    ],
    [
        "raise ValueError('Invalid SDO_RELATE mask: \"%s\"' % arg)",
        "raise ValueError('Invalid SDO_RELATE mask:"
    ],
    [
        "def as_sql(self, connection, lookup, template_params, sql_params):",
        "def as_sql(self, connection, lookup,"
    ],
    [
        "\"Unexpected geometry type returned for extent: %s\" % gtype",
        "\"Unexpected geometry type returned for"
    ],
    [
        "Return the geometry database type for Oracle. Unlike other spatial",
        "Return the geometry database type for"
    ],
    [
        "backends, no stored procedure is necessary and it's the same for all",
        "backends, no stored procedure is necessary and it's the"
    ],
    [
        "Return the distance parameters given the value and the lookup type.",
        "Return the distance parameters given the value and"
    ],
    [
        "On Oracle, geometry columns with a geodetic coordinate system behave",
        "On Oracle, geometry columns with a geodetic"
    ],
    [
        "implicitly like a geography column, and thus meters will be used as",
        "implicitly like a geography column, and"
    ],
    [
        "Return the spatial aggregate SQL name.",
        "Return the spatial aggregate SQL"
    ],
    [
        "agg_name = \"unionagg\" if agg_name.lower() == \"union\" else agg_name.lower()",
        "agg_name = \"unionagg\" if agg_name.lower() =="
    ],
    [
        "\"\"\"Drop out insert parameters for NULL placeholder. Needed for Oracle Spatial",
        "\"\"\"Drop out insert parameters for NULL placeholder."
    ],
    [
        "'SELECT \"DIMINFO\", \"SRID\" FROM \"USER_SDO_GEOM_METADATA\" '",
        "'SELECT \"DIMINFO\", \"SRID\" FROM"
    ],
    [
        "\"Could not find entry in USER_SDO_GEOM_METADATA \"",
        "\"Could not find entry in USER_SDO_GEOM_METADATA"
    ],
    [
        "'corresponding to \"%s\".\"%s\"' % (table_name, description.name)",
        "'corresponding to \"%s\".\"%s\"'"
    ],
    [
        "from django.db.backends.oracle.base import DatabaseWrapper as OracleDatabaseWrapper",
        "from django.db.backends.oracle.base import DatabaseWrapper as"
    ],
    [
        "\"CREATE INDEX %(index)s ON %(table)s(%(column)s) \"",
        "\"CREATE INDEX %(index)s"
    ],
    [
        "\"DELETE FROM USER_SDO_GEOM_METADATA WHERE TABLE_NAME = %(table)s\"",
        "\"DELETE FROM USER_SDO_GEOM_METADATA WHERE"
    ],
    [
        "\"DELETE FROM USER_SDO_GEOM_METADATA WHERE TABLE_NAME = %(table)s \"",
        "\"DELETE FROM USER_SDO_GEOM_METADATA WHERE TABLE_NAME"
    ],
    [
        "The GeometryColumns and SpatialRefSys models for the PostGIS backend.",
        "The GeometryColumns and SpatialRefSys models for"
    ],
    [
        "The 'geometry_columns' view from PostGIS. See the PostGIS",
        "The 'geometry_columns' view from PostGIS. See"
    ],
    [
        "return \"%s.%s - %dD %s field (SRID: %d)\" % (",
        "return \"%s.%s - %dD %s field"
    ],
    [
        "Return the name of the metadata column used to store the feature table",
        "Return the name of the metadata column used to store"
    ],
    [
        "Return the name of the metadata column used to store the feature",
        "Return the name of the metadata column"
    ],
    [
        "The 'spatial_ref_sys' table from PostGIS. See the PostGIS",
        "The 'spatial_ref_sys' table from PostGIS."
    ],
    [
        "This object provides quoting for GEOS geometries into PostgreSQL/PostGIS.",
        "This object provides quoting for GEOS"
    ],
    [
        "return isinstance(other, PostGISAdapter) and self.ewkb == other.ewkb",
        "return isinstance(other, PostGISAdapter) and self.ewkb"
    ],
    [
        "Return a properly quoted string for use in PostgreSQL/PostGIS.",
        "Return a properly quoted string"
    ],
    [
        "Pack data into hex string with little endian format.",
        "Pack data into hex string"
    ],
    [
        "Unpack little endian hexlified binary string into a list.",
        "Unpack little endian hexlified binary string"
    ],
    [
        "Split a string into two parts at the input index.",
        "Split a string into two parts"
    ],
    [
        "Convert a PostGIS HEX String into a dictionary.",
        "Convert a PostGIS HEX String"
    ],
    [
        "raise ValidationError(\"Band pixeltypes are not all equal.\")",
        "raise ValidationError(\"Band pixeltypes are not"
    ],
    [
        "Convert a GDALRaster into PostGIS Raster format.",
        "Convert a GDALRaster into PostGIS Raster"
    ],
    [
        "def as_sql(self, connection, lookup, template_params, *args):",
        "def as_sql(self, connection,"
    ],
    [
        "if lookup.band_lhs is not None and lhs_is_raster:",
        "if lookup.band_lhs is not"
    ],
    [
        "\"Band indices are not allowed for this operator, it works on bbox \"",
        "\"Band indices are not allowed for this"
    ],
    [
        "template_params[\"lhs\"] = \"%s, %s\" % (",
        "template_params[\"lhs\"] = \"%s, %s\" %"
    ],
    [
        "if lookup.band_rhs is not None and rhs_is_raster:",
        "if lookup.band_rhs is not None"
    ],
    [
        "\"Band indices are not allowed for this operator, it works on bbox \"",
        "\"Band indices are not allowed for this"
    ],
    [
        "template_params[\"rhs\"] = \"%s, %s\" % (",
        "template_params[\"rhs\"] = \"%s, %s\""
    ],
    [
        "\"\"\"Convert geography fields to geometry types, if necessary.\"\"\"",
        "\"\"\"Convert geography fields to geometry types,"
    ],
    [
        "if isinstance(expr, Value) and not expr._output_field_or_none:",
        "if isinstance(expr, Value) and"
    ],
    [
        "\"\"\"Determine the version of the PostGIS library.\"\"\"",
        "\"\"\"Determine the version of the"
    ],
    [
        "'Cannot determine PostGIS version for database \"%s\" '",
        "'Cannot determine PostGIS version"
    ],
    [
        "\"Was the database created from a spatial database \"",
        "\"Was the database created from"
    ],
    [
        "the bounding box text returned by PostGIS (`box` argument), for",
        "the bounding box text returned by PostGIS"
    ],
    [
        "xmin, ymin, zmin = map(float, ll.split())",
        "xmin, ymin, zmin"
    ],
    [
        "xmax, ymax, zmax = map(float, ur.split())",
        "xmax, ymax, zmax ="
    ],
    [
        "return (xmin, ymin, zmin, xmax, ymax, zmax)",
        "return (xmin, ymin, zmin, xmax,"
    ],
    [
        "Return the database field type for the given spatial field.",
        "Return the database field type for"
    ],
    [
        "Retrieve the distance parameters for the given geometry field,",
        "Retrieve the distance parameters for the given geometry"
    ],
    [
        "distance lookup value, and the distance lookup type.",
        "distance lookup value, and the distance"
    ],
    [
        "This is the most complex implementation of the spatial backends due to",
        "This is the most complex implementation"
    ],
    [
        "what is supported on geodetic geometry columns vs. what's available on",
        "what is supported on geodetic geometry columns vs. what's available"
    ],
    [
        "projected geometry columns.  In addition, it has to take into account",
        "projected geometry columns. In addition, it has to take into"
    ],
    [
        "\"Only numeric values of degree units are \"",
        "\"Only numeric values of"
    ],
    [
        "Provide a proper substitution value for Geometries or rasters that are",
        "Provide a proper substitution value for Geometries or rasters"
    ],
    [
        "not in the SRID of the field. Specifically, this routine will",
        "not in the SRID of the field. Specifically, this"
    ],
    [
        "substitute in the ST_Transform() function call.",
        "substitute in the ST_Transform()"
    ],
    [
        "placeholder = \"%s(%%s, %s)\" % (transform_func, f.srid)",
        "placeholder = \"%s(%%s, %s)\""
    ],
    [
        "if value_srid is None or value_srid == f.srid:",
        "if value_srid is None"
    ],
    [
        "placeholder = \"%s(%%s, %s)\" % (transform_func, f.srid)",
        "placeholder = \"%s(%%s, %s)\""
    ],
    [
        "Helper routine for calling PostGIS functions and returning their result.",
        "Helper routine for calling PostGIS functions and"
    ],
    [
        "\"Return the version of the GEOS library used with PostGIS.\"",
        "\"Return the version of the GEOS library used"
    ],
    [
        "\"Return the version number of the PostGIS library used with PostgreSQL.\"",
        "\"Return the version number of the PostGIS"
    ],
    [
        "\"\"\"Return the version of the PROJ library used with PostGIS.\"\"\"",
        "\"\"\"Return the version of the PROJ"
    ],
    [
        "\"Return PostGIS version number and compile-time options.\"",
        "\"Return PostGIS version number and"
    ],
    [
        "\"Return PostGIS version number and compile-time options.\"",
        "\"Return PostGIS version number and"
    ],
    [
        "Return the PostGIS version as a tuple (version string, major,",
        "Return the PostGIS version as a tuple (version string,"
    ],
    [
        "Return the version of PROJ used by PostGIS as a tuple of the",
        "Return the version of PROJ used by PostGIS as a tuple of"
    ],
    [
        "major, minor, and subminor release numbers.",
        "major, minor, and subminor release"
    ],
    [
        "raise Exception(\"Could not determine PROJ version from PostGIS.\")",
        "raise Exception(\"Could not determine PROJ version from"
    ],
    [
        "\"\"\"Convert a PostGIS HEX String into a dict readable by GDALRaster.\"\"\"",
        "\"\"\"Convert a PostGIS HEX String into a"
    ],
    [
        "return ST_Polygon(arg) if is_raster else arg",
        "return ST_Polygon(arg) if is_raster else"
    ],
    [
        "return None if value is None else GEOSGeometryBase(read(value), geom_class)",
        "return None if value is None else GEOSGeometryBase(read(value),"
    ],
    [
        "(oid, \"GeometryField\") for oid in self.postgis_oid_lookup",
        "(oid, \"GeometryField\") for oid"
    ],
    [
        "The geometry type OID used by PostGIS does not indicate the particular",
        "The geometry type OID used by PostGIS does not indicate the"
    ],
    [
        "type of field that a geometry column is (e.g., whether it's a",
        "type of field that a geometry"
    ],
    [
        "PointField or a PolygonField).  Thus, this routine queries the PostGIS",
        "PointField or a PolygonField). Thus,"
    ],
    [
        "metadata tables to determine the geometry type.",
        "metadata tables to determine the geometry"
    ],
    [
        "SELECT t.coord_dimension, t.srid, t.type FROM (",
        "SELECT t.coord_dimension, t.srid, t.type"
    ],
    [
        ") AS t WHERE t.f_table_name = %s AND t.f_geometry_column = %s",
        ") AS t WHERE t.f_table_name = %s AND t.f_geometry_column ="
    ],
    [
        "'Could not find a geometry or geography column for \"%s\".\"%s\"'",
        "'Could not find a geometry or geography"
    ],
    [
        "from django.db.backends.postgresql.base import DatabaseWrapper as PsycopgDatabaseWrapper",
        "from django.db.backends.postgresql.base import DatabaseWrapper"
    ],
    [
        "return GeographyType if obj.geography else GeometryType",
        "return GeographyType if obj.geography"
    ],
    [
        "cursor.execute(\"CREATE EXTENSION IF NOT EXISTS postgis\")",
        "cursor.execute(\"CREATE EXTENSION IF"
    ],
    [
        "return info.oid if info else None",
        "return info.oid if info else"
    ],
    [
        "PostGIS to GDAL conversion constant definitions",
        "PostGIS to GDAL conversion constant"
    ],
    [
        "POSTGIS_HEADER_STRUCTURE = \"B H H d d d d d d i H H\"",
        "POSTGIS_HEADER_STRUCTURE = \"B H H d d d d"
    ],
    [
        "def _create_index_sql(self, model, *, fields=None, **kwargs):",
        "def _create_index_sql(self, model,"
    ],
    [
        "self, table, old_field, new_field, new_type, old_collation, new_collation",
        "self, table, old_field, new_field, new_type,"
    ],
    [
        "if not hasattr(old_field, \"dim\") or not hasattr(new_field, \"dim\"):",
        "if not hasattr(old_field, \"dim\")"
    ],
    [
        "table, old_field, new_field, new_type, old_collation, new_collation",
        "table, old_field, new_field, new_type,"
    ],
    [
        "from django.db.backends.mysql.features import DatabaseFeatures as MySQLDatabaseFeatures",
        "from django.db.backends.mysql.features import DatabaseFeatures"
    ],
    [
        "\"Only numeric values of degree units are allowed on \"",
        "\"Only numeric values of degree units are allowed on"
    ],
    [
        "for column, typ, null, key, default, extra in cursor.fetchall():",
        "for column, typ, null, key, default, extra"
    ],
    [
        "return storage_engine in (\"MyISAM\", \"Aria\", \"InnoDB\")",
        "return storage_engine in (\"MyISAM\","
    ],
    [
        "from django.db.backends.mysql.base import DatabaseWrapper as MySQLDatabaseWrapper",
        "from django.db.backends.mysql.base import DatabaseWrapper"
    ],
    [
        "sql_add_spatial_index = \"CREATE SPATIAL INDEX %(index)s ON %(table)s(%(column)s)\"",
        "sql_add_spatial_index = \"CREATE SPATIAL INDEX %(index)s"
    ],
    [
        "if isinstance(field, GeometryField) and field.spatial_index and not field.null:",
        "if isinstance(field, GeometryField) and field.spatial_index and"
    ],
    [
        "f\"Cannot create SPATIAL INDEX {sql}. Only MyISAM, Aria, and InnoDB \"",
        "f\"Cannot create SPATIAL INDEX {sql}. Only MyISAM, Aria,"
    ],
    [
        "if isinstance(field, GeometryField) and field.spatial_index and not field.null:",
        "if isinstance(field, GeometryField) and field.spatial_index"
    ],
    [
        "\"Couldn't remove spatial index: %s (may be expected \"",
        "\"Couldn't remove spatial index: %s"
    ],
    [
        "\"if your storage engine doesn't support them).\",",
        "\"if your storage engine doesn't support"
    ],
    [
        "The GeometryColumns and SpatialRefSys models for the SpatiaLite backend.",
        "The GeometryColumns and SpatialRefSys models for the"
    ],
    [
        "return \"%s.%s - %dD %s field (SRID: %d)\" % (",
        "return \"%s.%s - %dD %s field (SRID: %d)\" %"
    ],
    [
        "Return the name of the metadata column used to store the feature table",
        "Return the name of the metadata column"
    ],
    [
        "Return the name of the metadata column used to store the feature",
        "Return the name of the metadata"
    ],
    [
        "\"SpatiaLite doesn't support distance lookups with Distance objects.\": {",
        "\"SpatiaLite doesn't support distance lookups with"
    ],
    [
        "def as_sql(self, connection, lookup, template_params, sql_params):",
        "def as_sql(self, connection,"
    ],
    [
        "sql, params = super().as_sql(connection, lookup, template_params, sql_params)",
        "sql, params = super().as_sql(connection,"
    ],
    [
        "select = \"CAST (AsEWKB(%s) AS BLOB)\"",
        "select = \"CAST (AsEWKB(%s) AS"
    ],
    [
        "\"\"\"Determine the version of the SpatiaLite library.\"\"\"",
        "\"\"\"Determine the version of the SpatiaLite"
    ],
    [
        "'Cannot determine the SpatiaLite version for the \"%s\" database. '",
        "'Cannot determine the SpatiaLite version"
    ],
    [
        "\"Was the SpatiaLite initialization SQL loaded on this database?\"",
        "\"Was the SpatiaLite initialization SQL loaded on"
    ],
    [
        "Convert the polygon data received from SpatiaLite to min/max values.",
        "Convert the polygon data received from"
    ],
    [
        "Return None because geometry columns are added via the",
        "Return None because geometry columns"
    ],
    [
        "Return the distance parameters for the given geometry field,",
        "Return the distance parameters for the"
    ],
    [
        "\"Only numeric values of degree units are allowed on \"",
        "\"Only numeric values of degree units are"
    ],
    [
        "Helper routine for calling SpatiaLite functions and returning",
        "Helper routine for calling SpatiaLite functions and"
    ],
    [
        "Any error occurring in this method should be handled by the caller.",
        "Any error occurring in this method"
    ],
    [
        "\"Return the version of GEOS used by SpatiaLite as a string.\"",
        "\"Return the version of GEOS used by"
    ],
    [
        "\"\"\"Return the version of the PROJ library used by SpatiaLite.\"\"\"",
        "\"\"\"Return the version of the PROJ library used by"
    ],
    [
        "\"\"\"Return the version of LWGEOM library used by SpatiaLite.\"\"\"",
        "\"\"\"Return the version of LWGEOM library used by"
    ],
    [
        "\"\"\"Return the version of RTTOPO library used by SpatiaLite.\"\"\"",
        "\"\"\"Return the version of RTTOPO library used by"
    ],
    [
        "Return the version of the version-dependant geom library used by",
        "Return the version of the version-dependant geom library used"
    ],
    [
        "\"Return the SpatiaLite library version as a string.\"",
        "\"Return the SpatiaLite library version as"
    ],
    [
        "Return the SpatiaLite version as a tuple (version string, major,",
        "Return the SpatiaLite version as a tuple (version"
    ],
    [
        "Return the spatial aggregate SQL template and function for the",
        "Return the spatial aggregate SQL template and function for"
    ],
    [
        "agg_name = \"unionagg\" if agg_name.lower() == \"union\" else agg_name.lower()",
        "agg_name = \"unionagg\" if agg_name.lower() =="
    ],
    [
        "return None if value is None else GEOSGeometryBase(read(value), geom_class)",
        "return None if value is None else"
    ],
    [
        "Subclass that includes updates the `base_data_types_reverse` dict",
        "Subclass that includes updates the"
    ],
    [
        "'Could not find a geometry column for \"%s\".\"%s\"'",
        "'Could not find a geometry"
    ],
    [
        "\"SpatiaLite requires SQLite to be configured to allow \"",
        "\"SpatiaLite requires SQLite to be configured"
    ],
    [
        "\"Unable to load the SpatiaLite library extension \"",
        "\"Unable to load the SpatiaLite library"
    ],
    [
        "\"as specified in your SPATIALITE_LIBRARY_PATH setting.\"",
        "\"as specified in your"
    ],
    [
        "\"Unable to load the SpatiaLite library extension. \"",
        "\"Unable to load the SpatiaLite library"
    ],
    [
        "\"Library names tried: %s\" % \", \".join(self.lib_spatialite_paths)",
        "\"Library names tried: %s\" %"
    ],
    [
        "\"DELETE FROM %(geom_table)s WHERE f_table_name = %(table)s\"",
        "\"DELETE FROM %(geom_table)s WHERE f_table_name ="
    ],
    [
        "\"UPDATE %(geom_table)s SET f_table_name = %(new_table)s \"",
        "\"UPDATE %(geom_table)s SET f_table_name = %(new_table)s"
    ],
    [
        "if old_db_table == new_db_table or (",
        "if old_db_table == new_db_table or"
    ],
    [
        "The SpatialRefSysMixin is a class used by the database-dependent",
        "The SpatialRefSysMixin is a class used"
    ],
    [
        "SpatialRefSys objects to reduce redundant code.",
        "SpatialRefSys objects to reduce redundant"
    ],
    [
        "Return a tuple of the ellipsoid parameters:",
        "Return a tuple of the"
    ],
    [
        "(semimajor axis, semiminor axis, and inverse flattening).",
        "(semimajor axis, semiminor axis,"
    ],
    [
        "\"Return the spheroid name for this spatial reference.\"",
        "\"Return the spheroid name for this spatial"
    ],
    [
        "\"Return the datum for this spatial reference.\"",
        "\"Return the datum for"
    ],
    [
        "\"Return the name of the angular units.\"",
        "\"Return the name of the"
    ],
    [
        "\"Return a tuple of the units and the name.\"",
        "\"Return a tuple of the units and"
    ],
    [
        "Return a tuple of (unit_value, unit_name) for the given WKT without",
        "Return a tuple of (unit_value, unit_name) for the"
    ],
    [
        "using any of the database fields.",
        "using any of the"
    ],
    [
        "Class method used by GeometryField on initialization to",
        "Class method used by GeometryField on"
    ],
    [
        "retrieve the `SPHEROID[..]` parameters from the given WKT.",
        "retrieve the `SPHEROID[..]` parameters from the given"
    ],
    [
        "return 'SPHEROID[\"%s\",%s,%s]' % (sphere_name, radius, flattening)",
        "return 'SPHEROID[\"%s\",%s,%s]' % (sphere_name, radius,"
    ],
    [
        "Return the string representation, a 'pretty' OGC WKT.",
        "Return the string representation, a 'pretty'"
    ],
    [
        "An adaptor for Geometries sent to the MySQL and Oracle database backends.",
        "An adaptor for Geometries sent to the MySQL and Oracle database"
    ],
    [
        "from django.contrib.gis.measure import Area as AreaMeasure",
        "from django.contrib.gis.measure import"
    ],
    [
        "from django.contrib.gis.measure import Distance as DistanceMeasure",
        "from django.contrib.gis.measure import"
    ],
    [
        "\"Aggregate extent not implemented for this spatial backend.\"",
        "\"Aggregate extent not implemented for"
    ],
    [
        "Return the database column type for the geometry field on",
        "Return the database column type for"
    ],
    [
        "\"subclasses of BaseSpatialOperations must provide a geo_db_type() method\"",
        "\"subclasses of BaseSpatialOperations must provide"
    ],
    [
        "Return the distance parameters for the given geometry field,",
        "Return the distance parameters for the given"
    ],
    [
        "\"Distance operations not available on this spatial backend.\"",
        "\"Distance operations not available on this"
    ],
    [
        "Return the placeholder for the given geometry field with the given",
        "Return the placeholder for the given geometry field"
    ],
    [
        "value.  Depending on the spatial backend, the placeholder may contain a",
        "value. Depending on the spatial backend, the"
    ],
    [
        "stored procedure call to the transformation function of the spatial",
        "stored procedure call to the transformation function of"
    ],
    [
        "return value is not None and value.srid != field.srid",
        "return value is not None and value.srid"
    ],
    [
        "\"%s spatial aggregation is not supported by this database backend.\"",
        "\"%s spatial aggregation is not supported by this database"
    ],
    [
        "\"Aggregate support not implemented for this spatial backend.\"",
        "\"Aggregate support not implemented"
    ],
    [
        "\"This backend doesn't support the %s function.\" % func_name",
        "\"This backend doesn't support the %s function.\" %"
    ],
    [
        "\"Subclasses of BaseSpatialOperations must provide a geometry_columns() \"",
        "\"Subclasses of BaseSpatialOperations must provide a"
    ],
    [
        "\"subclasses of BaseSpatialOperations must a provide spatial_ref_sys() \"",
        "\"subclasses of BaseSpatialOperations must a provide"
    ],
    [
        "\"Subclasses of BaseSpatialOperations must provide a \"",
        "\"Subclasses of BaseSpatialOperations must"
    ],
    [
        "\"Area on geodetic coordinate systems not supported.\"",
        "\"Area on geodetic coordinate systems not"
    ],
    [
        "\"%s function requires a geometric argument in position %d.\"",
        "\"%s function requires a geometric argument in position"
    ],
    [
        "if not geom.srid and not output_field:",
        "if not geom.srid"
    ],
    [
        "raise ValueError(\"SRID is required for all geometries.\")",
        "raise ValueError(\"SRID is required for all"
    ],
    [
        "def as_sql(self, compiler, connection, function=None, **extra_context):",
        "def as_sql(self, compiler,"
    ],
    [
        "if self.function is None and function is None:",
        "if self.function is None"
    ],
    [
        "\"%s function requires a GeometryField in position %s, got %s.\"",
        "\"%s function requires a GeometryField in"
    ],
    [
        "if check_types and not isinstance(value, check_types):",
        "if check_types and not"
    ],
    [
        "\"The %s parameter has the wrong type: should be %s.\"",
        "\"The %s parameter has the wrong type: should be"
    ],
    [
        "By default, Decimal values are converted to str by the SQLite backend, which",
        "By default, Decimal values are converted to str by the"
    ],
    [
        "is not acceptable by the GIS functions expecting numeric values.",
        "is not acceptable by the GIS functions"
    ],
    [
        "if hasattr(expr, \"value\") and isinstance(expr.value, Decimal)",
        "if hasattr(expr, \"value\")"
    ],
    [
        "\"Area on geodetic coordinate systems not supported.\"",
        "\"Area on geodetic coordinate systems"
    ],
    [
        "relative if hasattr(relative, \"resolve_expression\") else int(relative)",
        "relative if hasattr(relative,"
    ],
    [
        "sql, params = super().as_oracle(compiler, connection, **extra_context)",
        "sql, params = super().as_oracle(compiler, connection,"
    ],
    [
        "\"This backend doesn't support Length on geodetic fields\"",
        "\"This backend doesn't support Length on geodetic"
    ],
    [
        "dim = min(f.dim for f in self.get_source_fields() if f)",
        "dim = min(f.dim for f in self.get_source_fields()"
    ],
    [
        "function = \"GeodesicLength\" if self.spheroid else \"GreatCircleLength\"",
        "function = \"GeodesicLength\" if self.spheroid"
    ],
    [
        "\"ST_Perimeter cannot use a non-projected non-geography field.\"",
        "\"ST_Perimeter cannot use a"
    ],
    [
        "dim = min(f.dim for f in self.get_source_fields())",
        "dim = min(f.dim for f"
    ],
    [
        "raise NotSupportedError(\"Perimeter cannot use a non-projected field.\")",
        "raise NotSupportedError(\"Perimeter cannot use"
    ],
    [
        "[self._handle_param(arg, \"\", NUMERIC_TYPES) for arg in args]",
        "[self._handle_param(arg, \"\", NUMERIC_TYPES) for arg in"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "Return the units, unit name, and spheroid WKT associated with the",
        "Return the units, unit name, and spheroid"
    ],
    [
        "given SRID from the `spatial_ref_sys` (or equivalent) spatial database",
        "given SRID from the `spatial_ref_sys` (or equivalent)"
    ],
    [
        "table for the given database connection.  These results are cached.",
        "table for the given database connection. These results are"
    ],
    [
        "It's used as a base class for GeometryField and RasterField. Defines",
        "It's used as a base class for GeometryField"
    ],
    [
        "properties that are common to all GIS fields such as the characteristics",
        "properties that are common to all GIS fields such"
    ],
    [
        "of the spatial reference system of the field.",
        "of the spatial reference"
    ],
    [
        "description = _(\"The base GIS field.\")",
        "description = _(\"The base GIS"
    ],
    [
        "The initialization function for base spatial fields. Takes the following",
        "The initialization function for base spatial"
    ],
    [
        "The spatial reference system identifier, an OGC standard.",
        "The spatial reference system identifier,"
    ],
    [
        "Indicates whether to create a spatial index.  Defaults to True.",
        "Indicates whether to create a spatial index. Defaults"
    ],
    [
        "Set this instead of 'db_index' for geographic fields since index",
        "Set this instead of 'db_index' for geographic fields since"
    ],
    [
        "creation is different for geometry columns.",
        "creation is different for geometry"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "Return true if this field's SRID corresponds with a coordinate",
        "Return true if this field's SRID"
    ],
    [
        "system that uses non-projected units (e.g., latitude/longitude).",
        "system that uses non-projected units (e.g.,"
    ],
    [
        "Return the placeholder for the spatial column for the",
        "Return the placeholder for the spatial column"
    ],
    [
        "Return the default SRID for the given geometry or raster, taking into",
        "Return the default SRID for the given geometry or raster,"
    ],
    [
        "account the SRID set for the field. For example, if the input geometry",
        "account the SRID set for the field. For example, if the"
    ],
    [
        "or raster doesn't have an SRID, then the SRID of the field will be",
        "or raster doesn't have an SRID, then"
    ],
    [
        "def get_db_prep_value(self, value, connection, *args, **kwargs):",
        "def get_db_prep_value(self, value, connection, *args,"
    ],
    [
        "Return a GDALRaster if conversion is successful, otherwise return None.",
        "Return a GDALRaster if conversion is successful, otherwise"
    ],
    [
        "\"Couldn't create spatial object from lookup value '%s'.\" % value",
        "\"Couldn't create spatial object from"
    ],
    [
        "is_candidate = isinstance(obj, (bytes, str)) or hasattr(",
        "is_candidate = isinstance(obj, (bytes, str)) or"
    ],
    [
        "\"Couldn't create spatial object from lookup value '%s'.\" % obj",
        "\"Couldn't create spatial object from lookup value '%s'.\""
    ],
    [
        "\"Cannot use object with type %s for a spatial lookup parameter.\"",
        "\"Cannot use object with type %s for"
    ],
    [
        "The base Geometry field -- maps to the OpenGIS Specification Geometry type.",
        "The base Geometry field -- maps to"
    ],
    [
        "\"The base Geometry field — maps to the OpenGIS Specification Geometry type.\"",
        "\"The base Geometry field — maps to the OpenGIS Specification Geometry"
    ],
    [
        "The initialization function for geometry fields. In addition to the",
        "The initialization function for geometry fields. In addition"
    ],
    [
        "parameters from BaseSpatialField, it takes the following as keyword",
        "parameters from BaseSpatialField, it takes"
    ],
    [
        "geometry field entry in the `USER_SDO_GEOM_METADATA` table.  Defaults",
        "geometry field entry in the"
    ],
    [
        "Define the tolerance, in meters, to use for the geometry field",
        "Define the tolerance, in meters, to"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "Return the selection format string, depending on the requirements",
        "Return the selection format string, depending on the"
    ],
    [
        "of the spatial backend. For example, Oracle and MySQL require custom",
        "of the spatial backend. For example, Oracle and MySQL"
    ],
    [
        "selection formats in order to retrieve geometries in OGC WKB.",
        "selection formats in order to"
    ],
    [
        "\"Used as a return value from an extent aggregate\"",
        "\"Used as a return value from"
    ],
    [
        "return select % sql if select else sql, params",
        "return select % sql if select else sql,"
    ],
    [
        "Raster field for GeoDjango -- evaluates into GDALRaster objects.",
        "Raster field for GeoDjango -- evaluates into"
    ],
    [
        "\"Raster fields require backends with raster support.\"",
        "\"Raster fields require backends"
    ],
    [
        "The SpatialProxy object allows for lazy-geometries and lazy-rasters. The proxy",
        "The SpatialProxy object allows for lazy-geometries"
    ],
    [
        "uses Python descriptors for instantiating and setting Geometry or Raster",
        "uses Python descriptors for instantiating and setting"
    ],
    [
        "objects corresponding to geographic model fields.",
        "objects corresponding to geographic"
    ],
    [
        "Initialize on the given Geometry or Raster class (not an instance)",
        "Initialize on the given Geometry or"
    ],
    [
        "Retrieve the geometry or raster, initializing it using the",
        "Retrieve the geometry or raster, initializing it using"
    ],
    [
        "corresponding class specified during initialization and the value of",
        "corresponding class specified during initialization"
    ],
    [
        "the field. Currently, GEOS or OGR geometries as well as GDALRasters are",
        "the field. Currently, GEOS or OGR"
    ],
    [
        "elif (geo_value is None) or (geo_value == \"\"):",
        "elif (geo_value is None) or (geo_value =="
    ],
    [
        "Retrieve the proxied geometry or raster with the corresponding class",
        "Retrieve the proxied geometry or raster"
    ],
    [
        "To set geometries, use values of None, HEXEWKB, or WKT.",
        "To set geometries, use values of None,"
    ],
    [
        "To set rasters, use JSON or dict values.",
        "To set rasters, use JSON or"
    ],
    [
        "if gtype == \"RASTER\" and (",
        "if gtype == \"RASTER\""
    ],
    [
        "value is None or isinstance(value, (str, dict, self._klass))",
        "value is None or"
    ],
    [
        "elif value is None or isinstance(value, (str, memoryview)):",
        "elif value is None or"
    ],
    [
        "\"Cannot set %s SpatialProxy (%s) with value of type: %s\"",
        "\"Cannot set %s SpatialProxy (%s)"
    ],
    [
        "from django.contrib.gis.db.models.aggregates import __all__ as aggregates_all",
        "from django.contrib.gis.db.models.aggregates import __all__"
    ],
    [
        "from django.db.models import Expression, Lookup, Transform",
        "from django.db.models import Expression,"
    ],
    [
        "rhs, *self.rhs_params = rhs if isinstance(rhs, (list, tuple)) else [rhs]",
        "rhs, *self.rhs_params = rhs if isinstance(rhs, (list, tuple))"
    ],
    [
        "raise ValueError(\"Tuple too long for lookup %s.\" % self.lookup_name)",
        "raise ValueError(\"Tuple too long for lookup"
    ],
    [
        "Extract the lhs band index from the band transform class and the rhs",
        "Extract the lhs band index from the band transform class and the"
    ],
    [
        "band index from the input tuple.",
        "band index from"
    ],
    [
        "The overlaps_left operator returns true if A's bounding box overlaps or is to the",
        "The overlaps_left operator returns true if A's bounding box"
    ],
    [
        "The 'overlaps_right' operator returns true if A's bounding box overlaps or is to the",
        "The 'overlaps_right' operator returns true if A's bounding box"
    ],
    [
        "The 'overlaps_below' operator returns true if A's bounding box overlaps or is below",
        "The 'overlaps_below' operator returns true if A's bounding box overlaps"
    ],
    [
        "The 'overlaps_above' operator returns true if A's bounding box overlaps or is above",
        "The 'overlaps_above' operator returns true if A's bounding box overlaps"
    ],
    [
        "The 'left' operator returns true if A's bounding box is strictly to the left",
        "The 'left' operator returns true if A's bounding box"
    ],
    [
        "The 'right' operator returns true if A's bounding box is strictly to the right",
        "The 'right' operator returns true if A's bounding box is strictly to"
    ],
    [
        "The 'strictly_below' operator returns true if A's bounding box is strictly below B's",
        "The 'strictly_below' operator returns true if A's bounding box is"
    ],
    [
        "The 'strictly_above' operator returns true if A's bounding box is strictly above B's",
        "The 'strictly_above' operator returns true if A's bounding"
    ],
    [
        "The \"~=\" operator is the \"same as\" operator. It tests actual geometric",
        "The \"~=\" operator is the \"same as\" operator. It tests"
    ],
    [
        "equality of two features. So if A and B are the same feature,",
        "equality of two features. So if A and B"
    ],
    [
        "The 'bbcontains' operator returns true if A's bounding box completely contains",
        "The 'bbcontains' operator returns true if A's bounding box"
    ],
    [
        "The 'bboverlaps' operator returns true if A's bounding box overlaps B's",
        "The 'bboverlaps' operator returns true if A's bounding box"
    ],
    [
        "The 'contained' operator returns true if A's bounding box is completely contained",
        "The 'contained' operator returns true if A's bounding box is"
    ],
    [
        "elif not isinstance(pattern, str) or not self.pattern_regex.match(pattern):",
        "elif not isinstance(pattern, str)"
    ],
    [
        "raise ValueError('Invalid intersection matrix pattern \"%s\".' % pattern)",
        "raise ValueError('Invalid intersection matrix pattern"
    ],
    [
        "sql_template = \"%(func)s(%(lhs)s, %(rhs)s) %(op)s %(value)s\"",
        "sql_template = \"%(func)s(%(lhs)s, %(rhs)s)"
    ],
    [
        "\"This backend does not support expressions for specifying \"",
        "\"This backend does not support"
    ],
    [
        "\"%(func)s %(op)s %(dist)s\" % {\"func\": sql, \"op\": self.op, \"dist\": dist_sql},",
        "\"%(func)s %(op)s %(dist)s\" % {\"func\": sql,"
    ],
    [
        "from django.db.models import Aggregate, Func, Value",
        "from django.db.models import Aggregate, Func,"
    ],
    [
        "def as_sql(self, compiler, connection, function=None, **extra_context):",
        "def as_sql(self, compiler,"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None, summarize=False,"
    ],
    [
        "c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)",
        "c = super().resolve_expression(query, allow_joins, reuse,"
    ],
    [
        "\"Geospatial aggregates only allowed on geometry fields.\"",
        "\"Geospatial aggregates only allowed on geometry"
    ],
    [
        "This module holds simple classes to convert geospatial values from the",
        "This module holds simple classes to"
    ],
    [
        "raise ValueError(\"AreaField only accepts Area measurement objects.\")",
        "raise ValueError(\"AreaField only accepts Area measurement"
    ],
    [
        "return getattr(value, area_att) if area_att else value",
        "return getattr(value, area_att) if area_att"
    ],
    [
        "return Area(**{area_att: value}) if area_att else value",
        "return Area(**{area_att: value}) if area_att"
    ],
    [
        "\"Distance measure is supplied, but units are unknown for result.\"",
        "\"Distance measure is supplied, but units"
    ],
    [
        "return Distance(**{distance_att: value}) if distance_att else value",
        "return Distance(**{distance_att: value}) if distance_att else"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"Misc. utility functions/classes for admin documentation generator.\"",
        "\"Misc. utility functions/classes for admin documentation"
    ],
    [
        "return mod_name + \".\" + view_name",
        "return mod_name + \".\""
    ],
    [
        "Parse out the parts of a docstring.  Return (title, body, metadata).",
        "Parse out the parts of a"
    ],
    [
        "Convert the string from reST to an XHTML fragment.",
        "Convert the string from reST to"
    ],
    [
        "thing_being_parsed = thing_being_parsed and \"<%s>\" % thing_being_parsed",
        "thing_being_parsed = thing_being_parsed and \"<%s>\" %"
    ],
    [
        "Split role content into title and target, if given.",
        "Split role content into title and target, if"
    ],
    [
        "is_case_sensitive = rolename in [\"template\", \"view\"]",
        "is_case_sensitive = rolename in [\"template\","
    ],
    [
        "def _role(name, rawtext, text, lineno, inliner, options=None, content=None):",
        "def _role(name, rawtext, text,"
    ],
    [
        "name, rawtext, text, lineno, inliner, options=None, content=None",
        "name, rawtext, text, lineno, inliner, options=None,"
    ],
    [
        "\"\"\"Remove unescaped metacharacters from the pattern.\"\"\"",
        "\"\"\"Remove unescaped metacharacters"
    ],
    [
        "if val == \"(\" and prev_char != \"\\\\\":",
        "if val == \"(\" and prev_char !="
    ],
    [
        "elif val == \")\" and prev_char != \"\\\\\":",
        "elif val == \")\" and prev_char"
    ],
    [
        "if prev_end and start > prev_end or not prev_end:",
        "if prev_end and start > prev_end or not"
    ],
    [
        "Find named groups in `pattern` and replace them with the group name. E.g.,",
        "Find named groups in `pattern` and replace them with the group name."
    ],
    [
        "for start, end, match in _find_groups(pattern, named_group_matcher)",
        "for start, end, match"
    ],
    [
        "Find unnamed groups in `pattern` and replace them with '<var>'. E.g.,",
        "Find unnamed groups in `pattern` and replace them"
    ],
    [
        "for start, end, _ in _find_groups(pattern, unnamed_group_matcher):",
        "for start, end, _ in"
    ],
    [
        "Find non-capturing groups in the given `pattern` and remove them, e.g.",
        "Find non-capturing groups in the given `pattern` and remove"
    ],
    [
        "for start, end, _ in group_start_end_indices:",
        "for start, end,"
    ],
    [
        "Add an X-View header to internal HEAD requests.",
        "Add an X-View header to"
    ],
    [
        "def process_view(self, request, view_func, view_args, view_kwargs):",
        "def process_view(self, request, view_func,"
    ],
    [
        "If the request method is HEAD and either the IP is internal or the",
        "If the request method is HEAD and either the IP is internal"
    ],
    [
        "user is a logged-in staff member, return a response with an x-view",
        "user is a logged-in staff member, return"
    ],
    [
        "header indicating the view function. This is used to lookup the view",
        "header indicating the view function. This is used to lookup the"
    ],
    [
        "\"The XView middleware requires authentication middleware to \"",
        "\"The XView middleware requires authentication middleware to"
    ],
    [
        "\"be installed. Edit your MIDDLEWARE setting to insert \"",
        "\"be installed. Edit your MIDDLEWARE"
    ],
    [
        "if request.method == \"HEAD\" and (",
        "if request.method == \"HEAD\" and"
    ],
    [
        "from django.urls import get_mod_func, get_resolver, get_urlconf",
        "from django.urls import get_mod_func, get_resolver,"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import"
    ],
    [
        "MODEL_METHODS_EXCLUDE = (\"_\", \"add_\", \"delete\", \"save\", \"set_\")",
        "MODEL_METHODS_EXCLUDE = (\"_\", \"add_\", \"delete\","
    ],
    [
        "builtin_libs = [(\"\", lib) for lib in engine.template_builtins]",
        "builtin_libs = [(\"\", lib)"
    ],
    [
        "for module_name, library in builtin_libs + app_libs:",
        "for module_name, library in"
    ],
    [
        "body = body and utils.parse_rst(body, \"tag\", _(\"tag:\") + tag_name)",
        "body = body and utils.parse_rst(body, \"tag\", _(\"tag:\")"
    ],
    [
        "builtin_libs = [(\"\", lib) for lib in engine.template_builtins]",
        "builtin_libs = [(\"\", lib) for"
    ],
    [
        "for module_name, library in builtin_libs + app_libs:",
        "for module_name, library in builtin_libs"
    ],
    [
        "for func, regex, namespace, name in view_functions:",
        "for func, regex, namespace,"
    ],
    [
        "\"url_name\": \":\".join((namespace or []) + (name and [name] or [])),",
        "\"url_name\": \":\".join((namespace or []) +"
    ],
    [
        "title = title and utils.parse_rst(title, \"view\", _(\"view:\") + view)",
        "title = title and utils.parse_rst(title,"
    ],
    [
        "body = body and utils.parse_rst(body, \"view\", _(\"view:\") + view)",
        "body = body and utils.parse_rst(body,"
    ],
    [
        "metadata[key] = utils.parse_rst(metadata[key], \"model\", _(\"view:\") + view)",
        "metadata[key] = utils.parse_rst(metadata[key], \"model\","
    ],
    [
        "return user.has_perm(\"%s.%s\" % (opts.app_label, codename_view)) or user.has_perm(",
        "return user.has_perm(\"%s.%s\" % (opts.app_label, codename_view)) or"
    ],
    [
        "_(\"Model %(model_name)r not found in app %(app_label)r\") % self.kwargs",
        "_(\"Model %(model_name)r not found in app %(app_label)r\") %"
    ],
    [
        "title = title and utils.parse_rst(title, \"model\", _(\"model:\") + model_name)",
        "title = title and utils.parse_rst(title,"
    ],
    [
        "body = body and utils.parse_rst(body, \"model\", _(\"model:\") + model_name)",
        "body = body and utils.parse_rst(body, \"model\", _(\"model:\")"
    ],
    [
        "verbose = _(\"related `%(app_label)s.%(object_name)s` objects\") % {",
        "verbose = _(\"related `%(app_label)s.%(object_name)s` objects\")"
    ],
    [
        "_(\"all %s\") % verbose, \"model\", _(\"model:\") + opts.model_name",
        "_(\"all %s\") % verbose, \"model\", _(\"model:\") +"
    ],
    [
        "verbose = _(\"related `%(app_label)s.%(object_name)s` objects\") % {",
        "verbose = _(\"related `%(app_label)s.%(object_name)s`"
    ],
    [
        "_(\"all %s\") % verbose, \"model\", _(\"model:\") + opts.model_name",
        "_(\"all %s\") % verbose, \"model\", _(\"model:\") +"
    ],
    [
        "\"\"\"Return a somewhat-helpful data type given a function name\"\"\"",
        "\"\"\"Return a somewhat-helpful data type given a function"
    ],
    [
        "Return the description for a given field type, if it exists. Fields'",
        "Return the description for a given field type,"
    ],
    [
        "descriptions can contain format strings, which will be interpolated with",
        "descriptions can contain format strings, which"
    ],
    [
        "the values of field.__dict__ before being output.",
        "the values of field.__dict__ before being"
    ],
    [
        "Return a list of views from a list of urlpatterns.",
        "Return a list of views from a list of"
    ],
    [
        "(namespace or []) + (p.namespace and [p.namespace] or []),",
        "(namespace or []) + (p.namespace and [p.namespace] or"
    ],
    [
        "views.append((p.callback, base + str(p.pattern), namespace, p.name))",
        "views.append((p.callback, base + str(p.pattern), namespace,"
    ],
    [
        "raise TypeError(_(\"%s does not appear to be a urlpattern object\") % p)",
        "raise TypeError(_(\"%s does not appear to be a"
    ],
    [
        "Clean up urlpattern regexes into something more readable by humans. For",
        "Clean up urlpattern regexes into something more"
    ],
    [
        "Exposes one class, ``MultiPartParser``, which feeds chunks of uploaded data to",
        "Exposes one class, ``MultiPartParser``, which feeds"
    ],
    [
        "from django.core.files.uploadhandler import SkipFile, StopFutureHandlers, StopUpload",
        "from django.core.files.uploadhandler import"
    ],
    [
        "No more reads are allowed from this device.",
        "No more reads are allowed from"
    ],
    [
        "``MultiValueDict.parse()`` reads the input stream in ``chunk_size`` chunks",
        "``MultiValueDict.parse()`` reads the input"
    ],
    [
        "and returns a tuple of ``(MultiValueDict(POST), MultiValueDict(FILES))``.",
        "and returns a tuple of"
    ],
    [
        "def __init__(self, META, input_data, upload_handlers, encoding=None):",
        "def __init__(self, META, input_data,"
    ],
    [
        "The standard ``META`` dictionary in Django request objects.",
        "The standard ``META`` dictionary in Django"
    ],
    [
        "The raw post data, as a file-like object.",
        "The raw post data,"
    ],
    [
        "A list of UploadHandler instances that perform operations on the",
        "A list of UploadHandler instances that perform"
    ],
    [
        "The encoding with which to treat the incoming data.",
        "The encoding with which to treat"
    ],
    [
        "raise MultiPartParserError(\"Invalid Content-Type: %s\" % content_type)",
        "raise MultiPartParserError(\"Invalid Content-Type: %s\" %"
    ],
    [
        "\"Invalid non-ASCII Content-Type in multipart: %s\"",
        "\"Invalid non-ASCII Content-Type in"
    ],
    [
        "if not boundary or not self.boundary_re.fullmatch(boundary):",
        "if not boundary"
    ],
    [
        "\"Invalid boundary in multipart: %s\" % force_str(boundary)",
        "\"Invalid boundary in multipart:"
    ],
    [
        "raise MultiPartParserError(\"Invalid content length: %r\" % content_length)",
        "raise MultiPartParserError(\"Invalid content length: %r\" %"
    ],
    [
        "possible_sizes = [x.chunk_size for x in upload_handlers if x.chunk_size]",
        "possible_sizes = [x.chunk_size for x in upload_handlers"
    ],
    [
        "Parse the POST data and break it into a FILES MultiValueDict and a POST",
        "Parse the POST data and break it into a FILES MultiValueDict and a"
    ],
    [
        "Return a tuple containing the POST and FILES dictionary, respectively.",
        "Return a tuple containing the POST and"
    ],
    [
        "for item_type, meta_data, field_stream in Parser(stream, self._boundary):",
        "for item_type, meta_data, field_stream"
    ],
    [
        "\"The number of GET/POST parameters exceeded \"",
        "\"The number of GET/POST parameters exceeded"
    ],
    [
        "\"The number of files exceeded \"",
        "\"The number of"
    ],
    [
        "Handle all the signaling that takes place when a file is complete.",
        "Handle all the signaling that takes place when a"
    ],
    [
        "Sanitize the filename of an upload.",
        "Sanitize the filename"
    ],
    [
        "Remove all possible path separators, even though that might remove more",
        "Remove all possible path separators, even"
    ],
    [
        "than actually required by the target system. Filenames that could",
        "than actually required by the target system. Filenames that"
    ],
    [
        "potentially cause problems (current/parent dir) are also discarded.",
        "potentially cause problems (current/parent"
    ],
    [
        "It should be noted that this function could still return a \"filepath\"",
        "It should be noted that this function could still return a"
    ],
    [
        "like \"C:some_file.txt\" which is handled later on by the storage layer.",
        "like \"C:some_file.txt\" which is handled later on by the storage"
    ],
    [
        "So while this function does sanitize filenames to some extent, the",
        "So while this function does sanitize filenames to"
    ],
    [
        "resulting filename should still be considered as untrusted user input.",
        "resulting filename should still be considered"
    ],
    [
        "file_name = \"\".join([char for char in file_name if char.isprintable()])",
        "file_name = \"\".join([char for char in file_name"
    ],
    [
        "if file_name in {\"\", \".\", \"..\"}:",
        "if file_name in"
    ],
    [
        "The LazyStream wrapper allows one to get and \"unget\" bytes from a stream.",
        "The LazyStream wrapper allows one to get and"
    ],
    [
        "Given a producer object (an iterator that yields bytestrings), the",
        "Given a producer object (an iterator"
    ],
    [
        "LazyStream object will support iteration, reading, and keeping a \"look-back\"",
        "LazyStream object will support iteration, reading, and"
    ],
    [
        "variable in case you need to \"unget\" some bytes.",
        "variable in case you need to \"unget\" some"
    ],
    [
        "Every LazyStream must have a producer when instantiated.",
        "Every LazyStream must have"
    ],
    [
        "A producer is an iterable that returns a string each time it",
        "A producer is an iterable that returns a string"
    ],
    [
        "remaining = self._remaining if size is None else size",
        "remaining = self._remaining if size"
    ],
    [
        "Used when the exact number of bytes to read is unimportant.",
        "Used when the exact number of bytes to"
    ],
    [
        "Return whatever chunk is conveniently returned from the iterator.",
        "Return whatever chunk is conveniently returned from the"
    ],
    [
        "Useful to avoid unnecessary bookkeeping if performance is an issue.",
        "Useful to avoid unnecessary bookkeeping if performance is an"
    ],
    [
        "Used to invalidate/disable this lazy stream.",
        "Used to invalidate/disable this"
    ],
    [
        "Replace the producer with an empty list. Any leftover bytes that have",
        "Replace the producer with an empty list. Any leftover bytes that"
    ],
    [
        "already been read will still be reported upon read() and/or next().",
        "already been read will still be reported upon"
    ],
    [
        "Place bytes back onto the front of the lazy stream.",
        "Place bytes back onto the front"
    ],
    [
        "Future calls to read() will return those bytes first. The",
        "Future calls to read() will"
    ],
    [
        "stream position and thus tell() will be rewound.",
        "stream position and thus tell() will be"
    ],
    [
        "Update the unget history as a sanity check to see if we've pushed",
        "Update the unget history as a sanity check to see if we've"
    ],
    [
        "back the same number of bytes in one chunk. If we keep ungetting the",
        "back the same number of bytes in one chunk. If we keep ungetting"
    ],
    [
        "infinite loop of some sort. This is usually caused by a",
        "infinite loop of some sort. This is usually"
    ],
    [
        "\"The multipart parser got stuck, which shouldn't happen with\"",
        "\"The multipart parser got stuck, which shouldn't happen"
    ],
    [
        "\" normal uploaded files. Check for malicious upload activity;\"",
        "\" normal uploaded files. Check"
    ],
    [
        "\" if there is none, report this to the Django developers.\"",
        "\" if there is none, report"
    ],
    [
        "An iterable that will yield chunks of data. Given a file-like object as the",
        "An iterable that will yield chunks of data. Given a file-like object as"
    ],
    [
        "constructor, yield chunks of read operations from that object.",
        "constructor, yield chunks of read operations from"
    ],
    [
        "A Producer that will iterate over boundaries.",
        "A Producer that will"
    ],
    [
        "A Producer that is sensitive to boundaries.",
        "A Producer that is"
    ],
    [
        "Will happily yield bytes until a boundary is found. Will yield the bytes",
        "Will happily yield bytes until a boundary is found. Will yield the"
    ],
    [
        "before the boundary, throw away the boundary bytes themselves, and push the",
        "before the boundary, throw away the"
    ],
    [
        "post-boundary bytes back on the stream.",
        "post-boundary bytes back on the"
    ],
    [
        "The future calls to next() after locating the boundary will raise a",
        "The future calls to next() after locating the boundary"
    ],
    [
        "Find a multipart boundary in data.",
        "Find a multipart boundary"
    ],
    [
        "Should no boundary exist in the data, return None. Otherwise, return",
        "Should no boundary exist in the data,"
    ],
    [
        "a tuple containing the indices of the following:",
        "a tuple containing the indices of"
    ],
    [
        "* the end of current encapsulation",
        "* the end"
    ],
    [
        "* the start of the next encapsulation",
        "* the start of the"
    ],
    [
        "Parse one and exactly one stream that encapsulates a boundary.",
        "Parse one and exactly one stream that encapsulates"
    ],
    [
        "raise MultiPartParserError(\"Request max total header size exceeded.\")",
        "raise MultiPartParserError(\"Request max total header size"
    ],
    [
        "params = {k: v.encode() for k, v in params.items()}",
        "params = {k: v.encode() for k, v in"
    ],
    [
        "from urllib.parse import parse_qsl, quote, urlencode, urljoin, urlsplit",
        "from urllib.parse import parse_qsl, quote, urlencode, urljoin,"
    ],
    [
        "You cannot access raw_post_data from a request that has",
        "You cannot access raw_post_data from a request"
    ],
    [
        "multipart/* POST data if it has been accessed via POST,",
        "multipart/* POST data if it has been"
    ],
    [
        "if self.method is None or not self.get_full_path():",
        "if self.method is None"
    ],
    [
        "return \"<%s: %s %r>\" % (",
        "return \"<%s: %s"
    ],
    [
        "\"\"\"Return a list of MediaType instances, in order of preference.\"\"\"",
        "\"\"\"Return a list of MediaType instances,"
    ],
    [
        "(MediaType(token) for token in header_value.split(\",\") if token.strip()),",
        "(MediaType(token) for token in header_value.split(\",\")"
    ],
    [
        "Return the preferred MediaType instance which matches the given media type.",
        "Return the preferred MediaType instance which matches the given media"
    ],
    [
        "\"\"\"Select the preferred media type from the provided options.\"\"\"",
        "\"\"\"Select the preferred media type"
    ],
    [
        "if not media_types or not self.accepted_types:",
        "if not media_types"
    ],
    [
        "if (accepted_type := self.accepted_type(media_type)) is not None",
        "if (accepted_type := self.accepted_type(media_type)) is"
    ],
    [
        "\"\"\"Does the client accept a response in the given media type?\"\"\"",
        "\"\"\"Does the client accept a response in the given"
    ],
    [
        "Return the HTTP host using the environment or request headers. Skip",
        "Return the HTTP host using the environment"
    ],
    [
        "allowed hosts protection, so may return an insecure host.",
        "allowed hosts protection, so may return an"
    ],
    [
        "if settings.USE_X_FORWARDED_HOST and (\"HTTP_X_FORWARDED_HOST\" in self.META):",
        "if settings.USE_X_FORWARDED_HOST and"
    ],
    [
        "host = \"%s:%s\" % (host, server_port)",
        "host = \"%s:%s\" % (host,"
    ],
    [
        "\"\"\"Return the HTTP host using the environment or request headers.\"\"\"",
        "\"\"\"Return the HTTP host using the environment or"
    ],
    [
        "msg = \"Invalid HTTP_HOST header: %r.\" % host",
        "msg = \"Invalid HTTP_HOST header: %r.\""
    ],
    [
        "msg += \" You may need to add %r to ALLOWED_HOSTS.\" % domain",
        "msg += \" You may need to add %r to"
    ],
    [
        "\"\"\"Return the port number for the request as a string.\"\"\"",
        "\"\"\"Return the port number for the request as"
    ],
    [
        "if settings.USE_X_FORWARDED_PORT and \"HTTP_X_FORWARDED_PORT\" in self.META:",
        "if settings.USE_X_FORWARDED_PORT and \"HTTP_X_FORWARDED_PORT\""
    ],
    [
        "\"/\" if force_append_slash and not path.endswith(\"/\") else \"\",",
        "\"/\" if force_append_slash and"
    ],
    [
        "def get_signed_cookie(self, key, default=RAISE_ERROR, salt=\"\", max_age=None):",
        "def get_signed_cookie(self, key,"
    ],
    [
        "Attempt to return a signed cookie. If the signature fails or the",
        "Attempt to return a signed cookie. If the"
    ],
    [
        "cookie has expired, raise an exception, unless the `default` argument",
        "cookie has expired, raise an"
    ],
    [
        "is provided,  in which case return that value.",
        "is provided, in which case return that"
    ],
    [
        "Build an absolute URI from the location and the variables available in",
        "Build an absolute URI from the location and the"
    ],
    [
        "this request. If no ``location`` is specified, build the absolute URI",
        "this request. If no ``location`` is specified,"
    ],
    [
        "using request.get_full_path(). If the location is absolute, convert it",
        "using request.get_full_path(). If the location"
    ],
    [
        "is scheme-relative (i.e., ``//example.com/``), urljoin() it to a base",
        "is scheme-relative (i.e., ``//example.com/``), urljoin() it to"
    ],
    [
        "URL constructed from the request variables.",
        "URL constructed from the request"
    ],
    [
        "location = urljoin(self._current_scheme_host + self.path, location)",
        "location = urljoin(self._current_scheme_host +"
    ],
    [
        "Hook for subclasses like WSGIRequest to implement. Return 'http' by",
        "Hook for subclasses like WSGIRequest to implement. Return"
    ],
    [
        "\"The SECURE_PROXY_SSL_HEADER setting must be a tuple containing \"",
        "\"The SECURE_PROXY_SSL_HEADER setting must be"
    ],
    [
        "return \"https\" if header_value.strip() == secure_value else \"http\"",
        "return \"https\" if header_value.strip()"
    ],
    [
        "Set the encoding used for GET/POST accesses. If the GET or POST",
        "Set the encoding used for GET/POST accesses. If"
    ],
    [
        "dictionary has already been created, remove and recreate it on the",
        "dictionary has already been created, remove and recreate it on"
    ],
    [
        "next access (so that it is decoded correctly).",
        "next access (so that it is"
    ],
    [
        "\"You cannot set the upload handlers after the upload has been \"",
        "\"You cannot set the upload handlers after"
    ],
    [
        "\"\"\"Return a tuple of (POST QueryDict, FILES MultiValueDict).\"\"\"",
        "\"\"\"Return a tuple of (POST"
    ],
    [
        "\"You cannot alter upload handlers after the upload has been \"",
        "\"You cannot alter upload handlers after the upload has been"
    ],
    [
        "parser = MultiPartParser(META, post_data, self.upload_handlers, self.encoding)",
        "parser = MultiPartParser(META,"
    ],
    [
        "\"You cannot access body after reading from request's data stream\"",
        "\"You cannot access body after reading"
    ],
    [
        "\"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"",
        "\"\"\"Populate self._post and self._files if the content-type is a form"
    ],
    [
        "if self._read_started and not hasattr(self, \"_body\"):",
        "if self._read_started and not"
    ],
    [
        "\"HTTP requests with the 'application/x-www-form-urlencoded' \"",
        "\"HTTP requests with the 'application/x-www-form-urlencoded'"
    ],
    [
        "\"\"\"Allow header lookup using underscores in place of hyphens.\"\"\"",
        "\"\"\"Allow header lookup using underscores in place"
    ],
    [
        "A specialized MultiValueDict which represents a query string.",
        "A specialized MultiValueDict which represents"
    ],
    [
        "A QueryDict can be used to represent GET or POST data. It subclasses",
        "A QueryDict can be used to represent GET or POST data. It"
    ],
    [
        "MultiValueDict since keys in such data can be repeated, for instance",
        "MultiValueDict since keys in such data can"
    ],
    [
        "in the data from a form with a <select multiple> field.",
        "in the data from a form with a <select multiple>"
    ],
    [
        "By default QueryDicts are immutable, though the copy() method",
        "By default QueryDicts are immutable,"
    ],
    [
        "will always return a mutable copy.",
        "will always return a mutable"
    ],
    [
        "Both keys and values set on this class are converted from the given encoding",
        "Both keys and values set on this"
    ],
    [
        "for key, value in parse_qsl(query_string, **parse_qsl_kwargs):",
        "for key, value"
    ],
    [
        "\"The number of GET/POST parameters exceeded \"",
        "\"The number of GET/POST"
    ],
    [
        "def fromkeys(cls, iterable, value=\"\", mutable=False, encoding=None):",
        "def fromkeys(cls, iterable, value=\"\","
    ],
    [
        "Return a new QueryDict with keys (may be repeated) from an iterable and",
        "Return a new QueryDict with keys (may be repeated) from an"
    ],
    [
        "raise AttributeError(\"This QueryDict instance is immutable\")",
        "raise AttributeError(\"This QueryDict instance is"
    ],
    [
        "list_ = [bytes_to_text(elt, self.encoding) for elt in list_]",
        "list_ = [bytes_to_text(elt, self.encoding) for"
    ],
    [
        "\"\"\"Return a mutable copy of this object.\"\"\"",
        "\"\"\"Return a mutable copy of"
    ],
    [
        "Return an encoded string of all query string arguments.",
        "Return an encoded string of all query"
    ],
    [
        "`safe` specifies characters which don't require quoting, for example::",
        "`safe` specifies characters which don't require quoting,"
    ],
    [
        "return \"%s=%s\" % ((quote(k, safe), quote(v, safe)))",
        "return \"%s=%s\" % ((quote(k,"
    ],
    [
        "params_str = \"\".join(\"; %s=%s\" % (k, v) for k, v in self.params.items())",
        "params_str = \"\".join(\"; %s=%s\" % (k, v)"
    ],
    [
        "(\"/%s\" % self.sub_type) if self.sub_type else \"\",",
        "(\"/%s\" % self.sub_type) if self.sub_type"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__qualname__, self)",
        "return \"<%s: %s>\" %"
    ],
    [
        "return self.main_type == \"*\" and self.sub_type == \"*\"",
        "return self.main_type == \"*\" and self.sub_type"
    ],
    [
        "return self.main_type == other.main_type and self.sub_type in {",
        "return self.main_type == other.main_type and self.sub_type in"
    ],
    [
        "Convert bytes objects to strings, using the given encoding. Illegally",
        "Convert bytes objects to strings, using"
    ],
    [
        "encoded input characters are replaced with Unicode \"unknown\" codepoint",
        "encoded input characters are replaced"
    ],
    [
        "Return any non-bytes objects without change.",
        "Return any non-bytes"
    ],
    [
        "Return a (domain, port) tuple from a given host.",
        "Return a (domain, port) tuple from a given"
    ],
    [
        "Returned domain is lowercased. If the host is invalid, the domain will be",
        "Returned domain is lowercased. If the host is invalid, the"
    ],
    [
        "Validate the given host for this site.",
        "Validate the given host for"
    ],
    [
        "Check that the host looks valid and matches a host or host pattern in the",
        "Check that the host looks valid and matches a host or host pattern in"
    ],
    [
        "given list of ``allowed_hosts``. Any pattern beginning with a period",
        "given list of ``allowed_hosts``. Any"
    ],
    [
        "matches a domain and all its subdomains (e.g. ``.example.com`` matches",
        "matches a domain and all its subdomains (e.g."
    ],
    [
        "``example.com`` and any subdomain), ``*`` matches anything, and anything",
        "``example.com`` and any subdomain), ``*`` matches anything, and"
    ],
    [
        "Note: This function assumes that the given host is lowercased and has",
        "Note: This function assumes that the given host"
    ],
    [
        "already had the port, if any, stripped off.",
        "already had the port, if any, stripped"
    ],
    [
        "Return ``True`` for a valid host, ``False`` otherwise.",
        "Return ``True`` for a valid host,"
    ],
    [
        "pattern == \"*\" or is_same_domain(host, pattern) for pattern in allowed_hosts",
        "pattern == \"*\" or is_same_domain(host, pattern) for"
    ],
    [
        "Populate the initial data using __setitem__ to ensure values are",
        "Populate the initial data using"
    ],
    [
        "`value` can't be represented in the given charset, apply MIME-encoding.",
        "`value` can't be represented in the given charset, apply"
    ],
    [
        "if \"\\n\" in value or \"\\r\" in value:",
        "if \"\\n\" in value"
    ],
    [
        "f\"Header values can't contain newlines (got {value!r})\"",
        "f\"Header values can't contain newlines"
    ],
    [
        "if (isinstance(value, bytes) and (b\"\\n\" in value or b\"\\r\" in value)) or (",
        "if (isinstance(value, bytes) and (b\"\\n\" in value or b\"\\r\" in"
    ],
    [
        "isinstance(value, str) and (\"\\n\" in value or \"\\r\" in value)",
        "isinstance(value, str) and (\"\\n\" in value"
    ],
    [
        "f\"Header values can't contain newlines (got {value!r})\"",
        "f\"Header values can't contain newlines (got"
    ],
    [
        "e.reason += \", HTTP response headers must be in %s format\" % charset",
        "e.reason += \", HTTP response headers must be in %s format\" %"
    ],
    [
        "An HTTP response base class with dictionary-accessed headers.",
        "An HTTP response base"
    ],
    [
        "This class doesn't handle content. It should not be used directly.",
        "This class doesn't handle content. It should"
    ],
    [
        "Use the HttpResponse and StreamingHttpResponse subclasses instead.",
        "Use the HttpResponse and StreamingHttpResponse"
    ],
    [
        "self, content_type=None, status=None, reason=None, charset=None, headers=None",
        "self, content_type=None, status=None, reason=None, charset=None,"
    ],
    [
        "\"'headers' must not contain 'Content-Type' when the \"",
        "\"'headers' must not contain 'Content-Type'"
    ],
    [
        "raise TypeError(\"HTTP status code must be an integer.\")",
        "raise TypeError(\"HTTP status code must"
    ],
    [
        "- a string in the correct format,",
        "- a string in"
    ],
    [
        "- a naive ``datetime.datetime`` object in UTC,",
        "- a naive ``datetime.datetime``"
    ],
    [
        "- an aware ``datetime.datetime`` object in any time zone.",
        "- an aware ``datetime.datetime`` object in"
    ],
    [
        "If it is a ``datetime.datetime`` object then calculate ``max_age``.",
        "If it is a ``datetime.datetime``"
    ],
    [
        "raise ValueError(\"'expires' and 'max_age' can't be used together.\")",
        "raise ValueError(\"'expires' and 'max_age' can't"
    ],
    [
        "if samesite.lower() not in (\"lax\", \"none\", \"strict\"):",
        "if samesite.lower() not in"
    ],
    [
        "raise ValueError('samesite must be \"lax\", \"none\", or \"strict\".')",
        "raise ValueError('samesite must be \"lax\","
    ],
    [
        "\"\"\"Set a header unless it has already been set.\"\"\"",
        "\"\"\"Set a header unless it"
    ],
    [
        "def set_signed_cookie(self, key, value, salt=\"\", **kwargs):",
        "def set_signed_cookie(self, key,"
    ],
    [
        "def delete_cookie(self, key, path=\"/\", domain=None, samesite=None):",
        "def delete_cookie(self, key, path=\"/\","
    ],
    [
        "secure = key.startswith((\"__Secure-\", \"__Host-\")) or (",
        "secure = key.startswith((\"__Secure-\", \"__Host-\"))"
    ],
    [
        "\"\"\"Turn a value into a bytestring encoded in the output charset.\"\"\"",
        "\"\"\"Turn a value into a bytestring encoded in the output"
    ],
    [
        "raise OSError(\"This %s instance is not writable\" % self.__class__.__name__)",
        "raise OSError(\"This %s instance is not writable\""
    ],
    [
        "\"This %s instance cannot tell its position\" % self.__class__.__name__",
        "\"This %s instance cannot tell its position\" %"
    ],
    [
        "raise OSError(\"This %s instance is not writable\" % self.__class__.__name__)",
        "raise OSError(\"This %s instance is not writable\" %"
    ],
    [
        "An HTTP response class with a string as content.",
        "An HTTP response class with a string"
    ],
    [
        "This content can be read, appended to, or replaced.",
        "This content can be read, appended"
    ],
    [
        "\"\"\"Full HTTP message, including headers, as a bytestring.\"\"\"",
        "\"\"\"Full HTTP message, including"
    ],
    [
        "return self.serialize_headers() + b\"\\r\\n\\r\\n\" + self.content",
        "return self.serialize_headers() + b\"\\r\\n\\r\\n\" +"
    ],
    [
        "if hasattr(value, \"__iter__\") and not isinstance(",
        "if hasattr(value, \"__iter__\") and not"
    ],
    [
        "content = b\"\".join(self.make_bytes(chunk) for chunk in value)",
        "content = b\"\".join(self.make_bytes(chunk) for chunk"
    ],
    [
        "A streaming HTTP response class with an iterator as content.",
        "A streaming HTTP response class"
    ],
    [
        "This should only be iterated once, when the response is streamed to the",
        "This should only be iterated once, when the response is streamed"
    ],
    [
        "client. However, it can be appended to or replaced with a new iterator",
        "client. However, it can be appended to or replaced"
    ],
    [
        "that wraps the original content (or yields entirely new content).",
        "that wraps the original content (or yields"
    ],
    [
        "\"This %s instance has no `content` attribute. Use \"",
        "\"This %s instance has no `content` attribute."
    ],
    [
        "\"This %s instance has no `text` attribute.\" % self.__class__.__name__",
        "\"This %s instance has no `text`"
    ],
    [
        "\"StreamingHttpResponse must consume asynchronous iterators in order to \"",
        "\"StreamingHttpResponse must consume asynchronous iterators in order"
    ],
    [
        "\"serve them synchronously. Use a synchronous iterator instead.\",",
        "\"serve them synchronously. Use a"
    ],
    [
        "\"StreamingHttpResponse must consume synchronous iterators in order to \"",
        "\"StreamingHttpResponse must consume synchronous iterators in"
    ],
    [
        "\"serve them asynchronously. Use an asynchronous iterator instead.\",",
        "\"serve them asynchronously. Use an asynchronous iterator"
    ],
    [
        "A streaming HTTP response class optimized for files.",
        "A streaming HTTP response"
    ],
    [
        "def __init__(self, *args, as_attachment=False, filename=\"\", **kwargs):",
        "def __init__(self, *args, as_attachment=False,"
    ],
    [
        "\"content_type\" not in kwargs or kwargs[\"content_type\"] is None",
        "\"content_type\" not in kwargs"
    ],
    [
        "Set some common response headers (Content-Length, Content-Type, and",
        "Set some common response headers (Content-Length, Content-Type,"
    ],
    [
        "Content-Disposition) based on the `filelike` response content.",
        "Content-Disposition) based on the"
    ],
    [
        "filename = filename if isinstance(filename, str) else \"\"",
        "filename = filename if isinstance(filename, str) else"
    ],
    [
        "seekable = hasattr(filelike, \"seek\") and (",
        "seekable = hasattr(filelike, \"seek\") and"
    ],
    [
        "def __init__(self, redirect_to, preserve_request=False, *args, **kwargs):",
        "def __init__(self, redirect_to, preserve_request=False, *args,"
    ],
    [
        "if parsed.scheme and parsed.scheme not in self.allowed_schemes:",
        "if parsed.scheme and parsed.scheme not in"
    ],
    [
        "\"Unsafe redirect to URL with protocol '%s'\" % parsed.scheme",
        "\"Unsafe redirect to URL with protocol '%s'\""
    ],
    [
        "return \"<%(cls)s [%(methods)s] status_code=%(status_code)d%(content_type)s>\" % {",
        "return \"<%(cls)s [%(methods)s]"
    ],
    [
        "An HTTP response class that consumes data to be serialized to JSON.",
        "An HTTP response class that consumes data"
    ],
    [
        ":param data: Data to be dumped into json. By default only ``dict`` objects",
        ":param data: Data to be dumped into json. By default"
    ],
    [
        "the ``safe`` parameter for more information.",
        "the ``safe`` parameter for more"
    ],
    [
        ":param encoder: Should be a json encoder class. Defaults to",
        ":param encoder: Should be a json encoder class. Defaults"
    ],
    [
        ":param safe: Controls if only ``dict`` objects may be serialized. Defaults",
        ":param safe: Controls if only ``dict`` objects"
    ],
    [
        ":param json_dumps_params: A dictionary of kwargs passed to json.dumps().",
        ":param json_dumps_params: A dictionary of kwargs passed to"
    ],
    [
        "if safe and not isinstance(data, dict):",
        "if safe and not isinstance(data,"
    ],
    [
        "\"In order to allow non-dict objects to be serialized set the \"",
        "\"In order to allow non-dict objects to be serialized"
    ],
    [
        "Return a dictionary parsed from a `Cookie:` header string.",
        "Return a dictionary parsed from a `Cookie:` header"
    ],
    [
        "This module converts requested URLs to callback view functions.",
        "This module converts requested URLs to callback"
    ],
    [
        "URLResolver is the main class here. Its resolve() method takes a URL (as",
        "URLResolver is the main class here. Its"
    ],
    [
        "a string) and returns a ResolverMatch object which provides access to all",
        "a string) and returns a ResolverMatch object which provides"
    ],
    [
        "attributes of the resolved URL match.",
        "attributes of the resolved URL"
    ],
    [
        "self.app_names = [x for x in app_names if x] if app_names else []",
        "self.app_names = [x for x in app_names if x]"
    ],
    [
        "self.namespaces = [x for x in namespaces if x] if namespaces else []",
        "self.namespaces = [x for x in namespaces if x] if"
    ],
    [
        "self._func_path = func.__class__.__module__ + \".\" + func.__class__.__name__",
        "self._func_path = func.__class__.__module__ +"
    ],
    [
        "self._func_path = func.__module__ + \".\" + func.__name__",
        "self._func_path = func.__module__ +"
    ],
    [
        "f\", extra_kwargs={self.extra_kwargs!r}\" if self.extra_kwargs else \"\",",
        "f\", extra_kwargs={self.extra_kwargs!r}\" if"
    ],
    [
        "Return a compiled regular expression based on the active language.",
        "Return a compiled regular expression based"
    ],
    [
        "f'\"{regex}\" is not a valid regular expression: {e}'",
        "f'\"{regex}\" is not a valid"
    ],
    [
        "Format the URL pattern for display in warning messages.",
        "Format the URL pattern for display in"
    ],
    [
        "Check that the pattern does not begin with a forward slash.",
        "Check that the pattern does not begin with a forward"
    ],
    [
        "if self._regex.startswith((\"/\", \"^/\", \"^\\\\/\")) and not self._regex.endswith(",
        "if self._regex.startswith((\"/\", \"^/\", \"^\\\\/\")) and"
    ],
    [
        "\"Your URL pattern {} has a route beginning with a '/'. Remove this \"",
        "\"Your URL pattern {} has a route beginning with a '/'. Remove"
    ],
    [
        "\"slash as it is unnecessary. If this pattern is targeted in an \"",
        "\"slash as it is unnecessary. If this pattern is"
    ],
    [
        "\"include(), ensure the include() pattern has a trailing '/'.\".format(",
        "\"include(), ensure the include() pattern has a trailing"
    ],
    [
        "args = () if kwargs else match.groups()",
        "args = () if kwargs else"
    ],
    [
        "kwargs = {k: v for k, v in kwargs.items() if v is not None}",
        "kwargs = {k: v for k, v in kwargs.items()"
    ],
    [
        "\"Your URL pattern {} uses include with a route ending with a '$'. \"",
        "\"Your URL pattern {} uses include with a"
    ],
    [
        "\"Remove the dollar from the route to avoid problems including \"",
        "\"Remove the dollar from the route to avoid problems including"
    ],
    [
        "Convert a path pattern into a regular expression. Return the regular",
        "Convert a path pattern into a regular expression."
    ],
    [
        "expression and a dictionary mapping the capture names to the converters.",
        "expression and a dictionary mapping the capture"
    ],
    [
        "f\"URL route {route!r} cannot contain whitespace in angle brackets <…>.\"",
        "f\"URL route {route!r} cannot contain"
    ],
    [
        "f\"URL route {route!r} uses parameter name {parameter!r} which \"",
        "f\"URL route {route!r} uses parameter name {parameter!r}"
    ],
    [
        "f\"URL route {route!r} uses invalid converter {raw_converter!r}.\"",
        "f\"URL route {route!r} uses"
    ],
    [
        "Return a compiled regular expression based on the active language.",
        "Return a compiled regular expression based on"
    ],
    [
        "if \"(?P<\" in route or route.startswith(\"^\") or route.endswith(\"$\"):",
        "if \"(?P<\" in route or route.startswith(\"^\")"
    ],
    [
        "\"Your URL pattern {} has a route that contains '(?P<', begins \"",
        "\"Your URL pattern {} has a route that contains '(?P<', begins"
    ],
    [
        "\"with a '^', or ends with a '$'. This was likely an oversight \"",
        "\"with a '^', or ends with a '$'. This"
    ],
    [
        "msg = \"Your URL pattern %s has an unmatched '%s' bracket.\"",
        "msg = \"Your URL pattern %s"
    ],
    [
        "if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:",
        "if language_code == settings.LANGUAGE_CODE"
    ],
    [
        "def __init__(self, pattern, callback, default_args=None, name=None):",
        "def __init__(self, pattern, callback, default_args=None,"
    ],
    [
        "return \"<%s %s>\" % (self.__class__.__name__, self.pattern.describe())",
        "return \"<%s %s>\" %"
    ],
    [
        "Check that the pattern name does not contain a colon.",
        "Check that the pattern name does not contain"
    ],
    [
        "if self.pattern.name is not None and \":\" in self.pattern.name:",
        "if self.pattern.name is not None and \":\" in"
    ],
    [
        "\"Your URL pattern {} has a name including a ':'. Remove the colon, to \"",
        "\"Your URL pattern {} has a name including"
    ],
    [
        "\"Your URL pattern %s has an invalid view, pass %s.as_view() \"",
        "\"Your URL pattern %s has an invalid view, pass"
    ],
    [
        "A string that identifies the view (e.g. 'path.to.view_function' or",
        "A string that identifies the view"
    ],
    [
        "return callback.__module__ + \".\" + callback.__class__.__name__",
        "return callback.__module__ +"
    ],
    [
        "return callback.__module__ + \".\" + callback.__qualname__",
        "return callback.__module__ + \".\""
    ],
    [
        "self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None",
        "self, pattern, urlconf_name, default_kwargs=None, app_name=None,"
    ],
    [
        "return \"<%s %s (%s:%s) %s>\" % (",
        "return \"<%s %s (%s:%s) %s>\""
    ],
    [
        "namespaces[namespace] = (p_pattern + prefix, sub_pattern)",
        "namespaces[namespace] = (p_pattern + prefix,"
    ],
    [
        "tried.extend([pattern, *t] for t in sub_tried)",
        "tried.extend([pattern, *t] for t"
    ],
    [
        "\"\"\"Join two routes, without the starting ^ in the second route.\"\"\"",
        "\"\"\"Join two routes, without the starting ^"
    ],
    [
        "\"The included URLconf '{name}' does not appear to have \"",
        "\"The included URLconf '{name}' does"
    ],
    [
        "\"any patterns in it. If you see the 'urlpatterns' variable \"",
        "\"any patterns in it. If you see the"
    ],
    [
        "\"with valid patterns in the file then the issue is probably \"",
        "\"with valid patterns in the file then the issue is probably"
    ],
    [
        "callback = getattr(self.urlconf_module, \"handler%s\" % view_type, None)",
        "callback = getattr(self.urlconf_module, \"handler%s\""
    ],
    [
        "callback = getattr(urls, \"handler%s\" % view_type)",
        "callback = getattr(urls, \"handler%s\" %"
    ],
    [
        "def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):",
        "def _reverse_with_prefix(self, lookup_view, _prefix, *args,"
    ],
    [
        "raise ValueError(\"Don't mix *args and **kwargs in call to reverse()!\")",
        "raise ValueError(\"Don't mix *args and **kwargs in call"
    ],
    [
        "for possibility, pattern, defaults, converters in possibilities:",
        "for possibility, pattern, defaults, converters"
    ],
    [
        "candidate_pat = _prefix.replace(\"%\", \"%%\") + result",
        "candidate_pat = _prefix.replace(\"%\", \"%%\") +"
    ],
    [
        "if m is not None and n is not None:",
        "if m is not None"
    ],
    [
        "lookup_view_s = \"%s.%s\" % (m, n)",
        "lookup_view_s = \"%s.%s\" %"
    ],
    [
        "patterns = [pattern for (_, pattern, _, _) in possibilities]",
        "patterns = [pattern for (_, pattern, _, _)"
    ],
    [
        "arg_msg = \"arguments '%s'\" % (args,)",
        "arg_msg = \"arguments '%s'\""
    ],
    [
        "arg_msg = \"keyword arguments '%s'\" % kwargs",
        "arg_msg = \"keyword arguments '%s'\""
    ],
    [
        "msg = \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" % (",
        "msg = \"Reverse for '%s' with %s not found. %d"
    ],
    [
        "\"Reverse for '%(view)s' not found. '%(view)s' is not \"",
        "\"Reverse for '%(view)s' not found. '%(view)s'"
    ],
    [
        "\"a valid view function or pattern name.\" % {\"view\": lookup_view_s}",
        "\"a valid view function or"
    ],
    [
        "\"Cannot override the namespace for a dynamic module that \"",
        "\"Cannot override the namespace for a dynamic module"
    ],
    [
        "\"Passing a %d-tuple to include() is not supported. Pass a \"",
        "\"Passing a %d-tuple to include() is not supported."
    ],
    [
        "\"provide the namespace argument to include() instead.\" % len(arg)",
        "\"provide the namespace argument to include()"
    ],
    [
        "\"Specifying a namespace in include() without providing an app_name \"",
        "\"Specifying a namespace in include() without providing an"
    ],
    [
        "\"is not supported. Set the app_name attribute in the included \"",
        "\"is not supported. Set the app_name attribute in the included"
    ],
    [
        "def _path(route, view, kwargs=None, name=None, Pattern=None):",
        "def _path(route, view,"
    ],
    [
        "if kwargs is not None and not isinstance(kwargs, dict):",
        "if kwargs is not None"
    ],
    [
        "f\"kwargs argument must be a dict, but got {kwargs.__class__.__name__}.\"",
        "f\"kwargs argument must be a dict,"
    ],
    [
        "f\"view must be a callable, pass {view_cls_name}.as_view(), not \"",
        "f\"view must be a callable, pass {view_cls_name}.as_view(), not"
    ],
    [
        "\"view must be a callable or a list/tuple in the case of include().\"",
        "\"view must be a callable or a list/tuple in the"
    ],
    [
        "from .conf import include, path, re_path",
        "from .conf import"
    ],
    [
        "Return a callable corresponding to lookup_view.",
        "Return a callable"
    ],
    [
        "* If lookup_view is already a callable, return it.",
        "* If lookup_view is already"
    ],
    [
        "* If lookup_view is a string import path that can be resolved to a callable,",
        "* If lookup_view is a string import path that can be resolved to"
    ],
    [
        "import that callable and return it, otherwise raise an exception",
        "import that callable and return it, otherwise raise an"
    ],
    [
        "\"'%s' is not a callable or a dot-notation path\" % lookup_view",
        "\"'%s' is not a callable or a dot-notation path\" %"
    ],
    [
        "\"Could not import '%s'. The path must be fully qualified.\" % lookup_view",
        "\"Could not import '%s'. The path must be"
    ],
    [
        "if submod and not module_has_submodule(import_module(parentmod), submod):",
        "if submod and"
    ],
    [
        "\"Could not import '%s'. Parent module %s does not exist.\"",
        "\"Could not import '%s'. Parent module %s does"
    ],
    [
        "\"Could not import '%s'. View does not exist in module %s.\"",
        "\"Could not import '%s'. View does not exist in module"
    ],
    [
        "\"Could not import '%s.%s'. View is not callable.\"",
        "\"Could not import '%s.%s'. View"
    ],
    [
        "if type_name in REGISTERED_CONVERTERS or type_name in DEFAULT_CONVERTERS:",
        "if type_name in REGISTERED_CONVERTERS or type_name"
    ],
    [
        "raise ValueError(f\"Converter {type_name!r} is already registered.\")",
        "raise ValueError(f\"Converter {type_name!r} is"
    ],
    [
        "from urllib.parse import unquote, urlencode, urlsplit, urlunsplit",
        "from urllib.parse import unquote, urlencode, urlsplit,"
    ],
    [
        "from .resolvers import _get_cached_resolver, get_ns_resolver, get_resolver",
        "from .resolvers import"
    ],
    [
        "current_ns = current_path.pop() if current_path else None",
        "current_ns = current_path.pop() if current_path else"
    ],
    [
        "if current_ns and current_ns in app_list:",
        "if current_ns and current_ns in"
    ],
    [
        "\"%s is not a registered namespace inside '%s'\"",
        "\"%s is not a registered"
    ],
    [
        "raise NoReverseMatch(\"%s is not a registered namespace\" % key)",
        "raise NoReverseMatch(\"%s is not a registered namespace\" %"
    ],
    [
        "resolved_url = resolver._reverse_with_prefix(view, prefix, *args, **kwargs)",
        "resolved_url = resolver._reverse_with_prefix(view,"
    ],
    [
        "Set the script prefix for the current thread.",
        "Set the script prefix for the"
    ],
    [
        "Return the currently active script prefix. Useful for client code that",
        "Return the currently active script prefix. Useful for"
    ],
    [
        "wishes to construct their own URLs manually (although accessing the request",
        "wishes to construct their own URLs manually (although accessing"
    ],
    [
        "instance is normally going to be a lot cleaner).",
        "instance is normally going to be a lot"
    ],
    [
        "Unset the script prefix for the current thread.",
        "Unset the script prefix for"
    ],
    [
        "Set the URLconf for the current thread or asyncio task (overriding the",
        "Set the URLconf for the current thread or"
    ],
    [
        "default one in settings). If urlconf_name is None, revert back to the",
        "default one in settings). If urlconf_name is None, revert back to"
    ],
    [
        "Return the root URLconf to use for the current thread or asyncio task if it",
        "Return the root URLconf to use for the"
    ],
    [
        "has been changed from the default one.",
        "has been changed from the default"
    ],
    [
        "Return the ResolverMatch if the given path resolves against the default URL",
        "Return the ResolverMatch if the given path resolves against the"
    ],
    [
        "resolver, False otherwise. This is a convenience method to make working",
        "resolver, False otherwise. This is a"
    ],
    [
        "with \"is this a match?\" cases easier, avoiding try...except blocks.",
        "with \"is this a match?\" cases easier,"
    ],
    [
        "Given a URL (absolute or relative), try to get its translated version in",
        "Given a URL (absolute or relative), try"
    ],
    [
        "Return the original URL if no translated version is found.",
        "Return the original URL if no"
    ],
    [
        "Get a database connection by name, or the default database connection",
        "Get a database connection by name, or the default"
    ],
    [
        "if no name is provided. This is a private API.",
        "if no name is provided. This is"
    ],
    [
        "\"\"\"Get the autocommit status of the connection.\"\"\"",
        "\"\"\"Get the autocommit status of the"
    ],
    [
        "\"\"\"Set the autocommit status of the connection.\"\"\"",
        "\"\"\"Set the autocommit status of"
    ],
    [
        "Create a savepoint (if supported and required by the backend) inside the",
        "Create a savepoint (if supported and required by the backend) inside"
    ],
    [
        "current transaction. Return an identifier for the savepoint that will be",
        "current transaction. Return an identifier for the savepoint that will"
    ],
    [
        "used for the subsequent rollback or commit.",
        "used for the subsequent rollback or"
    ],
    [
        "Roll back the most recent savepoint (if one exists). Do nothing if",
        "Roll back the most recent savepoint (if one exists)."
    ],
    [
        "Commit the most recent savepoint (if one exists). Do nothing if",
        "Commit the most recent savepoint (if one exists). Do nothing"
    ],
    [
        "Reset the counter used to generate unique savepoint ids in this thread.",
        "Reset the counter used to generate"
    ],
    [
        "\"\"\"Get the \"needs rollback\" flag -- for *advanced use* only.\"\"\"",
        "\"\"\"Get the \"needs rollback\" flag -- for *advanced"
    ],
    [
        "Set or unset the \"needs rollback\" flag -- for *advanced use* only.",
        "Set or unset the \"needs rollback\""
    ],
    [
        "When `rollback` is `True`, trigger a rollback when exiting the innermost",
        "When `rollback` is `True`, trigger a"
    ],
    [
        "enclosing atomic block that has `savepoint=True` (that's the default). Use",
        "enclosing atomic block that has `savepoint=True` (that's the default)."
    ],
    [
        "this to force a rollback without raising an exception.",
        "this to force a rollback without"
    ],
    [
        "When `rollback` is `False`, prevent such a rollback. Use this only after",
        "When `rollback` is `False`, prevent such a rollback."
    ],
    [
        "rolling back to a known-good state! Otherwise, you break the atomic block",
        "rolling back to a known-good state! Otherwise, you break the"
    ],
    [
        "Internal low-level utility to mark a transaction as \"needs rollback\" when",
        "Internal low-level utility to mark a transaction"
    ],
    [
        "an exception is raised while not enforcing the enclosed block to be in a",
        "an exception is raised while not enforcing the enclosed block"
    ],
    [
        "transaction. This is needed by Model.save() and friends to avoid starting a",
        "transaction. This is needed by Model.save() and friends to avoid"
    ],
    [
        "transaction when in autocommit mode and a single query is executed.",
        "transaction when in autocommit mode and"
    ],
    [
        "but it uses low-level utilities to avoid performance overhead.",
        "but it uses low-level utilities to"
    ],
    [
        "Register `func` to be called when the current transaction is committed.",
        "Register `func` to be called when"
    ],
    [
        "If the current transaction is rolled back, `func` will not be called.",
        "If the current transaction is rolled back,"
    ],
    [
        "Guarantee the atomic execution of a given block.",
        "Guarantee the atomic execution of a"
    ],
    [
        "An instance can be used either as a decorator or as a context manager.",
        "An instance can be used either as a decorator"
    ],
    [
        "When it's used as a decorator, __call__ wraps the execution of the",
        "When it's used as a decorator, __call__ wraps the execution"
    ],
    [
        "decorated function in the instance itself, used as a context manager.",
        "decorated function in the instance itself, used"
    ],
    [
        "When it's used as a context manager, __enter__ creates a transaction or a",
        "When it's used as a context manager, __enter__ creates"
    ],
    [
        "savepoint, depending on whether a transaction is already in progress, and",
        "savepoint, depending on whether a transaction is already"
    ],
    [
        "__exit__ commits the transaction or releases the savepoint on normal exit,",
        "__exit__ commits the transaction or releases"
    ],
    [
        "and rolls back the transaction or to the savepoint on exceptions.",
        "and rolls back the transaction or to"
    ],
    [
        "It's possible to disable the creation of savepoints if the goal is to",
        "It's possible to disable the creation of"
    ],
    [
        "ensure that some code runs within a transaction without creating overhead.",
        "ensure that some code runs within a transaction without creating"
    ],
    [
        "A stack of savepoint identifiers is maintained as an attribute of the",
        "A stack of savepoint identifiers is maintained as"
    ],
    [
        "connection. None denotes the absence of a savepoint.",
        "connection. None denotes the absence of a"
    ],
    [
        "This allows reentrancy even if the same AtomicWrapper is reused. For",
        "This allows reentrancy even if the same AtomicWrapper is reused."
    ],
    [
        "example, it's possible to define `oa = atomic('other')` and use `@oa` or",
        "example, it's possible to define `oa = atomic('other')` and use"
    ],
    [
        "Since database connections are thread-local, this is thread-safe.",
        "Since database connections are thread-local, this is"
    ],
    [
        "An atomic block can be tagged as durable. In this case, a RuntimeError is",
        "An atomic block can be tagged as durable. In"
    ],
    [
        "raised if it's nested within another atomic block. This guarantees",
        "raised if it's nested within another atomic block."
    ],
    [
        "that database changes in a durable block are committed to the database when",
        "that database changes in a durable block"
    ],
    [
        "\"A durable atomic block cannot be nested within another \"",
        "\"A durable atomic block cannot be"
    ],
    [
        "elif exc_type is None and not connection.needs_rollback:",
        "elif exc_type is None and"
    ],
    [
        "elif not connection.savepoint_ids and not connection.commit_on_exit:",
        "elif not connection.savepoint_ids and not"
    ],
    [
        "Context manager and decorator that reraises backend-specific database",
        "Context manager and decorator that"
    ],
    [
        "if dj_exc_type not in (DataError, IntegrityError):",
        "if dj_exc_type not"
    ],
    [
        "Return a database backend's \"base\" module given a fully qualified database",
        "Return a database backend's \"base\" module given a fully"
    ],
    [
        "backend name, or raise an error if it doesn't exist.",
        "backend name, or raise an"
    ],
    [
        "for _, name, ispkg in pkgutil.iter_modules(django.db.backends.__path__)",
        "for _, name, ispkg in"
    ],
    [
        "if ispkg and name not in {\"base\", \"dummy\"}",
        "if ispkg and name not in"
    ],
    [
        "if backend_name not in [\"django.db.backends.%s\" % b for b in builtin_backends]:",
        "if backend_name not in [\"django.db.backends.%s\" % b for b"
    ],
    [
        "\"%r isn't an available database backend or couldn't be \"",
        "\"%r isn't an available database backend or couldn't"
    ],
    [
        "\"imported. Check the above exception. To use one of the \"",
        "\"imported. Check the above exception. To"
    ],
    [
        "\"built-in backends, use 'django.db.backends.XXX', where XXX \"",
        "\"built-in backends, use 'django.db.backends.XXX', where"
    ],
    [
        "\"    %s\" % (backend_name, \", \".join(backend_reprs))",
        "\" %s\" % (backend_name,"
    ],
    [
        "f\"You must define a '{DEFAULT_DB_ALIAS}' database.\"",
        "f\"You must define a '{DEFAULT_DB_ALIAS}'"
    ],
    [
        "if conn[\"ENGINE\"] == \"django.db.backends.\" or not conn[\"ENGINE\"]:",
        "if conn[\"ENGINE\"] == \"django.db.backends.\" or not"
    ],
    [
        "for setting in [\"NAME\", \"USER\", \"PASSWORD\", \"HOST\", \"PORT\"]:",
        "for setting in [\"NAME\", \"USER\","
    ],
    [
        "If routers is not specified, default to settings.DATABASE_ROUTERS.",
        "If routers is not specified,"
    ],
    [
        "if instance is not None and instance._state.db:",
        "if instance is not"
    ],
    [
        "\"\"\"Return app models allowed to be migrated on provided db.\"\"\"",
        "\"\"\"Return app models allowed to be migrated on provided"
    ],
    [
        "return [model for model in models if self.allow_migrate_model(db, model)]",
        "return [model for model in models if"
    ],
    [
        "Give the autodetector responses to questions it might have.",
        "Give the autodetector responses to questions it might"
    ],
    [
        "This base class has a built-in noninteractive mode, but the",
        "This base class has a"
    ],
    [
        "interactive subclass is what the command-line arguments will use.",
        "interactive subclass is what the"
    ],
    [
        "\"\"\"Should we create an initial migration for the app?\"\"\"",
        "\"\"\"Should we create an initial"
    ],
    [
        "return not any(x.endswith(\".py\") for x in filenames if x != \"__init__.py\")",
        "return not any(x.endswith(\".py\") for x in filenames if"
    ],
    [
        "\"\"\"Adding a NOT NULL field to a model.\"\"\"",
        "\"\"\"Adding a NOT NULL field"
    ],
    [
        "\"\"\"Changing a NULL field to NOT NULL.\"\"\"",
        "\"\"\"Changing a NULL field"
    ],
    [
        "def ask_rename(self, model_name, old_name, new_name, field_instance):",
        "def ask_rename(self, model_name,"
    ],
    [
        "\"\"\"Should these migrations really be merged?\"\"\"",
        "\"\"\"Should these migrations"
    ],
    [
        "\"\"\"Adding an auto_now_add field to a model.\"\"\"",
        "\"\"\"Adding an auto_now_add field"
    ],
    [
        "\"\"\"Adding a unique field with a callable default.\"\"\"",
        "\"\"\"Adding a unique field"
    ],
    [
        "if not result and default is not None:",
        "if not result and default is"
    ],
    [
        "self.prompt_output.write(\"Please answer yes or no: \", ending=\"\")",
        "self.prompt_output.write(\"Please answer yes or"
    ],
    [
        "self.prompt_output.write(\"Please select a valid option: \", ending=\"\")",
        "self.prompt_output.write(\"Please select a valid option: \","
    ],
    [
        "The ``default`` argument allows providing a custom default value (as a",
        "The ``default`` argument allows providing a custom"
    ],
    [
        "string) which will be shown to the user and used as the return value",
        "string) which will be shown to the user and used as"
    ],
    [
        "if the user doesn't provide any other input.",
        "if the user doesn't provide any"
    ],
    [
        "self.prompt_output.write(\"Please enter the default value as valid Python.\")",
        "self.prompt_output.write(\"Please enter the default"
    ],
    [
        "f\"Accept the default '{default}' by pressing 'Enter' or \"",
        "f\"Accept the default '{default}' by pressing"
    ],
    [
        "\"The datetime and django.utils.timezone modules are available, so \"",
        "\"The datetime and django.utils.timezone modules are available, so"
    ],
    [
        "\"it is possible to provide e.g. timezone.now as a value.\"",
        "\"it is possible to provide e.g. timezone.now as a"
    ],
    [
        "self.prompt_output.write(\"Type 'exit' to exit this prompt\")",
        "self.prompt_output.write(\"Type 'exit' to exit"
    ],
    [
        "prompt = \"[default: {}] >>> \".format(default)",
        "prompt = \"[default: {}] >>>"
    ],
    [
        "\"Please enter some code, or 'exit' (without quotes) to exit.\"",
        "\"Please enter some code, or 'exit' (without"
    ],
    [
        "return eval(code, {}, {\"datetime\": datetime, \"timezone\": timezone})",
        "return eval(code, {}, {\"datetime\": datetime,"
    ],
    [
        "\"\"\"Adding a NOT NULL field to a model.\"\"\"",
        "\"\"\"Adding a NOT NULL field"
    ],
    [
        "f\"It is impossible to add a non-nullable field '{field_name}' \"",
        "f\"It is impossible to add a"
    ],
    [
        "f\"to {model_name} without specifying a default. This is \"",
        "f\"to {model_name} without specifying a default. This is"
    ],
    [
        "f\"because the database needs something to populate existing \"",
        "f\"because the database needs something to populate existing"
    ],
    [
        "\"Provide a one-off default now (will be set on all existing \"",
        "\"Provide a one-off default now (will be set"
    ],
    [
        "\"rows with a null value for this column)\"",
        "\"rows with a null value for"
    ],
    [
        "\"Quit and manually define a default value in models.py.\",",
        "\"Quit and manually define a default value"
    ],
    [
        "\"\"\"Changing a NULL field to NOT NULL.\"\"\"",
        "\"\"\"Changing a NULL field to NOT"
    ],
    [
        "f\"It is impossible to change a nullable field '{field_name}' \"",
        "f\"It is impossible to change a nullable"
    ],
    [
        "f\"on {model_name} to non-nullable without providing a \"",
        "f\"on {model_name} to non-nullable without providing a"
    ],
    [
        "f\"default. This is because the database needs something to \"",
        "f\"default. This is because the"
    ],
    [
        "\"Provide a one-off default now (will be set on all existing \"",
        "\"Provide a one-off default now (will be set on all existing"
    ],
    [
        "\"rows with a null value for this column)\"",
        "\"rows with a null value for this"
    ],
    [
        "\"Ignore for now. Existing rows that contain NULL values \"",
        "\"Ignore for now. Existing rows that"
    ],
    [
        "\"will have to be handled manually, for example with a \"",
        "\"will have to be handled manually, for example with a"
    ],
    [
        "\"Quit and manually define a default value in models.py.\",",
        "\"Quit and manually define a default value in"
    ],
    [
        "def ask_rename(self, model_name, old_name, new_name, field_instance):",
        "def ask_rename(self, model_name, old_name, new_name,"
    ],
    [
        "msg = \"Was %s.%s renamed to %s.%s (a %s)? [y/N]\"",
        "msg = \"Was %s.%s renamed"
    ],
    [
        "msg = \"Was the model %s.%s renamed to %s? [y/N]\"",
        "msg = \"Was the model %s.%s"
    ],
    [
        "\"\\nMerging will only work if the operations printed above do not conflict\\n\"",
        "\"\\nMerging will only work if the operations"
    ],
    [
        "+ \"with each other (working on different fields or models)\\n\"",
        "+ \"with each other (working on"
    ],
    [
        "+ \"Should these migration branches be merged? [y/N]\",",
        "+ \"Should these migration branches"
    ],
    [
        "\"\"\"Adding an auto_now_add field to a model.\"\"\"",
        "\"\"\"Adding an auto_now_add field to a"
    ],
    [
        "f\"It is impossible to add the field '{field_name}' with \"",
        "f\"It is impossible to add the field"
    ],
    [
        "f\"'auto_now_add=True' to {model_name} without providing a \"",
        "f\"'auto_now_add=True' to {model_name} without providing"
    ],
    [
        "f\"default. This is because the database needs something to \"",
        "f\"default. This is because the database needs something"
    ],
    [
        "\"Provide a one-off default now which will be set on all \"",
        "\"Provide a one-off default now which will be set on"
    ],
    [
        "\"Quit and manually define a default value in models.py.\",",
        "\"Quit and manually define a default"
    ],
    [
        "\"\"\"Adding a unique field with a callable default.\"\"\"",
        "\"\"\"Adding a unique field"
    ],
    [
        "f\"Callable default on unique field {model_name}.{field_name} \"",
        "f\"Callable default on unique"
    ],
    [
        "f\"will not generate unique values upon migrating.\\n\"",
        "f\"will not generate unique values upon"
    ],
    [
        "f\"Continue making this migration as the first step in \"",
        "f\"Continue making this migration as the first step"
    ],
    [
        "f\"writing a manual migration to generate unique values \"",
        "f\"writing a manual migration to"
    ],
    [
        "\"Quit and edit field options in models.py.\",",
        "\"Quit and edit field options"
    ],
    [
        "f\"Field '{field_name}' on model '{model_name}' not migrated: \"",
        "f\"Field '{field_name}' on model '{model_name}' not"
    ],
    [
        "\"it is impossible to add a non-nullable field without specifying \"",
        "\"it is impossible to add a non-nullable field"
    ],
    [
        "f\"Field '{field_name}' on model '{model_name}' given a default of \"",
        "f\"Field '{field_name}' on model '{model_name}'"
    ],
    [
        "f\"NOT PROVIDED and must be corrected.\"",
        "f\"NOT PROVIDED and"
    ],
    [
        "\"it is impossible to add a field with 'auto_now_add=True' without \"",
        "\"it is impossible to add a"
    ],
    [
        "A single node in the migration graph. Contains direct links to adjacent",
        "A single node in the migration"
    ],
    [
        "A node that doesn't correspond to a migration file on disk.",
        "A node that doesn't correspond to"
    ],
    [
        "(A squashed migration that was removed, for example.)",
        "(A squashed migration that was removed, for"
    ],
    [
        "After the migration graph is processed, all dummy nodes should be removed.",
        "After the migration graph is processed, all"
    ],
    [
        "If there are any left, a nonexistent dependency error is raised.",
        "If there are any left, a nonexistent dependency"
    ],
    [
        "Represent the digraph of all migrations in a project.",
        "Represent the digraph of all migrations in a"
    ],
    [
        "Each migration is a node, and each dependency is an edge. There are",
        "Each migration is a node, and each dependency is an edge. There"
    ],
    [
        "no implicit dependencies between numbered migrations - the numbering is",
        "no implicit dependencies between numbered migrations -"
    ],
    [
        "merely a convention to aid file listing. Every new numbered migration",
        "merely a convention to aid file listing. Every"
    ],
    [
        "has a declared dependency to the previous number, meaning that VCS",
        "has a declared dependency to the previous number,"
    ],
    [
        "branch merges can be detected and resolved.",
        "branch merges can be detected and"
    ],
    [
        "Migrations files can be marked as replacing another set of migrations -",
        "Migrations files can be marked as"
    ],
    [
        "this is to support the \"squash\" feature. The graph handler isn't responsible",
        "this is to support the \"squash\" feature. The"
    ],
    [
        "for these; instead, the code to load them in here should examine the",
        "for these; instead, the code to load them in here should"
    ],
    [
        "migration files and if the replaced migrations are all either unapplied",
        "migration files and if the replaced migrations are all either"
    ],
    [
        "or not present, it should ignore the replaced ones, load in just the",
        "or not present, it should ignore the replaced ones, load in"
    ],
    [
        "replacing migration, and repoint any dependencies that pointed to the",
        "replacing migration, and repoint any dependencies"
    ],
    [
        "replaced migrations to point to the replacing one.",
        "replaced migrations to point to"
    ],
    [
        "A node should be a tuple: (app_path, migration_name). The tree special-cases",
        "A node should be a tuple: (app_path, migration_name). The tree"
    ],
    [
        "things within an app - namely, root nodes and leaf nodes ignore dependencies",
        "things within an app - namely, root"
    ],
    [
        "def add_dependency(self, migration, child, parent, skip_validation=False):",
        "def add_dependency(self, migration, child, parent,"
    ],
    [
        "This may create dummy nodes if they don't yet exist. If",
        "This may create dummy nodes if"
    ],
    [
        "\" child node %r\" % (migration, child)",
        "\" child node %r\""
    ],
    [
        "\" parent node %r\" % (migration, parent)",
        "\" parent node %r\" % (migration,"
    ],
    [
        "Remove each of the `replaced` nodes (when they exist). Any",
        "Remove each of the `replaced` nodes (when they"
    ],
    [
        "dependencies that were referencing them are changed to reference the",
        "dependencies that were referencing them are changed to reference"
    ],
    [
        "\"Unable to find replacement node %r. It was either never added\"",
        "\"Unable to find replacement node %r. It"
    ],
    [
        "\" to the migration graph, or has been removed.\" % (replacement,),",
        "\" to the migration graph, or"
    ],
    [
        "The inverse operation to `remove_replaced_nodes`. Almost. Remove the",
        "The inverse operation to `remove_replaced_nodes`."
    ],
    [
        "replacement node `replacement` and remap its child nodes to `replaced`",
        "replacement node `replacement` and remap its"
    ],
    [
        "- the list of nodes it would have replaced. Don't remap its parent",
        "- the list of nodes it would have replaced. Don't"
    ],
    [
        "nodes as they are expected to be correct already.",
        "nodes as they are expected"
    ],
    [
        "\"Unable to remove replacement node %r. It was either never added\"",
        "\"Unable to remove replacement node %r. It was"
    ],
    [
        "\" to the migration graph, or has been removed already.\"",
        "\" to the migration graph, or has"
    ],
    [
        "\"\"\"Ensure there are no dummy nodes remaining in the graph.\"\"\"",
        "\"\"\"Ensure there are no dummy nodes remaining in"
    ],
    [
        "[n.raise_error() for n in self.node_map.values() if isinstance(n, DummyNode)]",
        "[n.raise_error() for n in"
    ],
    [
        "Given a node, return a list of which previous nodes (dependencies) must",
        "Given a node, return a list of which"
    ],
    [
        "be applied, ending with the node itself. This is the list you would",
        "be applied, ending with the node itself. This is the"
    ],
    [
        "follow if applying the migrations to a database.",
        "follow if applying the migrations"
    ],
    [
        "raise NodeNotFoundError(\"Node %r not a valid node\" % (target,), target)",
        "raise NodeNotFoundError(\"Node %r not a valid node\""
    ],
    [
        "Given a node, return a list of which dependent nodes (dependencies)",
        "Given a node, return a list of which dependent"
    ],
    [
        "must be unapplied, ending with the node itself. This is the list you",
        "must be unapplied, ending with the node itself. This is the list"
    ],
    [
        "would follow if removing the migrations from a database.",
        "would follow if removing the"
    ],
    [
        "raise NodeNotFoundError(\"Node %r not a valid node\" % (target,), target)",
        "raise NodeNotFoundError(\"Node %r not a valid node\" % (target,),"
    ],
    [
        "\"\"\"Iterative depth-first search for finding dependencies.\"\"\"",
        "\"\"\"Iterative depth-first search for finding"
    ],
    [
        "for n in sorted(node.parents if forwards else node.children)",
        "for n in sorted(node.parents if forwards else"
    ],
    [
        "Return all root nodes - that is, nodes with no dependencies inside",
        "Return all root nodes - that is,"
    ],
    [
        "their app. These are the starting point for an app.",
        "their app. These are the starting point for an"
    ],
    [
        "Return all leaf nodes - that is, nodes with no dependents in their app.",
        "Return all leaf nodes - that is,"
    ],
    [
        "These are the \"most current\" version of an app's schema.",
        "These are the \"most current\""
    ],
    [
        "Having more than one per app is technically an error, but one that",
        "Having more than one per app is"
    ],
    [
        "gets handled further up, in the interactive command - it's usually the",
        "gets handled further up, in the interactive command - it's usually"
    ],
    [
        "result of a VCS merge and needs some user input.",
        "result of a VCS merge and needs"
    ],
    [
        "\", \".join(\"%s.%s\" % n for n in cycle)",
        "\", \".join(\"%s.%s\" % n for n in"
    ],
    [
        "return \"Graph: %s nodes, %s edges\" % self._nodes_and_edges()",
        "return \"Graph: %s nodes, %s edges\" %"
    ],
    [
        "return \"<%s: nodes=%s, edges=%s>\" % (self.__class__.__name__, nodes, edges)",
        "return \"<%s: nodes=%s, edges=%s>\" %"
    ],
    [
        "if migration not in plan and (at_end or migration not in nodes):",
        "if migration not in plan and (at_end or migration not in"
    ],
    [
        "Given a migration node or nodes, return a complete ProjectState for it.",
        "Given a migration node or nodes, return a"
    ],
    [
        "If at_end is False, return the state before the migration has run.",
        "If at_end is False, return the state before the"
    ],
    [
        "If nodes is not provided, return the overall most current project state.",
        "If nodes is not provided, return the overall most current project"
    ],
    [
        "Deal with storing migration records in the database.",
        "Deal with storing migration"
    ],
    [
        "Because this table is actually itself used for dealing with model",
        "Because this table is actually itself used"
    ],
    [
        "creation, it's the one thing we can't do normally via migrations.",
        "creation, it's the one thing we can't do"
    ],
    [
        "We manually handle table creation/schema updating (using schema backend)",
        "We manually handle table creation/schema updating"
    ],
    [
        "and then have a floating model to do queries with.",
        "and then have a floating"
    ],
    [
        "If a migration is unapplied its row is removed from the table. Having",
        "If a migration is unapplied its row is"
    ],
    [
        "a row in the table always means a migration is applied.",
        "a row in the table always means a migration is"
    ],
    [
        "Lazy load to avoid AppRegistryNotReady if installed apps import",
        "Lazy load to avoid AppRegistryNotReady if installed"
    ],
    [
        "return \"Migration %s for %s\" % (self.name, self.app)",
        "return \"Migration %s for"
    ],
    [
        "\"\"\"Return True if the django_migrations table exists.\"\"\"",
        "\"\"\"Return True if the"
    ],
    [
        "\"\"\"Ensure the table exists and has the correct schema.\"\"\"",
        "\"\"\"Ensure the table exists and"
    ],
    [
        "\"Unable to create the django_migrations table (%s)\" % exc",
        "\"Unable to create the django_migrations"
    ],
    [
        "Return a dict mapping (app_name, migration_name) to Migration instances",
        "Return a dict mapping (app_name, migration_name) to Migration"
    ],
    [
        "\"\"\"Record that a migration was applied.\"\"\"",
        "\"\"\"Record that a"
    ],
    [
        "\"\"\"Record that a migration was unapplied.\"\"\"",
        "\"\"\"Record that a"
    ],
    [
        "\"\"\"Delete all migration records. Useful for testing migrations.\"\"\"",
        "\"\"\"Delete all migration records."
    ],
    [
        "Take a pair of ProjectStates and compare them to see what the first would",
        "Take a pair of ProjectStates and compare"
    ],
    [
        "need doing to make it match the second (the second usually being the",
        "need doing to make it match the second (the"
    ],
    [
        "Note that this naturally operates on entire projects at a time,",
        "Note that this naturally operates on entire projects at a"
    ],
    [
        "as it's likely that changes interact (for example, you can't",
        "as it's likely that changes interact"
    ],
    [
        "add a ForeignKey without having a migration to add the table it",
        "add a ForeignKey without having a migration to add the"
    ],
    [
        "depends on first). A user interface may offer single-app usage",
        "depends on first). A user interface may offer"
    ],
    [
        "if it wishes, with the caveat that it may not always be possible.",
        "if it wishes, with the caveat that it may not always be"
    ],
    [
        "self.existing_apps = {app for app, model in from_state.models}",
        "self.existing_apps = {app for app, model in"
    ],
    [
        "def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):",
        "def changes(self, graph, trim_to_apps=None,"
    ],
    [
        "Main entry point to produce a list of applicable changes.",
        "Main entry point to produce a"
    ],
    [
        "Take a graph to base names on and an optional set of apps",
        "Take a graph to base names on and"
    ],
    [
        "to try and restrict to (restriction is not guaranteed)",
        "to try and restrict to"
    ],
    [
        "Recursive deconstruction for a field and its arguments.",
        "Recursive deconstruction for a field and its"
    ],
    [
        "Used for full comparison for rename/alter; sometimes a single-level",
        "Used for full comparison for rename/alter; sometimes"
    ],
    [
        "return [self.deep_deconstruct(value) for value in obj]",
        "return [self.deep_deconstruct(value) for value"
    ],
    [
        "return tuple(self.deep_deconstruct(value) for value in obj)",
        "return tuple(self.deep_deconstruct(value) for value"
    ],
    [
        "return {key: self.deep_deconstruct(value) for key, value in obj.items()}",
        "return {key: self.deep_deconstruct(value) for key, value"
    ],
    [
        "{key: self.deep_deconstruct(value) for key, value in kwargs.items()},",
        "{key: self.deep_deconstruct(value) for key,"
    ],
    [
        "Return a definition of the fields that ignores field names and",
        "Return a definition of the fields that ignores"
    ],
    [
        "what related fields actually relate to. Used for detecting renames (as",
        "what related fields actually relate to. Used for detecting"
    ],
    [
        "the related fields change during renames).",
        "the related fields change"
    ],
    [
        "Return a dict of migration plans which will achieve the",
        "Return a dict of migration plans which will"
    ],
    [
        "change from from_state to to_state. The dict has app labels",
        "change from from_state to to_state. The dict"
    ],
    [
        "as keys and a list of migrations as values.",
        "as keys and a list of migrations as"
    ],
    [
        "The resulting migrations aren't specially named, but the names",
        "The resulting migrations aren't specially"
    ],
    [
        "do matter for dependencies inside the set.",
        "do matter for dependencies inside"
    ],
    [
        "convert_apps is the list of apps to convert to use migrations",
        "convert_apps is the list of apps to"
    ],
    [
        "(i.e. to make initial migrations for, in the usual case)",
        "(i.e. to make initial migrations for, in the"
    ],
    [
        "graph is an optional argument that, if provided, can help improve",
        "graph is an optional argument that, if"
    ],
    [
        "dependency generation and avoid potential circular dependencies.",
        "dependency generation and avoid potential"
    ],
    [
        "for (app_label, model_name), model_state in self.from_state.models.items():",
        "for (app_label, model_name), model_state"
    ],
    [
        "for (app_label, model_name), model_state in self.to_state.models.items():",
        "for (app_label, model_name),"
    ],
    [
        "elif app_label not in self.from_state.real_apps or (",
        "elif app_label not in"
    ],
    [
        "Prepare field lists and a list of the fields that used through models",
        "Prepare field lists and a list of the fields that used through"
    ],
    [
        "in the old state so dependencies can be made from the through model",
        "in the old state so dependencies can be"
    ],
    [
        "deletion to the field that uses it.",
        "deletion to the field that uses"
    ],
    [
        "Return the resolved dependency and a boolean denoting whether or not",
        "Return the resolved dependency and a"
    ],
    [
        "Chop the lists of operations up into migrations with dependencies on",
        "Chop the lists of operations up into migrations with"
    ],
    [
        "each other. Do this by going through an app's list of operations until",
        "each other. Do this by going through an app's list of"
    ],
    [
        "one is found that has an outgoing dependency that isn't in another",
        "one is found that has an outgoing"
    ],
    [
        "app's migration yet (hasn't been chopped off its list). Then chop off",
        "app's migration yet (hasn't been chopped off its list). Then"
    ],
    [
        "the operations before it into a migration and move onto the next app.",
        "the operations before it into a migration and move"
    ],
    [
        "If the loops completes without doing anything, there's a circular",
        "If the loops completes without doing anything,"
    ],
    [
        "dependency (which _should_ be impossible as the operations are",
        "dependency (which _should_ be impossible as the operations"
    ],
    [
        "all split at this point so they can't depend and be depended on).",
        "all split at this point so they can't depend and be"
    ],
    [
        "num_ops = sum(len(x) for x in self.generated_operations.values())",
        "num_ops = sum(len(x) for x"
    ],
    [
        "instance.initial = app_label not in self.existing_apps",
        "instance.initial = app_label not in"
    ],
    [
        "new_num_ops = sum(len(x) for x in self.generated_operations.values())",
        "new_num_ops = sum(len(x) for x in"
    ],
    [
        "Reorder to make things possible. Reordering may be needed so FKs work",
        "Reorder to make things possible. Reordering may be"
    ],
    [
        "ts.add(op, *(x for x in ops if self.check_dependency(x, dep)))",
        "ts.add(op, *(x for x in"
    ],
    [
        "Return True if the given operation depends on the given dependency,",
        "Return True if the given operation"
    ],
    [
        "and any(dependency.field_name == x for x, y in operation.fields)",
        "and any(dependency.field_name == x for x, y in"
    ],
    [
        "raise ValueError(\"Can't handle dependency %r\" % (dependency,))",
        "raise ValueError(\"Can't handle dependency %r\""
    ],
    [
        "def add_operation(self, app_label, operation, dependencies=None, beginning=False):",
        "def add_operation(self, app_label, operation, dependencies=None,"
    ],
    [
        "Place potential swappable models first in lists of created models (only",
        "Place potential swappable models first in lists of created models"
    ],
    [
        "base if isinstance(base, str) else base.__name__",
        "base if isinstance(base, str) else"
    ],
    [
        "Find any renamed models, generate the operations for them, and remove",
        "Find any renamed models, generate the operations for them, and"
    ],
    [
        "the old entry from the model lists. Must be run before other",
        "the old entry from the model"
    ],
    [
        "Find all new models (both managed and unmanaged) and make create",
        "Find all new models (both managed and unmanaged) and make"
    ],
    [
        "operations for them as well as separate operations to create any",
        "operations for them as well as separate operations"
    ],
    [
        "Defer any model options that refer to collections of fields that might",
        "Defer any model options that refer to collections"
    ],
    [
        "if isinstance(base, str) and \".\" in base:",
        "if isinstance(base, str) and \".\" in"
    ],
    [
        "Make CreateModel statements for proxy models. Use the same statements",
        "Make CreateModel statements for proxy models."
    ],
    [
        "as that way there's less code duplication, but for proxy models it's",
        "as that way there's less code"
    ],
    [
        "safe to skip all the pointless field stuff and chuck out an operation.",
        "safe to skip all the pointless field stuff and"
    ],
    [
        "if isinstance(base, str) and \".\" in base:",
        "if isinstance(base, str) and \".\""
    ],
    [
        "Find all deleted models (managed and unmanaged) and make delete",
        "Find all deleted models (managed and"
    ],
    [
        "operations for them as well as separate operations to delete any",
        "operations for them as well as separate operations to delete"
    ],
    [
        "Also bring forward removal of any model options that refer to",
        "Also bring forward removal of any model options"
    ],
    [
        "collections of fields - the inverse of generate_created_models().",
        "collections of fields -"
    ],
    [
        "\"\"\"Make DeleteModel options for proxy models.\"\"\"",
        "\"\"\"Make DeleteModel options for"
    ],
    [
        "for app_label, model_name, field_name in sorted(",
        "for app_label, model_name, field_name"
    ],
    [
        "for rem_app_label, rem_model_name, rem_field_name in sorted(",
        "for rem_app_label, rem_model_name, rem_field_name in"
    ],
    [
        "if rem_app_label == app_label and rem_model_name == model_name:",
        "if rem_app_label == app_label and rem_model_name =="
    ],
    [
        "if old_field_dec == field_dec or (",
        "if old_field_dec == field_dec"
    ],
    [
        "for app_label, model_name, field_name in sorted(",
        "for app_label, model_name, field_name in"
    ],
    [
        "if field.unique and field.has_default() and callable(field.default):",
        "if field.unique and field.has_default()"
    ],
    [
        "for app_label, model_name, field_name in sorted(",
        "for app_label, model_name, field_name"
    ],
    [
        "Make AlterField operations, or possibly RemovedField/AddField if alter",
        "Make AlterField operations, or"
    ],
    [
        "for app_label, model_name, field_name in sorted(",
        "for app_label, model_name, field_name in"
    ],
    [
        "if old_from_fields := getattr(old_field, \"from_fields\", None):",
        "if old_from_fields := getattr(old_field,"
    ],
    [
        "if old_field_dec != new_field_dec and old_field_name == field_name:",
        "if old_field_dec != new_field_dec and old_field_name =="
    ],
    [
        "added_indexes = [idx for idx in new_indexes if idx not in old_indexes]",
        "added_indexes = [idx for idx in new_indexes if idx not in"
    ],
    [
        "removed_indexes = [idx for idx in old_indexes if idx not in new_indexes]",
        "removed_indexes = [idx for idx in old_indexes if"
    ],
    [
        "idx for idx in added_indexes if idx not in remove_from_added",
        "idx for idx in added_indexes if"
    ],
    [
        "idx for idx in removed_indexes if idx not in remove_from_removed",
        "idx for idx in removed_indexes if"
    ],
    [
        "for (app_label, model_name), alt_indexes in self.altered_indexes.items():",
        "for (app_label, model_name),"
    ],
    [
        "for (app_label, model_name), alt_indexes in self.altered_indexes.items():",
        "for (app_label, model_name),"
    ],
    [
        "for (app_label, model_name), alt_indexes in self.altered_indexes.items():",
        "for (app_label, model_name),"
    ],
    [
        "for old_index_name, new_index_name, old_fields in alt_indexes[",
        "for old_index_name, new_index_name, old_fields"
    ],
    [
        "return (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs)",
        "return (old_path, old_args, old_kwargs) != (new_path, new_args,"
    ],
    [
        "if c not in old_constraints and c.name not in alt_constraints_name",
        "if c not in old_constraints and c.name not in"
    ],
    [
        "if c not in new_constraints and c.name not in alt_constraints_name",
        "if c not in new_constraints and c.name"
    ],
    [
        "for (remote_app_label, remote_model_name), fields in relations.items():",
        "for (remote_app_label, remote_model_name), fields in"
    ],
    [
        "for app_label, model_name, added_field_name in newly_added_fields:",
        "for app_label, model_name, added_field_name in"
    ],
    [
        "\"\"\"Return foreign key dependencies of the given model.\"\"\"",
        "\"\"\"Return foreign key dependencies of the"
    ],
    [
        "new_value = set(new_value) if new_value else set()",
        "new_value = set(new_value) if new_value"
    ],
    [
        "Work out if any non-schema-affecting options have changed and make an",
        "Work out if any non-schema-affecting options have"
    ],
    [
        "operation to represent them in state changes (in case Python code in",
        "operation to represent them in state changes (in case Python code"
    ],
    [
        "Take a result from changes() and a MigrationGraph, and fix the names",
        "Take a result from changes() and a MigrationGraph, and fix the"
    ],
    [
        "and dependencies of the changes so they extend the graph from the leaf",
        "and dependencies of the changes so they"
    ],
    [
        "if app_leaf is None and not self.questioner.ask_initial(app_label):",
        "if app_leaf is None"
    ],
    [
        "name_map.get(d, d) for d in migration.dependencies",
        "name_map.get(d, d) for d in"
    ],
    [
        "Take changes from arrange_for_graph() and set of app labels, and return",
        "Take changes from arrange_for_graph() and set"
    ],
    [
        "a modified set of changes which trims out as many migrations that are",
        "a modified set of changes which trims"
    ],
    [
        "not in app_labels as possible. Note that some other migrations may",
        "not in app_labels as possible. Note that some"
    ],
    [
        "still be present as they may be required dependencies.",
        "still be present as they may"
    ],
    [
        "*[app_dependencies.get(app_label, ()) for app_label in required_apps]",
        "*[app_dependencies.get(app_label, ()) for app_label"
    ],
    [
        "Given a migration name, try to extract a number from the beginning of",
        "Given a migration name, try to extract a number from the beginning"
    ],
    [
        "second number. If no number is found, return None.",
        "second number. If no number is"
    ],
    [
        "return self.pattern == other.pattern and self.flags == other.flags",
        "return self.pattern == other.pattern and"
    ],
    [
        "Turn a model class or model reference string and return a model tuple.",
        "Turn a model class or model reference string"
    ],
    [
        "app_label and model_name are used to resolve the scope of recursive and",
        "app_label and model_name are used to resolve the scope"
    ],
    [
        "if app_label is None or model_name is None:",
        "if app_label is None or model_name"
    ],
    [
        "\"app_label and model_name must be provided to resolve \"",
        "\"app_label and model_name must be provided"
    ],
    [
        "\"app_label must be provided to resolve unscoped model relationships.\"",
        "\"app_label must be provided to resolve unscoped"
    ],
    [
        "Return either False or a FieldReference if `field` references provided",
        "Return either False or a"
    ],
    [
        "False positives can be returned if `reference_field_name` is provided",
        "False positives can be returned if `reference_field_name` is"
    ],
    [
        "without `reference_field` because of the introspection limitation it",
        "without `reference_field` because of"
    ],
    [
        "incurs. This should not be an issue when this function is used to determine",
        "incurs. This should not be an issue when"
    ],
    [
        "whether or not an optimization can take place.",
        "whether or not an optimization"
    ],
    [
        "and (reference_field is None or reference_field.primary_key)",
        "and (reference_field is None"
    ],
    [
        "if through and resolve_relation(through, *model_tuple) == reference_model_tuple:",
        "if through and resolve_relation(through, *model_tuple) =="
    ],
    [
        "Generator of (model_state, name, field, reference) referencing",
        "Generator of (model_state, name, field,"
    ],
    [
        "If field_tuple is provided only references to this particular field of",
        "If field_tuple is provided only references"
    ],
    [
        "\"\"\"Return whether `field_tuple` is referenced by any state models.\"\"\"",
        "\"\"\"Return whether `field_tuple` is referenced by any state"
    ],
    [
        "return next(get_references(state, model_tuple, field_tuple), None) is not None",
        "return next(get_references(state, model_tuple, field_tuple),"
    ],
    [
        "Load migration files from disk and their status from the database.",
        "Load migration files from disk and"
    ],
    [
        "Migration files are expected to live in the \"migrations\" directory of",
        "Migration files are expected to live in the"
    ],
    [
        "an app. Their names are entirely unimportant from a code perspective,",
        "an app. Their names are entirely unimportant from a code"
    ],
    [
        "On initialization, this class will scan those directories, and open and",
        "On initialization, this class will scan those directories,"
    ],
    [
        "read the Python files, looking for a class called Migration, which should",
        "read the Python files, looking for a class called"
    ],
    [
        "django.db.migrations.migration for what that looks like.",
        "django.db.migrations.migration for what"
    ],
    [
        "Some migrations will be marked as \"replacing\" another set of migrations.",
        "Some migrations will be marked as \"replacing\" another"
    ],
    [
        "These are loaded into a separate set of migrations away from the main ones.",
        "These are loaded into a separate set of migrations"
    ],
    [
        "If all the migrations they replace are either unapplied or missing from",
        "If all the migrations they replace are either unapplied or"
    ],
    [
        "disk, then they are injected into the main set, replacing the named migrations.",
        "disk, then they are injected into the main set, replacing the"
    ],
    [
        "Any dependency pointers to the replaced migrations are re-pointed to the",
        "Any dependency pointers to the replaced migrations"
    ],
    [
        "This does mean that this class MUST also talk to the database as well as",
        "This does mean that this class MUST also talk to the database"
    ],
    [
        "to disk, but this is probably fine. We're already not just operating",
        "to disk, but this is probably fine."
    ],
    [
        "Return the path to the migrations module for the specified app_label",
        "Return the path to the migrations"
    ],
    [
        "and a boolean indicating if the module is specified in",
        "and a boolean indicating if the"
    ],
    [
        "return \"%s.%s\" % (app_package_name, MIGRATIONS_MODULE_NAME), False",
        "return \"%s.%s\" % (app_package_name,"
    ],
    [
        "\"\"\"Load the migrations from all INSTALLED_APPS from disk.\"\"\"",
        "\"\"\"Load the migrations from"
    ],
    [
        "if (explicit and self.ignore_no_migrations) or (",
        "if (explicit and self.ignore_no_migrations)"
    ],
    [
        "not explicit and MIGRATIONS_MODULE_NAME in e.name.split(\".\")",
        "not explicit and MIGRATIONS_MODULE_NAME in"
    ],
    [
        "if getattr(module, \"__file__\", None) is None and not isinstance(",
        "if getattr(module, \"__file__\", None) is None and"
    ],
    [
        "for _, name, is_pkg in pkgutil.iter_modules(module.__path__)",
        "for _, name,"
    ],
    [
        "migration_path = \"%s.%s\" % (module_name, migration_name)",
        "migration_path = \"%s.%s\" % (module_name,"
    ],
    [
        "if \"bad magic number\" in str(e):",
        "if \"bad magic"
    ],
    [
        "\"Couldn't import %r as it appears to be a stale \"",
        "\"Couldn't import %r as it appears to"
    ],
    [
        "\"Migration %s in app %s has no Migration class\"",
        "\"Migration %s in app %s has no Migration"
    ],
    [
        "\"\"\"Return the named migration or raise NodeNotFoundError.\"\"\"",
        "\"\"\"Return the named migration"
    ],
    [
        "Return the migration(s) which match the given app label and name_prefix.",
        "Return the migration(s) which match the given app"
    ],
    [
        "if migration_app_label == app_label and migration_name.startswith(",
        "if migration_app_label =="
    ],
    [
        "\"There is more than one migration for '%s' with the prefix '%s'\"",
        "\"There is more than one migration for '%s' with"
    ],
    [
        "f\"There is no migration for '{app_label}' with the prefix \"",
        "f\"There is no migration for '{app_label}' with the"
    ],
    [
        "Internal dependencies need to be added first to ensure `__first__`",
        "Internal dependencies need to be added first to ensure"
    ],
    [
        "dependencies find the correct root node.",
        "dependencies find the correct"
    ],
    [
        "f\"Cyclical squash replacement found, starting at {migration_key}\"",
        "f\"Cyclical squash replacement found,"
    ],
    [
        "(target in self.applied_migrations) for target in replaced_keys",
        "(target in self.applied_migrations) for target in"
    ],
    [
        "Build a migration dependency graph using both the disk and database.",
        "Build a migration dependency graph using both the disk and"
    ],
    [
        "You'll need to rebuild the graph if you apply migrations. This isn't",
        "You'll need to rebuild the graph if"
    ],
    [
        "usually a problem as generally migration stuff runs in a one-shot process.",
        "usually a problem as generally migration"
    ],
    [
        "candidate in self.graph.nodes for candidate in candidates",
        "candidate in self.graph.nodes for candidate"
    ],
    [
        "tries = \", \".join(\"%s.%s\" % c for c in candidates)",
        "tries = \", \".join(\"%s.%s\" % c for c in"
    ],
    [
        "\"but wasn't able to because some of the replaced migrations \"",
        "\"but wasn't able to because some of the replaced"
    ],
    [
        "Raise InconsistentMigrationHistory if any applied migrations have",
        "Raise InconsistentMigrationHistory if any applied migrations"
    ],
    [
        "m in applied for m in self.replacements[parent].replaces",
        "m in applied for"
    ],
    [
        "\"Migration {}.{} is applied before its dependency \"",
        "\"Migration {}.{} is applied"
    ],
    [
        "Look through the loaded graph and detect any conflicts - apps",
        "Look through the loaded graph and detect any conflicts"
    ],
    [
        "with more than one leaf migration. Return a dict of the app labels",
        "with more than one leaf migration. Return a dict"
    ],
    [
        "that conflict with the migration names that conflict.",
        "that conflict with the migration names"
    ],
    [
        "app_label: sorted(seen_apps[app_label]) for app_label in conflicting_apps",
        "app_label: sorted(seen_apps[app_label]) for app_label in"
    ],
    [
        "Return a ProjectState object representing the most recent state",
        "Return a ProjectState object representing the"
    ],
    [
        "See graph.make_state() for the meaning of \"nodes\" and \"at_end\".",
        "See graph.make_state() for the meaning of \"nodes\""
    ],
    [
        "Take a migration plan and return a list of collected SQL statements",
        "Take a migration plan and return a list of collected"
    ],
    [
        "that represent the best-efforts version of that plan.",
        "that represent the best-efforts version of"
    ],
    [
        "Power the optimization process, where you provide a list of Operations",
        "Power the optimization process, where you provide"
    ],
    [
        "and you are returned a list of equal or shorter length - operations",
        "and you are returned a list of equal or"
    ],
    [
        "are merged into one if possible.",
        "are merged into one"
    ],
    [
        "For example, a CreateModel and an AddField can be optimized into a",
        "For example, a CreateModel and an AddField can be optimized into"
    ],
    [
        "new CreateModel, and CreateModel and DeleteModel can be optimized into",
        "new CreateModel, and CreateModel and DeleteModel can be"
    ],
    [
        "Main optimization entry point. Pass in a list of Operation instances,",
        "Main optimization entry point. Pass in"
    ],
    [
        "get out a new list of Operation instances.",
        "get out a new"
    ],
    [
        "Unfortunately, due to the scope of the optimization (two combinable",
        "Unfortunately, due to the scope"
    ],
    [
        "operations might be separated by several hundred others), this can't be",
        "operations might be separated by several hundred"
    ],
    [
        "done as a peephole optimization with checks/output implemented on",
        "done as a peephole optimization"
    ],
    [
        "the Operations themselves; instead, the optimizer looks at each",
        "the Operations themselves; instead, the optimizer"
    ],
    [
        "individual operation and scans forwards in the list to see if there",
        "individual operation and scans forwards in the list to see if"
    ],
    [
        "are any matches, stopping at boundaries - operations which can't",
        "are any matches, stopping at boundaries"
    ],
    [
        "be optimized over (RunSQL, operations on the same field/model, etc.)",
        "be optimized over (RunSQL, operations on the same field/model,"
    ],
    [
        "The inner loop is run until the starting list is the same as the result",
        "The inner loop is run until the starting list is the same as the"
    ],
    [
        "list, and then the result is returned. This means that operation",
        "list, and then the result is returned. This means that"
    ],
    [
        "optimization must be stable and always return an equal or shorter list.",
        "optimization must be stable and always"
    ],
    [
        "raise TypeError(\"app_label must be a str.\")",
        "raise TypeError(\"app_label must be a"
    ],
    [
        "elif all(op.reduce(other, app_label) is True for op in in_between):",
        "elif all(op.reduce(other, app_label) is True for"
    ],
    [
        "\"Subclasses of BaseSerializer must implement the serialize() method.\"",
        "\"Subclasses of BaseSerializer must"
    ],
    [
        "\"Subclasses of BaseSequenceSerializer must implement the _format() method.\"",
        "\"Subclasses of BaseSequenceSerializer must implement the _format()"
    ],
    [
        "return value % (\", \".join(strings)), imports",
        "return value % (\", \".join(strings)),"
    ],
    [
        "if self.value.tzinfo is not None and self.value.tzinfo != datetime.timezone.utc:",
        "if self.value.tzinfo is not None and self.value.tzinfo"
    ],
    [
        "return repr(self.value), {\"from decimal import Decimal\"}",
        "return repr(self.value), {\"from decimal import"
    ],
    [
        "return \"%s(%s)\" % (name, \", \".join(strings)), imports",
        "return \"%s(%s)\" % (name, \", \".join(strings)),"
    ],
    [
        "imports = {\"from django.db import models\"}",
        "imports = {\"from django.db"
    ],
    [
        "imports = {\"import %s\" % module}",
        "imports = {\"import %s\""
    ],
    [
        "return \"{%s}\" % (\", \".join(\"%s: %s\" % (k, v) for k, v in strings)), imports",
        "return \"{%s}\" % (\", \".join(\"%s: %s\" % (k, v) for k, v"
    ],
    [
        "if getattr(self.value, \"__self__\", None) and isinstance(",
        "if getattr(self.value, \"__self__\", None)"
    ],
    [
        "return \"%s.%s.%s\" % (module, klass.__qualname__, self.value.__name__), {",
        "return \"%s.%s.%s\" % (module, klass.__qualname__, self.value.__name__),"
    ],
    [
        "raise ValueError(\"Cannot serialize function %r: No module\" % self.value)",
        "raise ValueError(\"Cannot serialize function %r:"
    ],
    [
        "return \"%s.%s\" % (module_name, self.value.__qualname__), {",
        "return \"%s.%s\" % (module_name,"
    ],
    [
        "\"Could not find function %s in %s.\\n\" % (self.value.__name__, module_name)",
        "\"Could not find function %s"
    ],
    [
        "imports = {\"import functools\", *func_imports, *args_imports, *keywords_imports}",
        "imports = {\"import functools\","
    ],
    [
        "return value % (\", \".join(strings)), imports",
        "return value % (\","
    ],
    [
        "attr_name, path, args, kwargs = self.value.deconstruct()",
        "attr_name, path, args, kwargs"
    ],
    [
        "as_manager, manager_path, qs_path, args, kwargs = self.value.deconstruct()",
        "as_manager, manager_path, qs_path, args, kwargs ="
    ],
    [
        "prefix = \"Pure\" if isinstance(self.value, pathlib.Path) else \"\"",
        "prefix = \"Pure\" if isinstance(self.value, pathlib.Path) else"
    ],
    [
        "return \"pathlib.%s%r\" % (prefix, self.value), {\"import pathlib\"}",
        "return \"pathlib.%s%r\" % (prefix, self.value), {\"import"
    ],
    [
        "imports = {\"import re\", *pattern_imports, *flag_imports}",
        "imports = {\"import"
    ],
    [
        "return \"re.compile(%s)\" % \", \".join(args), imports",
        "return \"re.compile(%s)\" % \","
    ],
    [
        "return \"{%s}\" if self.value else \"set(%s)\"",
        "return \"{%s}\" if self.value"
    ],
    [
        "(models.Model, \"models.Model\", [\"from django.db import models\"]),",
        "(models.Model, \"models.Model\", [\"from django.db"
    ],
    [
        "for case, string, imports in special_cases:",
        "for case, string, imports"
    ],
    [
        "return \"%s.%s\" % (module, self.value.__qualname__), {",
        "return \"%s.%s\" % (module, self.value.__qualname__),"
    ],
    [
        "return \"uuid.%s\" % repr(self.value), {\"import uuid\"}",
        "return \"uuid.%s\" % repr(self.value),"
    ],
    [
        "(bool, int, types.NoneType, bytes, str, range): BaseSimpleSerializer,",
        "(bool, int, types.NoneType, bytes, str,"
    ],
    [
        "\"'%s' must inherit from 'BaseSerializer'.\" % serializer.__name__",
        "\"'%s' must inherit from 'BaseSerializer'.\""
    ],
    [
        "\"Cannot serialize: %r\\nThere are some values Django cannot serialize into \"",
        "\"Cannot serialize: %r\\nThere are some values Django"
    ],
    [
        "\"\"\"More than one migration matches a name prefix.\"\"\"",
        "\"\"\"More than one migration matches a name"
    ],
    [
        "\"\"\"There's a bad migration (unreadable/bad format/etc.).\"\"\"",
        "\"\"\"There's a bad"
    ],
    [
        "\"\"\"An applied migration has some of its dependencies not applied.\"\"\"",
        "\"\"\"An applied migration has some"
    ],
    [
        "\"\"\"A model's base classes can't be resolved.\"\"\"",
        "\"\"\"A model's base classes can't be"
    ],
    [
        "\"\"\"An irreversible migration is about to be reversed.\"\"\"",
        "\"\"\"An irreversible migration is about"
    ],
    [
        "\"\"\"An attempt on a node is made that is not available in the graph.\"\"\"",
        "\"\"\"An attempt on a node is made that is not"
    ],
    [
        "if _arg_name in self.operation.serialization_expand_args and isinstance(",
        "if _arg_name in self.operation.serialization_expand_args"
    ],
    [
        "if getattr(migrations, name, None) == self.operation.__class__:",
        "if getattr(migrations, name, None)"
    ],
    [
        "Take a Migration instance and is able to produce the contents",
        "Take a Migration instance and is able to"
    ],
    [
        "of the migration file from it.",
        "of the migration"
    ],
    [
        "\"\"\"Return a string of the file contents.\"\"\"",
        "\"\"\"Return a string of"
    ],
    [
        "items[\"operations\"] = \"\\n\".join(operations) + \"\\n\" if operations else \"\"",
        "items[\"operations\"] = \"\\n\".join(operations) + \"\\n\" if"
    ],
    [
        "\"\\n\".join(sorted(dependencies)) + \"\\n\" if dependencies else \"\"",
        "\"\\n\".join(sorted(dependencies)) + \"\\n\" if dependencies"
    ],
    [
        "if \"from django.db import models\" in imports:",
        "if \"from django.db import"
    ],
    [
        "items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"",
        "items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if"
    ],
    [
        "items[\"initial_str\"] = \"\\n    initial = True\\n\"",
        "items[\"initial_str\"] = \"\\n initial ="
    ],
    [
        "\"Django can't create migrations for app '%s' because \"",
        "\"Django can't create migrations for app"
    ],
    [
        "\"migrations have been disabled via the MIGRATION_MODULES \"",
        "\"migrations have been disabled via"
    ],
    [
        "\"Could not locate an appropriate location to create \"",
        "\"Could not locate an appropriate location"
    ],
    [
        "\"migrations package %s. Make sure the toplevel \"",
        "\"migrations package %s. Make"
    ],
    [
        "\"package exists and can be imported.\" % migrations_package_name",
        "\"package exists and can be imported.\""
    ],
    [
        "The base class for all migrations.",
        "The base class for"
    ],
    [
        "Migration files will import this from django.db.migrations.Migration",
        "Migration files will import this"
    ],
    [
        "and subclass it as a class called Migration. It will have one or more",
        "and subclass it as a class called"
    ],
    [
        "- operations: A list of Operation instances, probably from",
        "- operations: A list of"
    ],
    [
        "- dependencies: A list of tuples of (app_path, migration_name)",
        "- dependencies: A list of tuples"
    ],
    [
        "- run_before: A list of tuples of (app_path, migration_name)",
        "- run_before: A list of"
    ],
    [
        "- replaces: A list of migration_names",
        "- replaces: A list"
    ],
    [
        "Note that all migrations come out of migrations and into the Loader or",
        "Note that all migrations come out of migrations and into the"
    ],
    [
        "Graph as instances, having been initialized with their app label and name.",
        "Graph as instances, having been initialized"
    ],
    [
        "return \"<Migration %s.%s>\" % (self.app_label, self.name)",
        "return \"<Migration %s.%s>\" %"
    ],
    [
        "Take a ProjectState and return a new one with the migration's",
        "Take a ProjectState and return a new one"
    ],
    [
        "operations applied to it. Preserve the original object state by",
        "operations applied to it. Preserve the original"
    ],
    [
        "default and return a mutated state from a copy.",
        "default and return a mutated state from"
    ],
    [
        "Take a project_state representing all migrations prior to this one",
        "Take a project_state representing all migrations prior to"
    ],
    [
        "and a schema_editor for a live database and apply the migration",
        "and a schema_editor for a live database and"
    ],
    [
        "Return the resulting project state for efficient reuse by following",
        "Return the resulting project state for efficient reuse by"
    ],
    [
        "\"-- THIS OPERATION CANNOT BE WRITTEN AS SQL\"",
        "\"-- THIS OPERATION CANNOT BE WRITTEN AS"
    ],
    [
        "self.atomic and operation.atomic is not False",
        "self.atomic and operation.atomic is not"
    ],
    [
        "if collect_sql and collected_sql_before == len(schema_editor.collected_sql):",
        "if collect_sql and collected_sql_before =="
    ],
    [
        "Take a project_state representing all migrations prior to this one",
        "Take a project_state representing all migrations prior to"
    ],
    [
        "and a schema_editor for a live database and apply the migration",
        "and a schema_editor for a live database and apply the"
    ],
    [
        "The backwards migration process consists of two phases:",
        "The backwards migration process consists of"
    ],
    [
        "after the last operation inside this migration are preserved.",
        "after the last operation inside"
    ],
    [
        "\"Operation %s in %s is not reversible\" % (operation, self)",
        "\"Operation %s in %s is not reversible\" %"
    ],
    [
        "for operation, to_state, from_state in to_run:",
        "for operation, to_state,"
    ],
    [
        "\"-- THIS OPERATION CANNOT BE WRITTEN AS SQL\"",
        "\"-- THIS OPERATION CANNOT"
    ],
    [
        "self.atomic and operation.atomic is not False",
        "self.atomic and operation.atomic is not"
    ],
    [
        "if collect_sql and collected_sql_before == len(schema_editor.collected_sql):",
        "if collect_sql and"
    ],
    [
        "Suggest a name for the operations this migration might represent. Names",
        "Suggest a name for the operations this migration might"
    ],
    [
        "are not guaranteed to be unique, but put some effort into the fallback",
        "are not guaranteed to be unique, but put some effort into"
    ],
    [
        "name to avoid VCS conflicts if possible.",
        "name to avoid VCS"
    ],
    [
        "raw_fragments = [op.migration_name_fragment for op in self.operations]",
        "raw_fragments = [op.migration_name_fragment for"
    ],
    [
        "fragments = [re.sub(r\"\\W+\", \"_\", name) for name in raw_fragments if name]",
        "fragments = [re.sub(r\"\\W+\", \"_\", name) for"
    ],
    [
        "if not fragments or len(fragments) != len(self.operations):",
        "if not fragments or len(fragments)"
    ],
    [
        "Subclass of tuple so Django can tell this was originally a swappable",
        "Subclass of tuple so Django can tell this was originally"
    ],
    [
        "dependency when it reads the migration file.",
        "dependency when it reads"
    ],
    [
        "\"\"\"Turn a setting value into a dependency.\"\"\"",
        "\"\"\"Turn a setting value into a"
    ],
    [
        "from django.apps.registry import apps as global_apps",
        "from django.apps.registry import apps as"
    ],
    [
        "End-to-end migration execution - load migrations and run them up or down",
        "End-to-end migration execution - load migrations and run them up or"
    ],
    [
        "to a specified set of targets.",
        "to a specified set of"
    ],
    [
        "Given a set of targets, return a list of (Migration instance, backwards?).",
        "Given a set of targets, return"
    ],
    [
        "Create a project state including all the applications without",
        "Create a project state including all the applications"
    ],
    [
        "migrations and applied migrations if with_applied_migrations=True.",
        "migrations and applied migrations"
    ],
    [
        "def migrate(self, targets, plan=None, state=None, fake=False, fake_initial=False):",
        "def migrate(self, targets, plan=None,"
    ],
    [
        "Migrate the database up to the given targets.",
        "Migrate the database up to"
    ],
    [
        "Django first needs to create all project states before a migration is",
        "Django first needs to create all project states before a migration"
    ],
    [
        "(un)applied and in a second step run all the database operations.",
        "(un)applied and in a second step"
    ],
    [
        "all_forwards = all(not backwards for mig, backwards in plan)",
        "all_forwards = all(not backwards for"
    ],
    [
        "all_backwards = all(backwards for mig, backwards in plan)",
        "all_backwards = all(backwards for mig, backwards"
    ],
    [
        "\"Migration plans with both forwards and backwards migrations \"",
        "\"Migration plans with both forwards and"
    ],
    [
        "\"are not supported. Please split your migration process into \"",
        "\"are not supported. Please split your migration"
    ],
    [
        "\"separate plans of only forwards OR backwards migrations.\",",
        "\"separate plans of only forwards"
    ],
    [
        "def _migrate_all_forwards(self, state, plan, full_plan, fake, fake_initial):",
        "def _migrate_all_forwards(self, state, plan, full_plan, fake,"
    ],
    [
        "apply them in the order they occur in the full_plan.",
        "apply them in the order they occur in"
    ],
    [
        "unapply them in reverse order they occur in the full_plan.",
        "unapply them in reverse order they occur"
    ],
    [
        "Since unapplying a migration requires the project state prior to that",
        "Since unapplying a migration requires the project"
    ],
    [
        "migration, Django will compute the migration states before each of them",
        "migration, Django will compute the migration states"
    ],
    [
        "in a first run over the plan and then unapply them in a second run over",
        "in a first run over the plan and then unapply them in"
    ],
    [
        "for index, (migration, _) in enumerate(full_plan):",
        "for index, (migration,"
    ],
    [
        "def apply_migration(self, state, migration, fake=False, fake_initial=False):",
        "def apply_migration(self, state,"
    ],
    [
        "Mark replacement migrations applied if their replaced set all are.",
        "Mark replacement migrations applied if their replaced"
    ],
    [
        "Do this unconditionally on every migrate, rather than just when",
        "Do this unconditionally on every migrate, rather"
    ],
    [
        "migrations are applied or unapplied, to correctly handle the case",
        "migrations are applied or unapplied, to correctly handle the"
    ],
    [
        "when a new squash migration is pushed to a deployment that already had",
        "when a new squash migration is pushed to a deployment that already"
    ],
    [
        "all its replaced migrations applied. In this case no new migration will",
        "all its replaced migrations applied. In this case no new"
    ],
    [
        "be applied, but the applied state of the squashed migration must be",
        "be applied, but the applied state"
    ],
    [
        "all_applied = all(m in applied for m in migration.replaces)",
        "all_applied = all(m in applied for m"
    ],
    [
        "if all_applied and key not in applied:",
        "if all_applied and key not in"
    ],
    [
        "Test whether a migration has been implicitly applied - that the",
        "Test whether a migration has been implicitly applied - that"
    ],
    [
        "tables or columns it would create exist. This is intended only for use",
        "tables or columns it would create exist. This is"
    ],
    [
        "on initial migrations (as it only looks for CreateModel and AddField).",
        "on initial migrations (as it only looks for"
    ],
    [
        "No need to detect tables for proxy models, unmanaged models, or",
        "No need to detect tables for proxy"
    ],
    [
        "models that can't be migrated on the current database.",
        "models that can't be migrated on"
    ],
    [
        "if any(app == migration.app_label for app, name in migration.dependencies):",
        "if any(app == migration.app_label for app, name in"
    ],
    [
        "from django.apps.registry import apps as global_apps",
        "from django.apps.registry import apps as"
    ],
    [
        "\"\"\"Return all models that have a direct relationship to the given model.\"\"\"",
        "\"\"\"Return all models that have a direct"
    ],
    [
        "if opts.proxy and m in related_fields_models:",
        "if opts.proxy and m"
    ],
    [
        "Return a list of typical (app_label, model_name) tuples for all related",
        "Return a list of typical (app_label, model_name) tuples for all"
    ],
    [
        "Return all models that have a direct or indirect relationship",
        "Return all models that have a direct or indirect"
    ],
    [
        "Relationships are either defined by explicit relational fields, like",
        "Relationships are either defined by explicit relational"
    ],
    [
        "ForeignKey, ManyToManyField or OneToOneField, or by inheriting from another",
        "ForeignKey, ManyToManyField or OneToOneField, or by"
    ],
    [
        "model (a superclass is related to its subclasses, but not vice versa). Note,",
        "model (a superclass is related to its subclasses, but"
    ],
    [
        "however, that a model inheriting from a concrete model is also related to",
        "however, that a model inheriting from a concrete model is also"
    ],
    [
        "its superclass through the implicit *_ptr OneToOneField on the subclass.",
        "its superclass through the implicit *_ptr OneToOneField"
    ],
    [
        "Represent the entire project's overall state. This is the item that is",
        "Represent the entire project's overall state."
    ],
    [
        "passed around - do it here rather than at the app level so that cross-app",
        "passed around - do it here rather than"
    ],
    [
        "for model_state, name, field, reference in get_references(",
        "for model_state, name, field,"
    ],
    [
        "def alter_model_options(self, app_label, model_name, options, option_keys=None):",
        "def alter_model_options(self, app_label, model_name,"
    ],
    [
        "def remove_model_options(self, app_label, model_name, option_name, value_to_remove):",
        "def remove_model_options(self, app_label, model_name, option_name,"
    ],
    [
        "obj for obj in objs if tuple(obj) != tuple(value_to_remove)",
        "obj for obj in objs if"
    ],
    [
        "def _append_option(self, app_label, model_name, option_name, obj):",
        "def _append_option(self, app_label, model_name, option_name,"
    ],
    [
        "def _remove_option(self, app_label, model_name, option_name, obj_name):",
        "def _remove_option(self, app_label, model_name, option_name,"
    ],
    [
        "model_state.options[option_name] = [obj for obj in objs if obj.name != obj_name]",
        "model_state.options[option_name] = [obj for obj in objs if obj.name"
    ],
    [
        "def _alter_option(self, app_label, model_name, option_name, obj_name, alt_obj):",
        "def _alter_option(self, app_label, model_name,"
    ],
    [
        "obj if obj.name != obj_name else alt_obj for obj in objs",
        "obj if obj.name != obj_name else alt_obj for obj in"
    ],
    [
        "def rename_index(self, app_label, model_name, old_index_name, new_index_name):",
        "def rename_index(self, app_label,"
    ],
    [
        "def alter_constraint(self, app_label, model_name, constraint_name, constraint):",
        "def alter_constraint(self, app_label, model_name, constraint_name,"
    ],
    [
        "def add_field(self, app_label, model_name, name, field, preserve_default):",
        "def add_field(self, app_label, model_name,"
    ],
    [
        "def alter_field(self, app_label, model_name, name, field, preserve_default):",
        "def alter_field(self, app_label, model_name,"
    ],
    [
        "delay = not field.is_relation and not field_is_referenced(",
        "delay = not field.is_relation and"
    ],
    [
        "def rename_field(self, app_label, model_name, old_name, new_name):",
        "def rename_field(self, app_label, model_name, old_name,"
    ],
    [
        "f\"{app_label}.{model_name} has no field named '{old_name}'\"",
        "f\"{app_label}.{model_name} has no field"
    ],
    [
        "new_name if from_field_name == old_name else from_field_name",
        "new_name if from_field_name =="
    ],
    [
        "if field_names := getattr(field, \"field_names\", None):",
        "if field_names := getattr(field,"
    ],
    [
        "new_name if field_name == old_name else field_name",
        "new_name if field_name =="
    ],
    [
        "[new_name if n == old_name else n for n in together]",
        "[new_name if n == old_name else n for"
    ],
    [
        "references = get_references(self, model_key, (old_name, found))",
        "references = get_references(self, model_key, (old_name,"
    ],
    [
        "for *_, field, reference in references:",
        "for *_, field, reference"
    ],
    [
        "if getattr(remote_field, \"field_name\", None) == old_name:",
        "if getattr(remote_field, \"field_name\", None)"
    ],
    [
        "new_name if to_field_name == old_name else to_field_name",
        "new_name if to_field_name == old_name"
    ],
    [
        "if not (isinstance(base, str) or issubclass(base, models.Model)):",
        "if not (isinstance(base, str) or issubclass(base,"
    ],
    [
        "\"\"\"Return an exact copy of this ProjectState.\"\"\"",
        "\"\"\"Return an exact copy of"
    ],
    [
        "models={k: v.clone() for k, v in self.models.items()},",
        "models={k: v.clone() for k, v"
    ],
    [
        "if self.is_delayed and \"apps\" in self.__dict__:",
        "if self.is_delayed and \"apps\" in"
    ],
    [
        "\"\"\"Take an Apps and return a ProjectState matching it.\"\"\"",
        "\"\"\"Take an Apps and return a ProjectState matching"
    ],
    [
        "return self.models == other.models and self.real_apps == other.real_apps",
        "return self.models == other.models and self.real_apps =="
    ],
    [
        "\"\"\"Stub of an AppConfig. Only provides a label and a dict of models.\"\"\"",
        "\"\"\"Stub of an AppConfig. Only provides a label and a"
    ],
    [
        "Subclass of the global Apps registry class to better handle dynamic model",
        "Subclass of the global Apps registry class to"
    ],
    [
        "app_labels = {model_state.app_label for model_state in models.values()}",
        "app_labels = {model_state.app_label for"
    ],
    [
        "AppConfigStub(label) for label in sorted([*real_apps, *app_labels])",
        "AppConfigStub(label) for label in sorted([*real_apps,"
    ],
    [
        "raise ValueError(\"\\n\".join(error.msg for error in errors))",
        "raise ValueError(\"\\n\".join(error.msg for error in"
    ],
    [
        "\"Cannot resolve bases for %r\\nThis can happen if you are \"",
        "\"Cannot resolve bases for %r\\nThis can happen"
    ],
    [
        "\"inheriting models from an app with migrations (e.g. \"",
        "\"inheriting models from an app"
    ],
    [
        "\"contrib.auth)\\n in an app with no migrations; see \"",
        "\"contrib.auth)\\n in an app with"
    ],
    [
        "\"\"\"Return a clone of this registry.\"\"\"",
        "\"\"\"Return a clone"
    ],
    [
        "Represent a Django Model. Don't use the actual Model class as it's not",
        "Represent a Django Model. Don't use the actual Model class as it's"
    ],
    [
        "designed to have its options changed - instead, mutate this one and then",
        "designed to have its options changed - instead, mutate"
    ],
    [
        "render it into a Model as required.",
        "render it into a"
    ],
    [
        "Note that while you are allowed to mutate .fields, you are not allowed",
        "Note that while you are allowed to mutate .fields,"
    ],
    [
        "to mutate the Field instances inside there themselves - you must instead",
        "to mutate the Field instances inside there themselves -"
    ],
    [
        "assign new ones, as these are not detached during a clone.",
        "assign new ones, as these are not"
    ],
    [
        "self, app_label, name, fields, options=None, bases=None, managers=None",
        "self, app_label, name, fields,"
    ],
    [
        "'ModelState.fields cannot be bound to a model - \"%s\" is.' % name",
        "'ModelState.fields cannot be bound to a model - \"%s\" is.'"
    ],
    [
        "'Model fields in \"ModelState.fields\" cannot refer to a model class '",
        "'Model fields in \"ModelState.fields\" cannot refer to a"
    ],
    [
        "f'- \"{self.app_label}.{self.name}.{name}.to\" does. Use a string '",
        "f'- \"{self.app_label}.{self.name}.{name}.to\" does. Use a string"
    ],
    [
        "'Model fields in \"ModelState.fields\" cannot refer to a model class '",
        "'Model fields in \"ModelState.fields\" cannot refer to a model class"
    ],
    [
        "f'- \"{self.app_label}.{self.name}.{name}.through\" does. Use a '",
        "f'- \"{self.app_label}.{self.name}.{name}.through\" does. Use a"
    ],
    [
        "\"Indexes passed to ModelState require a name attribute. \"",
        "\"Indexes passed to ModelState require"
    ],
    [
        "\"%r doesn't have one.\" % index",
        "\"%r doesn't have"
    ],
    [
        "\"\"\"Given a model, return a ModelState representing it.\"\"\"",
        "\"\"\"Given a model, return"
    ],
    [
        "if getattr(field, \"remote_field\", None) and exclude_rels:",
        "if getattr(field, \"remote_field\", None) and"
    ],
    [
        "\"Couldn't reconstruct field %s on %s: %s\"",
        "\"Couldn't reconstruct field %s"
    ],
    [
        "indexes = [idx.clone() for idx in model._meta.indexes]",
        "indexes = [idx.clone() for idx in"
    ],
    [
        "(base._meta.label_lower if hasattr(base, \"_meta\") else base)",
        "(base._meta.label_lower if hasattr(base, \"_meta\")"
    ],
    [
        "(isinstance(base, str) or issubclass(base, models.Model)) for base in bases",
        "(isinstance(base, str) or issubclass(base, models.Model)) for base in"
    ],
    [
        "elif manager is model._base_manager or manager is model._default_manager:",
        "elif manager is model._base_manager"
    ],
    [
        "as_manager, manager_path, qs_path, args, kwargs = manager.deconstruct()",
        "as_manager, manager_path, qs_path, args, kwargs ="
    ],
    [
        "\"\"\"Return an exact copy of this ModelState.\"\"\"",
        "\"\"\"Return an exact copy of this"
    ],
    [
        "\"\"\"Create a Model object from our current state into the given apps.\"\"\"",
        "\"\"\"Create a Model object from our current state into the given"
    ],
    [
        "meta_contents = {\"app_label\": self.app_label, \"apps\": apps, **meta_options}",
        "meta_contents = {\"app_label\": self.app_label,"
    ],
    [
        "(apps.get_model(base) if isinstance(base, str) else base)",
        "(apps.get_model(base) if isinstance(base, str) else"
    ],
    [
        "\"Cannot resolve one or more bases from %r\" % (self.bases,)",
        "\"Cannot resolve one or more"
    ],
    [
        "body = {name: field.clone() for name, field in self.fields.items()}",
        "body = {name: field.clone() for name,"
    ],
    [
        "raise ValueError(\"No index named %s on model %s\" % (name, self.name))",
        "raise ValueError(\"No index named %s on model %s\" % (name,"
    ],
    [
        "raise ValueError(\"No constraint named %s on model %s\" % (name, self.name))",
        "raise ValueError(\"No constraint named %s on model %s\" %"
    ],
    [
        "return \"<%s: '%s.%s'>\" % (self.__class__.__name__, self.app_label, self.name)",
        "return \"<%s: '%s.%s'>\" % (self.__class__.__name__, self.app_label,"
    ],
    [
        "from .fields import AddField, AlterField, FieldOperation, RemoveField, RenameField",
        "from .fields import AddField, AlterField, FieldOperation, RemoveField,"
    ],
    [
        "\"Found duplicate value %s in CreateModel %s argument.\" % (val, arg_name)",
        "\"Found duplicate value %s in CreateModel %s argument.\""
    ],
    [
        "def __init__(self, name, fields, options=None, bases=None, managers=None):",
        "def __init__(self, name, fields, options=None,"
    ],
    [
        "_check_for_duplicates(\"fields\", (name for name, _ in self.fields))",
        "_check_for_duplicates(\"fields\", (name for name,"
    ],
    [
        "else base.lower() if isinstance(base, str) else base",
        "else base.lower() if isinstance(base, str) else"
    ],
    [
        "_check_for_duplicates(\"managers\", (name for name, _ in self.managers))",
        "_check_for_duplicates(\"managers\", (name for name,"
    ],
    [
        "if self.bases and self.bases != (models.Model,):",
        "if self.bases and self.bases !="
    ],
    [
        "if self.managers and self.managers != [(\"objects\", models.Manager())]:",
        "if self.managers and self.managers != [(\"objects\","
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "return \"Create %smodel %s\" % (",
        "return \"Create %smodel %s\""
    ],
    [
        "\"proxy \" if self.options.get(\"proxy\", False) else \"\",",
        "\"proxy \" if self.options.get(\"proxy\", False) else"
    ],
    [
        "(n, operation.field if n == operation.name else v)",
        "(n, operation.field if n =="
    ],
    [
        "f for f in fields if f != operation.name_lower",
        "f for f in fields"
    ],
    [
        "operation.new_name if f == operation.old_name else f",
        "operation.new_name if f == operation.old_name"
    ],
    [
        "(operation.new_name if n == operation.old_name else n, v)",
        "(operation.new_name if n =="
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "return \"Delete model %s\" % self.name",
        "return \"Delete model"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "name.lower() == self.old_name_lower or name.lower() == self.new_name_lower",
        "name.lower() == self.old_name_lower or name.lower() =="
    ],
    [
        "return \"Rename model %s to %s\" % (self.old_name, self.new_name)",
        "return \"Rename model %s to %s\""
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "return \"Rename table for %s to %s\" % (",
        "return \"Rename table for %s"
    ],
    [
        "self.table if self.table is not None else \"(default)\",",
        "self.table if self.table is not None else"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "alter_together = getattr(schema_editor, \"alter_%s\" % self.option_name)",
        "alter_together = getattr(schema_editor,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label,"
    ],
    [
        "or any((name in fields) for fields in self.option_value)",
        "or any((name in fields) for"
    ],
    [
        "return \"Alter %s for %s (%s constraint(s))\" % (",
        "return \"Alter %s for %s"
    ],
    [
        "Change the value of unique_together to the target one.",
        "Change the value of unique_together"
    ],
    [
        "Input value of unique_together must be a set of tuples.",
        "Input value of unique_together must"
    ],
    [
        "Change the value of index_together to the target one.",
        "Change the value of index_together to"
    ],
    [
        "Input value of index_together must be a set of tuples.",
        "Input value of index_together must be a set"
    ],
    [
        "\"\"\"Represent a change with the order_with_respect_to option.\"\"\"",
        "\"\"\"Represent a change with the"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "self.order_with_respect_to is None or name == self.order_with_respect_to",
        "self.order_with_respect_to is None or name =="
    ],
    [
        "return \"Set order_with_respect_to on %s to %s\" % (",
        "return \"Set order_with_respect_to on %s to %s\" %"
    ],
    [
        "Set new model options that don't directly affect the database schema",
        "Set new model options that don't directly affect the"
    ],
    [
        "(like verbose_name, permissions, ordering). Python code in migrations",
        "(like verbose_name, permissions, ordering). Python code"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "return \"Change Meta options on %s\" % self.name",
        "return \"Change Meta options on %s\""
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "return \"Change managers on %s\" % self.name",
        "return \"Change managers on %s\""
    ],
    [
        "\"\"\"Add an index on a model.\"\"\"",
        "\"\"\"Add an index on"
    ],
    [
        "\"Indexes passed to AddIndex operations require a name \"",
        "\"Indexes passed to AddIndex operations require a name"
    ],
    [
        "\"argument. %r doesn't have one.\" % index",
        "\"argument. %r doesn't have"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label,"
    ],
    [
        "return \"Create index %s on %s on model %s\" % (",
        "return \"Create index %s on %s on"
    ],
    [
        "\", \".join([str(expression) for expression in self.index.expressions]),",
        "\", \".join([str(expression) for"
    ],
    [
        "return \"Create index %s on field(s) %s of model %s\" % (",
        "return \"Create index %s on field(s) %s of"
    ],
    [
        "if isinstance(operation, RemoveIndex) and self.index.name == operation.name:",
        "if isinstance(operation, RemoveIndex) and self.index.name"
    ],
    [
        "if isinstance(operation, RenameIndex) and self.index.name == operation.old_name:",
        "if isinstance(operation, RenameIndex) and self.index.name"
    ],
    [
        "\"\"\"Remove an index from a model.\"\"\"",
        "\"\"\"Remove an index from a"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "return \"Remove index %s from %s\" % (self.name, self.model_name)",
        "return \"Remove index %s from %s\" %"
    ],
    [
        "def __init__(self, model_name, new_name, old_name=None, old_fields=None):",
        "def __init__(self, model_name, new_name,"
    ],
    [
        "if not old_name and not old_fields:",
        "if not old_name"
    ],
    [
        "\"RenameIndex requires one of old_name and old_fields arguments to be \"",
        "\"RenameIndex requires one of old_name and old_fields"
    ],
    [
        "\"RenameIndex.old_name and old_fields are mutually exclusive.\"",
        "\"RenameIndex.old_name and old_fields"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "\"Found wrong number (%s) of indexes for %s(%s).\"",
        "\"Found wrong number (%s) of indexes for"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "f\"Rename index {self.old_name} on {self.model_name} to {self.new_name}\"",
        "f\"Rename index {self.old_name} on"
    ],
    [
        "f\"Rename unnamed index for {self.old_fields} on {self.model_name} to \"",
        "f\"Rename unnamed index for {self.old_fields} on {self.model_name} to"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "return \"Create constraint %s on model %s\" % (",
        "return \"Create constraint %s on model %s\" %"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "return \"Remove constraint %s from model %s\" % (self.name, self.model_name)",
        "return \"Remove constraint %s from model %s\" %"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label,"
    ],
    [
        "return f\"Alter constraint {self.name} on {self.model_name}\"",
        "return f\"Alter constraint {self.name}"
    ],
    [
        "return super().reduce(operation, app_label) or not operation.references_field(",
        "return super().reduce(operation, app_label) or not"
    ],
    [
        "\"\"\"Add a field to a model.\"\"\"",
        "\"\"\"Add a field to"
    ],
    [
        "def __init__(self, model_name, name, field, preserve_default=True):",
        "def __init__(self, model_name, name, field,"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "return \"Add field %s to %s\" % (self.name, self.model_name)",
        "return \"Add field %s to %s\" % (self.name,"
    ],
    [
        "\"\"\"Remove a field from a model.\"\"\"",
        "\"\"\"Remove a field from a"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "return \"Remove field %s from %s\" % (self.name, self.model_name)",
        "return \"Remove field %s from %s\" % (self.name,"
    ],
    [
        "Alter a field's database column (e.g. null, max_length) to the provided",
        "Alter a field's database column (e.g."
    ],
    [
        "def __init__(self, model_name, name, field, preserve_default=True):",
        "def __init__(self, model_name, name, field,"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "return \"Alter field %s on %s\" % (self.name, self.model_name)",
        "return \"Alter field %s on %s\""
    ],
    [
        "\"\"\"Rename a field on the model. Might affect db_column too.\"\"\"",
        "\"\"\"Rename a field on the model. Might affect"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "return \"Rename field %s on %s to %s\" % (",
        "return \"Rename field %s on %s to %s\""
    ],
    [
        "name.lower() == self.old_name_lower or name.lower() == self.new_name_lower",
        "name.lower() == self.old_name_lower or name.lower()"
    ],
    [
        "return super(FieldOperation, self).reduce(operation, app_label) or not (",
        "return super(FieldOperation, self).reduce(operation, app_label)"
    ],
    [
        "from .fields import AddField, AlterField, RemoveField, RenameField",
        "from .fields import AddField, AlterField, RemoveField,"
    ],
    [
        "from .special import RunPython, RunSQL, SeparateDatabaseAndState",
        "from .special import RunPython,"
    ],
    [
        "Take two lists of operations - ones that will be used for the database,",
        "Take two lists of operations - ones that will be used"
    ],
    [
        "and ones that will be used for the state change. This allows operations",
        "and ones that will be used for the state change. This"
    ],
    [
        "that don't support state change to have it applied, or have operations",
        "that don't support state change to have it"
    ],
    [
        "that affect the state or not the database, or so on.",
        "that affect the state or not the"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label,"
    ],
    [
        "Run some raw SQL. A reverse SQL statement may be provided.",
        "Run some raw SQL. A reverse"
    ],
    [
        "Also accept a list of operations that represent the state change effected",
        "Also accept a list of operations"
    ],
    [
        "by this SQL change, in case it's custom column/table creation/deletion.",
        "by this SQL change, in case"
    ],
    [
        "self, sql, reverse_sql=None, state_operations=None, hints=None, elidable=False",
        "self, sql, reverse_sql=None, state_operations=None, hints=None,"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "raise NotImplementedError(\"You cannot reverse this operation\")",
        "raise NotImplementedError(\"You cannot"
    ],
    [
        "Run Python code in a context suitable for doing versioned ORM operations.",
        "Run Python code in a context suitable for doing versioned ORM"
    ],
    [
        "self, code, reverse_code=None, atomic=None, hints=None, elidable=False",
        "self, code, reverse_code=None, atomic=None,"
    ],
    [
        "raise ValueError(\"RunPython must be supplied with a callable\")",
        "raise ValueError(\"RunPython must be supplied"
    ],
    [
        "raise ValueError(\"RunPython must be supplied with callable arguments\")",
        "raise ValueError(\"RunPython must be"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "raise NotImplementedError(\"You cannot reverse this operation\")",
        "raise NotImplementedError(\"You cannot reverse this"
    ],
    [
        "It's responsible for both mutating the in-memory model state",
        "It's responsible for both mutating the"
    ],
    [
        "(see db/migrations/state.py) to represent what it performs, as well",
        "(see db/migrations/state.py) to represent what it performs,"
    ],
    [
        "as actually performing it against a live database.",
        "as actually performing it against a live"
    ],
    [
        "Note that some operations won't modify memory state at all (e.g. data",
        "Note that some operations won't modify memory state at"
    ],
    [
        "copying operations), and some will need their modifications to be",
        "copying operations), and some will need their modifications"
    ],
    [
        "optionally specified by the user (e.g. custom Python code snippets)",
        "optionally specified by the user (e.g."
    ],
    [
        "Due to the way this class deals with deconstruction, it should be",
        "Due to the way this class deals with deconstruction, it should"
    ],
    [
        "under django.db.migrations), positional arguments, and keyword",
        "under django.db.migrations), positional arguments, and"
    ],
    [
        "Take the state from the previous migration, and mutate it",
        "Take the state from the previous migration,"
    ],
    [
        "so that it matches what this migration would perform.",
        "so that it matches what this migration would"
    ],
    [
        "\"subclasses of Operation must provide a state_forwards() method\"",
        "\"subclasses of Operation must provide a state_forwards()"
    ],
    [
        "def database_forwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_forwards(self, app_label, schema_editor, from_state,"
    ],
    [
        "Perform the mutation on the database schema in the normal",
        "Perform the mutation on the database"
    ],
    [
        "\"subclasses of Operation must provide a database_forwards() method\"",
        "\"subclasses of Operation must provide"
    ],
    [
        "def database_backwards(self, app_label, schema_editor, from_state, to_state):",
        "def database_backwards(self, app_label, schema_editor,"
    ],
    [
        "Perform the mutation on the database schema in the reverse",
        "Perform the mutation on the"
    ],
    [
        "direction - e.g. if this were CreateModel, it would in fact",
        "direction - e.g. if this were CreateModel, it would in"
    ],
    [
        "\"subclasses of Operation must provide a database_backwards() method\"",
        "\"subclasses of Operation must provide a"
    ],
    [
        "Output a brief summary of what the action does.",
        "Output a brief summary of what"
    ],
    [
        "return \"%s: %s\" % (self.__class__.__name__, self._constructor_args)",
        "return \"%s: %s\""
    ],
    [
        "\"\"\"Output a description prefixed by a category symbol.\"\"\"",
        "\"\"\"Output a description prefixed by a category"
    ],
    [
        "A filename part suitable for automatically naming a migration",
        "A filename part suitable for automatically naming a"
    ],
    [
        "containing this operation, or None if not applicable.",
        "containing this operation, or None if not"
    ],
    [
        "Return True if there is a chance this operation references the given",
        "Return True if there is a chance this operation"
    ],
    [
        "model name (as a string), with an app label for accuracy.",
        "model name (as a string), with an app"
    ],
    [
        "Used for optimization. If in doubt, return True;",
        "Used for optimization. If"
    ],
    [
        "returning a false positive will merely make the optimizer a little",
        "returning a false positive will merely make"
    ],
    [
        "less efficient, while returning a false negative may result in an",
        "less efficient, while returning a false negative may result"
    ],
    [
        "Return True if there is a chance this operation references the given",
        "Return True if there is a"
    ],
    [
        "field name, with an app label for accuracy.",
        "field name, with an app label for"
    ],
    [
        "Used for optimization. If in doubt, return True.",
        "Used for optimization. If in"
    ],
    [
        "Return whether or not a model may be migrated.",
        "Return whether or not a"
    ],
    [
        "This is a thin wrapper around router.allow_migrate_model() that",
        "This is a thin wrapper around router.allow_migrate_model()"
    ],
    [
        "preemptively rejects any proxy, swapped out, or unmanaged model.",
        "preemptively rejects any proxy, swapped out, or unmanaged"
    ],
    [
        "Return either a list of operations the actual operation should be",
        "Return either a list of operations the actual"
    ],
    [
        "replaced with or a boolean that indicates whether or not the specified",
        "replaced with or a boolean that"
    ],
    [
        "Helpers to manipulate deferred DDL statements that might need to be adjusted or",
        "Helpers to manipulate deferred DDL statements that might need"
    ],
    [
        "discarded within when executing a migration.",
        "discarded within when executing a"
    ],
    [
        "\"\"\"Base class that defines the reference interface.\"\"\"",
        "\"\"\"Base class that defines the reference"
    ],
    [
        "Return whether or not this instance references the specified table.",
        "Return whether or not this instance references the"
    ],
    [
        "Return whether or not this instance references the specified column.",
        "Return whether or not this instance references the"
    ],
    [
        "Return whether or not this instance references the specified index.",
        "Return whether or not this"
    ],
    [
        "Rename all references to the old_name to the new_table.",
        "Rename all references to the old_name to the"
    ],
    [
        "Rename all references to the old_column to the new_column.",
        "Rename all references to the old_column"
    ],
    [
        "return \"<%s %r>\" % (self.__class__.__name__, str(self))",
        "return \"<%s %r>\" % (self.__class__.__name__,"
    ],
    [
        "\"Subclasses must define how they should be converted to string.\"",
        "\"Subclasses must define how they should be converted to"
    ],
    [
        "\"\"\"Hold a reference to a table.\"\"\"",
        "\"\"\"Hold a reference to a"
    ],
    [
        "return self.references_table(table) and str(self) == index",
        "return self.references_table(table) and"
    ],
    [
        "\"\"\"Base class for references to multiple columns of a table.\"\"\"",
        "\"\"\"Base class for references to multiple columns of a"
    ],
    [
        "return self.table == table and column in self.columns",
        "return self.table == table and column"
    ],
    [
        "\"\"\"Hold a reference to one or many columns.\"\"\"",
        "\"\"\"Hold a reference to one or"
    ],
    [
        "def __init__(self, table, columns, quote_name, col_suffixes=()):",
        "def __init__(self, table, columns, quote_name,"
    ],
    [
        "col_str(column, idx) for idx, column in enumerate(self.columns)",
        "col_str(column, idx) for idx, column in"
    ],
    [
        "\"\"\"Hold a reference to an index name.\"\"\"",
        "\"\"\"Hold a reference to an index"
    ],
    [
        "def __init__(self, table, columns, suffix, create_index_name):",
        "def __init__(self, table, columns, suffix,"
    ],
    [
        "def __init__(self, table, columns, quote_name, col_suffixes=(), opclasses=()):",
        "def __init__(self, table, columns, quote_name,"
    ],
    [
        "col_str(column, idx) for idx, column in enumerate(self.columns)",
        "col_str(column, idx) for idx, column"
    ],
    [
        "\"\"\"Hold a reference to a foreign key name.\"\"\"",
        "\"\"\"Hold a reference to a"
    ],
    [
        "Statement template and formatting parameters container.",
        "Statement template and"
    ],
    [
        "Allows keeping a reference to a statement without interpolating identifiers",
        "Allows keeping a reference to a statement without"
    ],
    [
        "that might have to be adjusted if they're referencing a table or column",
        "that might have to be adjusted if they're referencing a table or"
    ],
    [
        "def __init__(self, table, expressions, compiler, quote_value):",
        "def __init__(self, table, expressions,"
    ],
    [
        "WRAP_ERROR_ATTRS = frozenset([\"fetchone\", \"fetchmany\", \"fetchall\", \"nextset\"])",
        "WRAP_ERROR_ATTRS = frozenset([\"fetchone\","
    ],
    [
        "\"Accessing the database during app initialization is discouraged. To fix this \"",
        "\"Accessing the database during app initialization is discouraged. To"
    ],
    [
        "\"warning, avoid executing queries in AppConfig.ready() or when your app \"",
        "\"warning, avoid executing queries in AppConfig.ready() or"
    ],
    [
        "if kparams is not None and not self.db.features.supports_callproc_kwargs:",
        "if kparams is not"
    ],
    [
        "\"Keyword parameters for callproc are not supported on this \"",
        "\"Keyword parameters for callproc are not"
    ],
    [
        "if not apps.ready and not apps.stored_app_configs:",
        "if not apps.ready and not"
    ],
    [
        "if params is None and kparams is None:",
        "if params is None"
    ],
    [
        "def _execute_with_wrappers(self, sql, params, many, executor):",
        "def _execute_with_wrappers(self, sql,"
    ],
    [
        "context = {\"connection\": self.db, \"cursor\": self}",
        "context = {\"connection\": self.db, \"cursor\":"
    ],
    [
        "if not apps.ready and not apps.stored_app_configs:",
        "if not apps.ready"
    ],
    [
        "if not apps.ready and not apps.stored_app_configs:",
        "if not apps.ready and not"
    ],
    [
        "times = len(params) if many else \"\"",
        "times = len(params) if many else"
    ],
    [
        "\"sql\": \"%s times: %s\" % (times, sql) if many else sql,",
        "\"sql\": \"%s times: %s\" % (times, sql)"
    ],
    [
        "datetime.date(*map(int, s.split(\"-\"))) if s else None",
        "datetime.date(*map(int, s.split(\"-\"))) if s else"
    ],
    [
        "if \" \" not in s:",
        "if \" \" not"
    ],
    [
        "Split an SQL identifier into a two element tuple of (namespace, name).",
        "Split an SQL identifier into a two element tuple of"
    ],
    [
        "The identifier could be a table, column, or sequence name might be prefixed",
        "The identifier could be a table, column, or sequence name might"
    ],
    [
        "Shorten an SQL identifier to a repeatable mangled version with the given",
        "Shorten an SQL identifier to a repeatable mangled version with"
    ],
    [
        "If a quote stripped name contains a namespace, e.g. USERNAME\".\"TABLE,",
        "If a quote stripped name"
    ],
    [
        "if length is None or len(name) <= length:",
        "if length is None or"
    ],
    [
        "'%s\".\"' % namespace if namespace else \"\",",
        "'%s\".\"' % namespace if"
    ],
    [
        "Format a number into a string with the requisite number of digits and",
        "Format a number into a string with the requisite"
    ],
    [
        "Strip quotes off of quoted table names to make them safe for use in index",
        "Strip quotes off of quoted table names to make them safe for"
    ],
    [
        "names, sequence names, etc. For example '\"USER\".\"TABLE\"' (an Oracle naming",
        "names, sequence names, etc. For example"
    ],
    [
        "from django.db.models.sql.compiler import SQLInsertCompiler as BaseSQLInsertCompiler",
        "from django.db.models.sql.compiler import SQLInsertCompiler"
    ],
    [
        "Sentinel value to signal DatabaseOperations.bulk_insert_sql() that the",
        "Sentinel value to signal DatabaseOperations.bulk_insert_sql() that"
    ],
    [
        "UNNEST strategy should be used for the bulk insert.",
        "UNNEST strategy should be used"
    ],
    [
        "or any(field is None for field in fields)",
        "or any(field is None for field in"
    ],
    [
        "or any(any(hasattr(value, \"as_sql\") for value in row) for row in value_rows)",
        "or any(any(hasattr(value, \"as_sql\") for value in row) for row"
    ],
    [
        "db_types = [field.db_type(self.connection) for field in fields]",
        "db_types = [field.db_type(self.connection) for field in"
    ],
    [
        "if any(db_type.endswith(\"]\") for db_type in db_types):",
        "if any(db_type.endswith(\"]\") for"
    ],
    [
        "return InsertUnnest([\"(%%s)::%s[]\" % db_type for db_type in db_types]), [",
        "return InsertUnnest([\"(%%s)::%s[]\" % db_type for"
    ],
    [
        "return suffix and \"WITH\" + suffix",
        "return suffix and"
    ],
    [
        "\"PostgreSQL does not support collation setting at database \"",
        "\"PostgreSQL does not support collation setting at"
    ],
    [
        "self.log(\"Got an error creating the test database: %s\" % e)",
        "self.log(\"Got an error creating the test database: %s\""
    ],
    [
        "\"Destroying old test database for alias %s...\"",
        "\"Destroying old test database"
    ],
    [
        "self.log(\"Got an error cloning the test database: %s\" % e)",
        "self.log(\"Got an error cloning the test database: %s\" %"
    ],
    [
        "if not dbname and not service:",
        "if not dbname and not"
    ],
    [
        "CREATE FUNCTION test_procedure () RETURNS void AS $$",
        "CREATE FUNCTION test_procedure () RETURNS"
    ],
    [
        "CREATE FUNCTION test_procedure (P_I INTEGER) RETURNS void AS $$",
        "CREATE FUNCTION test_procedure (P_I INTEGER) RETURNS void"
    ],
    [
        "supported_explain_formats = {\"JSON\", \"TEXT\", \"XML\", \"YAML\"}",
        "supported_explain_formats = {\"JSON\", \"TEXT\", \"XML\","
    ],
    [
        "test_now_utc_template = \"STATEMENT_TIMESTAMP() AT TIME ZONE 'UTC'\"",
        "test_now_utc_template = \"STATEMENT_TIMESTAMP() AT TIME ZONE"
    ],
    [
        "insert_test_table_with_defaults = \"INSERT INTO {} DEFAULT VALUES\"",
        "insert_test_table_with_defaults = \"INSERT INTO {} DEFAULT"
    ],
    [
        "\"PostgreSQL requires casting to text.\": {",
        "\"PostgreSQL requires casting to text.\":"
    ],
    [
        "\"Pool does implicit health checks\": {",
        "\"Pool does implicit health"
    ],
    [
        "\"The actual query cannot be determined for server side bindings\": {",
        "\"The actual query cannot be determined for server side"
    ],
    [
        "def date_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def date_trunc_sql(self, lookup_type, sql,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql, params,"
    ],
    [
        "sign = \"-\" if sign == \"+\" else \"+\"",
        "sign = \"-\" if sign"
    ],
    [
        "return f\"{sql} AT TIME ZONE %s\", (*params, tzname_param)",
        "return f\"{sql} AT TIME ZONE"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params ="
    ],
    [
        "def datetime_extract_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_extract_sql(self, lookup_type,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql,"
    ],
    [
        "return f\"EXTRACT(SECOND FROM DATE_TRUNC(%s, {sql}))\", (\"second\", *params)",
        "return f\"EXTRACT(SECOND FROM DATE_TRUNC(%s,"
    ],
    [
        "def datetime_trunc_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_trunc_sql(self, lookup_type, sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params ="
    ],
    [
        "return f\"EXTRACT(SECOND FROM DATE_TRUNC(%s, {sql}))\", (\"second\", *params)",
        "return f\"EXTRACT(SECOND FROM DATE_TRUNC(%s, {sql}))\","
    ],
    [
        "def time_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def time_trunc_sql(self, lookup_type, sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql, params,"
    ],
    [
        "Given a cursor object that has just performed an INSERT...RETURNING",
        "Given a cursor object that"
    ],
    [
        "statement into a table, return the tuple of returned data.",
        "statement into a table, return the tuple of returned"
    ],
    [
        "if lookup_type in (\"iexact\", \"icontains\", \"istartswith\", \"iendswith\"):",
        "if lookup_type in (\"iexact\", \"icontains\","
    ],
    [
        "def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
        "def sql_flush(self, style, tables, *,"
    ],
    [
        "\", \".join(style.SQL_FIELD(self.quote_name(table)) for table in tables),",
        "\", \".join(style.SQL_FIELD(self.quote_name(table)) for table"
    ],
    [
        "return \"USING INDEX TABLESPACE %s\" % self.quote_name(tablespace)",
        "return \"USING INDEX TABLESPACE %s\" %"
    ],
    [
        "Return the maximum length of an identifier.",
        "Return the maximum length"
    ],
    [
        "changed by recompiling PostgreSQL after editing the NAMEDATALEN",
        "changed by recompiling PostgreSQL"
    ],
    [
        "database backend that inherits most of its behavior from this one.",
        "database backend that inherits most of its"
    ],
    [
        "params = [param for param_list in params for param in param_list]",
        "params = [param for param_list in params for param in"
    ],
    [
        "return ([\"DISTINCT ON (%s)\" % \", \".join(fields)], params)",
        "return ([\"DISTINCT ON (%s)\""
    ],
    [
        "if cursor._query and cursor._query.query is not None:",
        "if cursor._query and cursor._query.query is"
    ],
    [
        "return \"RETURNING %s\" % \", \".join(columns), ()",
        "return \"RETURNING %s\" %"
    ],
    [
        "if value is None or hasattr(value, \"resolve_expression\"):",
        "if value is None"
    ],
    [
        "name.upper(): \"true\" if value else \"false\"",
        "name.upper(): \"true\" if value"
    ],
    [
        "prefix += \" (%s)\" % \", \".join(\"%s %s\" % i for i in extra.items())",
        "prefix += \" (%s)\" % \", \".join(\"%s %s\" % i"
    ],
    [
        "def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):",
        "def on_conflict_suffix_sql(self, fields, on_conflict,"
    ],
    [
        "return \"ON CONFLICT(%s) DO UPDATE SET %s\" % (",
        "return \"ON CONFLICT(%s) DO UPDATE SET %s\" %"
    ],
    [
        "def prepare_join_on_clause(self, lhs_table, lhs_field, rhs_table, rhs_field):",
        "def prepare_join_on_clause(self, lhs_table,"
    ],
    [
        "from django.db.backends.base.introspection import FieldInfo as BaseFieldInfo",
        "from django.db.backends.base.introspection import"
    ],
    [
        "from django.db.backends.base.introspection import TableInfo as BaseTableInfo",
        "from django.db.backends.base.introspection import TableInfo as"
    ],
    [
        "FieldInfo = namedtuple(\"FieldInfo\", BaseFieldInfo._fields + (\"is_autofield\", \"comment\"))",
        "FieldInfo = namedtuple(\"FieldInfo\", BaseFieldInfo._fields + (\"is_autofield\","
    ],
    [
        "TableInfo = namedtuple(\"TableInfo\", BaseTableInfo._fields + (\"comment\",))",
        "TableInfo = namedtuple(\"TableInfo\", BaseTableInfo._fields +"
    ],
    [
        "\"\"\"Return a list of table and view names in the current database.\"\"\"",
        "\"\"\"Return a list of table and view"
    ],
    [
        "WHEN c.relkind IN ('m', 'v') THEN 'v'",
        "WHEN c.relkind IN ('m',"
    ],
    [
        "LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace",
        "LEFT JOIN pg_catalog.pg_namespace n ON"
    ],
    [
        "WHERE c.relkind IN ('f', 'm', 'p', 'r', 'v')",
        "WHERE c.relkind IN ('f', 'm',"
    ],
    [
        "AND n.nspname NOT IN ('pg_catalog', 'pg_toast')",
        "AND n.nspname NOT"
    ],
    [
        "Return a description of the table with the DB-API cursor.description",
        "Return a description of the table with the DB-API"
    ],
    [
        "NOT (a.attnotnull OR (t.typtype = 'd' AND t.typnotnull)) AS is_nullable,",
        "NOT (a.attnotnull OR (t.typtype ="
    ],
    [
        "CASE WHEN collname = 'default' THEN NULL ELSE collname END AS collation,",
        "CASE WHEN collname = 'default' THEN NULL"
    ],
    [
        "LEFT JOIN pg_attrdef ad ON a.attrelid = ad.adrelid AND a.attnum = ad.adnum",
        "LEFT JOIN pg_attrdef ad ON a.attrelid = ad.adrelid"
    ],
    [
        "LEFT JOIN pg_collation co ON a.attcollation = co.oid",
        "LEFT JOIN pg_collation co"
    ],
    [
        "JOIN pg_type t ON a.atttypid = t.oid",
        "JOIN pg_type t ON a.atttypid"
    ],
    [
        "JOIN pg_class c ON a.attrelid = c.oid",
        "JOIN pg_class c ON"
    ],
    [
        "JOIN pg_namespace n ON c.relnamespace = n.oid",
        "JOIN pg_namespace n ON"
    ],
    [
        "WHERE c.relkind IN ('f', 'm', 'p', 'r', 'v')",
        "WHERE c.relkind IN ('f', 'm',"
    ],
    [
        "AND n.nspname NOT IN ('pg_catalog', 'pg_toast')",
        "AND n.nspname NOT IN"
    ],
    [
        "line.internal_size if line.display_size is None else line.display_size,",
        "line.internal_size if line.display_size is None"
    ],
    [
        "JOIN pg_depend d ON d.objid = s.oid",
        "JOIN pg_depend d ON d.objid ="
    ],
    [
        "JOIN pg_attribute a ON d.refobjid = a.attrelid",
        "JOIN pg_attribute a ON d.refobjid"
    ],
    [
        "JOIN pg_class tbl ON tbl.oid = d.refobjid",
        "JOIN pg_class tbl ON tbl.oid ="
    ],
    [
        "Return a dictionary of {field_name: (field_name_other_table, other_table)}",
        "Return a dictionary of {field_name:"
    ],
    [
        "representing all foreign keys in the given table.",
        "representing all foreign keys in the given"
    ],
    [
        "Retrieve any constraints or keys (unique, pk, fk, check, index) across",
        "Retrieve any constraints or keys (unique, pk, fk, check, index)"
    ],
    [
        "one or more columns. Also retrieve the definition of expression-based",
        "one or more columns. Also"
    ],
    [
        "FROM unnest(c.conkey) WITH ORDINALITY cols(colid, arridx)",
        "FROM unnest(c.conkey) WITH ORDINALITY cols(colid,"
    ],
    [
        "JOIN pg_attribute AS ca ON cols.colid = ca.attnum",
        "JOIN pg_attribute AS ca ON"
    ],
    [
        "(SELECT fkc.relname || '.' || fka.attname",
        "(SELECT fkc.relname ||"
    ],
    [
        "JOIN pg_class AS fkc ON fka.attrelid = fkc.oid",
        "JOIN pg_class AS fkc"
    ],
    [
        "JOIN pg_class AS cl ON c.conrelid = cl.oid",
        "JOIN pg_class AS cl ON"
    ],
    [
        "WHERE cl.relname = %s AND pg_catalog.pg_table_is_visible(cl.oid)",
        "WHERE cl.relname = %s AND"
    ],
    [
        "for constraint, columns, kind, used_cols, options in cursor.fetchall():",
        "for constraint, columns, kind, used_cols, options"
    ],
    [
        "WHEN idx.indexprs IS NOT NULL THEN",
        "WHEN idx.indexprs IS NOT"
    ],
    [
        "LEFT JOIN pg_class c ON idx.indrelid = c.oid",
        "LEFT JOIN pg_class c ON"
    ],
    [
        "pg_attribute attr ON attr.attrelid = c.oid AND attr.attnum = idx.key",
        "pg_attribute attr ON attr.attrelid = c.oid AND attr.attnum ="
    ],
    [
        "WHERE c.relname = %s AND pg_catalog.pg_table_is_visible(c.oid)",
        "WHERE c.relname ="
    ],
    [
        "GROUP BY indexname, indisunique, indisprimary, amname, exprdef, attoptions;",
        "GROUP BY indexname, indisunique,"
    ],
    [
        "\"columns\": columns if columns != [None] else [],",
        "\"columns\": columns if columns != [None] else"
    ],
    [
        "\"orders\": orders if orders != [None] else [],",
        "\"orders\": orders if orders !="
    ],
    [
        "\"type\": Index.suffix if basic_index else type_,",
        "\"type\": Index.suffix if basic_index else"
    ],
    [
        "from psycopg import ClientCursor, IsolationLevel, adapt, adapters, errors, sql",
        "from psycopg import ClientCursor, IsolationLevel, adapt, adapters,"
    ],
    [
        "DateRange = DateTimeRange = DateTimeTZRange = NumericRange = Range",
        "DateRange = DateTimeRange = DateTimeTZRange = NumericRange ="
    ],
    [
        "Load a PostgreSQL timestamptz using the a specific timezone.",
        "Load a PostgreSQL timestamptz using the a"
    ],
    [
        "The timezone can be None too, in which case it will be chopped.",
        "The timezone can be None too, in"
    ],
    [
        "\"\"\"A Range dumper customized for Django.\"\"\"",
        "\"\"\"A Range dumper customized for"
    ],
    [
        "if dumper is not self and dumper.oid == TSRANGE_OID:",
        "if dumper is not self"
    ],
    [
        "RANGE_TYPES = (DateRange, DateTimeRange, DateTimeTZRange, NumericRange)",
        "RANGE_TYPES = (DateRange, DateTimeRange,"
    ],
    [
        "from django.db import DatabaseError as WrappedDatabaseError",
        "from django.db import DatabaseError"
    ],
    [
        "from django.db.backends.utils import CursorDebugWrapper as BaseCursorDebugWrapper",
        "from django.db.backends.utils import CursorDebugWrapper"
    ],
    [
        "\"AutoField\": \"GENERATED BY DEFAULT AS IDENTITY\",",
        "\"AutoField\": \"GENERATED BY DEFAULT AS"
    ],
    [
        "\"BigAutoField\": \"GENERATED BY DEFAULT AS IDENTITY\",",
        "\"BigAutoField\": \"GENERATED BY"
    ],
    [
        "\"SmallAutoField\": \"GENERATED BY DEFAULT AS IDENTITY\",",
        "\"SmallAutoField\": \"GENERATED BY DEFAULT AS"
    ],
    [
        "r\"REPLACE(REPLACE(REPLACE({}, E'\\\\', E'\\\\\\\\'), E'%%', E'\\\\%%'), E'_', E'\\\\_')\"",
        "r\"REPLACE(REPLACE(REPLACE({}, E'\\\\', E'\\\\\\\\'), E'%%', E'\\\\%%'),"
    ],
    [
        "\"contains\": \"LIKE '%%' || {} || '%%'\",",
        "\"contains\": \"LIKE '%%' || {}"
    ],
    [
        "\"icontains\": \"LIKE '%%' || UPPER({}) || '%%'\",",
        "\"icontains\": \"LIKE '%%' ||"
    ],
    [
        "if self.alias == NO_DB_ALIAS or not pool_options:",
        "if self.alias == NO_DB_ALIAS or not"
    ],
    [
        "\"Error loading psycopg_pool module.\\nDid you install psycopg[pool]?\"",
        "\"Error loading psycopg_pool module.\\nDid you install"
    ],
    [
        "Return a tuple of the database's version.",
        "Return a tuple of the database's"
    ],
    [
        "if settings_dict[\"NAME\"] == \"\" and not settings_dict[\"OPTIONS\"].get(\"service\"):",
        "if settings_dict[\"NAME\"] == \"\" and not"
    ],
    [
        "\"Please supply the NAME or OPTIONS['service'] value.\"",
        "\"Please supply the NAME"
    ],
    [
        "if len(settings_dict[\"NAME\"] or \"\") > self.ops.max_name_length():",
        "if len(settings_dict[\"NAME\"] or \"\") >"
    ],
    [
        "\"The database name '%s' (%d characters) is longer than \"",
        "\"The database name '%s' (%d characters) is longer than"
    ],
    [
        "\"PostgreSQL's limit of %d characters. Supply a shorter NAME \"",
        "\"PostgreSQL's limit of %d characters. Supply a"
    ],
    [
        "f\"Invalid transaction isolation level {isolation_level_value} \"",
        "f\"Invalid transaction isolation level {isolation_level_value}"
    ],
    [
        "f\"specified. Use one of the psycopg.IsolationLevel values.\"",
        "f\"specified. Use one of the psycopg.IsolationLevel"
    ],
    [
        "if timezone_name and conn_timezone_name != timezone_name:",
        "if timezone_name and conn_timezone_name"
    ],
    [
        "sql = self.ops.compose_sql(\"SET ROLE %s\", [new_role])",
        "sql = self.ops.compose_sql(\"SET"
    ],
    [
        "if self.connection is not None and not self.pool:",
        "if self.connection is not None"
    ],
    [
        "cursor.tzinfo_factory = self.tzinfo_factory if settings.USE_TZ else None",
        "cursor.tzinfo_factory = self.tzinfo_factory if"
    ],
    [
        "Check constraints by setting them to immediate. Return them to deferred",
        "Check constraints by setting them to immediate. Return them to"
    ],
    [
        "\"Normally Django will use a connection to the 'postgres' database \"",
        "\"Normally Django will use a connection"
    ],
    [
        "\"to avoid running initialization queries against the production \"",
        "\"to avoid running initialization queries"
    ],
    [
        "\"database when it's not needed (for example, when running tests). \"",
        "\"database when it's not needed (for"
    ],
    [
        "\"Django was unable to create a connection to the 'postgres' database \"",
        "\"Django was unable to create a connection to the 'postgres'"
    ],
    [
        "\"and will use the first PostgreSQL database instead.\",",
        "\"and will use the"
    ],
    [
        "A subclass of psycopg cursor implementing callproc.",
        "A subclass of psycopg cursor"
    ],
    [
        "qparts = [sql.SQL(\"SELECT * FROM \"), name, sql.SQL(\"(\")]",
        "qparts = [sql.SQL(\"SELECT * FROM \"),"
    ],
    [
        "cursors but the ORM doesn't yet support the systematic generation of",
        "cursors but the ORM doesn't yet support"
    ],
    [
        "ClientCursorMixin forces the usage of client-side bindings while",
        "ClientCursorMixin forces the usage of client-side"
    ],
    [
        "ServerCursor implements the logic required to declare and scroll",
        "ServerCursor implements the logic required"
    ],
    [
        "Mixing ClientCursorMixin in wouldn't be necessary if Cursor allowed to",
        "Mixing ClientCursorMixin in wouldn't be"
    ],
    [
        "specify how parameters should be bound instead, which ServerCursor",
        "specify how parameters should be bound"
    ],
    [
        "would inherit, but that's not the case.",
        "would inherit, but that's not the"
    ],
    [
        "def copy_to(self, file, table, *args, **kwargs):",
        "def copy_to(self, file,"
    ],
    [
        "with self.debug_sql(sql=\"COPY %s TO STDOUT\" % table):",
        "with self.debug_sql(sql=\"COPY %s TO STDOUT\""
    ],
    [
        "\"UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL\"",
        "\"UPDATE %(table)s SET %(column)s = %(default)s"
    ],
    [
        "sql_alter_sequence_type = \"ALTER SEQUENCE IF EXISTS %(sequence)s AS %(type)s\"",
        "sql_alter_sequence_type = \"ALTER SEQUENCE IF EXISTS %(sequence)s AS"
    ],
    [
        "sql_delete_sequence = \"DROP SEQUENCE IF EXISTS %(sequence)s CASCADE\"",
        "sql_delete_sequence = \"DROP SEQUENCE IF EXISTS"
    ],
    [
        "\"CREATE INDEX %(name)s ON %(table)s%(using)s \"",
        "\"CREATE INDEX %(name)s ON"
    ],
    [
        "\"CREATE INDEX CONCURRENTLY %(name)s ON %(table)s%(using)s \"",
        "\"CREATE INDEX CONCURRENTLY %(name)s"
    ],
    [
        "sql_delete_index = \"DROP INDEX IF EXISTS %(name)s\"",
        "sql_delete_index = \"DROP INDEX IF"
    ],
    [
        "sql_delete_index_concurrently = \"DROP INDEX CONCURRENTLY IF EXISTS %(name)s\"",
        "sql_delete_index_concurrently = \"DROP INDEX CONCURRENTLY"
    ],
    [
        "\"ALTER TABLE %(table)s DROP CONSTRAINT %(name)s\"",
        "\"ALTER TABLE %(table)s"
    ],
    [
        "\"ALTER TABLE %(table)s ALTER COLUMN %(column)s ADD \"",
        "\"ALTER TABLE %(table)s ALTER COLUMN %(column)s ADD"
    ],
    [
        "\"ALTER TABLE %(table)s ALTER COLUMN %(column)s DROP IDENTITY IF EXISTS\"",
        "\"ALTER TABLE %(table)s ALTER COLUMN %(column)s DROP IDENTITY"
    ],
    [
        "Return the statement to create an index with varchar operator pattern",
        "Return the statement to create an index with"
    ],
    [
        "when the column type is 'varchar' or 'text', otherwise return None.",
        "when the column type is 'varchar' or 'text', otherwise return"
    ],
    [
        "if db_type is not None and (field.db_index or field.unique):",
        "if db_type is not None"
    ],
    [
        "if new_internal_type == \"ArrayField\" and new_internal_type == old_internal_type:",
        "if new_internal_type == \"ArrayField\" and new_internal_type"
    ],
    [
        "return (old_field.db_index or old_field.unique) and (",
        "return (old_field.db_index or"
    ],
    [
        "self, model, old_field, new_field, new_type, old_collation, new_collation",
        "self, model, old_field, new_field, new_type,"
    ],
    [
        "model, old_field, new_field, new_type, old_collation, new_collation",
        "model, old_field, new_field, new_type,"
    ],
    [
        "elif new_is_auto and old_is_auto and old_internal_type != new_internal_type:",
        "elif new_is_auto and old_is_auto and old_internal_type"
    ],
    [
        "model, old_field, new_field, new_type, old_collation, new_collation",
        "model, old_field, new_field, new_type, old_collation,"
    ],
    [
        "model, old_field, new_field, new_type, old_collation, new_collation",
        "model, old_field, new_field, new_type, old_collation,"
    ],
    [
        "(not (old_field.db_index or old_field.unique) and new_field.db_index)",
        "(not (old_field.db_index or old_field.unique)"
    ],
    [
        "if old_field.unique and not (new_field.db_index or new_field.unique):",
        "if old_field.unique and not (new_field.db_index"
    ],
    [
        "def _index_columns(self, table, columns, col_suffixes, opclasses):",
        "def _index_columns(self, table, columns,"
    ],
    [
        "def _delete_index_sql(self, model, name, sql=None, concurrently=False):",
        "def _delete_index_sql(self, model,"
    ],
    [
        "Django uses this if the database ENGINE setting is empty (None or empty string).",
        "Django uses this if the database ENGINE setting is"
    ],
    [
        "Each of these API functions, except connection.close(), raise",
        "Each of these API"
    ],
    [
        "\"Please supply the ENGINE value. Check \"",
        "\"Please supply the ENGINE value. Check"
    ],
    [
        "from django.db.models import DecimalField, DurationField, Func",
        "from django.db.models import DecimalField, DurationField,"
    ],
    [
        "def __init__(self, expression, *, output_field=None, **extra):",
        "def __init__(self, expression,"
    ],
    [
        "def __init__(self, expression, *, output_field=None, **extra):",
        "def __init__(self, expression, *,"
    ],
    [
        "This is analogous to other backends' `_nodb_connection` property,",
        "This is analogous to other backends'"
    ],
    [
        "which allows access to an \"administrative\" connection which can",
        "which allows access to an \"administrative\""
    ],
    [
        "be used to manage the test databases.",
        "be used to manage the test"
    ],
    [
        "For Oracle, the only connection that can be used for that purpose",
        "For Oracle, the only connection that can"
    ],
    [
        "settings_dict = {**settings_dict, \"USER\": user, \"PASSWORD\": password}",
        "settings_dict = {**settings_dict, \"USER\": user, \"PASSWORD\":"
    ],
    [
        "self.log(\"Got an error creating the test database: %s\" % e)",
        "self.log(\"Got an error creating the"
    ],
    [
        "\"It appears the test database, %s, already exists. \"",
        "\"It appears the test database,"
    ],
    [
        "\"Type 'yes' to delete it, or 'no' to cancel: \"",
        "\"Type 'yes' to delete it, or 'no'"
    ],
    [
        "if autoclobber or confirm == \"yes\":",
        "if autoclobber or confirm =="
    ],
    [
        "\"Destroying old test database for alias '%s'...\"",
        "\"Destroying old test database"
    ],
    [
        "\"Got an error destroying the old test database: %s\"",
        "\"Got an error destroying the"
    ],
    [
        "\"Got an error destroying the old test database: %s\" % e",
        "\"Got an error destroying the old test"
    ],
    [
        "\"Got an error recreating the test database: %s\" % e",
        "\"Got an error recreating the test database: %s\""
    ],
    [
        "self.log(\"Got an error creating the test user: %s\" % e)",
        "self.log(\"Got an error creating the test user:"
    ],
    [
        "\"It appears the test user, %s, already exists. Type \"",
        "\"It appears the test user, %s, already exists."
    ],
    [
        "\"'yes' to delete it, or 'no' to cancel: \"",
        "\"'yes' to delete it, or 'no'"
    ],
    [
        "if autoclobber or confirm == \"yes\":",
        "if autoclobber or confirm =="
    ],
    [
        "self.log(\"Got an error recreating the test user: %s\" % e)",
        "self.log(\"Got an error recreating the test user: %s\" %"
    ],
    [
        "Switch to the user that's used for creating the test database.",
        "Switch to the user that's used"
    ],
    [
        "Oracle doesn't have the concept of separate databases under the same",
        "Oracle doesn't have the concept of separate databases"
    ],
    [
        "user, so a separate user is used; see _create_test_db(). The main user",
        "user, so a separate user is used; see _create_test_db()."
    ],
    [
        "is also needed for cleanup when testing is completed, so save its",
        "is also needed for cleanup when testing is completed, so save"
    ],
    [
        "credentials in the SAVED_USER/SAVED_PASSWORD key in the settings dict.",
        "credentials in the SAVED_USER/SAVED_PASSWORD key in the settings"
    ],
    [
        "real_test_settings[\"USER\"] = real_settings[\"USER\"] = test_settings[\"USER\"] = (",
        "real_test_settings[\"USER\"] = real_settings[\"USER\"] = test_settings[\"USER\"] ="
    ],
    [
        "Set this database up to be used in testing as a mirror of a primary",
        "Set this database up to be used in"
    ],
    [
        "\"There are objects in the old test database which prevent its destruction.\"",
        "\"There are objects in the old test database which prevent its"
    ],
    [
        "\"\\nIf they belong to the test user, deleting the user will allow the test \"",
        "\"\\nIf they belong to the test user, deleting the user will"
    ],
    [
        "\"Otherwise, you will need to find and remove each of these objects, \"",
        "\"Otherwise, you will need to find and remove each of"
    ],
    [
        "confirm = input(\"Type 'yes' to delete user %s: \" % parameters[\"user\"])",
        "confirm = input(\"Type 'yes' to delete user %s: \" %"
    ],
    [
        "if autoclobber or confirm == \"yes\":",
        "if autoclobber or confirm"
    ],
    [
        "self.log(\"Got an error destroying the test user: %s\" % e)",
        "self.log(\"Got an error destroying the test user: %s\""
    ],
    [
        "\"Destroying old test database for alias '%s'...\"",
        "\"Destroying old test database for alias"
    ],
    [
        "self.log(\"Got an error destroying the test database: %s\" % e)",
        "self.log(\"Got an error destroying the test database:"
    ],
    [
        "self.log(\"Tests cancelled -- test database cannot be recreated.\")",
        "self.log(\"Tests cancelled -- test database cannot"
    ],
    [
        "\"Django is configured to use pre-existing test user '%s',\"",
        "\"Django is configured to use"
    ],
    [
        "\" and will not attempt to delete it.\" % parameters[\"user\"]",
        "\" and will not attempt to delete"
    ],
    [
        "self.log(\"Tests cancelled -- test database cannot be recreated.\")",
        "self.log(\"Tests cancelled -- test database"
    ],
    [
        "Destroy a test database, prompting the user for confirmation if the",
        "Destroy a test database, prompting the"
    ],
    [
        "database already exists. Return the name of the test database created.",
        "database already exists. Return the name of the test database"
    ],
    [
        "def _execute_test_db_creation(self, cursor, parameters, verbosity, keepdb=False):",
        "def _execute_test_db_creation(self, cursor,"
    ],
    [
        "self.log(\"_create_test_db(): dbname = %s\" % parameters[\"user\"])",
        "self.log(\"_create_test_db(): dbname ="
    ],
    [
        "AUTOEXTEND ON NEXT %(extsize)s MAXSIZE %(maxsize)s",
        "AUTOEXTEND ON NEXT %(extsize)s MAXSIZE"
    ],
    [
        "AUTOEXTEND ON NEXT %(extsize_tmp)s MAXSIZE %(maxsize_tmp)s",
        "AUTOEXTEND ON NEXT"
    ],
    [
        "AUTOEXTEND ON NEXT %(extsize)s MAXSIZE %(maxsize)s",
        "AUTOEXTEND ON NEXT"
    ],
    [
        "AUTOEXTEND ON NEXT %(extsize_tmp)s MAXSIZE %(maxsize_tmp)s",
        "AUTOEXTEND ON NEXT %(extsize_tmp)s"
    ],
    [
        "def _create_test_user(self, cursor, parameters, verbosity, keepdb=False):",
        "def _create_test_user(self, cursor, parameters,"
    ],
    [
        "self.log(\"_create_test_user(): username = %s\" % parameters[\"user\"])",
        "self.log(\"_create_test_user(): username = %s\""
    ],
    [
        "if not success and self._test_settings_get(\"PASSWORD\") is None:",
        "if not success and self._test_settings_get(\"PASSWORD\") is"
    ],
    [
        "set_password = 'ALTER USER %(user)s IDENTIFIED BY \"%(password)s\"'",
        "set_password = 'ALTER USER %(user)s IDENTIFIED BY"
    ],
    [
        "for object_type in (\"VIEW\", \"MATERIALIZED VIEW\"):",
        "for object_type in"
    ],
    [
        "extra = \"GRANT CREATE %(object_type)s TO %(user)s\"",
        "extra = \"GRANT CREATE %(object_type)s"
    ],
    [
        "\"Failed to grant CREATE %s permission to test user. This may be ok.\"",
        "\"Failed to grant CREATE %s permission to test user. This may"
    ],
    [
        "\"INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINTS\",",
        "\"INCLUDING CONTENTS AND"
    ],
    [
        "\"INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINTS\",",
        "\"INCLUDING CONTENTS AND DATAFILES CASCADE"
    ],
    [
        "self.log(\"Be patient. This can take some time...\")",
        "self.log(\"Be patient. This can take"
    ],
    [
        "self, cursor, statements, parameters, verbosity, allow_quiet_fail=False",
        "self, cursor, statements, parameters, verbosity,"
    ],
    [
        "self, cursor, statements, parameters, verbosity, acceptable_ora_err",
        "self, cursor, statements, parameters,"
    ],
    [
        "Execute statements which are allowed to fail silently if the Oracle",
        "Execute statements which are allowed to fail silently"
    ],
    [
        "error code given by `acceptable_ora_err` is raised. Return True if the",
        "error code given by `acceptable_ora_err` is"
    ],
    [
        "statements execute without an exception, or False otherwise.",
        "statements execute without an exception,"
    ],
    [
        "if acceptable_ora_err is None or acceptable_ora_err not in description:",
        "if acceptable_ora_err is None or acceptable_ora_err not in"
    ],
    [
        "Return a value from the test settings dict, or a given default, or a",
        "Return a value from the test settings dict, or a given"
    ],
    [
        "prefixed entry from the main settings dict.",
        "prefixed entry from the"
    ],
    [
        "if val is None and prefixed:",
        "if val is None and"
    ],
    [
        "if password is None and self._test_user_create():",
        "if password is None and"
    ],
    [
        "\"TBLSPACE_TMP\", TEST_DATABASE_PREFIX + settings_dict[\"USER\"] + \"_temp\"",
        "\"TBLSPACE_TMP\", TEST_DATABASE_PREFIX + settings_dict[\"USER\"]"
    ],
    [
        "Return the 'production' DB name to get the test DB creation machinery",
        "Return the 'production' DB name to"
    ],
    [
        "to work. This isn't a great deal in this case because DB names as",
        "to work. This isn't a great deal in this case"
    ],
    [
        "handled by Django don't have real counterparts in Oracle.",
        "handled by Django don't have real counterparts"
    ],
    [
        "CREATE PROCEDURE \"TEST_PROCEDURE\" (P_I INTEGER) AS",
        "CREATE PROCEDURE \"TEST_PROCEDURE\" (P_I INTEGER)"
    ],
    [
        "test_now_utc_template = \"CURRENT_TIMESTAMP AT TIME ZONE 'UTC'\"",
        "test_now_utc_template = \"CURRENT_TIMESTAMP AT TIME"
    ],
    [
        "\"INSERT INTO {} VALUES (DEFAULT, DEFAULT, DEFAULT)\"",
        "\"INSERT INTO {} VALUES"
    ],
    [
        "\"Oracle doesn't support bitwise XOR.\": {",
        "\"Oracle doesn't support"
    ],
    [
        "\"Oracle requires ORDER BY in row_number, ANSI:SQL doesn't.\": {",
        "\"Oracle requires ORDER BY in row_number, ANSI:SQL doesn't.\":"
    ],
    [
        "\"Oracle doesn't support comparing NCLOB to NUMBER.\": {",
        "\"Oracle doesn't support comparing"
    ],
    [
        "\"Oracle doesn't support casting filters to NUMBER.\": {",
        "\"Oracle doesn't support casting filters"
    ],
    [
        "\"Pooling does not support persistent connections\": {",
        "\"Pooling does not support"
    ],
    [
        "\"virtual\": \"SWEDISH_CI\" if self.supports_collation_on_charfield else None,",
        "\"virtual\": \"SWEDISH_CI\" if self.supports_collation_on_charfield else"
    ],
    [
        "from django.db.backends.utils import split_tzname_delta, strip_quotes, truncate_name",
        "from django.db.backends.utils import split_tzname_delta, strip_quotes,"
    ],
    [
        "from .utils import BulkInsertMapper, InsertVar, Oracle_datetime",
        "from .utils import BulkInsertMapper,"
    ],
    [
        "SELECT sequence_name INTO seq_name FROM user_tab_identity_cols",
        "SELECT sequence_name INTO seq_name FROM"
    ],
    [
        "def date_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def date_trunc_sql(self, lookup_type, sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params ="
    ],
    [
        "return f\"{sign}{offset}\" if offset else tzname",
        "return f\"{sign}{offset}\" if offset else"
    ],
    [
        "raise ValueError(\"Invalid time zone name: %s\" % tzname)",
        "raise ValueError(\"Invalid time zone"
    ],
    [
        "f\"CAST((FROM_TZ({sql}, '{from_timezone_name}') AT TIME ZONE \"",
        "f\"CAST((FROM_TZ({sql}, '{from_timezone_name}') AT"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql, params,"
    ],
    [
        "f\"CASE WHEN {sql} IS NOT NULL THEN {convert_datetime_sql} ELSE NULL END\",",
        "f\"CASE WHEN {sql} IS NOT NULL THEN {convert_datetime_sql} ELSE NULL"
    ],
    [
        "def datetime_extract_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_extract_sql(self, lookup_type,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params ="
    ],
    [
        "def datetime_trunc_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_trunc_sql(self, lookup_type, sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql, params,"
    ],
    [
        "def time_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def time_trunc_sql(self, lookup_type,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql, params,"
    ],
    [
        "return \"\" if value is None else value",
        "return \"\" if value is"
    ],
    [
        "return b\"\" if value is None else value",
        "return b\"\" if value is None"
    ],
    [
        "(\"OFFSET %d ROWS\" % offset) if offset else None,",
        "(\"OFFSET %d ROWS\" % offset) if offset"
    ],
    [
        "(\"FETCH FIRST %d ROWS ONLY\" % fetch) if fetch else None,",
        "(\"FETCH FIRST %d ROWS ONLY\" % fetch) if fetch else"
    ],
    [
        "f\":arg{i}\": param for i, param in enumerate(dict.fromkeys(params))",
        "f\":arg{i}\": param for i,"
    ],
    [
        "params = {f\":{key}\": val for (key, val) in params.items()}",
        "params = {f\":{key}\": val for (key, val) in"
    ],
    [
        "for key in sorted(params, key=len, reverse=True):",
        "for key in sorted(params,"
    ],
    [
        "if lookup_type in (\"iexact\", \"icontains\", \"istartswith\", \"iendswith\"):",
        "if lookup_type in (\"iexact\","
    ],
    [
        "if lookup_type != \"isnull\" and internal_type in (",
        "if lookup_type != \"isnull\""
    ],
    [
        "if not name.startswith('\"') and not name.endswith('\"'):",
        "if not name.startswith('\"') and not"
    ],
    [
        "name = '\"%s\"' % truncate_name(name, self.max_name_length())",
        "name = '\"%s\"' %"
    ],
    [
        "return \"REGEXP_LIKE(%%s, %%s, %s)\" % match_option",
        "return \"REGEXP_LIKE(%%s, %%s, %s)\""
    ],
    [
        "return \"RETURNING %s INTO %s\" % (",
        "return \"RETURNING %s INTO %s\""
    ],
    [
        "def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
        "def sql_flush(self, style, tables, *, reset_sequences=False,"
    ],
    [
        "truncated_tables = {table.upper() for table in tables}",
        "truncated_tables = {table.upper() for"
    ],
    [
        "\"%s %s %s %s %s %s %s %s;\"",
        "\"%s %s %s %s %s"
    ],
    [
        "\"%s %s %s %s %s %s;\"",
        "\"%s %s %s"
    ],
    [
        "return \"USING INDEX TABLESPACE %s\" % self.quote_name(tablespace)",
        "return \"USING INDEX TABLESPACE %s\" %"
    ],
    [
        "Transform a date value to an object compatible with what is expected",
        "Transform a date value to an object compatible"
    ],
    [
        "by the backend driver for date columns.",
        "by the backend driver for"
    ],
    [
        "The default implementation transforms the date to text, but that is not",
        "The default implementation transforms the date to text,"
    ],
    [
        "Transform a datetime value to an object compatible with what is expected",
        "Transform a datetime value to an object compatible with what is"
    ],
    [
        "by the backend driver for datetime columns.",
        "by the backend driver for datetime"
    ],
    [
        "If naive datetime is passed assumes that is in UTC. Normally Django",
        "If naive datetime is passed assumes that"
    ],
    [
        "models.DateTimeField makes sure that if USE_TZ is True passed datetime",
        "models.DateTimeField makes sure that if"
    ],
    [
        "\"Oracle backend does not support timezone-aware datetimes when \"",
        "\"Oracle backend does not support timezone-aware datetimes when"
    ],
    [
        "raise ValueError(\"Oracle backend does not support timezone-aware times.\")",
        "raise ValueError(\"Oracle backend does not support"
    ],
    [
        "raise NotSupportedError(\"Bitwise XOR is not supported in Oracle.\")",
        "raise NotSupportedError(\"Bitwise XOR is not"
    ],
    [
        "Manually created sequence name to keep backward compatibility for",
        "Manually created sequence name to keep"
    ],
    [
        "AutoFields that aren't Oracle identity columns.",
        "AutoFields that aren't"
    ],
    [
        "placeholder = \"%s col_%s\" % (placeholder, i)",
        "placeholder = \"%s col_%s\""
    ],
    [
        "return \"SELECT * FROM (%s)\" % \" UNION ALL \".join(query)",
        "return \"SELECT * FROM (%s)\" % \""
    ],
    [
        "\"NUMTODSINTERVAL(TO_NUMBER(%s - %s), 'DAY')\" % (lhs_sql, rhs_sql),",
        "\"NUMTODSINTERVAL(TO_NUMBER(%s - %s), 'DAY')\" %"
    ],
    [
        "\"\"\"Oracle restricts the number of parameters in a query.\"\"\"",
        "\"\"\"Oracle restricts the number of parameters in a"
    ],
    [
        "field.fields if isinstance(field, CompositePrimaryKey) else [field]",
        "field.fields if isinstance(field, CompositePrimaryKey)"
    ],
    [
        "Oracle supports only EXISTS(...) or filters in the WHERE clause, others",
        "Oracle supports only EXISTS(...) or filters"
    ],
    [
        "A late-binding cursor variable that can be passed to Cursor.execute",
        "A late-binding cursor variable that can be passed"
    ],
    [
        "as a parameter, in order to receive the id of the row created by an",
        "as a parameter, in order to receive the id of the row created by"
    ],
    [
        "A datetime object, with an additional class attribute",
        "A datetime object, with"
    ],
    [
        "to tell oracledb to save the microseconds too.",
        "to tell oracledb to save the"
    ],
    [
        "from django.db.backends.base.introspection import FieldInfo as BaseFieldInfo",
        "from django.db.backends.base.introspection import FieldInfo"
    ],
    [
        "from django.db.backends.base.introspection import TableInfo as BaseTableInfo",
        "from django.db.backends.base.introspection import"
    ],
    [
        "\"FieldInfo\", BaseFieldInfo._fields + (\"is_autofield\", \"is_json\", \"comment\")",
        "\"FieldInfo\", BaseFieldInfo._fields +"
    ],
    [
        "TableInfo = namedtuple(\"TableInfo\", BaseTableInfo._fields + (\"comment\",))",
        "TableInfo = namedtuple(\"TableInfo\", BaseTableInfo._fields +"
    ],
    [
        "elif data_type == oracledb.NCLOB and description.is_json:",
        "elif data_type =="
    ],
    [
        "\"\"\"Return a list of table and view names in the current database.\"\"\"",
        "\"\"\"Return a list of table and"
    ],
    [
        "SELECT view_name, 'v', NULL FROM user_views",
        "SELECT view_name, 'v', NULL FROM"
    ],
    [
        "SELECT mview_name, 'v', NULL FROM user_mviews",
        "SELECT mview_name, 'v', NULL FROM"
    ],
    [
        "Return a description of the table with the DB-API cursor.description",
        "Return a description of the table with the DB-API"
    ],
    [
        "default.rstrip() if default and default != \"NULL\" else None,",
        "default.rstrip() if default and default"
    ],
    [
        "\"\"\"Identifier comparison is case insensitive under Oracle.\"\"\"",
        "\"\"\"Identifier comparison is case insensitive under"
    ],
    [
        "Return a dictionary of {field_name: (field_name_other_table, other_table)}",
        "Return a dictionary of"
    ],
    [
        "representing all foreign keys in the given table.",
        "representing all foreign keys in the"
    ],
    [
        "FROM   user_constraints, USER_CONS_COLUMNS ca, USER_CONS_COLUMNS cb",
        "FROM user_constraints, USER_CONS_COLUMNS ca,"
    ],
    [
        "for field_name, rel_table_name, rel_field_name in cursor.fetchall()",
        "for field_name, rel_table_name, rel_field_name"
    ],
    [
        "Retrieve any constraints or keys (unique, pk, fk, check, index) across",
        "Retrieve any constraints or keys (unique, pk,"
    ],
    [
        "for constraint, columns, pk, unique, check in cursor.fetchall():",
        "for constraint, columns, pk, unique, check in"
    ],
    [
        "for constraint, columns, other_table, other_column in cursor.fetchall():",
        "for constraint, columns, other_table, other_column"
    ],
    [
        "LISTAGG(cols.descend, ',') WITHIN GROUP (ORDER BY cols.column_position)",
        "LISTAGG(cols.descend, ',') WITHIN GROUP (ORDER"
    ],
    [
        "for constraint, type_, unique, columns, orders in cursor.fetchall():",
        "for constraint, type_, unique, columns,"
    ],
    [
        "\"type\": \"idx\" if type_ == \"normal\" else type_,",
        "\"type\": \"idx\" if type_"
    ],
    [
        "raise ImproperlyConfigured(f\"Error loading oracledb module: {e}\")",
        "raise ImproperlyConfigured(f\"Error loading"
    ],
    [
        "\"the Oracle backend requires ctypes to \"",
        "\"the Oracle backend requires"
    ],
    [
        "\"operate correctly under Cygwin.\" % e",
        "\"operate correctly under Cygwin.\" %"
    ],
    [
        "raise AttributeError(\"operators not available as class attribute\")",
        "raise AttributeError(\"operators not available as"
    ],
    [
        "\"LIKE TRANSLATE(%s USING NCHAR_CS) ESCAPE TRANSLATE('\\\\' USING NCHAR_CS)\"",
        "\"LIKE TRANSLATE(%s USING NCHAR_CS)"
    ],
    [
        "\"LIKE TRANSLATE(%s USING NCHAR_CS) ESCAPE TRANSLATE('\\\\' USING NCHAR_CS)\"",
        "\"LIKE TRANSLATE(%s USING NCHAR_CS)"
    ],
    [
        "\"LIKE TRANSLATE(%s USING NCHAR_CS) ESCAPE TRANSLATE('\\\\' USING NCHAR_CS)\"",
        "\"LIKE TRANSLATE(%s USING NCHAR_CS) ESCAPE"
    ],
    [
        "pattern_esc = r\"REPLACE(REPLACE(REPLACE({}, '\\', '\\\\'), '%%', '\\%%'), '_', '\\_')\"",
        "pattern_esc = r\"REPLACE(REPLACE(REPLACE({}, '\\', '\\\\'), '%%',"
    ],
    [
        "\"contains\": \"'%%' || {} || '%%'\",",
        "\"contains\": \"'%%' || {}"
    ],
    [
        "\"icontains\": \"'%%' || UPPER({}) || '%%'\",",
        "\"icontains\": \"'%%' ||"
    ],
    [
        "k: \"LIKE TRANSLATE( \" + v + \" USING NCHAR_CS)\"",
        "k: \"LIKE TRANSLATE( \" + v + \""
    ],
    [
        "k: \"LIKEC \" + v + \" ESCAPE '\\\\'\" for k, v in _pattern_ops.items()",
        "k: \"LIKEC \" + v + \" ESCAPE '\\\\'\" for k, v in"
    ],
    [
        "cursor.execute(\"ALTER SESSION SET NLS_TERRITORY = 'AMERICA'\")",
        "cursor.execute(\"ALTER SESSION SET"
    ],
    [
        "+ (\" TIME_ZONE = 'UTC'\" if settings.USE_TZ else \"\")",
        "+ (\" TIME_ZONE = 'UTC'\" if"
    ],
    [
        "\"sql\": \"-- RELEASE SAVEPOINT %s (faked)\" % self.ops.quote_name(sid),",
        "\"sql\": \"-- RELEASE SAVEPOINT %s (faked)\" %"
    ],
    [
        "Check constraints by setting them to immediate. Return them to deferred",
        "Check constraints by setting them to immediate. Return"
    ],
    [
        "return tuple(int(x) for x in self.connection.version.split(\".\"))",
        "return tuple(int(x) for x in"
    ],
    [
        "Wrapper object for formatting parameters for Oracle. If the string",
        "Wrapper object for formatting parameters"
    ],
    [
        "the input size needs to be set as CLOB. Alternatively, if the parameter",
        "the input size needs to be set as CLOB. Alternatively,"
    ],
    [
        "has an `input_size` attribute, then the value of the `input_size` attribute",
        "has an `input_size` attribute, then the value of the"
    ],
    [
        "will be used instead. Otherwise, no input size will be set for the",
        "will be used instead. Otherwise, no input size will be"
    ],
    [
        "An adapter class for cursor variables that prevents the wrapped object",
        "An adapter class for cursor variables that prevents the"
    ],
    [
        "from being converted into a string when used to instantiate an OracleParam.",
        "from being converted into a string when used to"
    ],
    [
        "This can be used generally for any other object that should be passed into",
        "This can be used generally for any other object that should"
    ],
    [
        "Django uses \"format\" (e.g. '%s') style placeholders, but Oracle uses \":var\"",
        "Django uses \"format\" (e.g. '%s') style placeholders, but"
    ],
    [
        "style. This fixes it -- but note that if you want to use a literal \"%s\" in",
        "style. This fixes it -- but note that if"
    ],
    [
        "a query, you'll need to use \"%%s\".",
        "a query, you'll need"
    ],
    [
        "return decimal.Decimal(value) if \".\" in value else int(value)",
        "return decimal.Decimal(value) if \".\" in value"
    ],
    [
        "def _output_type_handler(cursor, name, defaultType, length, precision, scale):",
        "def _output_type_handler(cursor, name, defaultType, length,"
    ],
    [
        "Called for each db column fetched from cursors. Return numbers as the",
        "Called for each db column fetched from cursors. Return"
    ],
    [
        "appropriate Python type, and NCLOB with JSON as strings.",
        "appropriate Python type, and NCLOB"
    ],
    [
        "return {k: OracleParam(v, self, True) for k, v in params.items()}",
        "return {k: OracleParam(v, self, True) for k,"
    ],
    [
        "return tuple(OracleParam(p, self, True) for p in params)",
        "return tuple(OracleParam(p, self, True) for p in"
    ],
    [
        "return {k: v.force_bytes for k, v in params.items()}",
        "return {k: v.force_bytes for k, v in"
    ],
    [
        "return [p.force_bytes for p in params]",
        "return [p.force_bytes for p in"
    ],
    [
        "args = {k: \":%s\" % k for k in params}",
        "args = {k: \":%s\" % k for k in"
    ],
    [
        "param_types = [(type(param), param) for param in params]",
        "param_types = [(type(param), param)"
    ],
    [
        "args = [params_dict[param_type] for param_type in param_types]",
        "args = [params_dict[param_type] for"
    ],
    [
        "placeholder: param for (_, param), placeholder in params_dict.items()",
        "placeholder: param for (_,"
    ],
    [
        "args = [(\":arg%d\" % i) for i in range(len(params))]",
        "args = [(\":arg%d\" % i)"
    ],
    [
        "query, params = self._fix_for_params(query, params, unify_by_values=True)",
        "query, params ="
    ],
    [
        "formatted = [firstparams] + [self._format_params(p) for p in params_iter]",
        "formatted = [firstparams] + [self._format_params(p) for"
    ],
    [
        "query, [self._param_generator(p) for p in formatted]",
        "query, [self._param_generator(p) for p in"
    ],
    [
        "sql_create_column = \"ALTER TABLE %(table)s ADD %(column)s %(definition)s\"",
        "sql_create_column = \"ALTER TABLE %(table)s ADD"
    ],
    [
        "sql_alter_column_not_null = \"MODIFY %(column)s NOT NULL\"",
        "sql_alter_column_not_null = \"MODIFY"
    ],
    [
        "sql_alter_column_default = \"MODIFY %(column)s DEFAULT %(default)s\"",
        "sql_alter_column_default = \"MODIFY"
    ],
    [
        "sql_alter_column_no_default = \"MODIFY %(column)s DEFAULT NULL\"",
        "sql_alter_column_no_default = \"MODIFY %(column)s"
    ],
    [
        "sql_delete_column = \"ALTER TABLE %(table)s DROP COLUMN %(column)s\"",
        "sql_delete_column = \"ALTER TABLE %(table)s DROP"
    ],
    [
        "sql_delete_table = \"DROP TABLE %(table)s CASCADE CONSTRAINTS\"",
        "sql_delete_table = \"DROP TABLE %(table)s"
    ],
    [
        "sql_create_index = \"CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s\"",
        "sql_create_index = \"CREATE INDEX %(name)s ON %(table)s"
    ],
    [
        "def alter_field(self, model, old_field, new_field, strict=False):",
        "def alter_field(self, model, old_field, new_field,"
    ],
    [
        "Oracle refuses to change from some type to other type.",
        "Oracle refuses to change from some type to"
    ],
    [
        "What we need to do instead is:",
        "What we need to do"
    ],
    [
        "- Add a nullable version of the desired field with a temporary name. If",
        "- Add a nullable version of the desired field with a temporary"
    ],
    [
        "the new column is an auto field, then the temporary column can't be",
        "the new column is an auto field, then"
    ],
    [
        "- Update the table to transfer values from old to new",
        "- Update the table to transfer"
    ],
    [
        "- Rename the new column and possibly drop the nullable property",
        "- Rename the new column and possibly drop"
    ],
    [
        "new_temp_field.null = new_field.get_internal_type() not in (",
        "new_temp_field.null = new_field.get_internal_type()"
    ],
    [
        "new_value = \"TO_DATE(%s, 'YYYY-MM-DD')\" % new_value",
        "new_value = \"TO_DATE(%s, 'YYYY-MM-DD')\" %"
    ],
    [
        "self, model, old_field, new_field, new_type, old_collation, new_collation",
        "self, model, old_field, new_field, new_type,"
    ],
    [
        "model, old_field, new_field, new_type, old_collation, new_collation",
        "model, old_field, new_field, new_type, old_collation,"
    ],
    [
        "Get the properly shortened and uppercased identifier as returned by",
        "Get the properly shortened and uppercased identifier as"
    ],
    [
        "\"\"\"Generate temporary names for workarounds that need temp columns.\"\"\"",
        "\"\"\"Generate temporary names for workarounds that need"
    ],
    [
        "return self.normalize_name(for_name + \"_\" + suffix)",
        "return self.normalize_name(for_name + \"_\""
    ],
    [
        "\"ALTER TABLE %(table)s MODIFY %(column)s DROP IDENTITY\"",
        "\"ALTER TABLE %(table)s MODIFY %(column)s"
    ],
    [
        "SELECT default_collation FROM user_tables WHERE table_name = %s",
        "SELECT default_collation FROM user_tables WHERE table_name ="
    ],
    [
        "if collation is None and old_collation is not None:",
        "if collation is None and old_collation is not"
    ],
    [
        "\"\"\"Oracle doesn't support a database index on some data types.\"\"\"",
        "\"\"\"Oracle doesn't support a database index on"
    ],
    [
        "if field.db_index and field_type.lower() in self.connection._limited_data_types:",
        "if field.db_index and field_type.lower() in"
    ],
    [
        "\"Oracle does not support a database index on %s columns.\"",
        "\"Oracle does not support a database index on"
    ],
    [
        "\"An index won't be created. Silence this warning if \"",
        "\"An index won't be created. Silence"
    ],
    [
        "return not isinstance(database_name, Path) and (",
        "return not isinstance(database_name,"
    ],
    [
        "database_name == \":memory:\" or \"mode=memory\" in database_name",
        "database_name == \":memory:\" or"
    ],
    [
        "\"Destroying old test database for alias %s...\"",
        "\"Destroying old test database for"
    ],
    [
        "\"Type 'yes' if you would like to try deleting the test \"",
        "\"Type 'yes' if you would like to try deleting the test"
    ],
    [
        "\"database '%s', or 'no' to cancel: \" % test_database_name",
        "\"database '%s', or 'no' to cancel: \""
    ],
    [
        "if autoclobber or confirm == \"yes\":",
        "if autoclobber or confirm =="
    ],
    [
        "self.log(\"Got an error deleting the old test database: %s\" % e)",
        "self.log(\"Got an error deleting the old test"
    ],
    [
        "f\"Cloning with start method {start_method!r} is not supported.\"",
        "f\"Cloning with start method {start_method!r}"
    ],
    [
        "\"Destroying old test database for alias %s...\"",
        "\"Destroying old test database"
    ],
    [
        "self.log(\"Got an error deleting the old test database: %s\" % e)",
        "self.log(\"Got an error deleting the old test database: %s\" %"
    ],
    [
        "self.log(\"Got an error cloning the test database: %s\" % e)",
        "self.log(\"Got an error cloning the test database: %s\""
    ],
    [
        "Return a tuple that uniquely identifies a test database.",
        "Return a tuple that uniquely identifies a test"
    ],
    [
        "This takes into account the special cases of \":memory:\" and \"\" for",
        "This takes into account the special cases of \":memory:\""
    ],
    [
        "SQLite since the databases will be distinct despite having the same",
        "SQLite since the databases will be distinct despite having"
    ],
    [
        "Implementations of SQL functions for SQLite.",
        "Implementations of SQL functions"
    ],
    [
        "from re import search as re_search",
        "from re import search"
    ],
    [
        "if tzname is not None and tzname != conn_tzname:",
        "if tzname is not None and"
    ],
    [
        "dt += offset_delta if sign == \"+\" else -offset_delta",
        "dt += offset_delta if sign =="
    ],
    [
        "dt = timezone.localtime(dt, zoneinfo.ZoneInfo(tzname or conn_tzname))",
        "dt = timezone.localtime(dt, zoneinfo.ZoneInfo(tzname or"
    ],
    [
        "LHS and RHS can be either:",
        "LHS and RHS can be"
    ],
    [
        "- An integer number of microseconds",
        "- An integer"
    ],
    [
        "- A string representing a datetime",
        "- A string"
    ],
    [
        "- A scalar value, e.g. float",
        "- A scalar value,"
    ],
    [
        "if connector is None or lhs is None or rhs is None:",
        "if connector is None or lhs is None"
    ],
    [
        "if lhs is None or rhs is None:",
        "if lhs is None or rhs is"
    ],
    [
        "if lhs is None or rhs is None:",
        "if lhs is None"
    ],
    [
        "if pattern is None or string is None:",
        "if pattern is None"
    ],
    [
        "if y is None or x is None:",
        "if y is None or x"
    ],
    [
        "if x is None or y is None:",
        "if x is None or y is"
    ],
    [
        "if base is None or x is None:",
        "if base is None"
    ],
    [
        "if text is None or length is None or fill_text is None:",
        "if text is None or length is None"
    ],
    [
        "return (fill_text * length)[:delta] + text",
        "return (fill_text *"
    ],
    [
        "if x is None or y is None:",
        "if x is None or"
    ],
    [
        "if x is None or y is None:",
        "if x is None or y"
    ],
    [
        "if text is None or count is None:",
        "if text is None or count"
    ],
    [
        "if text is None or length is None or fill_text is None:",
        "if text is None or length"
    ],
    [
        "return (text + fill_text * length)[:length]",
        "return (text + fill_text"
    ],
    [
        "\"SQLite naively remakes the table on field alteration.\": {",
        "\"SQLite naively remakes the table on"
    ],
    [
        "\"SQLite doesn't support negative precision for ROUND().\": {",
        "\"SQLite doesn't support negative precision for ROUND().\":"
    ],
    [
        "\"The actual query cannot be determined on SQLite\": {",
        "\"The actual query cannot be determined"
    ],
    [
        "\"the sqlite backend's close() method is a no-op when using an \"",
        "\"the sqlite backend's close() method is"
    ],
    [
        "\"For SQLite in-memory tests, closing the connection destroys \"",
        "\"For SQLite in-memory tests, closing the"
    ],
    [
        "\"Only connections to in-memory SQLite databases are passed to the \"",
        "\"Only connections to in-memory SQLite databases are passed"
    ],
    [
        "\"multiprocessing's start method is checked only for in-memory \"",
        "\"multiprocessing's start method is checked only for"
    ],
    [
        "\"SQLite does not parse escaped double quotes in the JSON path \"",
        "\"SQLite does not parse escaped double quotes in the JSON path"
    ],
    [
        "from django.db import DatabaseError, NotSupportedError, models",
        "from django.db import"
    ],
    [
        "from django.utils.dateparse import parse_date, parse_datetime, parse_time",
        "from django.utils.dateparse import parse_date, parse_datetime,"
    ],
    [
        "SQLite has a compile-time default (SQLITE_LIMIT_VARIABLE_NUMBER) of",
        "SQLite has a compile-time default (SQLITE_LIMIT_VARIABLE_NUMBER)"
    ],
    [
        "bad_aggregates = (models.Sum, models.Avg, models.Variance, models.StdDev)",
        "bad_aggregates = (models.Sum, models.Avg,"
    ],
    [
        "\"You cannot use Sum, Avg, StdDev, and Variance \"",
        "\"You cannot use Sum, Avg, StdDev, and"
    ],
    [
        "\"since date/time is saved as text.\"",
        "\"since date/time is saved as"
    ],
    [
        "\"SQLite doesn't support DISTINCT on aggregate functions \"",
        "\"SQLite doesn't support DISTINCT on"
    ],
    [
        "Support EXTRACT with a user-defined function django_date_extract()",
        "Support EXTRACT with a user-defined function"
    ],
    [
        "that's registered in connect(). Use single quotes because this is a",
        "that's registered in connect(). Use single quotes"
    ],
    [
        "string and could otherwise cause a collision with a field name.",
        "string and could otherwise cause a collision with a field"
    ],
    [
        "Given a cursor object that has just performed an INSERT...RETURNING",
        "Given a cursor object that has just performed an"
    ],
    [
        "statement into a table, return the list of returned data.",
        "statement into a table, return the list of"
    ],
    [
        "\"\"\"Do nothing since formatting is handled in the custom function.\"\"\"",
        "\"\"\"Do nothing since formatting is handled in the"
    ],
    [
        "def date_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def date_trunc_sql(self, lookup_type, sql,"
    ],
    [
        "return f\"django_date_trunc(%s, {sql}, %s, %s)\", (",
        "return f\"django_date_trunc(%s, {sql},"
    ],
    [
        "def time_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def time_trunc_sql(self, lookup_type,"
    ],
    [
        "return f\"django_time_trunc(%s, {sql}, %s, %s)\", (",
        "return f\"django_time_trunc(%s, {sql}, %s,"
    ],
    [
        "def datetime_extract_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_extract_sql(self, lookup_type, sql,"
    ],
    [
        "return f\"django_datetime_extract(%s, {sql}, %s, %s)\", (",
        "return f\"django_datetime_extract(%s, {sql},"
    ],
    [
        "def datetime_trunc_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_trunc_sql(self, lookup_type,"
    ],
    [
        "return f\"django_datetime_trunc(%s, {sql}, %s, %s)\", (",
        "return f\"django_datetime_trunc(%s, {sql}, %s, %s)\","
    ],
    [
        "Only for last_executed_query! Don't use this to execute SQL queries!",
        "Only for last_executed_query! Don't use this to execute SQL"
    ],
    [
        "chunk = params[index : index + BATCH_SIZE]",
        "chunk = params[index : index +"
    ],
    [
        "sql = \"SELECT \" + \", \".join([\"QUOTE(?)\"] * len(params))",
        "sql = \"SELECT \" + \", \".join([\"QUOTE(?)\"]"
    ],
    [
        "JOIN tables ON (sql REGEXP %s || tables.name || %s)",
        "JOIN tables ON (sql REGEXP"
    ],
    [
        "def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
        "def sql_flush(self, style, tables,"
    ],
    [
        "sequences = [{\"table\": table} for table in tables]",
        "sequences = [{\"table\": table} for"
    ],
    [
        "[\"'%s'\" % sequence_info[\"table\"] for sequence_info in sequences]",
        "[\"'%s'\" % sequence_info[\"table\"] for sequence_info"
    ],
    [
        "\"SQLite backend does not support timezone-aware datetimes when \"",
        "\"SQLite backend does not support timezone-aware datetimes when"
    ],
    [
        "raise ValueError(\"SQLite backend does not support timezone-aware times.\")",
        "raise ValueError(\"SQLite backend does not support timezone-aware"
    ],
    [
        "if connector not in [\"+\", \"-\", \"*\", \"/\"]:",
        "if connector not in [\"+\","
    ],
    [
        "raise DatabaseError(\"Invalid connector for timedelta: %s.\" % connector)",
        "raise DatabaseError(\"Invalid connector for timedelta:"
    ],
    [
        "fn_params = [\"'%s'\" % connector] + sub_expressions",
        "fn_params = [\"'%s'\" % connector] +"
    ],
    [
        "raise ValueError(\"Too many params for timedelta operations.\")",
        "raise ValueError(\"Too many params for"
    ],
    [
        "return \"django_time_diff(%s, %s)\" % (lhs_sql, rhs_sql), params",
        "return \"django_time_diff(%s, %s)\" %"
    ],
    [
        "return \"django_timestamp_diff(%s, %s)\" % (lhs_sql, rhs_sql), params",
        "return \"django_timestamp_diff(%s, %s)\" % (lhs_sql, rhs_sql),"
    ],
    [
        "return \"RETURNING %s\" % \", \".join(columns), ()",
        "return \"RETURNING %s\" % \", \".join(columns),"
    ],
    [
        "def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):",
        "def on_conflict_suffix_sql(self, fields, on_conflict,"
    ],
    [
        "return \"ON CONFLICT(%s) DO UPDATE SET %s\" % (",
        "return \"ON CONFLICT(%s) DO UPDATE SET"
    ],
    [
        "from django.db.backends.base.introspection import FieldInfo as BaseFieldInfo",
        "from django.db.backends.base.introspection import FieldInfo as"
    ],
    [
        "if description.pk and field_type in {",
        "if description.pk and field_type in"
    ],
    [
        "\"\"\"Return a list of table and view names in the current database.\"\"\"",
        "\"\"\"Return a list of table and view names in the current"
    ],
    [
        "WHERE type in ('table', 'view') AND NOT name='sqlite_sequence'",
        "WHERE type in ('table', 'view')"
    ],
    [
        "Return a description of the table with the DB-API cursor.description",
        "Return a description of the table with the"
    ],
    [
        "raise DatabaseError(f\"Table {table_name} does not exist (empty pragma).\")",
        "raise DatabaseError(f\"Table {table_name} does not exist"
    ],
    [
        "for cid, name, data_type, notnull, default, pk, hidden in table_info",
        "for cid, name, data_type, notnull, default,"
    ],
    [
        "Return a dictionary of {column_name: (ref_column_name, ref_table_name)}",
        "Return a dictionary of {column_name: (ref_column_name,"
    ],
    [
        "representing all foreign keys in the given table.",
        "representing all foreign keys in the given"
    ],
    [
        "return [name for _, name, *_, pk in cursor.fetchall() if pk]",
        "return [name for _, name, *_, pk"
    ],
    [
        "tokens = (token for token in statement.flatten() if not token.is_whitespace)",
        "tokens = (token for token in statement.flatten() if not"
    ],
    [
        "Retrieve any constraints or keys (unique, pk, fk, check, index) across",
        "Retrieve any constraints or keys (unique, pk, fk, check,"
    ],
    [
        "\"SELECT sql FROM sqlite_master WHERE type='table' and name=%s\",",
        "\"SELECT sql FROM sqlite_master WHERE type='table' and"
    ],
    [
        "info.name for info in self.get_table_description(cursor, table_name)",
        "info.name for info"
    ],
    [
        "\"SELECT sql FROM sqlite_master WHERE type='index' AND name=%s\",",
        "\"SELECT sql FROM sqlite_master WHERE type='index' AND"
    ],
    [
        "for index_rank, column_rank, column in cursor.fetchall():",
        "for index_rank, column_rank, column in"
    ],
    [
        "for index, (column_name, (ref_column_name, ref_table_name)) in relations",
        "for index, (column_name, (ref_column_name, ref_table_name))"
    ],
    [
        "return [\"DESC\" if info.endswith(\"DESC\") else \"ASC\" for info in columns]",
        "return [\"DESC\" if info.endswith(\"DESC\") else \"ASC\" for info"
    ],
    [
        "WHERE type = 'table' AND name = %s",
        "WHERE type = 'table' AND name"
    ],
    [
        "from django.utils.dateparse import parse_date, parse_datetime, parse_time",
        "from django.utils.dateparse import parse_date, parse_datetime,"
    ],
    [
        "from ._functions import register as register_functions",
        "from ._functions import register"
    ],
    [
        "\"JSONField\": '(JSON_VALID(\"%(column)s\") OR \"%(column)s\" IS NULL)',",
        "\"JSONField\": '(JSON_VALID(\"%(column)s\") OR"
    ],
    [
        "pattern_esc = r\"REPLACE(REPLACE(REPLACE({}, '\\', '\\\\'), '%%', '\\%%'), '_', '\\_')\"",
        "pattern_esc = r\"REPLACE(REPLACE(REPLACE({}, '\\', '\\\\'), '%%',"
    ],
    [
        "\"contains\": r\"LIKE '%%' || {} || '%%' ESCAPE '\\'\",",
        "\"contains\": r\"LIKE '%%' || {} || '%%' ESCAPE"
    ],
    [
        "\"icontains\": r\"LIKE '%%' || UPPER({}) || '%%' ESCAPE '\\'\",",
        "\"icontains\": r\"LIKE '%%' || UPPER({}) || '%%'"
    ],
    [
        "\"startswith\": r\"LIKE {} || '%%' ESCAPE '\\'\",",
        "\"startswith\": r\"LIKE {} || '%%'"
    ],
    [
        "\"istartswith\": r\"LIKE UPPER({}) || '%%' ESCAPE '\\'\",",
        "\"istartswith\": r\"LIKE UPPER({}) || '%%'"
    ],
    [
        "\"endswith\": r\"LIKE '%%' || {} ESCAPE '\\'\",",
        "\"endswith\": r\"LIKE '%%' || {}"
    ],
    [
        "\"iendswith\": r\"LIKE '%%' || UPPER({}) ESCAPE '\\'\",",
        "\"iendswith\": r\"LIKE '%%' || UPPER({})"
    ],
    [
        "if \"check_same_thread\" in kwargs and kwargs[\"check_same_thread\"]:",
        "if \"check_same_thread\" in"
    ],
    [
        "\"The `check_same_thread` option was provided and set to \"",
        "\"The `check_same_thread` option was provided and"
    ],
    [
        "\"True. It will be overridden with False. Use the \"",
        "\"True. It will be overridden with False."
    ],
    [
        "f\"is improperly configured to '{transaction_mode}'. Use one of \"",
        "f\"is improperly configured to '{transaction_mode}'. Use one of"
    ],
    [
        "self.transaction_mode = transaction_mode.upper() if transaction_mode else None",
        "self.transaction_mode = transaction_mode.upper() if transaction_mode"
    ],
    [
        "Check each table name in `table_names` for rows with invalid foreign",
        "Check each table name in `table_names` for"
    ],
    [
        "key references. This method is intended to be used in conjunction with",
        "key references. This method is intended to"
    ],
    [
        "determine if rows with invalid references were entered while constraint",
        "determine if rows with invalid references were"
    ],
    [
        "\"SELECT %s, %s FROM %s WHERE rowid = %%s\"",
        "\"SELECT %s, %s FROM %s WHERE rowid"
    ],
    [
        "\"The row in table '%s' with primary key '%s' has an \"",
        "\"The row in table '%s' with"
    ],
    [
        "\"invalid foreign key: %s.%s contains a value '%s' that \"",
        "\"invalid foreign key: %s.%s contains a"
    ],
    [
        "\"does not have a corresponding value in %s.%s.\"",
        "\"does not have a"
    ],
    [
        "Start a transaction explicitly in autocommit mode.",
        "Start a transaction explicitly in"
    ],
    [
        "This wrapper performs the following conversions:",
        "This wrapper performs the following"
    ],
    [
        "- \"format\" style to \"qmark\" style",
        "- \"format\" style"
    ],
    [
        "- \"pyformat\" style to \"named\" style",
        "- \"pyformat\" style to"
    ],
    [
        "In both cases, if you want to use a literal \"%s\", you'll need to use \"%%s\".",
        "In both cases, if you want to use a literal \"%s\","
    ],
    [
        "param_names = list(params) if isinstance(params, Mapping) else None",
        "param_names = list(params) if isinstance(params, Mapping) else"
    ],
    [
        "if (params := next(peekable, None)) and isinstance(params, Mapping):",
        "if (params := next(peekable, None)) and isinstance(params,"
    ],
    [
        "return query % {name: f\":{name}\" for name in param_names}",
        "return query % {name: f\":{name}\""
    ],
    [
        "\"REFERENCES %(to_table)s (%(to_column)s) DEFERRABLE INITIALLY DEFERRED\"",
        "\"REFERENCES %(to_table)s (%(to_column)s)"
    ],
    [
        "sql_delete_column = \"ALTER TABLE %(table)s DROP COLUMN %(column)s\"",
        "sql_delete_column = \"ALTER TABLE %(table)s DROP"
    ],
    [
        "sql_create_unique = \"CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)\"",
        "sql_create_unique = \"CREATE UNIQUE INDEX %(name)s"
    ],
    [
        "\"SQLite schema editor cannot be used while foreign key \"",
        "\"SQLite schema editor cannot be used while"
    ],
    [
        "\"constraint checks are enabled. Make sure to disable them \"",
        "\"constraint checks are enabled. Make"
    ],
    [
        "\"before entering a transaction.atomic() context because \"",
        "\"before entering a transaction.atomic() context because"
    ],
    [
        "\"SQLite does not support disabling them in the middle of \"",
        "\"SQLite does not support disabling them in the"
    ],
    [
        "\"Cannot quote parameter value %r of type %s\" % (value, type(value))",
        "\"Cannot quote parameter value %r of type %s\" % (value,"
    ],
    [
        "Shortcut to transform a model from old_model into new_model",
        "Shortcut to transform a model"
    ],
    [
        "This follows the correct procedure to perform non-rename or column",
        "This follows the correct procedure to perform"
    ],
    [
        "addition operations based on SQLite's documentation",
        "addition operations based on"
    ],
    [
        "return f.is_relation and f.remote_field.model is model",
        "return f.is_relation and f.remote_field.model is"
    ],
    [
        "f.name: f.clone() if is_self_referential(f) else f",
        "f.name: f.clone() if"
    ],
    [
        "if getattr(create_field, \"primary_key\", False) or any(",
        "if getattr(create_field, \"primary_key\", False)"
    ],
    [
        "getattr(new_field, \"primary_key\", False) for _, new_field in alter_fields",
        "getattr(new_field, \"primary_key\", False) for _,"
    ],
    [
        "case_sql = \"coalesce(%(col)s, %(default)s)\" % {",
        "case_sql = \"coalesce(%(col)s, %(default)s)\" %"
    ],
    [
        "[rename_mapping.get(n, n) for n in unique]",
        "[rename_mapping.get(n, n) for n in"
    ],
    [
        "index for index in indexes if delete_field.name not in index.fields",
        "index for index in indexes if"
    ],
    [
        "new_model = type(\"New%s\" % model._meta.object_name, model.__bases__, body_copy)",
        "new_model = type(\"New%s\" % model._meta.object_name,"
    ],
    [
        "if delete_field and delete_field.attname == new_model._meta.pk.attname:",
        "if delete_field and"
    ],
    [
        "\"INSERT INTO %s (%s) SELECT %s FROM %s\"",
        "\"INSERT INTO %s (%s)"
    ],
    [
        "\", \".join(self.quote_name(x) for x in mapping),",
        "\", \".join(self.quote_name(x) for"
    ],
    [
        "\"\"\"Create a field on a model.\"\"\"",
        "\"\"\"Create a field"
    ],
    [
        "or (field.has_db_default() and not isinstance(field.db_default, Value))",
        "or (field.has_db_default() and"
    ],
    [
        "Remove a field from a model. Usually involves deleting a column,",
        "Remove a field from a model. Usually involves deleting a"
    ],
    [
        "\"\"\"Perform a \"physical\" (non-ManyToMany) field update.\"\"\"",
        "\"\"\"Perform a \"physical\" (non-ManyToMany)"
    ],
    [
        "and self.column_sql(model, old_field) == self.column_sql(model, new_field)",
        "and self.column_sql(model, old_field) =="
    ],
    [
        "old_type != new_type or old_collation != new_collation",
        "old_type != new_type or"
    ],
    [
        "def _alter_many_to_many(self, model, old_field, new_field, strict):",
        "def _alter_many_to_many(self, model, old_field, new_field,"
    ],
    [
        "\"INSERT INTO %s (%s) SELECT %s FROM %s\"",
        "\"INSERT INTO %s (%s)"
    ],
    [
        "from django.db.models.sql.compiler import SQLDeleteCompiler as BaseSQLDeleteCompiler",
        "from django.db.models.sql.compiler import SQLDeleteCompiler"
    ],
    [
        "from django.db.models.sql.compiler import SQLUpdateCompiler as BaseSQLUpdateCompiler",
        "from django.db.models.sql.compiler import"
    ],
    [
        "if self.single_alias or having or qualify:",
        "if self.single_alias or having or"
    ],
    [
        "for resolved, (sql, params, _) in self.get_order_by():",
        "for resolved, (sql, params, _) in"
    ],
    [
        "update_query += \" ORDER BY \" + \", \".join(order_by_sql)",
        "update_query += \" ORDER BY"
    ],
    [
        "self.log(\"Got an error creating the test database: %s\" % e)",
        "self.log(\"Got an error creating the test database:"
    ],
    [
        "\"Destroying old test database for alias %s...\"",
        "\"Destroying old test database for alias"
    ],
    [
        "self.log(\"Got an error recreating the test database: %s\" % e)",
        "self.log(\"Got an error recreating the"
    ],
    [
        "dump_env = load_env = {**os.environ, **cmd_env} if cmd_env else None",
        "dump_env = load_env = {**os.environ,"
    ],
    [
        "insert_test_table_with_defaults = \"INSERT INTO {} () VALUES ()\"",
        "insert_test_table_with_defaults = \"INSERT INTO {}"
    ],
    [
        "\"This doesn't work on MySQL.\": {",
        "\"This doesn't work"
    ],
    [
        "\"MySQL doesn't support functional indexes on a function that \"",
        "\"MySQL doesn't support functional indexes"
    ],
    [
        "\"MySQL supports multiplying and dividing DurationFields by a \"",
        "\"MySQL supports multiplying and dividing DurationFields by a"
    ],
    [
        "\"UPDATE ... ORDER BY syntax on MySQL/MariaDB does not support ordering by\"",
        "\"UPDATE ... ORDER BY syntax on MySQL/MariaDB does"
    ],
    [
        "\"GROUP BY cannot contain nonaggregated column when \"",
        "\"GROUP BY cannot contain nonaggregated column"
    ],
    [
        "\"Nesting of UNIONs at the right-hand side is not supported on \"",
        "\"Nesting of UNIONs at the right-hand side is not supported on"
    ],
    [
        "\"MySQL doesn't allow renaming columns referenced by generated \"",
        "\"MySQL doesn't allow renaming columns referenced by"
    ],
    [
        "\"Internal method used in Django tests. Don't rely on this from your code\"",
        "\"Internal method used in Django tests. Don't rely"
    ],
    [
        "\"Confirm support for introspected foreign keys\"",
        "\"Confirm support for"
    ],
    [
        "return self.connection.mysql_is_mariadb or self.connection.mysql_version >= (",
        "return self.connection.mysql_is_mariadb or"
    ],
    [
        "if not self.connection.mysql_is_mariadb and self.connection.mysql_version >= (",
        "if not self.connection.mysql_is_mariadb and self.connection.mysql_version >="
    ],
    [
        "All storage engines except MyISAM support transactions.",
        "All storage engines except MyISAM support"
    ],
    [
        "from django.db.models import Exists, ExpressionWrapper, Lookup",
        "from django.db.models import"
    ],
    [
        "def date_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def date_trunc_sql(self, lookup_type, sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql, params,"
    ],
    [
        "return f\"CAST(DATE_FORMAT({sql}, %s) AS DATE)\", (*params, format_str)",
        "return f\"CAST(DATE_FORMAT({sql}, %s) AS DATE)\","
    ],
    [
        "return f\"DATE_SUB({sql}, INTERVAL WEEKDAY({sql}) DAY)\", (*params, *params)",
        "return f\"DATE_SUB({sql}, INTERVAL WEEKDAY({sql}) DAY)\","
    ],
    [
        "return f\"{sign}{offset}\" if offset else tzname",
        "return f\"{sign}{offset}\" if"
    ],
    [
        "if tzname and settings.USE_TZ and self.connection.timezone_name != tzname:",
        "if tzname and settings.USE_TZ and self.connection.timezone_name"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params ="
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params ="
    ],
    [
        "def datetime_extract_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_extract_sql(self, lookup_type, sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql,"
    ],
    [
        "def datetime_trunc_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_trunc_sql(self, lookup_type, sql, params,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params ="
    ],
    [
        "fields = [\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\"]",
        "fields = [\"year\", \"month\", \"day\", \"hour\","
    ],
    [
        "format = (\"%Y-\", \"%m\", \"-%d\", \" %H:\", \"%i\", \":%s\")",
        "format = (\"%Y-\", \"%m\", \"-%d\", \""
    ],
    [
        "f\"DATE_SUB({sql}, INTERVAL WEEKDAY({sql}) DAY), %s) AS DATETIME)\"",
        "f\"DATE_SUB({sql}, INTERVAL WEEKDAY({sql}) DAY), %s)"
    ],
    [
        "return f\"CAST(DATE_FORMAT({sql}, %s) AS DATETIME)\", (*params, format_str)",
        "return f\"CAST(DATE_FORMAT({sql}, %s) AS"
    ],
    [
        "def time_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def time_trunc_sql(self, lookup_type, sql,"
    ],
    [
        "sql, params = self._convert_sql_to_tz(sql, params, tzname)",
        "sql, params = self._convert_sql_to_tz(sql,"
    ],
    [
        "return f\"CAST(DATE_FORMAT({sql}, %s) AS TIME)\", (*params, format_str)",
        "return f\"CAST(DATE_FORMAT({sql}, %s) AS TIME)\","
    ],
    [
        "Given a cursor object that has just performed an INSERT...RETURNING",
        "Given a cursor object that has just"
    ],
    [
        "statement into a table, return the tuple of returned data.",
        "statement into a table, return the"
    ],
    [
        "return \"INTERVAL %s MICROSECOND\" % sql",
        "return \"INTERVAL %s MICROSECOND\""
    ],
    [
        "\"ORDER BY NULL\" prevents MySQL from implicitly ordering by grouped",
        "\"ORDER BY NULL\" prevents MySQL from implicitly"
    ],
    [
        "columns. If no ordering would otherwise be applied, we don't want any",
        "columns. If no ordering would otherwise be applied, we don't want"
    ],
    [
        "return \"RETURNING %s\" % \", \".join(columns), ()",
        "return \"RETURNING %s\" % \","
    ],
    [
        "def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
        "def sql_flush(self, style, tables,"
    ],
    [
        "\"MySQL backend does not support timezone-aware datetimes when \"",
        "\"MySQL backend does not support timezone-aware"
    ],
    [
        "raise ValueError(\"MySQL backend does not support timezone-aware times.\")",
        "raise ValueError(\"MySQL backend does not"
    ],
    [
        "\"_binary %s\" if value is not None and not hasattr(value, \"as_sql\") else \"%s\"",
        "\"_binary %s\" if value is not None and not hasattr(value, \"as_sql\") else"
    ],
    [
        "return \"TIMESTAMPDIFF(MICROSECOND, %s, %s)\" % (rhs_sql, lhs_sql), params",
        "return \"TIMESTAMPDIFF(MICROSECOND, %s, %s)\" % (rhs_sql,"
    ],
    [
        "if format and format.upper() == \"TEXT\":",
        "if format and format.upper() =="
    ],
    [
        "not format and \"TREE\" in self.connection.features.supported_explain_formats",
        "not format and \"TREE\" in"
    ],
    [
        "\"ANALYZE\" if self.connection.mysql_is_mariadb else prefix + \" ANALYZE\"",
        "\"ANALYZE\" if self.connection.mysql_is_mariadb else"
    ],
    [
        "if format and not (analyze and not self.connection.mysql_is_mariadb):",
        "if format and not (analyze and"
    ],
    [
        "prefix += \" FORMAT=%s\" % format",
        "prefix += \" FORMAT=%s\" %"
    ],
    [
        "match_option = \"c\" if lookup_type == \"regex\" else \"i\"",
        "match_option = \"c\" if lookup_type == \"regex\" else"
    ],
    [
        "return \"REGEXP_LIKE(%%s, %%s, '%s')\" % match_option",
        "return \"REGEXP_LIKE(%%s, %%s, '%s')\""
    ],
    [
        "if self.connection.mysql_is_mariadb or lookup_type in (",
        "if self.connection.mysql_is_mariadb or lookup_type in"
    ],
    [
        "def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):",
        "def on_conflict_suffix_sql(self, fields,"
    ],
    [
        "conflict_suffix_sql = \"ON DUPLICATE KEY UPDATE %(fields)s\"",
        "conflict_suffix_sql = \"ON DUPLICATE"
    ],
    [
        "from django.db.backends.base.introspection import FieldInfo as BaseFieldInfo",
        "from django.db.backends.base.introspection import"
    ],
    [
        "from django.db.backends.base.introspection import TableInfo as BaseTableInfo",
        "from django.db.backends.base.introspection import"
    ],
    [
        "+ (\"extra\", \"is_unsigned\", \"has_json_constraint\", \"comment\", \"data_type\"),",
        "+ (\"extra\", \"is_unsigned\", \"has_json_constraint\", \"comment\","
    ],
    [
        "\"col_name data_type max_len num_prec num_scale extra column_default \"",
        "\"col_name data_type max_len num_prec num_scale extra column_default"
    ],
    [
        "TableInfo = namedtuple(\"TableInfo\", BaseTableInfo._fields + (\"comment\",))",
        "TableInfo = namedtuple(\"TableInfo\","
    ],
    [
        "\"\"\"Return a list of table and view names in the current database.\"\"\"",
        "\"\"\"Return a list of table and view names in the"
    ],
    [
        "Return a description of the table with the DB-API cursor.description",
        "Return a description of the"
    ],
    [
        "'json_valid(`' + LOWER(c.constraint_name) + '`)' AND",
        "'json_valid(`' + LOWER(c.constraint_name)"
    ],
    [
        "WHEN collation_name = %s THEN NULL",
        "WHEN collation_name = %s THEN"
    ],
    [
        "WHERE table_name = %s AND table_schema = DATABASE()",
        "WHERE table_name = %s AND table_schema ="
    ],
    [
        "return int(i) if i is not None else i",
        "return int(i) if i is not"
    ],
    [
        "Return a dictionary of {field_name: (field_name_other_table, other_table)}",
        "Return a dictionary of {field_name: (field_name_other_table,"
    ],
    [
        "representing all foreign keys in the given table.",
        "representing all foreign keys in the"
    ],
    [
        "for field_name, other_field, other_table in cursor.fetchall()",
        "for field_name, other_field,"
    ],
    [
        "Retrieve the storage engine for a given table. Return the default",
        "Retrieve the storage engine for a given table. Return the"
    ],
    [
        "storage engine if the table doesn't exist.",
        "storage engine if the table"
    ],
    [
        "tokens = (token for token in statement.flatten() if not token.is_whitespace)",
        "tokens = (token for token in statement.flatten()"
    ],
    [
        "Retrieve any constraints or keys (unique, pk, fk, check, index) across",
        "Retrieve any constraints or keys (unique, pk, fk,"
    ],
    [
        "for constraint, column, ref_table, ref_column, kind in cursor.fetchall():",
        "for constraint, column, ref_table,"
    ],
    [
        "\"unique\": kind in {\"PRIMARY KEY\", \"UNIQUE\"},",
        "\"unique\": kind in {\"PRIMARY KEY\","
    ],
    [
        "\"foreign_key\": (ref_table, ref_column) if ref_column else None,",
        "\"foreign_key\": (ref_table, ref_column) if"
    ],
    [
        "info.name for info in self.get_table_description(cursor, table_name)",
        "info.name for info in self.get_table_description(cursor,"
    ],
    [
        "\"SHOW INDEX FROM %s\" % self.connection.ops.quote_name(table_name)",
        "\"SHOW INDEX FROM"
    ],
    [
        "for table, non_unique, index, colseq, column, order, type_ in [",
        "for table, non_unique, index, colseq, column,"
    ],
    [
        "Index.suffix if type_ == \"BTREE\" else type_.lower()",
        "Index.suffix if type_ =="
    ],
    [
        "constraints[index][\"orders\"].append(\"DESC\" if order == \"D\" else \"ASC\")",
        "constraints[index][\"orders\"].append(\"DESC\" if order == \"D\""
    ],
    [
        "from django.db.backends import utils as backend_utils",
        "from django.db.backends import"
    ],
    [
        "\"Error loading MySQLdb module.\\nDid you install mysqlclient?\"",
        "\"Error loading MySQLdb module.\\nDid you"
    ],
    [
        "A thin wrapper around MySQLdb's normal cursor class that catches particular",
        "A thin wrapper around MySQLdb's normal cursor class"
    ],
    [
        "exception instances and reraises them with the correct types.",
        "exception instances and reraises them with the correct"
    ],
    [
        "Implemented as a wrapper, rather than a subclass, so that it isn't stuck",
        "Implemented as a wrapper, rather than a subclass, so that"
    ],
    [
        "to the particular underlying representation returned by Connection.cursor().",
        "to the particular underlying representation"
    ],
    [
        "pattern_esc = r\"REPLACE(REPLACE(REPLACE({}, '\\\\', '\\\\\\\\'), '%%', '\\%%'), '_', '\\_')\"",
        "pattern_esc = r\"REPLACE(REPLACE(REPLACE({}, '\\\\', '\\\\\\\\'), '%%', '\\%%'),"
    ],
    [
        "\"contains\": \"LIKE BINARY CONCAT('%%', {}, '%%')\",",
        "\"contains\": \"LIKE BINARY"
    ],
    [
        "\"Invalid transaction isolation level '%s' specified.\\n\"",
        "\"Invalid transaction isolation"
    ],
    [
        "\"Use one of %s, or None.\"",
        "\"Use one of"
    ],
    [
        "\", \".join(\"'%s'\" % s for s in sorted(self.isolation_levels)),",
        "\", \".join(\"'%s'\" % s for"
    ],
    [
        "\"SET SESSION TRANSACTION ISOLATION LEVEL %s\"",
        "\"SET SESSION TRANSACTION ISOLATION LEVEL"
    ],
    [
        "Disable foreign key checks, primarily for use in adding rows with",
        "Disable foreign key checks, primarily for use in adding"
    ],
    [
        "forward references. Always return True to indicate constraint checks",
        "forward references. Always return True to indicate"
    ],
    [
        "Re-enable foreign key checks after they have been disabled.",
        "Re-enable foreign key checks after they have been"
    ],
    [
        "Check each table name in `table_names` for rows with invalid foreign",
        "Check each table name in `table_names`"
    ],
    [
        "key references. This method is intended to be used in conjunction with",
        "key references. This method is intended to be"
    ],
    [
        "determine if rows with invalid references were entered while constraint",
        "determine if rows with invalid references were entered while"
    ],
    [
        "SELECT REFERRING.`%s`, REFERRING.`%s` FROM `%s` as REFERRING",
        "SELECT REFERRING.`%s`, REFERRING.`%s` FROM"
    ],
    [
        "WHERE REFERRING.`%s` IS NOT NULL AND REFERRED.`%s` IS NULL",
        "WHERE REFERRING.`%s` IS NOT NULL AND REFERRED.`%s`"
    ],
    [
        "\"The row in table '%s' with primary key '%s' has an \"",
        "\"The row in table '%s' with primary key '%s'"
    ],
    [
        "\"invalid foreign key: %s.%s contains a value '%s' that \"",
        "\"invalid foreign key: %s.%s contains"
    ],
    [
        "\"does not have a corresponding value in %s.%s.\"",
        "\"does not have a corresponding value"
    ],
    [
        "return \"MariaDB\" if self.mysql_is_mariadb else \"MySQL\"",
        "return \"MariaDB\" if self.mysql_is_mariadb"
    ],
    [
        "\"Unable to determine MySQL version from version string %r\"",
        "\"Unable to determine MySQL version from version"
    ],
    [
        "return tuple(int(x) for x in match.groups())",
        "return tuple(int(x) for"
    ],
    [
        "return set(sql_mode.split(\",\") if sql_mode else ())",
        "return set(sql_mode.split(\",\") if"
    ],
    [
        "from django.db.models import NOT_PROVIDED, F, UniqueConstraint",
        "from django.db.models import NOT_PROVIDED,"
    ],
    [
        "sql_rename_table = \"RENAME TABLE %(old_table)s TO %(new_table)s\"",
        "sql_rename_table = \"RENAME TABLE %(old_table)s TO"
    ],
    [
        "sql_alter_column_null = \"MODIFY %(column)s %(type)s NULL\"",
        "sql_alter_column_null = \"MODIFY %(column)s %(type)s"
    ],
    [
        "sql_alter_column_not_null = \"MODIFY %(column)s %(type)s NOT NULL\"",
        "sql_alter_column_not_null = \"MODIFY %(column)s"
    ],
    [
        "sql_alter_column_no_default_null = \"ALTER COLUMN %(column)s SET DEFAULT NULL\"",
        "sql_alter_column_no_default_null = \"ALTER COLUMN %(column)s"
    ],
    [
        "sql_delete_column = \"ALTER TABLE %(table)s DROP COLUMN %(column)s\"",
        "sql_delete_column = \"ALTER TABLE"
    ],
    [
        "sql_delete_unique = \"ALTER TABLE %(table)s DROP INDEX %(name)s\"",
        "sql_delete_unique = \"ALTER TABLE"
    ],
    [
        "\", ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) \"",
        "\", ADD CONSTRAINT %(name)s FOREIGN KEY"
    ],
    [
        "sql_delete_fk = \"ALTER TABLE %(table)s DROP FOREIGN KEY %(name)s\"",
        "sql_delete_fk = \"ALTER TABLE %(table)s DROP FOREIGN KEY"
    ],
    [
        "sql_delete_index = \"DROP INDEX %(name)s ON %(table)s\"",
        "sql_delete_index = \"DROP INDEX"
    ],
    [
        "sql_rename_index = \"ALTER TABLE %(table)s RENAME INDEX %(old_name)s TO %(new_name)s\"",
        "sql_rename_index = \"ALTER TABLE %(table)s RENAME INDEX"
    ],
    [
        "\"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)\"",
        "\"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY"
    ],
    [
        "sql_delete_pk = \"ALTER TABLE %(table)s DROP PRIMARY KEY\"",
        "sql_delete_pk = \"ALTER TABLE %(table)s DROP PRIMARY"
    ],
    [
        "sql_create_index = \"CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s\"",
        "sql_create_index = \"CREATE INDEX %(name)s ON"
    ],
    [
        "sql_alter_table_comment = \"ALTER TABLE %(table)s COMMENT = %(comment)s\"",
        "sql_alter_table_comment = \"ALTER TABLE %(table)s COMMENT"
    ],
    [
        "return \"ALTER TABLE %(table)s DROP CONSTRAINT IF EXISTS %(name)s\"",
        "return \"ALTER TABLE %(table)s DROP CONSTRAINT"
    ],
    [
        "return \"ALTER TABLE %(table)s DROP CHECK %(name)s\"",
        "return \"ALTER TABLE %(table)s DROP"
    ],
    [
        "if isinstance(value, str) and isinstance(quoted, bytes):",
        "if isinstance(value, str) and isinstance(quoted,"
    ],
    [
        "default_is_empty = self.effective_default(field) in (\"\", b\"\")",
        "default_is_empty = self.effective_default(field) in (\"\","
    ],
    [
        "default_is_empty = self.effective_default(field) in (\"\", b\"\")",
        "default_is_empty = self.effective_default(field) in (\"\","
    ],
    [
        "if self.skip_default(field) and field.default not in (None, NOT_PROVIDED):",
        "if self.skip_default(field) and field.default"
    ],
    [
        "\"UPDATE %(table)s SET %(column)s = %%s\"",
        "\"UPDATE %(table)s SET"
    ],
    [
        "and constraint.create_sql(model, self) is not None",
        "and constraint.create_sql(model, self) is not"
    ],
    [
        "fields=[field_name for field_name, _ in index.fields_orders],",
        "fields=[field_name for field_name, _"
    ],
    [
        "MySQL can remove an implicit FK index on a field when that field is",
        "MySQL can remove an implicit FK index on a"
    ],
    [
        "covered by another index like a unique_together. \"covered\" here means",
        "covered by another index like"
    ],
    [
        "that the more complex index has the FK field as its first field (see",
        "that the more complex index has the FK field as its"
    ],
    [
        "Manually create an implicit FK index to make it possible to remove the",
        "Manually create an implicit FK index to"
    ],
    [
        "Keep the NULL and DEFAULT properties of the old field. If it has",
        "Keep the NULL and DEFAULT properties of the old field. If it"
    ],
    [
        "changed, it will be handled separately.",
        "changed, it will be handled"
    ],
    [
        "default_sql %= tuple(self.quote_value(p) for p in params)",
        "default_sql %= tuple(self.quote_value(p) for"
    ],
    [
        "self, model, old_field, new_field, new_type, old_collation, new_collation",
        "self, model, old_field, new_field, new_type,"
    ],
    [
        "model, old_field, new_field, new_type, old_collation, new_collation",
        "model, old_field, new_field,"
    ],
    [
        "def _rename_field_sql(self, table, old_field, new_field, new_type):",
        "def _rename_field_sql(self, table, old_field,"
    ],
    [
        "def _alter_column_comment_sql(self, model, new_field, new_type, new_db_comment):",
        "def _alter_column_comment_sql(self, model,"
    ],
    [
        "\"%s Strict Mode is not set for database connection '%s'\"",
        "\"%s Strict Mode is not"
    ],
    [
        "\"%s's Strict Mode fixes many data integrity problems in \"",
        "\"%s's Strict Mode fixes many data"
    ],
    [
        "\"%s, such as data truncation upon insertion, by \"",
        "\"%s, such as data truncation upon"
    ],
    [
        "\"escalating warnings into errors. It is strongly \"",
        "\"escalating warnings into errors. It"
    ],
    [
        "\"recommended you activate it. See: \"",
        "\"recommended you activate it."
    ],
    [
        "MySQL has the following field length restriction:",
        "MySQL has the following field length"
    ],
    [
        "characters if they have a unique index on them.",
        "characters if they have a unique index"
    ],
    [
        "MySQL doesn't support a database index on some data types.",
        "MySQL doesn't support a database"
    ],
    [
        "\"%s may not allow unique CharFields to have a max_length \"",
        "\"%s may not allow unique CharFields"
    ],
    [
        "if field.db_index and field_type.lower() in self.connection._limited_data_types:",
        "if field.db_index and field_type.lower() in"
    ],
    [
        "\"%s does not support a database index on %s columns.\"",
        "\"%s does not support a"
    ],
    [
        "\"An index won't be created. Silence this warning if \"",
        "\"An index won't be created. Silence this warning if"
    ],
    [
        "Encapsulate backend-specific differences pertaining to creation and",
        "Encapsulate backend-specific differences pertaining"
    ],
    [
        "Create a test database, prompting the user for confirmation if the",
        "Create a test database, prompting the"
    ],
    [
        "database already exists. Return the name of the test database created.",
        "database already exists. Return the name of the test"
    ],
    [
        "\"%s test database for alias %s...\"",
        "\"%s test database for"
    ],
    [
        "app.label: None for app in apps.get_app_configs()",
        "app.label: None for"
    ],
    [
        "Set this database up to be used in testing as a mirror of a primary",
        "Set this database up to be used in testing as a mirror of a"
    ],
    [
        "Serialize all data in the database into a JSON string.",
        "Serialize all data in the database into a"
    ],
    [
        "Designed only for test runner usage; will not handle large",
        "Designed only for test runner"
    ],
    [
        "Reload the database with data from a string generated by",
        "Reload the database with data from a"
    ],
    [
        "Return display string for a database for use in various actions.",
        "Return display string for a database for use"
    ],
    [
        "Internal implementation - return the name of the test DB that will be",
        "Internal implementation - return the name of the"
    ],
    [
        "created. Only useful when called from create_test_db() and",
        "created. Only useful when called"
    ],
    [
        "_create_test_db() and when no external munging is done with the 'NAME'",
        "_create_test_db() and when no external munging is"
    ],
    [
        "cursor.execute(\"CREATE DATABASE %(dbname)s %(suffix)s\" % parameters)",
        "cursor.execute(\"CREATE DATABASE %(dbname)s %(suffix)s\" %"
    ],
    [
        "Internal implementation - create the test db tables.",
        "Internal implementation - create the test db"
    ],
    [
        "self.log(\"Got an error creating the test database: %s\" % e)",
        "self.log(\"Got an error creating the test database: %s\" %"
    ],
    [
        "\"Type 'yes' if you would like to try deleting the test \"",
        "\"Type 'yes' if you would like"
    ],
    [
        "\"database '%s', or 'no' to cancel: \" % test_database_name",
        "\"database '%s', or 'no' to"
    ],
    [
        "if autoclobber or confirm == \"yes\":",
        "if autoclobber or confirm =="
    ],
    [
        "\"Destroying old test database for alias %s...\"",
        "\"Destroying old test database for"
    ],
    [
        "self.log(\"Got an error recreating the test database: %s\" % e)",
        "self.log(\"Got an error recreating the test database: %s\""
    ],
    [
        "Return a modified connection settings dict for the n-th clone of a DB.",
        "Return a modified connection settings dict for"
    ],
    [
        "Internal implementation - duplicate the test db tables.",
        "Internal implementation - duplicate the test"
    ],
    [
        "\"The database backend doesn't support cloning databases. \"",
        "\"The database backend doesn't support cloning databases."
    ],
    [
        "\"Disable the option to run tests in parallel processes.\"",
        "\"Disable the option to run tests in"
    ],
    [
        "Destroy a test database, prompting the user for confirmation if the",
        "Destroy a test database, prompting the user"
    ],
    [
        "\"%s test database for alias %s...\"",
        "\"%s test database for alias"
    ],
    [
        "Internal implementation - remove the test db tables.",
        "Internal implementation - remove"
    ],
    [
        "Mark tests in Django's test suite which are expected failures on this",
        "Mark tests in Django's test suite which are"
    ],
    [
        "database and test which should be skipped on this database.",
        "database and test which should be"
    ],
    [
        "SQL to append to the end of the test table creation statements.",
        "SQL to append to the end of the test"
    ],
    [
        "Return a tuple with elements of self.connection.settings_dict (a",
        "Return a tuple with"
    ],
    [
        "DATABASES setting value) that uniquely identify a database",
        "DATABASES setting value) that uniquely identify a"
    ],
    [
        "\"\"\"Encapsulate backend-specific methods for opening a client shell.\"\"\"",
        "\"\"\"Encapsulate backend-specific methods for opening a client"
    ],
    [
        "\"subclasses of BaseDatabaseClient must provide a \"",
        "\"subclasses of BaseDatabaseClient must provide"
    ],
    [
        "\"settings_to_cmd_args_env() method or override a runshell().\"",
        "\"settings_to_cmd_args_env() method or override a"
    ],
    [
        "env = {**os.environ, **env} if env else None",
        "env = {**os.environ, **env} if env"
    ],
    [
        "\"\"\"Does this backend support explaining query execution?\"\"\"",
        "\"\"\"Does this backend support"
    ],
    [
        "Encapsulate backend-specific differences, such as the way a backend",
        "Encapsulate backend-specific differences, such as the way"
    ],
    [
        "performs ordering or calculates the ID of a recently-inserted row.",
        "performs ordering or calculates the ID of"
    ],
    [
        "UNBOUNDED_PRECEDING = \"UNBOUNDED \" + PRECEDING",
        "UNBOUNDED_PRECEDING = \"UNBOUNDED \" +"
    ],
    [
        "UNBOUNDED_FOLLOWING = \"UNBOUNDED \" + FOLLOWING",
        "UNBOUNDED_FOLLOWING = \"UNBOUNDED \""
    ],
    [
        "Return any SQL needed to support auto-incrementing primary keys, or",
        "Return any SQL needed to support auto-incrementing primary"
    ],
    [
        "None if no SQL is necessary.",
        "None if no SQL"
    ],
    [
        "This SQL is executed when a table is created.",
        "This SQL is executed when a table is"
    ],
    [
        "Return the maximum allowed batch size for the backend. The fields",
        "Return the maximum allowed batch size for the"
    ],
    [
        "are the fields going to be inserted in the batch, the objs contains",
        "are the fields going to be inserted"
    ],
    [
        "all the objects to be inserted.",
        "all the objects to be"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a \"",
        "\"subclasses of BaseDatabaseOperations may require a"
    ],
    [
        "Return an SQL query that retrieves the first cache key greater than the",
        "Return an SQL query that retrieves the first cache"
    ],
    [
        "This is used by the 'db' cache backend to determine where to start",
        "This is used by the 'db' cache backend to determine where to"
    ],
    [
        "Given a field instance, return the SQL that casts the result of a union",
        "Given a field instance, return the SQL that casts the result of"
    ],
    [
        "to that type. The resulting string should contain a '%s' placeholder",
        "to that type. The resulting string should contain a '%s'"
    ],
    [
        "Given a lookup_type of 'year', 'month', or 'day', return the SQL that",
        "Given a lookup_type of 'year', 'month', or 'day', return the"
    ],
    [
        "extracts a value from the given date field field_name.",
        "extracts a value from the given"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a date_extract_sql() \"",
        "\"subclasses of BaseDatabaseOperations may"
    ],
    [
        "def date_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def date_trunc_sql(self, lookup_type,"
    ],
    [
        "Given a lookup_type of 'year', 'month', or 'day', return the SQL that",
        "Given a lookup_type of 'year', 'month', or"
    ],
    [
        "truncates the given date or datetime field field_name to a date object",
        "truncates the given date or datetime field field_name to a date"
    ],
    [
        "If `tzname` is provided, the given value is truncated in a specific",
        "If `tzname` is provided, the given value"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a date_trunc_sql() \"",
        "\"subclasses of BaseDatabaseOperations may require a date_trunc_sql()"
    ],
    [
        "Return the SQL to cast a datetime value to date value.",
        "Return the SQL to cast a datetime"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a \"",
        "\"subclasses of BaseDatabaseOperations may"
    ],
    [
        "Return the SQL to cast a datetime value to time value.",
        "Return the SQL to cast a datetime value to"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a \"",
        "\"subclasses of BaseDatabaseOperations may"
    ],
    [
        "def datetime_extract_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_extract_sql(self, lookup_type,"
    ],
    [
        "Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or",
        "Given a lookup_type of 'year', 'month',"
    ],
    [
        "'second', return the SQL that extracts a value from the given",
        "'second', return the SQL that extracts a value from"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a datetime_extract_sql() \"",
        "\"subclasses of BaseDatabaseOperations may require a datetime_extract_sql()"
    ],
    [
        "def datetime_trunc_sql(self, lookup_type, sql, params, tzname):",
        "def datetime_trunc_sql(self, lookup_type, sql, params,"
    ],
    [
        "Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or",
        "Given a lookup_type of 'year',"
    ],
    [
        "'second', return the SQL that truncates the given datetime field",
        "'second', return the SQL that truncates the given"
    ],
    [
        "field_name to a datetime object with only the given specificity.",
        "field_name to a datetime object with only"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a datetime_trunc_sql() \"",
        "\"subclasses of BaseDatabaseOperations may require"
    ],
    [
        "def time_trunc_sql(self, lookup_type, sql, params, tzname=None):",
        "def time_trunc_sql(self, lookup_type,"
    ],
    [
        "Given a lookup_type of 'hour', 'minute' or 'second', return the SQL",
        "Given a lookup_type of 'hour', 'minute' or 'second', return the"
    ],
    [
        "that truncates the given time or datetime field field_name to a time",
        "that truncates the given time or datetime field field_name"
    ],
    [
        "object with only the given specificity.",
        "object with only the"
    ],
    [
        "If `tzname` is provided, the given value is truncated in a specific",
        "If `tzname` is provided, the given value is truncated"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a time_trunc_sql() method\"",
        "\"subclasses of BaseDatabaseOperations may require a"
    ],
    [
        "Given a lookup_type of 'hour', 'minute', or 'second', return the SQL",
        "Given a lookup_type of 'hour', 'minute', or"
    ],
    [
        "that extracts a value from the given time field field_name.",
        "that extracts a value from the"
    ],
    [
        "Return the SQL to make a constraint \"initially deferred\" during a",
        "Return the SQL to make a constraint \"initially deferred\""
    ],
    [
        "Return an SQL DISTINCT clause which removes duplicate rows from the",
        "Return an SQL DISTINCT clause which removes duplicate rows from"
    ],
    [
        "result set. If any fields are given, only check the given fields for",
        "result set. If any fields are given, only check the given fields"
    ],
    [
        "\"DISTINCT ON fields is not supported by this database backend\"",
        "\"DISTINCT ON fields is not supported by this"
    ],
    [
        "Given a cursor object that has just performed an INSERT...RETURNING",
        "Given a cursor object that has"
    ],
    [
        "statement into a table, return the newly created data.",
        "statement into a table, return"
    ],
    [
        "Return a GROUP BY clause to use with a HAVING clause when no grouping",
        "Return a GROUP BY clause to use with a HAVING"
    ],
    [
        "Return a list used in the \"ORDER BY\" clause to force no ordering at",
        "Return a list used in the \"ORDER BY\" clause"
    ],
    [
        "all. Return an empty list to include nothing in the ordering.",
        "all. Return an empty list to"
    ],
    [
        "def for_update_sql(self, nowait=False, skip_locked=False, of=(), no_key=False):",
        "def for_update_sql(self, nowait=False,"
    ],
    [
        "Return the FOR UPDATE SQL clause to lock rows for an update operation.",
        "Return the FOR UPDATE SQL clause to lock rows for"
    ],
    [
        "\" NO KEY\" if no_key else \"\",",
        "\" NO KEY\" if"
    ],
    [
        "\" OF %s\" % \", \".join(of) if of else \"\",",
        "\" OF %s\" % \", \".join(of) if of"
    ],
    [
        "\" NOWAIT\" if nowait else \"\",",
        "\" NOWAIT\" if nowait"
    ],
    [
        "\" SKIP LOCKED\" if skip_locked else \"\",",
        "\" SKIP LOCKED\" if skip_locked"
    ],
    [
        "(\"LIMIT %d\" % limit) if limit else None,",
        "(\"LIMIT %d\" % limit) if"
    ],
    [
        "(\"OFFSET %d\" % offset) if offset else None,",
        "(\"OFFSET %d\" % offset) if offset else"
    ],
    [
        "placeholder_rows_sql = (\", \".join(row) for row in placeholder_rows)",
        "placeholder_rows_sql = (\", \".join(row) for row in"
    ],
    [
        "values_sql = \", \".join([f\"({sql})\" for sql in placeholder_rows_sql])",
        "values_sql = \", \".join([f\"({sql})\" for"
    ],
    [
        "Return a string of the query last executed by the given cursor, with",
        "Return a string of the query last executed"
    ],
    [
        "`sql` is the raw query containing placeholders and `params` is the",
        "`sql` is the raw query containing placeholders and"
    ],
    [
        "sequence of parameters. These are used by default, but this method",
        "sequence of parameters. These are used by default,"
    ],
    [
        "exists for database backends to provide a better implementation",
        "exists for database backends to"
    ],
    [
        "according to their own quoting schemes.",
        "according to their own"
    ],
    [
        "u_params = tuple(to_string(val) for val in params)",
        "u_params = tuple(to_string(val) for"
    ],
    [
        "u_params = {to_string(k): to_string(v) for k, v in params.items()}",
        "u_params = {to_string(k): to_string(v) for k, v in"
    ],
    [
        "return \"QUERY = %r - PARAMS = %r\" % (sql, u_params)",
        "return \"QUERY = %r - PARAMS = %r\""
    ],
    [
        "Given a cursor object that has just performed an INSERT statement into",
        "Given a cursor object that has"
    ],
    [
        "a table that has an auto-incrementing ID, return the newly created ID.",
        "a table that has an auto-incrementing ID, return the newly created"
    ],
    [
        "`pk_name` is the name of the primary-key column.",
        "`pk_name` is the name of the"
    ],
    [
        "Return the string to use in a query when performing lookups",
        "Return the string to use in a query"
    ],
    [
        "(\"contains\", \"like\", etc.). It should contain a '%s' placeholder for",
        "(\"contains\", \"like\", etc.). It should contain a '%s' placeholder"
    ],
    [
        "Return the maximum number of items that can be passed in a single 'IN'",
        "Return the maximum number of items that can be passed"
    ],
    [
        "list condition, or None if the backend does not impose a limit.",
        "list condition, or None if the"
    ],
    [
        "Return the maximum length of table and column names, or None if there",
        "Return the maximum length of table and column names, or"
    ],
    [
        "Return the value to use for the LIMIT when we are wanting \"LIMIT",
        "Return the value to use for the LIMIT when we"
    ],
    [
        "infinity\". Return None if the limit clause can be omitted in this case.",
        "infinity\". Return None if the limit clause"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a no_limit_value() method\"",
        "\"subclasses of BaseDatabaseOperations may require"
    ],
    [
        "Return the value to use during an INSERT statement to specify that",
        "Return the value to use during an INSERT statement to specify"
    ],
    [
        "the field should use its default value.",
        "the field should use"
    ],
    [
        "Take an SQL script that may contain multiple lines and return a list",
        "Take an SQL script that may contain multiple"
    ],
    [
        "of statements to feed to successive cursor.execute() calls.",
        "of statements to feed to successive cursor.execute()"
    ],
    [
        "Since few databases are able to process raw SQL scripts in a single",
        "Since few databases are able to process"
    ],
    [
        "Return the value of a CLOB column, for backends that return a locator",
        "Return the value of a CLOB column, for backends that return"
    ],
    [
        "For backends that support returning columns as part of an insert query,",
        "For backends that support returning columns as part"
    ],
    [
        "return the SQL and params to append to the INSERT query. The returned",
        "return the SQL and params to append to the"
    ],
    [
        "fragment should contain a format string to hold the appropriate column.",
        "fragment should contain a format string to"
    ],
    [
        "Return the SQLCompiler class corresponding to the given name,",
        "Return the SQLCompiler class corresponding to the given"
    ],
    [
        "in the namespace corresponding to the `compiler_module` attribute",
        "in the namespace corresponding to the `compiler_module`"
    ],
    [
        "Return a quoted version of the given table, index, or column name. Do",
        "Return a quoted version of the given table, index, or"
    ],
    [
        "not quote the given name if it's already been quoted.",
        "not quote the given name"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a quote_name() method\"",
        "\"subclasses of BaseDatabaseOperations may"
    ],
    [
        "Return the string to use in a query when performing regular expression",
        "Return the string to use in a query when performing"
    ],
    [
        "lookups (using \"regex\" or \"iregex\"). It should contain a '%s'",
        "lookups (using \"regex\" or \"iregex\"). It should contain"
    ],
    [
        "placeholder for the column being searched against.",
        "placeholder for the column"
    ],
    [
        "If the feature is not supported (or part of it is not supported), raise",
        "If the feature is not supported (or part of"
    ],
    [
        "\"subclasses of BaseDatabaseOperations may require a regex_lookup() method\"",
        "\"subclasses of BaseDatabaseOperations may"
    ],
    [
        "Return the SQL for starting a new savepoint. Only required if the",
        "Return the SQL for starting a new savepoint. Only required if"
    ],
    [
        "\"uses_savepoints\" feature is True. The \"sid\" parameter is a string",
        "\"uses_savepoints\" feature is True. The \"sid\" parameter is a"
    ],
    [
        "Return the SQL for committing the given savepoint.",
        "Return the SQL for"
    ],
    [
        "return \"RELEASE SAVEPOINT %s\" % self.quote_name(sid)",
        "return \"RELEASE SAVEPOINT"
    ],
    [
        "Return the SQL for rolling back the given savepoint.",
        "Return the SQL for rolling back the"
    ],
    [
        "return \"ROLLBACK TO SAVEPOINT %s\" % self.quote_name(sid)",
        "return \"ROLLBACK TO SAVEPOINT %s\""
    ],
    [
        "Return the SQL that will set the connection's time zone.",
        "Return the SQL that will"
    ],
    [
        "Return '' if the backend doesn't support time zones.",
        "Return '' if the backend doesn't support"
    ],
    [
        "def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
        "def sql_flush(self, style, tables, *,"
    ],
    [
        "Return a list of SQL statements required to remove all data from",
        "Return a list of SQL statements required to remove all data"
    ],
    [
        "the given database tables (without actually removing the tables",
        "the given database tables (without actually removing"
    ],
    [
        "The `style` argument is a Style object as returned by either",
        "The `style` argument is a Style"
    ],
    [
        "If `reset_sequences` is True, the list includes SQL statements required",
        "If `reset_sequences` is True, the list includes"
    ],
    [
        "The `allow_cascade` argument determines whether truncation may cascade",
        "The `allow_cascade` argument determines"
    ],
    [
        "to tables with foreign keys pointing the tables being truncated.",
        "to tables with foreign keys pointing the tables being"
    ],
    [
        "PostgreSQL requires a cascade even if these tables are empty.",
        "PostgreSQL requires a cascade even if these"
    ],
    [
        "\"subclasses of BaseDatabaseOperations must provide an sql_flush() method\"",
        "\"subclasses of BaseDatabaseOperations must provide an sql_flush()"
    ],
    [
        "\"\"\"Execute a list of SQL statements to flush the database.\"\"\"",
        "\"\"\"Execute a list of SQL statements to"
    ],
    [
        "Return a list of the SQL statements required to reset sequences",
        "Return a list of the SQL statements required to reset"
    ],
    [
        "The `style` argument is a Style object as returned by either",
        "The `style` argument is a Style object as returned"
    ],
    [
        "Return a list of the SQL statements required to reset sequences for",
        "Return a list of the SQL statements"
    ],
    [
        "The `style` argument is a Style object as returned by either",
        "The `style` argument is a Style object as returned"
    ],
    [
        "\"\"\"Return the SQL statement required to start a transaction.\"\"\"",
        "\"\"\"Return the SQL statement required to start a"
    ],
    [
        "\"\"\"Return the SQL statement required to end a transaction.\"\"\"",
        "\"\"\"Return the SQL statement required to end a"
    ],
    [
        "Return the SQL that will be used in a query to define the tablespace.",
        "Return the SQL that will be used in"
    ],
    [
        "Return '' if the backend doesn't support tablespaces.",
        "Return '' if the backend doesn't support"
    ],
    [
        "If `inline` is True, append the SQL to a row; otherwise append it to",
        "If `inline` is True, append the SQL to a row;"
    ],
    [
        "the entire CREATE TABLE or CREATE INDEX statement.",
        "the entire CREATE TABLE or"
    ],
    [
        "\"\"\"Prepare a value for use in a LIKE query.\"\"\"",
        "\"\"\"Prepare a value for use in a"
    ],
    [
        "Certain backends do not accept some values for \"serial\" fields",
        "Certain backends do not accept"
    ],
    [
        "(for example zero in MySQL). Raise a ValueError if the value is",
        "(for example zero in MySQL). Raise a ValueError if"
    ],
    [
        "invalid, otherwise return the validated value.",
        "invalid, otherwise return the"
    ],
    [
        "Transform a value to something compatible with the backend driver.",
        "Transform a value to something compatible with"
    ],
    [
        "This method only depends on the type of the value. It's designed for",
        "This method only depends on the type of the value."
    ],
    [
        "cases where the target type isn't known, such as .raw() SQL queries.",
        "cases where the target type isn't"
    ],
    [
        "As a consequence it may not work perfectly in all circumstances.",
        "As a consequence it may not"
    ],
    [
        "Transform a date value to an object compatible with what is expected",
        "Transform a date value to an object compatible with"
    ],
    [
        "by the backend driver for date columns.",
        "by the backend driver"
    ],
    [
        "Transform a datetime value to an object compatible with what is expected",
        "Transform a datetime value to an object compatible with"
    ],
    [
        "by the backend driver for datetime columns.",
        "by the backend driver"
    ],
    [
        "Transform a time value to an object compatible with what is expected",
        "Transform a time value to an object"
    ],
    [
        "by the backend driver for time columns.",
        "by the backend driver"
    ],
    [
        "raise ValueError(\"Django does not support timezone-aware times.\")",
        "raise ValueError(\"Django does not support timezone-aware"
    ],
    [
        "Transform a decimal.Decimal value to an object compatible with what is",
        "Transform a decimal.Decimal value to an object"
    ],
    [
        "expected by the backend driver for decimal (numeric) columns.",
        "expected by the backend driver for decimal (numeric)"
    ],
    [
        "Transform a string representation of an IP address into the expected",
        "Transform a string representation of an IP"
    ],
    [
        "Return a two-elements list with the lower and upper bound to be used",
        "Return a two-elements list with the lower and upper bound to be"
    ],
    [
        "with a BETWEEN operator to query a DateField value using a year",
        "with a BETWEEN operator to query a"
    ],
    [
        "`value` is an int, containing the looked-up year.",
        "`value` is an int, containing"
    ],
    [
        "Return a two-elements list with the lower and upper bound to be used",
        "Return a two-elements list with the lower and"
    ],
    [
        "with a BETWEEN operator to query a DateTimeField value using a year",
        "with a BETWEEN operator to query a DateTimeField value"
    ],
    [
        "`value` is an int, containing the looked-up year.",
        "`value` is an int, containing the"
    ],
    [
        "Return a list of functions needed to convert field data.",
        "Return a list of functions needed"
    ],
    [
        "Some field types on some backends do not provide data in the correct",
        "Some field types on some backends do not provide data"
    ],
    [
        "format, this is the hook for converter functions.",
        "format, this is the hook"
    ],
    [
        "Check that the backend supports the provided expression.",
        "Check that the backend supports"
    ],
    [
        "This is used on specific backends to rule out known expressions",
        "This is used on specific backends to rule"
    ],
    [
        "that have problematic or nonexistent implementations. If the",
        "that have problematic or nonexistent implementations. If"
    ],
    [
        "expression has a known problem, the backend should raise",
        "expression has a known problem, the backend"
    ],
    [
        "Return True, if the conditional expression is supported in the WHERE",
        "Return True, if the conditional expression is"
    ],
    [
        "Combine a list of subexpressions into a single expression, using",
        "Combine a list of subexpressions into a single expression,"
    ],
    [
        "the provided connecting operator. This is required because operators",
        "the provided connecting operator. This is required because"
    ],
    [
        "can vary between backends (e.g., Oracle with %% and &) and between",
        "can vary between backends (e.g., Oracle with"
    ],
    [
        "conn = \" %s \" % connector",
        "conn = \" %s \" %"
    ],
    [
        "Some backends require special syntax to insert binary content (MySQL",
        "Some backends require special syntax"
    ],
    [
        "Allow modification of insert parameters. Needed for Oracle Spatial",
        "Allow modification of insert parameters. Needed for"
    ],
    [
        "Given an integer field internal type (e.g. 'PositiveIntegerField'),",
        "Given an integer field internal"
    ],
    [
        "return a tuple of the (min_value, max_value) form representing the",
        "return a tuple of the (min_value, max_value)"
    ],
    [
        "range of the column type bound to the field.",
        "range of the column type bound to the"
    ],
    [
        "return \"(%s - %s)\" % (lhs_sql, rhs_sql), (*lhs_params, *rhs_params)",
        "return \"(%s - %s)\" %"
    ],
    [
        "\"This backend does not support %s subtraction.\" % internal_type",
        "\"This backend does not support"
    ],
    [
        "return \"%d %s\" % (abs(value), self.PRECEDING)",
        "return \"%d %s\""
    ],
    [
        "return \"%d %s\" % (value, self.FOLLOWING)",
        "return \"%d %s\""
    ],
    [
        "Return SQL for start and end points in an OVER clause window frame.",
        "Return SQL for start and end points in"
    ],
    [
        "if isinstance(start, int) and isinstance(end, int) and start > end:",
        "if isinstance(start, int) and isinstance(end, int) and"
    ],
    [
        "raise ValueError(\"start cannot be greater than end.\")",
        "raise ValueError(\"start cannot be"
    ],
    [
        "if start is not None and not isinstance(start, int):",
        "if start is not None and"
    ],
    [
        "f\"start argument must be an integer, zero, or None, but got '{start}'.\"",
        "f\"start argument must be an integer, zero, or"
    ],
    [
        "if end is not None and not isinstance(end, int):",
        "if end is not None and"
    ],
    [
        "f\"end argument must be an integer, zero, or None, but got '{end}'.\"",
        "f\"end argument must be an integer, zero, or None, but got"
    ],
    [
        "if (start is not None and not isinstance(start, int)) or (",
        "if (start is not None and not"
    ],
    [
        "\"start argument must be a negative integer, zero, or None, \"",
        "\"start argument must be a negative integer, zero, or"
    ],
    [
        "if (end is not None and not isinstance(end, int)) or (",
        "if (end is not None and not isinstance(end, int))"
    ],
    [
        "\"end argument must be a positive integer, zero, or None, but got '%s'.\"",
        "\"end argument must be a positive integer,"
    ],
    [
        "\"%s only supports UNBOUNDED together with PRECEDING and \"",
        "\"%s only supports UNBOUNDED together with PRECEDING"
    ],
    [
        "\"This backend does not support explaining query execution.\"",
        "\"This backend does not support explaining query"
    ],
    [
        "msg = \"%s is not a recognized format.\" % normalized_format",
        "msg = \"%s is not"
    ],
    [
        "msg += \" Allowed formats: %s\" % \", \".join(sorted(supported_formats))",
        "msg += \" Allowed formats: %s\" % \","
    ],
    [
        "f\" {self.connection.display_name} does not support any formats.\"",
        "f\" {self.connection.display_name} does not support"
    ],
    [
        "raise ValueError(\"Unknown options: %s\" % \", \".join(sorted(options.keys())))",
        "raise ValueError(\"Unknown options: %s\" %"
    ],
    [
        "def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):",
        "def on_conflict_suffix_sql(self, fields,"
    ],
    [
        "def prepare_join_on_clause(self, lhs_table, lhs_field, rhs_table, rhs_field):",
        "def prepare_join_on_clause(self, lhs_table, lhs_field,"
    ],
    [
        "\"name type_code display_size internal_size precision scale null_ok \"",
        "\"name type_code display_size internal_size precision scale"
    ],
    [
        "Hook for a database backend to use the cursor description to",
        "Hook for a database backend to use"
    ],
    [
        "match a Django field type to a database column.",
        "match a Django field type"
    ],
    [
        "For Oracle, the column data_type on its own is insufficient to",
        "For Oracle, the column data_type on its"
    ],
    [
        "distinguish between a FloatField and IntegerField, for example.",
        "distinguish between a FloatField and IntegerField, for"
    ],
    [
        "Apply a conversion to the identifier for the purposes of comparison.",
        "Apply a conversion to the identifier"
    ],
    [
        "The default identifier converter is for case sensitive comparison.",
        "The default identifier converter is for case"
    ],
    [
        "Return a list of names of all tables that exist in the database.",
        "Return a list of names of all tables that exist in the"
    ],
    [
        "Sort the returned table list by Python's default sorting. Do NOT use",
        "Sort the returned table list by Python's default sorting. Do NOT"
    ],
    [
        "the database's ORDER BY here to avoid subtle differences in sorting",
        "the database's ORDER BY here to"
    ],
    [
        "if include_views or ti.type == \"t\"",
        "if include_views or ti.type =="
    ],
    [
        "Return an unsorted list of TableInfo named tuples of all tables and",
        "Return an unsorted list of TableInfo named tuples of all"
    ],
    [
        "views that exist in the database.",
        "views that exist in the"
    ],
    [
        "\"subclasses of BaseDatabaseIntrospection may require a get_table_list() \"",
        "\"subclasses of BaseDatabaseIntrospection may require a"
    ],
    [
        "Return a description of the table with the DB-API cursor.description",
        "Return a description of the table"
    ],
    [
        "\"subclasses of BaseDatabaseIntrospection may require a \"",
        "\"subclasses of BaseDatabaseIntrospection may"
    ],
    [
        "Return a list of all table names that have associated Django models and",
        "Return a list of all table names that"
    ],
    [
        "If only_existing is True, include only the tables in the database.",
        "If only_existing is True, include only the tables in the"
    ],
    [
        "t for t in tables if self.identifier_converter(t) in existing_tables",
        "t for t in tables if self.identifier_converter(t) in"
    ],
    [
        "Return a set of all models represented by the provided list of table",
        "Return a set of all models represented by the provided list"
    ],
    [
        "Return a list of information about all DB sequences for all models in",
        "Return a list of information about all DB sequences for"
    ],
    [
        "Return a list of introspected sequences for table_name. Each sequence",
        "Return a list of introspected"
    ],
    [
        "is a dict: {'table': <table_name>, 'column': <column_name>}. An optional",
        "is a dict: {'table': <table_name>, 'column': <column_name>}. An"
    ],
    [
        "'name' key can be added if the backend supports named sequences.",
        "'name' key can be added if the"
    ],
    [
        "\"subclasses of BaseDatabaseIntrospection may require a get_sequences() \"",
        "\"subclasses of BaseDatabaseIntrospection may"
    ],
    [
        "Return a dictionary of {field_name: (field_name_other_table, other_table)}",
        "Return a dictionary of {field_name:"
    ],
    [
        "representing all foreign keys in the given table.",
        "representing all foreign keys in the"
    ],
    [
        "\"subclasses of BaseDatabaseIntrospection may require a \"",
        "\"subclasses of BaseDatabaseIntrospection may"
    ],
    [
        "Return the name of the primary key column for the given table.",
        "Return the name of the primary key column for the given"
    ],
    [
        "\"\"\"Return a list of primary key columns for the given table.\"\"\"",
        "\"\"\"Return a list of primary key columns for the"
    ],
    [
        "Retrieve any constraints or keys (unique, pk, fk, check, index)",
        "Retrieve any constraints or keys (unique, pk, fk,"
    ],
    [
        "Return a dict mapping constraint names to their attributes,",
        "Return a dict mapping constraint names"
    ],
    [
        "where attributes is a dict with keys:",
        "where attributes is a"
    ],
    [
        "* columns: List of columns this covers",
        "* columns: List of columns this"
    ],
    [
        "* primary_key: True if primary key, False otherwise",
        "* primary_key: True if"
    ],
    [
        "* unique: True if this is a unique constraint, False otherwise",
        "* unique: True if this is a unique constraint,"
    ],
    [
        "* foreign_key: (table, column) of target, or None",
        "* foreign_key: (table, column) of target, or"
    ],
    [
        "* check: True if check constraint, False otherwise",
        "* check: True if check constraint, False"
    ],
    [
        "* index: True if index, False otherwise.",
        "* index: True if"
    ],
    [
        "* orders: The order (ASC/DESC) defined for the columns of indexes",
        "* orders: The order (ASC/DESC) defined for the"
    ],
    [
        "* type: The type of the index (btree, hash, etc.)",
        "* type: The type of the index"
    ],
    [
        "Some backends may return special constraint names that don't exist",
        "Some backends may return special constraint names that don't"
    ],
    [
        "if they don't name constraints of a certain type (e.g. SQLite)",
        "if they don't name constraints of"
    ],
    [
        "\"subclasses of BaseDatabaseIntrospection may require a get_constraints() \"",
        "\"subclasses of BaseDatabaseIntrospection may require a"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, DatabaseError, NotSupportedError",
        "from django.db import"
    ],
    [
        "Ensure the connection's timezone is set to `self.timezone_name` and",
        "Ensure the connection's timezone is set to `self.timezone_name`"
    ],
    [
        "return whether it changed or not.",
        "return whether it changed"
    ],
    [
        "Return a tzinfo of the database connection time zone.",
        "Return a tzinfo of the database connection"
    ],
    [
        "This is only used when time zone support is enabled. When a datetime is",
        "This is only used when time zone support is enabled. When a"
    ],
    [
        "read from the database, it is always returned in this time zone.",
        "read from the database, it is"
    ],
    [
        "When the database backend supports time zones, it doesn't matter which",
        "When the database backend supports time zones, it"
    ],
    [
        "time zone Django uses, as long as aware datetimes are used everywhere.",
        "time zone Django uses, as long as"
    ],
    [
        "Other users connecting to the database can choose their own time zone.",
        "Other users connecting to the database can choose their own time"
    ],
    [
        "When the database backend doesn't support time zones, the time zone",
        "When the database backend doesn't support time zones, the time"
    ],
    [
        "Django uses may be constrained by the requirements of other users of",
        "Django uses may be constrained by"
    ],
    [
        "Name of the time zone of the database connection.",
        "Name of the time zone of the"
    ],
    [
        "\"Limit for query logging exceeded, only the last {} queries \"",
        "\"Limit for query logging exceeded, only the"
    ],
    [
        "\"\"\"Return a tuple of the database's version.\"\"\"",
        "\"\"\"Return a tuple of"
    ],
    [
        "\"subclasses of BaseDatabaseWrapper may require a get_database_version() \"",
        "\"subclasses of BaseDatabaseWrapper may require a get_database_version()"
    ],
    [
        "Raise an error if the database version isn't supported by this",
        "Raise an error if the database version isn't"
    ],
    [
        "f\"{self.display_name} {min_db_version} or later is required \"",
        "f\"{self.display_name} {min_db_version} or later"
    ],
    [
        "\"\"\"Return a dict of parameters suitable for get_new_connection.\"\"\"",
        "\"\"\"Return a dict of parameters suitable for"
    ],
    [
        "\"subclasses of BaseDatabaseWrapper may require a get_connection_params() \"",
        "\"subclasses of BaseDatabaseWrapper may require"
    ],
    [
        "\"\"\"Open a connection to the database.\"\"\"",
        "\"\"\"Open a connection to the"
    ],
    [
        "\"subclasses of BaseDatabaseWrapper may require a get_new_connection() \"",
        "\"subclasses of BaseDatabaseWrapper may require"
    ],
    [
        "\"\"\"Create a cursor. Assume that a connection is established.\"\"\"",
        "\"\"\"Create a cursor. Assume that"
    ],
    [
        "\"subclasses of BaseDatabaseWrapper may require a create_cursor() method\"",
        "\"subclasses of BaseDatabaseWrapper may require"
    ],
    [
        "\"\"\"Connect to the database. Assume that the connection is closed.\"\"\"",
        "\"\"\"Connect to the database. Assume that the"
    ],
    [
        "self.close_at = None if max_age is None else time.monotonic() + max_age",
        "self.close_at = None if max_age is"
    ],
    [
        "if self.settings_dict[\"TIME_ZONE\"] is not None and not settings.USE_TZ:",
        "if self.settings_dict[\"TIME_ZONE\"] is not"
    ],
    [
        "\"Connection '%s' cannot set TIME_ZONE because USE_TZ is False.\"",
        "\"Connection '%s' cannot set TIME_ZONE because USE_TZ is"
    ],
    [
        "\"\"\"Guarantee that a connection to the database is established.\"\"\"",
        "\"\"\"Guarantee that a connection to the"
    ],
    [
        "\"Cannot open a new connection in an atomic block.\"",
        "\"Cannot open a new connection in an atomic"
    ],
    [
        "Validate the connection is usable and perform database cursor wrapping.",
        "Validate the connection is usable"
    ],
    [
        "\"\"\"Create a cursor, opening a connection if necessary.\"\"\"",
        "\"\"\"Create a cursor, opening a"
    ],
    [
        "\"\"\"Commit a transaction and reset the dirty flag.\"\"\"",
        "\"\"\"Commit a transaction and reset the dirty"
    ],
    [
        "\"\"\"Roll back a transaction and reset the dirty flag.\"\"\"",
        "\"\"\"Roll back a transaction and reset"
    ],
    [
        "\"\"\"Close the connection to the database.\"\"\"",
        "\"\"\"Close the connection"
    ],
    [
        "if self.closed_in_transaction or self.connection is None:",
        "if self.closed_in_transaction or self.connection is"
    ],
    [
        "Create a savepoint inside the current transaction. Return an",
        "Create a savepoint inside the current transaction. Return"
    ],
    [
        "identifier for the savepoint that will be used for the subsequent",
        "identifier for the savepoint that will be used"
    ],
    [
        "rollback or commit. Do nothing if savepoints are not supported.",
        "rollback or commit. Do nothing if savepoints are not"
    ],
    [
        "sid = \"s%s_x%d\" % (tid, self.savepoint_state)",
        "sid = \"s%s_x%d\" %"
    ],
    [
        "Roll back to a savepoint. Do nothing if savepoints are not supported.",
        "Roll back to a savepoint. Do nothing if savepoints are not"
    ],
    [
        "for (sids, func, robust) in self.run_on_commit",
        "for (sids, func, robust) in"
    ],
    [
        "Release a savepoint. Do nothing if savepoints are not supported.",
        "Release a savepoint. Do nothing"
    ],
    [
        "Reset the counter used to generate unique savepoint ids in this thread.",
        "Reset the counter used to generate unique savepoint ids in"
    ],
    [
        "Backend-specific implementation to enable or disable autocommit.",
        "Backend-specific implementation to enable or disable"
    ],
    [
        "\"subclasses of BaseDatabaseWrapper may require a _set_autocommit() method\"",
        "\"subclasses of BaseDatabaseWrapper may require a _set_autocommit()"
    ],
    [
        "The usual way to start a transaction is to turn autocommit off.",
        "The usual way to start a"
    ],
    [
        "SQLite does not properly start a transaction when disabling",
        "SQLite does not properly start a transaction"
    ],
    [
        "autocommit. To avoid this buggy behavior and to actually enter a new",
        "autocommit. To avoid this buggy behavior"
    ],
    [
        "transaction, an explicit BEGIN is required. Using",
        "transaction, an explicit BEGIN is required."
    ],
    [
        "explicit BEGIN with SQLite. This option will be ignored for other",
        "explicit BEGIN with SQLite. This option will"
    ],
    [
        "\"\"\"Get the \"needs rollback\" flag -- for *advanced use* only.\"\"\"",
        "\"\"\"Get the \"needs rollback\" flag -- for *advanced"
    ],
    [
        "\"The rollback flag doesn't work outside of an 'atomic' block.\"",
        "\"The rollback flag doesn't work"
    ],
    [
        "Set or unset the \"needs rollback\" flag -- for *advanced use* only.",
        "Set or unset the \"needs rollback\""
    ],
    [
        "\"The rollback flag doesn't work outside of an 'atomic' block.\"",
        "\"The rollback flag doesn't work outside of an 'atomic'"
    ],
    [
        "\"\"\"Raise an error if an atomic block is active.\"\"\"",
        "\"\"\"Raise an error if an atomic block"
    ],
    [
        "\"This is forbidden when an 'atomic' block is active.\"",
        "\"This is forbidden when an 'atomic'"
    ],
    [
        "\"An error occurred in the current transaction. You can't \"",
        "\"An error occurred in the current transaction."
    ],
    [
        "\"execute queries until the end of the 'atomic' block.\"",
        "\"execute queries until the end"
    ],
    [
        "Backends can implement as needed to temporarily disable foreign key",
        "Backends can implement as needed to temporarily disable"
    ],
    [
        "constraint checking. Should return True if the constraints were",
        "constraint checking. Should return True if the constraints"
    ],
    [
        "disabled and will need to be reenabled.",
        "disabled and will need"
    ],
    [
        "Backends can implement as needed to re-enable foreign key constraint",
        "Backends can implement as needed"
    ],
    [
        "Backends can override this method if they can apply constraint",
        "Backends can override this method"
    ],
    [
        "checking (e.g. via \"SET CONSTRAINTS ALL IMMEDIATE\"). Should raise an",
        "checking (e.g. via \"SET CONSTRAINTS"
    ],
    [
        "IntegrityError if any invalid foreign key references are encountered.",
        "IntegrityError if any invalid foreign key"
    ],
    [
        "Test if the database connection is usable.",
        "Test if the database connection"
    ],
    [
        "This method may assume that self.connection is not None.",
        "This method may assume that"
    ],
    [
        "Actual implementations should take care not to raise exceptions",
        "Actual implementations should take care not to raise"
    ],
    [
        "as that may prevent Django from recycling unusable connections.",
        "as that may prevent Django"
    ],
    [
        "\"subclasses of BaseDatabaseWrapper may require an is_usable() method\"",
        "\"subclasses of BaseDatabaseWrapper may require"
    ],
    [
        "\"\"\"Close existing connection if it fails a health check.\"\"\"",
        "\"\"\"Close existing connection if it fails a health"
    ],
    [
        "Close the current connection if unrecoverable errors have occurred",
        "Close the current connection if unrecoverable errors have"
    ],
    [
        "or if it outlived its maximum age.",
        "or if it outlived its"
    ],
    [
        "if self.close_at is not None and time.monotonic() >= self.close_at:",
        "if self.close_at is not None and time.monotonic()"
    ],
    [
        "\"Cannot decrement the thread sharing count below zero.\"",
        "\"Cannot decrement the thread sharing count below"
    ],
    [
        "Validate that the connection isn't accessed by another thread than the",
        "Validate that the connection isn't accessed by another"
    ],
    [
        "one which originally created it, unless the connection was explicitly",
        "one which originally created it, unless"
    ],
    [
        "authorized to be shared between threads (via the `inc_thread_sharing()`",
        "authorized to be shared between"
    ],
    [
        "method). Raise an exception if the validation fails.",
        "method). Raise an exception"
    ],
    [
        "if not (self.allow_thread_sharing or self._thread_ident == _thread.get_ident()):",
        "if not (self.allow_thread_sharing or self._thread_ident =="
    ],
    [
        "\"DatabaseWrapper objects created in a \"",
        "\"DatabaseWrapper objects created in a"
    ],
    [
        "\"thread can only be used in that same thread. The object \"",
        "\"thread can only be used in that same thread. The object"
    ],
    [
        "\"with alias '%s' was created in thread id %s and this is \"",
        "\"with alias '%s' was created in thread"
    ],
    [
        "\"thread id %s.\" % (self.alias, self._thread_ident, _thread.get_ident())",
        "\"thread id %s.\" %"
    ],
    [
        "Hook to do any database check or preparation, generally called before",
        "Hook to do any database check"
    ],
    [
        "migrating a project or an app.",
        "migrating a project or"
    ],
    [
        "Context manager and decorator that re-throws backend-specific database",
        "Context manager and decorator that re-throws"
    ],
    [
        "Return a cursor that tries to avoid caching in the database (if",
        "Return a cursor that tries to avoid caching"
    ],
    [
        "supported by the database), otherwise return a regular cursor.",
        "supported by the database), otherwise return"
    ],
    [
        "\"\"\"Create a cursor that logs all queries in self.queries_log.\"\"\"",
        "\"\"\"Create a cursor that logs"
    ],
    [
        "\"\"\"Create a cursor without debug logging.\"\"\"",
        "\"\"\"Create a cursor without"
    ],
    [
        "Context manager that ensures that a connection is established, and",
        "Context manager that ensures that a connection is established,"
    ],
    [
        "if it opened one, closes it to avoid leaving a dangling connection.",
        "if it opened one, closes it to avoid leaving a"
    ],
    [
        "This is useful for operations outside of the request-response cycle.",
        "This is useful for operations outside of the request-response"
    ],
    [
        "Provide a cursor: with self.temporary_connection() as cursor: ...",
        "Provide a cursor: with self.temporary_connection() as cursor:"
    ],
    [
        "Return a cursor from an alternative connection to be used when there is",
        "Return a cursor from an alternative connection to be used"
    ],
    [
        "no need to access the main database, specifically for test db",
        "no need to access the main database,"
    ],
    [
        "creation/deletion. This also prevents the production database from",
        "creation/deletion. This also prevents"
    ],
    [
        "being exposed to potential child threads while (or after) the test",
        "being exposed to potential child threads while (or"
    ],
    [
        "conn = self.__class__({**self.settings_dict, \"NAME\": None}, alias=NO_DB_ALIAS)",
        "conn = self.__class__({**self.settings_dict,"
    ],
    [
        "Return a new instance of this backend's SchemaEditor.",
        "Return a new instance of this backend's"
    ],
    [
        "\"The SchemaEditorClass attribute of this database wrapper is still None\"",
        "\"The SchemaEditorClass attribute of this database wrapper"
    ],
    [
        "raise TypeError(\"on_commit()'s callback must be a callable.\")",
        "raise TypeError(\"on_commit()'s callback must be a"
    ],
    [
        "\"on_commit() cannot be used in manual transaction management\"",
        "\"on_commit() cannot be used in"
    ],
    [
        "f\"Error calling {func.__qualname__} in on_commit() (%s).\",",
        "f\"Error calling {func.__qualname__}"
    ],
    [
        "f\"Error calling {func.__qualname__} in on_commit() during \"",
        "f\"Error calling {func.__qualname__} in on_commit()"
    ],
    [
        "Return a context manager under which the wrapper is applied to suitable",
        "Return a context manager under which the wrapper"
    ],
    [
        "Return a copy of this connection.",
        "Return a copy of this"
    ],
    [
        "For tests that require two connections to the same database.",
        "For tests that require two connections to the"
    ],
    [
        "from django.db.backends.utils import names_digest, split_identifier, truncate_name",
        "from django.db.backends.utils import names_digest,"
    ],
    [
        "When altering the given field, must constraints on its model from the given",
        "When altering the given field, must constraints on"
    ],
    [
        "if altered_field.primary_key and field.to_fields == [None]:",
        "if altered_field.primary_key and"
    ],
    [
        "This class and its subclasses are responsible for emitting schema-changing",
        "This class and its subclasses are responsible"
    ],
    [
        "statements to the databases - model creation/removal/alteration, field",
        "statements to the databases - model creation/removal/alteration,"
    ],
    [
        "renaming, index fiddling, and so on.",
        "renaming, index fiddling, and"
    ],
    [
        "sql_create_table = \"CREATE TABLE %(table)s (%(definition)s)\"",
        "sql_create_table = \"CREATE TABLE %(table)s"
    ],
    [
        "sql_rename_table = \"ALTER TABLE %(old_table)s RENAME TO %(new_table)s\"",
        "sql_rename_table = \"ALTER TABLE"
    ],
    [
        "sql_retablespace_table = \"ALTER TABLE %(table)s SET TABLESPACE %(new_tablespace)s\"",
        "sql_retablespace_table = \"ALTER TABLE"
    ],
    [
        "sql_delete_table = \"DROP TABLE %(table)s CASCADE\"",
        "sql_delete_table = \"DROP TABLE %(table)s"
    ],
    [
        "sql_create_column = \"ALTER TABLE %(table)s ADD COLUMN %(column)s %(definition)s\"",
        "sql_create_column = \"ALTER TABLE %(table)s ADD COLUMN %(column)s"
    ],
    [
        "sql_alter_column = \"ALTER TABLE %(table)s %(changes)s\"",
        "sql_alter_column = \"ALTER TABLE %(table)s"
    ],
    [
        "sql_alter_column_type = \"ALTER COLUMN %(column)s TYPE %(type)s%(collation)s\"",
        "sql_alter_column_type = \"ALTER COLUMN %(column)s TYPE"
    ],
    [
        "sql_alter_column_null = \"ALTER COLUMN %(column)s DROP NOT NULL\"",
        "sql_alter_column_null = \"ALTER COLUMN %(column)s DROP"
    ],
    [
        "sql_alter_column_not_null = \"ALTER COLUMN %(column)s SET NOT NULL\"",
        "sql_alter_column_not_null = \"ALTER COLUMN"
    ],
    [
        "sql_alter_column_default = \"ALTER COLUMN %(column)s SET DEFAULT %(default)s\"",
        "sql_alter_column_default = \"ALTER COLUMN %(column)s SET"
    ],
    [
        "sql_alter_column_no_default = \"ALTER COLUMN %(column)s DROP DEFAULT\"",
        "sql_alter_column_no_default = \"ALTER COLUMN %(column)s DROP"
    ],
    [
        "sql_delete_column = \"ALTER TABLE %(table)s DROP COLUMN %(column)s CASCADE\"",
        "sql_delete_column = \"ALTER TABLE %(table)s DROP"
    ],
    [
        "\"ALTER TABLE %(table)s RENAME COLUMN %(old_column)s TO %(new_column)s\"",
        "\"ALTER TABLE %(table)s RENAME"
    ],
    [
        "\"UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL\"",
        "\"UPDATE %(table)s SET %(column)s ="
    ],
    [
        "sql_delete_constraint = \"ALTER TABLE %(table)s DROP CONSTRAINT %(name)s\"",
        "sql_delete_constraint = \"ALTER TABLE %(table)s"
    ],
    [
        "sql_create_check = \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s CHECK (%(check)s)\"",
        "sql_create_check = \"ALTER TABLE %(table)s ADD"
    ],
    [
        "\"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s \"",
        "\"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s"
    ],
    [
        "\"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) \"",
        "\"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s)"
    ],
    [
        "\"CREATE INDEX %(name)s ON %(table)s \"",
        "\"CREATE INDEX %(name)s"
    ],
    [
        "\"CREATE UNIQUE INDEX %(name)s ON %(table)s \"",
        "\"CREATE UNIQUE INDEX %(name)s"
    ],
    [
        "sql_rename_index = \"ALTER INDEX %(old_name)s RENAME TO %(new_name)s\"",
        "sql_rename_index = \"ALTER INDEX %(old_name)s"
    ],
    [
        "\"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)\"",
        "\"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s"
    ],
    [
        "sql_alter_table_comment = \"COMMENT ON TABLE %(table)s IS %(comment)s\"",
        "sql_alter_table_comment = \"COMMENT ON"
    ],
    [
        "sql_alter_column_comment = \"COMMENT ON COLUMN %(table)s.%(column)s IS %(comment)s\"",
        "sql_alter_column_comment = \"COMMENT ON COLUMN %(table)s.%(column)s"
    ],
    [
        "\"\"\"Execute the given SQL statement, with optional parameters.\"\"\"",
        "\"\"\"Execute the given SQL statement,"
    ],
    [
        "\"Executing DDL statements while in a transaction on databases \"",
        "\"Executing DDL statements while in a transaction on"
    ],
    [
        "\"that can't perform a rollback is prohibited.\"",
        "\"that can't perform a"
    ],
    [
        "\"%s; (params %r)\", sql, params, extra={\"params\": params, \"sql\": sql}",
        "\"%s; (params %r)\", sql, params, extra={\"params\":"
    ],
    [
        "ending = \"\" if sql.rstrip().endswith(\";\") else \";\"",
        "ending = \"\" if sql.rstrip().endswith(\";\")"
    ],
    [
        "(sql % tuple(map(self.quote_value, params))) + ending",
        "(sql % tuple(map(self.quote_value, params))) +"
    ],
    [
        "\"\"\"Take a model and return its table definition.\"\"\"",
        "\"\"\"Take a model and return"
    ],
    [
        "fields = [model._meta.get_field(field) for field in field_names]",
        "fields = [model._meta.get_field(field) for field"
    ],
    [
        "definition += \" \" + self.sql_check_constraint % db_params",
        "definition += \" \" + self.sql_check_constraint"
    ],
    [
        "definition += \" %s\" % col_type_suffix",
        "definition += \" %s\" %"
    ],
    [
        "definition += \" \" + self.sql_create_inline_fk % {",
        "definition += \" \""
    ],
    [
        "sql += \" \" + tablespace_sql",
        "sql += \""
    ],
    [
        "self, column_db_type, params, model, field, field_db_params, include_default",
        "self, column_db_type, params, model, field,"
    ],
    [
        "column_default = \"DEFAULT \" + self._column_default_sql(field)",
        "column_default = \"DEFAULT"
    ],
    [
        "Return the column definition for a field. The field must already have",
        "Return the column definition for a field. The field"
    ],
    [
        "Some backends don't accept default values for certain columns types",
        "Some backends don't accept default values for"
    ],
    [
        "Some backends don't accept default values for certain columns types",
        "Some backends don't accept default values"
    ],
    [
        "(i.e. MySQL longtext and longblob) in the ALTER COLUMN statement.",
        "(i.e. MySQL longtext and longblob) in the"
    ],
    [
        "Only used for backends which have requires_literal_defaults feature",
        "Only used for backends which have requires_literal_defaults"
    ],
    [
        "\"subclasses of BaseDatabaseSchemaEditor for backends which have \"",
        "\"subclasses of BaseDatabaseSchemaEditor for backends which"
    ],
    [
        "\"requires_literal_defaults must provide a prepare_default() method\"",
        "\"requires_literal_defaults must provide"
    ],
    [
        "Return the SQL to use in a DEFAULT clause. The resulting string should",
        "Return the SQL to use in a DEFAULT clause. The resulting"
    ],
    [
        "contain a '%s' placeholder for a default value.",
        "contain a '%s' placeholder for"
    ],
    [
        "\"\"\"Return the sql and params for the field's database default.\"\"\"",
        "\"\"\"Return the sql and params"
    ],
    [
        "self._column_default_sql(field) if isinstance(db_default, Value) else \"(%s)\"",
        "self._column_default_sql(field) if isinstance(db_default, Value) else"
    ],
    [
        "default_sql %= tuple(self.prepare_default(p) for p in params)",
        "default_sql %= tuple(self.prepare_default(p) for"
    ],
    [
        "\"\"\"Return the SQL to use in a GENERATED ALWAYS clause.\"\"\"",
        "\"\"\"Return the SQL to use in a GENERATED"
    ],
    [
        "persistency_sql = \"STORED\" if field.db_persist else \"VIRTUAL\"",
        "persistency_sql = \"STORED\" if field.db_persist"
    ],
    [
        "expression_sql = expression_sql % tuple(self.quote_value(p) for p in params)",
        "expression_sql = expression_sql % tuple(self.quote_value(p) for"
    ],
    [
        "return f\"GENERATED ALWAYS AS ({expression_sql}) {persistency_sql}\", params",
        "return f\"GENERATED ALWAYS AS ({expression_sql}) {persistency_sql}\","
    ],
    [
        "elif not field.null and field.blank and field.empty_strings_allowed:",
        "elif not field.null and"
    ],
    [
        "elif getattr(field, \"auto_now\", False) or getattr(field, \"auto_now_add\", False):",
        "elif getattr(field, \"auto_now\", False) or getattr(field, \"auto_now_add\","
    ],
    [
        "\"\"\"Return a field's effective database default value.\"\"\"",
        "\"\"\"Return a field's effective"
    ],
    [
        "Return a quoted version of the value so it's safe to use in an SQL",
        "Return a quoted version of the value so it's safe to use"
    ],
    [
        "string. This is not safe against injection from user code; it is",
        "string. This is not safe against injection"
    ],
    [
        "intended only for use in making SQL scripts or preparing default values",
        "intended only for use in making SQL scripts or preparing"
    ],
    [
        "for particularly tricky backends (defaults are not user-defined, though,",
        "for particularly tricky backends (defaults are not user-defined,"
    ],
    [
        "Create a table and any accompanying indexes or unique constraints for",
        "Create a table and any accompanying indexes or unique"
    ],
    [
        "\"\"\"Delete a model from the database.\"\"\"",
        "\"\"\"Delete a model from"
    ],
    [
        "\"\"\"Add an index on a model.\"\"\"",
        "\"\"\"Add an index on a"
    ],
    [
        "\"\"\"Remove an index from a model.\"\"\"",
        "\"\"\"Remove an index from a"
    ],
    [
        "\"\"\"Add a constraint to a model.\"\"\"",
        "\"\"\"Add a constraint"
    ],
    [
        "\"\"\"Remove a constraint from a model.\"\"\"",
        "\"\"\"Remove a constraint from a"
    ],
    [
        "Deal with a model changing its unique_together. The input",
        "Deal with a model changing"
    ],
    [
        "unique_togethers must be doubly-nested, not the single-nested",
        "unique_togethers must be doubly-nested,"
    ],
    [
        "olds = {tuple(fields) for fields in old_unique_together}",
        "olds = {tuple(fields) for"
    ],
    [
        "news = {tuple(fields) for fields in new_unique_together}",
        "news = {tuple(fields) for fields in"
    ],
    [
        "fields = [model._meta.get_field(field) for field in field_names]",
        "fields = [model._meta.get_field(field) for"
    ],
    [
        "Deal with a model changing its index_together. The input",
        "Deal with a model changing"
    ],
    [
        "index_togethers must be doubly-nested, not the single-nested",
        "index_togethers must be doubly-nested, not the"
    ],
    [
        "olds = {tuple(fields) for fields in old_index_together}",
        "olds = {tuple(fields) for fields in"
    ],
    [
        "news = {tuple(fields) for fields in new_index_together}",
        "news = {tuple(fields) for fields"
    ],
    [
        "fields = [model._meta.get_field(field) for field in field_names]",
        "fields = [model._meta.get_field(field) for field in"
    ],
    [
        "def _delete_composed_index(self, model, fields, constraint_kwargs, sql):",
        "def _delete_composed_index(self, model,"
    ],
    [
        "meta_index_names = {constraint.name for constraint in model._meta.indexes}",
        "meta_index_names = {constraint.name for"
    ],
    [
        "columns = [model._meta.get_field(field).column for field in fields]",
        "columns = [model._meta.get_field(field).column for"
    ],
    [
        "\"Found wrong number (%s) of constraints for %s(%s)\"",
        "\"Found wrong number (%s)"
    ],
    [
        "\"\"\"Rename the table a model points to.\"\"\"",
        "\"\"\"Rename the table a model"
    ],
    [
        "if old_db_table == new_db_table or (",
        "if old_db_table == new_db_table or"
    ],
    [
        "\"\"\"Move a model's table between tablespaces.\"\"\"",
        "\"\"\"Move a model's table"
    ],
    [
        "Create a field on a model. Usually involves adding a column, but may",
        "Create a field on a model. Usually involves adding"
    ],
    [
        "definition, params = self.column_sql(model, field, include_default=True)",
        "definition, params = self.column_sql(model,"
    ],
    [
        "definition += \" \" + self.sql_check_constraint % db_params",
        "definition += \" \" + self.sql_check_constraint"
    ],
    [
        "definition += \" \" + self.sql_create_column_inline_fk % {",
        "definition += \" \" +"
    ],
    [
        "\"%s.\" % self.quote_name(namespace) if namespace else \"\"",
        "\"%s.\" % self.quote_name(namespace) if"
    ],
    [
        "Remove a field from a model. Usually involves deleting a column,",
        "Remove a field from a model."
    ],
    [
        "def alter_field(self, model, old_field, new_field, strict=False):",
        "def alter_field(self, model, old_field, new_field,"
    ],
    [
        "Allow a field's type, uniqueness, nullability, default, column,",
        "Allow a field's type, uniqueness, nullability, default,"
    ],
    [
        "`old_field` is required to compute the necessary changes.",
        "`old_field` is required to"
    ],
    [
        "If `strict` is True, raise errors if the old column does not match",
        "If `strict` is True, raise errors if the"
    ],
    [
        "if (old_type is None and old_field.remote_field is None) or (",
        "if (old_type is None and old_field.remote_field is None) or"
    ],
    [
        "new_type is None and new_field.remote_field is None",
        "new_type is None and new_field.remote_field"
    ],
    [
        "\"Cannot alter field %s into %s - they do not properly define \"",
        "\"Cannot alter field %s into %s - they do not properly define"
    ],
    [
        "\"db_type (are you using a badly-written custom field?)\"",
        "\"db_type (are you using a"
    ],
    [
        "elif old_type is None or new_type is None:",
        "elif old_type is None or new_type"
    ],
    [
        "\"Cannot alter field %s into %s - they are not compatible types \"",
        "\"Cannot alter field %s into %s - they are not compatible"
    ],
    [
        "elif old_field.generated != new_field.generated or (",
        "elif old_field.generated != new_field.generated"
    ],
    [
        "f\"Modifying GeneratedFields is not supported - the field {new_field} \"",
        "f\"Modifying GeneratedFields is not supported -"
    ],
    [
        "\"must be removed and re-added with the new definition.\"",
        "\"must be removed and re-added with the new"
    ],
    [
        "\"\"\"Perform a \"physical\" (non-ManyToMany) field update.\"\"\"",
        "\"\"\"Perform a \"physical\" (non-ManyToMany) field"
    ],
    [
        "\"Found wrong number (%s) of foreign key constraints for %s.%s\"",
        "\"Found wrong number (%s) of foreign key constraints for"
    ],
    [
        "\"Found wrong number (%s) of unique constraints for %s.%s\"",
        "\"Found wrong number (%s) of unique constraints for"
    ],
    [
        "and ((old_type != new_type) or (old_collation != new_collation))",
        "and ((old_type != new_type)"
    ],
    [
        "meta_index_names = {index.name for index in model._meta.indexes}",
        "meta_index_names = {index.name for index in"
    ],
    [
        "if old_db_check != new_db_check and old_db_check:",
        "if old_db_check != new_db_check"
    ],
    [
        "\"Found wrong number (%s) of check constraints for %s.%s\"",
        "\"Found wrong number (%s) of check"
    ],
    [
        "model, old_field, new_field, new_type, old_collation, new_collation",
        "model, old_field, new_field, new_type, old_collation,"
    ],
    [
        "if old_field.null and not new_field.null and not new_field.has_db_default():",
        "if old_field.null and not new_field.null and"
    ],
    [
        ") and (old_field.null and not new_field.null)",
        ") and (old_field.null and"
    ],
    [
        "actions = [(\", \".join(sql), sum(params, []))]",
        "actions = [(\", \".join(sql),"
    ],
    [
        "fks_dropped or not old_field.remote_field or not old_field.db_constraint",
        "fks_dropped or not old_field.remote_field"
    ],
    [
        "if old_db_check != new_db_check and new_db_check:",
        "if old_db_check !="
    ],
    [
        "Hook to specialize column null alteration.",
        "Hook to specialize column null"
    ],
    [
        "Return a (sql, params) fragment to set a column to null or non-null",
        "Return a (sql, params) fragment to set a"
    ],
    [
        "as required by new_field, or None if no changes are required.",
        "as required by new_field, or None if no"
    ],
    [
        "def _alter_column_default_sql(self, model, old_field, new_field, drop=False):",
        "def _alter_column_default_sql(self, model,"
    ],
    [
        "Hook to specialize column default alteration.",
        "Hook to specialize column default"
    ],
    [
        "Return a (sql, params) fragment to add or drop (depending on the drop",
        "Return a (sql, params) fragment to add or drop"
    ],
    [
        "argument) a default to new_field's column.",
        "argument) a default"
    ],
    [
        "Hook to specialize column database default alteration.",
        "Hook to specialize column"
    ],
    [
        "Return a (sql, params) fragment to add or drop (depending on the drop",
        "Return a (sql, params) fragment to add or drop"
    ],
    [
        "argument) a default to new_field's column.",
        "argument) a default"
    ],
    [
        "self, model, old_field, new_field, new_type, old_collation, new_collation",
        "self, model, old_field, new_field,"
    ],
    [
        "Hook to specialize column type alteration for different backends,",
        "Hook to specialize column type alteration for different"
    ],
    [
        "for cases when a creation type is different to an alteration type",
        "for cases when a creation type is different to an alteration"
    ],
    [
        "(e.g. SERIAL in PostgreSQL, PostGIS fields).",
        "(e.g. SERIAL in"
    ],
    [
        "an ALTER TABLE statement and a list of extra (sql, params) tuples to",
        "an ALTER TABLE statement and a list of"
    ],
    [
        "run once the field is altered.",
        "run once the field is"
    ],
    [
        "def _alter_column_comment_sql(self, model, new_field, new_type, new_db_comment):",
        "def _alter_column_comment_sql(self, model,"
    ],
    [
        "def _alter_many_to_many(self, model, old_field, new_field, strict):",
        "def _alter_many_to_many(self, model, old_field,"
    ],
    [
        "Generate a unique name for an index/unique constraint.",
        "Generate a unique name"
    ],
    [
        "and a unique digest and suffix.",
        "and a unique"
    ],
    [
        "index_name = \"%s_%s_%s\" % (table_name, \"_\".join(column_names), hash_suffix_part)",
        "index_name = \"%s_%s_%s\" %"
    ],
    [
        "return \" WHERE \" + condition",
        "return \" WHERE \""
    ],
    [
        "if not columns or not self.connection.features.supports_covering_indexes:",
        "if not columns or not"
    ],
    [
        "Return the SQL statement to create the index for one or several fields",
        "Return the SQL statement to create the index for one or"
    ],
    [
        "or expressions. `sql` can be specified if the syntax differs from the",
        "or expressions. `sql` can be specified"
    ],
    [
        "columns = [field.column for field in fields]",
        "columns = [field.column for field in"
    ],
    [
        "def _index_columns(self, table, columns, col_suffixes, opclasses):",
        "def _index_columns(self, table,"
    ],
    [
        "Return a list of all index SQL statements (field indexes, Meta.indexes)",
        "Return a list of all index SQL statements (field"
    ],
    [
        "if not model._meta.managed or model._meta.proxy or model._meta.swapped:",
        "if not model._meta.managed or"
    ],
    [
        "Return a list of all index SQL statements for the specified field.",
        "Return a list of all index SQL statements for"
    ],
    [
        "if not old_field.concrete and not new_field.concrete:",
        "if not old_field.concrete and"
    ],
    [
        "_, old_path, old_args, old_kwargs = old_field.deconstruct()",
        "_, old_path, old_args, old_kwargs"
    ],
    [
        "_, new_path, new_args, new_kwargs = new_field.deconstruct()",
        "_, new_path, new_args, new_kwargs ="
    ],
    [
        ") or (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs)",
        ") or (old_path, old_args, old_kwargs) != (new_path,"
    ],
    [
        "def _rename_field_sql(self, table, old_field, new_field, new_type):",
        "def _rename_field_sql(self, table, old_field, new_field,"
    ],
    [
        "\"columns\": \", \".join([self.quote_name(field.column) for field in fields]),",
        "\"columns\": \", \".join([self.quote_name(field.column) for field"
    ],
    [
        "columns = [field.column for field in fields]",
        "columns = [field.column for"
    ],
    [
        "if condition or include or opclasses or expressions:",
        "if condition or include or opclasses"
    ],
    [
        "columns = Expressions(table, expressions, compiler, self.quote_value)",
        "columns = Expressions(table, expressions, compiler,"
    ],
    [
        "if condition or include or opclasses or expressions:",
        "if condition or include or opclasses"
    ],
    [
        "\"\"\"Return all constraint names matching the columns and conditions.\"\"\"",
        "\"\"\"Return all constraint names matching the columns"
    ],
    [
        "if column_names is None or column_names == infodict[\"columns\"]:",
        "if column_names is None or"
    ],
    [
        "if unique is not None and infodict[\"unique\"] != unique:",
        "if unique is not None and"
    ],
    [
        "if primary_key is not None and infodict[\"primary_key\"] != primary_key:",
        "if primary_key is not None and infodict[\"primary_key\"] !="
    ],
    [
        "if index is not None and infodict[\"index\"] != index:",
        "if index is not None"
    ],
    [
        "if check is not None and infodict[\"check\"] != check:",
        "if check is not None and infodict[\"check\"]"
    ],
    [
        "if foreign_key is not None and not infodict[\"foreign_key\"]:",
        "if foreign_key is not None and"
    ],
    [
        "if type_ is not None and infodict[\"type\"] != type_:",
        "if type_ is not None and infodict[\"type\"]"
    ],
    [
        "if not exclude or name not in exclude:",
        "if not exclude or name"
    ],
    [
        "\"columns\": \", \".join(self.quote_name(column) for column in columns)",
        "\"columns\": \", \".join(self.quote_name(column) for column in"
    ],
    [
        "\"Found wrong number (%s) of PK constraints for %s\"",
        "\"Found wrong number (%s) of PK constraints for"
    ],
    [
        "return \"COLLATE \" + self.quote_name(collation) if collation else \"\"",
        "return \"COLLATE \" + self.quote_name(collation) if collation"
    ],
    [
        "\"The return type of '%s' should never be mutated. If you want to manipulate this \"",
        "\"The return type of '%s' should never be mutated. If you want to manipulate this"
    ],
    [
        "\"list for your own use, make a copy first.\"",
        "\"list for your own use, make a"
    ],
    [
        "option_together can be either a tuple of tuples, or a single",
        "option_together can be either a tuple of"
    ],
    [
        "tuple of two strings. Normalize it to a tuple of tuples, so that",
        "tuple of two strings. Normalize it to a tuple of tuples, so"
    ],
    [
        "calling code can uniformly expect that.",
        "calling code can uniformly expect"
    ],
    [
        "return tuple(tuple(ot) for ot in option_together)",
        "return tuple(tuple(ot) for ot in"
    ],
    [
        "self.default_permissions = (\"add\", \"change\", \"delete\", \"view\")",
        "self.default_permissions = (\"add\", \"change\","
    ],
    [
        "\"'class Meta' got invalid attribute(s): %s\" % \",\".join(meta_attrs)",
        "\"'class Meta' got invalid attribute(s): %s\""
    ],
    [
        "self.db_table = \"%s_%s\" % (self.app_label, self.model_name)",
        "self.db_table = \"%s_%s\" % (self.app_label,"
    ],
    [
        "\"\"\"App label/class name interpolation for object names.\"\"\"",
        "\"\"\"App label/class name interpolation for object"
    ],
    [
        "names = {\"app_label\": self.app_label.lower(), \"class\": self.model_name}",
        "names = {\"app_label\": self.app_label.lower(), \"class\":"
    ],
    [
        "raise ImproperlyConfigured(f\"{source} must not be empty.\")",
        "raise ImproperlyConfigured(f\"{source} must not"
    ],
    [
        "f\"{source} refers to the module '{pk_class_path}' that could \"",
        "f\"{source} refers to the module '{pk_class_path}' that could"
    ],
    [
        "f\"Primary key '{pk_class_path}' referred by {source} must \"",
        "f\"Primary key '{pk_class_path}' referred by {source}"
    ],
    [
        "if f.name == query or f.attname == query",
        "if f.name == query or f.attname =="
    ],
    [
        "\"%s has no field named '%s'\" % (self.object_name, query)",
        "\"%s has no field named '%s'\""
    ],
    [
        "isinstance(field, OrderWrt) for field in model._meta.local_fields",
        "isinstance(field, OrderWrt) for field"
    ],
    [
        "fld for fld in self.local_fields if fld.name == field.name",
        "fld for fld in self.local_fields if"
    ],
    [
        "Do the internal setup so that the current model is a proxy for",
        "Do the internal setup so that the current model"
    ],
    [
        "return \"<Options for %s>\" % self.object_name",
        "return \"<Options for %s>\" %"
    ],
    [
        "Return True if the model can/should be migrated on the `connection`.",
        "Return True if the model can/should be migrated on"
    ],
    [
        "`connection` can be either a real connection or a connection alias.",
        "`connection` can be either a real connection or a"
    ],
    [
        "if self.proxy or self.swapped or not self.managed:",
        "if self.proxy or self.swapped or"
    ],
    [
        "Has this model been swapped out for another? If so, return the model",
        "Has this model been swapped out for another? If so, return"
    ],
    [
        "name of the replacement; otherwise, return None.",
        "name of the replacement;"
    ],
    [
        "For historical reasons, model name lookups using get_model() are",
        "For historical reasons, model name lookups using"
    ],
    [
        "case insensitive, so we make sure we are case insensitive here.",
        "case insensitive, so we make sure we are case insensitive"
    ],
    [
        "if setting == self.swappable and \"swapped\" in self.__dict__:",
        "if setting == self.swappable and \"swapped\" in"
    ],
    [
        "bases = (b for b in self.model.mro() if hasattr(b, \"_meta\"))",
        "bases = (b for b in self.model.mro() if"
    ],
    [
        "return {manager.name: manager for manager in self.managers}",
        "return {manager.name: manager for"
    ],
    [
        "\"%s has no manager named %r\"",
        "\"%s has no"
    ],
    [
        "if not default_manager_name and not self.local_managers:",
        "if not default_manager_name and not"
    ],
    [
        "\"%s has no manager named %r\"",
        "\"%s has no manager named"
    ],
    [
        "Return a list of all forward fields on the model and its parents,",
        "Return a list of all forward fields on the model and its"
    ],
    [
        "Private API intended only to be used by Django itself; get_fields()",
        "Private API intended only to be used by Django itself;"
    ],
    [
        "combined with filtering of field properties is the public API for",
        "combined with filtering of field properties is the public"
    ],
    [
        "and not (hasattr(f.remote_field, \"model\") and f.remote_field.model)",
        "and not (hasattr(f.remote_field, \"model\") and"
    ],
    [
        "Return a list of all concrete fields on the model and its parents.",
        "Return a list of all concrete fields on the model and"
    ],
    [
        "Private API intended only to be used by Django itself; get_fields()",
        "Private API intended only to be"
    ],
    [
        "combined with filtering of field properties is the public API for",
        "combined with filtering of field properties"
    ],
    [
        "\"concrete_fields\", (f for f in self.fields if f.concrete)",
        "\"concrete_fields\", (f for f"
    ],
    [
        "Return a list of all concrete fields on the model.",
        "Return a list of all"
    ],
    [
        "Private API intended only to be used by Django itself; get_fields()",
        "Private API intended only to be used by Django itself;"
    ],
    [
        "combined with filtering of field properties is the public API for",
        "combined with filtering of field properties"
    ],
    [
        "\"local_concrete_fields\", (f for f in self.local_fields if f.concrete)",
        "\"local_concrete_fields\", (f for f"
    ],
    [
        "Return a list of all many to many fields on the model and its parents.",
        "Return a list of all many to many fields on"
    ],
    [
        "Private API intended only to be used by Django itself; get_fields()",
        "Private API intended only to be used by Django itself;"
    ],
    [
        "combined with filtering of field properties is the public API for",
        "combined with filtering of field properties is the public API"
    ],
    [
        "Return all related objects pointing to the current model. The related",
        "Return all related objects pointing to the current"
    ],
    [
        "objects can come from a one-to-one, one-to-many, or many-to-many field",
        "objects can come from a"
    ],
    [
        "Private API intended only to be used by Django itself; get_fields()",
        "Private API intended only to be used by Django itself;"
    ],
    [
        "combined with filtering of field properties is the public API for",
        "combined with filtering of field properties is the public"
    ],
    [
        "Return a field instance given the name of a forward or reverse field.",
        "Return a field instance given the name of a forward or"
    ],
    [
        "\"%s has no field named '%s'. The app cache isn't ready yet, \"",
        "\"%s has no field named '%s'. The"
    ],
    [
        "\"so if this is an auto-created related field, it won't \"",
        "\"so if this is an auto-created related field,"
    ],
    [
        "\"be available yet.\" % (self.object_name, field_name)",
        "\"be available yet.\" %"
    ],
    [
        "\"%s has no field named '%s'\" % (self.object_name, field_name)",
        "\"%s has no field named '%s'\" %"
    ],
    [
        "Return a list of parent classes leading to `model` (ordered from",
        "Return a list of parent classes leading to"
    ],
    [
        "closest to most distant ancestor). This has to handle the case where",
        "closest to most distant ancestor). This has to"
    ],
    [
        "`model` is a grandparent or even more distant relation.",
        "`model` is a grandparent or even more"
    ],
    [
        "Return all the ancestors of this model as a tuple ordered by MRO.",
        "Return all the ancestors of this model as a tuple ordered by"
    ],
    [
        "Useful for determining if something is an ancestor, regardless of lineage.",
        "Useful for determining if something is an ancestor, regardless of"
    ],
    [
        "Return all the ancestors of this model as a list ordered by MRO.",
        "Return all the ancestors of this model as a"
    ],
    [
        "Return the field on the current model which points to the given",
        "Return the field on the current model which"
    ],
    [
        "\"ancestor\". This is possible an indirect link (a pointer to a parent",
        "\"ancestor\". This is possible an indirect link"
    ],
    [
        "model, which points, eventually, to the ancestor). Used when",
        "model, which points, eventually, to the ancestor). Used"
    ],
    [
        "constructing table joins for model inheritance.",
        "constructing table joins"
    ],
    [
        "Return None if the model isn't an ancestor of this one.",
        "Return None if the model isn't an"
    ],
    [
        "Return a list of PathInfos containing the path from the current",
        "Return a list of PathInfos containing the path from the"
    ],
    [
        "model to the parent model, or an empty list if parent is not a",
        "model to the parent model, or an empty list if"
    ],
    [
        "Return a list of PathInfos containing the path from the parent",
        "Return a list of PathInfos containing the"
    ],
    [
        "model to the current model, or an empty list if parent is not a",
        "model to the current model, or an empty list"
    ],
    [
        "This method is used by each model to find its reverse objects. As this",
        "This method is used by each model to find its reverse objects."
    ],
    [
        "method is very expensive and is accessed frequently (it looks up every",
        "method is very expensive and is accessed"
    ],
    [
        "field in a model, in every app), it is computed on first access and then",
        "field in a model, in every app), it is computed on first access and"
    ],
    [
        "is set as a property on every model.",
        "is set as a"
    ],
    [
        "if f.is_relation and f.related_model is not None",
        "if f.is_relation and f.related_model"
    ],
    [
        "Return a list of fields associated to the model. By default, include",
        "Return a list of fields associated to the model."
    ],
    [
        "forward and reverse fields, fields derived from inheritance, but not",
        "forward and reverse fields, fields derived from"
    ],
    [
        "hidden fields. The returned fields can be changed using the parameters:",
        "hidden fields. The returned fields can"
    ],
    [
        "- include_parents: include fields derived from inheritance",
        "- include_parents: include fields derived"
    ],
    [
        "- include_hidden:  include fields that have a related_name that",
        "- include_hidden: include fields that have"
    ],
    [
        "Internal helper function to return fields of the model.",
        "Internal helper function to return fields"
    ],
    [
        "* If forward=True, then fields defined on this model are returned.",
        "* If forward=True, then fields defined on this"
    ],
    [
        "* If reverse=True, then relations pointing to this model are returned.",
        "* If reverse=True, then relations pointing"
    ],
    [
        "* If include_hidden=True, then fields with is_hidden=True are returned.",
        "* If include_hidden=True, then fields with"
    ],
    [
        "* The include_parents argument toggles if fields from parent models",
        "* The include_parents argument toggles if fields"
    ],
    [
        "should be included. It has three values: True, False, and",
        "should be included. It has"
    ],
    [
        "PROXY_PARENTS. When set to PROXY_PARENTS, the call will return all",
        "PROXY_PARENTS. When set to PROXY_PARENTS, the call will return"
    ],
    [
        "fields defined for the current model or any of its parents in the",
        "fields defined for the current model or any of"
    ],
    [
        "parent chain to the model's concrete model.",
        "parent chain to the"
    ],
    [
        "if include_parents not in (True, False, PROXY_PARENTS):",
        "if include_parents not in"
    ],
    [
        "\"Invalid argument for include_parents: %s\" % (include_parents,)",
        "\"Invalid argument for include_parents: %s\" %"
    ],
    [
        "cache_key = (forward, reverse, include_parents, include_hidden, topmost_call)",
        "cache_key = (forward, reverse, include_parents, include_hidden,"
    ],
    [
        ") and obj not in parent_fields:",
        ") and obj not in"
    ],
    [
        "Return a list of total unique constraints. Useful for determining set",
        "Return a list of total unique constraints. Useful"
    ],
    [
        "of fields guaranteed to be unique for all rows.",
        "of fields guaranteed to be"
    ],
    [
        "\"\"\"Return a set of the names of the properties defined on the model.\"\"\"",
        "\"\"\"Return a set of the names of the properties"
    ],
    [
        "if isinstance(value, property) and name not in seen",
        "if isinstance(value, property) and name"
    ],
    [
        "Return a set of the non-pk concrete field names defined on the model.",
        "Return a set of the non-pk concrete field names"
    ],
    [
        "Return a set of reverse one to one field names pointing to the current",
        "Return a set of reverse one to one field names"
    ],
    [
        "field.name for field in self.related_objects if field.one_to_one",
        "field.name for field in"
    ],
    [
        "Private API intended only to be used by Django itself.",
        "Private API intended only to be used"
    ],
    [
        "Fields to be returned after a database insert.",
        "Fields to be returned after a"
    ],
    [
        "Signal subclass that allows the sender to be lazily specified as a string",
        "Signal subclass that allows the sender to be lazily specified"
    ],
    [
        "def _lazy_method(self, method, apps, receiver, sender, **kwargs):",
        "def _lazy_method(self, method, apps,"
    ],
    [
        "def connect(self, receiver, sender=None, weak=True, dispatch_uid=None, apps=None):",
        "def connect(self, receiver, sender=None, weak=True,"
    ],
    [
        "def disconnect(self, receiver=None, sender=None, dispatch_uid=None, apps=None):",
        "def disconnect(self, receiver=None, sender=None,"
    ],
    [
        "from enum import EnumType, IntEnum, StrEnum",
        "from enum import EnumType, IntEnum,"
    ],
    [
        "from enum import property as enum_property",
        "from enum import property"
    ],
    [
        "\"\"\"A metaclass for creating a enum choices.\"\"\"",
        "\"\"\"A metaclass for creating a"
    ],
    [
        "def __new__(metacls, classname, bases, classdict, **kwds):",
        "def __new__(metacls, classname, bases,"
    ],
    [
        "cls = super().__new__(metacls, classname, bases, classdict, **kwds)",
        "cls = super().__new__(metacls, classname, bases,"
    ],
    [
        "for member, label in zip(cls.__members__.values(), labels):",
        "for member, label"
    ],
    [
        "empty = [\"__empty__\"] if hasattr(cls, \"__empty__\") else []",
        "empty = [\"__empty__\"] if hasattr(cls,"
    ],
    [
        "return empty + [member.name for member in cls]",
        "return empty + [member.name for"
    ],
    [
        "empty = [(None, cls.__empty__)] if hasattr(cls, \"__empty__\") else []",
        "empty = [(None, cls.__empty__)] if"
    ],
    [
        "return empty + [(member.value, member.label) for member in cls]",
        "return empty + [(member.value, member.label)"
    ],
    [
        "return [label for _, label in cls.choices]",
        "return [label for _, label in"
    ],
    [
        "return [value for value, _ in cls.choices]",
        "return [value for value,"
    ],
    [
        "\"\"\"Class for creating enumerated integer choices.\"\"\"",
        "\"\"\"Class for creating enumerated integer"
    ],
    [
        "\"\"\"Class for creating enumerated string choices.\"\"\"",
        "\"\"\"Class for creating enumerated"
    ],
    [
        "The main QuerySet implementation. This provides the public API for the ORM.",
        "The main QuerySet implementation. This provides the public"
    ],
    [
        "from django.db.models import AutoField, DateField, DateTimeField, Field, sql",
        "from django.db.models import AutoField, DateField, DateTimeField,"
    ],
    [
        "from django.db.models.expressions import Case, F, Value, When",
        "from django.db.models.expressions import Case, F, Value,"
    ],
    [
        "\"\"\"Iterable that yields a model instance for each row.\"\"\"",
        "\"\"\"Iterable that yields a model"
    ],
    [
        "for field, rel_objs, rel_getter in known_related_objects:",
        "for field, rel_objs,"
    ],
    [
        "Iterable that yields a model instance for each row from a raw queryset.",
        "Iterable that yields a model instance for"
    ],
    [
        "\"Raw query must include the primary key\"",
        "\"Raw query must include"
    ],
    [
        "fields = [self.queryset.model_fields.get(c) for c in self.queryset.columns]",
        "fields = [self.queryset.model_fields.get(c) for"
    ],
    [
        "cols = [f.get_col(f.model._meta.db_table) if f else None for f in fields]",
        "cols = [f.get_col(f.model._meta.db_table) if f else None for"
    ],
    [
        "model_init_values = [values[pos] for pos in model_init_pos]",
        "model_init_values = [values[pos] for"
    ],
    [
        "Iterable returned by QuerySet.values() that yields a dict for each row.",
        "Iterable returned by QuerySet.values() that yields a"
    ],
    [
        "yield {names[i]: row[i] for i in indexes}",
        "yield {names[i]: row[i] for"
    ],
    [
        "Iterable returned by QuerySet.values_list(flat=False) that yields a tuple",
        "Iterable returned by QuerySet.values_list(flat=False) that yields"
    ],
    [
        "Iterable returned by QuerySet.values_list(named=True) that yields a",
        "Iterable returned by QuerySet.values_list(named=True)"
    ],
    [
        "Iterable returned by QuerySet.values_list(flat=True) that yields single",
        "Iterable returned by QuerySet.values_list(flat=True)"
    ],
    [
        "\"\"\"Represent a lazy database lookup for a set of objects.\"\"\"",
        "\"\"\"Represent a lazy database lookup"
    ],
    [
        "def __init__(self, model=None, query=None, using=None, hints=None):",
        "def __init__(self, model=None, query=None,"
    ],
    [
        "\"Pickled queryset instance's Django version %s does not \"",
        "\"Pickled queryset instance's Django version"
    ],
    [
        "\"Pickled queryset instance's Django version is not specified.\",",
        "\"Pickled queryset instance's Django version"
    ],
    [
        "return \"<%s %r>\" % (self.__class__.__name__, data)",
        "return \"<%s %r>\" % (self.__class__.__name__,"
    ],
    [
        "The queryset iterator protocol uses three nested iterators in the",
        "The queryset iterator protocol uses three nested iterators in"
    ],
    [
        "using cursor.fetchmany(). This part is responsible for",
        "using cursor.fetchmany(). This part"
    ],
    [
        "doing some column masking, and returning the rows in chunks.",
        "doing some column masking, and"
    ],
    [
        "- Returns one row at time. At this point the rows are still just",
        "- Returns one row at time. At"
    ],
    [
        "tuples. In some cases the return values are converted to",
        "tuples. In some cases the return"
    ],
    [
        "- Responsible for turning the rows into model objects.",
        "- Responsible for turning the rows"
    ],
    [
        "\"\"\"Retrieve an item or slice from the set of results.\"\"\"",
        "\"\"\"Retrieve an item or slice from the"
    ],
    [
        "\"QuerySet indices must be integers or slices, not %s.\"",
        "\"QuerySet indices must be integers or"
    ],
    [
        "raise ValueError(\"Negative indexing is not supported.\")",
        "raise ValueError(\"Negative indexing"
    ],
    [
        "return list(qs)[:: k.step] if k.step else qs",
        "return list(qs)[:: k.step] if k.step else"
    ],
    [
        "if not self._prefetch_related_lookups or chunk_size is None:",
        "if not self._prefetch_related_lookups or"
    ],
    [
        "An iterator over the results from applying this QuerySet to the",
        "An iterator over the results from"
    ],
    [
        "database. chunk_size must be provided for QuerySets that prefetch",
        "database. chunk_size must be provided for QuerySets"
    ],
    [
        "\"chunk_size must be provided when using QuerySet.iterator() after \"",
        "\"chunk_size must be provided when using QuerySet.iterator() after"
    ],
    [
        "raise ValueError(\"Chunk size must be strictly positive.\")",
        "raise ValueError(\"Chunk size must be strictly"
    ],
    [
        "An asynchronous iterator over the results from applying this QuerySet",
        "An asynchronous iterator over the results"
    ],
    [
        "raise ValueError(\"Chunk size must be strictly positive.\")",
        "raise ValueError(\"Chunk size must"
    ],
    [
        "Return a dictionary containing the calculations (aggregation)",
        "Return a dictionary containing"
    ],
    [
        "If args is present the expression is passed as a kwarg using",
        "If args is present the expression is passed"
    ],
    [
        "raise NotImplementedError(\"aggregate() + distinct(fields) not implemented.\")",
        "raise NotImplementedError(\"aggregate() + distinct(fields) not"
    ],
    [
        "raise TypeError(\"Complex aggregates require an alias\")",
        "raise TypeError(\"Complex aggregates"
    ],
    [
        "Perform a SELECT COUNT() and return the number of records as an",
        "Perform a SELECT COUNT() and return the"
    ],
    [
        "If the QuerySet is already fully cached, return the length of the",
        "If the QuerySet is already fully cached, return the"
    ],
    [
        "cached results set to avoid multiple SELECT COUNT(*) calls.",
        "cached results set to avoid multiple"
    ],
    [
        "Perform the query and return a single object matching the given",
        "Perform the query and return a"
    ],
    [
        "if self.query.combinator and (args or kwargs):",
        "if self.query.combinator and (args or"
    ],
    [
        "\"Calling QuerySet.get(...) with filters after %s() is not \"",
        "\"Calling QuerySet.get(...) with filters after %s()"
    ],
    [
        "clone = self._chain() if self.query.combinator else self.filter(*args, **kwargs)",
        "clone = self._chain() if"
    ],
    [
        "\"%s matching query does not exist.\" % self.model._meta.object_name",
        "\"%s matching query does not exist.\""
    ],
    [
        "\"get() returned more than one %s -- it returned %s!\"",
        "\"get() returned more than one %s -- it"
    ],
    [
        "Create a new object with the given kwargs, saving it to the database",
        "Create a new object with the given"
    ],
    [
        "\"The following fields do not exist in this model: %s\"",
        "\"The following fields do not"
    ],
    [
        "\"ignore_conflicts and update_conflicts are mutually exclusive.\"",
        "\"ignore_conflicts and update_conflicts are"
    ],
    [
        "\"This database backend does not support ignoring conflicts.\"",
        "\"This database backend does not"
    ],
    [
        "\"This database backend does not support updating conflicts.\"",
        "\"This database backend does not support updating"
    ],
    [
        "\"Fields that will be updated when a row insertion fails \"",
        "\"Fields that will be updated when a"
    ],
    [
        "\"This database backend does not support updating \"",
        "\"This database backend does not support"
    ],
    [
        "\"conflicts with specifying unique fields that can trigger \"",
        "\"conflicts with specifying unique fields that can"
    ],
    [
        "\"Unique fields that can trigger the upsert must be provided.\"",
        "\"Unique fields that can trigger the"
    ],
    [
        "if any(not f.concrete or f.many_to_many for f in update_fields):",
        "if any(not f.concrete or f.many_to_many for"
    ],
    [
        "\"bulk_create() can only be used with concrete fields in \"",
        "\"bulk_create() can only be used with concrete fields"
    ],
    [
        "if any(f in self.model._meta.pk_fields for f in update_fields):",
        "if any(f in self.model._meta.pk_fields for f"
    ],
    [
        "\"bulk_create() cannot be used with primary keys in \"",
        "\"bulk_create() cannot be used with primary keys"
    ],
    [
        "if any(not f.concrete or f.many_to_many for f in unique_fields):",
        "if any(not f.concrete or f.many_to_many for f"
    ],
    [
        "\"bulk_create() can only be used with concrete fields \"",
        "\"bulk_create() can only be used"
    ],
    [
        "Insert each of the instances into the database. Do *not* call",
        "Insert each of the instances into the database."
    ],
    [
        "save() on each of the instances, do not send any pre/post_save",
        "save() on each of the instances, do"
    ],
    [
        "signals, and do not set the primary key attribute if it is an",
        "signals, and do not set the primary key attribute"
    ],
    [
        "raise ValueError(\"Batch size must be a positive integer.\")",
        "raise ValueError(\"Batch size must"
    ],
    [
        "raise ValueError(\"Can't bulk create a multi-table inherited model\")",
        "raise ValueError(\"Can't bulk create a multi-table inherited"
    ],
    [
        "self.model._meta.get_field(opts.pk.name if name == \"pk\" else name)",
        "self.model._meta.get_field(opts.pk.name if name == \"pk\""
    ],
    [
        "update_fields = [self.model._meta.get_field(name) for name in update_fields]",
        "update_fields = [self.model._meta.get_field(name) for name"
    ],
    [
        "fields = [f for f in opts.concrete_fields if not f.generated]",
        "fields = [f for f in opts.concrete_fields"
    ],
    [
        "objs_without_pk, objs_with_pk = partition(lambda o: o._is_pk_set(), objs)",
        "objs_without_pk, objs_with_pk = partition(lambda"
    ],
    [
        "for obj_with_pk, results in zip(objs_with_pk, returned_columns):",
        "for obj_with_pk, results"
    ],
    [
        "for result, field in zip(results, opts.db_returning_fields):",
        "for result, field in zip(results,"
    ],
    [
        "fields = [f for f in fields if not isinstance(f, AutoField)]",
        "fields = [f for f in fields if not isinstance(f,"
    ],
    [
        "for obj_without_pk, results in zip(objs_without_pk, returned_columns):",
        "for obj_without_pk, results"
    ],
    [
        "for result, field in zip(results, opts.db_returning_fields):",
        "for result, field in zip(results,"
    ],
    [
        "Update the given fields in each of the given objects in the database.",
        "Update the given fields in each of the given objects in the"
    ],
    [
        "raise ValueError(\"Batch size must be a positive integer.\")",
        "raise ValueError(\"Batch size must be a positive"
    ],
    [
        "raise ValueError(\"Field names must be given to bulk_update().\")",
        "raise ValueError(\"Field names must be given"
    ],
    [
        "if not all(obj._is_pk_set() for obj in objs):",
        "if not all(obj._is_pk_set() for obj"
    ],
    [
        "raise ValueError(\"All bulk_update() objects must have a primary key set.\")",
        "raise ValueError(\"All bulk_update() objects must have a primary key"
    ],
    [
        "fields = [opts.get_field(name) for name in fields]",
        "fields = [opts.get_field(name) for name"
    ],
    [
        "if any(not f.concrete or f.many_to_many for f in fields):",
        "if any(not f.concrete or f.many_to_many for"
    ],
    [
        "raise ValueError(\"bulk_update() can only be used with concrete fields.\")",
        "raise ValueError(\"bulk_update() can only be used with concrete"
    ],
    [
        "if any(f in all_pk_fields for f in fields):",
        "if any(f in all_pk_fields for f"
    ],
    [
        "raise ValueError(\"bulk_update() cannot be used with primary key fields.\")",
        "raise ValueError(\"bulk_update() cannot be used with"
    ],
    [
        "batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size",
        "batch_size = min(batch_size, max_batch_size) if"
    ],
    [
        "updates.append(([obj.pk for obj in batch_objs], update_kwargs))",
        "updates.append(([obj.pk for obj"
    ],
    [
        "async def abulk_update(self, objs, fields, batch_size=None):",
        "async def abulk_update(self, objs, fields,"
    ],
    [
        "Look up an object with the given kwargs, creating one if necessary.",
        "Look up an object with the given kwargs, creating one if"
    ],
    [
        "Return a tuple of (object, created), where created is a boolean",
        "Return a tuple of (object, created), where created is"
    ],
    [
        "specifying whether an object was created.",
        "specifying whether an"
    ],
    [
        "Look up an object with the given kwargs, updating one with defaults",
        "Look up an object with the given kwargs, updating"
    ],
    [
        "if it exists, otherwise create a new one. Optionally, an object can",
        "if it exists, otherwise create a new one. Optionally,"
    ],
    [
        "be created with different values than defaults by using",
        "be created with different values than defaults by"
    ],
    [
        "Return a tuple (object, created), where created is a boolean",
        "Return a tuple (object, created),"
    ],
    [
        "specifying whether an object was created.",
        "specifying whether an object"
    ],
    [
        "field in pk_fields or field.__class__.pre_save is Field.pre_save",
        "field in pk_fields or field.__class__.pre_save is"
    ],
    [
        "async def aupdate_or_create(self, defaults=None, create_defaults=None, **kwargs):",
        "async def aupdate_or_create(self, defaults=None, create_defaults=None,"
    ],
    [
        "Prepare `params` for creating a model instance based on the given",
        "Prepare `params` for creating a model instance based on the"
    ],
    [
        "params = {k: v for k, v in kwargs.items() if LOOKUP_SEP not in k}",
        "params = {k: v for k, v in kwargs.items() if LOOKUP_SEP not in"
    ],
    [
        "if not (param in property_names and getattr(self.model, param).fset):",
        "if not (param in property_names and getattr(self.model,"
    ],
    [
        "\"Invalid field name(s) for model %s: '%s'.\"",
        "\"Invalid field name(s) for model"
    ],
    [
        "Return the earliest object according to fields (if given) or by the",
        "Return the earliest object according to fields (if given) or"
    ],
    [
        "if order_by and not isinstance(order_by, (tuple, list)):",
        "if order_by and not isinstance(order_by,"
    ],
    [
        "\"earliest() and latest() require either fields as positional \"",
        "\"earliest() and latest() require either fields as positional"
    ],
    [
        "\"arguments or 'get_latest_by' in the model's Meta.\"",
        "\"arguments or 'get_latest_by' in the"
    ],
    [
        "raise TypeError(\"Cannot change a query once a slice has been taken.\")",
        "raise TypeError(\"Cannot change a query once a slice"
    ],
    [
        "Return the latest object according to fields (if given) or by the",
        "Return the latest object according to fields (if given) or by"
    ],
    [
        "raise TypeError(\"Cannot change a query once a slice has been taken.\")",
        "raise TypeError(\"Cannot change a query once a slice has"
    ],
    [
        "\"\"\"Return the first object of a query or None if no match is found.\"\"\"",
        "\"\"\"Return the first object of a query or None if no"
    ],
    [
        "\"\"\"Return the last object of a query or None if no match is found.\"\"\"",
        "\"\"\"Return the last object of a query or None if"
    ],
    [
        "Return a dictionary mapping each of the given IDs to the object with",
        "Return a dictionary mapping each of the given IDs to"
    ],
    [
        "that ID. If `id_list` isn't provided, evaluate the entire QuerySet.",
        "that ID. If `id_list` isn't"
    ],
    [
        "raise TypeError(\"Cannot use 'limit' or 'offset' with in_bulk().\")",
        "raise TypeError(\"Cannot use 'limit' or 'offset'"
    ],
    [
        "raise TypeError(\"in_bulk() cannot be used with values() or values_list().\")",
        "raise TypeError(\"in_bulk() cannot be used"
    ],
    [
        "\"in_bulk()'s field_name must be a unique field but %r isn't.\"",
        "\"in_bulk()'s field_name must be a unique"
    ],
    [
        "if batch_size and batch_size < len(id_list):",
        "if batch_size and batch_size <"
    ],
    [
        "batch = id_list[offset : offset + batch_size]",
        "batch = id_list[offset : offset"
    ],
    [
        "return {getattr(obj, field_name): obj for obj in qs}",
        "return {getattr(obj, field_name): obj for obj"
    ],
    [
        "async def ain_bulk(self, id_list=None, *, field_name=\"pk\"):",
        "async def ain_bulk(self, id_list=None,"
    ],
    [
        "\"\"\"Delete the records in the current QuerySet.\"\"\"",
        "\"\"\"Delete the records in"
    ],
    [
        "raise TypeError(\"Cannot use 'limit' or 'offset' with delete().\")",
        "raise TypeError(\"Cannot use 'limit'"
    ],
    [
        "raise TypeError(\"Cannot call delete() after .distinct(*fields).\")",
        "raise TypeError(\"Cannot call delete()"
    ],
    [
        "raise TypeError(\"Cannot call delete() after .values() or .values_list()\")",
        "raise TypeError(\"Cannot call delete() after .values() or"
    ],
    [
        "Delete objects found from the given queryset in single direct SQL",
        "Delete objects found from the given queryset in single"
    ],
    [
        "query. No signals are sent and there is no protection for cascades.",
        "query. No signals are sent and there is"
    ],
    [
        "Update all elements in the current QuerySet, setting all the given",
        "Update all elements in the current QuerySet,"
    ],
    [
        "raise TypeError(\"Cannot update a query once a slice has been taken.\")",
        "raise TypeError(\"Cannot update a query once a slice has"
    ],
    [
        "f\"Cannot update when ordering by an aggregate: {annotation}\"",
        "f\"Cannot update when ordering by"
    ],
    [
        "A version of update() that accepts field objects instead of field names.",
        "A version of update() that accepts field objects instead of field"
    ],
    [
        "Used primarily for model saving and not intended for use by general",
        "Used primarily for model saving and not intended for use"
    ],
    [
        "code (it requires too much poking around at model internals to be",
        "code (it requires too much poking around at model"
    ],
    [
        "raise TypeError(\"Cannot update a query once a slice has been taken.\")",
        "raise TypeError(\"Cannot update a query once"
    ],
    [
        "Return True if the QuerySet would have any results, False otherwise.",
        "Return True if the QuerySet would have any"
    ],
    [
        "Return True if the QuerySet contains the provided obj,",
        "Return True if the QuerySet contains the provided"
    ],
    [
        "\"Cannot call QuerySet.contains() after .values() or .values_list().\"",
        "\"Cannot call QuerySet.contains() after .values()"
    ],
    [
        "raise TypeError(\"'obj' must be a model instance.\")",
        "raise TypeError(\"'obj' must be"
    ],
    [
        "raise ValueError(\"QuerySet.contains() cannot be used on unsaved objects.\")",
        "raise ValueError(\"QuerySet.contains() cannot be used"
    ],
    [
        "Runs an EXPLAIN on the SQL query this QuerySet would perform, and",
        "Runs an EXPLAIN on the SQL query this QuerySet would"
    ],
    [
        "async def aexplain(self, *, format=None, **options):",
        "async def aexplain(self,"
    ],
    [
        "def raw(self, raw_query, params=(), translations=None, using=None):",
        "def raw(self, raw_query, params=(), translations=None,"
    ],
    [
        "raise TypeError(\"'flat' and 'named' can't be used together.\")",
        "raise TypeError(\"'flat' and 'named' can't"
    ],
    [
        "\"'flat' is not valid when values_list is called with more than one \"",
        "\"'flat' is not valid when values_list is called with more"
    ],
    [
        "field_names = {f for f in fields if not hasattr(f, \"resolve_expression\")}",
        "field_names = {f for f in fields"
    ],
    [
        "else FlatValuesListIterable if flat else ValuesListIterable",
        "else FlatValuesListIterable if flat else"
    ],
    [
        "Return a list of date objects representing all available dates for",
        "Return a list of date objects representing"
    ],
    [
        "the given field_name, scoped to 'kind'.",
        "the given field_name,"
    ],
    [
        "if kind not in (\"year\", \"month\", \"week\", \"day\"):",
        "if kind not in (\"year\", \"month\", \"week\","
    ],
    [
        "raise ValueError(\"'kind' must be one of 'year', 'month', 'week', or 'day'.\")",
        "raise ValueError(\"'kind' must be one of 'year',"
    ],
    [
        "if order not in (\"ASC\", \"DESC\"):",
        "if order not"
    ],
    [
        "raise ValueError(\"'order' must be either 'ASC' or 'DESC'.\")",
        "raise ValueError(\"'order' must be either 'ASC'"
    ],
    [
        ".order_by((\"-\" if order == \"DESC\" else \"\") + \"datefield\")",
        ".order_by((\"-\" if order == \"DESC\" else \"\") +"
    ],
    [
        "def datetimes(self, field_name, kind, order=\"ASC\", tzinfo=None):",
        "def datetimes(self, field_name, kind,"
    ],
    [
        "Return a list of datetime objects representing all available",
        "Return a list of datetime objects"
    ],
    [
        "datetimes for the given field_name, scoped to 'kind'.",
        "datetimes for the given field_name, scoped to"
    ],
    [
        "if kind not in (\"year\", \"month\", \"week\", \"day\", \"hour\", \"minute\", \"second\"):",
        "if kind not in (\"year\", \"month\", \"week\", \"day\","
    ],
    [
        "\"'kind' must be one of 'year', 'month', 'week', 'day', \"",
        "\"'kind' must be one of 'year', 'month',"
    ],
    [
        "if order not in (\"ASC\", \"DESC\"):",
        "if order not in (\"ASC\","
    ],
    [
        "raise ValueError(\"'order' must be either 'ASC' or 'DESC'.\")",
        "raise ValueError(\"'order' must be either 'ASC' or"
    ],
    [
        ".order_by((\"-\" if order == \"DESC\" else \"\") + \"datetimefield\")",
        ".order_by((\"-\" if order == \"DESC\" else"
    ],
    [
        "Return a new QuerySet that is a copy of the current one. This allows a",
        "Return a new QuerySet that is a copy of the"
    ],
    [
        "QuerySet to proxy for a model manager in some cases.",
        "QuerySet to proxy for a model manager in some"
    ],
    [
        "Return a new QuerySet instance with the args ANDed to the existing",
        "Return a new QuerySet instance with the args ANDed to"
    ],
    [
        "Return a new QuerySet instance with NOT (args) ANDed to the existing",
        "Return a new QuerySet instance with"
    ],
    [
        "if (args or kwargs) and self.query.is_sliced:",
        "if (args or"
    ],
    [
        "raise TypeError(\"Cannot filter a query once a slice has been taken.\")",
        "raise TypeError(\"Cannot filter a query once a slice has been"
    ],
    [
        "Return a new QuerySet instance with filter_obj added to the filters.",
        "Return a new QuerySet instance with filter_obj added to"
    ],
    [
        "filter_obj can be a Q object or a dictionary of keyword lookup",
        "filter_obj can be a Q object or a"
    ],
    [
        "This exists to support framework features such as 'limit_choices_to',",
        "This exists to support framework features"
    ],
    [
        "and usually it will be more natural to use other methods.",
        "and usually it will be more natural to"
    ],
    [
        "qs = [q for q in other_qs if not isinstance(q, EmptyQuerySet)]",
        "qs = [q for q in other_qs"
    ],
    [
        "def select_for_update(self, nowait=False, skip_locked=False, of=(), no_key=False):",
        "def select_for_update(self, nowait=False, skip_locked=False,"
    ],
    [
        "Return a new QuerySet instance that will select objects with a",
        "Return a new QuerySet instance that"
    ],
    [
        "raise ValueError(\"The nowait option cannot be used with skip_locked.\")",
        "raise ValueError(\"The nowait option cannot"
    ],
    [
        "Return a new QuerySet instance that will select related objects.",
        "Return a new QuerySet instance that"
    ],
    [
        "If fields are specified, they must be ForeignKey fields and only those",
        "If fields are specified, they must be"
    ],
    [
        "related objects are included in the selection.",
        "related objects are included"
    ],
    [
        "If select_related(None) is called, clear the list.",
        "If select_related(None) is called, clear"
    ],
    [
        "\"Cannot call select_related() after .values() or .values_list()\"",
        "\"Cannot call select_related() after .values() or"
    ],
    [
        "Return a new QuerySet instance that will prefetch the specified",
        "Return a new QuerySet instance that will"
    ],
    [
        "Many-To-One and Many-To-Many related objects when the QuerySet is",
        "Many-To-One and Many-To-Many related objects when the"
    ],
    [
        "When prefetch_related() is called more than once, append to the list of",
        "When prefetch_related() is called more than once,"
    ],
    [
        "prefetch lookups. If prefetch_related(None) is called, clear the list.",
        "prefetch lookups. If prefetch_related(None) is called,"
    ],
    [
        "\"prefetch_related() is not supported with FilteredRelation.\"",
        "\"prefetch_related() is not"
    ],
    [
        "Return a query set in which the returned objects have been annotated",
        "Return a query set in which"
    ],
    [
        "Return a query set with added aliases for extra data or aggregations.",
        "Return a query set with added aliases for extra"
    ],
    [
        "\"The named annotation '%s' conflicts with the \"",
        "\"The named annotation '%s' conflicts with"
    ],
    [
        "\"default name for another annotation.\" % arg.default_alias",
        "\"default name for another"
    ],
    [
        "raise TypeError(\"Complex annotations require an alias\")",
        "raise TypeError(\"Complex annotations require an"
    ],
    [
        "\"The annotation '%s' conflicts with a field on \"",
        "\"The annotation '%s' conflicts with a field on"
    ],
    [
        "if alias in annotations and annotation.contains_aggregate:",
        "if alias in"
    ],
    [
        "\"\"\"Return a new QuerySet instance with the ordering changed.\"\"\"",
        "\"\"\"Return a new QuerySet instance"
    ],
    [
        "raise TypeError(\"Cannot reorder a query once a slice has been taken.\")",
        "raise TypeError(\"Cannot reorder a query once a slice has"
    ],
    [
        "Return a new QuerySet instance that will select only distinct results.",
        "Return a new QuerySet instance that will select only distinct"
    ],
    [
        "\"Cannot create distinct fields once a slice has been taken.\"",
        "\"Cannot create distinct fields once a slice"
    ],
    [
        "\"\"\"Add extra SQL fragments to the query.\"\"\"",
        "\"\"\"Add extra SQL fragments"
    ],
    [
        "raise TypeError(\"Cannot change a query once a slice has been taken.\")",
        "raise TypeError(\"Cannot change a query once a slice"
    ],
    [
        "clone.query.add_extra(select, select_params, where, params, tables, order_by)",
        "clone.query.add_extra(select, select_params, where, params, tables,"
    ],
    [
        "\"\"\"Reverse the ordering of the QuerySet.\"\"\"",
        "\"\"\"Reverse the ordering of"
    ],
    [
        "raise TypeError(\"Cannot reverse a query once a slice has been taken.\")",
        "raise TypeError(\"Cannot reverse a query once a slice"
    ],
    [
        "Defer the loading of data for certain fields until they are accessed.",
        "Defer the loading of data for certain fields"
    ],
    [
        "Add the set of deferred fields to any existing set of deferred fields.",
        "Add the set of deferred fields to any existing"
    ],
    [
        "The only exception to this is if None is passed in as the only",
        "The only exception to this is if None is passed"
    ],
    [
        "parameter, in which case remove all deferrals.",
        "parameter, in which case"
    ],
    [
        "raise TypeError(\"Cannot call defer() after .values() or .values_list()\")",
        "raise TypeError(\"Cannot call defer() after .values()"
    ],
    [
        "Essentially, the opposite of defer(). Only the fields passed into this",
        "Essentially, the opposite of defer(). Only the fields"
    ],
    [
        "method and that are not already specified as deferred are loaded",
        "method and that are not already specified as deferred"
    ],
    [
        "immediately when the queryset is evaluated.",
        "immediately when the"
    ],
    [
        "raise TypeError(\"Cannot call only() after .values() or .values_list()\")",
        "raise TypeError(\"Cannot call only() after"
    ],
    [
        "raise TypeError(\"Cannot pass None as an argument to only().\")",
        "raise TypeError(\"Cannot pass None as an argument to"
    ],
    [
        "raise ValueError(\"only() is not supported with FilteredRelation.\")",
        "raise ValueError(\"only() is not supported"
    ],
    [
        "\"\"\"Select which database this QuerySet should execute against.\"\"\"",
        "\"\"\"Select which database this QuerySet"
    ],
    [
        "Return True if the QuerySet is ordered -- i.e. has an order_by()",
        "Return True if the QuerySet is ordered -- i.e."
    ],
    [
        "clause or a default ordering on the model (or is empty).",
        "clause or a default ordering on the"
    ],
    [
        "\"\"\"Return the database used if this query is executed now.\"\"\"",
        "\"\"\"Return the database used if this query"
    ],
    [
        "Insert a new record for the given model. This provides an interface to",
        "Insert a new record for the given model. This provides"
    ],
    [
        "the InsertQuery class and is how Model.save() is implemented.",
        "the InsertQuery class and is how"
    ],
    [
        "Helper method for bulk_create() to insert objs one batch at a time.",
        "Helper method for bulk_create() to insert objs one"
    ],
    [
        "batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size",
        "batch_size = min(batch_size, max_batch_size) if batch_size else"
    ],
    [
        "on_conflict is None or on_conflict == OnConflict.UPDATE",
        "on_conflict is None or on_conflict =="
    ],
    [
        "Return a copy of the current QuerySet that's ready for another",
        "Return a copy of the current QuerySet"
    ],
    [
        "Return a copy of the current QuerySet. A lightweight alternative",
        "Return a copy of the"
    ],
    [
        "Indicate that the next filter call and the one following that should",
        "Indicate that the next filter call"
    ],
    [
        "be treated as a single filter. This is only important when it comes to",
        "be treated as a single filter. This is only important when it"
    ],
    [
        "determining when to reuse tables for many-to-many filters. Required so",
        "determining when to reuse tables for many-to-many filters."
    ],
    [
        "that we can filter naturally on the results of related managers.",
        "that we can filter naturally on the"
    ],
    [
        "This doesn't return a clone of the current QuerySet (it returns",
        "This doesn't return a clone of the current QuerySet (it"
    ],
    [
        "\"self\"). The method is only used internally and should be immediately",
        "\"self\"). The method is only used internally"
    ],
    [
        "followed by a filter() that does create a clone.",
        "followed by a filter() that does create a"
    ],
    [
        "\"\"\"Check that two QuerySet classes may be merged.\"\"\"",
        "\"\"\"Check that two QuerySet"
    ],
    [
        "if self._fields is not None and (",
        "if self._fields is not"
    ],
    [
        "\"Merging '%s' classes must involve the same values in each case.\"",
        "\"Merging '%s' classes must involve the same values in"
    ],
    [
        "Keep track of all known related objects from either QuerySet instance.",
        "Keep track of all known related objects from"
    ],
    [
        "Update hinting information for use by routers. Add new key/values or",
        "Update hinting information for use by routers. Add new key/values"
    ],
    [
        "Check if this QuerySet has any filtering going on. This isn't",
        "Check if this QuerySet has any"
    ],
    [
        "equivalent with checking if all objects are present in results, for",
        "equivalent with checking if all objects are present in"
    ],
    [
        "str(arg) for arg in values if not hasattr(arg, \"resolve_expression\")",
        "str(arg) for arg in values if not"
    ],
    [
        "\"Calling QuerySet.%s() after %s() is not supported.\"",
        "\"Calling QuerySet.%s() after %s() is not"
    ],
    [
        "raise TypeError(f\"Cannot use {operator_} operator with combined queryset.\")",
        "raise TypeError(f\"Cannot use {operator_} operator"
    ],
    [
        "if isinstance(self.query.group_by, tuple) and not any(",
        "if isinstance(self.query.group_by, tuple)"
    ],
    [
        "col.output_field is self.model._meta.pk for col in self.query.group_by",
        "col.output_field is self.model._meta.pk for col"
    ],
    [
        "f\"Cannot use QuerySet.{method}() on an unordered queryset performing \"",
        "f\"Cannot use QuerySet.{method}() on an"
    ],
    [
        "f\"aggregation. Add an ordering with order_by().\"",
        "f\"aggregation. Add an ordering"
    ],
    [
        "Marker class to checking if a queryset is empty by .none():",
        "Marker class to checking if a queryset"
    ],
    [
        "Provide an iterator which converts the results of raw SQL queries into",
        "Provide an iterator which converts the results of raw"
    ],
    [
        "self.query = query or sql.RawQuery(sql=raw_query, using=self.db, params=params)",
        "self.query = query or"
    ],
    [
        "\"\"\"Resolve the init field names and value positions.\"\"\"",
        "\"\"\"Resolve the init field"
    ],
    [
        "f for f in self.model._meta.fields if converter(f.column) in self.columns",
        "f for f in self.model._meta.fields if"
    ],
    [
        "model_init_names = [f.attname for f in model_init_fields]",
        "model_init_names = [f.attname for f in"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self.query)",
        "return \"<%s: %s>\" % (self.__class__.__name__,"
    ],
    [
        "\"\"\"Return the database used if this query is executed now.\"\"\"",
        "\"\"\"Return the database used if this"
    ],
    [
        "\"\"\"Select the database this RawQuerySet should execute against.\"\"\"",
        "\"\"\"Select the database this RawQuerySet should execute"
    ],
    [
        "A list of model field names in the order they'll appear in the",
        "A list of model field names in the order they'll appear"
    ],
    [
        "\"\"\"A dict mapping column names to model field names.\"\"\"",
        "\"\"\"A dict mapping column names"
    ],
    [
        "if queryset is not None and (",
        "if queryset is not"
    ],
    [
        "\"Prefetch querysets cannot use raw(), values(), and values_list().\"",
        "\"Prefetch querysets cannot use"
    ],
    [
        "self.prefetch_through = prefix + LOOKUP_SEP + self.prefetch_through",
        "self.prefetch_through = prefix + LOOKUP_SEP +"
    ],
    [
        "self.prefetch_to = prefix + LOOKUP_SEP + self.prefetch_to",
        "self.prefetch_to = prefix +"
    ],
    [
        "Populate prefetched object caches for a list of model instances based on",
        "Populate prefetched object caches for a list"
    ],
    [
        "\"'%s' lookup was already seen with a different queryset. \"",
        "\"'%s' lookup was already seen with a different"
    ],
    [
        "\"You may need to adjust the ordering of your lookups.\"",
        "\"You may need to adjust"
    ],
    [
        "prefetcher, descriptor, attr_found, is_fetched = get_prefetcher(",
        "prefetcher, descriptor, attr_found, is_fetched ="
    ],
    [
        "\"Cannot find '%s' on %s object, '%s' is an invalid \"",
        "\"Cannot find '%s' on %s object, '%s' is an"
    ],
    [
        "\"'%s' does not resolve to an item that supports \"",
        "\"'%s' does not resolve to"
    ],
    [
        "\"prefetching - this is an invalid parameter to \"",
        "\"prefetching - this is an invalid parameter"
    ],
    [
        "obj_to_fetch = [obj for obj in obj_list if not is_fetched(obj)]",
        "obj_to_fetch = [obj for obj in obj_list if"
    ],
    [
        "if through_attr in getattr(obj, \"_prefetched_objects_cache\", ()):",
        "if through_attr in getattr(obj, \"_prefetched_objects_cache\","
    ],
    [
        "For the attribute 'through_attr' on the given instance, find",
        "For the attribute 'through_attr' on the given instance,"
    ],
    [
        "an object that has a get_prefetch_querysets().",
        "an object that has"
    ],
    [
        "(the object with get_prefetch_querysets (or None),",
        "(the object with get_prefetch_querysets"
    ],
    [
        "the descriptor object representing this relationship (or None),",
        "the descriptor object representing this relationship"
    ],
    [
        "a boolean that is False if the attribute was not found at all,",
        "a boolean that is False if the attribute was"
    ],
    [
        "a function that takes an instance and returns a boolean that is True if",
        "a function that takes an instance and returns a boolean"
    ],
    [
        "the attribute has already been fetched for that instance)",
        "the attribute has already been"
    ],
    [
        "Run prefetches on all instances using the prefetcher object,",
        "Run prefetches on all instances using the"
    ],
    [
        "assigning results to relevant caches in instance.",
        "assigning results to relevant caches in"
    ],
    [
        "Return the prefetched objects along with any additional prefetches that",
        "Return the prefetched objects along"
    ],
    [
        "must be done due to prefetch_related lookups found from default managers.",
        "must be done due to prefetch_related"
    ],
    [
        "for additional_lookup in getattr(rel_qs, \"_prefetch_related_lookups\", ())",
        "for additional_lookup in"
    ],
    [
        "msg = \"to_attr={} conflicts with a field on the {} model.\"",
        "msg = \"to_attr={} conflicts with a"
    ],
    [
        "if leaf and lookup.queryset is not None:",
        "if leaf and lookup.queryset is not"
    ],
    [
        "RelatedPopulator is used for select_related() object instantiation.",
        "RelatedPopulator is used for select_related() object"
    ],
    [
        "The idea is that each select_related() model will be populated by a",
        "The idea is that each select_related() model will be populated by"
    ],
    [
        "different RelatedPopulator instance. The RelatedPopulator instances get",
        "different RelatedPopulator instance. The"
    ],
    [
        "klass_info and select (computed in SQLCompiler) plus the used db as",
        "klass_info and select (computed in SQLCompiler) plus the"
    ],
    [
        "input for initialization. That data is used to compute which columns",
        "input for initialization. That data is used to"
    ],
    [
        "to use, how to instantiate the model, and how to populate the links",
        "to use, how to instantiate the model, and how"
    ],
    [
        "The actual creation of the objects is done in populate() method. This",
        "The actual creation of the objects"
    ],
    [
        "method gets row and from_obj as input and populates the select_related()",
        "method gets row and from_obj as input"
    ],
    [
        "attname for attname in model_init_attnames if attname in attname_indexes",
        "attname for attname in model_init_attnames if attname"
    ],
    [
        "Constants used across the ORM in general.",
        "Constants used across the ORM"
    ],
    [
        "from django.core.exceptions import EmptyResultSet, FieldError, FullResultSet",
        "from django.core.exceptions import EmptyResultSet,"
    ],
    [
        "from django.db import DatabaseError, NotSupportedError, connection",
        "from django.db import DatabaseError,"
    ],
    [
        "Some expressions with output_field=DecimalField() must be cast to",
        "Some expressions with output_field=DecimalField() must"
    ],
    [
        "sql, params = self.as_sql(compiler, connection, **extra_context)",
        "sql, params = self.as_sql(compiler, connection,"
    ],
    [
        "sql = \"(CAST(%s AS NUMERIC))\" % sql",
        "sql = \"(CAST(%s AS"
    ],
    [
        "Provide the ability to combine one or two objects with",
        "Provide the ability to combine one or two objects"
    ],
    [
        "some connector. For example F('foo') + F('bar').",
        "some connector. For example F('foo') +"
    ],
    [
        "if getattr(self, \"conditional\", False) and getattr(other, \"conditional\", False):",
        "if getattr(self, \"conditional\", False) and getattr(other,"
    ],
    [
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise logical operations.\"",
        "\"Use .bitand(), .bitor(), and .bitxor()"
    ],
    [
        "if getattr(self, \"conditional\", False) and getattr(other, \"conditional\", False):",
        "if getattr(self, \"conditional\", False) and getattr(other, \"conditional\","
    ],
    [
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise logical operations.\"",
        "\"Use .bitand(), .bitor(), and .bitxor() for"
    ],
    [
        "if getattr(self, \"conditional\", False) and getattr(other, \"conditional\", False):",
        "if getattr(self, \"conditional\", False) and"
    ],
    [
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise logical operations.\"",
        "\"Use .bitand(), .bitor(), and .bitxor()"
    ],
    [
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise logical operations.\"",
        "\"Use .bitand(), .bitor(), and .bitxor() for"
    ],
    [
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise logical operations.\"",
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise"
    ],
    [
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise logical operations.\"",
        "\"Use .bitand(), .bitor(), and .bitxor() for bitwise logical"
    ],
    [
        "\"\"\"Base class for all query expressions.\"\"\"",
        "\"\"\"Base class for"
    ],
    [
        "else (F(arg) if isinstance(arg, str) else Value(arg))",
        "else (F(arg) if isinstance(arg, str) else"
    ],
    [
        "Responsible for returning a (sql, [params]) tuple to be included",
        "Responsible for returning a (sql, [params]) tuple to"
    ],
    [
        "Different backends can provide their own implementation, by",
        "Different backends can provide"
    ],
    [
        "providing an `as_{vendor}` method and patching the Expression:",
        "providing an `as_{vendor}` method and"
    ],
    [
        "* compiler: the query compiler responsible for generating the query.",
        "* compiler: the query compiler"
    ],
    [
        "Must have a compile method, returning a (sql, [params]) tuple.",
        "Must have a compile method, returning a"
    ],
    [
        "Calling compiler(value) will return a quoted `value`.",
        "Calling compiler(value) will return a quoted"
    ],
    [
        "* connection: the database connection used for the current query.",
        "* connection: the database connection used"
    ],
    [
        "Where `sql` is a string containing ordered sql parameters to be",
        "Where `sql` is a string containing ordered sql parameters"
    ],
    [
        "replaced with the elements of the list `params`.",
        "replaced with the elements"
    ],
    [
        "expr and expr.contains_aggregate for expr in self.get_source_expressions()",
        "expr and expr.contains_aggregate for"
    ],
    [
        "expr and expr.contains_over_clause for expr in self.get_source_expressions()",
        "expr and expr.contains_over_clause for expr"
    ],
    [
        "expr and (getattr(expr, \"subquery\", False) or expr.contains_subquery)",
        "expr and (getattr(expr, \"subquery\","
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None, summarize=False,"
    ],
    [
        "Provide the chance to do any preprocessing or validation before being",
        "Provide the chance to do any preprocessing or validation"
    ],
    [
        "* query: the backend query implementation",
        "* query: the backend query"
    ],
    [
        "* allow_joins: boolean allowing or denying use of joins",
        "* allow_joins: boolean allowing or"
    ],
    [
        "* reuse: a set of reusable joins for multijoins",
        "* reuse: a set of reusable joins"
    ],
    [
        "* summarize: a terminal aggregate clause",
        "* summarize: a terminal"
    ],
    [
        "* for_save: whether this expression about to be used in a save or update",
        "* for_save: whether this expression about to"
    ],
    [
        "Return: an Expression to be added to the query.",
        "Return: an Expression to be added to the"
    ],
    [
        "isinstance(expr, ColPairs) for expr in source_expressions",
        "isinstance(expr, ColPairs) for"
    ],
    [
        "f\"{self.__class__.__name__} expression does not support \"",
        "f\"{self.__class__.__name__} expression does"
    ],
    [
        "\"\"\"Return the output type of this expressions.\"\"\"",
        "\"\"\"Return the output type of this"
    ],
    [
        "\"Cannot resolve expression type, unknown output_field\"",
        "\"Cannot resolve expression"
    ],
    [
        "Return the output field of this expression, or None if",
        "Return the output field of this expression, or None"
    ],
    [
        "_resolve_output_field() didn't return an output type.",
        "_resolve_output_field() didn't return an"
    ],
    [
        "Attempt to infer the output type of the expression.",
        "Attempt to infer the output"
    ],
    [
        "As a guess, if the output fields of all source fields match then simply",
        "As a guess, if the output fields of all source fields"
    ],
    [
        "If a source's output field resolves to None, exclude it from this check.",
        "If a source's output field resolves to None,"
    ],
    [
        "If all sources are None, then an error is raised higher up the stack in",
        "If all sources are None, then an error"
    ],
    [
        "source for source in self.get_source_fields() if source is not None",
        "source for source in self.get_source_fields() if source is not"
    ],
    [
        "\"Expression contains mixed types: %s, %s. You must \"",
        "\"Expression contains mixed types: %s, %s. You must"
    ],
    [
        "Expressions provide their own converters because users have the option",
        "Expressions provide their own converters because"
    ],
    [
        "of manually specifying the output_field which may be a different type",
        "of manually specifying the output_field which may be a different"
    ],
    [
        "from the one the database returns.",
        "from the one the"
    ],
    [
        "return lambda value, expression, connection: (",
        "return lambda value, expression, connection:"
    ],
    [
        "None if value is None else float(value)",
        "None if value is"
    ],
    [
        "return lambda value, expression, connection: (",
        "return lambda value, expression, connection:"
    ],
    [
        "None if value is None else int(value)",
        "None if value is None"
    ],
    [
        "return lambda value, expression, connection: (",
        "return lambda value, expression, connection:"
    ],
    [
        "None if value is None else Decimal(value)",
        "None if value is None else"
    ],
    [
        "e.relabeled_clone(change_map) if e is not None else None",
        "e.relabeled_clone(change_map) if e is"
    ],
    [
        "\"\"\"Return the underlying field types used by this aggregate.\"\"\"",
        "\"\"\"Return the underlying field types used by this"
    ],
    [
        "return [e._output_field_or_none for e in self.get_source_expressions()]",
        "return [e._output_field_or_none for"
    ],
    [
        "Recursively yield this expression and all subexpressions, in",
        "Recursively yield this expression and all subexpressions,"
    ],
    [
        "Custom format for select clauses. For example, EXISTS expressions need",
        "Custom format for select clauses. For"
    ],
    [
        "to be wrapped in CASE WHEN on Oracle.",
        "to be wrapped in"
    ],
    [
        "\"Expressions with constraint_validation_compatible set to False \"",
        "\"Expressions with constraint_validation_compatible set to"
    ],
    [
        "\"must have only one source expression.\"",
        "\"must have only one source"
    ],
    [
        "\"\"\"An expression that can be combined with other expressions.\"\"\"",
        "\"\"\"An expression that can be combined with"
    ],
    [
        "[(field_type, NoneType, field_type), (NoneType, field_type, field_type)]",
        "[(field_type, NoneType, field_type), (NoneType, field_type,"
    ],
    [
        "for lhs, rhs, result in field_types:",
        "for lhs, rhs, result"
    ],
    [
        "for combinator_lhs_type, combinator_rhs_type, combined_type in combinators:",
        "for combinator_lhs_type, combinator_rhs_type,"
    ],
    [
        "def __init__(self, lhs, connector, rhs, output_field=None):",
        "def __init__(self, lhs, connector,"
    ],
    [
        "return \"{} {} {}\".format(self.lhs, self.connector, self.rhs)",
        "return \"{} {} {}\".format(self.lhs,"
    ],
    [
        "f\"Cannot infer type of {self.connector!r} expression involving these \"",
        "f\"Cannot infer type of {self.connector!r} expression involving"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None,"
    ],
    [
        "if \"DurationField\" in {lhs_type, rhs_type} and lhs_type != rhs_type:",
        "if \"DurationField\" in {lhs_type, rhs_type}"
    ],
    [
        "sql, params = self.compile(self.lhs, compiler, connection)",
        "sql, params = self.compile(self.lhs,"
    ],
    [
        "sql, params = self.compile(self.rhs, compiler, connection)",
        "sql, params = self.compile(self.rhs,"
    ],
    [
        "sql, params = self.as_sql(compiler, connection, **extra_context)",
        "sql, params ="
    ],
    [
        "if lhs_type not in allowed_fields or rhs_type not in allowed_fields:",
        "if lhs_type not in allowed_fields or rhs_type"
    ],
    [
        "\"\"\"An object capable of resolving references to existing query objects.\"\"\"",
        "\"\"\"An object capable of resolving references to existing query"
    ],
    [
        "* name: the name of the field this expression references",
        "* name: the name of the field this"
    ],
    [
        "raise TypeError(f\"argument of type '{self.__class__.__name__}' is not iterable\")",
        "raise TypeError(f\"argument of type '{self.__class__.__name__}' is"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None, summarize=False,"
    ],
    [
        "return self.__class__ == other.__class__ and self.name == other.name",
        "return self.__class__ == other.__class__ and self.name =="
    ],
    [
        "An object that contains a reference to an outer query.",
        "An object that contains a reference to an"
    ],
    [
        "In this case, the reference to the outer query has been resolved because",
        "In this case, the reference to the outer"
    ],
    [
        "the inner query has been used as a subquery.",
        "the inner query has been used"
    ],
    [
        "\"This queryset contains a reference to an outer query and may \"",
        "\"This queryset contains a reference to an outer"
    ],
    [
        "\"only be used in a subquery.\"",
        "\"only be used"
    ],
    [
        "f\"Referencing outer query window expression is not supported: \"",
        "f\"Referencing outer query window expression"
    ],
    [
        "An object that contains a slice of an F expression.",
        "An object that contains a slice of"
    ],
    [
        "Object resolves the column on which the slicing is applied, and then",
        "Object resolves the column on which the slicing is applied,"
    ],
    [
        "raise ValueError(\"Negative indexing is not supported.\")",
        "raise ValueError(\"Negative indexing is"
    ],
    [
        "raise ValueError(\"Negative indexing is not supported.\")",
        "raise ValueError(\"Negative indexing"
    ],
    [
        "raise ValueError(\"Step argument is not supported.\")",
        "raise ValueError(\"Step argument"
    ],
    [
        "if subscript.stop and subscript.start and subscript.stop < subscript.start:",
        "if subscript.stop and subscript.start and subscript.stop"
    ],
    [
        "raise ValueError(\"Slice stop must be greater than slice start.\")",
        "raise ValueError(\"Slice stop must be greater than slice"
    ],
    [
        "raise TypeError(\"Argument to slice must be either int or slice instance.\")",
        "raise TypeError(\"Argument to slice must be either int or slice"
    ],
    [
        "stop = None if self.length is None else start + self.length",
        "stop = None if self.length is"
    ],
    [
        "resolved = query.resolve_ref(self.name, allow_joins, reuse, summarize)",
        "resolved = query.resolve_ref(self.name, allow_joins,"
    ],
    [
        "if self.arity is not None and len(expressions) != self.arity:",
        "if self.arity is not None"
    ],
    [
        "\"'%s' takes exactly %s %s (%s given)\"",
        "\"'%s' takes exactly %s %s (%s"
    ],
    [
        "args = self.arg_joiner.join(str(arg) for arg in self.source_expressions)",
        "args = self.arg_joiner.join(str(arg) for arg in"
    ],
    [
        "str(key) + \"=\" + str(val) for key, val in sorted(extra.items())",
        "str(key) + \"=\" + str(val) for key, val in"
    ],
    [
        "\"\"\"Return a dict of extra __init__() options to include in the repr.\"\"\"",
        "\"\"\"Return a dict of extra __init__() options to"
    ],
    [
        "template = template or data.get(\"template\", self.template)",
        "template = template"
    ],
    [
        "arg_joiner = arg_joiner or data.get(\"arg_joiner\", self.arg_joiner)",
        "arg_joiner = arg_joiner or"
    ],
    [
        "return all(expression.allowed_default for expression in self.source_expressions)",
        "return all(expression.allowed_default for expression in"
    ],
    [
        "\"\"\"Represent a wrapped value as a node within an expression.\"\"\"",
        "\"\"\"Represent a wrapped value as"
    ],
    [
        "* value: the value this expression represents. The value will be",
        "* value: the value this expression represents. The value"
    ],
    [
        "added into the sql parameter list and properly quoted.",
        "added into the sql parameter list and"
    ],
    [
        "* output_field: an instance of the model field type that this",
        "* output_field: an instance of the model field type"
    ],
    [
        "expression will return, such as IntegerField() or CharField().",
        "expression will return, such as IntegerField()"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None,"
    ],
    [
        "c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)",
        "c = super().resolve_expression(query, allow_joins, reuse, summarize,"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None,"
    ],
    [
        "Expression to use DEFAULT keyword during insert otherwise the underlying expression.",
        "Expression to use DEFAULT keyword during"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None,"
    ],
    [
        "identifiers = (alias, str(target)) if alias else (str(target),)",
        "identifiers = (alias, str(target))"
    ],
    [
        "identifiers = (alias, column) if alias else (column,)",
        "identifiers = (alias, column) if alias else"
    ],
    [
        "def __init__(self, alias, targets, sources, output_field):",
        "def __init__(self, alias, targets, sources,"
    ],
    [
        "for target, source in zip(self.targets, self.sources)",
        "for target, source"
    ],
    [
        "assert all(isinstance(expr, Col) and expr.alias == self.alias for expr in exprs)",
        "assert all(isinstance(expr, Col) and expr.alias == self.alias"
    ],
    [
        "self.targets = [col.target for col in exprs]",
        "self.targets = [col.target for col in"
    ],
    [
        "self.sources = [col.field for col in exprs]",
        "self.sources = [col.field for"
    ],
    [
        "Reference to column alias of the query. For example, Ref('sum_cost') in",
        "Reference to column alias of the query. For example,"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None, summarize=False,"
    ],
    [
        "An expression containing multiple expressions. Can be used to provide a",
        "An expression containing multiple expressions. Can be"
    ],
    [
        "list of expressions as an argument to another expression, like a partition",
        "list of expressions as an argument"
    ],
    [
        "return self.arg_joiner.join(str(arg) for arg in self.source_expressions)",
        "return self.arg_joiner.join(str(arg) for arg"
    ],
    [
        "An expression that can wrap another expression so that it can provide",
        "An expression that can wrap another expression so that"
    ],
    [
        "extra context to the inner expression, such as the output_field.",
        "extra context to the inner expression, such"
    ],
    [
        "\"\"\"The logical negation of a conditional expression.\"\"\"",
        "\"\"\"The logical negation of a conditional"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None, summarize=False,"
    ],
    [
        "template = \"WHEN %(condition)s THEN %(result)s\"",
        "template = \"WHEN %(condition)s THEN"
    ],
    [
        "condition, lookups = Q(condition, **lookups), None",
        "condition, lookups = Q(condition,"
    ],
    [
        "if condition is None or not getattr(condition, \"conditional\", False) or lookups:",
        "if condition is None or not getattr(condition, \"conditional\", False) or"
    ],
    [
        "\"When() supports a Q object, a boolean expression, or lookups \"",
        "\"When() supports a Q object, a"
    ],
    [
        "if isinstance(condition, Q) and not condition:",
        "if isinstance(condition, Q) and"
    ],
    [
        "raise ValueError(\"An empty Q() can't be used as a When() condition.\")",
        "raise ValueError(\"An empty Q() can't be"
    ],
    [
        "return \"WHEN %r THEN %r\" % (self.condition, self.result)",
        "return \"WHEN %r THEN %r\""
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self)",
        "return \"<%s: %s>\" % (self.__class__.__name__,"
    ],
    [
        "def as_sql(self, compiler, connection, template=None, **extra_context):",
        "def as_sql(self, compiler,"
    ],
    [
        "template = \"CASE %(cases)s ELSE %(default)s END\"",
        "template = \"CASE %(cases)s"
    ],
    [
        "def __init__(self, *cases, default=None, output_field=None, **extra):",
        "def __init__(self, *cases, default=None,"
    ],
    [
        "if not all(isinstance(case, When) for case in cases):",
        "if not all(isinstance(case, When) for case in"
    ],
    [
        "raise TypeError(\"Positional arguments must all be When objects.\")",
        "raise TypeError(\"Positional arguments must all be"
    ],
    [
        "return \"CASE %s, ELSE %r\" % (",
        "return \"CASE %s, ELSE %r\""
    ],
    [
        "\", \".join(str(c) for c in self.cases),",
        "\", \".join(str(c) for c"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self)",
        "return \"<%s: %s>\" %"
    ],
    [
        "self, compiler, connection, template=None, case_joiner=None, **extra_context",
        "self, compiler, connection, template=None, case_joiner=None,"
    ],
    [
        "template = template or template_params.get(\"template\", self.template)",
        "template = template or template_params.get(\"template\","
    ],
    [
        "An explicit subquery. It may contain OuterRef() references to the outer",
        "An explicit subquery. It may contain"
    ],
    [
        "query which will be resolved when it is applied to that query.",
        "query which will be resolved when it is applied to"
    ],
    [
        "def as_sql(self, compiler, connection, template=None, **extra_context):",
        "def as_sql(self, compiler, connection,"
    ],
    [
        "template = template or template_params.get(\"template\", self.template)",
        "template = template or"
    ],
    [
        "def __init__(self, expression, descending=False, nulls_first=None, nulls_last=None):",
        "def __init__(self, expression, descending=False,"
    ],
    [
        "raise ValueError(\"nulls_first and nulls_last are mutually exclusive\")",
        "raise ValueError(\"nulls_first and nulls_last are mutually"
    ],
    [
        "if nulls_first is False or nulls_last is False:",
        "if nulls_first is False or nulls_last is"
    ],
    [
        "raise ValueError(\"nulls_first and nulls_last values must be True or None.\")",
        "raise ValueError(\"nulls_first and nulls_last values must be True or"
    ],
    [
        "raise ValueError(\"expression must be an expression type\")",
        "raise ValueError(\"expression must be an expression"
    ],
    [
        "def as_sql(self, compiler, connection, template=None, **extra_context):",
        "def as_sql(self, compiler, connection,"
    ],
    [
        "template = \"%s NULLS LAST\" % template",
        "template = \"%s NULLS LAST\""
    ],
    [
        "template = \"%s NULLS FIRST\" % template",
        "template = \"%s NULLS"
    ],
    [
        "template = \"%%(expression)s IS NULL, %s\" % template",
        "template = \"%%(expression)s IS NULL, %s\""
    ],
    [
        "template = \"%%(expression)s IS NOT NULL, %s\" % template",
        "template = \"%%(expression)s IS NOT NULL, %s\""
    ],
    [
        "\"ordering\": \"DESC\" if self.descending else \"ASC\",",
        "\"ordering\": \"DESC\" if self.descending else"
    ],
    [
        "\"Expression '%s' isn't compatible with OVER clauses.\"",
        "\"Expression '%s' isn't compatible with OVER"
    ],
    [
        "\"Window.order_by must be either a string reference to a \"",
        "\"Window.order_by must be either a"
    ],
    [
        "\"field, an expression, or a list or tuple of them.\"",
        "\"field, an expression, or a list or"
    ],
    [
        "self.source_expression, self.partition_by, self.order_by, self.frame = exprs",
        "self.source_expression, self.partition_by, self.order_by, self.frame ="
    ],
    [
        "raise NotSupportedError(\"This backend does not support window expressions.\")",
        "raise NotSupportedError(\"This backend does not support window"
    ],
    [
        "template % {\"expression\": expr_sql, \"window\": \" \".join(window_sql).strip()},",
        "template % {\"expression\": expr_sql,"
    ],
    [
        "\"PARTITION BY \" + str(self.partition_by) if self.partition_by else \"\",",
        "\"PARTITION BY \" + str(self.partition_by) if"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self)",
        "return \"<%s: %s>\""
    ],
    [
        "Model the frame clause in window expressions. There are two types of frame",
        "Model the frame clause in window expressions. There are two types"
    ],
    [
        "clauses which are subclasses, however, all processing and validation (by no",
        "clauses which are subclasses, however, all"
    ],
    [
        "means intended to be complete) is done here. Thus, providing an end for a",
        "means intended to be complete) is done here. Thus, providing"
    ],
    [
        "frame is optional (the default is UNBOUNDED FOLLOWING, which is the last",
        "frame is optional (the default is UNBOUNDED FOLLOWING, which is the"
    ],
    [
        "template = \"%(frame_type)s BETWEEN %(start)s AND %(end)s%(exclude)s\"",
        "template = \"%(frame_type)s BETWEEN %(start)s AND"
    ],
    [
        "\"This backend does not support window frame exclusions.\"",
        "\"This backend does not"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self)",
        "return \"<%s: %s>\" % (self.__class__.__name__,"
    ],
    [
        "start = \"%d %s\" % (abs(self.start.value), connection.ops.PRECEDING)",
        "start = \"%d %s\" % (abs(self.start.value),"
    ],
    [
        "start = \"%d %s\" % (self.start.value, connection.ops.FOLLOWING)",
        "start = \"%d %s\" % (self.start.value,"
    ],
    [
        "end = \"%d %s\" % (self.end.value, connection.ops.FOLLOWING)",
        "end = \"%d %s\" %"
    ],
    [
        "end = \"%d %s\" % (abs(self.end.value), connection.ops.PRECEDING)",
        "end = \"%d %s\""
    ],
    [
        "from django.db.models.aggregates import __all__ as aggregates_all",
        "from django.db.models.aggregates import __all__"
    ],
    [
        "from django.db.models.constraints import __all__ as constraints_all",
        "from django.db.models.constraints import __all__ as"
    ],
    [
        "from django.db.models.enums import __all__ as enums_all",
        "from django.db.models.enums import __all__"
    ],
    [
        "from django.db.models.fields import __all__ as fields_all",
        "from django.db.models.fields import"
    ],
    [
        "from django.db.models.indexes import __all__ as indexes_all",
        "from django.db.models.indexes import __all__ as"
    ],
    [
        "__all__ = aggregates_all + constraints_all + enums_all + fields_all + indexes_all",
        "__all__ = aggregates_all + constraints_all +"
    ],
    [
        "\"Bilateral transformations on nested querysets are not implemented.\"",
        "\"Bilateral transformations on nested"
    ],
    [
        "sqls, sqls_params = [\"%s\"] * len(params), params",
        "sqls, sqls_params = [\"%s\"] * len(params),"
    ],
    [
        "if not self.prepare_rhs or hasattr(self.rhs, \"resolve_expression\"):",
        "if not self.prepare_rhs"
    ],
    [
        "\"CompositePrimaryKey cannot be used as a lookup value.\"",
        "\"CompositePrimaryKey cannot be used as a lookup"
    ],
    [
        "lookup = type(self)(*exprs) if wrapped else self",
        "lookup = type(self)(*exprs) if"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None, summarize=False,"
    ],
    [
        "RegisterLookupMixin() is first so that get_lookup() and get_transform()",
        "RegisterLookupMixin() is first so that get_lookup()"
    ],
    [
        "first examine self and then check output_field.",
        "first examine self and then"
    ],
    [
        "lhs_sql, params = super().process_lhs(compiler, connection, lhs)",
        "lhs_sql, params ="
    ],
    [
        "return \"%s %s\" % (lhs_sql, rhs_sql), params",
        "return \"%s %s\" % (lhs_sql, rhs_sql),"
    ],
    [
        "Some lookups require Field.get_db_prep_value() to be called on their",
        "Some lookups require Field.get_db_prep_value() to be called on"
    ],
    [
        "Some lookups require Field.get_db_prep_value() to be called on each value",
        "Some lookups require Field.get_db_prep_value() to be called on each"
    ],
    [
        "def resolve_expression_parameter(self, compiler, connection, sql, param):",
        "def resolve_expression_parameter(self, compiler, connection,"
    ],
    [
        "\"\"\"Lookup defined by operators on PostgreSQL.\"\"\"",
        "\"\"\"Lookup defined by"
    ],
    [
        "return \"%s %s %s\" % (lhs, self.postgres_operator, rhs), params",
        "return \"%s %s %s\" % (lhs, self.postgres_operator, rhs),"
    ],
    [
        "\"The QuerySet value for an exact lookup must be limited to \"",
        "\"The QuerySet value for an exact lookup must be"
    ],
    [
        "if (rhs_len := query._subquery_fields_len) != lhs_len:",
        "if (rhs_len :="
    ],
    [
        "f\"The QuerySet value for the exact lookup must have {lhs_len} \"",
        "f\"The QuerySet value for the exact lookup must have {lhs_len}"
    ],
    [
        "template = \"%s\" if self.rhs else \"NOT %s\"",
        "template = \"%s\" if self.rhs else"
    ],
    [
        "if min_value is not None and rhs < min_value:",
        "if min_value is not None and rhs"
    ],
    [
        "if max_value is not None and rhs > max_value:",
        "if max_value is not None and rhs >"
    ],
    [
        "Allow floats to work as query values for IntegerField. Without this, the",
        "Allow floats to work as query values"
    ],
    [
        "decimal portion of the float would always be discarded.",
        "decimal portion of the float would always"
    ],
    [
        "if (rhs_len := self.rhs._subquery_fields_len) != lhs_len:",
        "if (rhs_len := self.rhs._subquery_fields_len)"
    ],
    [
        "f\"The QuerySet value for the 'in' lookup must have {lhs_len} \"",
        "f\"The QuerySet value for the 'in' lookup"
    ],
    [
        "if db_rhs is not None and db_rhs != connection.alias:",
        "if db_rhs is not None and db_rhs"
    ],
    [
        "\"Subqueries aren't allowed across different databases. Force \"",
        "\"Subqueries aren't allowed across different databases. Force"
    ],
    [
        "\"the inner query to be evaluated using `list(inner_query)`.\"",
        "\"the inner query to"
    ],
    [
        "rhs = [r for r in self.rhs if r is not None]",
        "rhs = [r for r in self.rhs if"
    ],
    [
        "sqls, sqls_params = self.batch_process_rhs(compiler, connection, rhs)",
        "sqls, sqls_params = self.batch_process_rhs(compiler, connection,"
    ],
    [
        "placeholder = \"(\" + \", \".join(sqls) + \")\"",
        "placeholder = \"(\" + \", \".join(sqls)"
    ],
    [
        "sqls = rhs[offset : offset + max_in_list_size]",
        "sqls = rhs[offset : offset +"
    ],
    [
        "sqls_params = rhs_params[offset : offset + max_in_list_size]",
        "sqls_params = rhs_params[offset : offset"
    ],
    [
        "if self.rhs_is_direct_value() and params and not self.bilateral_transforms:",
        "if self.rhs_is_direct_value() and params"
    ],
    [
        "\"The QuerySet value for an isnull lookup must be True or False.\"",
        "\"The QuerySet value for an isnull"
    ],
    [
        "if self.lhs.value is None or (",
        "if self.lhs.value is"
    ],
    [
        "result_exception = FullResultSet if self.rhs else EmptyResultSet",
        "result_exception = FullResultSet if self.rhs"
    ],
    [
        "result_exception = EmptyResultSet if self.rhs else FullResultSet",
        "result_exception = EmptyResultSet if"
    ],
    [
        "return \"%s IS NULL\" % sql, params",
        "return \"%s IS NULL\" % sql,"
    ],
    [
        "return \"%s IS NOT NULL\" % sql, params",
        "return \"%s IS NOT"
    ],
    [
        "return sql_template % (lhs, rhs), lhs_params + rhs_params",
        "return sql_template % (lhs, rhs), lhs_params +"
    ],
    [
        "lhs_sql, params = self.process_lhs(compiler, connection, self.lhs.lhs)",
        "lhs_sql, params = self.process_lhs(compiler,"
    ],
    [
        "return \"%s %s\" % (lhs_sql, rhs_sql), params",
        "return \"%s %s\" % (lhs_sql, rhs_sql),"
    ],
    [
        "\"subclasses of YearLookup must provide a get_bound_params() method\"",
        "\"subclasses of YearLookup must provide a get_bound_params()"
    ],
    [
        "Strip hyphens from a value when filtering a UUIDField on backends without",
        "Strip hyphens from a value when filtering a UUIDField"
    ],
    [
        "from django.db.models.expressions import Col, ExpressionList, F, Func, OrderBy",
        "from django.db.models.expressions import Col, ExpressionList, F, Func,"
    ],
    [
        "raise ValueError(\"An index must be named to use opclasses.\")",
        "raise ValueError(\"An index must be named to"
    ],
    [
        "raise ValueError(\"Index.condition must be a Q instance.\")",
        "raise ValueError(\"Index.condition must be a Q"
    ],
    [
        "raise ValueError(\"An index must be named to use condition.\")",
        "raise ValueError(\"An index must be named to use"
    ],
    [
        "raise ValueError(\"Index.fields must be a list or tuple.\")",
        "raise ValueError(\"Index.fields must be"
    ],
    [
        "raise ValueError(\"Index.opclasses must be a list or tuple.\")",
        "raise ValueError(\"Index.opclasses must be a list or"
    ],
    [
        "if not expressions and not fields:",
        "if not expressions"
    ],
    [
        "\"At least one field or expression is required to define an index.\"",
        "\"At least one field or expression is"
    ],
    [
        "\"Index.fields and expressions are mutually exclusive.\",",
        "\"Index.fields and expressions"
    ],
    [
        "raise ValueError(\"An index must be named to use expressions.\")",
        "raise ValueError(\"An index must be"
    ],
    [
        "\"Index.opclasses cannot be used with expressions. Use \"",
        "\"Index.opclasses cannot be used with"
    ],
    [
        "if opclasses and len(fields) != len(opclasses):",
        "if opclasses and"
    ],
    [
        "\"Index.fields and Index.opclasses must have the same number of \"",
        "\"Index.fields and Index.opclasses must have the same number of"
    ],
    [
        "if fields and not all(isinstance(field, str) for field in fields):",
        "if fields and not all(isinstance(field, str)"
    ],
    [
        "raise ValueError(\"Index.fields must contain only strings with field names.\")",
        "raise ValueError(\"Index.fields must contain only strings with field"
    ],
    [
        "raise ValueError(\"A covering index must be named.\")",
        "raise ValueError(\"A covering index must be"
    ],
    [
        "if not isinstance(include, (NoneType, list, tuple)):",
        "if not isinstance(include, (NoneType,"
    ],
    [
        "raise ValueError(\"Index.include must be a list or tuple.\")",
        "raise ValueError(\"Index.include must be a"
    ],
    [
        "(field_name.removeprefix(\"-\"), \"DESC\" if field_name.startswith(\"-\") else \"\")",
        "(field_name.removeprefix(\"-\"), \"DESC\" if"
    ],
    [
        "self.include = tuple(include) if include else ()",
        "self.include = tuple(include) if include else"
    ],
    [
        "F(expression) if isinstance(expression, str) else expression",
        "F(expression) if isinstance(expression, str)"
    ],
    [
        "return sql % tuple(schema_editor.quote_value(p) for p in params)",
        "return sql % tuple(schema_editor.quote_value(p) for"
    ],
    [
        "def create_sql(self, model, schema_editor, using=\"\", **kwargs):",
        "def create_sql(self, model, schema_editor,"
    ],
    [
        "path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)",
        "path = \"%s.%s\" % (self.__class__.__module__,"
    ],
    [
        "\"\"\"Create a copy of this Index.\"\"\"",
        "\"\"\"Create a copy of this"
    ],
    [
        "Generate a unique name for the index.",
        "Generate a unique name for"
    ],
    [
        "fit its size by truncating the excess length.",
        "fit its size by truncating the"
    ],
    [
        "((\"-%s\" if order else \"%s\") % column_name)",
        "((\"-%s\" if order else \"%s\") %"
    ],
    [
        "for column_name, (field_name, order) in zip(",
        "for column_name, (field_name, order) in"
    ],
    [
        "hash_data = [table_name] + column_names_with_order + [self.suffix]",
        "hash_data = [table_name] +"
    ],
    [
        "\"Index too long for multiple database support. Is self.suffix \"",
        "\"Index too long for multiple"
    ],
    [
        "\"\" if not self.fields else \" fields=%s\" % repr(self.fields),",
        "\"\" if not self.fields else"
    ],
    [
        "\"\" if not self.expressions else \" expressions=%s\" % repr(self.expressions),",
        "\"\" if not self.expressions else \" expressions=%s\" %"
    ],
    [
        "\"\" if not self.name else \" name=%s\" % repr(self.name),",
        "\"\" if not self.name else \" name=%s\""
    ],
    [
        "\"\" if self.condition is None else \" condition=%s\" % self.condition,",
        "\"\" if self.condition is None"
    ],
    [
        "\"\" if not self.include else \" include=%s\" % repr(self.include),",
        "\"\" if not self.include else \""
    ],
    [
        "\"\" if not self.opclasses else \" opclasses=%s\" % repr(self.opclasses),",
        "\"\" if not self.opclasses else \" opclasses=%s\" %"
    ],
    [
        "\"\"\"Order and wrap expressions for CREATE INDEX statements.\"\"\"",
        "\"\"\"Order and wrap expressions for CREATE"
    ],
    [
        "wrapper_types = [type(wrapper) for wrapper in wrappers]",
        "wrapper_types = [type(wrapper) for wrapper in"
    ],
    [
        "\"Multiple references to %s can't be used in an indexed \"",
        "\"Multiple references to %s can't be used in an indexed"
    ],
    [
        "\"%s must be topmost expressions in an indexed expression.\"",
        "\"%s must be topmost expressions"
    ],
    [
        "wrappers = [wrapper.copy() for wrapper in wrappers]",
        "wrappers = [wrapper.copy() for wrapper"
    ],
    [
        "Take a model or a string of the form \"app_label.ModelName\" and return a",
        "Take a model or a string of the"
    ],
    [
        "corresponding (\"app_label\", \"modelname\") tuple. If a tuple is passed in,",
        "corresponding (\"app_label\", \"modelname\") tuple. If"
    ],
    [
        "assume it's a valid model tuple already and return it unchanged.",
        "assume it's a valid model tuple already and"
    ],
    [
        "\"Invalid model reference '%s'. String model references \"",
        "\"Invalid model reference '%s'. String model references"
    ],
    [
        "\"must be of the form 'app_label.ModelName'.\" % model",
        "\"must be of the"
    ],
    [
        "Generate key/value pairs for the given mapping where the values are",
        "Generate key/value pairs for the given mapping"
    ],
    [
        "yield k, v() if callable(v) else v",
        "yield k, v() if callable(v) else"
    ],
    [
        "Make subclasses preserve the alters_data attribute on overridden methods.",
        "Make subclasses preserve the alters_data attribute on overridden"
    ],
    [
        "if callable(fn) and not hasattr(fn, \"alters_data\"):",
        "if callable(fn) and"
    ],
    [
        "if base_fn := getattr(base, fn_name, None):",
        "if base_fn := getattr(base, fn_name,"
    ],
    [
        "Classes to represent the definitions of aggregate functions.",
        "Classes to represent the definitions"
    ],
    [
        "from django.db.models.expressions import Case, ColPairs, Func, Star, Value, When",
        "from django.db.models.expressions import Case, ColPairs,"
    ],
    [
        "filter_template = \"%s FILTER (WHERE %%(filter)s)\"",
        "filter_template = \"%s"
    ],
    [
        "self, *expressions, distinct=False, filter=None, default=None, **extra",
        "self, *expressions, distinct=False,"
    ],
    [
        "raise TypeError(\"%s does not allow distinct.\" % self.__class__.__name__)",
        "raise TypeError(\"%s does not allow distinct.\" %"
    ],
    [
        "if default is not None and self.empty_result_set_value is not None:",
        "if default is not None and"
    ],
    [
        "raise TypeError(f\"{self.__class__.__name__} does not allow default.\")",
        "raise TypeError(f\"{self.__class__.__name__} does not"
    ],
    [
        "return [e._output_field_or_none for e in super().get_source_expressions()]",
        "return [e._output_field_or_none for"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None,"
    ],
    [
        "c = super().resolve_expression(query, allow_joins, reuse, summarize)",
        "c = super().resolve_expression(query, allow_joins, reuse,"
    ],
    [
        "f\"Cannot compute {c.name}('{ref}'): '{ref}' is an aggregate\"",
        "f\"Cannot compute {c.name}('{ref}'): '{ref}'"
    ],
    [
        "\"Cannot compute %s('%s'): '%s' is an aggregate\"",
        "\"Cannot compute %s('%s'): '%s' is"
    ],
    [
        "if (default := c.default) is None:",
        "if (default :="
    ],
    [
        "default = default.resolve_expression(query, allow_joins, reuse, summarize)",
        "default = default.resolve_expression(query,"
    ],
    [
        "expr for expr in self.get_source_expressions() if expr is not None",
        "expr for expr in self.get_source_expressions() if expr"
    ],
    [
        "raise TypeError(\"Complex expressions require an alias\")",
        "raise TypeError(\"Complex expressions require an"
    ],
    [
        "extra_context[\"distinct\"] = \"DISTINCT \" if self.distinct else \"\"",
        "extra_context[\"distinct\"] = \"DISTINCT \" if self.distinct"
    ],
    [
        "if isinstance(expression, Star) and filter is not None:",
        "if isinstance(expression, Star) and filter is not"
    ],
    [
        "raise ValueError(\"Star cannot be used with filter. Please specify a field.\")",
        "raise ValueError(\"Star cannot be used with"
    ],
    [
        "\"COUNT(DISTINCT) doesn't support composite primary keys\"",
        "\"COUNT(DISTINCT) doesn't support composite"
    ],
    [
        "self.function = \"STDDEV_SAMP\" if sample else \"STDDEV_POP\"",
        "self.function = \"STDDEV_SAMP\" if sample else"
    ],
    [
        "return {**super()._get_repr_options(), \"sample\": self.function == \"STDDEV_SAMP\"}",
        "return {**super()._get_repr_options(), \"sample\": self.function"
    ],
    [
        "self.function = \"VAR_SAMP\" if sample else \"VAR_POP\"",
        "self.function = \"VAR_SAMP\" if"
    ],
    [
        "return {**super()._get_repr_options(), \"sample\": self.function == \"VAR_SAMP\"}",
        "return {**super()._get_repr_options(), \"sample\":"
    ],
    [
        "from django.db import IntegrityError, connections, models, transaction",
        "from django.db import IntegrityError, connections,"
    ],
    [
        "from django.db.models import query_utils, signals, sql",
        "from django.db.models import"
    ],
    [
        "\"Cannot delete some instances of model '%s' because they are \"",
        "\"Cannot delete some instances of model '%s' because they"
    ],
    [
        "\"referenced through a protected foreign key: '%s.%s'\"",
        "\"referenced through a protected foreign key:"
    ],
    [
        "set_on_delete.deconstruct = lambda: (\"django.db.models.SET\", (value,), {})",
        "set_on_delete.deconstruct = lambda: (\"django.db.models.SET\", (value,),"
    ],
    [
        "if f.auto_created and not f.concrete and (f.one_to_one or f.one_to_many)",
        "if f.auto_created and not f.concrete and"
    ],
    [
        "def add(self, objs, source=None, nullable=False, reverse_dependency=False):",
        "def add(self, objs, source=None,"
    ],
    [
        "Add 'objs' to the collection of objects to be deleted.  If the call is",
        "Add 'objs' to the collection of objects to be"
    ],
    [
        "the result of a cascade, 'source' should be the model that caused it,",
        "the result of a cascade, 'source' should be"
    ],
    [
        "and 'nullable' should be set to True if the relation can be null.",
        "and 'nullable' should be set to True if the"
    ],
    [
        "Return a list of all objects that were not already collected.",
        "Return a list of all objects that were not"
    ],
    [
        "if source is not None and not nullable:",
        "if source is not None and not"
    ],
    [
        "Schedule a field update. 'objs' must be a homogeneous iterable",
        "Schedule a field update. 'objs' must be a"
    ],
    [
        "collection of model instances (e.g. a QuerySet).",
        "collection of model instances (e.g. a"
    ],
    [
        "Determine if the objects in the given queryset-like or single object",
        "Determine if the objects in the"
    ],
    [
        "can be fast-deleted. This can be done if there are no cascades, no",
        "can be fast-deleted. This can be done if there are"
    ],
    [
        "parents and no signal listeners for the object class.",
        "parents and no signal listeners for the"
    ],
    [
        "The 'from_field' tells where we are coming from - we need this to",
        "The 'from_field' tells where we are coming from"
    ],
    [
        "determine if the objects are in fact to be deleted. Allow also",
        "determine if the objects are in fact to be deleted."
    ],
    [
        "skipping parent -> child -> parent chain preventing fast delete of",
        "skipping parent -> child -> parent chain preventing fast"
    ],
    [
        "if from_field and from_field.remote_field.on_delete is not CASCADE:",
        "if from_field and from_field.remote_field.on_delete is not"
    ],
    [
        "elif hasattr(objs, \"model\") and hasattr(objs, \"_raw_delete\"):",
        "elif hasattr(objs, \"model\") and hasattr(objs,"
    ],
    [
        "Return the objs in suitably sized batches for the used connection.",
        "Return the objs in suitably sized batches for the used"
    ],
    [
        "Add 'objs' to the collection of objects to be deleted as well as all",
        "Add 'objs' to the collection of objects to"
    ],
    [
        "parent instances.  'objs' must be a homogeneous iterable collection of",
        "parent instances. 'objs' must be"
    ],
    [
        "model instances (e.g. a QuerySet).  If 'collect_related' is True,",
        "model instances (e.g. a QuerySet)."
    ],
    [
        "related objects will be handled by their respective on_delete handler.",
        "related objects will be handled by their respective"
    ],
    [
        "If the call is the result of a cascade, 'source' should be the model",
        "If the call is the result of a cascade, 'source'"
    ],
    [
        "that caused it and 'nullable' should be set to True, if the relation",
        "that caused it and 'nullable' should be"
    ],
    [
        "If 'reverse_dependency' is True, 'source' will be deleted before the",
        "If 'reverse_dependency' is True, 'source' will be deleted before"
    ],
    [
        "current model, rather than after. (Needed for cascading to parent",
        "current model, rather than after. (Needed"
    ],
    [
        "models, the one case in which the cascade follows the forwards",
        "models, the one case in which the cascade"
    ],
    [
        "direction of an FK rather than the reverse direction.)",
        "direction of an FK rather than"
    ],
    [
        "If 'keep_parents' is True, data of parent model's will be not deleted.",
        "If 'keep_parents' is True, data of parent"
    ],
    [
        "If 'fail_on_restricted' is False, error won't be raised even if it's",
        "If 'fail_on_restricted' is False, error won't be raised"
    ],
    [
        "prohibited to delete such objects due to RESTRICT, that defers",
        "prohibited to delete such objects due"
    ],
    [
        "restricted object checking in recursive calls where the top-level call",
        "restricted object checking in recursive calls where"
    ],
    [
        "may need to collect more objects to determine whether restricted ones",
        "may need to collect more objects"
    ],
    [
        "parent_objs = [getattr(obj, ptr.name) for obj in new_objs]",
        "parent_objs = [getattr(obj, ptr.name) for"
    ],
    [
        "if keep_parents and related.model in model._meta.all_parents:",
        "if keep_parents and"
    ],
    [
        "if getattr(on_delete, \"lazy_sub_objs\", False) or sub_objs:",
        "if getattr(on_delete, \"lazy_sub_objs\","
    ],
    [
        "key = \"'%s.%s'\" % (field.model.__name__, field.name)",
        "key = \"'%s.%s'\" %"
    ],
    [
        "\"Cannot delete some instances of model %r because they are \"",
        "\"Cannot delete some instances of model %r because they"
    ],
    [
        "\"referenced through protected foreign keys: %s.\"",
        "\"referenced through protected foreign keys:"
    ],
    [
        "key = \"'%s.%s'\" % (related_model.__name__, field.name)",
        "key = \"'%s.%s'\" %"
    ],
    [
        "\"Cannot delete some instances of model %r because \"",
        "\"Cannot delete some instances of model %r"
    ],
    [
        "\"they are referenced through restricted foreign keys: \"",
        "\"they are referenced through restricted foreign keys:"
    ],
    [
        "Get a QuerySet of the related model to objs via related fields.",
        "Get a QuerySet of the related model to objs via related"
    ],
    [
        "[(f\"{related_field.name}__in\", objs) for related_field in related_fields],",
        "[(f\"{related_field.name}__in\", objs) for related_field in"
    ],
    [
        "self.data = {model: self.data[model] for model in sorted_models}",
        "self.data = {model: self.data[model] for model"
    ],
    [
        "for (field, value), instances_list in self.field_updates.items():",
        "for (field, value), instances_list in"
    ],
    [
        "list({obj.pk for obj in objs}), {field.name: value}, self.using",
        "list({obj.pk for obj in"
    ],
    [
        "pk_list = [obj.pk for obj in instances]",
        "pk_list = [obj.pk for obj"
    ],
    [
        "from django.core.exceptions import FieldDoesNotExist, FieldError, ValidationError",
        "from django.core.exceptions import"
    ],
    [
        "from django.db.models.expressions import Exists, ExpressionList, F, RawSQL",
        "from django.db.models.expressions import Exists,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "__all__ = [\"BaseConstraint\", \"CheckConstraint\", \"Deferrable\", \"UniqueConstraint\"]",
        "__all__ = [\"BaseConstraint\","
    ],
    [
        "default_violation_error_message = _(\"Constraint “%(name)s” is violated.\")",
        "default_violation_error_message = _(\"Constraint"
    ],
    [
        "raise NotImplementedError(\"This method must be implemented by a subclass.\")",
        "raise NotImplementedError(\"This method must be implemented by a"
    ],
    [
        "raise NotImplementedError(\"This method must be implemented by a subclass.\")",
        "raise NotImplementedError(\"This method must be implemented"
    ],
    [
        "raise NotImplementedError(\"This method must be implemented by a subclass.\")",
        "raise NotImplementedError(\"This method must be"
    ],
    [
        "def validate(self, model, instance, exclude=None, using=DEFAULT_DB_ALIAS):",
        "def validate(self, model, instance, exclude=None,"
    ],
    [
        "raise NotImplementedError(\"This method must be implemented by a subclass.\")",
        "raise NotImplementedError(\"This method must be"
    ],
    [
        "if field_name != \"pk\" or isinstance(model._meta.pk, CompositePrimaryKey):",
        "if field_name != \"pk\""
    ],
    [
        "if not field.is_relation or field.many_to_many or field.one_to_many:",
        "if not field.is_relation or field.many_to_many or"
    ],
    [
        "\"'constraints' refers to the joined field '%s'.\"",
        "\"'constraints' refers to the joined field"
    ],
    [
        "path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)",
        "path = \"%s.%s\" % (self.__class__.__module__,"
    ],
    [
        "\"CheckConstraint.condition must be a Q instance or boolean expression.\"",
        "\"CheckConstraint.condition must be a Q instance or boolean"
    ],
    [
        "f\"{connection.display_name} does not support check constraints.\",",
        "f\"{connection.display_name} does not support"
    ],
    [
        "\"A constraint won't be created. Silence this warning if you \"",
        "\"A constraint won't be created. Silence this warning"
    ],
    [
        "if any(isinstance(expr, RawSQL) for expr in condition.flatten()):",
        "if any(isinstance(expr, RawSQL) for expr in"
    ],
    [
        "f\"Check constraint {self.name!r} contains RawSQL() expression \"",
        "f\"Check constraint {self.name!r} contains RawSQL() expression"
    ],
    [
        "\"and won't be validated during the model full_clean().\",",
        "\"and won't be validated during"
    ],
    [
        "hint=\"Silence this warning if you don't care about it.\",",
        "hint=\"Silence this warning if you don't"
    ],
    [
        "return sql % tuple(schema_editor.quote_value(p) for p in params)",
        "return sql % tuple(schema_editor.quote_value(p) for p"
    ],
    [
        "def validate(self, model, instance, exclude=None, using=DEFAULT_DB_ALIAS):",
        "def validate(self, model, instance, exclude=None,"
    ],
    [
        "return \"<%s: condition=%s name=%s%s%s>\" % (",
        "return \"<%s: condition=%s name=%s%s%s>\""
    ],
    [
        "raise ValueError(\"A unique constraint must be named.\")",
        "raise ValueError(\"A unique constraint"
    ],
    [
        "if not expressions and not fields:",
        "if not expressions"
    ],
    [
        "\"At least one field or expression is required to define a \"",
        "\"At least one field or expression is required to define a"
    ],
    [
        "\"UniqueConstraint.fields and expressions are mutually exclusive.\"",
        "\"UniqueConstraint.fields and expressions are"
    ],
    [
        "raise ValueError(\"UniqueConstraint.condition must be a Q instance.\")",
        "raise ValueError(\"UniqueConstraint.condition must be a"
    ],
    [
        "raise ValueError(\"UniqueConstraint with conditions cannot be deferred.\")",
        "raise ValueError(\"UniqueConstraint with conditions cannot be"
    ],
    [
        "raise ValueError(\"UniqueConstraint with include fields cannot be deferred.\")",
        "raise ValueError(\"UniqueConstraint with include fields"
    ],
    [
        "raise ValueError(\"UniqueConstraint with opclasses cannot be deferred.\")",
        "raise ValueError(\"UniqueConstraint with opclasses cannot be"
    ],
    [
        "raise ValueError(\"UniqueConstraint with expressions cannot be deferred.\")",
        "raise ValueError(\"UniqueConstraint with expressions"
    ],
    [
        "\"UniqueConstraint.opclasses cannot be used with expressions. \"",
        "\"UniqueConstraint.opclasses cannot be used with expressions."
    ],
    [
        "\"UniqueConstraint.deferrable must be a Deferrable instance.\"",
        "\"UniqueConstraint.deferrable must be a Deferrable"
    ],
    [
        "if not isinstance(include, (NoneType, list, tuple)):",
        "if not isinstance(include,"
    ],
    [
        "raise TypeError(\"UniqueConstraint.include must be a list or tuple.\")",
        "raise TypeError(\"UniqueConstraint.include must be a list"
    ],
    [
        "raise TypeError(\"UniqueConstraint.opclasses must be a list or tuple.\")",
        "raise TypeError(\"UniqueConstraint.opclasses must be a"
    ],
    [
        "raise TypeError(\"UniqueConstraint.nulls_distinct must be a bool.\")",
        "raise TypeError(\"UniqueConstraint.nulls_distinct must be"
    ],
    [
        "if opclasses and len(fields) != len(opclasses):",
        "if opclasses and len(fields)"
    ],
    [
        "\"have the same number of elements.\"",
        "\"have the same number of"
    ],
    [
        "self.include = tuple(include) if include else ()",
        "self.include = tuple(include) if include"
    ],
    [
        "F(expression) if isinstance(expression, str) else expression",
        "F(expression) if isinstance(expression, str)"
    ],
    [
        "if self.condition is not None and not (",
        "if self.condition is not None and"
    ],
    [
        "f\"{connection.display_name} does not support unique constraints \"",
        "f\"{connection.display_name} does not support unique"
    ],
    [
        "\"A constraint won't be created. Silence this warning if you \"",
        "\"A constraint won't be created. Silence this warning if you"
    ],
    [
        "if self.deferrable is not None and not (",
        "if self.deferrable is not None and"
    ],
    [
        "f\"{connection.display_name} does not support deferrable unique \"",
        "f\"{connection.display_name} does not support"
    ],
    [
        "\"A constraint won't be created. Silence this warning if you \"",
        "\"A constraint won't be created. Silence this warning if you"
    ],
    [
        "f\"{connection.display_name} does not support unique constraints \"",
        "f\"{connection.display_name} does not support unique"
    ],
    [
        "\"A constraint won't be created. Silence this warning if you \"",
        "\"A constraint won't be created. Silence this warning"
    ],
    [
        "f\"{connection.display_name} does not support unique constraints on \"",
        "f\"{connection.display_name} does not support unique constraints"
    ],
    [
        "\"A constraint won't be created. Silence this warning if you \"",
        "\"A constraint won't be created. Silence this warning if"
    ],
    [
        "if self.nulls_distinct is not None and not (",
        "if self.nulls_distinct is not None"
    ],
    [
        "f\"{connection.display_name} does not support unique constraints \"",
        "f\"{connection.display_name} does not support unique"
    ],
    [
        "\"A constraint won't be created. Silence this warning if you \"",
        "\"A constraint won't be created. Silence this warning"
    ],
    [
        "return sql % tuple(schema_editor.quote_value(p) for p in params)",
        "return sql % tuple(schema_editor.quote_value(p)"
    ],
    [
        "fields = [model._meta.get_field(field_name) for field_name in self.fields]",
        "fields = [model._meta.get_field(field_name) for"
    ],
    [
        "fields = [model._meta.get_field(field_name) for field_name in self.fields]",
        "fields = [model._meta.get_field(field_name) for field_name in"
    ],
    [
        "\"\" if not self.fields else \" fields=%s\" % repr(self.fields),",
        "\"\" if not self.fields else \""
    ],
    [
        "\"\" if not self.expressions else \" expressions=%s\" % repr(self.expressions),",
        "\"\" if not self.expressions else \" expressions=%s\" %"
    ],
    [
        "\"\" if self.condition is None else \" condition=%s\" % self.condition,",
        "\"\" if self.condition is None else \" condition=%s\" %"
    ],
    [
        "\"\" if self.deferrable is None else \" deferrable=%r\" % self.deferrable,",
        "\"\" if self.deferrable is None else \""
    ],
    [
        "\"\" if not self.include else \" include=%s\" % repr(self.include),",
        "\"\" if not self.include else \" include=%s\""
    ],
    [
        "\"\" if not self.opclasses else \" opclasses=%s\" % repr(self.opclasses),",
        "\"\" if not self.opclasses else"
    ],
    [
        "def validate(self, model, instance, exclude=None, using=DEFAULT_DB_ALIAS):",
        "def validate(self, model, instance, exclude=None,"
    ],
    [
        "if exclude and field_name in exclude:",
        "if exclude and field_name"
    ],
    [
        "condition = Q(Exact(lhs, expression)) | Q(",
        "condition = Q(Exact(lhs, expression))"
    ],
    [
        "condition = Q(condition) | Q(IsNull(expr, True), IsNull(rhs, True))",
        "condition = Q(condition) |"
    ],
    [
        "Raise a ValueError if the manager is dynamically generated.",
        "Raise a ValueError if the manager is"
    ],
    [
        "\"Could not find manager %s in %s.\\n\"",
        "\"Could not find manager"
    ],
    [
        "\"Please note that you need to inherit from managers you \"",
        "\"Please note that you need to inherit from managers you"
    ],
    [
        "if queryset_only or (queryset_only is None and name.startswith(\"_\")):",
        "if queryset_only or (queryset_only is None and"
    ],
    [
        "class_name = \"%sFrom%s\" % (cls.__name__, queryset_class.__name__)",
        "class_name = \"%sFrom%s\" % (cls.__name__,"
    ],
    [
        "Set the creation counter value for this instance and increment the",
        "Set the creation counter value for this"
    ],
    [
        "Return a new QuerySet object. Subclasses can override this method to",
        "Return a new QuerySet object. Subclasses can"
    ],
    [
        "customize the behavior of the Manager.",
        "customize the behavior of the"
    ],
    [
        "\"Manager isn't accessible via %s instances\" % cls.__name__",
        "\"Manager isn't accessible via"
    ],
    [
        "\"Manager isn't available; %s is abstract\" % (cls._meta.object_name,)",
        "\"Manager isn't available; %s"
    ],
    [
        "\"Manager isn't available; '%s' has been swapped for '%s'\"",
        "\"Manager isn't available; '%s' has"
    ],
    [
        "Various data structures used in query construction.",
        "Various data structures used in"
    ],
    [
        "Factored out from django.db.models.query to avoid making the main module very",
        "Factored out from django.db.models.query to avoid making"
    ],
    [
        "large and/or so that they can be used by other modules without getting into",
        "large and/or so that they can be"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, DatabaseError, connections, transaction",
        "from django.db import DEFAULT_DB_ALIAS, DatabaseError, connections,"
    ],
    [
        "Encapsulate filters as objects that can then be combined logically (using",
        "Encapsulate filters as objects that can then"
    ],
    [
        "def __init__(self, *args, _connector=None, _negated=False, **kwargs):",
        "def __init__(self, *args, _connector=None,"
    ],
    [
        "if getattr(other, \"conditional\", False) is False:",
        "if getattr(other, \"conditional\", False) is"
    ],
    [
        "if not other and isinstance(other, Q):",
        "if not other and"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None,"
    ],
    [
        "Recursively yield this Q object and all subexpressions, in depth-first",
        "Recursively yield this Q object and all subexpressions, in"
    ],
    [
        "Do a database query to check if the expressions of the Q instance",
        "Do a database query to check if the expressions of the Q"
    ],
    [
        "logger.warning(\"Got a database error calling check() on %r: %s\", self, e)",
        "logger.warning(\"Got a database error calling check() on"
    ],
    [
        "path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)",
        "path = \"%s.%s\" %"
    ],
    [
        "Retrieve all base fields referenced directly or through F expressions",
        "Retrieve all base fields referenced directly or through F"
    ],
    [
        "excluding any fields referenced through joins.",
        "excluding any fields referenced"
    ],
    [
        "A wrapper for a deferred-loading field. When the value is read from this",
        "A wrapper for a deferred-loading field. When"
    ],
    [
        "object the first time, the query is executed.",
        "object the first time,"
    ],
    [
        "Retrieve and caches the value from the datastore on the first lookup.",
        "Retrieve and caches the value from the datastore on"
    ],
    [
        "\"Cannot read a generated field from an unsaved model.\"",
        "\"Cannot read a generated field from an"
    ],
    [
        "Check if the field value can be fetched from a parent field already",
        "Check if the field value can be fetched from"
    ],
    [
        "loaded in the instance. This can be done if the to-be fetched",
        "loaded in the instance. This can be done if the"
    ],
    [
        "field is a primary key field.",
        "field is a primary"
    ],
    [
        "if self.field.primary_key and self.field != link_field:",
        "if self.field.primary_key and self.field"
    ],
    [
        "Hook used in RegisterLookupMixin to return partial functions depending on",
        "Hook used in RegisterLookupMixin to return"
    ],
    [
        "the caller type (instance or class of models.Field).",
        "the caller type (instance or class of"
    ],
    [
        "parent.__dict__.get(\"class_lookups\", {}) for parent in inspect.getmro(cls)",
        "parent.__dict__.get(\"class_lookups\", {}) for parent in"
    ],
    [
        "if instance_lookups := getattr(self, \"instance_lookups\", None):",
        "if instance_lookups := getattr(self, \"instance_lookups\","
    ],
    [
        "if found is None and hasattr(self, \"output_field\"):",
        "if found is None and"
    ],
    [
        "if found is not None and not issubclass(found, Lookup):",
        "if found is not None and"
    ],
    [
        "if found is None and hasattr(self, \"output_field\"):",
        "if found is None"
    ],
    [
        "if found is not None and not issubclass(found, Transform):",
        "if found is not None and not"
    ],
    [
        "Merge dicts in reverse to preference the order of the original list. e.g.,",
        "Merge dicts in reverse to preference the order of the"
    ],
    [
        "merge_dicts([a, b]) will preference the keys in 'a' over those in 'b'.",
        "merge_dicts([a, b]) will preference the keys in 'a' over"
    ],
    [
        "Remove given lookup from cls lookups. For use in tests only as it's",
        "Remove given lookup from cls lookups. For"
    ],
    [
        "Remove given lookup from instance lookups. For use in tests only as",
        "Remove given lookup from instance lookups. For use"
    ],
    [
        "Return whether `field` should be used to descend deeper for",
        "Return whether `field` should be used to descend deeper"
    ],
    [
        "* `field` - the field to be checked. Can be either a `Field` or",
        "* `field` - the field to be checked. Can be either a `Field`"
    ],
    [
        "* `restricted` - a boolean field, indicating if the field list has been",
        "* `restricted` - a boolean field, indicating if the field list"
    ],
    [
        "manually restricted using a select_related() clause.",
        "manually restricted using a"
    ],
    [
        "* `requested` - the select_related() dictionary.",
        "* `requested` - the select_related()"
    ],
    [
        "* `select_mask` - the dictionary of selected fields.",
        "* `select_mask` - the dictionary of"
    ],
    [
        "if select_mask and field not in select_mask:",
        "if select_mask and field not"
    ],
    [
        "f\"Field {field.model._meta.object_name}.{field.name} cannot be both \"",
        "f\"Field {field.model._meta.object_name}.{field.name} cannot"
    ],
    [
        "\"deferred and traversed using select_related at the same time.\"",
        "\"deferred and traversed using select_related"
    ],
    [
        "Check if the lookup_parts contains references to the given annotations set.",
        "Check if the lookup_parts contains references to the given annotations"
    ],
    [
        "Because the LOOKUP_SEP is contained in the default annotation names, check",
        "Because the LOOKUP_SEP is contained in the default annotation names,"
    ],
    [
        "each prefix of the lookup_parts for a match.",
        "each prefix of the lookup_parts for"
    ],
    [
        "Check that self.model is compatible with target_opts. Compatibility",
        "Check that self.model is compatible with"
    ],
    [
        "\"\"\"Specify custom filtering in the ON clause of SQL joins.\"\"\"",
        "\"\"\"Specify custom filtering in the ON"
    ],
    [
        "raise ValueError(\"condition argument must be a Q() instance.\")",
        "raise ValueError(\"condition argument must be"
    ],
    [
        "if (resolved_condition := self.resolved_condition) is not None:",
        "if (resolved_condition := self.resolved_condition) is not"
    ],
    [
        "def resolve_expression(self, query, reuse, *args, **kwargs):",
        "def resolve_expression(self, query, reuse, *args,"
    ],
    [
        "from django.db.models import NOT_PROVIDED, ExpressionWrapper, IntegerField, Max, Value",
        "from django.db.models import NOT_PROVIDED, ExpressionWrapper,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy as"
    ],
    [
        "Create exception subclass. Used by ModelBase below.",
        "Create exception subclass. Used by ModelBase"
    ],
    [
        "The exception is created in a way that allows it to be pickled, assuming",
        "The exception is created in a way that allows it to"
    ],
    [
        "that the returned exception class will be added as an attribute to the",
        "that the returned exception class will be added as"
    ],
    [
        "return not inspect.isclass(value) and hasattr(value, \"contribute_to_class\")",
        "return not inspect.isclass(value) and"
    ],
    [
        "def __new__(cls, name, bases, attrs, **kwargs):",
        "def __new__(cls, name, bases,"
    ],
    [
        "parents = [b for b in bases if isinstance(b, ModelBase)]",
        "parents = [b for b in bases"
    ],
    [
        "new_class = super_new(cls, name, bases, new_attrs, **kwargs)",
        "new_class = super_new(cls, name, bases,"
    ],
    [
        "meta = attr_meta or getattr(new_class, \"Meta\", None)",
        "meta = attr_meta or getattr(new_class,"
    ],
    [
        "if getattr(meta, \"app_label\", None) is None:",
        "if getattr(meta, \"app_label\","
    ],
    [
        "\"Model class %s.%s doesn't declare an explicit \"",
        "\"Model class %s.%s doesn't declare"
    ],
    [
        "\"app_label and isn't in an application in \"",
        "\"app_label and isn't in an application"
    ],
    [
        "if hasattr(x, \"_meta\") and not x._meta.abstract",
        "if hasattr(x, \"_meta\")"
    ],
    [
        "if hasattr(x, \"_meta\") and not x._meta.abstract",
        "if hasattr(x, \"_meta\") and not"
    ],
    [
        "if is_proxy and base_meta and base_meta.swapped:",
        "if is_proxy and base_meta and"
    ],
    [
        "\"%s cannot proxy the swapped model '%s'.\" % (name, base_meta.swapped)",
        "\"%s cannot proxy the swapped model '%s'.\" %"
    ],
    [
        "field_names = {f.name for f in new_fields}",
        "field_names = {f.name for f in"
    ],
    [
        "for parent in [kls for kls in parents if hasattr(kls, \"_meta\")]:",
        "for parent in [kls for kls in parents"
    ],
    [
        "\"Abstract base class containing model fields not \"",
        "\"Abstract base class containing model fields"
    ],
    [
        "\"permitted for proxy model '%s'.\" % name",
        "\"permitted for proxy model '%s'.\""
    ],
    [
        "\"Proxy model '%s' has more than one non-abstract model base \"",
        "\"Proxy model '%s' has more than"
    ],
    [
        "\"Proxy model '%s' has no non-abstract model base class.\" % name",
        "\"Proxy model '%s' has no non-abstract model base class.\""
    ],
    [
        "for base in reversed([new_class] + parents):",
        "for base in reversed([new_class]"
    ],
    [
        "if base != new_class and not base._meta.abstract:",
        "if base != new_class and"
    ],
    [
        "if base not in parents or not hasattr(base, \"_meta\"):",
        "if base not in parents or not"
    ],
    [
        "\"Local field %r in class %r clashes with field of \"",
        "\"Local field %r in class %r clashes"
    ],
    [
        "\"the same name from base class %r.\"",
        "\"the same name from"
    ],
    [
        "\"Auto-generated field '%s' in class %r for \"",
        "\"Auto-generated field '%s' in class"
    ],
    [
        "\"parent_link to base class %r clashes with \"",
        "\"parent_link to base class %r clashes with"
    ],
    [
        "\"declared field of the same name.\"",
        "\"declared field of the same"
    ],
    [
        "\"Local field %r in class %r clashes with field of \"",
        "\"Local field %r in class %r"
    ],
    [
        "\"the same name from base class %r.\"",
        "\"the same name from base"
    ],
    [
        "\"\"\"Create some methods once self._meta has been populated.\"\"\"",
        "\"\"\"Create some methods once self._meta has been"
    ],
    [
        "\", \".join(f.name for f in opts.fields),",
        "\", \".join(f.name for f"
    ],
    [
        "if any(f.name == \"objects\" for f in opts.fields):",
        "if any(f.name == \"objects\""
    ],
    [
        "\"Model %s must specify a custom Manager, because it has a \"",
        "\"Model %s must specify a custom Manager, because it has a"
    ],
    [
        "raise TypeError(\"Abstract models cannot be instantiated.\")",
        "raise TypeError(\"Abstract models cannot be"
    ],
    [
        "raise IndexError(\"Number of args exceeds number of fields\")",
        "raise IndexError(\"Number of args exceeds number"
    ],
    [
        "for val, field in zip(args, fields_iter):",
        "for val, field in zip(args,"
    ],
    [
        "for val, field in zip(args, fields_iter):",
        "for val, field in"
    ],
    [
        "if kwargs.pop(field.name, NOT_PROVIDED) is not NOT_PROVIDED:",
        "if kwargs.pop(field.name, NOT_PROVIDED) is not"
    ],
    [
        "f\"{cls.__qualname__}() got both positional and \"",
        "f\"{cls.__qualname__}() got both positional"
    ],
    [
        "if field.column is None or field.generated:",
        "if field.column is None"
    ],
    [
        "unexpected_names = \", \".join(repr(n) for n in unexpected)",
        "unexpected_names = \", \".join(repr(n) for"
    ],
    [
        "f\"{cls.__name__}() got unexpected keyword arguments: \"",
        "f\"{cls.__name__}() got unexpected keyword"
    ],
    [
        "next(values_iter) if f.attname in field_names else DEFERRED",
        "next(values_iter) if f.attname in field_names"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self)",
        "return \"<%s: %s>\""
    ],
    [
        "return \"%s object (%s)\" % (self.__class__.__name__, self.pk)",
        "return \"%s object (%s)\" %"
    ],
    [
        "raise TypeError(\"Model instances without primary key value are unhashable\")",
        "raise TypeError(\"Model instances without primary key value"
    ],
    [
        "\"\"\"Hook to allow choosing the attributes to pickle.\"\"\"",
        "\"\"\"Hook to allow choosing the attributes to"
    ],
    [
        "\"Pickled model instance's Django version %s does not \"",
        "\"Pickled model instance's Django version"
    ],
    [
        "\"Pickled model instance's Django version is not specified.\",",
        "\"Pickled model instance's Django version is"
    ],
    [
        "if parent_link and parent_link != self._meta.pk:",
        "if parent_link and"
    ],
    [
        "or (isinstance(pk_val, tuple) and any(f is None for f in pk_val))",
        "or (isinstance(pk_val, tuple) and any(f is None for"
    ],
    [
        "Return a set containing names of deferred fields for this instance.",
        "Return a set containing names of deferred fields"
    ],
    [
        "Reload field values from the database.",
        "Reload field values"
    ],
    [
        "By default, the reloading happens from the database this instance was",
        "By default, the reloading happens from the database this instance"
    ],
    [
        "loaded from, or by the read router if this instance wasn't loaded from",
        "loaded from, or by the read router if this instance wasn't"
    ],
    [
        "any database. The using parameter will override the default.",
        "any database. The using parameter will"
    ],
    [
        "Fields can be used to specify which fields to reload. The fields",
        "Fields can be used to specify"
    ],
    [
        "should be an iterable of field attnames. If fields is None, then",
        "should be an iterable of field"
    ],
    [
        "When accessing deferred fields of an instance, the deferred loading",
        "When accessing deferred fields of an instance, the deferred"
    ],
    [
        "of the field will call this method.",
        "of the field will call"
    ],
    [
        "if any(LOOKUP_SEP in f for f in fields):",
        "if any(LOOKUP_SEP in f for f in"
    ],
    [
        "'Found \"%s\" in fields argument. Relations and transforms '",
        "'Found \"%s\" in fields argument. Relations and transforms"
    ],
    [
        "\"are not allowed in fields.\" % LOOKUP_SEP",
        "\"are not allowed in fields.\""
    ],
    [
        "if (fields is None or rel.name in fields) and rel.is_cached(self):",
        "if (fields is None or"
    ],
    [
        "(fields is None or field.name in fields)",
        "(fields is None or field.name in"
    ],
    [
        "async def arefresh_from_db(self, using=None, fields=None, from_queryset=None):",
        "async def arefresh_from_db(self, using=None, fields=None,"
    ],
    [
        "Return the value of the field name for this instance. If the field is",
        "Return the value of the field name for this instance."
    ],
    [
        "a foreign key, return the id value instead of the object. If there's",
        "a foreign key, return the id value"
    ],
    [
        "no Field object with this name on the model, return the model",
        "no Field object with this name on the"
    ],
    [
        "Used to serialize a field's value (in the serializer, or form output,",
        "Used to serialize a field's value (in"
    ],
    [
        "for example). Normally, you would just access the attribute directly",
        "for example). Normally, you would"
    ],
    [
        "Save the current instance. Override this in a subclass if you want to",
        "Save the current instance. Override this in"
    ],
    [
        "The 'force_insert' and 'force_update' parameters can be used to insist",
        "The 'force_insert' and 'force_update' parameters can be"
    ],
    [
        "that the \"save\" must be an SQL insert or update (or equivalent for",
        "that the \"save\" must be an SQL insert or"
    ],
    [
        "non-SQL backends), respectively. Normally, they should not be set.",
        "non-SQL backends), respectively. Normally, they"
    ],
    [
        "using = using or router.db_for_write(self.__class__, instance=self)",
        "using = using or router.db_for_write(self.__class__,"
    ],
    [
        "if force_insert and (force_update or update_fields):",
        "if force_insert and (force_update"
    ],
    [
        "raise ValueError(\"Cannot force both insert and updating in model saving.\")",
        "raise ValueError(\"Cannot force both insert and updating"
    ],
    [
        "if f.attname not in self.__dict__ and f.generated is False",
        "if f.attname not in self.__dict__ and f.generated"
    ],
    [
        "\"fields, primary keys, or are non-concrete fields: %s\"",
        "\"fields, primary keys, or are non-concrete"
    ],
    [
        "if field not in pk_fields and not hasattr(field, \"through\"):",
        "if field not in pk_fields and not"
    ],
    [
        "raise TypeError(\"force_insert must be a bool or tuple.\")",
        "raise TypeError(\"force_insert must be a"
    ],
    [
        "f\"Invalid force_insert member. {member!r} must be a model subclass.\"",
        "f\"Invalid force_insert member. {member!r} must be"
    ],
    [
        "f\"Invalid force_insert member. {member.__qualname__} must be a \"",
        "f\"Invalid force_insert member. {member.__qualname__} must"
    ],
    [
        "Handle the parts of saving which should be done only once per save,",
        "Handle the parts of saving which should be"
    ],
    [
        "yet need to be done in raw saves, too. This includes some sanity",
        "yet need to be done in raw saves, too. This includes"
    ],
    [
        "The 'raw' argument is telling save_base not to save any parent",
        "The 'raw' argument is telling save_base not to save any"
    ],
    [
        "models and not to do any changes to the values before save. This",
        "models and not to do any changes to the values"
    ],
    [
        "using = using or router.db_for_write(self.__class__, instance=self)",
        "using = using or"
    ],
    [
        "assert not (force_insert and (force_update or update_fields))",
        "assert not (force_insert and (force_update or"
    ],
    [
        "assert update_fields is None or update_fields",
        "assert update_fields is"
    ],
    [
        "self, cls, using, update_fields, force_insert, updated_parents=None",
        "self, cls, using, update_fields,"
    ],
    [
        "\"\"\"Save all the parents of cls using values from self.\"\"\"",
        "\"\"\"Save all the parents of cls using values from"
    ],
    [
        "and getattr(self, field.attname) is not None",
        "and getattr(self, field.attname) is"
    ],
    [
        "if (parent_updated := updated_parents.get(parent)) is None:",
        "if (parent_updated :="
    ],
    [
        "Do the heavy-lifting involved in saving. Update or insert the data",
        "Do the heavy-lifting involved in saving. Update or insert"
    ],
    [
        "if f not in pk_fields and not f.generated",
        "if f not in"
    ],
    [
        "if f.name in update_fields or f.attname in update_fields",
        "if f.name in update_fields or f.attname"
    ],
    [
        "if not pk_set and (force_update or update_fields):",
        "if not pk_set and"
    ],
    [
        "raise ValueError(\"Cannot force an update in save() with no primary key.\")",
        "raise ValueError(\"Cannot force an update in save() with no"
    ],
    [
        "and all(f.has_default() or f.has_db_default() for f in meta.pk_fields)",
        "and all(f.has_default() or f.has_db_default() for f in"
    ],
    [
        "(getattr(self, f.attname) if raw else f.pre_save(self, False)),",
        "(getattr(self, f.attname) if raw else f.pre_save(self,"
    ],
    [
        "base_qs, using, pk_val, values, update_fields, forced_update",
        "base_qs, using, pk_val,"
    ],
    [
        "raise DatabaseError(\"Forced update did not affect any rows.\")",
        "raise DatabaseError(\"Forced update did"
    ],
    [
        "raise DatabaseError(\"Save with update_fields did not affect any rows.\")",
        "raise DatabaseError(\"Save with update_fields did not affect any"
    ],
    [
        "if not f.generated and (pk_set or f is not meta.auto_field)",
        "if not f.generated and (pk_set or"
    ],
    [
        "def _do_update(self, base_qs, using, pk_val, values, update_fields, forced_update):",
        "def _do_update(self, base_qs, using, pk_val, values, update_fields,"
    ],
    [
        "Try to update the model. Return True if the model was updated (if an",
        "Try to update the model. Return True if"
    ],
    [
        "update query was done and a matching row was found in the DB).",
        "update query was done and a matching"
    ],
    [
        "return update_fields is not None or filtered.exists()",
        "return update_fields is not None"
    ],
    [
        "def _do_insert(self, manager, using, fields, returning_fields, raw):",
        "def _do_insert(self, manager, using,"
    ],
    [
        "Do an INSERT. If returning_fields is defined then this method should",
        "Do an INSERT. If returning_fields is defined then"
    ],
    [
        "return the newly created data for the model.",
        "return the newly created data"
    ],
    [
        "if fields and field not in fields:",
        "if fields and field not"
    ],
    [
        "\"%s() prohibited to prevent data loss due to unsaved \"",
        "\"%s() prohibited to prevent data loss"
    ],
    [
        "\"related object '%s'.\" % (operation_name, field.name)",
        "\"related object '%s'.\" % (operation_name,"
    ],
    [
        "if fields and field not in fields:",
        "if fields and field not"
    ],
    [
        "f\"{operation_name}() prohibited to prevent data loss due to \"",
        "f\"{operation_name}() prohibited to prevent data loss due"
    ],
    [
        "\"%s object can't be deleted because its %s attribute is set \"",
        "\"%s object can't be deleted because its %s attribute"
    ],
    [
        "using = using or router.db_for_write(self.__class__, instance=self)",
        "using = using or"
    ],
    [
        "raise ValueError(\"get_next/get_previous cannot be used on unsaved objects.\")",
        "raise ValueError(\"get_next/get_previous cannot be"
    ],
    [
        "op = \"gt\" if is_next else \"lt\"",
        "op = \"gt\" if is_next else"
    ],
    [
        "order = \"\" if is_next else \"-\"",
        "order = \"\" if"
    ],
    [
        "q = Q.create([(field.name, param), (f\"pk__{op}\", self.pk)], connector=Q.AND)",
        "q = Q.create([(field.name, param),"
    ],
    [
        "q = Q.create([q, (f\"{field.name}__{op}\", param)], connector=Q.OR)",
        "q = Q.create([q, (f\"{field.name}__{op}\", param)],"
    ],
    [
        ".order_by(\"%s%s\" % (order, field.name), \"%spk\" % order)",
        ".order_by(\"%s%s\" % (order, field.name), \"%spk\""
    ],
    [
        "\"%s matching query does not exist.\" % self.__class__._meta.object_name",
        "\"%s matching query does"
    ],
    [
        "op = \"gt\" if is_next else \"lt\"",
        "op = \"gt\" if"
    ],
    [
        "order = \"_order\" if is_next else \"-_order\"",
        "order = \"_order\" if"
    ],
    [
        "if not value or not hasattr(value, \"resolve_expression\"):",
        "if not value or"
    ],
    [
        "replacements = {F(name): value for name, value in field_map.items()}",
        "replacements = {F(name): value for"
    ],
    [
        "\"Unsaved model instance %r cannot be used in an ORM query.\" % self",
        "\"Unsaved model instance %r cannot be used in"
    ],
    [
        "Hook for doing any extra model-wide validation after clean() has been",
        "Hook for doing any extra model-wide validation after"
    ],
    [
        "called on every field by self.clean_fields. Any ValidationError raised",
        "called on every field by self.clean_fields."
    ],
    [
        "by this method will not be associated with a particular field; it will",
        "by this method will not be associated"
    ],
    [
        "have a special-case association with the field defined by NON_FIELD_ERRORS.",
        "have a special-case association with"
    ],
    [
        "Check unique constraints on the model and raise ValidationError if any",
        "Check unique constraints on the model and raise"
    ],
    [
        "Return a list of checks to perform. Since validate_unique() could be",
        "Return a list of checks to"
    ],
    [
        "called from a ModelForm, some fields may have been excluded; we can't",
        "called from a ModelForm, some fields may have been excluded;"
    ],
    [
        "perform a unique check on a model that is missing fields involved",
        "perform a unique check on a model"
    ],
    [
        "in that check. Fields that did not validate should also be excluded,",
        "in that check. Fields that did"
    ],
    [
        "but they need to be passed in via the exclude argument.",
        "but they need to be passed in"
    ],
    [
        "if not any(name in exclude for name in check):",
        "if not any(name in exclude for name in"
    ],
    [
        "if not any(name in exclude for name in constraint.fields):",
        "if not any(name in exclude for name"
    ],
    [
        "names = tuple(field.name for field in f.fields)",
        "names = tuple(field.name for"
    ],
    [
        "if f.unique_for_date and f.unique_for_date not in exclude:",
        "if f.unique_for_date and f.unique_for_date"
    ],
    [
        "if f.unique_for_year and f.unique_for_year not in exclude:",
        "if f.unique_for_year and f.unique_for_year not in"
    ],
    [
        "if f.unique_for_month and f.unique_for_month not in exclude:",
        "if f.unique_for_month and f.unique_for_month"
    ],
    [
        "if lookup_value is None or (",
        "if lookup_value is None"
    ],
    [
        "if f in model_class._meta.pk_fields and not self._state.adding:",
        "if f in model_class._meta.pk_fields and not"
    ],
    [
        "for model_class, lookup_type, field, unique_for in date_checks:",
        "for model_class, lookup_type, field, unique_for in"
    ],
    [
        "lookup_kwargs[\"%s__%s\" % (unique_for, lookup_type)] = getattr(",
        "lookup_kwargs[\"%s__%s\" % (unique_for,"
    ],
    [
        "message=_(\"%(model_name)s with this %(field_labels)s already exists.\"),",
        "message=_(\"%(model_name)s with this %(field_labels)s already"
    ],
    [
        "validate_constraints() on the model. Raise a ValidationError for any",
        "validate_constraints() on the model. Raise a"
    ],
    [
        "if name != NON_FIELD_ERRORS and name not in exclude:",
        "if name != NON_FIELD_ERRORS and"
    ],
    [
        "if name != NON_FIELD_ERRORS and name not in exclude:",
        "if name != NON_FIELD_ERRORS and name"
    ],
    [
        "Clean all fields and raise a ValidationError containing a dict",
        "Clean all fields and raise a ValidationError containing"
    ],
    [
        "of all validation errors if any occur.",
        "of all validation errors"
    ],
    [
        "if f.name in exclude or f.generated:",
        "if f.name in"
    ],
    [
        "if f.blank and raw_value in f.empty_values:",
        "if f.blank and raw_value in"
    ],
    [
        "f\"Auto-created primary key used when not defining a \"",
        "f\"Auto-created primary key used when not defining a"
    ],
    [
        "f\"primary key type, by default \"",
        "f\"primary key type,"
    ],
    [
        "f\"Configure the DEFAULT_AUTO_FIELD setting or the \"",
        "f\"Configure the DEFAULT_AUTO_FIELD setting or the"
    ],
    [
        "f\"default_auto_field attribute to point to a subclass \"",
        "f\"default_auto_field attribute to point to a"
    ],
    [
        "hint = f\"{field_name!r} is not a valid field.\"",
        "hint = f\"{field_name!r} is not a valid"
    ],
    [
        "hint = f\"{field_name!r} field has no column.\"",
        "hint = f\"{field_name!r} field has"
    ],
    [
        "hint = f\"{field_name!r} field may not set 'null=True'.\"",
        "hint = f\"{field_name!r} field may"
    ],
    [
        "hint = f\"{field_name!r} field is a generated field.\"",
        "hint = f\"{field_name!r} field is a"
    ],
    [
        "hint = f\"{field_name!r} field is not a local field.\"",
        "hint = f\"{field_name!r} field is"
    ],
    [
        "f\"{field_name!r} cannot be included in the composite primary \"",
        "f\"{field_name!r} cannot be included in the composite"
    ],
    [
        "duplicates = \", \".join(repr(field) for field in rest)",
        "duplicates = \", \".join(repr(field) for"
    ],
    [
        "f\"{duplicates} cannot be included in the composite primary \"",
        "f\"{duplicates} cannot be included in the composite primary"
    ],
    [
        "hint=f\"{duplicates} and {field_name!r} are the same fields.\",",
        "hint=f\"{duplicates} and {field_name!r} are"
    ],
    [
        "f\"{connection.display_name} does not support comments on \"",
        "f\"{connection.display_name} does not support"
    ],
    [
        "\"\"\"Check if the swapped model exists.\"\"\"",
        "\"\"\"Check if the"
    ],
    [
        "\"'%s' is not of the form 'app_label.app_name'.\"",
        "\"'%s' is not of the"
    ],
    [
        "\"'%s' references '%s.%s', which has not been \"",
        "\"'%s' references '%s.%s', which"
    ],
    [
        "\"Proxy model '%s' contains model fields.\" % cls.__name__,",
        "\"Proxy model '%s' contains model fields.\" %"
    ],
    [
        "fields = (f for f in fields if isinstance(f.remote_field.model, ModelBase))",
        "fields = (f for f"
    ],
    [
        "fields = (f for f in fields if isinstance(f.remote_field.through, ModelBase))",
        "fields = (f for f in fields"
    ],
    [
        "\"The model has two identical many-to-many relations \"",
        "\"The model has two identical many-to-many"
    ],
    [
        "\"\"\"Check if `id` field is a primary key.\"\"\"",
        "\"\"\"Check if `id` field"
    ],
    [
        "f for f in cls._meta.local_fields if f.name == \"id\" and f != cls._meta.pk",
        "f for f in cls._meta.local_fields if f.name == \"id\" and f"
    ],
    [
        "\"'id' can only be used as a field name if the field also \"",
        "\"'id' can only be used as a field name"
    ],
    [
        "\"\"\"Forbid field shadowing in multi-table inheritance.\"\"\"",
        "\"\"\"Forbid field shadowing in multi-table"
    ],
    [
        "clash = used_fields.get(f.name) or used_fields.get(f.attname) or None",
        "clash = used_fields.get(f.name) or used_fields.get(f.attname)"
    ],
    [
        "\"The field '%s' from parent model \"",
        "\"The field '%s' from parent model"
    ],
    [
        "\"'%s' clashes with the field '%s' \"",
        "\"'%s' clashes with the field"
    ],
    [
        "f\"The field '{parent_link.name}' clashes with the field \"",
        "f\"The field '{parent_link.name}' clashes with"
    ],
    [
        "clash = used_fields.get(f.name) or used_fields.get(f.attname) or None",
        "clash = used_fields.get(f.name) or"
    ],
    [
        "f.name == \"id\" and clash and clash.name == \"id\" and clash.model == cls",
        "f.name == \"id\" and clash and clash.name == \"id\" and clash.model"
    ],
    [
        "\"The field '%s' clashes with the field '%s' \"",
        "\"The field '%s' clashes with the field"
    ],
    [
        "\"from model '%s'.\" % (f.name, clash.name, clash.model._meta),",
        "\"from model '%s'.\" % (f.name, clash.name,"
    ],
    [
        "if column_name and column_name in used_column_names:",
        "if column_name and column_name in"
    ],
    [
        "\"Field '%s' has column name '%s' that is used by \"",
        "\"Field '%s' has column name '%s'"
    ],
    [
        "hint=\"Specify a 'db_column' for the field.\",",
        "hint=\"Specify a 'db_column'"
    ],
    [
        "\"The model name '%s' cannot start or end with an underscore \"",
        "\"The model name '%s' cannot start or"
    ],
    [
        "\"as it collides with the query lookup syntax.\" % model_name,",
        "\"as it collides with the query lookup"
    ],
    [
        "\"The model name '%s' cannot contain double underscores as \"",
        "\"The model name '%s' cannot contain"
    ],
    [
        "\"it collides with the query lookup syntax.\" % model_name,",
        "\"it collides with the query lookup"
    ],
    [
        "if f.is_relation and f.related_model is not None",
        "if f.is_relation and f.related_model is"
    ],
    [
        "\"The property '%s' clashes with a related field \"",
        "\"The property '%s' clashes with"
    ],
    [
        "\"The model cannot have more than one field with \"",
        "\"The model cannot have more than"
    ],
    [
        "\"\"\"Check the value of \"unique_together\" option.\"\"\"",
        "\"\"\"Check the value of \"unique_together\""
    ],
    [
        "\"'unique_together' must be a list or tuple.\",",
        "\"'unique_together' must be a"
    ],
    [
        "\"All 'unique_together' elements must be lists or tuples.\",",
        "\"All 'unique_together' elements must"
    ],
    [
        "\"\"\"Check fields, names, and conditions of indexes.\"\"\"",
        "\"\"\"Check fields, names, and"
    ],
    [
        "\"The index name '%s' cannot start with an underscore \"",
        "\"The index name '%s' cannot start with an underscore"
    ],
    [
        "\"The index name '%s' cannot be longer than %d \"",
        "\"The index name '%s' cannot be"
    ],
    [
        ") and any(index.condition is not None for index in cls._meta.indexes):",
        ") and any(index.condition is not"
    ],
    [
        "\"%s does not support indexes with conditions.\"",
        "\"%s does not support"
    ],
    [
        "\"Conditions will be ignored. Silence this warning \"",
        "\"Conditions will be ignored. Silence"
    ],
    [
        "\"if you don't care about it.\"",
        "\"if you don't care about"
    ],
    [
        ") and any(index.include for index in cls._meta.indexes):",
        ") and any(index.include for"
    ],
    [
        "\"%s does not support indexes with non-key columns.\"",
        "\"%s does not support"
    ],
    [
        "\"Non-key columns will be ignored. Silence this \"",
        "\"Non-key columns will be ignored. Silence this"
    ],
    [
        "\"warning if you don't care about it.\"",
        "\"warning if you don't care"
    ],
    [
        ") and any(index.contains_expressions for index in cls._meta.indexes):",
        ") and any(index.contains_expressions for index"
    ],
    [
        "\"%s does not support indexes on expressions.\"",
        "\"%s does not support"
    ],
    [
        "\"An index won't be created. Silence this warning \"",
        "\"An index won't be created. Silence"
    ],
    [
        "\"if you don't care about it.\"",
        "\"if you don't care"
    ],
    [
        "field for index in cls._meta.indexes for field, _ in index.fields_orders",
        "field for index in cls._meta.indexes for"
    ],
    [
        "fields += [include for index in cls._meta.indexes for include in index.include]",
        "fields += [include for index in cls._meta.indexes for include in"
    ],
    [
        "\"'%s' refers to the nonexistent field '%s'.\"",
        "\"'%s' refers to the nonexistent field"
    ],
    [
        "\"'%s' refers to a ManyToManyField '%s', but \"",
        "\"'%s' refers to a ManyToManyField"
    ],
    [
        "\"ManyToManyFields are not permitted in '%s'.\"",
        "\"ManyToManyFields are not permitted in"
    ],
    [
        "f\"{option!r} refers to a CompositePrimaryKey \"",
        "f\"{option!r} refers to"
    ],
    [
        "f\"{field_name!r}, but CompositePrimaryKeys are not \"",
        "f\"{field_name!r}, but CompositePrimaryKeys are not"
    ],
    [
        "\"'%s' refers to field '%s' which is not local to model \"",
        "\"'%s' refers to field '%s' which is not local to model"
    ],
    [
        "hint=\"This issue may be caused by multi-table inheritance.\",",
        "hint=\"This issue may be caused by multi-table"
    ],
    [
        "Check \"ordering\" option -- is it a list of strings and do all fields",
        "Check \"ordering\" option -- is it a list of"
    ],
    [
        "\"'ordering' and 'order_with_respect_to' cannot be used together.\",",
        "\"'ordering' and 'order_with_respect_to' cannot"
    ],
    [
        "\"'ordering' must be a tuple or list (even if you want to order by \"",
        "\"'ordering' must be a tuple or list (even if you want to"
    ],
    [
        "fields = (f for f in fields if isinstance(f, str) and f != \"?\")",
        "fields = (f for f in fields if isinstance(f, str) and f !="
    ],
    [
        "fields = (f.removeprefix(\"-\") for f in fields)",
        "fields = (f.removeprefix(\"-\") for f in"
    ],
    [
        "if fld is None or (",
        "if fld is None"
    ],
    [
        "fld.get_transform(part) is None and fld.get_lookup(part) is None",
        "fld.get_transform(part) is None and fld.get_lookup(part)"
    ],
    [
        "\"'ordering' refers to the nonexistent field, \"",
        "\"'ordering' refers to the nonexistent field,"
    ],
    [
        "\"related field, or lookup '%s'.\" % field,",
        "\"related field, or lookup '%s'.\""
    ],
    [
        "fields = {f for f in fields if f != \"pk\"}",
        "fields = {f for f in fields if f"
    ],
    [
        "if not (f.auto_created and not f.concrete)",
        "if not (f.auto_created"
    ],
    [
        "\"'ordering' refers to the nonexistent field, related \"",
        "\"'ordering' refers to the nonexistent"
    ],
    [
        "\"field, or lookup '%s'.\" % invalid_field,",
        "\"field, or lookup"
    ],
    [
        "Check that any auto-generated column names are shorter than the limits",
        "Check that any auto-generated column names are shorter than the"
    ],
    [
        "for each database in which the model will be created.",
        "for each database in which"
    ],
    [
        "if max_name_length is None or connection.features.truncates_names:",
        "if max_name_length is None or"
    ],
    [
        "and (column_name := f.column) is not None",
        "and (column_name := f.column) is"
    ],
    [
        "'Autogenerated column name too long for field \"%s\". '",
        "'Autogenerated column name too long for field \"%s\"."
    ],
    [
        "'Maximum length is \"%s\" for database \"%s\".'",
        "'Maximum length is \"%s\" for database"
    ],
    [
        "hint=\"Set the column name manually using 'db_column'.\",",
        "hint=\"Set the column name"
    ],
    [
        "'\"%s\". Maximum length is \"%s\" for database \"%s\".'",
        "'\"%s\". Maximum length is \"%s\" for database"
    ],
    [
        "\"Use 'through' to create a separate model for \"",
        "\"Use 'through' to create a"
    ],
    [
        "[ordered_obj(pk=pk, _order=order) for order, pk in enumerate(id_list)],",
        "[ordered_obj(pk=pk, _order=order) for order, pk in"
    ],
    [
        "\"\"\"Used to unpickle Model subclasses with deferred fields.\"\"\"",
        "\"\"\"Used to unpickle Model"
    ],
    [
        "from django.db.models.fields import DecimalField, FloatField, IntegerField",
        "from django.db.models.fields import DecimalField,"
    ],
    [
        "sql, params = super().as_sql(compiler, connection, **extra_context)",
        "sql, params = super().as_sql(compiler, connection,"
    ],
    [
        "sql = \"CAST(%s AS SIGNED)\" % sql",
        "sql = \"CAST(%s AS SIGNED)\""
    ],
    [
        "if any(isinstance(s, DecimalField) for s in source_fields):",
        "if any(isinstance(s, DecimalField) for s in"
    ],
    [
        "if any(isinstance(s, IntegerField) for s in source_fields):",
        "if any(isinstance(s, IntegerField) for"
    ],
    [
        "return super()._resolve_output_field() if source_fields else FloatField()",
        "return super()._resolve_output_field() if source_fields else"
    ],
    [
        "\"%s requires a non-null source expression.\" % self.__class__.__name__",
        "\"%s requires a non-null source expression.\""
    ],
    [
        "\"%s requires a positive integer for the offset.\"",
        "\"%s requires a positive"
    ],
    [
        "\"%s requires a non-null source expression.\" % self.__class__.__name__",
        "\"%s requires a non-null source expression.\" %"
    ],
    [
        "\"%s requires a positive integer as for nth.\" % self.__class__.__name__",
        "\"%s requires a positive integer as for nth.\""
    ],
    [
        "from .comparison import Cast, Coalesce, Collate, Greatest, Least, NullIf",
        "from .comparison import Cast, Coalesce, Collate, Greatest, Least,"
    ],
    [
        "\"\"\"Database functions that do comparisons or type conversions.\"\"\"",
        "\"\"\"Database functions that do comparisons"
    ],
    [
        "\"\"\"Coerce an expression to a new field type.\"\"\"",
        "\"\"\"Coerce an expression to a new field"
    ],
    [
        "format_string = \"%H:%M:%f\" if db_type == \"time\" else \"%Y-%m-%d %H:%M:%f\"",
        "format_string = \"%H:%M:%f\" if db_type =="
    ],
    [
        "elif output_type == \"JSONField\" and connection.mysql_is_mariadb:",
        "elif output_type == \"JSONField\""
    ],
    [
        "\"\"\"Return, from left to right, the first non-null expression.\"\"\"",
        "\"\"\"Return, from left to right,"
    ],
    [
        "raise ValueError(\"Coalesce must take at least two expressions\")",
        "raise ValueError(\"Coalesce must take"
    ],
    [
        "if result is NotImplemented or result is not None:",
        "if result is NotImplemented or result is"
    ],
    [
        "raise ValueError(\"Invalid collation name: %r.\" % collation)",
        "raise ValueError(\"Invalid collation name: %r.\""
    ],
    [
        "If any expression is null the return value is database-specific:",
        "If any expression is null the"
    ],
    [
        "On PostgreSQL, the maximum not-null expression is returned.",
        "On PostgreSQL, the maximum not-null expression is"
    ],
    [
        "On MySQL, Oracle, and SQLite, if any expression is null, null is returned.",
        "On MySQL, Oracle, and SQLite, if any expression is"
    ],
    [
        "raise ValueError(\"Greatest must take at least two expressions\")",
        "raise ValueError(\"Greatest must take at"
    ],
    [
        "\"\"\"Use the MAX function on SQLite.\"\"\"",
        "\"\"\"Use the MAX function on"
    ],
    [
        "If any expression is null the return value is database-specific:",
        "If any expression is null the return"
    ],
    [
        "On PostgreSQL, return the minimum not-null expression.",
        "On PostgreSQL, return the minimum"
    ],
    [
        "On MySQL, Oracle, and SQLite, if any expression is null, return null.",
        "On MySQL, Oracle, and SQLite, if any expression is"
    ],
    [
        "raise ValueError(\"Least must take at least two expressions\")",
        "raise ValueError(\"Least must take at least two"
    ],
    [
        "\"\"\"Use the MIN function on SQLite.\"\"\"",
        "\"\"\"Use the MIN function on"
    ],
    [
        "from django.db.models.fields import CharField, IntegerField, TextField",
        "from django.db.models.fields import"
    ],
    [
        "Concatenate two arguments together. This is used by `Concat` because not",
        "Concatenate two arguments together. This is used by"
    ],
    [
        "all backend databases support more than two arguments.",
        "all backend databases support more than two"
    ],
    [
        "Concatenate text fields together. Backends that result in an entire",
        "Concatenate text fields together. Backends that"
    ],
    [
        "null expression when any arguments are null will wrap each argument in",
        "null expression when any arguments are null will wrap each argument"
    ],
    [
        "coalesce functions to ensure a non-null result.",
        "coalesce functions to ensure"
    ],
    [
        "raise ValueError(\"Concat must take at least two expressions\")",
        "raise ValueError(\"Concat must take at least"
    ],
    [
        "expression: the name of a field, or an expression returning a string",
        "expression: the name of a field, or an expression returning a"
    ],
    [
        "length: the number of characters to return from the start of the string",
        "length: the number of characters to return from the start of"
    ],
    [
        "\"\"\"Return the number of characters in the expression.\"\"\"",
        "\"\"\"Return the number of characters in"
    ],
    [
        "def __init__(self, expression, length, fill_text=Value(\" \"), **extra):",
        "def __init__(self, expression, length,"
    ],
    [
        "length = None if number is None else Length(expression) * number",
        "length = None if number is"
    ],
    [
        "def __init__(self, expression, text, replacement=Value(\"\"), **extra):",
        "def __init__(self, expression, text,"
    ],
    [
        "\"(SELECT LISTAGG(s) WITHIN GROUP (ORDER BY n DESC) FROM \"",
        "\"(SELECT LISTAGG(s) WITHIN GROUP (ORDER BY n"
    ],
    [
        "\"CONNECT BY LEVEL <= LENGTH(%(expressions)s)) \"",
        "\"CONNECT BY LEVEL <="
    ],
    [
        "def __init__(self, expression, pos, length=None, **extra):",
        "def __init__(self, expression,"
    ],
    [
        "expression: the name of a field, or an expression returning a string",
        "expression: the name of a field, or an expression returning"
    ],
    [
        "length: an optional number of characters to return",
        "length: an optional number of characters"
    ],
    [
        "raise ValueError(\"SQLite does not support negative precision.\")",
        "raise ValueError(\"SQLite does not support negative"
    ],
    [
        "def __init__(self, expression, lookup_name=None, tzinfo=None, **extra):",
        "def __init__(self, expression,"
    ],
    [
        "raise ValueError(\"tzinfo can only be used with DateTimeField.\")",
        "raise ValueError(\"tzinfo can only be used with"
    ],
    [
        "\"Extract requires native DurationField database support.\"",
        "\"Extract requires native DurationField"
    ],
    [
        "assert False, \"Tried to Extract from an invalid type.\"",
        "assert False, \"Tried to Extract from an"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True, reuse=None, summarize=False,"
    ],
    [
        "if not isinstance(field, (DateField, DateTimeField, TimeField, DurationField)):",
        "if not isinstance(field, (DateField,"
    ],
    [
        "\"Extract input expression must be DateField, DateTimeField, \"",
        "\"Extract input expression must be DateField,"
    ],
    [
        "if type(field) is DateField and copy.lookup_name in (",
        "if type(field) is DateField and copy.lookup_name in"
    ],
    [
        "\"Cannot extract time component '%s' from DateField '%s'.\"",
        "\"Cannot extract time component"
    ],
    [
        "if isinstance(field, DurationField) and copy.lookup_name in (",
        "if isinstance(field, DurationField) and copy.lookup_name in"
    ],
    [
        "\"Cannot extract component '%s' from DurationField '%s'.\"",
        "\"Cannot extract component '%s'"
    ],
    [
        "raise ValueError(\"tzinfo can only be used with DateTimeField.\")",
        "raise ValueError(\"tzinfo can only be used with"
    ],
    [
        "\"Trunc only valid on DateField, TimeField, or DateTimeField.\"",
        "\"Trunc only valid on"
    ],
    [
        "self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False",
        "self, query=None, allow_joins=True,"
    ],
    [
        "\"%r isn't a DateField, TimeField, or DateTimeField.\" % field.name",
        "\"%r isn't a DateField, TimeField, or DateTimeField.\" %"
    ],
    [
        "if not isinstance(copy.output_field, (DateField, DateTimeField, TimeField)):",
        "if not isinstance(copy.output_field, (DateField, DateTimeField,"
    ],
    [
        "\"output_field must be either DateField, TimeField, or DateTimeField\"",
        "\"output_field must be either DateField, TimeField, or"
    ],
    [
        "class_output_field or field.__class__ is not copy.output_field.__class__",
        "class_output_field or field.__class__"
    ],
    [
        "if type(field) is DateField and (",
        "if type(field) is"
    ],
    [
        "or copy.kind in (\"hour\", \"minute\", \"second\", \"time\")",
        "or copy.kind in (\"hour\", \"minute\", \"second\","
    ],
    [
        "\"Cannot truncate DateField '%s' to %s.\"",
        "\"Cannot truncate DateField '%s' to"
    ],
    [
        "or copy.kind in (\"year\", \"quarter\", \"month\", \"week\", \"day\", \"date\")",
        "or copy.kind in (\"year\", \"quarter\", \"month\", \"week\", \"day\","
    ],
    [
        "\"Cannot truncate TimeField '%s' to %s.\"",
        "\"Cannot truncate TimeField"
    ],
    [
        "\"Database returned an invalid datetime value. Are time \"",
        "\"Database returned an invalid datetime"
    ],
    [
        "\"zone definitions for your database installed?\"",
        "\"zone definitions for your"
    ],
    [
        "\"\"\"Truncate to midnight on the Monday of the week.\"\"\"",
        "\"\"\"Truncate to midnight on the Monday of"
    ],
    [
        "\"JSONFields are not supported on this database backend.\"",
        "\"JSONFields are not supported on this database"
    ],
    [
        "def as_native(self, compiler, connection, *, returning, **extra_context):",
        "def as_native(self, compiler, connection,"
    ],
    [
        "\"JSONObject() is not supported on this database backend.\"",
        "\"JSONObject() is not supported on this"
    ],
    [
        "return \", \".join([f\"({key}) VALUE {value}\" for key, value in pairs])",
        "return \", \".join([f\"({key}) VALUE {value}\" for key, value in"
    ],
    [
        "def as_native(self, compiler, connection, *, returning, **extra_context):",
        "def as_native(self, compiler, connection, *,"
    ],
    [
        "When a field defines a relation between two models, each model class provides",
        "When a field defines a relation between two models, each model"
    ],
    [
        "an attribute to access related instances of the other model class (unless the",
        "an attribute to access related instances of the other model"
    ],
    [
        "reverse accessor has been disabled with related_name='+').",
        "reverse accessor has been disabled"
    ],
    [
        "Accessors are implemented as descriptors in order to customize access and",
        "Accessors are implemented as descriptors in order to"
    ],
    [
        "assignment. This module defines the descriptor classes.",
        "assignment. This module defines the"
    ],
    [
        "Forward accessors follow foreign keys. Reverse accessors trace them back. For",
        "Forward accessors follow foreign keys. Reverse accessors trace"
    ],
    [
        "``child.parent`` is a forward many-to-one relation. ``parent.children`` is a",
        "``child.parent`` is a forward many-to-one"
    ],
    [
        "There are three types of relations (many-to-one, one-to-one, and many-to-many)",
        "There are three types of relations (many-to-one,"
    ],
    [
        "and two directions (forward and reverse) for a total of six combinations.",
        "and two directions (forward and reverse) for a total"
    ],
    [
        "Uniqueness of foreign key values is irrelevant to accessing the related",
        "Uniqueness of foreign key values is irrelevant to accessing"
    ],
    [
        "instance, making the many-to-one and one-to-one cases identical as far as",
        "instance, making the many-to-one and one-to-one cases identical"
    ],
    [
        "the descriptor is concerned. The constraint is checked upstream (unicity",
        "the descriptor is concerned. The constraint is checked upstream"
    ],
    [
        "validation in forms) or downstream (unique indexes in the database).",
        "validation in forms) or downstream (unique indexes in the"
    ],
    [
        "It avoids querying the database when accessing the parent link field in",
        "It avoids querying the database when accessing the parent link field"
    ],
    [
        "One-to-one relations are asymmetrical, despite the apparent symmetry of the",
        "One-to-one relations are asymmetrical, despite the apparent symmetry"
    ],
    [
        "name, because they're implemented in the database with a foreign key from",
        "name, because they're implemented in the database with a"
    ],
    [
        "one table to another. As a consequence ``ReverseOneToOneDescriptor`` is",
        "one table to another. As a"
    ],
    [
        "Unlike the previous two classes, this one provides access to a collection",
        "Unlike the previous two classes, this one provides"
    ],
    [
        "of objects. It returns a manager rather than an instance.",
        "of objects. It returns a manager rather than an"
    ],
    [
        "sides of a many-to-many relation: ``ManyToManyDescriptor``.",
        "sides of a"
    ],
    [
        "Many-to-many relations are symmetrical. The syntax of Django models",
        "Many-to-many relations are symmetrical. The"
    ],
    [
        "requires declaring them on one side but that's an implementation detail.",
        "requires declaring them on one side but"
    ],
    [
        "They could be declared on the other side without any change in behavior.",
        "They could be declared on the other side without"
    ],
    [
        "Therefore the forward and reverse descriptors can be the same.",
        "Therefore the forward and reverse descriptors"
    ],
    [
        "If you're looking for ``ForwardManyToManyDescriptor`` or",
        "If you're looking for ``ForwardManyToManyDescriptor``"
    ],
    [
        "from django.db.models import Manager, Q, Window, signals",
        "from django.db.models import Manager,"
    ],
    [
        "if instance.__dict__.get(self.field.attname) != value and self.field.is_cached(",
        "if instance.__dict__.get(self.field.attname) != value and"
    ],
    [
        "\"Prefetching from a limited queryset is only supported on backends \"",
        "\"Prefetching from a limited queryset is only"
    ],
    [
        "expr for expr, _ in queryset.query.get_compiler(using=db).get_order_by()",
        "expr for expr, _"
    ],
    [
        "Accessor to the related object on the forward side of a many-to-one or",
        "Accessor to the related object on the forward side of a"
    ],
    [
        "\"querysets argument of get_prefetch_querysets() should have a length \"",
        "\"querysets argument of get_prefetch_querysets() should have a length"
    ],
    [
        "instances_dict = {instance_attr(inst): inst for inst in instances}",
        "instances_dict = {instance_attr(inst): inst for"
    ],
    [
        "Get the related instance through the forward relation.",
        "Get the related instance through the"
    ],
    [
        "With the example above, when getting ``child.parent``:",
        "With the example above, when"
    ],
    [
        "- ``self`` is the descriptor managing the ``parent`` attribute",
        "- ``self`` is the descriptor managing"
    ],
    [
        "- ``instance`` is the ``child`` instance",
        "- ``instance`` is the ``child``"
    ],
    [
        "- ``cls`` is the ``Child`` class (we don't need it)",
        "- ``cls`` is the ``Child`` class (we"
    ],
    [
        "has_value = None not in self.field.get_local_related_value(instance)",
        "has_value = None not in"
    ],
    [
        "if rel_obj is None and has_value:",
        "if rel_obj is None and"
    ],
    [
        "if rel_obj is None and not self.field.null:",
        "if rel_obj is None and"
    ],
    [
        "\"%s has no %s.\" % (self.field.model.__name__, self.field.name)",
        "\"%s has no %s.\" %"
    ],
    [
        "Set the related instance through the forward relation.",
        "Set the related instance through the"
    ],
    [
        "With the example above, when setting ``child.parent = parent``:",
        "With the example above, when"
    ],
    [
        "- ``self`` is the descriptor managing the ``parent`` attribute",
        "- ``self`` is the descriptor managing the"
    ],
    [
        "- ``instance`` is the ``child`` instance",
        "- ``instance`` is"
    ],
    [
        "- ``value`` is the ``parent`` instance on the right of the equal sign",
        "- ``value`` is the ``parent`` instance on the right of the"
    ],
    [
        "if value is not None and not isinstance(",
        "if value is not"
    ],
    [
        "'Cannot assign \"%r\": \"%s.%s\" must be a \"%s\" instance.'",
        "'Cannot assign \"%r\": \"%s.%s\" must"
    ],
    [
        "'Cannot assign \"%r\": the current database router prevents this '",
        "'Cannot assign \"%r\": the current database router"
    ],
    [
        "if value is not None and not remote_field.multiple:",
        "if value is not None and not"
    ],
    [
        "Pickling should return the instance attached by self.field on the",
        "Pickling should return the instance attached by"
    ],
    [
        "model, not a new copy of that descriptor. Use getattr() to retrieve",
        "model, not a new copy of that descriptor. Use getattr()"
    ],
    [
        "the instance directly from the model.",
        "the instance directly"
    ],
    [
        "Accessor to the related object on the forward side of a one-to-one relation.",
        "Accessor to the related object on the forward side of a"
    ],
    [
        "fields = [field.attname for field in rel_model._meta.concrete_fields]",
        "fields = [field.attname for field in"
    ],
    [
        "if not any(field in fields for field in deferred):",
        "if not any(field in fields for field"
    ],
    [
        "kwargs = {field: getattr(instance, field) for field in fields}",
        "kwargs = {field: getattr(instance, field) for"
    ],
    [
        "getattr(value, rel_model_pk_name) if value is not None else None",
        "getattr(value, rel_model_pk_name) if value is not None else"
    ],
    [
        "Accessor to the related object on the reverse side of a one-to-one",
        "Accessor to the related object on the"
    ],
    [
        "\"querysets argument of get_prefetch_querysets() should have a length \"",
        "\"querysets argument of get_prefetch_querysets() should have"
    ],
    [
        "instances_dict = {instance_attr(inst): inst for inst in instances}",
        "instances_dict = {instance_attr(inst): inst"
    ],
    [
        "query = {\"%s__in\" % self.related.field.name: instances}",
        "query = {\"%s__in\""
    ],
    [
        "Get the related instance through the reverse relation.",
        "Get the related instance through the"
    ],
    [
        "With the example above, when getting ``place.restaurant``:",
        "With the example above, when"
    ],
    [
        "- ``self`` is the descriptor managing the ``restaurant`` attribute",
        "- ``self`` is the descriptor managing the"
    ],
    [
        "- ``instance`` is the ``place`` instance",
        "- ``instance`` is"
    ],
    [
        "- ``cls`` is the ``Place`` class (unused)",
        "- ``cls`` is the ``Place`` class"
    ],
    [
        "Keep in mind that ``Restaurant`` holds the foreign key to ``Place``.",
        "Keep in mind that ``Restaurant`` holds"
    ],
    [
        "Set the related instance through the reverse relation.",
        "Set the related instance"
    ],
    [
        "With the example above, when setting ``place.restaurant = restaurant``:",
        "With the example above, when"
    ],
    [
        "- ``self`` is the descriptor managing the ``restaurant`` attribute",
        "- ``self`` is the descriptor managing the ``restaurant``"
    ],
    [
        "- ``instance`` is the ``place`` instance",
        "- ``instance`` is the ``place``"
    ],
    [
        "- ``value`` is the ``restaurant`` instance on the right of the equal sign",
        "- ``value`` is the ``restaurant`` instance on the"
    ],
    [
        "Keep in mind that ``Restaurant`` holds the foreign key to ``Place``.",
        "Keep in mind that ``Restaurant`` holds the foreign"
    ],
    [
        "'Cannot assign \"%r\": \"%s.%s\" must be a \"%s\" instance.'",
        "'Cannot assign \"%r\": \"%s.%s\" must"
    ],
    [
        "'Cannot assign \"%r\": the current database router prevents this '",
        "'Cannot assign \"%r\": the current database router prevents"
    ],
    [
        "Accessor to the related objects manager on the reverse side of a",
        "Accessor to the related objects manager"
    ],
    [
        "Most of the implementation is delegated to a dynamically defined manager",
        "Most of the implementation is delegated"
    ],
    [
        "class built by ``create_forward_many_to_many_manager()`` defined below.",
        "class built by"
    ],
    [
        "Get the related objects through the reverse relation.",
        "Get the related objects through"
    ],
    [
        "With the example above, when getting ``parent.children``:",
        "With the example above, when getting"
    ],
    [
        "- ``self`` is the descriptor managing the ``children`` attribute",
        "- ``self`` is the descriptor managing the ``children``"
    ],
    [
        "- ``instance`` is the ``parent`` instance",
        "- ``instance`` is"
    ],
    [
        "- ``cls`` is the ``Parent`` class (unused)",
        "- ``cls`` is the"
    ],
    [
        "\"reverse side of a related set\",",
        "\"reverse side of"
    ],
    [
        "\"Direct assignment to the %s is prohibited. Use %s.set() instead.\"",
        "\"Direct assignment to the %s is prohibited. Use"
    ],
    [
        "Create a manager for the reverse side of a many-to-one relation.",
        "Create a manager for the reverse side of a many-to-one"
    ],
    [
        "This manager subclasses another manager, generally the default manager of",
        "This manager subclasses another manager, generally"
    ],
    [
        "the related model, and adds behaviors specific to many-to-one relations.",
        "the related model, and adds behaviors"
    ],
    [
        "f'\"{self.instance!r}\" needs to have a value for field '",
        "f'\"{self.instance!r}\" needs to have a value"
    ],
    [
        "f'\"{field.attname}\" before this relationship can be used.'",
        "f'\"{field.attname}\" before this relationship"
    ],
    [
        "Filter the queryset for the instance this manager is bound to.",
        "Filter the queryset for the instance this manager is bound"
    ],
    [
        "db = self._db or router.db_for_read(self.model, instance=self.instance)",
        "db = self._db"
    ],
    [
        "if val is None or (val == \"\" and empty_strings_as_null):",
        "if val is None or"
    ],
    [
        "f\"{self.instance.__class__.__name__!r} instance needs to have a \"",
        "f\"{self.instance.__class__.__name__!r} instance needs to"
    ],
    [
        "f\"primary key value before this relationship can be used.\"",
        "f\"primary key value before this relationship"
    ],
    [
        "\"querysets argument of get_prefetch_querysets() should have a \"",
        "\"querysets argument of get_prefetch_querysets()"
    ],
    [
        "instances_dict = {instance_attr(inst): inst for inst in instances}",
        "instances_dict = {instance_attr(inst): inst"
    ],
    [
        "return queryset, rel_obj_attr, instance_attr, False, cache_name, False",
        "return queryset, rel_obj_attr, instance_attr, False,"
    ],
    [
        "if obj._state.adding or obj._state.db != db:",
        "if obj._state.adding or obj._state.db"
    ],
    [
        "\"%r instance isn't saved. Use bulk=False or save \"",
        "\"%r instance isn't saved. Use bulk=False or save"
    ],
    [
        "\"%r is not related to %r.\" % (obj, self.instance)",
        "\"%r is not related to %r.\" %"
    ],
    [
        "def set(self, objs, *, bulk=True, clear=False):",
        "def set(self, objs, *, bulk=True,"
    ],
    [
        "async def aset(self, objs, *, bulk=True, clear=False):",
        "async def aset(self, objs,"
    ],
    [
        "Accessor to the related objects manager on the forward and reverse sides of",
        "Accessor to the related objects manager on the forward and reverse sides"
    ],
    [
        "Most of the implementation is delegated to a dynamically defined manager",
        "Most of the implementation is delegated"
    ],
    [
        "class built by ``create_forward_many_to_many_manager()`` defined below.",
        "class built by"
    ],
    [
        "related_model = self.rel.related_model if self.reverse else self.rel.model",
        "related_model = self.rel.related_model if self.reverse"
    ],
    [
        "\"%s side of a many-to-many set\"",
        "\"%s side of a"
    ],
    [
        "% (\"reverse\" if self.reverse else \"forward\"),",
        "% (\"reverse\" if self.reverse"
    ],
    [
        "Create a manager for the either side of a many-to-many relation.",
        "Create a manager for the either side of"
    ],
    [
        "This manager subclasses another manager, generally the default manager of",
        "This manager subclasses another manager,"
    ],
    [
        "the related model, and adds behaviors specific to many-to-many relations.",
        "the related model, and adds behaviors specific to many-to-many"
    ],
    [
        "core_filter_key = \"%s__%s\" % (self.query_field_name, rh_field.name)",
        "core_filter_key = \"%s__%s\" %"
    ],
    [
        "'\"%r\" needs to have a value for field \"%s\" before '",
        "'\"%r\" needs to have a value for field \"%s\""
    ],
    [
        "\"this many-to-many relationship can be used.\"",
        "\"this many-to-many relationship"
    ],
    [
        "\"%r instance needs to have a primary key value before \"",
        "\"%r instance needs to have a primary key value before"
    ],
    [
        "\"a many-to-many relationship can be used.\"",
        "\"a many-to-many relationship can be"
    ],
    [
        "Filter the queryset for the instance this manager is bound to.",
        "Filter the queryset for the instance this"
    ],
    [
        "if (cache := self.get_prefetch_cache()) is not None:",
        "if (cache := self.get_prefetch_cache())"
    ],
    [
        "\"querysets argument of get_prefetch_querysets() should have a \"",
        "\"querysets argument of get_prefetch_querysets()"
    ],
    [
        "and (constrained_target := self.constrained_target) is not None",
        "and (constrained_target := self.constrained_target) is not"
    ],
    [
        "and (constrained_target := self.constrained_target) is not None",
        "and (constrained_target := self.constrained_target) is"
    ],
    [
        "def set(self, objs, *, clear=False, through_defaults=None):",
        "def set(self, objs, *, clear=False,"
    ],
    [
        "async def aset(self, objs, *, clear=False, through_defaults=None):",
        "async def aset(self, objs,"
    ],
    [
        "async def acreate(self, *, through_defaults=None, **kwargs):",
        "async def acreate(self,"
    ],
    [
        "async def aget_or_create(self, *, through_defaults=None, **kwargs):",
        "async def aget_or_create(self,"
    ],
    [
        "async def aupdate_or_create(self, *, through_defaults=None, **kwargs):",
        "async def aupdate_or_create(self, *,"
    ],
    [
        "Return the set of ids of `objs` that the target field references.",
        "Return the set of ids of"
    ],
    [
        "'Cannot add \"%r\": instance is on database \"%s\", '",
        "'Cannot add \"%r\": instance is on database \"%s\","
    ],
    [
        "'Cannot add \"%r\": the value for field \"%s\" is None'",
        "'Cannot add \"%r\": the value for field \"%s\" is"
    ],
    [
        "Return the subset of ids of `objs` that aren't already assigned to",
        "Return the subset of ids of `objs` that aren't already"
    ],
    [
        "Return a boolean triple of the way the add should be performed.",
        "Return a boolean triple of the way the add should"
    ],
    [
        "The first element is whether or not bulk_create(ignore_conflicts)",
        "The first element is whether or"
    ],
    [
        "can be used, the second whether or not signals must be sent, and",
        "can be used, the second whether or not signals"
    ],
    [
        "the third element is whether or not the immediate bulk insertion",
        "the third element is whether or not the immediate bulk"
    ],
    [
        "with conflicts ignored can be performed.",
        "with conflicts ignored can be"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"The '%s' attribute has no file associated with it.\" % self.field.name",
        "\"The '%s' attribute has no file associated with it.\""
    ],
    [
        "if getattr(self, \"_file\", None) is None:",
        "if getattr(self, \"_file\", None)"
    ],
    [
        "if getattr(self, \"_file\", None) is None:",
        "if getattr(self, \"_file\","
    ],
    [
        "return file is None or file.closed",
        "return file is None"
    ],
    [
        "The descriptor for the file attribute on the model instance. Return a",
        "The descriptor for the file attribute on"
    ],
    [
        "FieldFile when accessed so you can write code like::",
        "FieldFile when accessed so you"
    ],
    [
        "Assign a file object on assignment so you can do::",
        "Assign a file object on assignment so you can"
    ],
    [
        "if isinstance(file, str) or file is None:",
        "if isinstance(file, str) or file"
    ],
    [
        "elif isinstance(file, File) and not isinstance(file, FieldFile):",
        "elif isinstance(file, File) and not"
    ],
    [
        "elif isinstance(file, FieldFile) and not hasattr(file, \"field\"):",
        "elif isinstance(file, FieldFile) and not"
    ],
    [
        "elif isinstance(file, FieldFile) and instance is not file.instance:",
        "elif isinstance(file, FieldFile) and instance is"
    ],
    [
        "self, verbose_name=None, name=None, upload_to=\"\", storage=None, **kwargs",
        "self, verbose_name=None, name=None, upload_to=\"\", storage=None,"
    ],
    [
        "\"%s.storage must be a subclass/instance of %s.%s\"",
        "\"%s.storage must be a subclass/instance"
    ],
    [
        "\"'primary_key' is not a valid argument for a %s.\"",
        "\"'primary_key' is not a valid argument for a"
    ],
    [
        "\"%s's 'upload_to' argument must be a relative path, not an \"",
        "\"%s's 'upload_to' argument must be a relative"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "if file.name is None and file._file is not None:",
        "if file.name is None and file._file"
    ],
    [
        "f\"File for {self.name} must have \"",
        "f\"File for {self.name}"
    ],
    [
        "\"the name attribute specified to be saved.\"",
        "\"the name attribute specified"
    ],
    [
        "exc.add_note(\"Pass a 'name' argument to ContentFile.\")",
        "exc.add_note(\"Pass a 'name' argument"
    ],
    [
        "Apply (if callable) or prepend (if a string) upload_to to the filename,",
        "Apply (if callable) or prepend (if a string)"
    ],
    [
        "then delegate further processing of the name to the storage backend.",
        "then delegate further processing of the name to"
    ],
    [
        "Until the storage layer, all file paths are expected to be Unix style",
        "Until the storage layer, all file paths are expected"
    ],
    [
        "Just like the FileDescriptor, but for ImageFields. The only difference is",
        "Just like the FileDescriptor, but for ImageFields."
    ],
    [
        "assigning the width/height to the width_field/height_field, if appropriate.",
        "assigning the width/height to the width_field/height_field,"
    ],
    [
        "\"Cannot use ImageField because Pillow is not installed.\",",
        "\"Cannot use ImageField because Pillow"
    ],
    [
        "'or run command \"python -m pip install Pillow\".'",
        "'or run command \"python -m pip"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "if not cls._meta.abstract and (self.width_field or self.height_field):",
        "if not cls._meta.abstract and (self.width_field"
    ],
    [
        "def update_dimension_fields(self, instance, force=False, *args, **kwargs):",
        "def update_dimension_fields(self, instance, force=False, *args,"
    ],
    [
        "Update field's width and height fields, if defined.",
        "Update field's width and height fields,"
    ],
    [
        "This method is hooked up to model's post_init signal to update",
        "This method is hooked up to"
    ],
    [
        "dimensions after instantiating a model instance.  However, dimensions",
        "dimensions after instantiating a model instance."
    ],
    [
        "won't be updated if the dimensions fields are already populated.  This",
        "won't be updated if the dimensions fields are"
    ],
    [
        "avoids unnecessary recalculation when loading an object from the",
        "avoids unnecessary recalculation when loading an object from"
    ],
    [
        "Dimensions can be forced to update with force=True, which is how",
        "Dimensions can be forced to update with force=True, which"
    ],
    [
        "if not has_dimension_fields or self.attname not in instance.__dict__:",
        "if not has_dimension_fields or self.attname"
    ],
    [
        "if not file and not force:",
        "if not file and not"
    ],
    [
        "or (self.height_field and not getattr(instance, self.height_field))",
        "or (self.height_field and not getattr(instance,"
    ],
    [
        "An API for working with the model's fields value cache.",
        "An API for working with the model's fields"
    ],
    [
        "Subclasses must set self.cache_name to a unique entry for the cache -",
        "Subclasses must set self.cache_name to a unique entry for"
    ],
    [
        "_default_hint = (\"<valid default>\", \"<invalid default>\")",
        "_default_hint = (\"<valid default>\","
    ],
    [
        "\"%s default should be a callable instead of an instance \"",
        "\"%s default should be a callable"
    ],
    [
        "\"so that it's not shared between all field instances.\"",
        "\"so that it's not shared between all field"
    ],
    [
        "\"Use a callable instead, e.g., use `%s` instead of \"",
        "\"Use a callable instead, e.g., use `%s`"
    ],
    [
        "def __init__(self, *, expression, output_field, db_persist=None, **kwargs):",
        "def __init__(self, *, expression,"
    ],
    [
        "if kwargs.get(\"default\", NOT_PROVIDED) is not NOT_PROVIDED:",
        "if kwargs.get(\"default\", NOT_PROVIDED)"
    ],
    [
        "raise ValueError(\"GeneratedField cannot have a default.\")",
        "raise ValueError(\"GeneratedField cannot have"
    ],
    [
        "if kwargs.get(\"db_default\", NOT_PROVIDED) is not NOT_PROVIDED:",
        "if kwargs.get(\"db_default\", NOT_PROVIDED)"
    ],
    [
        "raise ValueError(\"GeneratedField cannot have a database default.\")",
        "raise ValueError(\"GeneratedField cannot have a"
    ],
    [
        "if db_persist not in (True, False):",
        "if db_persist not"
    ],
    [
        "raise ValueError(\"GeneratedField.db_persist must be True or False.\")",
        "raise ValueError(\"GeneratedField.db_persist must be True or"
    ],
    [
        "if alias != self.model._meta.db_table and output_field in (None, self):",
        "if alias != self.model._meta.db_table and output_field in"
    ],
    [
        "if not self.db_persist and not (",
        "if not self.db_persist and"
    ],
    [
        "f\"{connection.display_name} does not support non-persisted \"",
        "f\"{connection.display_name} does not support"
    ],
    [
        "f\"{connection.display_name} does not support persisted \"",
        "f\"{connection.display_name} does not support persisted"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "from django.db.models.deletion import CASCADE, SET_DEFAULT, SET_NULL",
        "from django.db.models.deletion import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "from .reverse_related import ForeignObjectRel, ManyToManyRel, ManyToOneRel, OneToOneRel",
        "from .reverse_related import ForeignObjectRel, ManyToManyRel,"
    ],
    [
        "Transform relation into a model or fully-qualified model string of the form",
        "Transform relation into a model or fully-qualified"
    ],
    [
        "* RECURSIVE_RELATIONSHIP_CONSTANT, i.e. the string \"self\", in which case",
        "* RECURSIVE_RELATIONSHIP_CONSTANT, i.e. the string \"self\", in which"
    ],
    [
        "the model argument will be returned.",
        "the model argument will"
    ],
    [
        "* A bare model name without an app_label, in which case scope_model's",
        "* A bare model name without an app_label, in"
    ],
    [
        "* A model class, which will be returned unchanged.",
        "* A model class, which will be"
    ],
    [
        "relation = \"%s.%s\" % (scope_model._meta.app_label, relation)",
        "relation = \"%s.%s\" %"
    ],
    [
        "Schedule `function` to be called once `model` and all `related_models`",
        "Schedule `function` to be called once"
    ],
    [
        "have been imported and registered with the app registry. `function` will",
        "have been imported and registered with the app"
    ],
    [
        "be called with the newly-loaded model classes as its positional arguments,",
        "be called with the newly-loaded model classes as its positional"
    ],
    [
        "The `model` argument must be a model class. Each subsequent positional",
        "The `model` argument must be a"
    ],
    [
        "argument is another model, or a reference to another model - see",
        "argument is another model, or a reference to another model"
    ],
    [
        "`resolve_relation()` for the various forms these may take. Any relative",
        "`resolve_relation()` for the various forms these may take. Any"
    ],
    [
        "references will be resolved relative to `model`.",
        "references will be resolved relative"
    ],
    [
        "This is a convenience wrapper for `Apps.lazy_model_operation` - the app",
        "This is a convenience wrapper for `Apps.lazy_model_operation`"
    ],
    [
        "registry model used is the one found in `model._meta.apps`.",
        "registry model used is the one found"
    ],
    [
        "models = [model] + [resolve_relation(model, rel) for rel in related_models]",
        "models = [model] + [resolve_relation(model, rel) for rel"
    ],
    [
        "model_keys = (make_model_tuple(m) for m in models)",
        "model_keys = (make_model_tuple(m) for m in"
    ],
    [
        "\"\"\"Base class that all relational fields inherit from.\"\"\"",
        "\"\"\"Base class that all relational fields"
    ],
    [
        "\"The name '%s' is invalid related_name for field %s.%s\"",
        "\"The name '%s' is invalid related_name"
    ],
    [
        "\"Related name must be a valid Python identifier or end with a \"",
        "\"Related name must be a valid Python identifier"
    ],
    [
        "\"Reverse query name '%s' must not end with an underscore.\"",
        "\"Reverse query name '%s' must not"
    ],
    [
        "\"Add or change a related_name or related_query_name \"",
        "\"Add or change a"
    ],
    [
        "\"Reverse query name '%s' must not contain '%s'.\"",
        "\"Reverse query name '%s' must"
    ],
    [
        "\"Add or change a related_name or related_query_name \"",
        "\"Add or change a related_name"
    ],
    [
        "rel_is_missing = self.remote_field.model not in self.opts.apps.get_models(",
        "rel_is_missing = self.remote_field.model"
    ],
    [
        "\"Field defines a relation with model '%s', which is either \"",
        "\"Field defines a relation with model '%s',"
    ],
    [
        "\"not installed, or is abstract.\" % model_name,",
        "\"not installed, or is abstract.\" %"
    ],
    [
        "\"Field defines a relation with the model '%s', which has \"",
        "\"Field defines a relation with the model"
    ],
    [
        "hint=\"Update the relation to point at 'settings.%s'.\"",
        "hint=\"Update the relation to point at"
    ],
    [
        "\"\"\"Check accessor and reverse query name clashes.\"\"\"",
        "\"\"\"Check accessor and reverse query name"
    ],
    [
        "field_name = \"%s.%s\" % (opts.label, self.name)",
        "field_name = \"%s.%s\""
    ],
    [
        "if not rel_is_hidden and clash_field.name == rel_name:",
        "if not rel_is_hidden and clash_field.name"
    ],
    [
        "f\"for '{field_name}' clashes with field name \"",
        "f\"for '{field_name}' clashes with"
    ],
    [
        "\"Rename field '%s', or add/change a related_name \"",
        "\"Rename field '%s', or add/change"
    ],
    [
        "\"argument to the definition for field '%s'.\"",
        "\"argument to the definition for"
    ],
    [
        "\"Reverse query name for '%s' clashes with field name '%s'.\"",
        "\"Reverse query name for '%s' clashes with"
    ],
    [
        "\"Rename field '%s', or add/change a related_name \"",
        "\"Rename field '%s', or add/change a"
    ],
    [
        "\"argument to the definition for field '%s'.\"",
        "\"argument to the definition"
    ],
    [
        "potential_clashes = (r for r in rel_opts.related_objects if r.field is not self)",
        "potential_clashes = (r for r in rel_opts.related_objects if r.field is not"
    ],
    [
        "if not rel_is_hidden and clash_field.accessor_name == rel_name:",
        "if not rel_is_hidden and clash_field.accessor_name =="
    ],
    [
        "f\"for '{field_name}' clashes with reverse accessor for \"",
        "f\"for '{field_name}' clashes with"
    ],
    [
        "\"Add or change a related_name argument \"",
        "\"Add or change a related_name"
    ],
    [
        "\"to the definition for '%s' or '%s'.\"",
        "\"to the definition for '%s'"
    ],
    [
        "\"Reverse query name for '%s' clashes with reverse query name \"",
        "\"Reverse query name for '%s' clashes"
    ],
    [
        "\"Add or change a related_name argument \"",
        "\"Add or change a"
    ],
    [
        "\"to the definition for '%s' or '%s'.\"",
        "\"to the definition for"
    ],
    [
        "def contribute_to_class(self, cls, name, private_only=False, **kwargs):",
        "def contribute_to_class(self, cls, name,"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "Return the keyword arguments that when supplied to",
        "Return the keyword arguments that when supplied"
    ],
    [
        "self.model.object.filter(), would select all instances related through",
        "self.model.object.filter(), would select all instances related"
    ],
    [
        "this field to the remote obj. This is used to build the querysets",
        "this field to the remote obj. This is used"
    ],
    [
        "returned by related descriptors. obj is an instance of",
        "returned by related descriptors. obj is an"
    ],
    [
        "\"%s__%s\" % (self.name, rh_field.name): getattr(obj, rh_field.attname)",
        "\"%s__%s\" % (self.name, rh_field.name):"
    ],
    [
        "Complement to get_forward_related_filter(). Return the keyword",
        "Complement to get_forward_related_filter(). Return the"
    ],
    [
        "arguments that when passed to self.related_field.model.object.filter()",
        "arguments that when passed to"
    ],
    [
        "select all instances of self.related_field.model related through",
        "select all instances of self.related_field.model"
    ],
    [
        "this field to obj. obj is an instance of self.model.",
        "this field to obj. obj is"
    ],
    [
        "Get the setting that this is powered from for swapping, or None",
        "Get the setting that this is"
    ],
    [
        "if it's not swapped in / marked with swappable=False.",
        "if it's not swapped in"
    ],
    [
        "Return ``limit_choices_to`` for this model field.",
        "Return ``limit_choices_to`` for this model"
    ],
    [
        "If it is a callable, it will be invoked and the result will be",
        "If it is a callable, it will be invoked and the result will"
    ],
    [
        "Pass ``limit_choices_to`` to the field being constructed.",
        "Pass ``limit_choices_to`` to the field being"
    ],
    [
        "Only passes it if there is a type that supports related fields.",
        "Only passes it if there is a type that supports related"
    ],
    [
        "This is a similar strategy used to pass the ``queryset`` to the field",
        "This is a similar strategy used to pass the ``queryset`` to the"
    ],
    [
        "Define the name that can be used to identify this related object in a",
        "Define the name that can be used to"
    ],
    [
        "When filtering against this relation, return the field on the remote",
        "When filtering against this relation, return the"
    ],
    [
        "model against which the filtering should happen.",
        "model against which the"
    ],
    [
        "\"The relation has multiple target fields, but only single target field \"",
        "\"The relation has multiple target fields, but only"
    ],
    [
        "Abstraction of the ForeignKey relation to support multi-column relations.",
        "Abstraction of the ForeignKey relation to support multi-column"
    ],
    [
        "\"The to_field '%s' doesn't exist on the related \"",
        "\"The to_field '%s' doesn't exist on the"
    ],
    [
        "\"Field defines a relation to the CompositePrimaryKey of \"",
        "\"Field defines a relation to the CompositePrimaryKey"
    ],
    [
        "foreign_fields = {f.name for f in self.foreign_related_fields}",
        "foreign_fields = {f.name for f"
    ],
    [
        "f\"No subset of the fields {field_combination} on model \"",
        "f\"No subset of the fields"
    ],
    [
        "\"Mark a single field as unique=True or add a set of \"",
        "\"Mark a single field as unique=True or"
    ],
    [
        "\"fields to a unique constraint (via unique_together \"",
        "\"fields to a unique"
    ],
    [
        "\"or a UniqueConstraint (without condition) in the \"",
        "\"or a UniqueConstraint (without"
    ],
    [
        "f\"'{model_name}.{field_name}' must be unique because it is \"",
        "f\"'{model_name}.{field_name}' must be unique because"
    ],
    [
        "\"Add unique=True to this field or add a \"",
        "\"Add unique=True to this field or add"
    ],
    [
        "\"UniqueConstraint (without condition) in the model \"",
        "\"UniqueConstraint (without condition) in the"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "kwargs[\"to\"] = \"%s.%s\" % (app_label, model_name.lower())",
        "kwargs[\"to\"] = \"%s.%s\" % (app_label,"
    ],
    [
        "\"Cannot deconstruct a ForeignKey pointing to a model \"",
        "\"Cannot deconstruct a ForeignKey pointing to"
    ],
    [
        "\"that is swapped in place of more than one model (%s and %s)\"",
        "\"that is swapped in place of more than"
    ],
    [
        "if not self.from_fields or len(self.from_fields) != len(self.to_fields):",
        "if not self.from_fields or len(self.from_fields) !="
    ],
    [
        "\"Foreign Object from and to fields must be the same non-zero length\"",
        "\"Foreign Object from and to fields must be the same non-zero"
    ],
    [
        "\"Related model %r cannot be resolved\" % self.remote_field.model",
        "\"Related model %r cannot be resolved\""
    ],
    [
        "for from_field_name, to_field_name in zip(self.from_fields, self.to_fields):",
        "for from_field_name, to_field_name in zip(self.from_fields,"
    ],
    [
        "return [(rhs_field, lhs_field) for lhs_field, rhs_field in self.related_fields]",
        "return [(rhs_field, lhs_field) for"
    ],
    [
        "return tuple(lhs_field for lhs_field, rhs_field in self.related_fields)",
        "return tuple(lhs_field for lhs_field, rhs_field"
    ],
    [
        "rhs_field for lhs_field, rhs_field in self.related_fields if rhs_field",
        "rhs_field for lhs_field, rhs_field in self.related_fields"
    ],
    [
        "Return an extra filter condition for related object fetching when",
        "Return an extra filter condition for related object fetching"
    ],
    [
        "user does 'instance.fieldname', that is the extra filter is used in",
        "user does 'instance.fieldname', that is the extra filter"
    ],
    [
        "The filter should be either a dict usable in .filter(**kwargs) call or",
        "The filter should be either a dict usable"
    ],
    [
        "a Q-object. The condition will be ANDed together with the relation's",
        "a Q-object. The condition will be ANDed together"
    ],
    [
        "A parallel method is get_extra_restriction() which is used in",
        "A parallel method is get_extra_restriction()"
    ],
    [
        "Return a pair condition used for joining and subquery pushdown. The",
        "Return a pair condition used for"
    ],
    [
        "condition is something that responds to as_sql(compiler, connection)",
        "condition is something that"
    ],
    [
        "Note that currently referring both the 'alias' and 'related_alias'",
        "Note that currently referring both the 'alias'"
    ],
    [
        "will not work in some conditions, like subquery pushdown.",
        "will not work in some conditions, like"
    ],
    [
        "A parallel method is get_extra_descriptor_filter() which is used in",
        "A parallel method is get_extra_descriptor_filter() which"
    ],
    [
        "\"\"\"Get path from this field to the related model.\"\"\"",
        "\"\"\"Get path from this field to the related"
    ],
    [
        "\"\"\"Get path from the related model to this field's model.\"\"\"",
        "\"\"\"Get path from the related model"
    ],
    [
        "class_lookups = [parent.__dict__.get(\"class_lookups\", {}) for parent in bases]",
        "class_lookups = [parent.__dict__.get(\"class_lookups\", {})"
    ],
    [
        "def contribute_to_class(self, cls, name, private_only=False, **kwargs):",
        "def contribute_to_class(self, cls, name, private_only=False,"
    ],
    [
        "if not self.remote_field.hidden and not related.related_model._meta.swapped:",
        "if not self.remote_field.hidden"
    ],
    [
        "Provide a many-to-one relation by adding a column to the local model",
        "Provide a many-to-one relation by adding a column to"
    ],
    [
        "By default ForeignKey will target the pk of the remote model but this",
        "By default ForeignKey will target the pk of the remote model"
    ],
    [
        "behavior can be changed by using the ``to_field`` argument.",
        "behavior can be changed by"
    ],
    [
        "\"%(model)s instance with %(field)s %(value)r is not a valid choice.\"",
        "\"%(model)s instance with %(field)s %(value)r"
    ],
    [
        "description = _(\"Foreign Key (type determined by related field)\")",
        "description = _(\"Foreign Key (type determined"
    ],
    [
        "\"%s(%r) is invalid. First parameter to ForeignKey must be \"",
        "\"%s(%r) is invalid. First parameter to"
    ],
    [
        "\"either a model, a model name, or the string %r\"",
        "\"either a model, a model name, or"
    ],
    [
        "to_field = to_field or (to._meta.pk and to._meta.pk.name)",
        "to_field = to_field or (to._meta.pk"
    ],
    [
        "if on_delete == SET_NULL and not self.null:",
        "if on_delete == SET_NULL and not"
    ],
    [
        "\"Field specifies on_delete=SET_NULL, but cannot be null.\",",
        "\"Field specifies on_delete=SET_NULL, but cannot be"
    ],
    [
        "\"Set null=True argument on the field, or change the on_delete \"",
        "\"Set null=True argument on the field,"
    ],
    [
        "elif on_delete == SET_DEFAULT and not self.has_default():",
        "elif on_delete == SET_DEFAULT"
    ],
    [
        "\"Field specifies on_delete=SET_DEFAULT, but has no default value.\",",
        "\"Field specifies on_delete=SET_DEFAULT, but has"
    ],
    [
        "hint=\"Set a default value, or change the on_delete rule.\",",
        "hint=\"Set a default value, or change the"
    ],
    [
        "\"Setting unique=True on a ForeignKey has the same effect as using \"",
        "\"Setting unique=True on a ForeignKey has the"
    ],
    [
        "\"ForeignKey(unique=True) is usually better served by a \"",
        "\"ForeignKey(unique=True) is usually better served"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "or (to_meta.pk and self.remote_field.field_name != to_meta.pk.name)",
        "or (to_meta.pk and self.remote_field.field_name"
    ],
    [
        "\"'%s.%s' refers to field '%s' which is not local to model \"",
        "\"'%s.%s' refers to field '%s' which is not"
    ],
    [
        "\"\"\"Return the to_field if the default value is an object.\"\"\"",
        "\"\"\"Return the to_field if the default"
    ],
    [
        "if value is None or (",
        "if value is None"
    ],
    [
        "\"Cannot create form field for %r yet, because \"",
        "\"Cannot create form field for %r yet, because"
    ],
    [
        "\"its related model %r has not been loaded yet\"",
        "\"its related model %r has"
    ],
    [
        "if (not value) and isinstance(value, str):",
        "if (not value) and isinstance(value,"
    ],
    [
        "A OneToOneField is essentially the same as a ForeignKey, with the exception",
        "A OneToOneField is essentially the same as a"
    ],
    [
        "that it always carries a \"unique\" constraint with it and the reverse",
        "that it always carries a \"unique\""
    ],
    [
        "relation always returns the object pointed to (since there will only ever",
        "relation always returns the object pointed to (since there will only"
    ],
    [
        "be one), rather than returning a list.",
        "be one), rather than returning"
    ],
    [
        "def __init__(self, to, on_delete, to_field=None, **kwargs):",
        "def __init__(self, to,"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "name = \"%s_%s\" % (klass._meta.object_name, field.name)",
        "name = \"%s_%s\" %"
    ],
    [
        "Provide a many-to-many relation by using an intermediary model that",
        "Provide a many-to-many relation by"
    ],
    [
        "holds two ForeignKey fields pointed at the two sides of the relation.",
        "holds two ForeignKey fields pointed at"
    ],
    [
        "Unless a ``through`` model was provided, ManyToManyField will use the",
        "Unless a ``through`` model was"
    ],
    [
        "\"%s(%r) is invalid. First parameter to ManyToManyField \"",
        "\"%s(%r) is invalid. First parameter to ManyToManyField"
    ],
    [
        "\"must be either a model, a model name, or the string %r\"",
        "\"must be either a model, a model name, or the string"
    ],
    [
        "if through is not None and db_table is not None:",
        "if through is not None and db_table is"
    ],
    [
        "\"Cannot specify a db_table if an intermediary model is used.\"",
        "\"Cannot specify a db_table if"
    ],
    [
        "\"null has no effect on ManyToManyField.\",",
        "\"null has no effect"
    ],
    [
        "\"related_name has no effect on ManyToManyField \"",
        "\"related_name has no effect on"
    ],
    [
        "'with a symmetrical relationship, e.g. to \"self\".',",
        "'with a symmetrical relationship, e.g. to"
    ],
    [
        "\"db_comment has no effect on ManyToManyField.\",",
        "\"db_comment has no effect"
    ],
    [
        "\"Field specifies a many-to-many relation through model \"",
        "\"Field specifies a many-to-many relation through"
    ],
    [
        "\"'%s', which has not been installed.\" % qualified_model_name,",
        "\"'%s', which has not been installed.\" %"
    ],
    [
        "assert from_model is not None, (",
        "assert from_model is not"
    ],
    [
        "\"tables cannot be checked if you don't pass the model \"",
        "\"tables cannot be checked if you don't pass the model"
    ],
    [
        "\"where the field is attached to.\"",
        "\"where the field is attached"
    ],
    [
        "\"Field defines a relation to the CompositePrimaryKey of model \"",
        "\"Field defines a relation to the CompositePrimaryKey"
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an"
    ],
    [
        "\"'%s', but it has more than two foreign keys \"",
        "\"'%s', but it has more than"
    ],
    [
        "\"to '%s', which is ambiguous. You must specify \"",
        "\"to '%s', which is ambiguous."
    ],
    [
        "\"which two foreign keys Django should use via the \"",
        "\"which two foreign keys Django should use"
    ],
    [
        "\"Use through_fields to specify which two foreign keys \"",
        "\"Use through_fields to specify which two foreign"
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an"
    ],
    [
        "\"'%s', but it has more than one foreign key \"",
        "\"'%s', but it has more than one"
    ],
    [
        "\"from '%s', which is ambiguous. You must specify \"",
        "\"from '%s', which is ambiguous. You must"
    ],
    [
        "\"which foreign key Django should use via the \"",
        "\"which foreign key Django should use via"
    ],
    [
        "\"If you want to create a recursive relationship, \"",
        "\"If you want to create a recursive relationship,"
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an intermediate model by"
    ],
    [
        "\"'%s', but it has more than one foreign key \"",
        "\"'%s', but it has more than"
    ],
    [
        "\"to '%s', which is ambiguous. You must specify \"",
        "\"to '%s', which is ambiguous. You must specify"
    ],
    [
        "\"which foreign key Django should use via the \"",
        "\"which foreign key Django should use via"
    ],
    [
        "\"through_fields keyword argument.\" % (self, to_model_name),",
        "\"through_fields keyword argument.\" % (self,"
    ],
    [
        "\"If you want to create a recursive relationship, \"",
        "\"If you want to create"
    ],
    [
        "\"The model is used as an intermediate model by \"",
        "\"The model is used as an intermediate"
    ],
    [
        "\"'%s', but it does not have a foreign key to '%s' or '%s'.\"",
        "\"'%s', but it does not have a foreign key to '%s'"
    ],
    [
        "\"Field specifies 'through_fields' but does not provide \"",
        "\"Field specifies 'through_fields' but"
    ],
    [
        "\"the names of the two link fields that should be used \"",
        "\"the names of the two link fields"
    ],
    [
        "\"for the relation through model '%s'.\" % qualified_model_name,",
        "\"for the relation through model '%s'.\""
    ],
    [
        "\"Make sure you specify 'through_fields' as \"",
        "\"Make sure you specify 'through_fields' as"
    ],
    [
        "assert from_model is not None, (",
        "assert from_model is not None,"
    ],
    [
        "\"tables cannot be checked if you don't pass the model \"",
        "\"tables cannot be checked if you don't pass the"
    ],
    [
        "\"where the field is attached to.\"",
        "\"where the field"
    ],
    [
        "and getattr(f.remote_field, \"model\", None) == related_model",
        "and getattr(f.remote_field, \"model\", None) =="
    ],
    [
        "\"Did you mean one of the following foreign keys to '%s': \"",
        "\"Did you mean one of the following"
    ],
    [
        "\"The intermediary model '%s' has no field '%s'.\"",
        "\"The intermediary model '%s' has no"
    ],
    [
        "\"'%s.%s' is not a foreign key to '%s'.\"",
        "\"'%s.%s' is not a foreign key to"
    ],
    [
        "if model != self.remote_field.through and model._meta.managed",
        "if model != self.remote_field.through and"
    ],
    [
        "clashing_obj = \"%s.%s\" % (opts.label, _get_field_name(model))",
        "clashing_obj = \"%s.%s\""
    ],
    [
        "\"You have configured settings.DATABASE_ROUTERS. Verify \"",
        "\"You have configured"
    ],
    [
        "\"that the table of %r is correctly routed to a separate \"",
        "\"that the table of %r is"
    ],
    [
        "\"The field's intermediary table '%s' clashes with the \"",
        "\"The field's intermediary table '%s' clashes with the"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "kwargs[\"to\"] = \"%s.%s\" % (app_label, model_name.lower())",
        "kwargs[\"to\"] = \"%s.%s\" % (app_label,"
    ],
    [
        "if getattr(self.remote_field, \"through\", None) is not None:",
        "if getattr(self.remote_field, \"through\", None)"
    ],
    [
        "if through_fields := getattr(self.remote_field, \"through_fields\", None):",
        "if through_fields := getattr(self.remote_field, \"through_fields\","
    ],
    [
        "\"Cannot deconstruct a ManyToManyField pointing to a \"",
        "\"Cannot deconstruct a ManyToManyField pointing to a"
    ],
    [
        "\"model that is swapped in place of more than one model \"",
        "\"model that is swapped in place of"
    ],
    [
        "\"(%s and %s)\" % (kwargs[\"to\"].setting_name, swappable_setting)",
        "\"(%s and %s)\""
    ],
    [
        "Function that can be curried to provide the source accessor or DB",
        "Function that can be curried to provide the source accessor or"
    ],
    [
        "and (link_field_name is None or link_field_name == f.name)",
        "and (link_field_name is None or link_field_name"
    ],
    [
        "Function that can be curried to provide the related accessor or DB",
        "Function that can be curried to provide the related accessor or"
    ],
    [
        "if f.is_relation and f.remote_field.model == related.model:",
        "if f.is_relation and f.remote_field.model =="
    ],
    [
        "if link_field_name is None and related.related_model == related.model:",
        "if link_field_name is None and related.related_model =="
    ],
    [
        "elif link_field_name is None or link_field_name == f.name:",
        "elif link_field_name is None or"
    ],
    [
        "if not self.remote_field.hidden and not related.related_model._meta.swapped:",
        "if not self.remote_field.hidden and not"
    ],
    [
        "return list(getattr(obj, self.attname).all()) if obj._is_pk_set() else []",
        "return list(getattr(obj, self.attname).all()) if obj._is_pk_set()"
    ],
    [
        "defaults[\"initial\"] = [i.pk for i in initial]",
        "defaults[\"initial\"] = [i.pk for i in"
    ],
    [
        "from django.db.models.sql.where import AND, OR, WhereNode",
        "from django.db.models.sql.where import"
    ],
    [
        "f\"{self.lookup_name!r} lookup of {lhs_str} must be a tuple or a list\"",
        "f\"{self.lookup_name!r} lookup of {lhs_str} must be"
    ],
    [
        "f\"{self.lookup_name!r} lookup of {lhs_str} must have {len_lhs} elements\"",
        "f\"{self.lookup_name!r} lookup of {lhs_str}"
    ],
    [
        "f\"{self.lookup_name!r} subquery lookup of {lhs_str} \"",
        "f\"{self.lookup_name!r} subquery lookup"
    ],
    [
        "f\"only supports OuterRef and QuerySet objects (received {rhs_cls!r})\"",
        "f\"only supports OuterRef and QuerySet objects"
    ],
    [
        "names = \", \".join(repr(f.name) for f in self.lhs)",
        "names = \", \".join(repr(f.name)"
    ],
    [
        "sql, params = super().process_lhs(compiler, connection, lhs)",
        "sql, params = super().process_lhs(compiler, connection,"
    ],
    [
        "for col, val in zip(self.lhs, self.rhs)",
        "for col, val"
    ],
    [
        "\"Composite field lookups only work with composite expressions.\"",
        "\"Composite field lookups only work"
    ],
    [
        "f\"for backends that don't have the supports_tuple_lookups feature enabled.\"",
        "f\"for backends that don't have the supports_tuple_lookups"
    ],
    [
        "lookups = [Exact(col, val) for col, val in zip(self.lhs, self.rhs)]",
        "lookups = [Exact(col, val) for col, val in"
    ],
    [
        "\"The QuerySet value for an isnull lookup must be True or False.\"",
        "\"The QuerySet value for an isnull"
    ],
    [
        "lookups = [IsNull(col, rhs) for col in self.lhs]",
        "lookups = [IsNull(col, rhs) for"
    ],
    [
        "root = WhereNode(lookups, connector=OR if rhs else AND)",
        "root = WhereNode(lookups, connector=OR if rhs else"
    ],
    [
        "root = node = WhereNode([lookup(col, val)], connector=connector)",
        "root = node ="
    ],
    [
        "for col, val in zip(cols_iter, vals_iter):",
        "for col, val in"
    ],
    [
        "root = node = WhereNode([lookup(col, val)], connector=connector)",
        "root = node = WhereNode([lookup(col, val)],"
    ],
    [
        "for col, val in zip(cols_iter, vals_iter):",
        "for col, val in"
    ],
    [
        "root = node = WhereNode([lookup(col, val)], connector=connector)",
        "root = node = WhereNode([lookup(col,"
    ],
    [
        "for col, val in zip(cols_iter, vals_iter):",
        "for col, val"
    ],
    [
        "root = node = WhereNode([lookup(col, val)], connector=connector)",
        "root = node = WhereNode([lookup(col,"
    ],
    [
        "for col, val in zip(cols_iter, vals_iter):",
        "for col, val in zip(cols_iter,"
    ],
    [
        "if not all(isinstance(vals, (tuple, list)) for vals in self.rhs):",
        "if not all(isinstance(vals, (tuple, list)) for vals in"
    ],
    [
        "\"must be a collection of tuples or lists\"",
        "\"must be a collection of"
    ],
    [
        "if not all(len_lhs == len(vals) for vals in self.rhs):",
        "if not all(len_lhs == len(vals) for vals in"
    ],
    [
        "f\"{self.lookup_name!r} subquery lookup of {lhs_str} \"",
        "f\"{self.lookup_name!r} subquery lookup of {lhs_str}"
    ],
    [
        "f\"must be a Query object (received {rhs_cls!r})\"",
        "f\"must be a Query object (received"
    ],
    [
        "for col, val in zip(lhs, vals)",
        "for col, val"
    ],
    [
        "lookups = [Exact(col, val) for col, val in zip(lhs, vals)]",
        "lookups = [Exact(col, val) for col, val in"
    ],
    [
        "Field-like classes that aren't really fields. It's easier to use objects that",
        "Field-like classes that aren't really fields. It's easier"
    ],
    [
        "have the same attributes as fields sometimes (avoids a lot of special casing).",
        "have the same attributes as fields sometimes (avoids a lot"
    ],
    [
        "A proxy for the _order database field that is used when",
        "A proxy for the _order database field that is"
    ],
    [
        "from django.core import checks, exceptions, validators",
        "from django.core import checks, exceptions,"
    ],
    [
        "from django.db import connection, connections, router",
        "from django.db import"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import"
    ],
    [
        "\"\"\"Base class for all field types\"\"\"",
        "\"\"\"Base class for all field"
    ],
    [
        "\"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),",
        "\"invalid_choice\": _(\"Value %(value)r is"
    ],
    [
        "\"null\": _(\"This field cannot be null.\"),",
        "\"null\": _(\"This field cannot be"
    ],
    [
        "\"blank\": _(\"This field cannot be blank.\"),",
        "\"blank\": _(\"This field cannot be"
    ],
    [
        "\"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),",
        "\"unique\": _(\"%(model_name)s with this %(field_label)s"
    ],
    [
        "\"%(field_label)s must be unique for \"",
        "\"%(field_label)s must be"
    ],
    [
        "return _(\"Field of type: %(field_type)s\") % {",
        "return _(\"Field of type:"
    ],
    [
        "self.is_relation = self.remote_field is not None",
        "self.is_relation = self.remote_field is"
    ],
    [
        "Return \"app_label.model_label.field_name\" for fields attached to",
        "Return \"app_label.model_label.field_name\" for"
    ],
    [
        "\"\"\"Display the module, class, and name of the field.\"\"\"",
        "\"\"\"Display the module, class, and"
    ],
    [
        "path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)",
        "path = \"%s.%s\" %"
    ],
    [
        "return \"<%s: %s>\" % (path, name)",
        "return \"<%s: %s>\""
    ],
    [
        "\"Field names must not end with an underscore.\",",
        "\"Field names must not"
    ],
    [
        "'Field names must not contain \"%s\".' % LOOKUP_SEP,",
        "'Field names must not contain \"%s\".'"
    ],
    [
        "\"'pk' is a reserved word that cannot be used as a field name.\",",
        "\"'pk' is a reserved word that cannot"
    ],
    [
        "return isinstance(value, (str, Promise)) or not isinstance(value, Iterable)",
        "return isinstance(value, (str, Promise)) or not isinstance(value,"
    ],
    [
        "if not isinstance(self.choices, Iterable) or isinstance(self.choices, str):",
        "if not isinstance(self.choices, Iterable) or isinstance(self.choices,"
    ],
    [
        "\"'choices' must be a mapping (e.g. a dictionary) or an iterable \"",
        "\"'choices' must be a mapping (e.g. a"
    ],
    [
        "if self.max_length is not None and group_choices:",
        "if self.max_length is not None"
    ],
    [
        "if not self._choices_is_value(value) or not self._choices_is_value(",
        "if not self._choices_is_value(value)"
    ],
    [
        "if self.max_length is not None and isinstance(value, str):",
        "if self.max_length is not None and"
    ],
    [
        "if self.max_length is not None and choice_max_length > self.max_length:",
        "if self.max_length is not None and"
    ],
    [
        "\"'max_length' is too small to fit the longest value \"",
        "\"'max_length' is too small to fit"
    ],
    [
        "\"in 'choices' (%d characters).\" % choice_max_length,",
        "\"in 'choices' (%d characters).\""
    ],
    [
        "\"'choices' must be a mapping of actual values to human readable names \"",
        "\"'choices' must be a mapping of actual values"
    ],
    [
        "\"or an iterable containing (actual value, human readable name) tuples.\",",
        "\"or an iterable containing (actual value, human"
    ],
    [
        "if not getattr(self._db_default_expression, \"allowed_default\", False) and (",
        "if not getattr(self._db_default_expression, \"allowed_default\", False)"
    ],
    [
        "msg = f\"{self.db_default} cannot be used in db_default.\"",
        "msg = f\"{self.db_default} cannot"
    ],
    [
        "f\"{connection.display_name} does not support default database \"",
        "f\"{connection.display_name} does not support"
    ],
    [
        "if self.db_index not in (None, True, False):",
        "if self.db_index not in (None, True,"
    ],
    [
        "\"'db_index' must be None, True or False.\",",
        "\"'db_index' must be None, True"
    ],
    [
        "if not self.db_comment or not databases:",
        "if not self.db_comment"
    ],
    [
        "f\"{connection.display_name} does not support comments on \"",
        "f\"{connection.display_name} does not support"
    ],
    [
        "\"Primary keys must not have null=True.\",",
        "\"Primary keys must not have"
    ],
    [
        "\"Set null=False on the field, or \"",
        "\"Set null=False on the"
    ],
    [
        "\"validators[{i}] ({repr}) isn't a function or \"",
        "\"validators[{i}] ({repr}) isn't a function"
    ],
    [
        "\"%s has been removed except for support in historical \"",
        "\"%s has been removed except for support in"
    ],
    [
        "\"msg\", \"%s has been deprecated.\" % self.__class__.__name__",
        "\"msg\", \"%s has been"
    ],
    [
        "if alias == self.model._meta.db_table and (",
        "if alias == self.model._meta.db_table and"
    ],
    [
        "output_field is None or output_field == self",
        "output_field is None or output_field =="
    ],
    [
        "Custom format for select clauses. For example, GIS columns need to be",
        "Custom format for select clauses. For example, GIS columns"
    ],
    [
        "selected as AsText(table.col) on MySQL as the table.col data can't be",
        "selected as AsText(table.col) on MySQL as the table.col"
    ],
    [
        "* The name of the field on the model, if contribute_to_class() has",
        "* The name of the field on the model,"
    ],
    [
        "* The import path of the field, including the class, e.g.",
        "* The import path of the field,"
    ],
    [
        "django.db.models.IntegerField. This should be the most portable",
        "django.db.models.IntegerField. This should be"
    ],
    [
        "version, so less specific may be better.",
        "version, so less specific"
    ],
    [
        "* A list of positional arguments.",
        "* A list of"
    ],
    [
        "* A dict of keyword arguments.",
        "* A dict of"
    ],
    [
        "Note that the positional or keyword arguments must contain values of",
        "Note that the positional or keyword"
    ],
    [
        "the following types (including inner values of collection types):",
        "the following types (including inner values"
    ],
    [
        "* None, bool, str, int, float, complex, set, frozenset, list, tuple,",
        "* None, bool, str, int, float, complex, set,"
    ],
    [
        "* top-level classes, top-level functions - will be referenced by their",
        "* top-level classes, top-level functions - will"
    ],
    [
        "* Storage instances - these have their own deconstruct() method",
        "* Storage instances - these"
    ],
    [
        "This is because the values here must be serialized into a text format",
        "This is because the values here must be serialized into a"
    ],
    [
        "(possibly new Python code, possibly JSON) and these are the only types",
        "(possibly new Python code, possibly JSON)"
    ],
    [
        "There's no need to return the exact way the field was instantiated this",
        "There's no need to return the exact way the"
    ],
    [
        "time, just ensure that the resulting field is the same - prefer keyword",
        "time, just ensure that the resulting field"
    ],
    [
        "arguments over positional ones, and omit parameters with their default",
        "arguments over positional ones, and omit parameters with their"
    ],
    [
        "path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)",
        "path = \"%s.%s\" %"
    ],
    [
        "Uses deconstruct() to clone a new copy of this Field.",
        "Uses deconstruct() to clone a"
    ],
    [
        "Will not preserve any class attachments/attribute names.",
        "Will not preserve any"
    ],
    [
        "name, path, args, kwargs = self.deconstruct()",
        "name, path, args,"
    ],
    [
        "return self.creation_counter == other.creation_counter and getattr(",
        "return self.creation_counter == other.creation_counter"
    ],
    [
        "elif hasattr(self, \"model\") != hasattr(other, \"model\"):",
        "elif hasattr(self, \"model\")"
    ],
    [
        "if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:",
        "if hasattr(self.remote_field, \"field\") and self.remote_field.field is"
    ],
    [
        "Pickling should return the model._meta.fields instance of the field,",
        "Pickling should return the model._meta.fields instance"
    ],
    [
        "not a new copy of that field. So, use the app registry to load the",
        "not a new copy of that field. So, use the app registry to load"
    ],
    [
        "model and then the field back.",
        "model and then"
    ],
    [
        "Hook to generate new PK values on save. This method is called when",
        "Hook to generate new PK values on save. This method is"
    ],
    [
        "saving instances with no primary key value set. If this method returns",
        "saving instances with no primary key value set. If"
    ],
    [
        "something else than None, then the returned value is used when saving",
        "something else than None, then the returned value"
    ],
    [
        "Convert the input value into the expected Python data type, raising",
        "Convert the input value into the expected Python"
    ],
    [
        "django.core.exceptions.ValidationError if the data can't be converted.",
        "django.core.exceptions.ValidationError if the data can't"
    ],
    [
        "Return the converted value. Subclasses should override this.",
        "Return the converted value. Subclasses"
    ],
    [
        "Some validators can't be created at field initialization time.",
        "Some validators can't be created"
    ],
    [
        "This method provides a way to delay their creation until required.",
        "This method provides a way to delay their creation"
    ],
    [
        "if hasattr(e, \"code\") and e.code in self.error_messages:",
        "if hasattr(e, \"code\") and e.code in"
    ],
    [
        "Validate value and raise ValidationError if necessary. Subclasses",
        "Validate value and raise ValidationError if"
    ],
    [
        "should override this to provide validation logic.",
        "should override this to provide"
    ],
    [
        "if self.choices is not None and value not in self.empty_values:",
        "if self.choices is not None and value"
    ],
    [
        "if value is None and not self.null:",
        "if value is None"
    ],
    [
        "if not self.blank and value in self.empty_values:",
        "if not self.blank and value in"
    ],
    [
        "Convert the value's type and run validation. Validation errors",
        "Convert the value's type and run validation. Validation"
    ],
    [
        "from to_python() and validate() are propagated. Return the correct",
        "from to_python() and validate() are"
    ],
    [
        "value if no error is raised.",
        "value if no error"
    ],
    [
        "Return the database column check constraint for this field, for the",
        "Return the database column check constraint"
    ],
    [
        "provided connection. Works the same way as db_type() for the case that",
        "provided connection. Works the same way as db_type() for the case"
    ],
    [
        "get_internal_type() does not map to a preexisting model field.",
        "get_internal_type() does not map to a"
    ],
    [
        "Return the database column data type for this field, for the provided",
        "Return the database column data type"
    ],
    [
        "Return the data type that a related field pointing to this field should",
        "Return the data type that a related field pointing to"
    ],
    [
        "use. For example, this method is called by ForeignKey and OneToOneField",
        "use. For example, this method is"
    ],
    [
        "\"\"\"Return the data type to use in the Cast() function.\"\"\"",
        "\"\"\"Return the data type to use in the"
    ],
    [
        "Extension of db_type(), providing a range of different return values",
        "Extension of db_type(), providing a range of different return"
    ],
    [
        "(type, checks). This will look at db_type(), allowing custom model",
        "(type, checks). This will look at db_type(), allowing custom"
    ],
    [
        "\"\"\"Private API intended only to be used by Django itself.\"\"\"",
        "\"\"\"Private API intended only to"
    ],
    [
        "self.concrete = self.column is not None",
        "self.concrete = self.column"
    ],
    [
        "if self.verbose_name is None and self.name:",
        "if self.verbose_name is"
    ],
    [
        "Register the field with the model class it belongs to.",
        "Register the field with the model class it"
    ],
    [
        "If private_only is True, create a separate instance of this field",
        "If private_only is True, create a separate"
    ],
    [
        "for every subclass of cls, even if cls is not an abstract model.",
        "for every subclass of cls, even if cls is"
    ],
    [
        "if \"get_%s_display\" % self.name not in cls.__dict__:",
        "if \"get_%s_display\" % self.name not"
    ],
    [
        "Return a dict that when passed as kwargs to self.model.filter(), would",
        "Return a dict that when passed as kwargs to"
    ],
    [
        "yield all instances having the same value for this field as obj has.",
        "yield all instances having the same value for this field as"
    ],
    [
        "\"\"\"Return field's value just before saving.\"\"\"",
        "\"\"\"Return field's value just before"
    ],
    [
        "\"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"",
        "\"\"\"Perform preliminary non-db specific"
    ],
    [
        "Return field's value prepared for interacting with the database backend.",
        "Return field's value prepared for interacting"
    ],
    [
        "Used by the default implementations of get_db_prep_save().",
        "Used by the default"
    ],
    [
        "\"\"\"Return field's value prepared for saving into a database.\"\"\"",
        "\"\"\"Return field's value prepared for saving into a"
    ],
    [
        "\"\"\"Return a boolean of whether this field has a default value.\"\"\"",
        "\"\"\"Return a boolean of whether this field has a"
    ],
    [
        "\"\"\"Return a boolean of whether this field has a db_default value.\"\"\"",
        "\"\"\"Return a boolean of whether this field has"
    ],
    [
        "\"\"\"Return the default value for this field.\"\"\"",
        "\"\"\"Return the default value for"
    ],
    [
        "if self.has_db_default() and not hasattr(db_default, \"resolve_expression\"):",
        "if self.has_db_default() and not"
    ],
    [
        "Return choices with a default blank choices included, for use",
        "Return choices with a default blank choices included,"
    ],
    [
        "as <select> choices for this field.",
        "as <select> choices for this"
    ],
    [
        "return (blank_choice if include_blank else []) + [",
        "return (blank_choice if include_blank else"
    ],
    [
        "(choice_func(x), str(x)) for x in qs",
        "(choice_func(x), str(x)) for"
    ],
    [
        "Return a string value of this field from the passed obj.",
        "Return a string value of this field from"
    ],
    [
        "This is used by the serialization framework.",
        "This is used by"
    ],
    [
        "\"\"\"Return a django.forms.Field instance for this field.\"\"\"",
        "\"\"\"Return a django.forms.Field instance for this"
    ],
    [
        "include_blank = self.blank or not (",
        "include_blank = self.blank or"
    ],
    [
        "\"\"\"Return the value of this field in the given model instance.\"\"\"",
        "\"\"\"Return the value of this field"
    ],
    [
        "\"\"\"Return a slice of this field.\"\"\"",
        "\"\"\"Return a slice of"
    ],
    [
        "raise NotSupportedError(\"This field does not support slicing.\")",
        "raise NotSupportedError(\"This field does not"
    ],
    [
        "\"invalid\": _(\"“%(value)s” value must be either True or False.\"),",
        "\"invalid\": _(\"“%(value)s” value must be either True"
    ],
    [
        "\"invalid_nullable\": _(\"“%(value)s” value must be either True, False, or None.\"),",
        "\"invalid_nullable\": _(\"“%(value)s” value must be either True, False,"
    ],
    [
        "description = _(\"Boolean (Either True or False)\")",
        "description = _(\"Boolean (Either True"
    ],
    [
        "if self.null and value in self.empty_values:",
        "if self.null and value"
    ],
    [
        "include_blank = not (self.has_default() or \"initial\" in kwargs)",
        "include_blank = not (self.has_default() or \"initial\" in"
    ],
    [
        "form_class = forms.NullBooleanField if self.null else forms.BooleanField",
        "form_class = forms.NullBooleanField if"
    ],
    [
        "defaults = {\"form_class\": form_class, \"required\": False}",
        "defaults = {\"form_class\": form_class, \"required\":"
    ],
    [
        "\"CharFields must define a 'max_length' attribute.\",",
        "\"CharFields must define"
    ],
    [
        "\"'max_length' must be a positive integer.\",",
        "\"'max_length' must be"
    ],
    [
        "\"%s does not support a database collation on \"",
        "\"%s does not support a database"
    ],
    [
        "if isinstance(value, str) or value is None:",
        "if isinstance(value, str) or value is"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "\"CommaSeparatedIntegerField is removed except for support in \"",
        "\"CommaSeparatedIntegerField is removed except"
    ],
    [
        "option not in (None, False) for option in mutually_exclusive_options",
        "option not in (None, False)"
    ],
    [
        "\"The options auto_now, auto_now_add, and default \"",
        "\"The options auto_now, auto_now_add, and"
    ],
    [
        "\"are mutually exclusive. Only one of these options \"",
        "\"are mutually exclusive. Only one of"
    ],
    [
        "Check if the given value appears to have been provided as a \"fixed\"",
        "Check if the given value appears to have been"
    ],
    [
        "time value, and include a warning in the returned list if it does. The",
        "time value, and include a warning in the returned list if"
    ],
    [
        "value argument must be a date object or aware/naive datetime object. If",
        "value argument must be a date object"
    ],
    [
        "now is provided, it must be a naive datetime object.",
        "now is provided, it must"
    ],
    [
        "if lower <= value <= upper:",
        "if lower <= value <="
    ],
    [
        "\"It seems you set a fixed date / time / datetime \"",
        "\"It seems you set a fixed date"
    ],
    [
        "\"value as default for this field. This may not be \"",
        "\"value as default for this field. This may not be"
    ],
    [
        "\"what you want. If you want to have the current date \"",
        "\"what you want. If you want to have"
    ],
    [
        "\"“%(value)s” value has an invalid date format. It must be \"",
        "\"“%(value)s” value has an invalid date format."
    ],
    [
        "\"“%(value)s” value has the correct format (YYYY-MM-DD) \"",
        "\"“%(value)s” value has the correct"
    ],
    [
        "\"but it is an invalid date.\"",
        "\"but it is an"
    ],
    [
        "self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs",
        "self, verbose_name=None, name=None, auto_now=False, auto_now_add=False,"
    ],
    [
        "Warn that using an actual date or datetime value is probably wrong;",
        "Warn that using an actual date or datetime value"
    ],
    [
        "it's only evaluated on server startup.",
        "it's only evaluated"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "if self.auto_now or (self.auto_now_add and add):",
        "if self.auto_now or (self.auto_now_add and"
    ],
    [
        "return \"\" if val is None else val.isoformat()",
        "return \"\" if val is None"
    ],
    [
        "\"“%(value)s” value has an invalid format. It must be in \"",
        "\"“%(value)s” value has an invalid format. It must be"
    ],
    [
        "\"“%(value)s” value has the correct format \"",
        "\"“%(value)s” value has the"
    ],
    [
        "\"(YYYY-MM-DD) but it is an invalid date.\"",
        "\"(YYYY-MM-DD) but it is an invalid"
    ],
    [
        "\"“%(value)s” value has the correct format \"",
        "\"“%(value)s” value has the correct"
    ],
    [
        "\"but it is an invalid date/time.\"",
        "\"but it is"
    ],
    [
        "Warn that using an actual date or datetime value is probably wrong;",
        "Warn that using an actual date or datetime value is probably"
    ],
    [
        "it's only evaluated on server startup.",
        "it's only evaluated on server"
    ],
    [
        "f\"DateTimeField {name} received a naive datetime ({value}) while \"",
        "f\"DateTimeField {name} received a naive datetime"
    ],
    [
        "if self.auto_now or (self.auto_now_add and add):",
        "if self.auto_now or (self.auto_now_add and"
    ],
    [
        "if value is not None and settings.USE_TZ and timezone.is_naive(value):",
        "if value is not None and settings.USE_TZ and"
    ],
    [
        "name = \"%s.%s\" % (self.model.__name__, self.name)",
        "name = \"%s.%s\""
    ],
    [
        "\"DateTimeField %s received a naive datetime (%s)\"",
        "\"DateTimeField %s received a naive"
    ],
    [
        "\" while time zone support is active.\" % (name, value),",
        "\" while time zone support"
    ],
    [
        "return \"\" if val is None else val.isoformat()",
        "return \"\" if val is None else"
    ],
    [
        "\"invalid\": _(\"“%(value)s” value must be a decimal number.\"),",
        "\"invalid\": _(\"“%(value)s” value must be a"
    ],
    [
        "\"DecimalFields must define a 'decimal_places' attribute.\",",
        "\"DecimalFields must define a 'decimal_places'"
    ],
    [
        "\"'decimal_places' must be a non-negative integer.\",",
        "\"'decimal_places' must be a"
    ],
    [
        "\"DecimalFields must define a 'max_digits' attribute.\",",
        "\"DecimalFields must define a 'max_digits'"
    ],
    [
        "\"'max_digits' must be a positive integer.\",",
        "\"'max_digits' must be a"
    ],
    [
        "\"'max_digits' must be greater or equal to 'decimal_places'.\",",
        "\"'max_digits' must be greater or equal"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint",
        "Use interval on PostgreSQL, INTERVAL DAY TO"
    ],
    [
        "\"“%(value)s” value has an invalid format. It must be in \"",
        "\"“%(value)s” value has an invalid format. It must be"
    ],
    [
        "return \"\" if val is None else duration_string(val)",
        "return \"\" if val is None"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "self.path, self.match, self.recursive = path, match, recursive",
        "self.path, self.match, self.recursive = path, match,"
    ],
    [
        "if not self.allow_files and not self.allow_folders:",
        "if not self.allow_files and"
    ],
    [
        "\"FilePathFields must have either 'allow_files' or 'allow_folders' \"",
        "\"FilePathFields must have either 'allow_files' or 'allow_folders'"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "\"path\": self.path() if callable(self.path) else self.path,",
        "\"path\": self.path() if callable(self.path)"
    ],
    [
        "\"invalid\": _(\"“%(value)s” value must be a float.\"),",
        "\"invalid\": _(\"“%(value)s” value must be a"
    ],
    [
        "\"Field '%s' expected a number but got %r.\" % (self.name, value),",
        "\"Field '%s' expected a number but got %r.\" %"
    ],
    [
        "\"invalid\": _(\"“%(value)s” value must be an integer.\"),",
        "\"invalid\": _(\"“%(value)s” value must"
    ],
    [
        "\"'max_length' is ignored when used with %s.\"",
        "\"'max_length' is ignored when used"
    ],
    [
        "if min_value is not None and not any(",
        "if min_value is not None and"
    ],
    [
        "if max_value is not None and not any(",
        "if max_value is not"
    ],
    [
        "\"Field '%s' expected a number but got %r.\" % (self.name, value),",
        "\"Field '%s' expected a number but got %r.\""
    ],
    [
        "\"IPAddressField has been removed except for support in \"",
        "\"IPAddressField has been removed except for support in"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "default_error_messages = {\"invalid\": _(\"Enter a valid %(protocol)s address.\")}",
        "default_error_messages = {\"invalid\": _(\"Enter a valid"
    ],
    [
        "if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):",
        "if not getattr(self, \"null\", False) and"
    ],
    [
        "\"GenericIPAddressFields cannot have blank=True if null=False, \"",
        "\"GenericIPAddressFields cannot have blank=True if"
    ],
    [
        "\"as blank values are stored as nulls.\",",
        "\"as blank values are stored as"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "if value and \":\" in value:",
        "if value and"
    ],
    [
        "\"invalid\": _(\"“%(value)s” value must be either None, True or False.\"),",
        "\"invalid\": _(\"“%(value)s” value must be"
    ],
    [
        "\"invalid_nullable\": _(\"“%(value)s” value must be either None, True or False.\"),",
        "\"invalid_nullable\": _(\"“%(value)s” value must be either None,"
    ],
    [
        "description = _(\"Boolean (Either True, False or None)\")",
        "description = _(\"Boolean (Either"
    ],
    [
        "\"NullBooleanField is removed except for support in historical \"",
        "\"NullBooleanField is removed except for support"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "Return the data type that a related field pointing to this field should",
        "Return the data type that a related field pointing to this field"
    ],
    [
        "use. In most cases, a foreign key pointing to a positive integer",
        "use. In most cases, a foreign"
    ],
    [
        "primary key will have an integer column data type but some databases",
        "primary key will have an integer column data type"
    ],
    [
        "(e.g. MySQL) have an unsigned integer type. In that case",
        "(e.g. MySQL) have an unsigned integer type. In"
    ],
    [
        "(related_fields_match_type=True), the primary key should return its",
        "(related_fields_match_type=True), the primary key"
    ],
    [
        "description = _(\"Slug (up to %(max_length)s)\")",
        "description = _(\"Slug (up"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "\"%s does not support a database collation on \"",
        "\"%s does not support a database collation"
    ],
    [
        "if isinstance(value, str) or value is None:",
        "if isinstance(value, str) or value"
    ],
    [
        "**({} if self.choices is not None else {\"widget\": forms.Textarea}),",
        "**({} if self.choices is not None else {\"widget\":"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "\"“%(value)s” value has an invalid format. It must be in \"",
        "\"“%(value)s” value has an invalid format. It must"
    ],
    [
        "\"“%(value)s” value has the correct format \"",
        "\"“%(value)s” value has the correct"
    ],
    [
        "\"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"",
        "\"(HH:MM[:ss[.uuuuuu]]) but it is an invalid"
    ],
    [
        "self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs",
        "self, verbose_name=None, name=None, auto_now=False,"
    ],
    [
        "Warn that using an actual date or datetime value is probably wrong;",
        "Warn that using an actual date or datetime value is probably"
    ],
    [
        "it's only evaluated on server startup.",
        "it's only evaluated on"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "if self.auto_now or (self.auto_now_add and add):",
        "if self.auto_now or (self.auto_now_add and"
    ],
    [
        "return \"\" if val is None else val.isoformat()",
        "return \"\" if val is None"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "\"BinaryField's default cannot be a string. Use bytes \"",
        "\"BinaryField's default cannot be a string. Use"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args,"
    ],
    [
        "\"invalid\": _(\"“%(value)s” is not a valid UUID.\"),",
        "\"invalid\": _(\"“%(value)s” is not a"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "if value is not None and not isinstance(value, uuid.UUID):",
        "if value is not None and not isinstance(value,"
    ],
    [
        "input_form = \"int\" if isinstance(value, int) else \"hex\"",
        "input_form = \"int\" if"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs"
    ],
    [
        "\"Model %s can't have more than one auto-generated field.\"",
        "\"Model %s can't have more than"
    ],
    [
        "Metaclass to maintain backward inheritance compatibility for AutoField.",
        "Metaclass to maintain backward inheritance"
    ],
    [
        "It is intended that AutoFieldMixin become public API when it is possible to",
        "It is intended that AutoFieldMixin become public API when"
    ],
    [
        "create a non-integer automatically-generated field using column defaults",
        "create a non-integer automatically-generated field using column"
    ],
    [
        "In many areas Django also relies on using isinstance() to check for an",
        "In many areas Django also relies on using isinstance() to"
    ],
    [
        "automatically-generated field as a subclass of AutoField. A new flag needs",
        "automatically-generated field as a subclass of AutoField. A"
    ],
    [
        "to be implemented on Field to be used instead.",
        "to be implemented on Field"
    ],
    [
        "When these issues have been addressed, this metaclass could be used to",
        "When these issues have been addressed, this metaclass could"
    ],
    [
        "deprecate inheritance from AutoField and use of isinstance() with AutoField",
        "deprecate inheritance from AutoField and use of isinstance() with"
    ],
    [
        "return [field.attname for field in self.field.fields]",
        "return [field.attname for field"
    ],
    [
        "return tuple(getattr(instance, attname) for attname in self.attnames)",
        "return tuple(getattr(instance, attname) for attname in"
    ],
    [
        "raise ValueError(f\"{self.field.name!r} must be a list or a tuple.\")",
        "raise ValueError(f\"{self.field.name!r} must be a list"
    ],
    [
        "raise ValueError(f\"{self.field.name!r} must have {length} elements.\")",
        "raise ValueError(f\"{self.field.name!r} must"
    ],
    [
        "for attname, value in zip(attnames, values):",
        "for attname, value in zip(attnames,"
    ],
    [
        "or not all(isinstance(field, str) for field in args)",
        "or not all(isinstance(field, str) for"
    ],
    [
        "raise ValueError(\"CompositePrimaryKey args must be unique strings.\")",
        "raise ValueError(\"CompositePrimaryKey args must be"
    ],
    [
        "raise ValueError(\"CompositePrimaryKey must include at least two fields.\")",
        "raise ValueError(\"CompositePrimaryKey must include at"
    ],
    [
        "if kwargs.get(\"default\", NOT_PROVIDED) is not NOT_PROVIDED:",
        "if kwargs.get(\"default\", NOT_PROVIDED) is not"
    ],
    [
        "raise ValueError(\"CompositePrimaryKey cannot have a default.\")",
        "raise ValueError(\"CompositePrimaryKey cannot have"
    ],
    [
        "if kwargs.get(\"db_default\", NOT_PROVIDED) is not NOT_PROVIDED:",
        "if kwargs.get(\"db_default\", NOT_PROVIDED) is"
    ],
    [
        "raise ValueError(\"CompositePrimaryKey cannot have a database default.\")",
        "raise ValueError(\"CompositePrimaryKey cannot have"
    ],
    [
        "if kwargs.get(\"db_column\", None) is not None:",
        "if kwargs.get(\"db_column\", None) is not"
    ],
    [
        "raise ValueError(\"CompositePrimaryKey cannot have a db_column.\")",
        "raise ValueError(\"CompositePrimaryKey cannot have a"
    ],
    [
        "raise ValueError(\"CompositePrimaryKey must be a primary key.\")",
        "raise ValueError(\"CompositePrimaryKey must be a"
    ],
    [
        "name, path, _, kwargs = super().deconstruct()",
        "name, path, _, kwargs"
    ],
    [
        "return tuple(meta.get_field(field_name) for field_name in self.field_names)",
        "return tuple(meta.get_field(field_name) for field_name"
    ],
    [
        "return tuple(field.column for field in self.fields)",
        "return tuple(field.column for field in"
    ],
    [
        "if alias == self.model._meta.db_table and (",
        "if alias =="
    ],
    [
        "output_field is None or output_field == self",
        "output_field is None or output_field"
    ],
    [
        "for field, value in zip(self.fields, vals):",
        "for field, value in zip(self.fields,"
    ],
    [
        "for field, val in zip(self.fields, vals, strict=True)",
        "for field, val in zip(self.fields,"
    ],
    [
        "\"Rel objects\" (for lack of a better name) carry information about the relation",
        "\"Rel objects\" (for lack of a better name) carry information about the"
    ],
    [
        "modeled by a related field and provide some utility functions. They're stored",
        "modeled by a related field and provide some"
    ],
    [
        "in the ``remote_field`` attribute of the field.",
        "in the ``remote_field`` attribute of the"
    ],
    [
        "They also act as reverse fields for the purposes of the Meta API because",
        "They also act as reverse fields for the purposes of the"
    ],
    [
        "they're the closest concept currently available.",
        "they're the closest concept currently"
    ],
    [
        "Used by ForeignObject to store information about the relation.",
        "Used by ForeignObject to store"
    ],
    [
        "``_meta.get_fields()`` returns this class to provide access to the field",
        "``_meta.get_fields()`` returns this class to provide access to"
    ],
    [
        "self.limit_choices_to = {} if limit_choices_to is None else limit_choices_to",
        "self.limit_choices_to = {} if limit_choices_to is None else"
    ],
    [
        "\"\"\"Should the related object be hidden?\"\"\"",
        "\"\"\"Should the related object be"
    ],
    [
        "When filtering against this relation, return the field on the remote",
        "When filtering against this relation, return"
    ],
    [
        "model against which the filtering should happen.",
        "model against which the filtering"
    ],
    [
        "\"Can't use target_field for multicolumn relations.\"",
        "\"Can't use target_field for"
    ],
    [
        "\"This property can't be accessed before self.field.contribute_to_class \"",
        "\"This property can't be accessed"
    ],
    [
        "Return choices with a default blank choices included, for use",
        "Return choices with a default blank choices included, for"
    ],
    [
        "as <select> choices for this field.",
        "as <select> choices for this"
    ],
    [
        "return (blank_choice if include_blank else []) + [(x.pk, str(x)) for x in qs]",
        "return (blank_choice if include_blank else []) + [(x.pk, str(x))"
    ],
    [
        "Set the related field's name, this is not available until later stages",
        "Set the related field's name, this is not"
    ],
    [
        "of app loading, so set_field_name is called from",
        "of app loading, so set_field_name is"
    ],
    [
        "opts = model._meta if model else self.related_model._meta",
        "opts = model._meta if model"
    ],
    [
        "if self.symmetrical and model == self.model:",
        "if self.symmetrical and"
    ],
    [
        "return opts.model_name + (\"_set\" if self.multiple else \"\")",
        "return opts.model_name + (\"_set\""
    ],
    [
        "Return the name of the cache key to use for storing an instance of the",
        "Return the name of the cache key to use for"
    ],
    [
        "forward model on the reverse model.",
        "forward model on the reverse"
    ],
    [
        "Used by the ForeignKey field to store information about the relation.",
        "Used by the ForeignKey field to store information about"
    ],
    [
        "``_meta.get_fields()`` returns this class to provide access to the field",
        "``_meta.get_fields()`` returns this class to provide access to the"
    ],
    [
        "Note: Because we somewhat abuse the Rel objects by using them as reverse",
        "Note: Because we somewhat abuse the Rel objects by using them"
    ],
    [
        "fields we get the funny situation where",
        "fields we get the"
    ],
    [
        "``ManyToOneRel.one_to_many == True``. This is unfortunate but the actual",
        "``ManyToOneRel.one_to_many == True``. This is unfortunate but the"
    ],
    [
        "ManyToOneRel class is a private API and there is work underway to turn",
        "ManyToOneRel class is a private API and there"
    ],
    [
        "Return the Field in the 'to' object to which this relationship is tied.",
        "Return the Field in the 'to' object to which this relationship"
    ],
    [
        "\"No related field named '%s'\" % self.field_name",
        "\"No related field named '%s'\""
    ],
    [
        "Used by OneToOneField to store information about the relation.",
        "Used by OneToOneField to store information"
    ],
    [
        "``_meta.get_fields()`` returns this class to provide access to the field",
        "``_meta.get_fields()`` returns this class to provide access"
    ],
    [
        "Used by ManyToManyField to store information about the relation.",
        "Used by ManyToManyField to store information about the"
    ],
    [
        "``_meta.get_fields()`` returns this class to provide access to the field",
        "``_meta.get_fields()`` returns this class to provide"
    ],
    [
        "raise ValueError(\"Can't supply a through model and db_constraint=False\")",
        "raise ValueError(\"Can't supply a through model"
    ],
    [
        "raise ValueError(\"Cannot specify through_fields without a through model\")",
        "raise ValueError(\"Cannot specify through_fields"
    ],
    [
        "Return the field in the 'to' object to which this relationship is tied.",
        "Return the field in the 'to' object to which this"
    ],
    [
        "if rel and rel.model == self.model:",
        "if rel and rel.model =="
    ],
    [
        "raise ValueError(\"Model instances passed to related filters must be saved.\")",
        "raise ValueError(\"Model instances passed to"
    ],
    [
        "while not isinstance(value, source.model) and source.remote_field:",
        "while not isinstance(value,"
    ],
    [
        "return pk if isinstance(pk, tuple) else (pk,)",
        "return pk if isinstance(pk, tuple) else"
    ],
    [
        "self.rhs = [target_field.get_prep_value(v) for v in self.rhs]",
        "self.rhs = [target_field.get_prep_value(v) for"
    ],
    [
        "elif not getattr(self.rhs, \"has_select_fields\", True) and not getattr(",
        "elif not getattr(self.rhs, \"has_select_fields\", True) and not"
    ],
    [
        "values = [get_normalized_value(value, self.lhs) for value in self.rhs]",
        "values = [get_normalized_value(value, self.lhs) for value"
    ],
    [
        "if not isinstance(self.lhs, ColPairs) and not hasattr(",
        "if not isinstance(self.lhs, ColPairs)"
    ],
    [
        "from django.db import NotSupportedError, connections, router",
        "from django.db import NotSupportedError, connections,"
    ],
    [
        "from django.utils.translation import gettext_lazy as _",
        "from django.utils.translation import gettext_lazy"
    ],
    [
        "\"invalid\": _(\"Value must be valid JSON.\"),",
        "\"invalid\": _(\"Value must be"
    ],
    [
        "raise ValueError(\"The encoder parameter must be a callable object.\")",
        "raise ValueError(\"The encoder parameter must be a"
    ],
    [
        "raise ValueError(\"The decoder parameter must be a callable object.\")",
        "raise ValueError(\"The decoder parameter must"
    ],
    [
        "\"%s does not support JSONFields.\" % connection.display_name,",
        "\"%s does not support"
    ],
    [
        "name, path, args, kwargs = super().deconstruct()",
        "name, path, args, kwargs ="
    ],
    [
        "if isinstance(expression, KeyTransform) and not isinstance(value, str):",
        "if isinstance(expression, KeyTransform) and"
    ],
    [
        "path = [\"$\"] if include_root else []",
        "path = [\"$\"] if include_root else"
    ],
    [
        "\"contains lookup is not supported on this database backend.\"",
        "\"contains lookup is not supported on this"
    ],
    [
        "return \"JSON_CONTAINS(%s, %s)\" % (lhs, rhs), params",
        "return \"JSON_CONTAINS(%s, %s)\" % (lhs, rhs),"
    ],
    [
        "\"contained_by lookup is not supported on this database backend.\"",
        "\"contained_by lookup is not supported on this database"
    ],
    [
        "return \"JSON_CONTAINS(%s, %s)\" % (rhs, lhs), params",
        "return \"JSON_CONTAINS(%s, %s)\" % (rhs,"
    ],
    [
        "yield lhs_sql, lhs_params, lhs_json_path + rhs_json_path",
        "yield lhs_sql, lhs_params, lhs_json_path +"
    ],
    [
        "for lhs_sql, lhs_params, rhs_json_path in self._as_sql_parts(",
        "for lhs_sql, lhs_params,"
    ],
    [
        "for lhs_sql, lhs_params, rhs_json_path in self._as_sql_parts(",
        "for lhs_sql, lhs_params,"
    ],
    [
        "compiler, connection, template=\"JSON_TYPE(%s, %s) IS NOT NULL\"",
        "compiler, connection, template=\"JSON_TYPE(%s, %s) IS NOT"
    ],
    [
        "return [str(item) for item in self.rhs]",
        "return [str(item) for item in"
    ],
    [
        "Mixin to allow case-insensitive comparison of JSON values on MySQL.",
        "Mixin to allow case-insensitive comparison of JSON"
    ],
    [
        "if rhs == \"%s\" and rhs_params == [None]:",
        "if rhs == \"%s\" and"
    ],
    [
        "func = [\"JSON_EXTRACT(%s, '$')\"] * len(rhs_params)",
        "func = [\"JSON_EXTRACT(%s,"
    ],
    [
        "return f\"JSON_EQUAL({lhs}, {rhs} ERROR ON ERROR)\", (*lhs_params, *rhs_params)",
        "return f\"JSON_EQUAL({lhs}, {rhs} ERROR ON"
    ],
    [
        "key_transforms = [key.replace(\"%\", \"%%\") for key in key_transforms]",
        "key_transforms = [key.replace(\"%\", \"%%\")"
    ],
    [
        "lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)",
        "lhs, params, key_transforms = self.preprocess_lhs(compiler,"
    ],
    [
        "return \"JSON_EXTRACT(%s, %%s)\" % lhs, tuple(params) + (json_path,)",
        "return \"JSON_EXTRACT(%s, %%s)\" %"
    ],
    [
        "lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)",
        "lhs, params, key_transforms"
    ],
    [
        "lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)",
        "lhs, params, key_transforms = self.preprocess_lhs(compiler,"
    ],
    [
        "sql = \"(%s %s %%s)\" % (lhs, self.postgres_nested_operator)",
        "sql = \"(%s %s %%s)\""
    ],
    [
        "return \"(%s %s %%s)\" % (lhs, self.postgres_operator), tuple(params) + (lookup,)",
        "return \"(%s %s %%s)\" %"
    ],
    [
        "lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)",
        "lhs, params, key_transforms"
    ],
    [
        "\"(CASE WHEN JSON_TYPE(%s, %%s) IN (%s) \"",
        "\"(CASE WHEN JSON_TYPE(%s, %%s) IN"
    ],
    [
        "\"THEN JSON_TYPE(%s, %%s) ELSE JSON_EXTRACT(%s, %%s) END)\"",
        "\"THEN JSON_TYPE(%s, %%s) ELSE JSON_EXTRACT(%s, %%s)"
    ],
    [
        "lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)",
        "lhs, params, key_transforms = self.preprocess_lhs(compiler,"
    ],
    [
        "return \"(%s ->> %%s)\" % lhs, tuple(params) + (json_path,)",
        "return \"(%s ->> %%s)\" % lhs,"
    ],
    [
        "raise ValueError(\"Lookup must contain key or index transforms.\")",
        "raise ValueError(\"Lookup must contain"
    ],
    [
        "Mixin for combining with a lookup expecting a text lhs from a JSONField",
        "Mixin for combining with a lookup expecting a text"
    ],
    [
        "key lookup. On PostgreSQL, make use of the ->> operator instead of casting",
        "key lookup. On PostgreSQL, make use of the"
    ],
    [
        "key values to text and performing the lookup on the resulting",
        "key values to text and performing the lookup on"
    ],
    [
        "\"Transform should be an instance of KeyTransform in order to \"",
        "\"Transform should be an instance of"
    ],
    [
        "lhs, lhs_params, _ = self.lhs.preprocess_lhs(compiler, connection)",
        "lhs, lhs_params, _"
    ],
    [
        "return \"(NOT %s OR %s IS NULL)\" % (sql, lhs), tuple(params) + tuple(lhs_params)",
        "return \"(NOT %s OR %s IS NULL)\" % (sql, lhs),"
    ],
    [
        "template = \"JSON_TYPE(%s, %s) IS NULL\"",
        "template = \"JSON_TYPE(%s,"
    ],
    [
        "template = \"JSON_TYPE(%s, %s) IS NOT NULL\"",
        "template = \"JSON_TYPE(%s, %s) IS NOT"
    ],
    [
        "def resolve_expression_parameter(self, compiler, connection, sql, param):",
        "def resolve_expression_parameter(self, compiler, connection,"
    ],
    [
        "sql = \"%s(JSON_OBJECT('value' VALUE %%s FORMAT JSON), '$.value')\"",
        "sql = \"%s(JSON_OBJECT('value' VALUE %%s"
    ],
    [
        "elif connection.vendor == \"mysql\" or (",
        "elif connection.vendor == \"mysql\" or"
    ],
    [
        "if connection.vendor == \"mysql\" and connection.mysql_is_mariadb:",
        "if connection.vendor == \"mysql\""
    ],
    [
        "sql = \"%s(JSON_OBJECT('value' VALUE %%s FORMAT JSON), '$.value')\"",
        "sql = \"%s(JSON_OBJECT('value' VALUE"
    ],
    [
        "\"%s AND %s\" % (has_key_sql, is_null_sql),",
        "\"%s AND %s\""
    ],
    [
        "rhs_params = [json.loads(value) for value in rhs_params]",
        "rhs_params = [json.loads(value) for value in"
    ],
    [
        "from django.core.exceptions import EmptyResultSet, FieldError, FullResultSet",
        "from django.core.exceptions import EmptyResultSet,"
    ],
    [
        "from django.db.models.expressions import ColPairs, F, OrderBy, RawSQL, Ref, Value",
        "from django.db.models.expressions import ColPairs, F,"
    ],
    [
        "def __init__(self, query, connection, using, elide_empty=True):",
        "def __init__(self, query, connection, using,"
    ],
    [
        "Do any necessary class setup immediately prior to producing SQL. This",
        "Do any necessary class setup immediately prior to producing"
    ],
    [
        "is for things that can't necessarily be done in __init__ because we",
        "is for things that can't necessarily"
    ],
    [
        "might not have all the pieces in place at that time.",
        "might not have all the pieces"
    ],
    [
        "group_by = self.get_group_by(self.select + extra_select, order_by)",
        "group_by = self.get_group_by(self.select"
    ],
    [
        "The logic of what exactly the GROUP BY clause contains is hard",
        "The logic of what exactly the"
    ],
    [
        "to describe in other words than \"if it passes the test suite,",
        "to describe in other words than \"if it passes the test"
    ],
    [
        "for expr, (sql, params, is_ref) in order_by:",
        "for expr, (sql, params, is_ref)"
    ],
    [
        "having_group_by = self.having.get_group_by_cols() if self.having else ()",
        "having_group_by = self.having.get_group_by_cols() if"
    ],
    [
        "and (position := selected_expr_positions.get(expr)) is not None",
        "and (position := selected_expr_positions.get(expr))"
    ],
    [
        "sql, params = expr.select_format(self, sql, params)",
        "sql, params = expr.select_format(self, sql,"
    ],
    [
        "if (sql, params_hash) not in seen:",
        "if (sql, params_hash) not in"
    ],
    [
        "aliases = {expr.alias for expr in pks}",
        "aliases = {expr.alias for expr in"
    ],
    [
        "or getattr(expr, \"alias\", None) not in aliases",
        "or getattr(expr, \"alias\", None) not"
    ],
    [
        "The (sql, params) is what the expression will produce, and alias is the",
        "The (sql, params) is what the expression"
    ],
    [
        "\"AS alias\" for the column (possibly None).",
        "\"AS alias\" for the column"
    ],
    [
        "The klass_info structure contains the following information:",
        "The klass_info structure contains the following"
    ],
    [
        "- The base model of the query.",
        "- The base model"
    ],
    [
        "- Which columns for that model are present in the query (by",
        "- Which columns for that model are present in the query"
    ],
    [
        "- related_klass_infos: [f, klass_info] to descent into",
        "- related_klass_infos: [f, klass_info]"
    ],
    [
        "The annotations is a dictionary of {'attname': column position} values.",
        "The annotations is a dictionary of"
    ],
    [
        "*((None, col) for col in cols),",
        "*((None, col) for col"
    ],
    [
        "for select_idx, (alias, expression) in enumerate(selected):",
        "for select_idx, (alias, expression)"
    ],
    [
        "sql, params = col.select_format(self, sql, params)",
        "sql, params = col.select_format(self, sql,"
    ],
    [
        "if alias is None and with_col_aliases:",
        "if alias is None"
    ],
    [
        "elif (meta := self.query.get_meta()) and meta.ordering:",
        "elif (meta := self.query.get_meta()) and"
    ],
    [
        "if ordering and (select := self.select):",
        "if ordering and"
    ],
    [
        "field.nulls_first is None and field.nulls_last is None",
        "field.nulls_first is None and field.nulls_last is"
    ],
    [
        "yield field, select_ref is not None",
        "yield field, select_ref"
    ],
    [
        "\"Ordering combined queries by transforms is not \"",
        "\"Ordering combined queries by transforms is not"
    ],
    [
        "if self.query.extra and col in self.query.extra:",
        "if self.query.extra and col"
    ],
    [
        "The order_by clause can alter the select clause (for example it can add",
        "The order_by clause can alter the select clause"
    ],
    [
        "aliases to clauses that do not yet have one, or it can add totally new",
        "aliases to clauses that do not yet have one, or it"
    ],
    [
        "if not is_ref and self.query.combinator and self.select:",
        "if not is_ref and self.query.combinator and"
    ],
    [
        "for sel_expr, _, col_alias in self.select:",
        "for sel_expr, _, col_alias in"
    ],
    [
        "isinstance(expr_src, F) and col_alias == expr_src.name",
        "isinstance(expr_src, F) and col_alias =="
    ],
    [
        "[Ref(col_alias if col_alias else src.target.column, src)]",
        "[Ref(col_alias if col_alias else"
    ],
    [
        "\"ORDER BY term does not match any column in \"",
        "\"ORDER BY term does not"
    ],
    [
        "for expr, (sql, params, is_ref) in order_by:",
        "for expr, (sql, params, is_ref)"
    ],
    [
        "if not is_ref and (without_ordering, params) not in select_sql:",
        "if not is_ref and (without_ordering,"
    ],
    [
        "A wrapper around connection.ops.quote_name that doesn't quote aliases",
        "A wrapper around connection.ops.quote_name that"
    ],
    [
        "for table names. This avoids problems with some SQL dialects that treat",
        "for table names. This avoids problems with some SQL"
    ],
    [
        "(name in self.query.alias_map and name not in self.query.table_map)",
        "(name in self.query.alias_map and name not in"
    ],
    [
        "vendor_impl = getattr(node, \"as_\" + self.connection.vendor, None)",
        "vendor_impl = getattr(node, \"as_\" +"
    ],
    [
        "\"LIMIT/OFFSET not allowed in subqueries of compound statements.\"",
        "\"LIMIT/OFFSET not allowed in subqueries"
    ],
    [
        "\"ORDER BY not allowed in subqueries of compound statements.\"",
        "\"ORDER BY not allowed in"
    ],
    [
        "if combinator == \"union\" or (combinator == \"difference\" and parts):",
        "if combinator == \"union\" or"
    ],
    [
        "if all and combinator == \"union\":",
        "if all and combinator =="
    ],
    [
        "*((braces.format(sql), args) for sql, args in parts)",
        "*((braces.format(sql), args) for sql,"
    ],
    [
        "if selected is not None and compiler.query.selected is None:",
        "if selected is not None and"
    ],
    [
        "part_sql = \"SELECT * FROM ({})\".format(part_sql)",
        "part_sql = \"SELECT * FROM"
    ],
    [
        "{expr: Ref(alias, expr) for expr, alias in replacements.items()}",
        "{expr: Ref(alias, expr) for expr, alias"
    ],
    [
        "{expr: Ref(alias, expr) for expr, alias in replacements.items()}",
        "{expr: Ref(alias, expr) for"
    ],
    [
        "cols = [self.connection.ops.quote_name(alias) for alias in select.values()]",
        "cols = [self.connection.ops.quote_name(alias) for"
    ],
    [
        "Create the SQL for this query. Return the SQL string and list of",
        "Create the SQL for this query. Return the SQL string and"
    ],
    [
        "If 'with_limits' is False, any limit/offset information is not included",
        "If 'with_limits' is False, any limit/offset information"
    ],
    [
        "\"{} is not supported on this database backend.\".format(",
        "\"{} is not supported on"
    ],
    [
        "self.compile(self.where) if self.where is not None else (\"\", [])",
        "self.compile(self.where) if self.where is not"
    ],
    [
        "for _, (s_sql, s_params), alias in self.select + extra_select:",
        "for _, (s_sql, s_params), alias in self.select"
    ],
    [
        "s_sql = \"%s AS %s\" % (",
        "s_sql = \"%s AS %s\" %"
    ],
    [
        "\"select_for_update cannot be used outside of a transaction.\"",
        "\"select_for_update cannot be used"
    ],
    [
        "\"LIMIT/OFFSET is not supported with \"",
        "\"LIMIT/OFFSET is not supported"
    ],
    [
        "\"NOWAIT is not supported on this database backend.\"",
        "\"NOWAIT is not supported on"
    ],
    [
        "\"SKIP LOCKED is not supported on this database backend.\"",
        "\"SKIP LOCKED is not supported"
    ],
    [
        "\"FOR UPDATE OF is not supported on this database backend.\"",
        "\"FOR UPDATE OF is not supported on this"
    ],
    [
        "\"FOR NO KEY UPDATE is not supported on this \"",
        "\"FOR NO KEY UPDATE is not supported on"
    ],
    [
        "\"annotate() + distinct(fields) is not implemented.\"",
        "\"annotate() + distinct(fields) is not"
    ],
    [
        "result.append(\"GROUP BY %s\" % \", \".join(grouping))",
        "result.append(\"GROUP BY %s\""
    ],
    [
        "for _, (o_sql, o_params, _) in order_by:",
        "for _, (o_sql, o_params, _) in"
    ],
    [
        "order_by_sql = \"ORDER BY %s\" % \", \".join(ordering)",
        "order_by_sql = \"ORDER BY %s\""
    ],
    [
        "result = [\"SELECT * FROM (\", *result, \")\", order_by_sql]",
        "result = [\"SELECT * FROM (\", *result,"
    ],
    [
        "return \"SELECT %s FROM (%s) subquery\" % (",
        "return \"SELECT %s FROM (%s)"
    ],
    [
        "Compute the default columns for selecting every field in the base",
        "Compute the default columns for selecting every field in the"
    ],
    [
        "model. Will sometimes be called to pull in related models (e.g. via",
        "model. Will sometimes be called to pull in related models"
    ],
    [
        "select_related), in which case \"opts\" and \"start_alias\" will be given",
        "select_related), in which case \"opts\" and \"start_alias\" will"
    ],
    [
        "to provide a starting point for the traversal.",
        "to provide a starting point"
    ],
    [
        "Return a list of strings, quoted appropriately for use in SQL",
        "Return a list of strings, quoted"
    ],
    [
        "directly, as well as a set of aliases used in the select statement (if",
        "directly, as well as a set of aliases used in the select"
    ],
    [
        "'as_pairs' is True, return a list of (alias, col_name) pairs instead",
        "'as_pairs' is True, return a list of (alias,"
    ],
    [
        "of strings as the first component and None as the second component).",
        "of strings as the first component and None as the second"
    ],
    [
        "if (opts := self.query.get_meta()) is None:",
        "if (opts :="
    ],
    [
        "if select_mask and field not in select_mask_fields:",
        "if select_mask and field"
    ],
    [
        "alias = self.query.join_parent_model(opts, model, start_alias, seen_models)",
        "alias = self.query.join_parent_model(opts,"
    ],
    [
        "Return a quoted list of fields to use in DISTINCT ON part of the query.",
        "Return a quoted list of fields to use in DISTINCT ON part"
    ],
    [
        "This method can alter the tables in the query, and thus it must be",
        "This method can alter the tables in the query,"
    ],
    [
        "_, targets, alias, joins, path, _, transform_function = self._setup_joins(",
        "_, targets, alias, joins, path, _, transform_function"
    ],
    [
        "targets, alias, _ = self.query.trim_joins(targets, joins, path)",
        "targets, alias, _ ="
    ],
    [
        "self, name, opts, alias=None, default_order=\"ASC\", already_seen=None",
        "self, name, opts, alias=None, default_order=\"ASC\","
    ],
    [
        "Return the table alias (the name might be ambiguous, the alias will",
        "Return the table alias (the name might be"
    ],
    [
        "not be) and column name for ordering by the given 'name' parameter.",
        "not be) and column name for ordering by the given"
    ],
    [
        "getattr(self.query.alias_map[j], \"join_cols\", None) for j in joins",
        "getattr(self.query.alias_map[j], \"join_cols\", None) for j"
    ],
    [
        "raise FieldError(\"Infinite loop caused by ordering.\")",
        "raise FieldError(\"Infinite loop"
    ],
    [
        "if hasattr(item, \"resolve_expression\") and not isinstance(",
        "if hasattr(item, \"resolve_expression\")"
    ],
    [
        "item = item.desc() if descending else item.asc()",
        "item = item.desc() if descending"
    ],
    [
        "targets, alias, _ = self.query.trim_joins(targets, joins, path)",
        "targets, alias, _ = self.query.trim_joins(targets,"
    ],
    [
        "Helper method for get_order_by() and get_distinct().",
        "Helper method for get_order_by() and"
    ],
    [
        "get_ordering() and get_distinct() must produce same target columns on",
        "get_ordering() and get_distinct() must produce same target columns"
    ],
    [
        "same input, as the prefixes of get_ordering() and get_distinct() must",
        "same input, as the prefixes of get_ordering()"
    ],
    [
        "match. Executing SQL where this is not true is an error.",
        "match. Executing SQL where this is"
    ],
    [
        "field, targets, opts, joins, path, transform_function = self.query.setup_joins(",
        "field, targets, opts, joins, path, transform_function ="
    ],
    [
        "return field, targets, alias, joins, path, opts, transform_function",
        "return field, targets, alias, joins, path, opts,"
    ],
    [
        "Return a list of strings that are joined together to go after the",
        "Return a list of strings that are joined together"
    ],
    [
        "\"FROM\" part of the query, as well as a list any extra parameters that",
        "\"FROM\" part of the query, as well as a list any extra"
    ],
    [
        "need to be included. Subclasses, can override this to create a",
        "need to be included. Subclasses, can override this"
    ],
    [
        "This should only be called after any SQL construction methods that",
        "This should only be called after any SQL"
    ],
    [
        "might change the tables that are needed. This means the select columns,",
        "might change the tables that are needed. This means the select"
    ],
    [
        "ordering, and distinct must be done first.",
        "ordering, and distinct must be done"
    ],
    [
        "Fill in the information needed for a select_related query. The current",
        "Fill in the information needed for a select_related"
    ],
    [
        "depth is measured as the number of connections away from the root model",
        "depth is measured as the number of connections"
    ],
    [
        "direct_choices = (f.name for f in opts.fields if f.is_relation)",
        "direct_choices = (f.name for f"
    ],
    [
        "if not restricted and cur_depth > self.query.max_depth:",
        "if not restricted and"
    ],
    [
        "if next or f.name in requested:",
        "if next or f.name in"
    ],
    [
        "\"Non-relational field given in select_related: '%s'. \"",
        "\"Non-relational field given in"
    ],
    [
        "if not select_related_descend(f, restricted, requested, select_mask):",
        "if not select_related_descend(f, restricted,"
    ],
    [
        "f.remote_field.set_cached_value if f.unique else lambda x, y: None",
        "f.remote_field.set_cached_value if f.unique else"
    ],
    [
        "_, _, _, joins, _, _ = self.query.setup_joins([f.name], opts, root_alias)",
        "_, _, _, joins, _,"
    ],
    [
        "for related_object, related_field, model in related_fields:",
        "for related_object, related_field,"
    ],
    [
        "from_parent = issubclass(model, opts.model) and model is not opts.model",
        "from_parent = issubclass(model, opts.model) and model is not"
    ],
    [
        "final_field, _, join_opts, joins, _, _ = self.query.setup_joins(",
        "final_field, _, join_opts, joins, _,"
    ],
    [
        "issubclass(model, opts.model) and model is not opts.model",
        "issubclass(model, opts.model) and model is not"
    ],
    [
        "field_select_mask = select_mask.get((name, final_field)) or {}",
        "field_select_mask = select_mask.get((name, final_field)) or"
    ],
    [
        "invalid_fields = (\"'%s'\" % s for s in fields_not_found)",
        "invalid_fields = (\"'%s'\" % s for s in"
    ],
    [
        "\"Invalid field name(s) given in select_related: %s. \"",
        "\"Invalid field name(s) given in select_related: %s."
    ],
    [
        "Return a quoted list of arguments for the SELECT FOR UPDATE OF part of",
        "Return a quoted list of arguments for the SELECT FOR UPDATE OF part"
    ],
    [
        "Find the first selected column from a model. If it doesn't exist,",
        "Find the first selected column from a"
    ],
    [
        "select_fields is filled recursively, so it also contains fields",
        "select_fields is filled recursively, so it also contains"
    ],
    [
        "\"\"\"Yield all allowed field paths in breadth-first search order.\"\"\"",
        "\"\"\"Yield all allowed field paths"
    ],
    [
        "\"Invalid field name(s) given in select_for_update(of=(...)): %s. \"",
        "\"Invalid field name(s) given in select_for_update(of=(...)):"
    ],
    [
        "\"Only relational fields followed in the query are allowed. \"",
        "\"Only relational fields followed in the query are allowed."
    ],
    [
        "for j, (convs, col) in cols_converters.items():",
        "for j, (convs,"
    ],
    [
        "converters[i + j] = (convs, col)",
        "converters[i + j] = (convs,"
    ],
    [
        "converters[i] = (backend_converters + field_converters, expression)",
        "converters[i] = (backend_converters"
    ],
    [
        "for pos, (convs, expression) in converters:",
        "for pos, (convs, expression)"
    ],
    [
        "return any(isinstance(expression, ColPairs) for expression in expressions)",
        "return any(isinstance(expression, ColPairs) for expression in"
    ],
    [
        "\"\"\"Return an iterator over the results from executing this query.\"\"\"",
        "\"\"\"Return an iterator over the results from executing this"
    ],
    [
        "Backends (e.g. NoSQL) can override this in order to use optimized",
        "Backends (e.g. NoSQL) can override this in"
    ],
    [
        "versions of \"query has any results.\"",
        "versions of \"query"
    ],
    [
        "Run the query against the database and return the result(s). The",
        "Run the query against the database and return"
    ],
    [
        "return value depends on the value of result_type.",
        "return value depends on the"
    ],
    [
        "- MULTI: Retrieves all rows using fetchmany(). Wraps in an iterator for",
        "- MULTI: Retrieves all rows using fetchmany(). Wraps in an iterator"
    ],
    [
        "- SINGLE: Retrieves a single row using fetchone().",
        "- SINGLE: Retrieves a single row using"
    ],
    [
        "- ROW_COUNT: Retrieves the number of rows in the result.",
        "- ROW_COUNT: Retrieves the number"
    ],
    [
        "- CURSOR: Runs the query, and returns the cursor object. It is the",
        "- CURSOR: Runs the query, and returns the"
    ],
    [
        "caller's responsibility to close the cursor.",
        "caller's responsibility to close the"
    ],
    [
        "if not chunked_fetch or not self.connection.features.can_use_chunked_reads:",
        "if not chunked_fetch"
    ],
    [
        "output_formatter = json.dumps if format_ and format_.lower() == \"json\" else str",
        "output_formatter = json.dumps if format_ and format_.lower() == \"json\""
    ],
    [
        "yield \" \".join([output_formatter(c) for c in value])",
        "yield \" \".join([output_formatter(c) for"
    ],
    [
        "Take a field and a value intended to be saved on that field, and",
        "Take a field and a value intended to be saved on"
    ],
    [
        "return placeholder SQL and accompanying params. Check for raw values,",
        "return placeholder SQL and accompanying"
    ],
    [
        "expressions, and fields with get_placeholder() defined in that order.",
        "expressions, and fields with get_placeholder() defined in that"
    ],
    [
        "When field is None, consider the value raw and use it as the",
        "When field is None, consider the value raw"
    ],
    [
        "placeholder, with no corresponding parameters returned.",
        "placeholder, with no corresponding parameters"
    ],
    [
        "sql, params = get_placeholder(val, self, self.connection), [val]",
        "sql, params = get_placeholder(val, self,"
    ],
    [
        "Prepare a value to be used in a query by resolving it if it is an",
        "Prepare a value to be used in a query by"
    ],
    [
        "expression and otherwise calling the field's get_db_prep_save().",
        "expression and otherwise calling"
    ],
    [
        "'Failed to insert expression \"%s\" on %s. F() expressions '",
        "'Failed to insert expression \"%s\" on %s. F() expressions"
    ],
    [
        "\"can only be used to update, not to insert.\" % (value, field)",
        "\"can only be used to update, not"
    ],
    [
        "\"Aggregate functions are not allowed in this query \"",
        "\"Aggregate functions are not allowed in this query"
    ],
    [
        "\"Window expressions are not allowed in this query (%s=%r).\"",
        "\"Window expressions are not allowed in this"
    ],
    [
        "Get the given field's value off the given obj. pre_save() is used for",
        "Get the given field's value off the given"
    ],
    [
        "things like auto_now on DateTimeField. Skip it if this is a raw query.",
        "things like auto_now on DateTimeField. Skip it if this is"
    ],
    [
        "Take a sequence of N fields and a sequence of M rows of values, and",
        "Take a sequence of N fields and a sequence of M rows of"
    ],
    [
        "generate placeholder SQL and parameters for each field and value.",
        "generate placeholder SQL and parameters for each"
    ],
    [
        "* a sequence of M rows of N SQL placeholder strings, and",
        "* a sequence of M rows of N SQL placeholder strings,"
    ],
    [
        "* a sequence of M rows of corresponding parameter values.",
        "* a sequence of M rows of"
    ],
    [
        "Each placeholder string may contain any number of '%s' interpolation",
        "Each placeholder string may contain any number of '%s'"
    ],
    [
        "strings, and each parameter row will contain exactly as many params",
        "strings, and each parameter row will contain exactly as many"
    ],
    [
        "as the total number of '%s's in the corresponding placeholder row.",
        "as the total number of '%s's in the"
    ],
    [
        "get_placeholders = [getattr(field, \"get_placeholder\", None) for field in fields]",
        "get_placeholders = [getattr(field, \"get_placeholder\", None) for field in"
    ],
    [
        "for field, get_placeholder, value in zip(fields, get_placeholders, row)",
        "for field, get_placeholder, value"
    ],
    [
        "sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)",
        "sql_and_param_pair_rows = (zip(*row) for"
    ],
    [
        "param_rows = [[p for ps in row for p in ps] for row in param_rows]",
        "param_rows = [[p for ps in row for p in ps] for"
    ],
    [
        "result = [\"%s %s\" % (insert_statement, qn(opts.db_table))]",
        "result = [\"%s %s\" % (insert_statement,"
    ],
    [
        "isinstance(value, DatabaseDefault) for value in field_values",
        "isinstance(value, DatabaseDefault) for"
    ],
    [
        "result.append(\"(%s)\" % \", \".join(qn(f.column) for f in fields))",
        "result.append(\"(%s)\" % \", \".join(qn(f.column) for"
    ],
    [
        "return [(\" \".join(result), tuple(p for ps in param_rows for p in ps))]",
        "return [(\" \".join(result), tuple(p for ps in param_rows"
    ],
    [
        "(\" \".join(result + [\"VALUES (%s)\" % \", \".join(p)]), vals)",
        "(\" \".join(result + [\"VALUES (%s)\" %"
    ],
    [
        "for p, vals in zip(placeholder_rows, param_rows)",
        "for p, vals"
    ],
    [
        "cols = [field.get_col(opts.db_table) for field in self.returning_fields]",
        "cols = [field.get_col(opts.db_table) for field"
    ],
    [
        "cols = [field.get_col(opts.db_table) for field in self.returning_fields]",
        "cols = [field.get_col(opts.db_table) for field in"
    ],
    [
        "delete = \"DELETE FROM %s\" % self.quote_name_unless_alias(query.base_table)",
        "delete = \"DELETE FROM %s\" %"
    ],
    [
        "Create the SQL for this query. Return the SQL string and list of",
        "Create the SQL for this query. Return the"
    ],
    [
        "innerq = RawSQL(\"SELECT * FROM (%s) subquery\" % sql, params)",
        "innerq = RawSQL(\"SELECT * FROM (%s) subquery\" %"
    ],
    [
        "Create the SQL for this query. Return the SQL string and list of",
        "Create the SQL for this query. Return the SQL string"
    ],
    [
        "for field, model, val in self.query.values:",
        "for field, model, val in"
    ],
    [
        "\"Aggregate functions are not allowed in this query \"",
        "\"Aggregate functions are not allowed in"
    ],
    [
        "\"Window expressions are not allowed in this query \"",
        "\"Window expressions are not allowed in this"
    ],
    [
        "\"Composite primary keys expressions are not allowed \"",
        "\"Composite primary keys expressions"
    ],
    [
        "\"in this query (%s=F('pk')).\" % field.name",
        "\"in this query (%s=F('pk')).\" %"
    ],
    [
        "\"Tried to update field %s with a model instance, %r. \"",
        "\"Tried to update field %s with a model instance,"
    ],
    [
        "\"Use a value compatible with %s.\"",
        "\"Use a value compatible with"
    ],
    [
        "values.append(\"%s = %s\" % (qn(name), placeholder % sql))",
        "values.append(\"%s = %s\" % (qn(name), placeholder %"
    ],
    [
        "values.append(\"%s = %s\" % (qn(name), placeholder))",
        "values.append(\"%s = %s\""
    ],
    [
        "return \" \".join(result), tuple(update_params + params)",
        "return \" \".join(result), tuple(update_params +"
    ],
    [
        "Execute the specified update. Return the number of rows affected by",
        "Execute the specified update. Return the number of rows"
    ],
    [
        "the primary update query. The \"primary update query\" is the first",
        "the primary update query. The \"primary update query\""
    ],
    [
        "non-empty query that is executed. Row counts for any subsequent,",
        "non-empty query that is executed. Row counts for any"
    ],
    [
        "If the update depends on results from other tables, munge the \"where\"",
        "If the update depends on results"
    ],
    [
        "conditions to match the format required for (portable) SQL updates.",
        "conditions to match the format required for (portable) SQL"
    ],
    [
        "If multiple updates are required, pull out the id values to update at",
        "If multiple updates are required, pull out"
    ],
    [
        "this point so that they don't change as a result of the progressive",
        "this point so that they don't change as"
    ],
    [
        "Create the SQL for this query. Return the SQL string and list of",
        "Create the SQL for this query. Return"
    ],
    [
        "ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)",
        "ann_sql, ann_params = annotation.select_format(self,"
    ],
    [
        "sql = \"SELECT %s FROM (%s) subquery\" % (sql, inner_query_sql)",
        "sql = \"SELECT %s FROM (%s) subquery\" % (sql,"
    ],
    [
        "Yield blocks of rows from a cursor and ensure the cursor is closed when",
        "Yield blocks of rows from a cursor and ensure the"
    ],
    [
        "for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):",
        "for rows in iter((lambda:"
    ],
    [
        "yield rows if col_count is None else [r[:col_count] for r in rows]",
        "yield rows if col_count is None else [r[:col_count] for"
    ],
    [
        "The code in here encapsulates all of the SQL construction so that QuerySets",
        "The code in here encapsulates all of the SQL construction"
    ],
    [
        "themselves do not have to (and could be backed by things other than SQL",
        "themselves do not have to (and could be backed"
    ],
    [
        "databases). The abstraction barrier only works one way: this module has to know",
        "databases). The abstraction barrier only works one way: this module has to"
    ],
    [
        "all about the internals of models in order to get the information it needs.",
        "all about the internals of models in order"
    ],
    [
        "from itertools import chain, count, product",
        "from itertools import"
    ],
    [
        "from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections",
        "from django.db import"
    ],
    [
        "from django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE",
        "from django.db.models.sql.constants import INNER,"
    ],
    [
        "from django.db.models.sql.datastructures import BaseTable, Empty, Join, MultiJoin",
        "from django.db.models.sql.datastructures import BaseTable, Empty, Join,"
    ],
    [
        "from django.db.models.sql.where import AND, OR, ExtraWhere, NothingNode, WhereNode",
        "from django.db.models.sql.where import AND, OR, ExtraWhere, NothingNode,"
    ],
    [
        "(f.name, f.attname) if f.concrete else (f.name,) for f in opts.get_fields()",
        "(f.name, f.attname) if f.concrete else"
    ],
    [
        "if not isinstance(rhs, F) and hasattr(rhs, \"resolve_expression\"):",
        "if not isinstance(rhs, F) and"
    ],
    [
        "\"Passing a QuerySet within a FilteredRelation is not supported.\"",
        "\"Passing a QuerySet within a"
    ],
    [
        "[get_child_with_renamed_prefix(prefix, replacement, c) for c in q.children],",
        "[get_child_with_renamed_prefix(prefix, replacement, c) for c"
    ],
    [
        "(\"final_field\", \"targets\", \"opts\", \"joins\", \"path\", \"transform_function\"),",
        "(\"final_field\", \"targets\", \"opts\","
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self)",
        "return \"<%s: %s>\""
    ],
    [
        "return dict if isinstance(self.params, Mapping) else tuple",
        "return dict if isinstance(self.params, Mapping) else"
    ],
    [
        "params = tuple(adapter(val) for val in self.params)",
        "params = tuple(adapter(val) for"
    ],
    [
        "params = {key: adapter(val) for key, val in self.params.items()}",
        "params = {key: adapter(val) for key, val"
    ],
    [
        "raise RuntimeError(\"Unexpected params type: %s\" % params_type)",
        "raise RuntimeError(\"Unexpected params type: %s\" %"
    ],
    [
        "return getattr(select, \"target\", None) or select.field",
        "return getattr(select, \"target\","
    ],
    [
        "Return the query as a string of SQL with the parameter values",
        "Return the query as a string of SQL"
    ],
    [
        "substituted in (use sql_with_params() to see the unsubstituted string).",
        "substituted in (use sql_with_params() to see the unsubstituted"
    ],
    [
        "Parameter values won't necessarily be quoted correctly, since that is",
        "Parameter values won't necessarily be"
    ],
    [
        "done by the database interface at execution time.",
        "done by the database interface"
    ],
    [
        "Return the query as an SQL string and the parameters that will be",
        "Return the query as an SQL string and the"
    ],
    [
        "\"\"\"Limit the amount of work when a Query is deepcopied.\"\"\"",
        "\"\"\"Limit the amount of work when a"
    ],
    [
        "if using is None and connection is None:",
        "if using is None and"
    ],
    [
        "raise ValueError(\"Need either using or connection\")",
        "raise ValueError(\"Need either using"
    ],
    [
        "Return the Options instance (the model._meta) from which to start",
        "Return the Options instance (the model._meta) from which"
    ],
    [
        "processing. Normally, this is self.model._meta, but it can be changed",
        "processing. Normally, this is self.model._meta,"
    ],
    [
        "Return a copy of the current Query. A lightweight alternative to",
        "Return a copy of the current Query. A lightweight alternative"
    ],
    [
        "Return a copy of the current Query that's ready for another operation.",
        "Return a copy of the current Query that's ready"
    ],
    [
        "The klass argument changes the type of the Query, e.g. UpdateQuery.",
        "The klass argument changes the type of the"
    ],
    [
        "if klass and obj.__class__ != klass:",
        "if klass and obj.__class__"
    ],
    [
        "Return the dictionary with the values of the existing aggregations.",
        "Return the dictionary with the values of the"
    ],
    [
        "raise TypeError(\"%s is not an aggregate expression\" % alias)",
        "raise TypeError(\"%s is not an aggregate expression\""
    ],
    [
        "aggregates = {alias: self.annotations.pop(alias) for alias in aggregate_exprs}",
        "aggregates = {alias: self.annotations.pop(alias)"
    ],
    [
        "if not qualify and not self.combinator:",
        "if not qualify and"
    ],
    [
        "elide_empty = not any(result is NotImplemented for result in empty_set_result)",
        "elide_empty = not any(result is NotImplemented for"
    ],
    [
        "Perform a COUNT() query using the current filter constraints.",
        "Perform a COUNT() query using the current filter"
    ],
    [
        "(f.attname for f in self.model._meta.concrete_fields), False",
        "(f.attname for f in"
    ],
    [
        "if q.combined_queries and q.combinator == \"union\":",
        "if q.combined_queries and q.combinator"
    ],
    [
        "Merge the 'rhs' query into the current one (with any 'rhs' effects",
        "Merge the 'rhs' query into the"
    ],
    [
        "being applied *after* (that is, \"to the right of\") anything in the",
        "being applied *after* (that is, \"to the right of\") anything in"
    ],
    [
        "current query. 'rhs' is not modified during a call to this function.",
        "current query. 'rhs' is not modified during a"
    ],
    [
        "The 'connector' parameter describes how to connect filters from the",
        "The 'connector' parameter describes how to connect filters"
    ],
    [
        "raise TypeError(\"Cannot combine queries on two different base models.\")",
        "raise TypeError(\"Cannot combine queries on"
    ],
    [
        "raise TypeError(\"Cannot combine queries once a slice has been taken.\")",
        "raise TypeError(\"Cannot combine queries once a slice has been"
    ],
    [
        "raise TypeError(\"Cannot combine a unique query with a non-unique query.\")",
        "raise TypeError(\"Cannot combine a unique"
    ],
    [
        "raise TypeError(\"Cannot combine queries with different distinct fields.\")",
        "raise TypeError(\"Cannot combine queries"
    ],
    [
        "reuse = set() if conjunction else set(self.alias_map)",
        "reuse = set() if"
    ],
    [
        "j for j in self.alias_map if self.alias_map[j].join_type == INNER",
        "j for j in self.alias_map if self.alias_map[j].join_type"
    ],
    [
        "\"When merging querysets using 'or', you cannot have \"",
        "\"When merging querysets using 'or',"
    ],
    [
        "for field in opts.concrete_fields + opts.related_objects:",
        "for field in"
    ],
    [
        "if field_attname := getattr(field, \"attname\", None):",
        "if field_attname := getattr(field,"
    ],
    [
        "if field_mask is None and field_att_mask is None:",
        "if field_mask is None and field_att_mask"
    ],
    [
        "Convert the self.deferred_loading data structure to an alternate data",
        "Convert the self.deferred_loading data structure to an alternate"
    ],
    [
        "structure, describing the field that *will* be loaded. This is used to",
        "structure, describing the field that *will* be loaded."
    ],
    [
        "compute the columns to select from the database and also by the",
        "compute the columns to select from the database and"
    ],
    [
        "QuerySet class to work out which fields are being initialized on each",
        "QuerySet class to work out which fields are"
    ],
    [
        "model. Models that have all their fields included aren't mentioned in",
        "model. Models that have all their fields included aren't mentioned"
    ],
    [
        "the result, only those that have field restrictions in place.",
        "the result, only those that have"
    ],
    [
        "Return a table alias for the given table_name and whether this is a",
        "Return a table alias for the given"
    ],
    [
        "If 'create' is true, a new alias is always created. Otherwise, the",
        "If 'create' is true, a new alias"
    ],
    [
        "most recently created alias for the table (if one exists) is reused.",
        "most recently created alias for the"
    ],
    [
        "filtered_relation.alias if filtered_relation is not None else table_name",
        "filtered_relation.alias if filtered_relation is"
    ],
    [
        "\"\"\"Increases the reference count for this alias.\"\"\"",
        "\"\"\"Increases the reference count for this"
    ],
    [
        "\"\"\"Decreases the reference count for this alias.\"\"\"",
        "\"\"\"Decreases the reference count for this"
    ],
    [
        "Promote recursively the join type of given aliases and its children to",
        "Promote recursively the join type of given aliases"
    ],
    [
        "an outer join. If 'unconditional' is False, only promote the join if",
        "an outer join. If 'unconditional' is False, only"
    ],
    [
        "it is nullable or the parent join is an outer join.",
        "it is nullable or the parent join is"
    ],
    [
        "The children promotion is done to avoid join chains that contain a LOUTER",
        "The children promotion is done to avoid join chains that"
    ],
    [
        "b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,",
        "b INNER c. So, if we have currently a INNER b INNER c and"
    ],
    [
        "then we must also promote b->c automatically, or otherwise the promotion",
        "then we must also promote b->c automatically,"
    ],
    [
        "of a->b doesn't actually change anything in the query results.",
        "of a->b doesn't actually change"
    ],
    [
        "if (self.alias_map[alias].nullable or parent_louter) and not already_louter:",
        "if (self.alias_map[alias].nullable or parent_louter) and"
    ],
    [
        "Change join type from LOUTER to INNER for all joins in aliases.",
        "Change join type from LOUTER to INNER for all joins in"
    ],
    [
        "Similarly to promote_joins(), this method must ensure no join chains",
        "Similarly to promote_joins(), this method must ensure no join"
    ],
    [
        "containing first an outer, then an inner join are generated. If we",
        "containing first an outer, then an"
    ],
    [
        "are demoting b->c join in chain a LOUTER b LOUTER c then we must",
        "are demoting b->c join in chain a"
    ],
    [
        "demote a->b automatically, or otherwise the demotion of b->c doesn't",
        "demote a->b automatically, or otherwise"
    ],
    [
        "actually change anything in the query results. .",
        "actually change anything in"
    ],
    [
        "Reset reference counts for aliases so that they match the value passed",
        "Reset reference counts for aliases so that they match"
    ],
    [
        "Change the aliases in change_map (which maps old-alias -> new-alias),",
        "Change the aliases in change_map"
    ],
    [
        "relabelling any references to them in select columns and the where",
        "relabelling any references to them in select columns and the"
    ],
    [
        "self.select = tuple([col.relabeled_clone(change_map) for col in self.select])",
        "self.select = tuple([col.relabeled_clone(change_map) for col in"
    ],
    [
        "change_map.get(alias, alias): (aliased or alias in change_map)",
        "change_map.get(alias, alias): (aliased or alias in"
    ],
    [
        "Change the alias prefix to the next letter in the alphabet in a way",
        "Change the alias prefix to the next letter in the alphabet"
    ],
    [
        "that the other query's aliases and this query's aliases will not",
        "that the other query's aliases and"
    ],
    [
        "conflict. Even tables that previously had no alias will get an alias",
        "conflict. Even tables that previously had no"
    ],
    [
        "after this call. To prevent changing aliases use the exclude parameter.",
        "after this call. To prevent changing aliases"
    ],
    [
        "Generate a sequence of characters in alphabetical order:",
        "Generate a sequence of"
    ],
    [
        "When the alphabet is finished, the sequence will continue with the",
        "When the alphabet is finished, the sequence will continue"
    ],
    [
        "seq = alphabet[alphabet.index(prefix) :] if prefix else alphabet",
        "seq = alphabet[alphabet.index(prefix) :] if prefix else"
    ],
    [
        "\"Maximum recursion depth exceeded: too many subqueries.\"",
        "\"Maximum recursion depth exceeded: too"
    ],
    [
        "Return the first alias for this query, after increasing its reference",
        "Return the first alias for this query, after increasing its"
    ],
    [
        "Return the number of tables in this query with a non-zero reference",
        "Return the number of tables in this query with"
    ],
    [
        "count. After execution, the reference counts are zeroed, so tables",
        "count. After execution, the reference counts are zeroed, so"
    ],
    [
        "added in compiler will not be seen by this method.",
        "added in compiler will not be seen by"
    ],
    [
        "Return an alias for the 'join', either reusing an existing alias for",
        "Return an alias for the 'join', either reusing an"
    ],
    [
        "that join or creating a new one. 'join' is either a base_table_class or",
        "that join or creating a new one. 'join' is either a base_table_class"
    ],
    [
        "The 'reuse' parameter can be either None which means all joins are",
        "The 'reuse' parameter can be either None which means"
    ],
    [
        "reusable, or it can be a set containing the aliases that can be reused.",
        "reusable, or it can be a set containing the aliases that can be"
    ],
    [
        "A join is always created as LOUTER if the lhs alias is LOUTER to make",
        "A join is always created as LOUTER if the lhs alias is LOUTER"
    ],
    [
        "joins are created as LOUTER if the join is nullable.",
        "joins are created as LOUTER if the join is"
    ],
    [
        "if (reuse is None or a in reuse) and j == join",
        "if (reuse is None or a"
    ],
    [
        "if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:",
        "if self.alias_map[join.parent_alias].join_type == LOUTER"
    ],
    [
        "def join_parent_model(self, opts, model, alias, seen):",
        "def join_parent_model(self, opts, model,"
    ],
    [
        "Make sure the given 'model' is joined in the query. If 'model' isn't",
        "Make sure the given 'model' is joined in"
    ],
    [
        "a parent of 'opts' or if it is None this method is a no-op.",
        "a parent of 'opts' or if it is None"
    ],
    [
        "The 'alias' is the root alias for starting the join, 'seen' is a dict",
        "The 'alias' is the root alias for"
    ],
    [
        "of model -> alias of existing joins. It must also contain a mapping",
        "of model -> alias of existing joins."
    ],
    [
        "of None -> some alias. This will be returned in the no-op case.",
        "of None -> some alias. This will"
    ],
    [
        "\"Column aliases cannot contain whitespace characters, quotation marks, \"",
        "\"Column aliases cannot contain whitespace characters, quotation"
    ],
    [
        "\"\"\"Add a single annotation expression to the Query.\"\"\"",
        "\"\"\"Add a single annotation"
    ],
    [
        "isinstance(table, BaseTable) and table.table_name != table.table_alias",
        "isinstance(table, BaseTable) and table.table_name !="
    ],
    [
        "if any(col.possibly_multivalued for col in external_cols):",
        "if any(col.possibly_multivalued for"
    ],
    [
        "def resolve_lookup_value(self, value, can_reuse, allow_joins, summarize=False):",
        "def resolve_lookup_value(self, value,"
    ],
    [
        "Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').",
        "Solve the lookup type from the"
    ],
    [
        "_, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())",
        "_, field, _, lookup_parts = self.names_to_path(lookup_splitted,"
    ],
    [
        "'Invalid lookup \"%s\" for model %s\".'",
        "'Invalid lookup \"%s\""
    ],
    [
        "Check whether the object passed while querying is of the correct type.",
        "Check whether the object passed while querying is"
    ],
    [
        "If not, raise a ValueError specifying the wrong object.",
        "If not, raise a ValueError specifying the"
    ],
    [
        "'Cannot query \"%s\": Must be \"%s\" instance.'",
        "'Cannot query \"%s\": Must"
    ],
    [
        "\"\"\"Check the type of object passed to query relations.\"\"\"",
        "\"\"\"Check the type of object passed to query"
    ],
    [
        "'Cannot use QuerySet for \"%s\": Use a QuerySet for \"%s\".'",
        "'Cannot use QuerySet for \"%s\": Use a"
    ],
    [
        "\"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"",
        "\"\"\"Raise an error if expression cannot be"
    ],
    [
        "if hasattr(expression, \"resolve_expression\") and not getattr(",
        "if hasattr(expression, \"resolve_expression\")"
    ],
    [
        "expression.__class__.__name__ + \" is disallowed in the filter \"",
        "expression.__class__.__name__ + \" is disallowed"
    ],
    [
        "Try to extract transforms and lookup from given lhs.",
        "Try to extract transforms and lookup from given"
    ],
    [
        "The lhs value is something that works like SQLExpression.",
        "The lhs value is something"
    ],
    [
        "The rhs value is what the lookup is going to compare against.",
        "The rhs value is what the lookup is going"
    ],
    [
        "The lookups is a list of names to extract using get_lookup()",
        "The lookups is a list of names"
    ],
    [
        "*transforms, lookup_name = lookups or [\"exact\"]",
        "*transforms, lookup_name = lookups"
    ],
    [
        "if lookup.rhs is None and not lookup.can_use_none_as_rhs:",
        "if lookup.rhs is None and"
    ],
    [
        "if lookup_name not in (\"exact\", \"iexact\"):",
        "if lookup_name not"
    ],
    [
        "raise ValueError(\"Cannot use None as a query value\")",
        "raise ValueError(\"Cannot use None"
    ],
    [
        "Helper method for build_lookup(). Try to fetch and initialize",
        "Helper method for build_lookup(). Try to"
    ],
    [
        "a transform for name parameter from lhs.",
        "a transform for name"
    ],
    [
        "suggestion = \", perhaps you meant %s?\" % \" or \".join(suggested_lookups)",
        "suggestion = \", perhaps you meant %s?\" % \""
    ],
    [
        "\"Unsupported lookup '%s' for %s or join on the field not \"",
        "\"Unsupported lookup '%s' for %s or join on the field"
    ],
    [
        "Build a WhereNode for a single filter clause but don't add it",
        "Build a WhereNode for a single filter clause but don't add"
    ],
    [
        "to this Query. Query.add_q() will then add this filter to the where",
        "to this Query. Query.add_q() will then"
    ],
    [
        "The 'branch_negated' tells us if the current branch contains any",
        "The 'branch_negated' tells us if the current branch"
    ],
    [
        "negations. This will be used to determine if subqueries are needed.",
        "negations. This will be used to"
    ],
    [
        "The 'current_negated' is used to determine if the current filter is",
        "The 'current_negated' is used to determine if"
    ],
    [
        "negated or not and this will be used to determine if IS NULL filtering",
        "negated or not and this will be"
    ],
    [
        "The difference between current_negated and branch_negated is that",
        "The difference between current_negated and branch_negated"
    ],
    [
        "branch_negated is set on first negation, but current_negated is",
        "branch_negated is set on first"
    ],
    [
        "Note that add_filter will not do any negating itself, that is done",
        "Note that add_filter will not do any"
    ],
    [
        "upper in the code by add_q().",
        "upper in the code"
    ],
    [
        "The 'can_reuse' is a set of reusable joins for multijoins.",
        "The 'can_reuse' is a set of reusable"
    ],
    [
        "The method will create a filter clause that can be added to the current",
        "The method will create a filter clause that can be added"
    ],
    [
        "query. However, if the filter isn't added to the query then the caller",
        "query. However, if the filter isn't added"
    ],
    [
        "is responsible for unreffing the joins used.",
        "is responsible for unreffing"
    ],
    [
        "raise FieldError(\"Cannot parse keyword query as dict\")",
        "raise FieldError(\"Cannot parse keyword query as"
    ],
    [
        "raise TypeError(\"Cannot filter against a non-conditional expression.\")",
        "raise TypeError(\"Cannot filter against a non-conditional"
    ],
    [
        "raise FieldError(\"Cannot parse keyword query %r\" % arg)",
        "raise FieldError(\"Cannot parse keyword query"
    ],
    [
        "lookups, parts, reffed_expression = self.solve_lookup_type(arg, summarize)",
        "lookups, parts, reffed_expression = self.solve_lookup_type(arg,"
    ],
    [
        "raise FieldError(\"Joined field references are not permitted in this query\")",
        "raise FieldError(\"Joined field references are not permitted"
    ],
    [
        "value = self.resolve_lookup_value(value, can_reuse, allow_joins, summarize)",
        "value = self.resolve_lookup_value(value, can_reuse,"
    ],
    [
        "allow_many = not branch_negated or not split_subq",
        "allow_many = not branch_negated"
    ],
    [
        "col = ColPairs(alias, targets, join_info.targets, join_info.final_field)",
        "col = ColPairs(alias, targets, join_info.targets,"
    ],
    [
        "lookup_type == \"isnull\" and condition.rhs is True and not current_negated",
        "lookup_type == \"isnull\" and condition.rhs is True"
    ],
    [
        "and (lookup_type != \"isnull\" or condition.rhs is False)",
        "and (lookup_type != \"isnull\""
    ],
    [
        "return clause, used_joins if not require_outer else ()",
        "return clause, used_joins if not require_outer else"
    ],
    [
        "A preprocessor for the internal _add_q(). Responsible for doing final",
        "A preprocessor for the internal _add_q(). Responsible"
    ],
    [
        "a for a in self.alias_map if self.alias_map[a].join_type == INNER",
        "a for a in self.alias_map if self.alias_map[a].join_type =="
    ],
    [
        "\"\"\"Add a Q-object to the current filter.\"\"\"",
        "\"\"\"Add a Q-object to"
    ],
    [
        "\"FilteredRelation's relation_name cannot contain lookups \"",
        "\"FilteredRelation's relation_name cannot"
    ],
    [
        "\"relations outside the %r (got %r).\"",
        "\"relations outside the"
    ],
    [
        "\"FilteredRelation's condition doesn't support nested \"",
        "\"FilteredRelation's condition doesn't support"
    ],
    [
        "\"relations deeper than the relation_name (got %r for \"",
        "\"relations deeper than the relation_name"
    ],
    [
        "def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):",
        "def names_to_path(self, names, opts, allow_many=True,"
    ],
    [
        "Walk the list of names and turns them into PathInfo tuples. A single",
        "Walk the list of names and turns them into PathInfo tuples."
    ],
    [
        "'names' is the path of names to travel, 'opts' is the model Options we",
        "'names' is the path of names to travel, 'opts'"
    ],
    [
        "start the name resolving from, 'allow_many' is as for setup_joins().",
        "start the name resolving from, 'allow_many' is as"
    ],
    [
        "If fail_on_missing is set to True, then a name that can't be resolved",
        "If fail_on_missing is set to True, then a name that can't be"
    ],
    [
        "Return a list of PathInfo tuples. In addition return the final field",
        "Return a list of PathInfo tuples. In addition"
    ],
    [
        "(the last used join field) and target (which is a field guaranteed to",
        "(the last used join field) and target"
    ],
    [
        "contain the same value as the final field). Finally, return those names",
        "contain the same value as the final field). Finally, return"
    ],
    [
        "that weren't found (which are likely transforms and the final lookup).",
        "that weren't found (which are likely transforms"
    ],
    [
        "if name == \"pk\" and opts is not None:",
        "if name == \"pk\" and opts is"
    ],
    [
        "filtered_relation_path, field, _, _ = self.names_to_path(",
        "filtered_relation_path, field, _, _ ="
    ],
    [
        "\"Field %r does not generate an automatic reverse \"",
        "\"Field %r does not generate an automatic"
    ],
    [
        "\"relation and therefore cannot be used for reverse \"",
        "\"relation and therefore cannot be used for"
    ],
    [
        "\"querying. If it is a GenericForeignKey, consider \"",
        "\"querying. If it is a GenericForeignKey,"
    ],
    [
        "\"Cannot resolve keyword '%s' into field. \"",
        "\"Cannot resolve keyword '%s'"
    ],
    [
        "\"Choices are: %s\" % (name, \", \".join(available))",
        "\"Choices are: %s\" % (name, \","
    ],
    [
        "if opts is not None and model is not opts.model:",
        "if opts is not None and"
    ],
    [
        "\"Cannot resolve keyword %r into field. Join on '%s'\"",
        "\"Cannot resolve keyword %r into field. Join"
    ],
    [
        "Compute the necessary table joins for the passage through the fields",
        "Compute the necessary table joins for the passage through the"
    ],
    [
        "given in 'names'. 'opts' is the Options class for the current model",
        "given in 'names'. 'opts' is the Options class for"
    ],
    [
        "(which gives the table we are starting from), 'alias' is the alias for",
        "(which gives the table we are starting from), 'alias' is the alias"
    ],
    [
        "the table to start the joining from.",
        "the table to start the joining"
    ],
    [
        "The 'can_reuse' defines the reverse foreign key joins we can reuse. It",
        "The 'can_reuse' defines the reverse foreign key joins we can reuse."
    ],
    [
        "can be None in which case all joins are reusable or a set of aliases",
        "can be None in which case all joins"
    ],
    [
        "that can be reused. Note that non-reverse foreign keys are always",
        "that can be reused. Note that non-reverse foreign keys"
    ],
    [
        "If 'allow_many' is False, then any reverse foreign key seen will",
        "If 'allow_many' is False, then any"
    ],
    [
        "Return the final field involved in the joins, the target field (used",
        "Return the final field involved in"
    ],
    [
        "for any 'where' constraint), the final 'opts' value, the joins, the",
        "for any 'where' constraint), the final 'opts' value, the joins,"
    ],
    [
        "field path traveled to generate the joins, and a transform function",
        "field path traveled to generate the"
    ],
    [
        "that takes a field and alias and is equivalent to `field.get_col(alias)`",
        "that takes a field and alias and is equivalent"
    ],
    [
        "in the simple case but wraps field transforms if they were included in",
        "in the simple case but wraps field transforms if they were included"
    ],
    [
        "The target field is the field containing the concrete value. Final",
        "The target field is the field containing"
    ],
    [
        "field can be something different, for example foreign key pointing to",
        "field can be something different, for"
    ],
    [
        "that value. Final field is needed for example in some value",
        "that value. Final field is needed for example in some"
    ],
    [
        "conversions (convert 'obj' in fk__id=obj to pk val using the foreign",
        "conversions (convert 'obj' in fk__id=obj to pk val"
    ],
    [
        "path, final_field, targets, rest = self.names_to_path(",
        "path, final_field, targets, rest"
    ],
    [
        "def transform(field, alias, *, name, previous):",
        "def transform(field, alias,"
    ],
    [
        "if join.filtered_relation and can_reuse is not None:",
        "if join.filtered_relation and can_reuse is"
    ],
    [
        "return JoinInfo(final_field, targets, opts, joins, path, final_transformer)",
        "return JoinInfo(final_field, targets, opts, joins, path,"
    ],
    [
        "The 'target' parameter is the final field being joined to, 'joins'",
        "The 'target' parameter is the final"
    ],
    [
        "is the full list of join aliases. The 'path' contain the PathInfos",
        "is the full list of join aliases. The 'path' contain"
    ],
    [
        "Return the final target field and table alias and the new active",
        "Return the final target field and table alias"
    ],
    [
        "Always trim any direct join if the target column is already in the",
        "Always trim any direct join if the target column"
    ],
    [
        "previous table. Can't trim reverse joins as it's unknown if there's",
        "previous table. Can't trim reverse joins as it's unknown if"
    ],
    [
        "anything on the other side of the join.",
        "anything on the other side of the"
    ],
    [
        "join_targets = {t.column for t in info.join_field.foreign_related_fields}",
        "join_targets = {t.column for t"
    ],
    [
        "cur_targets = {t.column for t in targets}",
        "cur_targets = {t.column for t"
    ],
    [
        "targets = tuple(targets_dict[t.column] for t in targets)",
        "targets = tuple(targets_dict[t.column] for t"
    ],
    [
        "if not resolve_refs and isinstance(expr, Ref):",
        "if not resolve_refs and"
    ],
    [
        "yield from (expr.alias for expr in cls._gen_cols(exprs))",
        "yield from (expr.alias for expr in"
    ],
    [
        "def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False):",
        "def resolve_ref(self, name, allow_joins=True,"
    ],
    [
        "\"Joined field references are not permitted in this query\"",
        "\"Joined field references are not permitted in this"
    ],
    [
        "\"Cannot aggregate over the '%s' alias. Use annotate() \"",
        "\"Cannot aggregate over the '%s' alias. Use annotate()"
    ],
    [
        "\"Joined field references are not permitted in this query\"",
        "\"Joined field references are not permitted in this"
    ],
    [
        "\"Referencing multicolumn fields with F() objects isn't supported\"",
        "\"Referencing multicolumn fields with F() objects"
    ],
    [
        "When doing an exclude against any kind of N-to-many relation, we need",
        "When doing an exclude against any kind"
    ],
    [
        "to use a subquery. This method constructs the nested query, given the",
        "to use a subquery. This method constructs the"
    ],
    [
        "original exclude filter (filter_expr) and the portion up to the first",
        "original exclude filter (filter_expr) and the"
    ],
    [
        "For example, if the origin filter is ~Q(child__name='foo'), filter_expr",
        "For example, if the origin filter is ~Q(child__name='foo'),"
    ],
    [
        "is ('child__name', 'foo') and can_reuse is a set of joins usable for",
        "is ('child__name', 'foo') and can_reuse is a set of"
    ],
    [
        "We will turn this into equivalent of:",
        "We will turn this into"
    ],
    [
        "WHERE name = 'foo' AND child.parent_id = parent.id",
        "WHERE name = 'foo' AND child.parent_id"
    ],
    [
        "return any(isinstance(c, NothingNode) for c in self.where.children)",
        "return any(isinstance(c, NothingNode) for c in"
    ],
    [
        "Adjust the limits on the rows retrieved. Use low/high to set these,",
        "Adjust the limits on the rows"
    ],
    [
        "as it makes it more Pythonic to read and write. When the SQL query is",
        "as it makes it more Pythonic to read"
    ],
    [
        "created, convert them to the appropriate offset and limit values.",
        "created, convert them to the"
    ],
    [
        "Apply any limits passed in here to the existing constraints. Add low",
        "Apply any limits passed in here to the existing"
    ],
    [
        "to the current low value and clamp both to any existing high value.",
        "to the current low value and clamp both to any existing high"
    ],
    [
        "self.high_mark = min(self.high_mark, self.low_mark + high)",
        "self.high_mark = min(self.high_mark, self.low_mark"
    ],
    [
        "self.low_mark = min(self.high_mark, self.low_mark + low)",
        "self.low_mark = min(self.high_mark,"
    ],
    [
        "Return True if adding filters to this instance is still possible.",
        "Return True if adding filters to this instance is still"
    ],
    [
        "Typically, this means no limits or offsets have been put on the results.",
        "Typically, this means no limits or offsets"
    ],
    [
        "\"\"\"Remove all fields from SELECT clause.\"\"\"",
        "\"\"\"Remove all fields"
    ],
    [
        "Clear the list of fields to select (but not extra_select columns).",
        "Clear the list of fields to select"
    ],
    [
        "Some queryset types completely replace any existing list of select",
        "Some queryset types completely replace any existing list"
    ],
    [
        "Add and resolve the given fields to the query's \"distinct on\" clause.",
        "Add and resolve the given fields to the"
    ],
    [
        "Add the given (model) fields to the select set. Add the field names in",
        "Add the given (model) fields to the select set. Add"
    ],
    [
        "raise FieldError(\"Invalid field name: '%s'\" % name)",
        "raise FieldError(\"Invalid field name: '%s'\" %"
    ],
    [
        "\"Cannot resolve keyword %r into field. \"",
        "\"Cannot resolve keyword %r into"
    ],
    [
        "\"Choices are: %s\" % (name, \", \".join(names))",
        "\"Choices are: %s\" %"
    ],
    [
        "Add items from the 'ordering' sequence to the query's \"order by\"",
        "Add items from the 'ordering' sequence to the"
    ],
    [
        "clause. These items are either field names (not column names) --",
        "clause. These items are either field names (not"
    ],
    [
        "possibly with a direction prefix ('-' or '?') -- or OrderBy",
        "possibly with a direction prefix ('-' or '?') --"
    ],
    [
        "If 'ordering' is empty, clear all ordering from the query.",
        "If 'ordering' is empty, clear all ordering from the"
    ],
    [
        "if self.extra and item in self.extra:",
        "if self.extra and item in"
    ],
    [
        "\"Using an aggregate in order_by() without also including \"",
        "\"Using an aggregate in order_by()"
    ],
    [
        "\"it in annotate() is not allowed: %s\" % item",
        "\"it in annotate() is not allowed: %s\""
    ],
    [
        "raise FieldError(\"Invalid order_by arguments: %s\" % errors)",
        "raise FieldError(\"Invalid order_by arguments: %s\""
    ],
    [
        "Remove any ordering settings if the current query allows it without",
        "Remove any ordering settings if the"
    ],
    [
        "side effects, set 'force' to True to clear the ordering regardless.",
        "side effects, set 'force' to True to clear the"
    ],
    [
        "If 'clear_default' is True, there will be no ordering in the resulting",
        "If 'clear_default' is True, there will be"
    ],
    [
        "query (not even the model's default).",
        "query (not even the"
    ],
    [
        "Expand the GROUP BY clause required by the query.",
        "Expand the GROUP BY clause required"
    ],
    [
        "This will usually be the set of all non-aggregate fields in the",
        "This will usually be the set of all non-aggregate"
    ],
    [
        "return data. If the database backend supports grouping by the",
        "return data. If the database"
    ],
    [
        "primary key, and the query would be equivalent, the optimization",
        "primary key, and the query would be equivalent, the"
    ],
    [
        "for alias, expr in zip(self.values_select, self.select):",
        "for alias, expr"
    ],
    [
        "Set up the select_related data structure so that we only select",
        "Set up the select_related data structure so that"
    ],
    [
        "certain related models (as opposed to all models, when",
        "certain related models (as opposed to all"
    ],
    [
        "def add_extra(self, select, select_params, where, params, tables, order_by):",
        "def add_extra(self, select, select_params, where, params,"
    ],
    [
        "Add data to the various extra_* attributes for user-created additions",
        "Add data to the various extra_*"
    ],
    [
        "\"\"\"Remove any fields from the deferred loading set.\"\"\"",
        "\"\"\"Remove any fields from the deferred"
    ],
    [
        "Add the given list of model field names to the set of fields to",
        "Add the given list of model field names to the set of fields"
    ],
    [
        "exclude from loading from the database when automatic column selection",
        "exclude from loading from the database when"
    ],
    [
        "is done. Add the new field names to any existing field names that",
        "is done. Add the new field names to any"
    ],
    [
        "are deferred (or removed from any existing field names that are marked",
        "are deferred (or removed from any"
    ],
    [
        "as the only ones for immediate loading).",
        "as the only ones for immediate"
    ],
    [
        "Add the given list of model field names to the set of fields to",
        "Add the given list of model field names to the set of"
    ],
    [
        "retrieve when the SQL is executed (\"immediate loading\" fields). The",
        "retrieve when the SQL is executed (\"immediate loading\" fields)."
    ],
    [
        "field names replace any existing immediate loading field names. If",
        "field names replace any existing immediate loading field names."
    ],
    [
        "there are field names already specified for deferred loading, remove",
        "there are field names already specified for"
    ],
    [
        "those names from the new field_names before storing the new names",
        "those names from the new field_names before"
    ],
    [
        "for immediate loading. (That is, immediate loading overrides any",
        "for immediate loading. (That is, immediate"
    ],
    [
        "existing immediate values, but respects existing deferrals.)",
        "existing immediate values, but respects"
    ],
    [
        "\"\"\"Set the mask of annotations that will be returned by the SELECT.\"\"\"",
        "\"\"\"Set the mask of annotations that will be"
    ],
    [
        "Set the mask of extra select items that will be returned by SELECT.",
        "Set the mask of extra select items that will"
    ],
    [
        "Don't remove them from the Query since they might be used later.",
        "Don't remove them from the Query since they might be"
    ],
    [
        "if not self.extra and not self.annotations:",
        "if not self.extra"
    ],
    [
        "f\"Cannot select the '{f}' alias. Use annotate() to \"",
        "f\"Cannot select the '{f}' alias."
    ],
    [
        "field_names = [f.attname for f in self.model._meta.concrete_fields]",
        "field_names = [f.attname for"
    ],
    [
        "(f.attname for f in self.model._meta.concrete_fields), False",
        "(f.attname for f in self.model._meta.concrete_fields),"
    ],
    [
        "if isinstance(expr, Ref) and expr.refs not in selected:",
        "if isinstance(expr, Ref) and expr.refs not"
    ],
    [
        "self.selected = selected if fields else None",
        "self.selected = selected if fields else"
    ],
    [
        "Return the dictionary of aggregate columns that are not masked and",
        "Return the dictionary of aggregate columns that are not"
    ],
    [
        "should be used in the SELECT clause. Cache this result for performance.",
        "should be used in the SELECT clause."
    ],
    [
        "k: v for k, v in self.extra.items() if k in self.extra_select_mask",
        "k: v for k, v in self.extra.items()"
    ],
    [
        "Trim joins from the start of the join path. The candidates for trim",
        "Trim joins from the start of the"
    ],
    [
        "Also set the select column so the start matches the join.",
        "Also set the select column so the start matches"
    ],
    [
        "This method is meant to be used for generating the subquery joins &",
        "This method is meant to be used for generating the subquery"
    ],
    [
        "Return a lookup usable for doing outerq.filter(lookup=self) and a",
        "Return a lookup usable for doing"
    ],
    [
        "boolean indicating if the joins in the prefix contain a LEFT OUTER join.",
        "boolean indicating if the joins in the prefix contain a LEFT"
    ],
    [
        "t for t in self.alias_map if t in self._lookup_joins or t == self.base_table",
        "t for t in self.alias_map if t in"
    ],
    [
        "if first_join.join_type != LOUTER and not first_join.filtered_relation:",
        "if first_join.join_type != LOUTER and not"
    ],
    [
        "Check if the given field should be treated as nullable.",
        "Check if the given field should"
    ],
    [
        "Some backends treat '' as null and Django treats such fields as",
        "Some backends treat '' as null and"
    ],
    [
        "nullable for those backends. In such situations field.null can be",
        "nullable for those backends. In such"
    ],
    [
        "False even if we should treat the field as nullable.",
        "False even if we should"
    ],
    [
        "Return the field name and direction for an order specification. For",
        "Return the field name and direction for an"
    ],
    [
        "example, '-foo' is returned as ('foo', 'DESC').",
        "example, '-foo' is returned"
    ],
    [
        "The 'default' param is used to indicate which way no prefix (or a '+'",
        "The 'default' param is used to indicate"
    ],
    [
        "prefix) should sort. The '-' prefix always sorts the opposite way.",
        "prefix) should sort. The '-' prefix"
    ],
    [
        "A class to abstract away join promotion problems for complex filter",
        "A class to abstract away join promotion problems for"
    ],
    [
        "Add single vote per item to self.votes. Parameter can be any",
        "Add single vote per item to self.votes. Parameter"
    ],
    [
        "Change join types so that the generated query is as efficient as",
        "Change join types so that the"
    ],
    [
        "possible, but still correct. So, change as many joins as possible",
        "possible, but still correct. So, change as many"
    ],
    [
        "to INNER, but don't make OUTER joins INNER if that could remove",
        "to INNER, but don't make OUTER joins INNER"
    ],
    [
        "if self.effective_connector == OR and votes < self.num_children:",
        "if self.effective_connector == OR"
    ],
    [
        "if self.effective_connector == AND or (",
        "if self.effective_connector == AND"
    ],
    [
        "self.effective_connector == OR and votes == self.num_children",
        "self.effective_connector == OR and"
    ],
    [
        "Query subclasses which provide extra functionality beyond simple data retrieval.",
        "Query subclasses which provide extra functionality beyond"
    ],
    [
        "__all__ = [\"DeleteQuery\", \"UpdateQuery\", \"InsertQuery\", \"AggregateQuery\"]",
        "__all__ = [\"DeleteQuery\", \"UpdateQuery\","
    ],
    [
        "Set up and execute delete queries for all the objects in pk_list.",
        "Set up and execute delete queries for all the objects in"
    ],
    [
        "More than one physical query may be executed if there are a",
        "More than one physical query may"
    ],
    [
        "Run on initialization and at the end of chaining. Any attributes that",
        "Run on initialization and at the end"
    ],
    [
        "would normally be set in __init__() should go here instead.",
        "would normally be set in __init__()"
    ],
    [
        "\"pk__in\", pk_list[offset : offset + GET_ITERATOR_CHUNK_SIZE]",
        "\"pk__in\", pk_list[offset : offset"
    ],
    [
        "Convert a dictionary of field name to value mappings into an update",
        "Convert a dictionary of field name to value mappings into an"
    ],
    [
        "query. This is the entry point for the public update() method on",
        "query. This is the entry point for the public update() method"
    ],
    [
        "not (field.auto_created and not field.concrete) or not field.concrete",
        "not (field.auto_created and not"
    ],
    [
        "if field.name == \"pk\" and model._meta.is_composite_pk:",
        "if field.name == \"pk\" and"
    ],
    [
        "\"Composite primary key fields must be updated individually.\"",
        "\"Composite primary key fields"
    ],
    [
        "if not direct or (field.is_relation and field.many_to_many):",
        "if not direct or"
    ],
    [
        "\"Cannot update model field %r (only non-relations and \"",
        "\"Cannot update model field %r (only non-relations"
    ],
    [
        "Append a sequence of (field, model, value) triples to the internal list",
        "Append a sequence of (field, model, value) triples to the internal"
    ],
    [
        "that will be used to generate the UPDATE query. Might be more usefully",
        "that will be used to generate the UPDATE query. Might be"
    ],
    [
        "called add_update_targets() to hint at the extra information here.",
        "called add_update_targets() to hint at the"
    ],
    [
        "for field, model, val in values_seq:",
        "for field, model,"
    ],
    [
        "Add (name, value) to an update query for an ancestor model.",
        "Add (name, value) to an update"
    ],
    [
        "Update are coalesced so that only one update query per ancestor is run.",
        "Update are coalesced so that only one update query"
    ],
    [
        "Return a list of query objects: one for each update required to an",
        "Return a list of query objects: one for each update required to"
    ],
    [
        "ancestor model. Each query will have the same filtering conditions as",
        "ancestor model. Each query will have the same"
    ],
    [
        "the current query but will only update a single table.",
        "the current query but will only update a"
    ],
    [
        "self, *args, on_conflict=None, update_fields=None, unique_fields=None, **kwargs",
        "self, *args, on_conflict=None, update_fields=None, unique_fields=None,"
    ],
    [
        "Take another query as a parameter to the FROM clause and only select the",
        "Take another query as a parameter to the"
    ],
    [
        "Code to manage the creation and SQL rendering of 'where' constraints.",
        "Code to manage the creation and SQL"
    ],
    [
        "The class is tied to the Query class that created it (in order to create",
        "The class is tied to the Query class that created it (in"
    ],
    [
        "A child is usually an expression producing boolean values. Most likely the",
        "A child is usually an expression producing boolean"
    ],
    [
        "However, a child could also be any class with as_sql() and either",
        "However, a child could also be any class with as_sql()"
    ],
    [
        "relabeled_clone() method or relabel_aliases() and clone() methods and",
        "relabeled_clone() method or relabel_aliases() and clone() methods"
    ],
    [
        "Return three possibly None nodes: one for those parts of self that",
        "Return three possibly None nodes: one for those parts of"
    ],
    [
        "should be included in the WHERE clause, one for those parts of self",
        "should be included in the WHERE clause,"
    ],
    [
        "that must be included in the HAVING clause, and one for those parts",
        "that must be included in the HAVING clause, and one"
    ],
    [
        "if not self.contains_aggregate and not self.contains_over_clause:",
        "if not self.contains_aggregate and not"
    ],
    [
        "or (not in_negated and self.connector == OR)",
        "or (not in_negated and self.connector =="
    ],
    [
        "if not where_parts or (where_parts and not must_group_by):",
        "if not where_parts or (where_parts and not"
    ],
    [
        "\"Heterogeneous disjunctive predicates against window functions are \"",
        "\"Heterogeneous disjunctive predicates against window functions"
    ],
    [
        "\"not implemented when performing conditional aggregation.\"",
        "\"not implemented when"
    ],
    [
        "Return the SQL version of the where clause and the value to be",
        "Return the SQL version of the where clause and"
    ],
    [
        "substituted in. Return '', [] if this node matches everything,",
        "substituted in. Return '', [] if"
    ],
    [
        "None, [] if this node is empty, and raise EmptyResultSet if this",
        "None, [] if this node is empty, and raise EmptyResultSet"
    ],
    [
        "if self.connector == XOR and not connection.features.supports_logical_xor:",
        "if self.connector == XOR and"
    ],
    [
        "conn = \" %s \" % self.connector",
        "conn = \" %s"
    ],
    [
        "sql_string = \"NOT (%s)\" % sql_string",
        "sql_string = \"NOT"
    ],
    [
        "Relabel the alias values of any children. 'change_map' is a dictionary",
        "Relabel the alias values of any"
    ],
    [
        "mapping old (current) alias values to the new values.",
        "mapping old (current) alias values to"
    ],
    [
        "return any(cls._contains_aggregate(c) for c in obj.children)",
        "return any(cls._contains_aggregate(c) for"
    ],
    [
        "return any(cls._contains_over_clause(c) for c in obj.children)",
        "return any(cls._contains_over_clause(c) for c in"
    ],
    [
        "return any(child.is_summary for child in self.children)",
        "return any(child.is_summary for"
    ],
    [
        "def _resolve_node(cls, node, query, *args, **kwargs):",
        "def _resolve_node(cls, node, query,"
    ],
    [
        "node.lhs = cls._resolve_leaf(node.lhs, query, *args, **kwargs)",
        "node.lhs = cls._resolve_leaf(node.lhs, query, *args,"
    ],
    [
        "node.rhs = cls._resolve_leaf(node.rhs, query, *args, **kwargs)",
        "node.rhs = cls._resolve_leaf(node.rhs,"
    ],
    [
        "sqls = [\"(%s)\" % sql for sql in self.sqls]",
        "sqls = [\"(%s)\" % sql for sql"
    ],
    [
        "return \" AND \".join(sqls), list(self.params or ())",
        "return \" AND \".join(sqls), list(self.params"
    ],
    [
        "Constants specific to the SQL storage portion of the ORM.",
        "Constants specific to the SQL storage portion of the"
    ],
    [
        "from django.db.models.sql.where import AND, OR, XOR",
        "from django.db.models.sql.where import AND,"
    ],
    [
        "__all__ = [\"Query\", \"AND\", \"OR\", \"XOR\"]",
        "__all__ = [\"Query\", \"AND\", \"OR\","
    ],
    [
        "Useful auxiliary data structures for query construction. Not useful outside",
        "Useful auxiliary data structures for query construction. Not"
    ],
    [
        "Used by join construction code to indicate the point at which a",
        "Used by join construction code to"
    ],
    [
        "multi-valued join was attempted (if the caller wants to treat that",
        "multi-valued join was attempted (if the caller wants to treat"
    ],
    [
        "Used by sql.Query and sql.SQLCompiler to generate JOIN clauses into the",
        "Used by sql.Query and sql.SQLCompiler to generate JOIN"
    ],
    [
        "FROM entry. For example, the SQL generated could be",
        "FROM entry. For example, the SQL generated could"
    ],
    [
        "This class is primarily used in Query.alias_map. All entries in alias_map",
        "This class is primarily used in Query.alias_map."
    ],
    [
        "must be Join compatible by providing the following attributes and methods:",
        "must be Join compatible by providing"
    ],
    [
        "- table_alias (possible alias for the table, can be None)",
        "- table_alias (possible alias for the table, can"
    ],
    [
        "- join_type (can be None for those entries that aren't joined from",
        "- join_type (can be None for those entries"
    ],
    [
        "- parent_alias (which table is this join's parent, can be None similarly",
        "- parent_alias (which table is this join's parent, can"
    ],
    [
        "LEFT OUTER JOIN sometable ON sometable.somecol = othertable.othercol, params",
        "LEFT OUTER JOIN sometable ON sometable.somecol"
    ],
    [
        "\"Join generated an empty ON clause. %s did not yield either \"",
        "\"Join generated an empty ON clause. %s did not yield"
    ],
    [
        "\"joining columns or extra restrictions.\" % declared_field.__class__",
        "\"joining columns or extra"
    ],
    [
        "\"\" if self.table_alias == self.table_name else (\" %s\" % self.table_alias)",
        "\"\" if self.table_alias == self.table_name else (\""
    ],
    [
        "sql = \"%s %s%s ON (%s)\" % (",
        "sql = \"%s %s%s ON (%s)\" %"
    ],
    [
        "The BaseTable class is used for base table references in FROM clause. For",
        "The BaseTable class is used for base table"
    ],
    [
        "SELECT * FROM \"foo\" WHERE somecond",
        "SELECT * FROM \"foo\""
    ],
    [
        "could be generated by this class.",
        "could be generated by"
    ],
    [
        "\"\" if self.table_alias == self.table_name else (\" %s\" % self.table_alias)",
        "\"\" if self.table_alias == self.table_name else (\" %s\""
    ],
    [
        "from django.template import Context, Engine, TemplateDoesNotExist, loader",
        "from django.template import Context,"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "Return a path to a builtin template.",
        "Return a path to"
    ],
    [
        "Avoid calling this function at the module level or in a class-definition",
        "Avoid calling this function at the"
    ],
    [
        "because __file__ may not exist, e.g. in frozen environments.",
        "because __file__ may not exist, e.g. in"
    ],
    [
        "return Path(__file__).parent / \"templates\" / name",
        "return Path(__file__).parent / \"templates\""
    ],
    [
        "Default view used when request fails CSRF protection",
        "Default view used when request"
    ],
    [
        "\"main\": _(\"CSRF verification failed. Request aborted.\"),",
        "\"main\": _(\"CSRF verification"
    ],
    [
        "\"You are seeing this message because this HTTPS site requires a \"",
        "\"You are seeing this message because this HTTPS site requires"
    ],
    [
        "\"“Referer header” to be sent by your web browser, but none was \"",
        "\"“Referer header” to be sent by your web"
    ],
    [
        "\"sent. This header is required for security reasons, to ensure \"",
        "\"sent. This header is required for security reasons, to ensure"
    ],
    [
        "\"that your browser is not being hijacked by third parties.\"",
        "\"that your browser is not being hijacked"
    ],
    [
        "\"If you have configured your browser to disable “Referer” headers, \"",
        "\"If you have configured your browser to disable"
    ],
    [
        "\"please re-enable them, at least for this site, or for HTTPS \"",
        "\"please re-enable them, at least for this site, or for"
    ],
    [
        "'If you are using the <meta name=\"referrer\" '",
        "'If you are using the <meta"
    ],
    [
        "'content=\"no-referrer\"> tag or including the “Referrer-Policy: '",
        "'content=\"no-referrer\"> tag or including the “Referrer-Policy:"
    ],
    [
        "\"no-referrer” header, please remove them. The CSRF protection \"",
        "\"no-referrer” header, please remove them. The CSRF protection"
    ],
    [
        "\"requires the “Referer” header to do strict referer checking. If \"",
        "\"requires the “Referer” header to do strict referer checking. If"
    ],
    [
        "\"you’re concerned about privacy, use alternatives like \"",
        "\"you’re concerned about privacy, use alternatives"
    ],
    [
        "'<a rel=\"noreferrer\" …> for links to third-party sites.'",
        "'<a rel=\"noreferrer\" …> for links to third-party"
    ],
    [
        "\"You are seeing this message because this site requires a CSRF \"",
        "\"You are seeing this message because this site requires"
    ],
    [
        "\"cookie when submitting forms. This cookie is required for \"",
        "\"cookie when submitting forms. This cookie is required for"
    ],
    [
        "\"security reasons, to ensure that your browser is not being \"",
        "\"security reasons, to ensure that your browser is not"
    ],
    [
        "\"If you have configured your browser to disable cookies, please \"",
        "\"If you have configured your browser to disable"
    ],
    [
        "\"re-enable them, at least for this site, or for “same-origin” \"",
        "\"re-enable them, at least for this"
    ],
    [
        "\"more\": _(\"More information is available with DEBUG=True.\"),",
        "\"more\": _(\"More information is"
    ],
    [
        "from django.template import Context, Engine, TemplateDoesNotExist",
        "from django.template import Context,"
    ],
    [
        "Return a path to a builtin template.",
        "Return a path to a builtin"
    ],
    [
        "Avoid calling this function at the module level or in a class-definition",
        "Avoid calling this function at the module level or in a"
    ],
    [
        "because __file__ may not exist, e.g. in frozen environments.",
        "because __file__ may not exist, e.g. in frozen"
    ],
    [
        "return Path(__file__).parent / \"templates\" / name",
        "return Path(__file__).parent /"
    ],
    [
        "Object to wrap callable appearing in settings.",
        "Object to wrap callable appearing in"
    ],
    [
        "* Not to break the debug page if the callable forbidding to set attributes",
        "* Not to break the debug page"
    ],
    [
        "Create a technical server error response. The last three arguments are",
        "Create a technical server error response. The last three arguments"
    ],
    [
        "the values returned from sys.exc_info() and friends.",
        "the values returned from sys.exc_info() and"
    ],
    [
        "reporter = get_exception_reporter_class(request)(request, exc_type, exc_value, tb)",
        "reporter = get_exception_reporter_class(request)(request, exc_type,"
    ],
    [
        "return \"\" if resolver_match is None else resolver_match._func_path",
        "return \"\" if resolver_match"
    ],
    [
        "Use annotations made by the sensitive_post_parameters and",
        "Use annotations made by"
    ],
    [
        "sensitive_variables decorators to filter out sensitive information.",
        "sensitive_variables decorators to filter out sensitive"
    ],
    [
        "Cleanse an individual setting key/value of sensitive content. If the",
        "Cleanse an individual setting key/value of sensitive content. If"
    ],
    [
        "value is a dictionary, recursively cleanse the keys in that dictionary.",
        "value is a dictionary, recursively cleanse the keys in that"
    ],
    [
        "cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}",
        "cleansed = {k: self.cleanse_setting(k, v) for k, v"
    ],
    [
        "cleansed = [self.cleanse_setting(\"\", v) for v in value]",
        "cleansed = [self.cleanse_setting(\"\", v)"
    ],
    [
        "cleansed = tuple([self.cleanse_setting(\"\", v) for v in value])",
        "cleansed = tuple([self.cleanse_setting(\"\", v) for"
    ],
    [
        "Return a dictionary of the settings module with values of sensitive",
        "Return a dictionary of the settings"
    ],
    [
        "Return a dictionary of request.META with sensitive values redacted.",
        "Return a dictionary of request.META with sensitive"
    ],
    [
        "return {k: self.cleanse_setting(k, v) for k, v in request.META.items()}",
        "return {k: self.cleanse_setting(k, v) for k, v in"
    ],
    [
        "Return a dictionary of request.COOKIES with sensitive values redacted.",
        "Return a dictionary of request.COOKIES with sensitive values"
    ],
    [
        "return {k: self.cleanse_setting(k, v) for k, v in request.COOKIES.items()}",
        "return {k: self.cleanse_setting(k, v) for"
    ],
    [
        "This filter is to add safety in production environments (i.e. DEBUG",
        "This filter is to add safety in production environments (i.e."
    ],
    [
        "is False). If DEBUG is True then your site is not safe anyway.",
        "is False). If DEBUG is True then your"
    ],
    [
        "This hook is provided as a convenience to easily activate or",
        "This hook is provided as a convenience to"
    ],
    [
        "deactivate the filter on a per request basis.",
        "deactivate the filter on a per"
    ],
    [
        "Replace the keys in a MultiValueDict marked as sensitive with stars.",
        "Replace the keys in a MultiValueDict"
    ],
    [
        "This mitigates leaking sensitive POST parameters if something like",
        "This mitigates leaking sensitive POST"
    ],
    [
        "Replace the values of POST parameters marked as sensitive with",
        "Replace the values of POST parameters"
    ],
    [
        "return \"{!r} while evaluating {!r}\".format(e, value)",
        "return \"{!r} while evaluating {!r}\".format(e,"
    ],
    [
        "Replace the values of variables marked as sensitive with",
        "Replace the values of variables marked as sensitive"
    ],
    [
        "\"\"\"Organize and coordinate reporting on exceptions.\"\"\"",
        "\"\"\"Organize and coordinate reporting"
    ],
    [
        "def __init__(self, request, exc_type, exc_value, tb, is_email=False):",
        "def __init__(self, request, exc_type, exc_value, tb,"
    ],
    [
        "Return an absolute URI from variables available in this request. Skip",
        "Return an absolute URI from variables available"
    ],
    [
        "allowed hosts protection, so may return insecure URI.",
        "allowed hosts protection, so"
    ],
    [
        "\"\"\"Return a dictionary containing traceback information.\"\"\"",
        "\"\"\"Return a dictionary containing traceback"
    ],
    [
        "if start is not None and end is not None:",
        "if start is not None and end is"
    ],
    [
        "user_str = \"[unable to retrieve the current user]\"",
        "user_str = \"[unable to retrieve"
    ],
    [
        "if exc_notes := getattr(self.exc_value, \"__notes__\", None):",
        "if exc_notes := getattr(self.exc_value, \"__notes__\","
    ],
    [
        "self, filename, lineno, context_lines, loader=None, module_name=None",
        "self, filename, lineno, context_lines,"
    ],
    [
        "Return context_lines before and after lineno from file.",
        "Return context_lines before and"
    ],
    [
        "source = [str(sline, encoding, \"replace\") for sline in source]",
        "source = [str(sline, encoding, \"replace\") for sline in"
    ],
    [
        "return explicit or (None if suppress_context else implicit)",
        "return explicit or (None"
    ],
    [
        "\"Cycle in the exception chain detected: exception '%s' \"",
        "\"Cycle in the exception chain detected: exception '%s'"
    ],
    [
        "tb = self.tb if not exceptions else exc_value.__traceback__",
        "tb = self.tb if"
    ],
    [
        "context_line = \"<source code not available>\"",
        "context_line = \"<source code not"
    ],
    [
        "_, _, start_column, end_column = next(",
        "_, _, start_column, end_column"
    ],
    [
        "underline = \"^\" * (end_column - start_column)",
        "underline = \"^\" *"
    ],
    [
        "tb_area_spaces = \" \" * (",
        "tb_area_spaces = \""
    ],
    [
        "\"type\": \"django\" if module_name.startswith(\"django.\") else \"user\",",
        "\"type\": \"django\" if"
    ],
    [
        "tried = request.resolver_match.tried if request.resolver_match else None",
        "tried = request.resolver_match.tried if request.resolver_match else"
    ],
    [
        "Views and functions for serving static files. These are only to be used",
        "Views and functions for serving static files. These are"
    ],
    [
        "during development, and SHOULD NOT be used in a production setting.",
        "during development, and SHOULD NOT be used in a production"
    ],
    [
        "from django.template import Context, Engine, TemplateDoesNotExist, loader",
        "from django.template import Context, Engine, TemplateDoesNotExist,"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "Return a path to a builtin template.",
        "Return a path to a"
    ],
    [
        "Avoid calling this function at the module level or in a class-definition",
        "Avoid calling this function at the module level"
    ],
    [
        "because __file__ may not exist, e.g. in frozen environments.",
        "because __file__ may not exist, e.g. in"
    ],
    [
        "return Path(__file__).parent / \"templates\" / name",
        "return Path(__file__).parent /"
    ],
    [
        "Serve static files below a given point in the directory structure.",
        "Serve static files below a given point"
    ],
    [
        "To use, put a URL pattern such as::",
        "To use, put a URL pattern"
    ],
    [
        "in your URLconf. You must provide the ``document_root`` param. You may",
        "in your URLconf. You must provide the ``document_root``"
    ],
    [
        "also set ``show_indexes`` to ``True`` if you'd like to serve a basic index",
        "also set ``show_indexes`` to ``True`` if you'd like to serve a"
    ],
    [
        "of the directory.  This index view will use the template hardcoded below,",
        "of the directory. This index view will use the template"
    ],
    [
        "but if you'd like to override it, you can create a template called",
        "but if you'd like to override it, you can create a template"
    ],
    [
        "Was something modified since the user last downloaded it?",
        "Was something modified since the user"
    ],
    [
        "This is the value of the If-Modified-Since header.  If this is None,",
        "This is the value of the If-Modified-Since header."
    ],
    [
        "This is the modification time of the item we're talking about.",
        "This is the modification time of"
    ],
    [
        "from django.template import Context, Engine, TemplateDoesNotExist, loader",
        "from django.template import Context,"
    ],
    [
        "The path of the requested URL (e.g., '/app/pages/bad_page/'). It's",
        "The path of the requested URL (e.g.,"
    ],
    [
        "quoted to prevent a content injection attack.",
        "quoted to prevent a content"
    ],
    [
        "supplied), or the exception class name",
        "supplied), or the exception"
    ],
    [
        "\"details\": \"The requested resource was not found on this server.\",",
        "\"details\": \"The requested resource was"
    ],
    [
        "from django.http import HttpResponse, HttpResponseRedirect, JsonResponse",
        "from django.http import HttpResponse,"
    ],
    [
        "Return a path to a builtin template.",
        "Return a path to a"
    ],
    [
        "Avoid calling this function at the module level or in a class-definition",
        "Avoid calling this function at the module level or in a"
    ],
    [
        "because __file__ may not exist, e.g. in frozen environments.",
        "because __file__ may not exist, e.g."
    ],
    [
        "return Path(__file__).parent / \"templates\" / name",
        "return Path(__file__).parent /"
    ],
    [
        "Redirect to a given URL while setting the chosen language in the session",
        "Redirect to a given URL while setting the"
    ],
    [
        "(if enabled) and in a cookie. The URL and the language code need to be",
        "(if enabled) and in a cookie. The URL and the language code"
    ],
    [
        "Since this view changes how the user will see the rest of the site, it must",
        "Since this view changes how the user will see the rest of the site, it"
    ],
    [
        "only be accessed as a POST request. If called as a GET request, it will",
        "only be accessed as a POST request. If called as a GET"
    ],
    [
        "redirect to the page in the request (the 'next' parameter) without changing",
        "redirect to the page in the request (the"
    ],
    [
        "return {attr: get_format(attr) for attr in FORMAT_SETTINGS}",
        "return {attr: get_format(attr) for attr"
    ],
    [
        "Return the selected language catalog as a JavaScript library.",
        "Return the selected language catalog as a JavaScript"
    ],
    [
        "Receive the list of packages to check for translations in the `packages`",
        "Receive the list of packages to check"
    ],
    [
        "kwarg either from the extra dictionary passed to the path() function or as",
        "kwarg either from the extra dictionary passed to the path() function"
    ],
    [
        "a plus-sign delimited string from the request. Default is 'django.conf'.",
        "a plus-sign delimited string from the request."
    ],
    [
        "You can override the gettext domain for this view, but usually you don't",
        "You can override the gettext domain for this"
    ],
    [
        "want to do that as JavaScript messages go to the djangojs domain. This",
        "want to do that as JavaScript messages go"
    ],
    [
        "might be needed if you deliver your JavaScript source from Django templates.",
        "might be needed if you deliver your JavaScript"
    ],
    [
        "packages = packages.split(\"+\") if packages else self.packages",
        "packages = packages.split(\"+\") if packages"
    ],
    [
        "paths = self.get_paths(packages) if packages else None",
        "paths = self.get_paths(packages) if packages else"
    ],
    [
        "app_config.name: app_config for app_config in apps.get_app_configs()",
        "app_config.name: app_config for app_config"
    ],
    [
        "allowable_packages[p] for p in packages if p in allowable_packages",
        "allowable_packages[p] for p in packages if"
    ],
    [
        "excluded = [p for p in packages if p not in allowable_packages]",
        "excluded = [p for p in packages if p"
    ],
    [
        "\"Invalid package(s) provided to JavaScriptCatalog: %s\"",
        "\"Invalid package(s) provided to"
    ],
    [
        "return [os.path.join(app.path, \"locale\") for app in app_configs]",
        "return [os.path.join(app.path, \"locale\") for"
    ],
    [
        "match = re.search(r\"nplurals=\\s*(\\d+)\", self._plural_string or \"\")",
        "match = re.search(r\"nplurals=\\s*(\\d+)\","
    ],
    [
        "Return the plural string (including nplurals) for this catalog language,",
        "Return the plural string (including"
    ],
    [
        "or None if no plural string is available.",
        "or None if no plural string"
    ],
    [
        "if key == \"\" or key in seen_keys:",
        "if key == \"\""
    ],
    [
        "catalog[k] = [v.get(i, \"\") for i in range(num_plurals)]",
        "catalog[k] = [v.get(i, \"\") for i"
    ],
    [
        "Return the selected language catalog as a JSON object.",
        "Return the selected language catalog"
    ],
    [
        "Receive the same parameters as JavaScriptCatalog and return a response",
        "Receive the same parameters as JavaScriptCatalog"
    ],
    [
        "with a JSON object of the following format:",
        "with a JSON object of"
    ],
    [
        "Modify a view function so its response has the X-Frame-Options HTTP",
        "Modify a view function so its"
    ],
    [
        "header set to 'DENY' as long as the response doesn't already have that",
        "header set to 'DENY' as long as the response doesn't"
    ],
    [
        "Modify a view function so its response has the X-Frame-Options HTTP",
        "Modify a view function so its"
    ],
    [
        "header set to 'SAMEORIGIN' as long as the response doesn't already have",
        "header set to 'SAMEORIGIN' as long as the response doesn't already"
    ],
    [
        "Modify a view function by setting a response variable that instructs",
        "Modify a view function by setting a"
    ],
    [
        "XFrameOptionsMiddleware to NOT set the X-Frame-Options HTTP header. Usage:",
        "XFrameOptionsMiddleware to NOT set the X-Frame-Options HTTP header."
    ],
    [
        "gzip_page.__doc__ = \"Decorator for views that gzips pages if the client supports it.\"",
        "gzip_page.__doc__ = \"Decorator for views that gzips pages if the client supports"
    ],
    [
        "This decorator adds CSRF protection in exactly the same way as",
        "This decorator adds CSRF protection in exactly the same"
    ],
    [
        "CsrfViewMiddleware, but it can be used on a per view basis.  Using both, or",
        "CsrfViewMiddleware, but it can be used on"
    ],
    [
        "using the decorator multiple times, is harmless and efficient.",
        "using the decorator multiple times, is harmless"
    ],
    [
        "Use this decorator on views that need a correct csrf_token available to",
        "Use this decorator on views that need a correct csrf_token available"
    ],
    [
        "RequestContext, but without the CSRF protection that csrf_protect",
        "RequestContext, but without the CSRF protection that"
    ],
    [
        "def process_view(self, request, callback, callback_args, callback_kwargs):",
        "def process_view(self, request, callback, callback_args,"
    ],
    [
        "retval = super().process_view(request, callback, callback_args, callback_kwargs)",
        "retval = super().process_view(request,"
    ],
    [
        "Use this decorator to ensure that a view sets a CSRF cookie, whether or not it",
        "Use this decorator to ensure that a view sets a CSRF cookie, whether or"
    ],
    [
        "uses the csrf_token template tag, or the CsrfViewMiddleware is used.",
        "uses the csrf_token template tag, or the CsrfViewMiddleware is"
    ],
    [
        "\"\"\"Mark a view function as being exempt from the CSRF view protection.\"\"\"",
        "\"\"\"Mark a view function as being exempt from"
    ],
    [
        "A view decorator that adds the specified headers to the Vary header of the",
        "A view decorator that adds the specified headers to the"
    ],
    [
        "Note that the header names are not case-sensitive.",
        "Note that the header names are"
    ],
    [
        "response = await func(request, *args, **kwargs)",
        "response = await func(request,"
    ],
    [
        "'A view decorator that adds \"Cookie\" to the Vary header of a response. This '",
        "'A view decorator that adds \"Cookie\" to the Vary header"
    ],
    [
        "\"indicates that a page's contents depends on cookies.\"",
        "\"indicates that a page's contents depends on"
    ],
    [
        "Decorator for views that tries getting the page from the cache and",
        "Decorator for views that tries getting the page from"
    ],
    [
        "populates the cache if the page isn't in the cache yet.",
        "populates the cache if the page isn't in the cache"
    ],
    [
        "The cache is keyed by the URL and some data from the headers.",
        "The cache is keyed by the URL"
    ],
    [
        "Additionally there is the key prefix that is used to distinguish different",
        "Additionally there is the key prefix that is used to distinguish"
    ],
    [
        "cache areas in a multi-site setup. You could use the",
        "cache areas in a multi-site setup."
    ],
    [
        "get_current_site().domain, for example, as that is unique across a Django",
        "get_current_site().domain, for example, as that"
    ],
    [
        "Additionally, all headers from the response's Vary header will be taken",
        "Additionally, all headers from the response's Vary header"
    ],
    [
        "into account on caching -- just like the middleware does.",
        "into account on caching -- just like the middleware"
    ],
    [
        "f\"{decorator_name} didn't receive an HttpRequest. If you are \"",
        "f\"{decorator_name} didn't receive an HttpRequest. If you"
    ],
    [
        "\"decorating a classmethod, be sure to use @method_decorator.\"",
        "\"decorating a classmethod, be"
    ],
    [
        "response = await viewfunc(request, *args, **kw)",
        "response = await viewfunc(request,"
    ],
    [
        "Decorator that adds headers to a response so that it will never be cached.",
        "Decorator that adds headers to a response so"
    ],
    [
        "response = await view_func(request, *args, **kwargs)",
        "response = await"
    ],
    [
        "Mark a view function as excluded from CommonMiddleware's APPEND_SLASH",
        "Mark a view function as excluded"
    ],
    [
        "Indicate which variables used in the decorated function are sensitive so",
        "Indicate which variables used in the decorated function are sensitive"
    ],
    [
        "that those variables can later be treated in a special way, for example",
        "that those variables can later be treated in a"
    ],
    [
        "by hiding them when logging unhandled exceptions.",
        "by hiding them when logging unhandled"
    ],
    [
        "* without any specified variable names, in which case consider all",
        "* without any specified variable names, in which case"
    ],
    [
        "\"sensitive_variables() must be called to use it as a decorator, \"",
        "\"sensitive_variables() must be called to use it as a"
    ],
    [
        "while getattr(wrapped_func, \"__wrapped__\", None) is not None:",
        "while getattr(wrapped_func, \"__wrapped__\", None)"
    ],
    [
        "f\"{func.__name__} cannot safely be wrapped by \"",
        "f\"{func.__name__} cannot safely be wrapped"
    ],
    [
        "\"@sensitive_variables, make it either non-async or defined in a \"",
        "\"@sensitive_variables, make it either non-async or defined in"
    ],
    [
        "\"Python file (not a builtin or from a native extension).\"",
        "\"Python file (not a builtin or from a"
    ],
    [
        "Indicate which POST parameters used in the decorated view are sensitive,",
        "Indicate which POST parameters used in the decorated view"
    ],
    [
        "so that those parameters can later be treated in a special way, for example",
        "so that those parameters can later be treated in a"
    ],
    [
        "by hiding them when logging unhandled exceptions.",
        "by hiding them when logging"
    ],
    [
        "* without any specified parameters, in which case consider all",
        "* without any specified parameters, in"
    ],
    [
        "\"sensitive_post_parameters() must be called to use it as a \"",
        "\"sensitive_post_parameters() must be called to use"
    ],
    [
        "\"decorator, e.g., use @sensitive_post_parameters(), not \"",
        "\"decorator, e.g., use @sensitive_post_parameters(),"
    ],
    [
        "\"sensitive_post_parameters didn't receive an HttpRequest \"",
        "\"sensitive_post_parameters didn't receive an HttpRequest"
    ],
    [
        "\"object. If you are decorating a classmethod, make sure to use \"",
        "\"object. If you are decorating a classmethod, make sure to use"
    ],
    [
        "\"sensitive_post_parameters didn't receive an HttpRequest \"",
        "\"sensitive_post_parameters didn't receive"
    ],
    [
        "\"object. If you are decorating a classmethod, make sure to use \"",
        "\"object. If you are decorating a"
    ],
    [
        "Decorators for views based on HTTP headers.",
        "Decorators for views based on HTTP"
    ],
    [
        "Decorator to make a view only accept particular request methods.  Usage::",
        "Decorator to make a view only accept particular request methods."
    ],
    [
        "Note that request methods should be in uppercase.",
        "Note that request methods"
    ],
    [
        "require_GET.__doc__ = \"Decorator to require that a view only accepts the GET method.\"",
        "require_GET.__doc__ = \"Decorator to require that a view only accepts the GET"
    ],
    [
        "require_POST.__doc__ = \"Decorator to require that a view only accepts the POST method.\"",
        "require_POST.__doc__ = \"Decorator to require that a view only accepts the"
    ],
    [
        "\"Decorator to require that a view only accepts safe methods: GET and HEAD.\"",
        "\"Decorator to require that a view only accepts safe"
    ],
    [
        "Decorator to support conditional retrieval (or change) for a view",
        "Decorator to support conditional retrieval (or change) for a"
    ],
    [
        "The parameters are callables to compute the ETag and last modified time for",
        "The parameters are callables to compute the ETag and last modified"
    ],
    [
        "the requested resource, respectively. The callables are passed the same",
        "the requested resource, respectively. The callables are passed the"
    ],
    [
        "parameters as the view itself. The ETag function should return a string (or",
        "parameters as the view itself. The ETag function should return a string"
    ],
    [
        "None if the resource doesn't exist), while the last_modified function",
        "None if the resource doesn't exist), while the"
    ],
    [
        "should return a datetime object (or None if the resource doesn't exist).",
        "should return a datetime object (or None if the resource doesn't"
    ],
    [
        "The ETag function should return a complete ETag, including quotes (e.g.",
        "The ETag function should return a"
    ],
    [
        "'\"etag\"'), since that's the only way to distinguish between weak and strong",
        "'\"etag\"'), since that's the only way to distinguish between weak"
    ],
    [
        "ETags. If an unquoted ETag is returned (e.g. 'etag'), it will be converted",
        "ETags. If an unquoted ETag is returned (e.g. 'etag'),"
    ],
    [
        "to a strong ETag by adding quotes.",
        "to a strong ETag by adding"
    ],
    [
        "This decorator will either pass control to the wrapped view function or",
        "This decorator will either pass control to the"
    ],
    [
        "failed), depending upon the request method. In either case, the decorator",
        "failed), depending upon the request method. In either case,"
    ],
    [
        "will add the generated ETag and Last-Modified headers to the response if",
        "will add the generated ETag and Last-Modified headers to the response"
    ],
    [
        "the headers aren't already set and if the request's method is safe.",
        "the headers aren't already set and if the request's"
    ],
    [
        "if dt := last_modified_func(request, *args, **kwargs):",
        "if dt :="
    ],
    [
        "res_etag = etag_func(request, *args, **kwargs) if etag_func else None",
        "res_etag = etag_func(request, *args, **kwargs)"
    ],
    [
        "res_etag = quote_etag(res_etag) if res_etag is not None else None",
        "res_etag = quote_etag(res_etag) if res_etag is not"
    ],
    [
        "response = await func(request, *args, **kwargs)",
        "response = await"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "from django.views.generic.base import ContextMixin, TemplateResponseMixin, View",
        "from django.views.generic.base import"
    ],
    [
        "\"\"\"A mixin for views manipulating multiple objects.\"\"\"",
        "\"\"\"A mixin for views manipulating multiple"
    ],
    [
        "Return the list of items for this view.",
        "Return the list of items for this"
    ],
    [
        "The return value must be an iterable and may be an instance of",
        "The return value must be an iterable and"
    ],
    [
        "`QuerySet` in which case `QuerySet` specific behavior will be enabled.",
        "`QuerySet` in which case `QuerySet` specific behavior"
    ],
    [
        "\"%(cls)s is missing a QuerySet. Define \"",
        "\"%(cls)s is missing a QuerySet."
    ],
    [
        "\"\"\"Return the field or fields to use for ordering the queryset.\"\"\"",
        "\"\"\"Return the field or fields to use for ordering"
    ],
    [
        "_(\"Page is not “last”, nor can it be converted to an int.\")",
        "_(\"Page is not “last”, nor can it be"
    ],
    [
        "Get the number of items to paginate by, or ``None`` for no pagination.",
        "Get the number of items to paginate by, or"
    ],
    [
        "\"\"\"Return an instance of the paginator for this view.\"\"\"",
        "\"\"\"Return an instance of the paginator"
    ],
    [
        "Return the maximum number of orphans extend the last page by when",
        "Return the maximum number of orphans extend"
    ],
    [
        "Return ``True`` if the view should display empty lists and ``False``",
        "Return ``True`` if the view should display"
    ],
    [
        "\"\"\"Get the name of the item to be used in the context.\"\"\"",
        "\"\"\"Get the name of the item to be used"
    ],
    [
        "\"\"\"Get the context for this view.\"\"\"",
        "\"\"\"Get the context for"
    ],
    [
        "queryset = object_list if object_list is not None else self.object_list",
        "queryset = object_list if object_list"
    ],
    [
        "paginator, page, queryset, is_paginated = self.paginate_queryset(",
        "paginator, page, queryset, is_paginated ="
    ],
    [
        "Base view for displaying a list of objects.",
        "Base view for displaying"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to"
    ],
    [
        "if self.get_paginate_by(self.object_list) is not None and hasattr(",
        "if self.get_paginate_by(self.object_list) is not None and"
    ],
    [
        "_(\"Empty list and “%(class_name)s.allow_empty” is False.\")",
        "_(\"Empty list and “%(class_name)s.allow_empty” is"
    ],
    [
        "\"\"\"Mixin for responding with a template and list of objects.\"\"\"",
        "\"\"\"Mixin for responding with a"
    ],
    [
        "Return a list of template names to be used for the request. Must return",
        "Return a list of template names to be used"
    ],
    [
        "a list. May not be called if render_to_response is overridden.",
        "a list. May not be called"
    ],
    [
        "\"%(cls)s requires either a 'template_name' attribute \"",
        "\"%(cls)s requires either a"
    ],
    [
        "\"or a get_queryset() method that returns a QuerySet.\"",
        "\"or a get_queryset() method"
    ],
    [
        "Render some list of objects, set by `self.model` or `self.queryset`.",
        "Render some list of objects, set by `self.model` or"
    ],
    [
        "`self.queryset` can actually be any iterable of items, not just a queryset.",
        "`self.queryset` can actually be any iterable of items, not"
    ],
    [
        "from django.views.generic.base import RedirectView, TemplateView, View",
        "from django.views.generic.base import RedirectView,"
    ],
    [
        "from django.views.generic.edit import CreateView, DeleteView, FormView, UpdateView",
        "from django.views.generic.edit import CreateView, DeleteView,"
    ],
    [
        "\"\"\"A problem in a generic view.\"\"\"",
        "\"\"\"A problem in a generic"
    ],
    [
        "from django.forms import models as model_forms",
        "from django.forms import models as"
    ],
    [
        "from django.views.generic.base import ContextMixin, TemplateResponseMixin, View",
        "from django.views.generic.base import ContextMixin, TemplateResponseMixin,"
    ],
    [
        "\"\"\"Provide a way to show and handle a form in a request.\"\"\"",
        "\"\"\"Provide a way to show and"
    ],
    [
        "\"\"\"Return the initial data to use for forms on this view.\"\"\"",
        "\"\"\"Return the initial data to use for"
    ],
    [
        "\"\"\"Return the prefix to use for forms.\"\"\"",
        "\"\"\"Return the prefix to"
    ],
    [
        "\"\"\"Return the form class to use.\"\"\"",
        "\"\"\"Return the form class"
    ],
    [
        "\"\"\"Return an instance of the form to be used in this view.\"\"\"",
        "\"\"\"Return an instance of the form to be used in this"
    ],
    [
        "\"\"\"Return the keyword arguments for instantiating the form.\"\"\"",
        "\"\"\"Return the keyword arguments for instantiating"
    ],
    [
        "\"\"\"Return the URL to redirect to after processing a valid form.\"\"\"",
        "\"\"\"Return the URL to redirect to after processing"
    ],
    [
        "raise ImproperlyConfigured(\"No URL to redirect to. Provide a success_url.\")",
        "raise ImproperlyConfigured(\"No URL to redirect to."
    ],
    [
        "\"\"\"If the form is valid, redirect to the supplied URL.\"\"\"",
        "\"\"\"If the form is valid,"
    ],
    [
        "\"\"\"If the form is invalid, render the invalid form.\"\"\"",
        "\"\"\"If the form is invalid, render the invalid"
    ],
    [
        "\"\"\"Insert the form into the context dict.\"\"\"",
        "\"\"\"Insert the form into the"
    ],
    [
        "\"\"\"Provide a way to show and handle a ModelForm in a request.\"\"\"",
        "\"\"\"Provide a way to show and"
    ],
    [
        "\"\"\"Return the form class to use in this view.\"\"\"",
        "\"\"\"Return the form class to"
    ],
    [
        "if self.fields is not None and self.form_class:",
        "if self.fields is not None"
    ],
    [
        "\"Specifying both 'fields' and 'form_class' is not permitted.\"",
        "\"Specifying both 'fields' and 'form_class' is"
    ],
    [
        "elif getattr(self, \"object\", None) is not None:",
        "elif getattr(self, \"object\", None) is"
    ],
    [
        "\"Using ModelFormMixin (base class of %s) without \"",
        "\"Using ModelFormMixin (base class of %s) without"
    ],
    [
        "\"the 'fields' attribute is prohibited.\" % self.__class__.__name__",
        "\"the 'fields' attribute is prohibited.\" %"
    ],
    [
        "\"\"\"Return the keyword arguments for instantiating the form.\"\"\"",
        "\"\"\"Return the keyword arguments for"
    ],
    [
        "\"\"\"Return the URL to redirect to after processing a valid form.\"\"\"",
        "\"\"\"Return the URL to redirect to after processing a"
    ],
    [
        "\"No URL to redirect to.  Either provide a url or define\"",
        "\"No URL to redirect to. Either"
    ],
    [
        "\" a get_absolute_url method on the Model.\"",
        "\" a get_absolute_url method on"
    ],
    [
        "\"\"\"If the form is valid, save the associated model.\"\"\"",
        "\"\"\"If the form is valid,"
    ],
    [
        "\"\"\"Render a form on GET and processes it on POST.\"\"\"",
        "\"\"\"Render a form on GET and processes"
    ],
    [
        "\"\"\"Handle GET requests: instantiate a blank version of the form.\"\"\"",
        "\"\"\"Handle GET requests: instantiate a blank version of the"
    ],
    [
        "Handle POST requests: instantiate a form instance with the passed",
        "Handle POST requests: instantiate a"
    ],
    [
        "POST variables and then check if it's valid.",
        "POST variables and then check if it's"
    ],
    [
        "\"\"\"A base view for displaying a form.\"\"\"",
        "\"\"\"A base view for displaying"
    ],
    [
        "\"\"\"A view for displaying a form and rendering a template response.\"\"\"",
        "\"\"\"A view for displaying a form and"
    ],
    [
        "Base view for creating a new object instance.",
        "Base view for creating a new object"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide a response"
    ],
    [
        "View for creating a new object, with a response rendered by a template.",
        "View for creating a new object, with a response rendered"
    ],
    [
        "Base view for updating an existing object.",
        "Base view for updating"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide a response"
    ],
    [
        "\"\"\"View for updating an object, with a response rendered by a template.\"\"\"",
        "\"\"\"View for updating an object, with a response rendered by a"
    ],
    [
        "\"\"\"Provide the ability to delete objects.\"\"\"",
        "\"\"\"Provide the ability to"
    ],
    [
        "Call the delete() method on the fetched object and then redirect to the",
        "Call the delete() method on the fetched"
    ],
    [
        "raise ImproperlyConfigured(\"No URL to redirect to. Provide a success_url.\")",
        "raise ImproperlyConfigured(\"No URL to redirect to."
    ],
    [
        "Base view for deleting an object.",
        "Base view for deleting"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to"
    ],
    [
        "View for deleting an object retrieved with self.get_object(), with a",
        "View for deleting an object retrieved"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext"
    ],
    [
        "from django.views.generic.base import ContextMixin, TemplateResponseMixin, View",
        "from django.views.generic.base import"
    ],
    [
        "Provide the ability to retrieve a single object for further manipulation.",
        "Provide the ability to retrieve a single object for further"
    ],
    [
        "Return the object the view is displaying.",
        "Return the object the"
    ],
    [
        "Require `self.queryset` and a `pk` or `slug` argument in the URLconf.",
        "Require `self.queryset` and a `pk` or `slug`"
    ],
    [
        "Subclasses can override this to return any object.",
        "Subclasses can override this to"
    ],
    [
        "if slug is not None and (pk is None or self.query_pk_and_slug):",
        "if slug is not None and (pk"
    ],
    [
        "if pk is None and slug is None:",
        "if pk is None"
    ],
    [
        "\"Generic detail view %s must be called with either an object \"",
        "\"Generic detail view %s must be called with either an object"
    ],
    [
        "\"pk or a slug in the URLconf.\" % self.__class__.__name__",
        "\"pk or a slug in"
    ],
    [
        "_(\"No %(verbose_name)s found matching the query\")",
        "_(\"No %(verbose_name)s found matching"
    ],
    [
        "Return the `QuerySet` that will be used to look up the object.",
        "Return the `QuerySet` that will be"
    ],
    [
        "This method is called by the default implementation of get_object() and",
        "This method is called by the default implementation"
    ],
    [
        "may not be called if get_object() is overridden.",
        "may not be called if get_object() is"
    ],
    [
        "\"%(cls)s is missing a QuerySet. Define \"",
        "\"%(cls)s is missing a"
    ],
    [
        "\"\"\"Get the name of a slug field to be used to look up by slug.\"\"\"",
        "\"\"\"Get the name of a slug field to be used to look up"
    ],
    [
        "\"\"\"Get the name to use for the object.\"\"\"",
        "\"\"\"Get the name to use for the"
    ],
    [
        "\"\"\"Insert the single object into the context dict.\"\"\"",
        "\"\"\"Insert the single object into the"
    ],
    [
        "Base view for displaying a single object.",
        "Base view for displaying a"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide a response"
    ],
    [
        "Return a list of template names to be used for the request. May not be",
        "Return a list of template names to be used for the request. May not"
    ],
    [
        "called if render_to_response() is overridden. Return a list containing",
        "called if render_to_response() is overridden."
    ],
    [
        "``template_name``, if set on the value. Otherwise, return a list",
        "``template_name``, if set on the value. Otherwise, return"
    ],
    [
        "* the contents of the ``template_name_field`` field on the",
        "* the contents of the ``template_name_field`` field on"
    ],
    [
        "object instance that the view is operating upon (if available)",
        "object instance that the view"
    ],
    [
        "elif getattr(self, \"model\", None) is not None and issubclass(",
        "elif getattr(self, \"model\", None) is not None"
    ],
    [
        "\"of 'template_name', 'template_name_field', or 'model'; \"",
        "\"of 'template_name', 'template_name_field', or"
    ],
    [
        "Render a \"detail\" view of an object.",
        "Render a \"detail\" view of an"
    ],
    [
        "By default this is a model instance looked up from `self.queryset`, but the",
        "By default this is a model instance looked up from"
    ],
    [
        "view will support display of *any* object by overriding `self.get_object()`.",
        "view will support display of *any* object by"
    ],
    [
        "from django.utils.translation import gettext as _",
        "from django.utils.translation import gettext as"
    ],
    [
        "\"\"\"Mixin for views manipulating year-based data.\"\"\"",
        "\"\"\"Mixin for views manipulating year-based"
    ],
    [
        "Get a year format string in strptime syntax to be used to parse the",
        "Get a year format string in strptime syntax to be used"
    ],
    [
        "\"\"\"Return the year for which this view should display data.\"\"\"",
        "\"\"\"Return the year for which this view should display"
    ],
    [
        "Return the start date of the next interval.",
        "Return the start date of the next"
    ],
    [
        "The interval is defined by start date <= item date < next start date.",
        "The interval is defined by start date <="
    ],
    [
        "\"\"\"Return the start date of the current interval.\"\"\"",
        "\"\"\"Return the start date of the"
    ],
    [
        "\"\"\"Mixin for views manipulating month-based data.\"\"\"",
        "\"\"\"Mixin for views manipulating month-based"
    ],
    [
        "Get a month format string in strptime syntax to be used to parse the",
        "Get a month format string in strptime syntax to be used to"
    ],
    [
        "\"\"\"Return the month for which this view should display data.\"\"\"",
        "\"\"\"Return the month for which this"
    ],
    [
        "Return the start date of the next interval.",
        "Return the start date of the"
    ],
    [
        "The interval is defined by start date <= item date < next start date.",
        "The interval is defined by start date <= item date < next start"
    ],
    [
        "\"\"\"Return the start date of the previous interval.\"\"\"",
        "\"\"\"Return the start date of the"
    ],
    [
        "\"\"\"Mixin for views manipulating day-based data.\"\"\"",
        "\"\"\"Mixin for views manipulating day-based"
    ],
    [
        "Get a day format string in strptime syntax to be used to parse the day",
        "Get a day format string in strptime syntax to be used to parse"
    ],
    [
        "\"\"\"Return the day for which this view should display data.\"\"\"",
        "\"\"\"Return the day for which this view"
    ],
    [
        "Return the start date of the next interval.",
        "Return the start date"
    ],
    [
        "The interval is defined by start date <= item date < next start date.",
        "The interval is defined by start date <= item date <"
    ],
    [
        "\"\"\"Return the start date of the current interval.\"\"\"",
        "\"\"\"Return the start date of"
    ],
    [
        "\"\"\"Mixin for views manipulating week-based data.\"\"\"",
        "\"\"\"Mixin for views"
    ],
    [
        "Get a week format string in strptime syntax to be used to parse the",
        "Get a week format string in strptime"
    ],
    [
        "\"\"\"Return the week for which this view should display data.\"\"\"",
        "\"\"\"Return the week for which"
    ],
    [
        "Return the start date of the next interval.",
        "Return the start date of the next"
    ],
    [
        "The interval is defined by start date <= item date < next start date.",
        "The interval is defined by start date <= item"
    ],
    [
        "\"\"\"Return the start date of the current interval.\"\"\"",
        "\"\"\"Return the start date of"
    ],
    [
        "Return the weekday for a given date.",
        "Return the weekday for a"
    ],
    [
        "raise ValueError(\"unknown week format: %s\" % week_format)",
        "raise ValueError(\"unknown week format:"
    ],
    [
        "\"\"\"Mixin class for views manipulating date-based data.\"\"\"",
        "\"\"\"Mixin class for views"
    ],
    [
        "\"\"\"Get the name of the date field to be used to filter by.\"\"\"",
        "\"\"\"Get the name of the date field"
    ],
    [
        "Return `True` if the view should be allowed to display objects from",
        "Return `True` if the view should be allowed to"
    ],
    [
        "Return `True` if the date field is a `DateTimeField` and `False`",
        "Return `True` if the date field is a"
    ],
    [
        "model = self.get_queryset().model if self.model is None else self.model",
        "model = self.get_queryset().model if self.model is None else"
    ],
    [
        "Convert a date into a datetime when the date field is a DateTimeField.",
        "Convert a date into a datetime when the date field is a"
    ],
    [
        "When time zone support is enabled, `date` is assumed to be in the",
        "When time zone support is enabled, `date` is assumed to be in"
    ],
    [
        "current time zone, so that displayed items are consistent with the URL.",
        "current time zone, so that displayed items are consistent with the"
    ],
    [
        "Get the lookup kwargs for filtering on a single date.",
        "Get the lookup kwargs for filtering on a"
    ],
    [
        "If the date field is a DateTimeField, we can't just filter on",
        "If the date field is a DateTimeField, we can't just"
    ],
    [
        "date_field=date because that doesn't take the time into account.",
        "date_field=date because that doesn't take"
    ],
    [
        "Base class for date-based views displaying a list of objects.",
        "Base class for date-based views displaying a list of"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide a response"
    ],
    [
        "\"\"\"Obtain the list of dates and items.\"\"\"",
        "\"\"\"Obtain the list of"
    ],
    [
        "\"A DateView must provide an implementation of get_dated_items()\"",
        "\"A DateView must provide an implementation of"
    ],
    [
        "Return the field or fields to use for ordering the queryset; use the",
        "Return the field or fields to use"
    ],
    [
        "return \"-%s\" % self.get_date_field() if self.ordering is None else self.ordering",
        "return \"-%s\" % self.get_date_field() if self.ordering"
    ],
    [
        "Get a queryset properly filtered according to `allow_future` and any",
        "Get a queryset properly filtered according to"
    ],
    [
        "now = timezone.now() if self.uses_datetime_field else timezone_today()",
        "now = timezone.now() if self.uses_datetime_field else"
    ],
    [
        "qs = qs.filter(**{\"%s__lte\" % date_field: now})",
        "qs = qs.filter(**{\"%s__lte\" % date_field:"
    ],
    [
        "is_empty = not qs if paginate_by is None else not qs.exists()",
        "is_empty = not qs if paginate_by is None else not"
    ],
    [
        "Get the aggregation period for the list of dates: 'year', 'month', or",
        "Get the aggregation period for the list"
    ],
    [
        "Get a date list by calling `queryset.dates/datetimes()`, checking",
        "Get a date list by calling"
    ],
    [
        "along the way for empty lists that aren't allowed.",
        "along the way for empty"
    ],
    [
        "if date_list is not None and not date_list and not allow_empty:",
        "if date_list is not None and not date_list and"
    ],
    [
        "Base view for archives of date-based items.",
        "Base view for archives of"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide a"
    ],
    [
        "\"\"\"Return (date_list, items, extra_context) for this request.\"\"\"",
        "\"\"\"Return (date_list, items, extra_context) for this"
    ],
    [
        "Base view for a list of objects published in a given year.",
        "Base view for a list of objects published in a"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide"
    ],
    [
        "\"\"\"Return (date_list, items, extra_context) for this request.\"\"\"",
        "\"\"\"Return (date_list, items, extra_context) for"
    ],
    [
        "Return `True` if this view should contain the full list of objects in",
        "Return `True` if this view should contain the full list of"
    ],
    [
        "\"\"\"List of objects published in a given year.\"\"\"",
        "\"\"\"List of objects published"
    ],
    [
        "Base view for a list of objects published in a given month.",
        "Base view for a list of"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide a"
    ],
    [
        "\"\"\"Return (date_list, items, extra_context) for this request.\"\"\"",
        "\"\"\"Return (date_list, items, extra_context)"
    ],
    [
        "\"\"\"List of objects published in a given month.\"\"\"",
        "\"\"\"List of objects published in"
    ],
    [
        "Base view for a list of objects published in a given week.",
        "Base view for a list of"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide a response"
    ],
    [
        "\"\"\"Return (date_list, items, extra_context) for this request.\"\"\"",
        "\"\"\"Return (date_list, items, extra_context)"
    ],
    [
        "\"Unknown week format %r. Choices are: %s\"",
        "\"Unknown week format %r. Choices are:"
    ],
    [
        "if week_format == \"%V\" and year_format != \"%G\":",
        "if week_format == \"%V\" and"
    ],
    [
        "\"ISO week directive '%s' is incompatible with the year \"",
        "\"ISO week directive '%s' is"
    ],
    [
        "\"directive '%s'. Use the ISO year '%%G' instead.\"",
        "\"directive '%s'. Use the ISO year"
    ],
    [
        "date = _date_from_string(year, year_format, week_start, \"%w\", week, week_format)",
        "date = _date_from_string(year, year_format,"
    ],
    [
        "\"\"\"List of objects published in a given week.\"\"\"",
        "\"\"\"List of objects published in a given"
    ],
    [
        "Base view for a list of objects published on a given day.",
        "Base view for a list of objects published on a given"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide"
    ],
    [
        "\"\"\"Return (date_list, items, extra_context) for this request.\"\"\"",
        "\"\"\"Return (date_list, items, extra_context)"
    ],
    [
        "Do the actual heavy lifting of getting the dated items; this accepts a",
        "Do the actual heavy lifting of getting the dated"
    ],
    [
        "date object so that TodayArchiveView can be trivial.",
        "date object so that TodayArchiveView can"
    ],
    [
        "\"\"\"List of objects published on a given day.\"\"\"",
        "\"\"\"List of objects published on a"
    ],
    [
        "Base view for a list of objects published today.",
        "Base view for a list of objects"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide"
    ],
    [
        "\"\"\"Return (date_list, items, extra_context) for this request.\"\"\"",
        "\"\"\"Return (date_list, items, extra_context) for this"
    ],
    [
        "class BaseDateDetailView(YearMixin, MonthMixin, DayMixin, DateMixin, BaseDetailView):",
        "class BaseDateDetailView(YearMixin, MonthMixin,"
    ],
    [
        "Base detail view for a single object on a single date; this differs from the",
        "Base detail view for a single object on a single date;"
    ],
    [
        "standard DetailView by accepting a year/month/day in the URL.",
        "standard DetailView by accepting a year/month/day in the"
    ],
    [
        "This requires subclassing to provide a response mixin.",
        "This requires subclassing to provide"
    ],
    [
        "\"\"\"Get the object this request displays.\"\"\"",
        "\"\"\"Get the object this"
    ],
    [
        "qs = self.get_queryset() if queryset is None else queryset",
        "qs = self.get_queryset() if queryset is None"
    ],
    [
        "if not self.get_allow_future() and date > datetime.date.today():",
        "if not self.get_allow_future() and"
    ],
    [
        "\"Future %(verbose_name_plural)s not available because \"",
        "\"Future %(verbose_name_plural)s not"
    ],
    [
        "Detail view of a single object on a single date; this differs from the",
        "Detail view of a single object on"
    ],
    [
        "standard DetailView by accepting a year/month/day in the URL.",
        "standard DetailView by accepting a year/month/day in the"
    ],
    [
        "year, year_format, month=\"\", month_format=\"\", day=\"\", day_format=\"\", delim=\"__\"",
        "year, year_format, month=\"\", month_format=\"\", day=\"\","
    ],
    [
        "Get a datetime.date object given a format string and a year, month, and day",
        "Get a datetime.date object given a format string and"
    ],
    [
        "format = year_format + delim + month_format + delim + day_format",
        "format = year_format + delim + month_format"
    ],
    [
        "datestr = str(year) + delim + str(month) + delim + str(day)",
        "datestr = str(year) + delim + str(month) + delim"
    ],
    [
        "_(\"Invalid date string “%(datestr)s” given format “%(format)s”\")",
        "_(\"Invalid date string “%(datestr)s” given format"
    ],
    [
        "Get the next or the previous valid date. The idea is to allow links on",
        "Get the next or the previous valid date. The idea"
    ],
    [
        "This is a bit complicated since it handles different intervals of time,",
        "This is a bit complicated since it handles different intervals"
    ],
    [
        "However in essence the logic comes down to:",
        "However in essence the logic comes"
    ],
    [
        "* If allow_empty and allow_future are both true, this is easy: just",
        "* If allow_empty and allow_future are both true, this"
    ],
    [
        "return the naive result (just the next/previous day/week/month,",
        "return the naive result (just"
    ],
    [
        "* If allow_empty is true, allow_future is false, and the naive result",
        "* If allow_empty is true, allow_future is"
    ],
    [
        "isn't in the future, then return it; otherwise return None.",
        "isn't in the future, then"
    ],
    [
        "* If allow_empty is false and allow_future is true, return the next",
        "* If allow_empty is false and allow_future"
    ],
    [
        "date *that contains a valid object*, even if it's in the future. If",
        "date *that contains a valid object*, even if it's in the"
    ],
    [
        "there are no next objects, return None.",
        "there are no next objects,"
    ],
    [
        "* If allow_empty is false and allow_future is false, return the next",
        "* If allow_empty is false and allow_future"
    ],
    [
        "date that contains a valid object. If that date is in the future, or",
        "date that contains a valid object. If that"
    ],
    [
        "if there are no next objects, return None.",
        "if there are no"
    ],
    [
        "get_current = getattr(generic_view, \"_get_current_%s\" % period)",
        "get_current = getattr(generic_view, \"_get_current_%s\""
    ],
    [
        "get_next = getattr(generic_view, \"_get_next_%s\" % period)",
        "get_next = getattr(generic_view, \"_get_next_%s\" %"
    ],
    [
        "if allow_future or result <= timezone_today():",
        "if allow_future or"
    ],
    [
        "lookup = {\"%s__lt\" % date_field: generic_view._make_date_lookup_arg(start)}",
        "lookup = {\"%s__lt\""
    ],
    [
        "lookup = {\"%s__gte\" % date_field: generic_view._make_date_lookup_arg(end)}",
        "lookup = {\"%s__gte\" %"
    ],
    [
        "\"\"\"Return the current date in the current time zone.\"\"\"",
        "\"\"\"Return the current date in the"
    ],
    [
        "A default context mixin that passes the keyword arguments received by",
        "A default context mixin that passes the keyword"
    ],
    [
        "Intentionally simple parent class for all views. Only implements",
        "Intentionally simple parent class for"
    ],
    [
        "Constructor. Called in the URLconf; can contain helpful extra",
        "Constructor. Called in the URLconf; can"
    ],
    [
        "if (method != \"options\" and hasattr(cls, method))",
        "if (method != \"options\" and"
    ],
    [
        "f\"{cls.__qualname__} HTTP handlers must either be all sync or all \"",
        "f\"{cls.__qualname__} HTTP handlers must either be all sync"
    ],
    [
        "\"\"\"Main entry point for a request-response process.\"\"\"",
        "\"\"\"Main entry point for"
    ],
    [
        "\"The method name %s is not accepted as a keyword argument \"",
        "\"The method name %s is not accepted as a keyword argument"
    ],
    [
        "\"%s() received an invalid keyword %r. as_view \"",
        "\"%s() received an invalid"
    ],
    [
        "\"only accepts arguments that are already \"",
        "\"only accepts arguments that"
    ],
    [
        "\"attributes of the class.\" % (cls.__name__, key)",
        "\"attributes of the class.\" %"
    ],
    [
        "\"%s instance has no 'request' attribute. Did you override \"",
        "\"%s instance has no 'request' attribute."
    ],
    [
        "\"setup() and forget to call super()?\" % cls.__name__",
        "\"setup() and forget to"
    ],
    [
        "\"\"\"Initialize attributes shared by all view methods.\"\"\"",
        "\"\"\"Initialize attributes shared by all"
    ],
    [
        "if hasattr(self, \"get\") and not hasattr(self, \"head\"):",
        "if hasattr(self, \"get\") and not hasattr(self,"
    ],
    [
        "\"\"\"Handle responding to requests for the OPTIONS HTTP verb.\"\"\"",
        "\"\"\"Handle responding to requests for the"
    ],
    [
        "return [m.upper() for m in self.http_method_names if hasattr(self, m)]",
        "return [m.upper() for m in self.http_method_names"
    ],
    [
        "\"\"\"A mixin that can be used to render a template.\"\"\"",
        "\"\"\"A mixin that can be"
    ],
    [
        "Return a response, using the `response_class` for this view, with a",
        "Return a response, using the `response_class` for this"
    ],
    [
        "template rendered with the given context.",
        "template rendered with the"
    ],
    [
        "Pass response_kwargs to the constructor of the response class.",
        "Pass response_kwargs to the constructor of the"
    ],
    [
        "Return a list of template names to be used for the request. Must return",
        "Return a list of template names to be"
    ],
    [
        "a list. May not be called if render_to_response() is overridden.",
        "a list. May not be called"
    ],
    [
        "\"TemplateResponseMixin requires either a definition of \"",
        "\"TemplateResponseMixin requires either a definition"
    ],
    [
        "\"'template_name' or an implementation of 'get_template_names()'\"",
        "\"'template_name' or an"
    ],
    [
        "Render a template. Pass keyword arguments from the URLconf to the context.",
        "Render a template. Pass keyword arguments from"
    ],
    [
        "\"\"\"Provide a redirect on any GET request.\"\"\"",
        "\"\"\"Provide a redirect on any GET"
    ],
    [
        "Return the URL redirect to. Keyword arguments from the URL pattern",
        "Return the URL redirect to. Keyword arguments from the URL"
    ],
    [
        "match generating the redirect request are provided as kwargs to this",
        "match generating the redirect request are provided as kwargs to"
    ],
    [
        "url = \"%s?%s\" % (url, args)",
        "url = \"%s?%s\" %"
    ],
    [
        "Read values from the module specified by the DJANGO_SETTINGS_MODULE environment",
        "Read values from the module specified by"
    ],
    [
        "variable, and then from django.conf.global_settings; see the global_settings.py",
        "variable, and then from"
    ],
    [
        "for a list of all possible variables.",
        "for a list of"
    ],
    [
        "String subclass which references a current settings value. It's treated as",
        "String subclass which references a current settings"
    ],
    [
        "the value in memory but serializes to a settings.NAME attribute reference.",
        "the value in memory but serializes to a"
    ],
    [
        "A lazy proxy for either global Django settings or a custom settings object.",
        "A lazy proxy for either global Django settings or a custom settings"
    ],
    [
        "The user can manually configure settings prior to using them. Otherwise,",
        "The user can manually configure settings prior to using them."
    ],
    [
        "Django uses the settings module pointed to by DJANGO_SETTINGS_MODULE.",
        "Django uses the settings module pointed to by"
    ],
    [
        "Load the settings module pointed to by the environment variable. This",
        "Load the settings module pointed to by"
    ],
    [
        "is used the first time settings are needed, if the user hasn't",
        "is used the first time settings"
    ],
    [
        "desc = (\"setting %s\" % name) if name else \"settings\"",
        "desc = (\"setting %s\" % name) if name"
    ],
    [
        "\"Requested %s, but settings are not configured. \"",
        "\"Requested %s, but settings are"
    ],
    [
        "\"You must either define the environment variable %s \"",
        "\"You must either define the environment variable"
    ],
    [
        "\"or call settings.configure() before accessing settings.\"",
        "\"or call settings.configure() before"
    ],
    [
        "\"\"\"Return the value of a setting and cache it in self.__dict__.\"\"\"",
        "\"\"\"Return the value of a setting and cache it in"
    ],
    [
        "if (_wrapped := self._wrapped) is empty:",
        "if (_wrapped := self._wrapped)"
    ],
    [
        "if name in {\"MEDIA_URL\", \"STATIC_URL\"} and val is not None:",
        "if name in {\"MEDIA_URL\", \"STATIC_URL\"}"
    ],
    [
        "elif name == \"SECRET_KEY\" and not val:",
        "elif name == \"SECRET_KEY\" and not"
    ],
    [
        "raise ImproperlyConfigured(\"The SECRET_KEY setting must not be empty.\")",
        "raise ImproperlyConfigured(\"The SECRET_KEY setting must not"
    ],
    [
        "Set the value of setting. Clear all cached values if _wrapped changes",
        "Set the value of setting. Clear all"
    ],
    [
        "(@override_settings does this) or clear single values when set.",
        "(@override_settings does this) or clear single"
    ],
    [
        "\"\"\"Delete a setting and clear it from cache if needed.\"\"\"",
        "\"\"\"Delete a setting and clear it from"
    ],
    [
        "Called to manually configure the settings. The 'default_settings'",
        "Called to manually configure the"
    ],
    [
        "parameter sets where to retrieve any unspecified values from (its",
        "parameter sets where to retrieve any"
    ],
    [
        "argument must support attribute access (__getattr__)).",
        "argument must support attribute access"
    ],
    [
        "raise TypeError(\"Setting %r must be uppercase.\" % name)",
        "raise TypeError(\"Setting %r must be uppercase.\""
    ],
    [
        "Add SCRIPT_NAME prefix to relative paths.",
        "Add SCRIPT_NAME prefix to relative"
    ],
    [
        "Useful when the app is being served at a subpath and manually prefixing",
        "Useful when the app is being served at a"
    ],
    [
        "subpath to STATIC_URL and MEDIA_URL in settings is inconvenient.",
        "subpath to STATIC_URL and MEDIA_URL"
    ],
    [
        "\"\"\"Return True if the settings have already been configured.\"\"\"",
        "\"\"\"Return True if the settings have"
    ],
    [
        "if setting in tuple_settings and not isinstance(",
        "if setting in tuple_settings and not"
    ],
    [
        "\"The %s setting must be a list or a tuple.\" % setting",
        "\"The %s setting must be a list or a tuple.\""
    ],
    [
        "raise ValueError(\"Incorrect timezone setting: %s\" % self.TIME_ZONE)",
        "raise ValueError(\"Incorrect timezone setting:"
    ],
    [
        "Requests for configuration variables not in this class are satisfied",
        "Requests for configuration variables not"
    ],
    [
        "from the module specified in default_settings (if possible).",
        "from the module specified in"
    ],
    [
        "if not name.isupper() or name in self._deleted:",
        "if not name.isupper() or"
    ],
    [
        "return deleted or set_locally or set_on_default",
        "return deleted or set_locally or"
    ],
    [
        "Default Django settings. Override these with settings in the module pointed to",
        "Default Django settings. Override these with settings in the module pointed"
    ],
    [
        "LANGUAGES_BIDI = [\"he\", \"ar\", \"ar-dz\", \"ckb\", \"fa\", \"ug\", \"ur\"]",
        "LANGUAGES_BIDI = [\"he\", \"ar\", \"ar-dz\", \"ckb\", \"fa\", \"ug\","
    ],
    [
        "DATETIME_FORMAT = \"N j, Y, P\"",
        "DATETIME_FORMAT = \"N j, Y,"
    ],
    [
        "LANG_INFO is a dictionary structure to provide meta information about languages.",
        "LANG_INFO is a dictionary structure to provide meta information about"
    ],
    [
        "About name_local: capitalize it as if your language name was appearing",
        "About name_local: capitalize it as if your language name was"
    ],
    [
        "inside a sentence in your language.",
        "inside a sentence"
    ],
    [
        "The 'fallback' key can be used to specify a special fallback logic which doesn't",
        "The 'fallback' key can be used to specify a special fallback logic"
    ],
    [
        "follow the traditional 'fr-ca' -> 'fr' fallback logic.",
        "follow the traditional 'fr-ca' -> 'fr'"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y. H:i\"",
        "DATETIME_FORMAT = \"j."
    ],
    [
        "DATETIME_FORMAT = \"j. F Y G:i\"",
        "DATETIME_FORMAT = \"j. F Y"
    ],
    [
        "DATETIME_FORMAT = \"j E Y H:i\"",
        "DATETIME_FORMAT = \"j E"
    ],
    [
        "DATETIME_FORMAT = \"j F Y H:i\"",
        "DATETIME_FORMAT = \"j F"
    ],
    [
        "DATE_FORMAT = r\"\\N\\gà\\y d \\t\\há\\n\\g n \\nă\\m Y\"",
        "DATE_FORMAT = r\"\\N\\gà\\y d \\t\\há\\n\\g n \\nă\\m"
    ],
    [
        "DATETIME_FORMAT = r\"H:i \\N\\gà\\y d \\t\\há\\n\\g n \\nă\\m Y\"",
        "DATETIME_FORMAT = r\"H:i \\N\\gà\\y d \\t\\há\\n\\g n \\nă\\m"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y H:i\"",
        "DATETIME_FORMAT = \"j. F"
    ],
    [
        "DATETIME_FORMAT = \"j F Y H:i\"",
        "DATETIME_FORMAT = \"j F"
    ],
    [
        "DATETIME_FORMAT = \"j בF Y H:i\"",
        "DATETIME_FORMAT = \"j בF"
    ],
    [
        "DATE_FORMAT = \"j ខែ F ឆ្នាំ Y\"",
        "DATE_FORMAT = \"j ខែ F"
    ],
    [
        "DATETIME_FORMAT = \"j ខែ F ឆ្នាំ Y, G:i\"",
        "DATETIME_FORMAT = \"j ខែ F ឆ្នាំ"
    ],
    [
        "SHORT_DATETIME_FORMAT = \"j M Y, G:i\"",
        "SHORT_DATETIME_FORMAT = \"j M Y,"
    ],
    [
        "DATETIME_FORMAT = \"j F Y H:i\"",
        "DATETIME_FORMAT = \"j F"
    ],
    [
        "SHORT_DATETIME_FORMAT = \"j F Y H:i\"",
        "SHORT_DATETIME_FORMAT = \"j F Y"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y H:i\"",
        "DATETIME_FORMAT = \"j. F Y"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y H:i\"",
        "DATETIME_FORMAT = \"j. F"
    ],
    [
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e Y\"",
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e"
    ],
    [
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\a \\l\\a\\s H:i\"",
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\a"
    ],
    [
        "DATE_FORMAT = \"j E Y ж.\"",
        "DATE_FORMAT = \"j E Y"
    ],
    [
        "DATETIME_FORMAT = \"j E Y ж. G:i\"",
        "DATETIME_FORMAT = \"j E Y"
    ],
    [
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e Y\"",
        "DATE_FORMAT = r\"j \\d\\e"
    ],
    [
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y à\\s H:i\"",
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y à\\s"
    ],
    [
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e Y\"",
        "DATE_FORMAT = r\"j \\d\\e F"
    ],
    [
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\a \\l\\a\\s H:i\"",
        "DATETIME_FORMAT = r\"j \\d\\e F"
    ],
    [
        "DATETIME_FORMAT = \"j F Y P\"",
        "DATETIME_FORMAT = \"j F"
    ],
    [
        "DATE_FORMAT = r\"Y. \\g\\a\\d\\a j. F\"",
        "DATE_FORMAT = r\"Y. \\g\\a\\d\\a j."
    ],
    [
        "DATETIME_FORMAT = r\"Y. \\g\\a\\d\\a j. F, H:i\"",
        "DATETIME_FORMAT = r\"Y. \\g\\a\\d\\a"
    ],
    [
        "DATE_FORMAT = r\"j E \\d\\e Y\"",
        "DATE_FORMAT = r\"j E"
    ],
    [
        "DATETIME_FORMAT = r\"j E \\d\\e Y \\a \\l\\e\\s G:i\"",
        "DATETIME_FORMAT = r\"j E \\d\\e"
    ],
    [
        "DATETIME_FORMAT = \"j. E Y G:i\"",
        "DATETIME_FORMAT = \"j."
    ],
    [
        "DATE_FORMAT = \"j E Y г.\"",
        "DATE_FORMAT = \"j E Y"
    ],
    [
        "DATETIME_FORMAT = \"j E Y г. G:i\"",
        "DATETIME_FORMAT = \"j E"
    ],
    [
        "DATE_FORMAT = \"j E Y г.\"",
        "DATE_FORMAT = \"j E"
    ],
    [
        "DATETIME_FORMAT = \"j E Y г. G:i\"",
        "DATETIME_FORMAT = \"j E Y"
    ],
    [
        "DATETIME_FORMAT = \"j F Y H:i\"",
        "DATETIME_FORMAT = \"j F"
    ],
    [
        "DATETIME_FORMAT = \"j F Y, H:i\"",
        "DATETIME_FORMAT = \"j F"
    ],
    [
        "DATETIME_FORMAT = \"j F Y، کاتژمێر G:i\"",
        "DATETIME_FORMAT = \"j F Y، کاتژمێر"
    ],
    [
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e Y\"",
        "DATE_FORMAT = r\"j \\d\\e F"
    ],
    [
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y à\\s H:i\"",
        "DATETIME_FORMAT = r\"j \\d\\e F"
    ],
    [
        "DATE_FORMAT = \"d E Y р.\"",
        "DATE_FORMAT = \"d"
    ],
    [
        "DATETIME_FORMAT = \"d E Y р. H:i\"",
        "DATETIME_FORMAT = \"d E"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y. H:i\"",
        "DATETIME_FORMAT = \"j. F Y."
    ],
    [
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e Y\"",
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e"
    ],
    [
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\a \\l\\a\\s H:i\"",
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\a \\l\\a\\s"
    ],
    [
        "DATETIME_FORMAT = \"N j, Y, P\"",
        "DATETIME_FORMAT = \"N j, Y,"
    ],
    [
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e Y\"",
        "DATE_FORMAT = r\"j \\d\\e"
    ],
    [
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\a \\l\\a\\s H:i\"",
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\a"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y H:i\"",
        "DATETIME_FORMAT = \"j. F"
    ],
    [
        "DATETIME_FORMAT = \"j. N. Y. G:i T\"",
        "DATETIME_FORMAT = \"j. N."
    ],
    [
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e Y\"",
        "DATE_FORMAT = r\"j \\d\\e"
    ],
    [
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\á\\s H:i\"",
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y"
    ],
    [
        "DATETIME_FORMAT = \"j. E Y. H:i\"",
        "DATETIME_FORMAT = \"j. E"
    ],
    [
        "DATETIME_FORMAT = \"Y. F j. H:i\"",
        "DATETIME_FORMAT = \"Y. F"
    ],
    [
        "DATETIME_FORMAT = r\"j N Y H:i\"",
        "DATETIME_FORMAT = r\"j N"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y H:i\"",
        "DATETIME_FORMAT = \"j."
    ],
    [
        "DATE_FORMAT = \"l, j F, Y\"",
        "DATE_FORMAT = \"l, j"
    ],
    [
        "DATETIME_FORMAT = \"j F, Y h:i a\"",
        "DATETIME_FORMAT = \"j F,"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y H:i\"",
        "DATETIME_FORMAT = \"j."
    ],
    [
        "DATETIME_FORMAT = \"j E Y, G:i\"",
        "DATETIME_FORMAT = \"j E"
    ],
    [
        "DATETIME_FORMAT = \"j F Y h:ia\"",
        "DATETIME_FORMAT = \"j F"
    ],
    [
        "SHORT_DATETIME_FORMAT = \"j M Y h:ia\"",
        "SHORT_DATETIME_FORMAT = \"j M Y"
    ],
    [
        "DATETIME_FORMAT = \"Y년 n월 j일 g:i A\"",
        "DATETIME_FORMAT = \"Y년 n월 j일"
    ],
    [
        "DATETIME_FORMAT = r\"j. E Y \\k\\e\\l\\l\\o G.i\"",
        "DATETIME_FORMAT = r\"j. E Y \\k\\e\\l\\l\\o"
    ],
    [
        "DATETIME_FORMAT = \"j. F Y. H:i\"",
        "DATETIME_FORMAT = \"j."
    ],
    [
        "DATETIME_FORMAT = \"j N Y, G.i\"",
        "DATETIME_FORMAT = \"j"
    ],
    [
        "DATETIME_FORMAT = \"j F Y H:i\"",
        "DATETIME_FORMAT = \"j F"
    ],
    [
        "DATE_FORMAT = r\"j \\d\\e F \\d\\e Y\"",
        "DATE_FORMAT = r\"j \\d\\e"
    ],
    [
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e Y \\a \\l\\a\\s H:i\"",
        "DATETIME_FORMAT = r\"j \\d\\e F \\d\\e"
    ],
    [
        "DATETIME_FORMAT = \"N j, Y, P\"",
        "DATETIME_FORMAT = \"N"
    ],
    [
        "DATETIME_FORMAT = \"j F Y، ساعت G:i\"",
        "DATETIME_FORMAT = \"j F Y،"
    ],
    [
        "DATE_FORMAT = r\"Y \\m. E j \\d.\"",
        "DATE_FORMAT = r\"Y \\m. E j"
    ],
    [
        "DATETIME_FORMAT = r\"Y \\m. E j \\d., H:i\"",
        "DATETIME_FORMAT = r\"Y \\m. E j"
    ],
    [
        "DATETIME_FORMAT = r\"Y\\k\\o N j\\a, H:i\"",
        "DATETIME_FORMAT = r\"Y\\k\\o N"
    ],
    [
        "DATETIME_FORMAT = \"j F Y, G:i\"",
        "DATETIME_FORMAT = \"j"
    ],
    [
        "SHORT_DATETIME_FORMAT = \"j M Y, G:i\"",
        "SHORT_DATETIME_FORMAT = \"j M"
    ],
    [
        "DATETIME_FORMAT = \"d F Y H:i\"",
        "DATETIME_FORMAT = \"d"
    ],
    [
        "SHORT_DATETIME_FORMAT = \"d M Y H:i\"",
        "SHORT_DATETIME_FORMAT = \"d"
    ],
    [
        "DATE_FORMAT = \"j E Y г.\"",
        "DATE_FORMAT = \"j E"
    ],
    [
        "DATETIME_FORMAT = \"j E Y г. G:i\"",
        "DATETIME_FORMAT = \"j E Y"
    ],
    [
        "Return a URL pattern for serving files in debug mode.",
        "Return a URL pattern for"
    ],
    [
        "raise ImproperlyConfigured(\"Empty static prefix not permitted\")",
        "raise ImproperlyConfigured(\"Empty static prefix"
    ],
    [
        "from django.urls import LocalePrefixPattern, URLResolver, get_resolver, path",
        "from django.urls import LocalePrefixPattern,"
    ],
    [
        "Add the language code prefix to every URL pattern within this function.",
        "Add the language code prefix to every URL pattern"
    ],
    [
        "This may only be used in the root URLconf, not in an included URLconf.",
        "This may only be used in the root"
    ],
    [
        "Return a tuple of two booleans: (",
        "Return a tuple of two booleans:"
    ],
    [
        "`True` if the default language should be prefixed",
        "`True` if the default"
    ],
    [
        "\"\"\"Class representing a Django application and its configuration.\"\"\"",
        "\"\"\"Class representing a Django application and"
    ],
    [
        "\"The app label '%s' is not a valid Python identifier.\" % self.label",
        "\"The app label '%s' is not a"
    ],
    [
        "return \"<%s: %s>\" % (self.__class__.__name__, self.label)",
        "return \"<%s: %s>\""
    ],
    [
        "\"\"\"Attempt to determine app's filesystem path from its module.\"\"\"",
        "\"\"\"Attempt to determine app's filesystem"
    ],
    [
        "\"The app module %r has multiple filesystem locations (%r); \"",
        "\"The app module %r has multiple filesystem locations (%r);"
    ],
    [
        "\"you must configure this app with an AppConfig subclass \"",
        "\"you must configure this app with an AppConfig subclass"
    ],
    [
        "\"with a 'path' class attribute.\" % (module, paths)",
        "\"with a 'path' class"
    ],
    [
        "\"The app module %r has no filesystem location, \"",
        "\"The app module %r has no filesystem location,"
    ],
    [
        "\"you must configure this app with an AppConfig subclass \"",
        "\"you must configure this app with an"
    ],
    [
        "\"with a 'path' class attribute.\" % module",
        "\"with a 'path' class attribute.\" %"
    ],
    [
        "Factory that creates an app config from an entry in INSTALLED_APPS.",
        "Factory that creates an app config from an"
    ],
    [
        "mod_path = \"%s.%s\" % (entry, APPS_MODULE_NAME)",
        "mod_path = \"%s.%s\" %"
    ],
    [
        "for name, candidate in inspect.getmembers(mod, inspect.isclass)",
        "for name, candidate in inspect.getmembers(mod,"
    ],
    [
        "candidates = [repr(name) for name, _ in app_configs]",
        "candidates = [repr(name) for name, _"
    ],
    [
        "\"%r declares more than one default AppConfig: \"",
        "\"%r declares more than"
    ],
    [
        "if app_module is None and app_config_class is None:",
        "if app_module is None"
    ],
    [
        "for name, candidate in inspect.getmembers(mod, inspect.isclass)",
        "for name, candidate"
    ],
    [
        "if issubclass(candidate, cls) and candidate is not cls",
        "if issubclass(candidate, cls) and candidate"
    ],
    [
        "msg = \"Module '%s' does not contain a '%s' class.\" % (",
        "msg = \"Module '%s' does not contain a"
    ],
    [
        "msg += \" Choices are: %s.\" % \", \".join(candidates)",
        "msg += \" Choices are: %s.\" %"
    ],
    [
        "raise ImproperlyConfigured(\"'%s' isn't a subclass of AppConfig.\" % entry)",
        "raise ImproperlyConfigured(\"'%s' isn't a subclass of AppConfig.\" %"
    ],
    [
        "raise ImproperlyConfigured(\"'%s' must supply a name attribute.\" % entry)",
        "raise ImproperlyConfigured(\"'%s' must supply a name attribute.\""
    ],
    [
        "\"Cannot import '%s'. Check that '%s.%s.name' is correct.\"",
        "\"Cannot import '%s'. Check that '%s.%s.name'"
    ],
    [
        "Return the model with the given case-insensitive model_name.",
        "Return the model with"
    ],
    [
        "Raise LookupError if no model exists with this name.",
        "Raise LookupError if no model exists with"
    ],
    [
        "\"App '%s' doesn't have a '%s' model.\" % (self.label, model_name)",
        "\"App '%s' doesn't have a"
    ],
    [
        "By default, the following models aren't included:",
        "By default, the following models"
    ],
    [
        "- auto-created models for many-to-many relations without",
        "- auto-created models for"
    ],
    [
        "- models that have been swapped out.",
        "- models that have been"
    ],
    [
        "Set the corresponding keyword argument to True to include such models.",
        "Set the corresponding keyword argument to True"
    ],
    [
        "Keyword arguments aren't documented; they're a private API.",
        "Keyword arguments aren't documented; they're"
    ],
    [
        "models_module_name = \"%s.%s\" % (self.name, MODELS_MODULE_NAME)",
        "models_module_name = \"%s.%s\" %"
    ],
    [
        "Override this method in subclasses to run code when Django starts.",
        "Override this method in subclasses to run code when Django"
    ],
    [
        "A registry that stores the configuration of installed applications.",
        "A registry that stores the configuration of"
    ],
    [
        "It also keeps track of models, e.g. to provide reverse relations.",
        "It also keeps track of models, e.g. to provide"
    ],
    [
        "if installed_apps is None and hasattr(sys.modules[__name__], \"apps\"):",
        "if installed_apps is None and"
    ],
    [
        "raise RuntimeError(\"You must supply an installed_apps argument.\")",
        "raise RuntimeError(\"You must supply"
    ],
    [
        "self.apps_ready = self.models_ready = self.ready = False",
        "self.apps_ready = self.models_ready = self.ready"
    ],
    [
        "Import each application module and then each model module.",
        "Import each application module and"
    ],
    [
        "It is thread-safe and idempotent, but not reentrant.",
        "It is thread-safe and idempotent,"
    ],
    [
        "\"\"\"Raise an exception if all apps haven't been imported yet.\"\"\"",
        "\"\"\"Raise an exception if all apps"
    ],
    [
        "\"\"\"Raise an exception if all models haven't been imported yet.\"\"\"",
        "\"\"\"Raise an exception if all models"
    ],
    [
        "\"\"\"Import applications and return an iterable of app configs.\"\"\"",
        "\"\"\"Import applications and return an iterable"
    ],
    [
        "Import applications and returns an app config for the given label.",
        "Import applications and returns an app config for"
    ],
    [
        "Raise LookupError if no application exists with this label.",
        "Raise LookupError if no application exists"
    ],
    [
        "message = \"No installed app with label '%s'.\" % app_label",
        "message = \"No installed app with label '%s'.\""
    ],
    [
        "message += \" Did you mean '%s'?\" % app_config.label",
        "message += \" Did you mean '%s'?\" %"
    ],
    [
        "Return a list of all installed models.",
        "Return a list of"
    ],
    [
        "By default, the following models aren't included:",
        "By default, the following models aren't"
    ],
    [
        "- auto-created models for many-to-many relations without",
        "- auto-created models for"
    ],
    [
        "- models that have been swapped out.",
        "- models that have"
    ],
    [
        "Set the corresponding keyword argument to True to include such models.",
        "Set the corresponding keyword argument to True to include such"
    ],
    [
        "Return the model matching the given app_label and model_name.",
        "Return the model matching the given"
    ],
    [
        "As a shortcut, app_label may be in the form <app_label>.<model_name>.",
        "As a shortcut, app_label may be"
    ],
    [
        "Raise LookupError if no application exists with this label, or no",
        "Raise LookupError if no application exists with this"
    ],
    [
        "model exists with this name in the application. Raise ValueError if",
        "model exists with this name in the application. Raise"
    ],
    [
        "called with a single argument that doesn't contain exactly one dot.",
        "called with a single argument that"
    ],
    [
        "if not require_ready and app_config.models is None:",
        "if not require_ready and"
    ],
    [
        "\"Model '%s.%s' was already registered. Reloading models is not \"",
        "\"Model '%s.%s' was already registered. Reloading models"
    ],
    [
        "\"advised as it can lead to inconsistencies, most notably with \"",
        "\"advised as it can lead to inconsistencies, most notably"
    ],
    [
        "\"Conflicting '%s' models in application '%s': %s and %s.\"",
        "\"Conflicting '%s' models in application '%s': %s and"
    ],
    [
        "Check whether an application with this name exists in the registry.",
        "Check whether an application with this"
    ],
    [
        "app_name is the full name of the app e.g. 'django.contrib.admin'.",
        "app_name is the full name of the app"
    ],
    [
        "return any(ac.name == app_name for ac in self.app_configs.values())",
        "return any(ac.name == app_name for"
    ],
    [
        "Look for an app config containing a given object.",
        "Look for an app config containing a"
    ],
    [
        "object_name is the dotted Python path to the object.",
        "object_name is the dotted Python path"
    ],
    [
        "Return the app config for the inner application in case of nesting.",
        "Return the app config for the inner application in case of"
    ],
    [
        "Return None if the object isn't in any registered app config.",
        "Return None if the object isn't in any registered"
    ],
    [
        "Similar to get_model(), but doesn't require that an app exists with",
        "Similar to get_model(), but doesn't require that an app exists"
    ],
    [
        "It's safe to call this method at import time, even while the registry",
        "It's safe to call this method at import time, even while"
    ],
    [
        "raise LookupError(\"Model '%s.%s' not registered.\" % (app_label, model_name))",
        "raise LookupError(\"Model '%s.%s' not registered.\""
    ],
    [
        "For a given model string (e.g. \"auth.User\"), return the name of the",
        "For a given model string (e.g. \"auth.User\"), return the name of"
    ],
    [
        "corresponding settings name if it refers to a swappable model. If the",
        "corresponding settings name if it refers to a"
    ],
    [
        "referred model is not swappable, return None.",
        "referred model is not swappable, return"
    ],
    [
        "This method is decorated with @functools.cache because it's performance",
        "This method is decorated with @functools.cache because"
    ],
    [
        "critical when it comes to migrations. Since the swappable settings don't",
        "critical when it comes to migrations. Since the"
    ],
    [
        "change after Django has loaded the settings, there is no reason to get",
        "change after Django has loaded the settings,"
    ],
    [
        "the respective settings attribute over and over again.",
        "the respective settings attribute over and over"
    ],
    [
        "if swapped and swapped.lower() == to_string:",
        "if swapped and swapped.lower() =="
    ],
    [
        "if model._meta.swappable and model._meta.label_lower == to_string:",
        "if model._meta.swappable and"
    ],
    [
        "Restrict the set of installed apps used by get_app_config[s].",
        "Restrict the set of installed"
    ],
    [
        "available must be an iterable of application names.",
        "available must be an iterable of"
    ],
    [
        "set_available_apps() must be balanced with unset_available_apps().",
        "set_available_apps() must be balanced with"
    ],
    [
        "Primarily used for performance optimization in TransactionTestCase.",
        "Primarily used for performance optimization in"
    ],
    [
        "This method is safe in the sense that it doesn't trigger any imports.",
        "This method is safe in the sense that it doesn't trigger any"
    ],
    [
        "installed = {app_config.name for app_config in self.get_app_configs()}",
        "installed = {app_config.name for app_config"
    ],
    [
        "\"Available apps isn't a subset of installed apps, extra apps: %s\"",
        "\"Available apps isn't a subset of installed apps, extra"
    ],
    [
        "\"\"\"Cancel a previous call to set_available_apps().\"\"\"",
        "\"\"\"Cancel a previous"
    ],
    [
        "Enable a different set of installed apps for get_app_config[s].",
        "Enable a different set of installed apps"
    ],
    [
        "installed must be an iterable in the same format as INSTALLED_APPS.",
        "installed must be an iterable in the"
    ],
    [
        "set_installed_apps() must be balanced with unset_installed_apps(),",
        "set_installed_apps() must be"
    ],
    [
        "even if it exits with an exception.",
        "even if it exits"
    ],
    [
        "Primarily used as a receiver of the setting_changed signal in tests.",
        "Primarily used as a receiver of the setting_changed signal"
    ],
    [
        "This method may trigger new imports, which may add new models to the",
        "This method may trigger new imports, which may add"
    ],
    [
        "registry of all imported models. They will stay in the registry even",
        "registry of all imported models. They will stay"
    ],
    [
        "after unset_installed_apps(). Since it isn't possible to replay",
        "after unset_installed_apps(). Since it isn't possible to"
    ],
    [
        "imports safely (e.g. that could lead to registering listeners twice),",
        "imports safely (e.g. that could lead to"
    ],
    [
        "models are registered when they're imported and never removed.",
        "models are registered when they're imported and"
    ],
    [
        "raise AppRegistryNotReady(\"App registry isn't ready yet.\")",
        "raise AppRegistryNotReady(\"App registry"
    ],
    [
        "self.apps_ready = self.models_ready = self.loading = self.ready = False",
        "self.apps_ready = self.models_ready = self.loading = self.ready ="
    ],
    [
        "\"\"\"Cancel a previous call to set_installed_apps().\"\"\"",
        "\"\"\"Cancel a previous"
    ],
    [
        "self.apps_ready = self.models_ready = self.ready = True",
        "self.apps_ready = self.models_ready = self.ready ="
    ],
    [
        "Clear all internal caches, for methods that alter the app registry.",
        "Clear all internal caches, for methods"
    ],
    [
        "This is mostly used in tests.",
        "This is mostly"
    ],
    [
        "Take a function and a number of (\"app_label\", \"modelname\") tuples, and",
        "Take a function and a number of (\"app_label\", \"modelname\")"
    ],
    [
        "when all the corresponding models have been imported and registered,",
        "when all the corresponding models"
    ],
    [
        "call the function with the model classes as its arguments.",
        "call the function with the"
    ],
    [
        "The function passed to this method must accept exactly n models as",
        "The function passed to this method must"
    ],
    [
        "Take a newly-prepared model and pass it to each function waiting for",
        "Take a newly-prepared model and pass it to each function"
    ],
    [
        "it. This is called at the very end of Apps.register_model().",
        "it. This is called at"
    ]
]