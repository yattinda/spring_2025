[
    [
        "This paver file is intended to help with the release process as much as",
        "This paver file is intended to help with the"
    ],
    [
        "possible. It relies on virtualenv to generate 'bootstrap' environments as",
        "possible. It relies on virtualenv to generate 'bootstrap' environments"
    ],
    [
        "independent from the user system as possible (e.g. to make sure the sphinx doc",
        "independent from the user system as possible (e.g. to"
    ],
    [
        "is built against the built numpy, not an installed one).",
        "is built against the built numpy, not an"
    ],
    [
        "Assumes you have git and the binaries/tarballs in installers/::",
        "Assumes you have git and the binaries/tarballs"
    ],
    [
        "This automatically put the checksum into README.rst, and writes the Changelog.",
        "This automatically put the checksum into README.rst, and"
    ],
    [
        "- the script is messy, lots of global variables",
        "- the script is messy,"
    ],
    [
        "- make it more easily customizable (through command line args)",
        "- make it more easily"
    ],
    [
        "- missing targets: install & test, sdist test, debian packaging",
        "- missing targets: install & test, sdist"
    ],
    [
        "- fix bdist_mpkg: we build the same source twice -> how to make sure we use",
        "- fix bdist_mpkg: we build the same source"
    ],
    [
        "the same underlying python for egg install in venv and for bdist_mpkg",
        "the same underlying python for egg install in"
    ],
    [
        "from paver.easy import Bunch, options, task, sh",
        "from paver.easy import Bunch,"
    ],
    [
        "Directory containing files to be hashed.",
        "Directory containing files"
    ],
    [
        "Function to be used to hash the files.",
        "Function to be used to"
    ],
    [
        "Directory containing files to be hashed.",
        "Directory containing files"
    ],
    [
        "Directory containing files to be hashed.",
        "Directory containing files"
    ],
    [
        "\"\"\"Append hashes of release files to release notes.",
        "\"\"\"Append hashes of release"
    ],
    [
        "This appends file hashes to the release notes and creates",
        "This appends file hashes to"
    ],
    [
        "four README files of the result in various formats:",
        "four README files of the result"
    ],
    [
        "The md file are created using `pandoc` so that the links are",
        "The md file are created using `pandoc` so that"
    ],
    [
        "properly updated. The gpg files are kept separate, so that",
        "properly updated. The gpg files are kept"
    ],
    [
        "the unsigned files may be edited before signing if needed.",
        "the unsigned files may be edited"
    ],
    [
        "Filename of the modified notes. The file is written",
        "Filename of the modified notes. The file is"
    ],
    [
        "cmd = f'gpg --clearsign --armor --default_key {options.gpg_key}'",
        "cmd = f'gpg --clearsign --armor --default_key"
    ],
    [
        "sh(cmd + f' --output {rst_readme}.gpg {rst_readme}')",
        "sh(cmd + f'"
    ],
    [
        "sh(cmd + f' --output {md_readme}.gpg {md_readme}')",
        "sh(cmd + f'"
    ],
    [
        "Two README files are generated from the release notes, one in ``rst``",
        "Two README files are generated from the release notes,"
    ],
    [
        "markup for the general release, the other in ``md`` markup for the github",
        "markup for the general release, the other in"
    ],
    [
        "meson_import_dir = curdir.parent / 'vendored-meson' / 'meson' / 'mesonbuild'",
        "meson_import_dir = curdir.parent / 'vendored-meson' /"
    ],
    [
        "'The `vendored-meson/meson` git submodule does not exist! '",
        "'The `vendored-meson/meson` git submodule does not"
    ],
    [
        "'Run `git submodule update --init` to fix this problem.'",
        "'Run `git submodule update --init` to fix this"
    ],
    [
        "\"\"\"ðŸ‘© Get change log for provided revision range",
        "\"\"\"ðŸ‘© Get change log"
    ],
    [
        "f\"{e.msg}. Install the missing packages to use this command.\"",
        "f\"{e.msg}. Install the missing packages to use"
    ],
    [
        "f\"Generating change log for range {revision_range}\",",
        "f\"Generating change log for"
    ],
    [
        "f\"GithubException raised with status: {e.status} \"",
        "f\"GithubException raised with status: {e.status}"
    ],
    [
        "f\"Git error in command `{' '.join(e.command)}` \"",
        "f\"Git error in command `{' '.join(e.command)}`"
    ],
    [
        "By default, SPHINXOPTS=\"-W\", raising errors on warnings.",
        "By default, SPHINXOPTS=\"-W\", raising errors"
    ],
    [
        "To build without raising on warnings:",
        "To build without raising"
    ],
    [
        "E.g., to build a zipfile of the html docs for distribution:",
        "E.g., to build a zipfile of the"
    ],
    [
        "p = subprocess.run(cmd, check=True, capture_output=True, text=True)",
        "p = subprocess.run(cmd,"
    ],
    [
        "outfile = curdir.parent / 'doc' / 'source' / 'release' / 'notes-towncrier.rst'",
        "outfile = curdir.parent / 'doc' / 'source'"
    ],
    [
        "jobs_param = next(p for p in docs.params if p.name == 'jobs')",
        "jobs_param = next(p for p in docs.params if"
    ],
    [
        "help=\"Run tests with the given markers\"",
        "help=\"Run tests with the given"
    ],
    [
        "def test(*, parent_callback, pytest_args, tests, markexpr, **kwargs):",
        "def test(*, parent_callback, pytest_args, tests, markexpr,"
    ],
    [
        "By default, spin will run `-m 'not slow'`. To run the full test suite, use",
        "By default, spin will run `-m 'not slow'`. To run the full test"
    ],
    [
        "if (not pytest_args) and (not tests):",
        "if (not pytest_args) and (not"
    ],
    [
        "pytest_args = ('-m', markexpr) + pytest_args",
        "pytest_args = ('-m', markexpr) +"
    ],
    [
        "\"\"\"ðŸ”§ Run doctests of objects in the public API.",
        "\"\"\"ðŸ”§ Run doctests of objects in the public"
    ],
    [
        "PYTEST_ARGS are passed through directly to pytest, e.g.:",
        "PYTEST_ARGS are passed through directly to"
    ],
    [
        "To run tests on a directory:",
        "To run tests on a"
    ],
    [
        "To report the durations of the N slowest doctests:",
        "To report the durations of the N slowest"
    ],
    [
        "To run doctests that match a given pattern:",
        "To run doctests that match a"
    ],
    [
        "spin check-docs numpy/linalg -- -k \"det and not slogdet\"",
        "spin check-docs numpy/linalg -- -k \"det and not"
    ],
    [
        "- This command only runs doctests and skips everything under tests/",
        "- This command only runs doctests and skips"
    ],
    [
        "- This command only doctests public objects: those which are accessible",
        "- This command only doctests public objects: those which are"
    ],
    [
        "raise ModuleNotFoundError(\"scipy-doctest not installed\") from e",
        "raise ModuleNotFoundError(\"scipy-doctest not"
    ],
    [
        "\"\"\"ðŸ”§ Run doctests of user-facing rst tutorials.",
        "\"\"\"ðŸ”§ Run doctests of user-facing"
    ],
    [
        "To test all tutorials in the numpy doc/source/user/ directory, use",
        "To test all tutorials in the"
    ],
    [
        "To run tests on a specific RST file:",
        "To run tests on a specific RST"
    ],
    [
        "- This command only runs doctests and skips everything under tests/",
        "- This command only runs doctests and skips everything under"
    ],
    [
        "- This command only doctests public objects: those which are accessible",
        "- This command only doctests public objects: those"
    ],
    [
        "if (not pytest_args) or all(arg.startswith('-') for arg in pytest_args):",
        "if (not pytest_args) or all(arg.startswith('-') for"
    ],
    [
        "str(curdir / '..' / arg) if not arg.startswith('-') else arg",
        "str(curdir / '..' / arg) if not arg.startswith('-')"
    ],
    [
        "p = spin.util.run(['git', 'rev-parse', commit], output=False, echo=False)",
        "p = spin.util.run(['git', 'rev-parse', commit], output=False,"
    ],
    [
        "f'Could not find SHA matching commit `{commit}`'",
        "f'Could not find SHA matching commit"
    ],
    [
        "\"\"\"ðŸ”¦ Run lint checks with Ruff",
        "\"\"\"ðŸ”¦ Run lint"
    ],
    [
        "help=\"Compare benchmarks between the current branch and main \"",
        "help=\"Compare benchmarks between the current branch and main"
    ],
    [
        "\"The benchmarks are each executed in a new isolated \"",
        "\"The benchmarks are each executed"
    ],
    [
        "help=\"Run each benchmark only once (timings won't be accurate)\"",
        "help=\"Run each benchmark only once (timings won't"
    ],
    [
        "def bench(ctx, tests, compare, verbose, quick, commits, build_dir):",
        "def bench(ctx, tests, compare, verbose, quick,"
    ],
    [
        "$ spin bench -t Random -t Shuffle",
        "$ spin bench -t Random -t"
    ],
    [
        "Two benchmark runs can be compared.",
        "Two benchmark runs can be"
    ],
    [
        "By default, `HEAD` is compared to `main`.",
        "By default, `HEAD` is compared to"
    ],
    [
        "You can also specify the branches/commits to compare:",
        "You can also specify"
    ],
    [
        "$ spin bench --compare main HEAD",
        "$ spin bench"
    ],
    [
        "You can also choose which benchmarks to run in comparison mode:",
        "You can also choose which benchmarks to run"
    ],
    [
        "$ spin bench -t Random --compare",
        "$ spin bench -t"
    ],
    [
        "'Need a maximum of two revisions to compare'",
        "'Need a maximum of two revisions"
    ],
    [
        "\"Invoking `build` prior to running benchmarks:\",",
        "\"Invoking `build` prior"
    ],
    [
        "['python', '-c', 'import numpy as np; print(np.__version__)'],",
        "['python', '-c', 'import numpy"
    ],
    [
        "commit_a, commit_b = [_commit_to_sha(c) for c in commits]",
        "commit_a, commit_b = [_commit_to_sha(c) for c"
    ],
    [
        "if commit_b == 'HEAD' and _dirty_git_working_dir():",
        "if commit_b == 'HEAD'"
    ],
    [
        "\"WARNING: you have uncommitted changes --- \"",
        "\"WARNING: you have uncommitted changes ---"
    ],
    [
        "] + bench_args + [commit_a, commit_b]",
        "] + bench_args + [commit_a,"
    ],
    [
        "\"\"\"ðŸ’» Launch IPython shell with PYTHONPATH set",
        "\"\"\"ðŸ’» Launch IPython shell with PYTHONPATH"
    ],
    [
        "OPTIONS are passed through directly to IPython, e.g.:",
        "OPTIONS are passed through directly to IPython,"
    ],
    [
        "preimport = (r\"import numpy as np; \"",
        "preimport = (r\"import numpy as np;"
    ],
    [
        "\"\"\"ðŸ¦† Run Mypy tests for NumPy",
        "\"\"\"ðŸ¦† Run Mypy tests for"
    ],
    [
        "\"\"\"ðŸŽ‰ Generate release notes and validate",
        "\"\"\"ðŸŽ‰ Generate release notes"
    ],
    [
        "f\"Generating release notes for NumPy {version}\",",
        "f\"Generating release notes for NumPy"
    ],
    [
        "\"please install `towncrier` to use this command\"",
        "\"please install `towncrier` to"
    ],
    [
        "cmd = [\"towncrier\", \"build\", \"--version\", version, \"--yes\"]",
        "cmd = [\"towncrier\", \"build\","
    ],
    [
        "f\"`towncrier` failed returned {p.returncode} with error `{p.stderr}`\"",
        "f\"`towncrier` failed returned {p.returncode}"
    ],
    [
        "f\"Release notes successfully written to {output_path}\",",
        "f\"Release notes successfully"
    ],
    [
        "\"Verifying consumption of all news fragments\",",
        "\"Verifying consumption of"
    ],
    [
        "f\"{e.msg}. Install the missing packages to use this command.\"",
        "f\"{e.msg}. Install the missing packages to use"
    ],
    [
        "Check if all the test and .pyi files are installed after building.",
        "Check if all the test and .pyi files"
    ],
    [
        "the relative path to the directory where NumPy is installed after",
        "the relative path to the directory where NumPy is installed"
    ],
    [
        "The script will stop on encountering the first missing file in the install dir,",
        "The script will stop on encountering the"
    ],
    [
        "it will not give a full listing. This should be okay, because the script is",
        "it will not give a full listing. This should be"
    ],
    [
        "meant for use in CI so it's not like many files will be missing at once.",
        "meant for use in CI so it's not like many files will be missing"
    ],
    [
        "f\"Provided install dir {INSTALLED_DIR} does not exist\"",
        "f\"Provided install dir {INSTALLED_DIR}"
    ],
    [
        "raise Exception(\"Test files aren't expected to be installed in %s\"",
        "raise Exception(\"Test files aren't expected"
    ],
    [
        "\", found %s\" % (INSTALLED_DIR, installed_test_files))",
        "\", found %s\" %"
    ],
    [
        "print(\"----------- No test files were installed --------------\")",
        "print(\"----------- No test files were installed"
    ],
    [
        "\"%s is not installed\" % numpy_test_files[test_file]",
        "\"%s is not installed\" %"
    ],
    [
        "print(\"----------- All the test files were installed --------------\")",
        "print(\"----------- All the test files"
    ],
    [
        "raise Exception(\"%s is not installed\" % numpy_pyi_files[pyi_file])",
        "raise Exception(\"%s is not installed\" %"
    ],
    [
        "print(\"----------- All the necessary .pyi files \"",
        "print(\"----------- All the necessary .pyi"
    ],
    [
        "k: v for k, v in files.items() if not k.startswith('distutils')",
        "k: v for k, v"
    ],
    [
        "k: v for k, v in files.items() if 'pythoncapi-compat' not in k",
        "k: v for k, v in files.items() if 'pythoncapi-compat' not"
    ],
    [
        "raise ValueError(\"Incorrect number of input arguments, need \"",
        "raise ValueError(\"Incorrect number of input arguments,"
    ],
    [
        "if all_tags != {'runtime', 'python-runtime', 'devel', 'tests'}:",
        "if all_tags != {'runtime', 'python-runtime',"
    ],
    [
        "raise AssertionError(f\"Found unexpected install tag: {all_tags}\")",
        "raise AssertionError(f\"Found unexpected install"
    ],
    [
        "Script to download NumPy wheels from the Anaconda staging area.",
        "Script to download NumPy wheels from"
    ],
    [
        "\"\"\" Get wheel names from Anaconda HTML directory.",
        "\"\"\" Get wheel names from"
    ],
    [
        "This looks in the Anaconda multibuild-wheels-staging page and",
        "This looks in the Anaconda multibuild-wheels-staging"
    ],
    [
        "parses the HTML to get all the wheel names for a release version.",
        "parses the HTML to get all the wheel"
    ],
    [
        "The release wheels for the given NumPy version are downloaded",
        "The release wheels for the given NumPy version"
    ],
    [
        "Directory in which to download the wheels.",
        "Directory in which to download the"
    ],
    [
        "with http.request(\"GET\", wheel_url, preload_content=False,) as r:",
        "with http.request(\"GET\", wheel_url, preload_content=False,) as"
    ],
    [
        "help=\"Directory in which to store downloaded wheels\\n\"",
        "help=\"Directory in which to"
    ],
    [
        "help=\"only list available wheels, do not download\")",
        "help=\"only list available wheels,"
    ],
    [
        "f\"{wheelhouse} wheelhouse directory is not present.\"",
        "f\"{wheelhouse} wheelhouse directory is not"
    ],
    [
        "\" Perhaps you need to use the '-w' flag to specify one.\")",
        "\" Perhaps you need to use the '-w'"
    ],
    [
        "- Check for a NumPy submodule whether the objects in its __all__ dict",
        "- Check for a NumPy submodule whether the objects"
    ],
    [
        "correspond to the objects included in the reference guide.",
        "correspond to the objects included in the reference"
    ],
    [
        "- Check example blocks in RST files",
        "- Check example blocks in RST"
    ],
    [
        "Note that this is a helper script to be able to check if things are missing;",
        "Note that this is a helper script to be able to check if"
    ],
    [
        "the output of this script does need to be checked manually.  In some cases",
        "the output of this script does need to be checked manually."
    ],
    [
        "objects are left out of the refguide for a good reason (it's an alias of",
        "objects are left out of the refguide for a good reason (it's an"
    ],
    [
        "another function, or deprecated, or ...)",
        "another function, or"
    ],
    [
        "Another use of this helper script is to check validity of code samples",
        "Another use of this helper script is to check validity"
    ],
    [
        "Return relative or absolute path name, whichever is shortest.",
        "Return relative or absolute path name, whichever"
    ],
    [
        "Relative path or absolute path based on current working directory",
        "Relative path or absolute path based on current"
    ],
    [
        "Finds the occurrences of function names, special directives like data",
        "Finds the occurrences of function names,"
    ],
    [
        "and functions and scipy constants in the docstrings of `module`. The",
        "and functions and scipy constants in the docstrings"
    ],
    [
        "dashes, and an explanation; only function names listed in",
        "dashes, and an explanation; only"
    ],
    [
        "refguide are formatted like this (mostly, there may be some false",
        "refguide are formatted like this (mostly, there"
    ],
    [
        "* special directives, such as data and function",
        "* special directives, such"
    ],
    [
        "The `names_dict` is updated by reference and accessible in calling method",
        "The `names_dict` is updated by reference and accessible in calling"
    ],
    [
        "The module, whose docstrings is to be searched",
        "The module, whose docstrings is to be"
    ],
    [
        "Dictionary which contains module name as key and a set of found",
        "Dictionary which contains module name as"
    ],
    [
        "function names and directives as value",
        "function names and directives as"
    ],
    [
        "patterns = [re.compile(pattern) for pattern in patterns]",
        "patterns = [re.compile(pattern) for pattern"
    ],
    [
        "Return a copy of the __all__ dict with irrelevant items removed.",
        "Return a copy of the __all__ dict"
    ],
    [
        "The module whose __all__ dict has to be processed",
        "The module whose __all__ dict has to"
    ],
    [
        "List of callable and deprecated sub modules",
        "List of callable and deprecated sub"
    ],
    [
        "List of non callable or non deprecated sub modules",
        "List of non callable or non"
    ],
    [
        "List of remaining types of sub modules",
        "List of remaining types of"
    ],
    [
        "all_dict = [name for name in all_dict",
        "all_dict = [name for name in"
    ],
    [
        "for name in ['absolute_import', 'division', 'print_function']:",
        "for name in"
    ],
    [
        "all_dict = [name for name in all_dict",
        "all_dict = [name for name in"
    ],
    [
        "Return sets of objects from all_dict.",
        "Return sets of objects from"
    ],
    [
        "List of non deprecated sub modules for module_name",
        "List of non deprecated"
    ],
    [
        "List of sub modules for module_name",
        "List of sub"
    ],
    [
        "Set of function names or special directives present in",
        "Set of function names or special"
    ],
    [
        "if re.match(pat, module_name + '.' + name):",
        "if re.match(pat, module_name + '.' +"
    ],
    [
        "if re.match(pat, module_name + '.' + name):",
        "if re.match(pat, module_name +"
    ],
    [
        "Check if module `f` is deprecated",
        "Check if module"
    ],
    [
        "def check_items(all_dict, names, deprecated, others, module_name, dots=True):",
        "def check_items(all_dict, names, deprecated,"
    ],
    [
        "Check that `all_dict` is consistent with the `names` in `module_name`",
        "Check that `all_dict` is consistent with the"
    ],
    [
        "For instance, that there are no deprecated or extra objects.",
        "For instance, that there are no deprecated or extra"
    ],
    [
        "Whether to print a dot for each check",
        "Whether to print a"
    ],
    [
        "output += \"Non-deprecated objects in __all__: %i\\n\" % num_all",
        "output += \"Non-deprecated objects in __all__: %i\\n\" %"
    ],
    [
        "output += \"Objects in refguide: %i\\n\\n\" % num_ref",
        "output += \"Objects in refguide:"
    ],
    [
        "only_all, only_ref, missing = compare(all_dict, others, names, module_name)",
        "only_all, only_ref, missing = compare(all_dict, others,"
    ],
    [
        "output += \"Deprecated objects in refguide::\\n\\n\"",
        "output += \"Deprecated objects in"
    ],
    [
        "output += \"    \" + name + \"\\n\"",
        "output += \" \""
    ],
    [
        "output += \"    \" + name + \"\\n\"",
        "output += \" \" + name +"
    ],
    [
        "output += \"\\nThis issue can be fixed by adding these objects to\\n\"",
        "output += \"\\nThis issue can be fixed"
    ],
    [
        "output += \"the function listing in __init__.py for this module\\n\"",
        "output += \"the function listing in __init__.py for"
    ],
    [
        "output += \"    \" + name + \"\\n\"",
        "output += \" \" + name +"
    ],
    [
        "output += \"\\nThis issue should likely be fixed by removing these objects\\n\"",
        "output += \"\\nThis issue should likely be"
    ],
    [
        "output += \"from the function listing in __init__.py for this module\\n\"",
        "output += \"from the function listing in __init__.py"
    ],
    [
        "output += \"or adding them to __all__.\\n\"",
        "output += \"or adding them to"
    ],
    [
        "output += \"    \" + name + \"\\n\"",
        "output += \" \" +"
    ],
    [
        "Validates the doc string in a snippet of documentation",
        "Validates the doc string in a snippet of"
    ],
    [
        "File name for which the doc string is to be validated",
        "File name for which the doc string is to be"
    ],
    [
        "Whether to print a dot symbol for each check",
        "Whether to print a dot symbol for"
    ],
    [
        "return False, \"ERROR: %s: no documentation\" % (name,)",
        "return False, \"ERROR: %s:"
    ],
    [
        "'mod', 'doc', 'currentmodule', 'autosummary', 'data', 'attr',",
        "'mod', 'doc', 'currentmodule',"
    ],
    [
        "'ref', 'func', 'toctree', 'moduleauthor', 'term', 'c:member',",
        "'ref', 'func', 'toctree', 'moduleauthor', 'term',"
    ],
    [
        "'sectionauthor', 'codeauthor', 'eq', 'doi', 'DOI', 'arXiv', 'arxiv'",
        "'sectionauthor', 'codeauthor', 'eq', 'doi', 'DOI',"
    ],
    [
        "skip_types = (dict, str, unicode, float, int)",
        "skip_types = (dict, str, unicode,"
    ],
    [
        "skip_types = (dict, str, float, int)",
        "skip_types = (dict, str, float,"
    ],
    [
        "full_name = module.__name__ + '.' + name",
        "full_name = module.__name__ +"
    ],
    [
        "results.append((full_name, False, \"%s has no docstring\" % (full_name,)))",
        "results.append((full_name, False, \"%s has no docstring\" %"
    ],
    [
        "msg = (\"Docstring contains a non-printable character %r! \"",
        "msg = (\"Docstring contains a"
    ],
    [
        "file_full_name = src_file + ':' + full_name",
        "file_full_name = src_file + ':'"
    ],
    [
        "Validates the docstrings of all the pre decided set of",
        "Validates the docstrings of all the pre decided"
    ],
    [
        "modules for errors and docstring standards.",
        "modules for errors and docstring"
    ],
    [
        "nargs='*', help=\"Submodules to check (default: all public)\")",
        "nargs='*', help=\"Submodules to check"
    ],
    [
        "print(\"Running checks for %d modules:\" % (len(modules),))",
        "print(\"Running checks for %d"
    ],
    [
        "mod_results += check_items(all_dict, names, deprecated, others,",
        "mod_results += check_items(all_dict, names, deprecated,"
    ],
    [
        "for name, success, output in mod_results:",
        "for name, success, output in"
    ],
    [
        "Check the blas version is blas from scipy-openblas and is higher than",
        "Check the blas version is blas from scipy-openblas and"
    ],
    [
        "Script to generate contributor and pull request lists",
        "Script to generate contributor and pull request"
    ],
    [
        "This script generates contributor and pull request lists for release",
        "This script generates contributor and pull request lists for"
    ],
    [
        "order to have sufficient bandwidth, you can get one following the directions at",
        "order to have sufficient bandwidth, you can get one following the"
    ],
    [
        "Don't add any scope, as the default is read access to public information. The",
        "Don't add any scope, as the default is read"
    ],
    [
        "token may be stored in an environment variable as you only get one chance to",
        "token may be stored in an environment variable as you only get"
    ],
    [
        "Some code was copied from scipy `tools/gh_list.py` and `tools/authors.py`.",
        "Some code was copied from"
    ],
    [
        "From the bash command line with $GITHUB token::",
        "From the bash command line with $GITHUB"
    ],
    [
        "A total of %d people contributed to this release.  People with a \"+\" by their",
        "A total of %d people contributed to this release. People with a \"+\" by"
    ],
    [
        "names contributed a patch for the first time.",
        "names contributed a patch"
    ],
    [
        "A total of %d pull requests were merged for this release.",
        "A total of %d pull requests were merged for"
    ],
    [
        "lst_release, cur_release = [r.strip() for r in revision_range.split('..')]",
        "lst_release, cur_release = [r.strip() for r in"
    ],
    [
        "authors_new = [s + ' +' for s in authors_cur - authors_pre]",
        "authors_new = [s + ' +' for s"
    ],
    [
        "prs = [repo.get_pull(n) for n in prnums]",
        "prs = [repo.get_pull(n) for n in"
    ],
    [
        "lst_release, cur_release = [r.strip() for r in revision_range.split('..')]",
        "lst_release, cur_release = [r.strip() for r in"
    ],
    [
        "\"\"\"repl to add an escaped space following a code block if needed\"\"\"",
        "\"\"\"repl to add an escaped space following"
    ],
    [
        "title = re.sub(r\"\\s+\", \" \", pull.title.strip())",
        "title = re.sub(r\"\\s+\","
    ],
    [
        "parser = ArgumentParser(description=\"Generate author/pr lists for release\")",
        "parser = ArgumentParser(description=\"Generate author/pr"
    ],
    [
        "count = [(x, result.count(x), repo) for x in u]",
        "count = [(x, result.count(x), repo) for"
    ],
    [
        "def run_ruff(self, fix: bool) -> tuple[int, str]:",
        "def run_ruff(self, fix: bool) -> tuple[int,"
    ],
    [
        "Unlike pycodestyle, ruff by itself is not capable of limiting",
        "Unlike pycodestyle, ruff by itself is not capable of"
    ],
    [
        "its output to the given diff.",
        "its output to"
    ],
    [
        "def run_lint(self, fix: bool) -> None:",
        "def run_lint(self, fix: bool)"
    ],
    [
        "were accepted before. For instance, '\\(' was previously accepted but must now",
        "were accepted before. For instance, '\\(' was previously"
    ],
    [
        "be written as '\\\\(' or r'\\('.",
        "be written as '\\\\(' or"
    ],
    [
        "Checks for deprecated escape sequences in ``*.py files``. If `root` is a",
        "Checks for deprecated escape sequences in ``*.py files``. If `root` is"
    ],
    [
        "file, that file is checked, if `root` is a directory all ``*.py`` files",
        "file, that file is checked, if `root`"
    ],
    [
        "found in a recursive descent are checked.",
        "found in a recursive"
    ],
    [
        "If a deprecated escape sequence is found, the file and line where found is",
        "If a deprecated escape sequence is found,"
    ],
    [
        "printed. Note that for multiline strings the line where the string ends is",
        "printed. Note that for multiline strings the line"
    ],
    [
        "printed and the error(s) are somewhere in the body of the string.",
        "printed and the error(s) are somewhere in the body"
    ],
    [
        "paths = base.rglob(\"*.py\") if base.is_dir() else [base]",
        "paths = base.rglob(\"*.py\") if base.is_dir()"
    ],
    [
        "print('line: ', e.lineno, ': ', e.message)",
        "print('line: ', e.lineno,"
    ],
    [
        "parser = ArgumentParser(description=\"Find deprecated escaped characters\")",
        "parser = ArgumentParser(description=\"Find"
    ],
    [
        "parser.add_argument('root', help='directory or file to be checked')",
        "parser.add_argument('root', help='directory or file to be"
    ],
    [
        "\"\"\"Find the functions in a module missing type annotations.",
        "\"\"\"Find the functions in a module missing"
    ],
    [
        "and it will print out a list of functions in the module that don't",
        "and it will print out a list of functions in the module that"
    ],
    [
        "\"\"\"Find top-level attributes/functions/classes in stubs files.",
        "\"\"\"Find top-level attributes/functions/classes in"
    ],
    [
        "Do this by walking the stubs ast. See e.g.",
        "Do this by walking the"
    ],
    [
        "for more information on working with Python's ast.",
        "for more information on working with Python's"
    ],
    [
        "attribute for attribute in dir(module) if not attribute.startswith(\"_\")",
        "attribute for attribute in dir(module)"
    ],
    [
        "missing = module_attributes - stubs_attributes - exclude_list",
        "missing = module_attributes - stubs_attributes -"
    ],
    [
        "\"Test ArrayZ resize method, negative length\"",
        "\"Test ArrayZ resize"
    ],
    [
        "\"Test ArrayZ __setitem__ method, negative index\"",
        "\"Test ArrayZ __setitem__ method,"
    ],
    [
        "\"Test ArrayZ __setitem__ method, out-of-range index\"",
        "\"Test ArrayZ __setitem__"
    ],
    [
        "\"Test ArrayZ __getitem__ method, negative index\"",
        "\"Test ArrayZ __getitem__"
    ],
    [
        "\"Test ArrayZ __getitem__ method, out-of-range index\"",
        "\"Test ArrayZ __getitem__ method,"
    ],
    [
        "self.array[i, j] = i + j",
        "self.array[i, j] ="
    ],
    [
        "\"Test Farray size constructor, negative nrows\"",
        "\"Test Farray size constructor, negative"
    ],
    [
        "\"Test Farray size constructor, negative ncols\"",
        "\"Test Farray size constructor,"
    ],
    [
        "self.array[i, j] = i * j",
        "self.array[i, j] ="
    ],
    [
        "self.assertTrue(self.array[i, j] == i * j)",
        "self.assertTrue(self.array[i, j] == i"
    ],
    [
        "\"Test Farray __setitem__ method, negative row\"",
        "\"Test Farray __setitem__"
    ],
    [
        "\"Test Farray __setitem__ method, negative col\"",
        "\"Test Farray __setitem__ method, negative"
    ],
    [
        "\"Test Farray __setitem__ method, out-of-range row\"",
        "\"Test Farray __setitem__ method, out-of-range"
    ],
    [
        "\"Test Farray __setitem__ method, out-of-range col\"",
        "\"Test Farray __setitem__"
    ],
    [
        "\"Test Farray __getitem__ method, negative row\"",
        "\"Test Farray __getitem__ method,"
    ],
    [
        "\"Test Farray __getitem__ method, negative col\"",
        "\"Test Farray __getitem__ method, negative"
    ],
    [
        "\"Test Farray __getitem__ method, out-of-range row\"",
        "\"Test Farray __getitem__ method, out-of-range"
    ],
    [
        "\"Test Farray __getitem__ method, out-of-range col\"",
        "\"Test Farray __getitem__"
    ],
    [
        "self.array[i, j] = i + j",
        "self.array[i, j] = i"
    ],
    [
        "self.array[i, j] = i - j",
        "self.array[i, j] = i"
    ],
    [
        "self.array[i, j] = i + j",
        "self.array[i, j] ="
    ],
    [
        "self.assertTrue(a[i, j] == i + j)",
        "self.assertTrue(a[i, j] =="
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test norm function with bad list\"",
        "\"Test norm function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test norm function with wrong dimensions\"",
        "\"Test norm function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test norm function with wrong size\"",
        "\"Test norm function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test max function with bad list\"",
        "\"Test max function with bad"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test max function with wrong dimensions\"",
        "\"Test max function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test min function with bad list\"",
        "\"Test min function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test min function with wrong dimensions\"",
        "\"Test min function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test scale function with wrong type\"",
        "\"Test scale function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test scale function with wrong dimensions\"",
        "\"Test scale function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test scale function with wrong size\"",
        "\"Test scale function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test ceil function with wrong type\"",
        "\"Test ceil function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test ceil function with wrong dimensions\"",
        "\"Test ceil function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "description = \"Functions that work on arrays\",",
        "description = \"Functions that work on"
    ],
    [
        "py_modules = [\"Array\", \"Farray\", \"Vector\", \"Matrix\", \"Tensor\",",
        "py_modules = [\"Array\", \"Farray\", \"Vector\", \"Matrix\","
    ],
    [
        "ext_modules = [_Array, _Farray, _Vector, _Matrix, _Tensor,",
        "ext_modules = [_Array, _Farray, _Vector,"
    ],
    [
        "\"Test norm function with bad list\"",
        "\"Test norm function with"
    ],
    [
        "\"Test norm function with wrong dimensions\"",
        "\"Test norm function with wrong"
    ],
    [
        "\"Test norm function with wrong size\"",
        "\"Test norm function with wrong"
    ],
    [
        "\"Test max function with bad list\"",
        "\"Test max function with"
    ],
    [
        "\"Test max function with wrong dimensions\"",
        "\"Test max function with wrong"
    ],
    [
        "\"Test min function with bad list\"",
        "\"Test min function"
    ],
    [
        "\"Test min function with wrong dimensions\"",
        "\"Test min function with"
    ],
    [
        "\"Test scale function with wrong type\"",
        "\"Test scale function with"
    ],
    [
        "\"Test scale function with wrong dimensions\"",
        "\"Test scale function with wrong"
    ],
    [
        "\"Test scale function with wrong size\"",
        "\"Test scale function with"
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function with wrong"
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function with"
    ],
    [
        "\"Test ceil function with wrong type\"",
        "\"Test ceil function with"
    ],
    [
        "\"Test ceil function with wrong dimensions\"",
        "\"Test ceil function with"
    ],
    [
        "\"Test Fortran matrix initialized from reshaped NumPy fortranarray\"",
        "\"Test Fortran matrix initialized"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test Fortran matrix initialized from nested list fortranarray\"",
        "\"Test Fortran matrix initialized"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test length function with bad list\"",
        "\"Test length function with bad"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test length function with wrong size\"",
        "\"Test length function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test length function with wrong dimensions\"",
        "\"Test length function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test prod function with bad list\"",
        "\"Test prod function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test prod function with wrong dimensions\"",
        "\"Test prod function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test sum function with bad list\"",
        "\"Test sum function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test sum function with wrong dimensions\"",
        "\"Test sum function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test reverse function with wrong dimensions\"",
        "\"Test reverse function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test reverse function with wrong size\"",
        "\"Test reverse function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test reverse function with wrong type\"",
        "\"Test reverse function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test ones function with wrong dimensions\"",
        "\"Test ones function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test ones function with wrong type\"",
        "\"Test ones function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test zeros function with wrong dimensions\"",
        "\"Test zeros function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test zeros function with wrong type\"",
        "\"Test zeros function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test twos function with non-integer dimension\"",
        "\"Test twos function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test threes function with non-integer dimension\"",
        "\"Test threes function with non-integer"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test det function with bad list\"",
        "\"Test det function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test det function with wrong dimensions\"",
        "\"Test det function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test det function with wrong size\"",
        "\"Test det function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test max function with bad list\"",
        "\"Test max function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test max function with wrong dimensions\"",
        "\"Test max function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test min function with bad list\"",
        "\"Test min function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "matrix = [[\"nine\", \"eight\"], [\"seven\", \"six\"]]",
        "matrix = [[\"nine\", \"eight\"],"
    ],
    [
        "\"Test min function with wrong dimensions\"",
        "\"Test min function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test scale function with wrong dimensions\"",
        "\"Test scale function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test scale function with wrong size\"",
        "\"Test scale function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test scale function with wrong type\"",
        "\"Test scale function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test floor function with wrong dimensions\"",
        "\"Test floor function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test ceil function with wrong dimensions\"",
        "\"Test ceil function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test ceil function with wrong dimensions\"",
        "\"Test ceil function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test Process function with non-contiguous array, which should raise an error\"",
        "\"Test Process function with non-contiguous array, which should raise"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(\"The following files were not found by towncrier:\")",
        "print(\"The following files were"
    ],
    [
        "description='Upload files to a remote repo, replacing existing content'",
        "description='Upload files to a remote repo, replacing"
    ],
    [
        "parser.add_argument('dir', help='directory of which content will be uploaded')",
        "parser.add_argument('dir', help='directory of which content"
    ],
    [
        "parser.add_argument('remote', help='remote to which content will be pushed')",
        "parser.add_argument('remote', help='remote to which"
    ],
    [
        "help='hereby acknowledge that remote repo content will be overwritten'",
        "help='hereby acknowledge that remote repo content will"
    ],
    [
        "count = len([name for name in os.listdir(args.dir)",
        "count = len([name for name in"
    ],
    [
        "print(f\"Expected {args.count} top-directory files to upload, got {count}\")",
        "print(f\"Expected {args.count} top-directory files to upload, got"
    ],
    [
        "pipe = None if stdout else subprocess.DEVNULL",
        "pipe = None if stdout else"
    ],
    [
        "print(\"\\n! Error executing: `%s;` aborting\" % ' '.join(cmd))",
        "print(\"\\n! Error executing: `%s;`"
    ],
    [
        "print('- committing new content: \"%s\"' % args.message)",
        "print('- committing new content: \"%s\"'"
    ],
    [
        "run(['git', 'commit', '--allow-empty', '-m', args.message], stdout=False)",
        "run(['git', 'commit', '--allow-empty', '-m',"
    ],
    [
        "print('- uploading as %s <%s>' % (args.committer, args.email))",
        "print('- uploading as %s"
    ],
    [
        "print('\\n!! No `--force` argument specified; aborting')",
        "print('\\n!! No `--force` argument specified;"
    ],
    [
        "print('!! Before enabling that flag, make sure you know what it does\\n')",
        "print('!! Before enabling that flag, make sure you know"
    ],
    [
        "Check the presence of a LICENSE.txt in the installed module directory,",
        "Check the presence of a LICENSE.txt in the installed module"
    ],
    [
        "and that it appears to contain text prevalent for a NumPy binary",
        "and that it appears to contain text prevalent for a"
    ],
    [
        "ok = \"Copyright (c)\" in text and re.search(",
        "ok = \"Copyright (c)\""
    ],
    [
        "r\"This binary distribution of \\w+ also bundles the following software\",",
        "r\"This binary distribution of \\w+ also"
    ],
    [
        "\"ERROR: License text {} does not contain expected \"",
        "\"ERROR: License text {} does"
    ],
    [
        "A script to create C code-coverage reports based on the output of",
        "A script to create C code-coverage reports based"
    ],
    [
        "\"\"\"Custom HTML formatter to insert extra information with the lines.\"\"\"",
        "\"\"\"Custom HTML formatter to insert extra information"
    ],
    [
        "for i, (c, t) in enumerate(HtmlFormatter.wrap(self, source, outfile)):",
        "for i, (c, t) in enumerate(HtmlFormatter.wrap(self, source,"
    ],
    [
        "with open(os.path.join(root, self.clean_path(path)), \"w\") as fd:",
        "with open(os.path.join(root, self.clean_path(path)), \"w\") as"
    ],
    [
        "with open(os.path.join(root, 'index.html'), 'w') as fd:",
        "with open(os.path.join(root, 'index.html'), 'w')"
    ],
    [
        "help='Destination directory for output (default: %(default)s)')",
        "help='Destination directory for output"
    ],
    [
        "help='Regex pattern to match against source file paths '",
        "help='Regex pattern to match against"
    ],
    [
        "\"If option not provided, both will be generated.\")",
        "\"If option not provided, both will"
    ],
    [
        "This is the namespace for inspection functions as defined by the array API",
        "This is the namespace for inspection functions as defined by the"
    ],
    [
        "Get the array API inspection namespace for NumPy.",
        "Get the array API"
    ],
    [
        "The array API inspection namespace defines the following functions:",
        "The array API inspection namespace defines the following"
    ],
    [
        "The array API inspection namespace for NumPy.",
        "The array API inspection"
    ],
    [
        "Return a dictionary of array API library capabilities.",
        "Return a dictionary of array API library"
    ],
    [
        "The resulting dictionary has the following keys:",
        "The resulting dictionary has"
    ],
    [
        "- **\"boolean indexing\"**: boolean indicating whether an array library",
        "- **\"boolean indexing\"**: boolean indicating whether an"
    ],
    [
        "supports boolean indexing. Always ``True`` for NumPy.",
        "supports boolean indexing. Always"
    ],
    [
        "- **\"data-dependent shapes\"**: boolean indicating whether an array",
        "- **\"data-dependent shapes\"**: boolean indicating"
    ],
    [
        "library supports data-dependent output shapes. Always ``True`` for",
        "library supports data-dependent output shapes. Always ``True``"
    ],
    [
        "A dictionary of array API library capabilities.",
        "A dictionary of array"
    ],
    [
        "The default device used for new NumPy arrays.",
        "The default device used for new"
    ],
    [
        "For NumPy, this always returns ``'cpu'``.",
        "For NumPy, this always"
    ],
    [
        "The default device used for new NumPy arrays.",
        "The default device used for new"
    ],
    [
        "The default data types used for new NumPy arrays.",
        "The default data types used"
    ],
    [
        "For NumPy, this always returns the following dictionary:",
        "For NumPy, this always returns the following"
    ],
    [
        "The device to get the default data types for. For NumPy, only",
        "The device to get the default data"
    ],
    [
        "A dictionary describing the default data types used for new NumPy",
        "A dictionary describing the default data types"
    ],
    [
        "if device not in [\"cpu\", None]:",
        "if device not in"
    ],
    [
        "'Device not understood. Only \"cpu\" is allowed, but received:'",
        "'Device not understood. Only \"cpu\" is"
    ],
    [
        "The array API data types supported by NumPy.",
        "The array API data types supported by"
    ],
    [
        "Note that this function only returns data types that are defined by",
        "Note that this function only returns data types"
    ],
    [
        "The device to get the data types for. For NumPy, only ``'cpu'`` is",
        "The device to get the data types for. For NumPy,"
    ],
    [
        "kind : str or tuple of str, optional",
        "kind : str or tuple of"
    ],
    [
        "The kind of data types to return. If ``None``, all data types are",
        "The kind of data types to return. If"
    ],
    [
        "returned. If a string, only data types of that kind are returned.",
        "returned. If a string, only data types of"
    ],
    [
        "If a tuple, a dictionary containing the union of the given kinds",
        "If a tuple, a dictionary containing the union of the"
    ],
    [
        "is returned. The following kinds are supported:",
        "is returned. The following kinds are"
    ],
    [
        "- ``'bool'``: boolean data types (i.e., ``bool``).",
        "- ``'bool'``: boolean data types (i.e.,"
    ],
    [
        "- ``'unsigned integer'``: unsigned integer data types (i.e.,",
        "- ``'unsigned integer'``: unsigned integer data"
    ],
    [
        "- ``'integral'``: integer data types. Shorthand for ``('signed",
        "- ``'integral'``: integer data"
    ],
    [
        "- ``'real floating'``: real-valued floating-point data types",
        "- ``'real floating'``: real-valued floating-point data"
    ],
    [
        "- ``'complex floating'``: complex floating-point data types (i.e.,",
        "- ``'complex floating'``: complex"
    ],
    [
        "- ``'numeric'``: numeric data types. Shorthand for ``('integral',",
        "- ``'numeric'``: numeric data"
    ],
    [
        "A dictionary mapping the names of data types to the corresponding",
        "A dictionary mapping the names of data types"
    ],
    [
        "if device not in [\"cpu\", None]:",
        "if device not"
    ],
    [
        "'Device not understood. Only \"cpu\" is allowed, but received:'",
        "'Device not understood. Only \"cpu\" is allowed, but"
    ],
    [
        "For NumPy, this always returns ``['cpu']``.",
        "For NumPy, this always"
    ],
    [
        "Pytest configuration and fixtures for the Numpy test suite.",
        "Pytest configuration and fixtures for the Numpy test"
    ],
    [
        "\"numpy-profile\" if os.path.isfile(_pytest_ini) else \"np.test() profile\"",
        "\"numpy-profile\" if os.path.isfile(_pytest_ini) else \"np.test()"
    ],
    [
        "\"valgrind_error: Tests that are known to error under valgrind.\")",
        "\"valgrind_error: Tests that are known to error under"
    ],
    [
        "\"leaks_references: Tests that are known to leak references.\")",
        "\"leaks_references: Tests that are known to leak"
    ],
    [
        "\"slow: Tests that are very slow.\")",
        "\"slow: Tests that are very"
    ],
    [
        "\"slow_pypy: Tests that are very slow on pypy.\")",
        "\"slow_pypy: Tests that are very"
    ],
    [
        "help=(\"Set amount of memory available for running the \"",
        "help=(\"Set amount of memory available for running the"
    ],
    [
        "\"test suite. This can result to tests requiring \"",
        "\"test suite. This can result to tests"
    ],
    [
        "\"especially large amounts of memory to be skipped. \"",
        "\"especially large amounts of memory to be"
    ],
    [
        "\"Equivalent to setting environment variable \"",
        "\"Equivalent to setting environment variable"
    ],
    [
        "if NOGIL_BUILD and not gil_enabled_at_start and sys._is_gil_enabled():",
        "if NOGIL_BUILD and not gil_enabled_at_start and"
    ],
    [
        "tr.line(\"The GIL was re-enabled at runtime during the tests.\")",
        "tr.line(\"The GIL was re-enabled at runtime during"
    ],
    [
        "tr.line(\"This can happen with no test failures if the RuntimeWarning\")",
        "tr.line(\"This can happen with no test failures if"
    ],
    [
        "tr.line(\"raised by Python when this happens is filtered by a test.\")",
        "tr.line(\"raised by Python when this happens is filtered"
    ],
    [
        "tr.line(\"Please ensure all new C modules declare support for running\")",
        "tr.line(\"Please ensure all new C modules"
    ],
    [
        "tr.line(\"without the GIL. Any new tests that intentionally imports \")",
        "tr.line(\"without the GIL. Any new"
    ],
    [
        "tr.line(\"code that re-enables the GIL should do so in a subprocess.\")",
        "tr.line(\"code that re-enables the GIL should do"
    ],
    [
        "Check FPU precision mode was not changed during test collection.",
        "Check FPU precision mode was"
    ],
    [
        "The clumsy way we do it here is mainly necessary because numpy",
        "The clumsy way we do it here"
    ],
    [
        "still uses yield tests, which can execute code at test collection",
        "still uses yield tests, which can execute code"
    ],
    [
        "Check FPU precision mode was not changed during the test.",
        "Check FPU precision mode was not changed"
    ],
    [
        "\"\"\"Filter out the wall of DeprecationWarnings.",
        "\"\"\"Filter out the wall"
    ],
    [
        "'basics.subclassing.rst': '.. testcode:: admonitions not understood',",
        "'basics.subclassing.rst': '.. testcode::"
    ],
    [
        "params=[\"unset\", None, pd_NA, np.nan, float(\"nan\"), \"__nan__\"],",
        "params=[\"unset\", None, pd_NA, np.nan, float(\"nan\"),"
    ],
    [
        "ids=[\"unset\", \"None\", \"pandas.NA\", \"np.nan\", \"float('nan')\", \"string nan\"],",
        "ids=[\"unset\", \"None\", \"pandas.NA\", \"np.nan\", \"float('nan')\","
    ],
    [
        "This module raises a RuntimeError if an attempt to reload it is made. In that",
        "This module raises a RuntimeError if an attempt to"
    ],
    [
        "way the identities of the classes defined here are fixed and will remain so",
        "way the identities of the classes defined here are fixed and"
    ],
    [
        "even if numpy itself is reloaded. In particular, a function like the following",
        "even if numpy itself is reloaded. In particular, a"
    ],
    [
        "will still work correctly after numpy is reloaded::",
        "will still work correctly after numpy"
    ],
    [
        "That was not the case when the singleton classes were defined in the numpy",
        "That was not the case when the singleton classes were defined"
    ],
    [
        "from ._utils import set_module as _set_module",
        "from ._utils import set_module"
    ],
    [
        "raise RuntimeError('Reloading numpy._globals is not allowed')",
        "raise RuntimeError('Reloading numpy._globals is not"
    ],
    [
        "The instance of this class may be used as the default value assigned to a",
        "The instance of this class may be used as the default value assigned"
    ],
    [
        "keyword if no other obvious default (e.g., `None`) is suitable,",
        "keyword if no other obvious default (e.g., `None`)"
    ],
    [
        "Common reasons for using this keyword are:",
        "Common reasons for using this keyword"
    ],
    [
        "- A new keyword is added to a function, and that function forwards its",
        "- A new keyword is added to a function, and"
    ],
    [
        "inputs to another function or method which can be defined outside of",
        "inputs to another function or method which"
    ],
    [
        "NumPy. For example, ``np.std(x)`` calls ``x.std``, so when a ``keepdims``",
        "NumPy. For example, ``np.std(x)`` calls ``x.std``,"
    ],
    [
        "keyword was added that could only be forwarded if the user explicitly",
        "keyword was added that could only be"
    ],
    [
        "specified ``keepdims``; downstream array libraries may not have added",
        "specified ``keepdims``; downstream array libraries may not have"
    ],
    [
        "the same keyword, so adding ``x.std(..., keepdims=keepdims)``",
        "the same keyword, so adding ``x.std(...,"
    ],
    [
        "unconditionally could have broken previously working code.",
        "unconditionally could have broken previously working"
    ],
    [
        "- A keyword is being deprecated, and a deprecation warning must only be",
        "- A keyword is being deprecated, and a deprecation warning"
    ],
    [
        "emitted when the keyword is used.",
        "emitted when the keyword is"
    ],
    [
        "An enumeration for the copy modes supported",
        "An enumeration for the copy modes"
    ],
    [
        "by numpy.copy() and numpy.array(). The following three modes are supported,",
        "by numpy.copy() and numpy.array(). The following three modes"
    ],
    [
        "- ALWAYS: This means that a deep copy of the input",
        "- ALWAYS: This means that a deep copy"
    ],
    [
        "- IF_NEEDED: This means that a deep copy of the input",
        "- IF_NEEDED: This means that a deep copy"
    ],
    [
        "array will be taken only if necessary.",
        "array will be taken"
    ],
    [
        "- NEVER: This means that the deep copy will never be taken.",
        "- NEVER: This means that the"
    ],
    [
        "If a copy cannot be avoided then a `ValueError` will be",
        "If a copy cannot be avoided then"
    ],
    [
        "Note that the buffer-protocol could in theory do copies.  NumPy currently",
        "Note that the buffer-protocol could in theory do copies. NumPy"
    ],
    [
        "assumes an object exporting the buffer protocol will never do this.",
        "assumes an object exporting the buffer protocol will never"
    ],
    [
        "raise ValueError(f\"{self} is neither True nor False.\")",
        "raise ValueError(f\"{self} is neither True"
    ],
    [
        "help=\"Compile flag needed when using the NumPy headers.\",",
        "help=\"Compile flag needed when"
    ],
    [
        "help=(\"Print the pkgconfig directory in which `numpy.pc` is stored \"",
        "help=(\"Print the pkgconfig directory in which"
    ],
    [
        "_path = Path(get_include()) / '..' / 'lib' / 'pkgconfig'",
        "_path = Path(get_include()) / '..' /"
    ],
    [
        "Documentation is available in two forms: docstrings provided",
        "Documentation is available in two forms: docstrings"
    ],
    [
        "with the code, and a loose standing reference guide, available from",
        "with the code, and a loose standing"
    ],
    [
        "We recommend exploring the docstrings using",
        "We recommend exploring the"
    ],
    [
        "`IPython <https://ipython.org>`_, an advanced Python shell with",
        "`IPython <https://ipython.org>`_, an advanced"
    ],
    [
        "TAB-completion and introspection capabilities.  See below for further",
        "TAB-completion and introspection capabilities."
    ],
    [
        "The docstring examples assume that `numpy` has been imported as ``np``::",
        "The docstring examples assume that `numpy` has been imported"
    ],
    [
        "Code snippets are indicated by three greater-than signs::",
        "Code snippets are indicated by three"
    ],
    [
        "Use the built-in ``help`` function to view a function's docstring::",
        "Use the built-in ``help`` function to view a"
    ],
    [
        "For some objects, ``np.info(obj)`` may provide additional help.  This is",
        "For some objects, ``np.info(obj)`` may provide additional help. This"
    ],
    [
        "particularly true if you see the line \"Help on ufunc object:\" at the top",
        "particularly true if you see the line"
    ],
    [
        "of the help() page.  Ufuncs are implemented in C, not Python, for speed.",
        "of the help() page. Ufuncs are implemented in C, not"
    ],
    [
        "The native Python help() does not know how to view their help, but our",
        "The native Python help() does not know how to view"
    ],
    [
        "Basic functions used by several sub-packages.",
        "Basic functions used by"
    ],
    [
        "Enhancements to distutils with support for",
        "Enhancements to distutils"
    ],
    [
        "Start IPython and import `numpy` usually under the alias ``np``: `import",
        "Start IPython and import `numpy` usually"
    ],
    [
        "numpy as np`.  Then, directly past or use the ``%cpaste`` magic to paste",
        "numpy as np`. Then, directly past or use the ``%cpaste``"
    ],
    [
        "examples into the shell.  To see which functions are available in `numpy`,",
        "examples into the shell. To see which functions are available"
    ],
    [
        "type ``np.<TAB>`` (where ``<TAB>`` refers to the TAB key), or use",
        "type ``np.<TAB>`` (where ``<TAB>`` refers to the"
    ],
    [
        "``np.*cos*?<ENTER>`` (where ``<ENTER>`` refers to the ENTER key) to narrow",
        "``np.*cos*?<ENTER>`` (where ``<ENTER>`` refers to the ENTER"
    ],
    [
        "down the list.  To view the docstring for a function, use",
        "down the list. To view the docstring for"
    ],
    [
        "``np.cos?<ENTER>`` (to view the docstring) and ``np.cos??<ENTER>`` (to view",
        "``np.cos?<ENTER>`` (to view the docstring)"
    ],
    [
        "Most of the functions in `numpy` return a copy of the array argument",
        "Most of the functions in `numpy` return a copy of the array"
    ],
    [
        "(e.g., `np.sort`).  In-place versions of these functions are often",
        "(e.g., `np.sort`). In-place versions of these functions are"
    ],
    [
        "Exceptions to this rule are documented.",
        "Exceptions to this rule are"
    ],
    [
        "msg = \"\"\"Error importing numpy: you should not try to import numpy from",
        "msg = \"\"\"Error importing numpy: you should"
    ],
    [
        "its source directory; please exit the numpy source tree, and relaunch",
        "its source directory; please exit the numpy source tree, and"
    ],
    [
        "abs, absolute, acos, acosh, add, all, allclose,",
        "abs, absolute, acos, acosh, add,"
    ],
    [
        "amax, amin, any, arange, arccos, arccosh, arcsin, arcsinh,",
        "amax, amin, any, arange, arccos,"
    ],
    [
        "bitwise_or, bitwise_right_shift, bitwise_xor, block, bool, bool_,",
        "bitwise_or, bitwise_right_shift, bitwise_xor, block, bool,"
    ],
    [
        "broadcast, busday_count, busday_offset, busdaycalendar, byte, bytes_,",
        "broadcast, busday_count, busday_offset, busdaycalendar, byte,"
    ],
    [
        "can_cast, cbrt, cdouble, ceil, character, choose, clip, clongdouble,",
        "can_cast, cbrt, cdouble, ceil, character, choose,"
    ],
    [
        "conj, conjugate, convolve, copysign, copyto, correlate, cos, cosh,",
        "conj, conjugate, convolve, copysign, copyto, correlate,"
    ],
    [
        "count_nonzero, cross, csingle, cumprod, cumsum, cumulative_prod,",
        "count_nonzero, cross, csingle, cumprod, cumsum,"
    ],
    [
        "einsum, einsum_path, empty, empty_like, equal, errstate, euler_gamma,",
        "einsum, einsum_path, empty, empty_like,"
    ],
    [
        "frexp, from_dlpack, frombuffer, fromfile, fromfunction, fromiter,",
        "frexp, from_dlpack, frombuffer, fromfile,"
    ],
    [
        "frompyfunc, fromstring, full, full_like, gcd, generic, geomspace,",
        "frompyfunc, fromstring, full, full_like, gcd,"
    ],
    [
        "greater_equal, half, heaviside, hstack, hypot, identity, iinfo,",
        "greater_equal, half, heaviside, hstack,"
    ],
    [
        "integer, intp, invert, is_busday, isclose, isdtype, isfinite,",
        "integer, intp, invert, is_busday, isclose, isdtype,"
    ],
    [
        "isfortran, isinf, isnan, isnat, isscalar, issubdtype, lcm, ldexp,",
        "isfortran, isinf, isnan, isnat,"
    ],
    [
        "left_shift, less, less_equal, lexsort, linspace, little_endian, log,",
        "left_shift, less, less_equal, lexsort,"
    ],
    [
        "logical_or, logical_xor, logspace, long, longdouble, longlong, matmul,",
        "logical_or, logical_xor, logspace, long, longdouble, longlong,"
    ],
    [
        "matvec, matrix_transpose, max, maximum, may_share_memory, mean, memmap,",
        "matvec, matrix_transpose, max, maximum, may_share_memory, mean,"
    ],
    [
        "min, min_scalar_type, minimum, mod, modf, moveaxis, multiply, nan,",
        "min, min_scalar_type, minimum, mod, modf,"
    ],
    [
        "ndarray, ndim, nditer, negative, nested_iters, newaxis, nextafter,",
        "ndarray, ndim, nditer, negative,"
    ],
    [
        "nonzero, not_equal, number, object_, ones, ones_like, outer, partition,",
        "nonzero, not_equal, number, object_, ones,"
    ],
    [
        "permute_dims, pi, positive, pow, power, printoptions, prod,",
        "permute_dims, pi, positive, pow, power, printoptions,"
    ],
    [
        "reciprocal, record, remainder, repeat, require, reshape, resize,",
        "reciprocal, record, remainder, repeat, require, reshape,"
    ],
    [
        "result_type, right_shift, rint, roll, rollaxis, round, sctypeDict,",
        "result_type, right_shift, rint, roll,"
    ],
    [
        "searchsorted, set_printoptions, setbufsize, seterr, seterrcall, shape,",
        "searchsorted, set_printoptions, setbufsize, seterr,"
    ],
    [
        "shares_memory, short, sign, signbit, signedinteger, sin, single, sinh,",
        "shares_memory, short, sign, signbit, signedinteger, sin,"
    ],
    [
        "size, sort, spacing, sqrt, square, squeeze, stack, std,",
        "size, sort, spacing, sqrt, square, squeeze,"
    ],
    [
        "str_, subtract, sum, swapaxes, take, tan, tanh, tensordot,",
        "str_, subtract, sum, swapaxes, take, tan, tanh,"
    ],
    [
        "ulonglong, unsignedinteger, unstack, ushort, var, vdot, vecdot,",
        "ulonglong, unsignedinteger, unstack, ushort, var,"
    ],
    [
        "vecmat, void, vstack, where, zeros, zeros_like",
        "vecmat, void, vstack, where, zeros,"
    ],
    [
        "from .lib import scimath as emath",
        "from .lib import scimath as"
    ],
    [
        "nanargmax, nanargmin, nancumprod, nancumsum, nanmax, nanmean,",
        "nanargmax, nanargmin, nancumprod, nancumsum, nanmax,"
    ],
    [
        "nanmedian, nanmin, nanpercentile, nanprod, nanquantile, nanstd,",
        "nanmedian, nanmin, nanpercentile, nanprod, nanquantile,"
    ],
    [
        "select, piecewise, trim_zeros, copy, iterable, percentile, diff,",
        "select, piecewise, trim_zeros, copy, iterable, percentile,"
    ],
    [
        "vectorize, asarray_chkfinite, average, bincount, digitize, cov,",
        "vectorize, asarray_chkfinite, average, bincount,"
    ],
    [
        "corrcoef, median, sinc, hamming, hanning, bartlett, blackman,",
        "corrcoef, median, sinc, hamming,"
    ],
    [
        "diag, diagflat, eye, fliplr, flipud, tri, triu, tril, vander,",
        "diag, diagflat, eye, fliplr, flipud, tri, triu, tril,"
    ],
    [
        "dstack, expand_dims, hsplit, kron, put_along_axis, row_stack, split,",
        "dstack, expand_dims, hsplit, kron,"
    ],
    [
        "iscomplexobj, isrealobj, imag, iscomplex, isreal, nan_to_num, real,",
        "iscomplexobj, isrealobj, imag, iscomplex, isreal,"
    ],
    [
        "from .lib._ufunclike_impl import fix, isneginf, isposinf",
        "from .lib._ufunclike_impl import fix,"
    ],
    [
        "poly, polyint, polyder, polyadd, polysub, polymul, polydiv, polyval,",
        "poly, polyint, polyder, polyadd, polysub, polymul, polydiv,"
    ],
    [
        "savetxt, loadtxt, genfromtxt, load, save, savez, packbits,",
        "savetxt, loadtxt, genfromtxt, load, save, savez,"
    ],
    [
        "ix_, c_, r_, s_, ogrid, mgrid, unravel_index, ravel_multi_index,",
        "ix_, c_, r_, s_, ogrid,"
    ],
    [
        "from . import matrixlib as _mat",
        "from . import matrixlib as"
    ],
    [
        "\"linalg\", \"fft\", \"dtypes\", \"random\", \"polynomial\", \"ma\",",
        "\"linalg\", \"fft\", \"dtypes\", \"random\","
    ],
    [
        "\"module 'numpy' has no attribute '{n}'.\\n\"",
        "\"module 'numpy' has"
    ],
    [
        "\"`np.{n}` was a deprecated alias for the builtin `{n}`. \"",
        "\"`np.{n}` was a deprecated alias for"
    ],
    [
        "\"To avoid this error in existing code, use `{n}` by itself. \"",
        "\"To avoid this error in existing code,"
    ],
    [
        "\"Doing this will not modify any behavior and is safe. {extended_msg}\\n\"",
        "\"Doing this will not modify any behavior"
    ],
    [
        "\"details and guidance see the original release note at:\\n\"",
        "\"details and guidance see the original release note"
    ],
    [
        "\"If you specifically wanted the numpy scalar type, use `np.{}` here.\")",
        "\"If you specifically wanted the numpy"
    ],
    [
        "\"your current use, check the release note link for \"",
        "\"your current use, check the release"
    ],
    [
        "raise AttributeError(\"`numpy.array_api` is not available from \"",
        "raise AttributeError(\"`numpy.array_api` is not available from"
    ],
    [
        "raise AttributeError(\"`numpy.distutils` is not available from \"",
        "raise AttributeError(\"`numpy.distutils` is not available"
    ],
    [
        "f\"In the future `np.{attr}` will be defined as the \"",
        "f\"In the future `np.{attr}` will be"
    ],
    [
        "\"`np.chararray` is deprecated and will be removed from \"",
        "\"`np.chararray` is deprecated and will be removed"
    ],
    [
        "\"the main namespace in the future. Use an array with a string \"",
        "\"the main namespace in the future. Use"
    ],
    [
        "raise AttributeError(\"module {!r} has no attribute \"",
        "raise AttributeError(\"module {!r} has"
    ],
    [
        "Quick sanity checks for common bugs caused by environment.",
        "Quick sanity checks for common bugs caused"
    ],
    [
        "There are some cases e.g. with wrong BLAS ABI that cause wrong",
        "There are some cases e.g. with wrong"
    ],
    [
        "results under specific runtime conditions that are not necessarily",
        "results under specific runtime conditions that are not"
    ],
    [
        "achieved during test suite runs, and it is useful to catch those early.",
        "achieved during test suite runs, and it is useful to catch those"
    ],
    [
        "msg = (\"The current Numpy installation ({!r}) fails to \"",
        "msg = (\"The current Numpy"
    ],
    [
        "\"pass simple sanity checks. This can be caused for example \"",
        "\"pass simple sanity checks. This can be caused"
    ],
    [
        "\"by incorrect BLAS library being linked in, or by mixing \"",
        "\"by incorrect BLAS library being linked in, or by mixing"
    ],
    [
        "\"package managers (pip, conda, apt, ...). Search closed \"",
        "\"package managers (pip, conda, apt, ...). Search closed"
    ],
    [
        "Quick Sanity check for Mac OS look for accelerate build bugs.",
        "Quick Sanity check for Mac OS look for accelerate"
    ],
    [
        "\"Polyfit sanity test emitted a warning, most likely due \"",
        "\"Polyfit sanity test emitted a warning, most likely due"
    ],
    [
        "\"to using a buggy Accelerate backend.\"",
        "\"to using a"
    ],
    [
        "\"\\nIf you compiled yourself, more information is available at:\"",
        "\"\\nIf you compiled yourself, more information is"
    ],
    [
        "\"\\nOtherwise report this to the vendor \"",
        "\"\\nOtherwise report this to the"
    ],
    [
        "We usually use madvise hugepages support, but on some old kernels it",
        "We usually use madvise hugepages support, but on"
    ],
    [
        "had a bug fix which probably fixed this:",
        "had a bug fix which"
    ],
    [
        "if sys.platform == \"linux\" and use_hugepage is None:",
        "if sys.platform == \"linux\" and use_hugepage is"
    ],
    [
        "kernel_version = tuple(int(v) for v in kernel_version)",
        "kernel_version = tuple(int(v) for v in"
    ],
    [
        "This module is home to specific dtypes related functionality and their classes.",
        "This module is home to specific dtypes related functionality"
    ],
    [
        "For more general information about dtypes, also see `numpy.dtype` and",
        "For more general information about dtypes,"
    ],
    [
        "Similar to the builtin ``types`` module, this submodule defines types (classes)",
        "Similar to the builtin ``types`` module, this submodule"
    ],
    [
        "that are not widely used directly.",
        "that are not widely used"
    ],
    [
        "The following are the classes of the corresponding NumPy dtype instances and",
        "The following are the classes of"
    ],
    [
        "NumPy scalar types.  The classes can be used in ``isinstance`` checks and can",
        "NumPy scalar types. The classes can be used in ``isinstance`` checks and"
    ],
    [
        "also be instantiated or used directly.  Direct use of these classes is not",
        "also be instantiated or used directly. Direct use of these classes"
    ],
    [
        "Distributors: you can add custom code here to support particular distributions",
        "Distributors: you can add custom code"
    ],
    [
        "For example, this is a good place to put any BLAS/LAPACK initialization code.",
        "For example, this is a good place to put any BLAS/LAPACK initialization"
    ],
    [
        "The numpy standard source distribution will not put code in this file, so you",
        "The numpy standard source distribution will not put code"
    ],
    [
        "can safely replace this file with your own version.",
        "can safely replace this file with"
    ],
    [
        "\"The matrix subclass is not the recommended way to represent \"",
        "\"The matrix subclass is not the recommended"
    ],
    [
        "\"matrices or deal with linear algebra (see \"",
        "\"matrices or deal with linear"
    ],
    [
        "\"Please adjust your code to use regular ndarray. \",",
        "\"Please adjust your code to"
    ],
    [
        "\"\"\"Return a new matrix of given shape and type, without initializing entries.",
        "\"\"\"Return a new matrix of given shape"
    ],
    [
        "shape : int or tuple of int",
        "shape : int or tuple of"
    ],
    [
        "Whether to store multi-dimensional data in row-major",
        "Whether to store multi-dimensional data"
    ],
    [
        "(C-style) or column-major (Fortran-style) order in",
        "(C-style) or column-major (Fortran-style) order"
    ],
    [
        "matlib.zeros : Return a matrix of zeros.",
        "matlib.zeros : Return a"
    ],
    [
        "matlib.ones : Return a matrix of ones.",
        "matlib.ones : Return a matrix"
    ],
    [
        "Unlike other matrix creation functions (e.g. `matlib.zeros`,",
        "Unlike other matrix creation functions (e.g."
    ],
    [
        "`matlib.ones`), `matlib.empty` does not initialize the values of the",
        "`matlib.ones`), `matlib.empty` does not initialize the values"
    ],
    [
        "matrix, and may therefore be marginally faster. However, the values",
        "matrix, and may therefore be marginally"
    ],
    [
        "stored in the newly allocated matrix are arbitrary. For reproducible",
        "stored in the newly allocated"
    ],
    [
        "behavior, be sure to set each element of the matrix before reading.",
        "behavior, be sure to set each"
    ],
    [
        "Return a matrix of given shape and type, filled with ones.",
        "Return a matrix of given shape and type, filled"
    ],
    [
        "shape : {sequence of ints, int}",
        "shape : {sequence"
    ],
    [
        "Whether to store matrix in C- or Fortran-contiguous order,",
        "Whether to store matrix in C- or"
    ],
    [
        "Matrix of ones of given shape, dtype, and order.",
        "Matrix of ones of given"
    ],
    [
        "If `shape` has length one i.e. ``(N,)``, or is a scalar ``N``,",
        "If `shape` has length one i.e. ``(N,)``, or is a"
    ],
    [
        "a = ndarray.__new__(matrix, shape, dtype, order=order)",
        "a = ndarray.__new__(matrix,"
    ],
    [
        "Return a matrix of given shape and type, filled with zeros.",
        "Return a matrix of given shape and type, filled"
    ],
    [
        "shape : int or sequence of ints",
        "shape : int or sequence"
    ],
    [
        "The desired data-type for the matrix, default is float.",
        "The desired data-type for the matrix, default is"
    ],
    [
        "Whether to store the result in C- or Fortran-contiguous order,",
        "Whether to store the result in C- or"
    ],
    [
        "Zero matrix of given shape, dtype, and order.",
        "Zero matrix of given shape, dtype, and"
    ],
    [
        "matlib.ones : Return a matrix of ones.",
        "matlib.ones : Return a matrix of"
    ],
    [
        "If `shape` has length one i.e. ``(N,)``, or is a scalar ``N``,",
        "If `shape` has length one i.e. ``(N,)``, or is a scalar"
    ],
    [
        "a = ndarray.__new__(matrix, shape, dtype, order=order)",
        "a = ndarray.__new__(matrix, shape, dtype,"
    ],
    [
        "Returns the square identity matrix of given size.",
        "Returns the square identity matrix of given"
    ],
    [
        "Size of the returned identity matrix.",
        "Size of the returned identity"
    ],
    [
        "Data-type of the output. Defaults to ``float``.",
        "Data-type of the output. Defaults"
    ],
    [
        "`n` x `n` matrix with its main diagonal set to one,",
        "`n` x `n` matrix with its main diagonal"
    ],
    [
        "matlib.eye : More general matrix identity function.",
        "matlib.eye : More general matrix"
    ],
    [
        "Return a matrix with ones on the diagonal and zeros elsewhere.",
        "Return a matrix with ones on the diagonal and"
    ],
    [
        "Number of rows in the output.",
        "Number of rows in"
    ],
    [
        "Number of columns in the output, defaults to `n`.",
        "Number of columns in the"
    ],
    [
        "a positive value refers to an upper diagonal,",
        "a positive value refers to an"
    ],
    [
        "and a negative value to a lower diagonal.",
        "and a negative value to a"
    ],
    [
        "Whether the output should be stored in row-major (C-style) or",
        "Whether the output should be stored"
    ],
    [
        "A `n` x `M` matrix where all elements are equal to zero,",
        "A `n` x `M` matrix where all elements"
    ],
    [
        "except for the `k`-th diagonal, whose values are equal to one.",
        "except for the `k`-th diagonal, whose"
    ],
    [
        "return asmatrix(np.eye(n, M=M, k=k, dtype=dtype, order=order))",
        "return asmatrix(np.eye(n, M=M,"
    ],
    [
        "Return a matrix of random values with given shape.",
        "Return a matrix of random values with"
    ],
    [
        "Create a matrix of the given shape and propagate it with",
        "Create a matrix of the given shape and propagate it"
    ],
    [
        "If given as N integers, each integer specifies the size of one",
        "If given as N integers, each"
    ],
    [
        "If given as a tuple, this tuple gives the complete shape.",
        "If given as a tuple, this tuple gives"
    ],
    [
        "The matrix of random values with shape given by `\\\\*args`.",
        "The matrix of random values with shape"
    ],
    [
        "If the first argument is a tuple, other arguments are ignored:",
        "If the first argument is a tuple, other arguments are"
    ],
    [
        "Return a random matrix with data from the \"standard normal\" distribution.",
        "Return a random matrix with data"
    ],
    [
        "`randn` generates a matrix filled with random floats sampled from a",
        "`randn` generates a matrix filled with"
    ],
    [
        "If given as N integers, each integer specifies the size of one",
        "If given as N integers, each integer specifies"
    ],
    [
        "dimension. If given as a tuple, this tuple gives the complete shape.",
        "dimension. If given as a tuple, this tuple"
    ],
    [
        "A matrix of floating-point samples drawn from the standard normal",
        "A matrix of floating-point samples drawn"
    ],
    [
        "For random samples from the normal distribution with mean ``mu`` and",
        "For random samples from the normal distribution with mean ``mu``"
    ],
    [
        "Two-by-four matrix of samples from the normal distribution with",
        "Two-by-four matrix of samples from the normal"
    ],
    [
        "The array or matrix to be repeated.",
        "The array or matrix"
    ],
    [
        "The number of times `a` is repeated along the first and second axes.",
        "The number of times `a` is repeated along the first and second"
    ],
    [
        "General exceptions used by NumPy.  Note that some exceptions may be module",
        "General exceptions used by NumPy. Note that"
    ],
    [
        "specific, such as linear algebra errors.",
        "specific, such as linear algebra"
    ],
    [
        "available through the main NumPy namespace for compatibility.",
        "available through the main NumPy"
    ],
    [
        "ComplexWarning             Given when converting complex to real.",
        "ComplexWarning Given when converting complex to"
    ],
    [
        "VisibleDeprecationWarning  Same as a DeprecationWarning, but more visible.",
        "VisibleDeprecationWarning Same as a"
    ],
    [
        "RankWarning                Issued when the design matrix is rank deficient.",
        "RankWarning Issued when the design"
    ],
    [
        "AxisError          Given when an axis was invalid.",
        "AxisError Given when an axis was"
    ],
    [
        "DTypePromotionError   Given when no common dtype could be found.",
        "DTypePromotionError Given when no common dtype could be"
    ],
    [
        "raise RuntimeError('Reloading numpy._globals is not allowed')",
        "raise RuntimeError('Reloading numpy._globals is"
    ],
    [
        "The warning raised when casting a complex dtype to a real dtype.",
        "The warning raised when casting a complex dtype to a real"
    ],
    [
        "As implemented, casting a complex number to a real discards its imaginary",
        "As implemented, casting a complex number to a real discards"
    ],
    [
        "part, but this behavior may not be what the user actually wants.",
        "part, but this behavior may not be"
    ],
    [
        "This warning should not be used, since nose testing is not relevant",
        "This warning should not be used, since nose"
    ],
    [
        "The nose tester turns ordinary Deprecation warnings into test failures.",
        "The nose tester turns ordinary Deprecation warnings"
    ],
    [
        "That makes it hard to deprecate whole modules, because they get",
        "That makes it hard to deprecate whole modules, because"
    ],
    [
        "imported by default. So this is a special Deprecation warning that the",
        "imported by default. So this is a special"
    ],
    [
        "nose tester will let pass without making tests fail.",
        "nose tester will let pass without making"
    ],
    [
        "By default, python will not show deprecation warnings, so this class",
        "By default, python will not show deprecation warnings,"
    ],
    [
        "can be used when a very visible warning is helpful, for example because",
        "can be used when a very visible warning"
    ],
    [
        "the usage is most likely a user bug.",
        "the usage is most likely a"
    ],
    [
        "Issued by polynomial functions when the design matrix is rank deficient.",
        "Issued by polynomial functions when the design matrix is"
    ],
    [
        "This is raised whenever the maximum number of candidate solutions",
        "This is raised whenever the"
    ],
    [
        "to consider specified by the ``max_work`` parameter is exceeded.",
        "to consider specified by the ``max_work`` parameter"
    ],
    [
        "Assigning a finite number to ``max_work`` may have caused the operation",
        "Assigning a finite number to ``max_work``"
    ],
    [
        "This is raised whenever an ``axis`` parameter is specified that is larger",
        "This is raised whenever an ``axis`` parameter is specified"
    ],
    [
        "than the number of array dimensions.",
        "than the number"
    ],
    [
        "For compatibility with code written against older numpy versions, which",
        "For compatibility with code written against older numpy"
    ],
    [
        "raised a mixture of :exc:`ValueError` and :exc:`IndexError` for this",
        "raised a mixture of :exc:`ValueError`"
    ],
    [
        "situation, this exception subclasses both to ensure that",
        "situation, this exception subclasses both to"
    ],
    [
        "``except ValueError`` and ``except IndexError`` statements continue",
        "``except ValueError`` and ``except IndexError``"
    ],
    [
        "The out of bounds axis or a custom exception message.",
        "The out of bounds axis"
    ],
    [
        "If an axis is provided, then `ndim` should be specified as well.",
        "If an axis is provided, then `ndim` should be specified as"
    ],
    [
        "A prefix for the exception message.",
        "A prefix for the"
    ],
    [
        "The out of bounds axis or ``None`` if a custom exception",
        "The out of bounds axis or ``None`` if a custom"
    ],
    [
        "message was provided. This should be the axis as passed by",
        "message was provided. This should be the axis"
    ],
    [
        "the user, before any normalization to resolve negative indices.",
        "the user, before any normalization to resolve negative"
    ],
    [
        "The number of array dimensions or ``None`` if a custom exception",
        "The number of array dimensions or ``None`` if a custom"
    ],
    [
        "The class constructor generally takes the axis and arrays'",
        "The class constructor generally takes"
    ],
    [
        "Alternatively, a custom exception message can be passed:",
        "Alternatively, a custom exception message can be"
    ],
    [
        "if ndim is msg_prefix is None:",
        "if ndim is"
    ],
    [
        "if axis is ndim is None:",
        "if axis is ndim"
    ],
    [
        "msg = f\"axis {axis} is out of bounds for array of dimension {ndim}\"",
        "msg = f\"axis {axis} is out of bounds for array of dimension"
    ],
    [
        "\"\"\"Multiple DTypes could not be converted to a common one.",
        "\"\"\"Multiple DTypes could not be converted to"
    ],
    [
        "This exception derives from ``TypeError`` and is raised whenever dtypes",
        "This exception derives from ``TypeError``"
    ],
    [
        "cannot be converted to a single common one.  This can be because they",
        "cannot be converted to a single common"
    ],
    [
        "are of a different category/class or incompatible instances of the same",
        "are of a different category/class or incompatible instances of"
    ],
    [
        "Many functions will use promotion to find the correct result and",
        "Many functions will use promotion to find the correct"
    ],
    [
        "implementation.  For these functions the error will typically be chained",
        "implementation. For these functions the error will"
    ],
    [
        "with a more specific error indicating that no implementation was found",
        "with a more specific error indicating that no"
    ],
    [
        "Typically promotion should be considered \"invalid\" between the dtypes of",
        "Typically promotion should be considered \"invalid\" between the dtypes"
    ],
    [
        "Datetimes and complex numbers are incompatible classes and cannot be",
        "Datetimes and complex numbers are incompatible classes and"
    ],
    [
        "DType exists for the given inputs. For example they cannot be stored in a",
        "DType exists for the given inputs. For example they cannot be stored"
    ],
    [
        "single array unless the dtype is `object`. The full list of DTypes is:",
        "single array unless the dtype is `object`. The"
    ],
    [
        "For example for structured dtypes, the structure can mismatch and the",
        "For example for structured dtypes, the"
    ],
    [
        "same ``DTypePromotionError`` is given when two structured dtypes with",
        "same ``DTypePromotionError`` is given when two structured dtypes"
    ],
    [
        "a mismatch in their number of fields is given:",
        "a mismatch in their number of fields is"
    ],
    [
        "Each item is associated with a migration note.",
        "Each item is associated with a migration"
    ],
    [
        "\"geterrobj\": \"Use the np.errstate context manager instead.\",",
        "\"geterrobj\": \"Use the np.errstate context manager"
    ],
    [
        "\"seterrobj\": \"Use the np.errstate context manager instead.\",",
        "\"seterrobj\": \"Use the np.errstate context manager"
    ],
    [
        "\"who\": \"Use an IDE variable explorer or `locals()` instead.\",",
        "\"who\": \"Use an IDE variable explorer"
    ],
    [
        "\"For the general case, use `PyUFunc_ReplaceLoopBySignature`. \"",
        "\"For the general case, use"
    ],
    [
        "\"For ndarray subclasses, define the ``__array_ufunc__`` method \"",
        "\"For ndarray subclasses, define the ``__array_ufunc__``"
    ],
    [
        "\"It's an internal function and doesn't have a replacement.\",",
        "\"It's an internal function and"
    ],
    [
        "\"Use a specific dtype instead. You should avoid relying \"",
        "\"Use a specific dtype instead. You"
    ],
    [
        "\"on any implicit mechanism and select the largest dtype of \"",
        "\"on any implicit mechanism and select the largest"
    ],
    [
        "\"a kind explicitly in the code.\",",
        "\"a kind explicitly in"
    ],
    [
        "\"Use `np.set_printoptions` instead with a formatter for \"",
        "\"Use `np.set_printoptions` instead with a formatter for"
    ],
    [
        "\"asfarray\": \"Use `np.asarray` with a proper dtype instead.\",",
        "\"asfarray\": \"Use `np.asarray` with a proper"
    ],
    [
        "\"tracemalloc_domain\": \"It's now available from `np.lib`.\",",
        "\"tracemalloc_domain\": \"It's now"
    ],
    [
        "\"recfromcsv\": \"Use `np.genfromtxt` with comma delimiter instead.\",",
        "\"recfromcsv\": \"Use `np.genfromtxt` with"
    ],
    [
        "\"deprecate\": \"Emit `DeprecationWarning` with `warnings.warn` directly, \"",
        "\"deprecate\": \"Emit `DeprecationWarning` with `warnings.warn`"
    ],
    [
        "\"deprecate_with_doc\": \"Emit `DeprecationWarning` with `warnings.warn` \"",
        "\"deprecate_with_doc\": \"Emit `DeprecationWarning` with"
    ],
    [
        "\"disp\": \"Use your own printing function instead.\",",
        "\"disp\": \"Use your own printing function"
    ],
    [
        "\"Use `numpy.promote_types` or `numpy.result_type` instead. \"",
        "\"Use `numpy.promote_types` or `numpy.result_type` instead."
    ],
    [
        "\"To achieve semantics for the `scalar_types` argument, use \"",
        "\"To achieve semantics for the `scalar_types` argument,"
    ],
    [
        "\"DataSource\": \"It's still available as `np.lib.npyio.DataSource`.\",",
        "\"DataSource\": \"It's still"
    ],
    [
        "\"byte_bounds\": \"Now it's available under `np.lib.array_utils.byte_bounds`\",",
        "\"byte_bounds\": \"Now it's available under"
    ],
    [
        "\"format_parser\": \"It's still available as `np.rec.format_parser`.\",",
        "\"format_parser\": \"It's still available as"
    ],
    [
        "This module implements the ``test()`` function for NumPy modules. The usual",
        "This module implements the ``test()`` function"
    ],
    [
        "boiler plate for doing that is to put the following in the module",
        "boiler plate for doing that is to put the following"
    ],
    [
        "Warnings filtering and other runtime settings should be dealt with in the",
        "Warnings filtering and other runtime settings should be dealt"
    ],
    [
        "``pytest.ini`` file in the numpy repo root. The behavior of the test depends on",
        "``pytest.ini`` file in the numpy repo root."
    ],
    [
        "whether or not that file is found as follows:",
        "whether or not that file is"
    ],
    [
        "* ``pytest.ini`` is present (develop mode)",
        "* ``pytest.ini`` is present"
    ],
    [
        "All warnings except those explicitly filtered out are raised as error.",
        "All warnings except those explicitly filtered out are raised"
    ],
    [
        "* ``pytest.ini`` is absent (release mode)",
        "* ``pytest.ini`` is"
    ],
    [
        "DeprecationWarnings and PendingDeprecationWarnings are ignored, other",
        "DeprecationWarnings and PendingDeprecationWarnings are ignored,"
    ],
    [
        "In practice, tests run from the numpy repo are run in development mode with",
        "In practice, tests run from the numpy repo are"
    ],
    [
        "``spin``, through the standard ``spin test`` invocation or from an inplace",
        "``spin``, through the standard ``spin test`` invocation"
    ],
    [
        "This module is imported by every numpy subpackage, so lies at the top level to",
        "This module is imported by every numpy subpackage, so lies"
    ],
    [
        "simplify circular import issues. For the same reason, it contains no numpy",
        "simplify circular import issues. For the same"
    ],
    [
        "imports at module scope, instead importing numpy within function calls.",
        "imports at module scope, instead importing numpy"
    ],
    [
        "print(\"NumPy CPU features: \", (info if info else 'nothing enabled'))",
        "print(\"NumPy CPU features: \", (info if info"
    ],
    [
        "A test function is typically added to a package's __init__.py like so::",
        "A test function is typically added to a"
    ],
    [
        "Calling this test function finds and runs all tests associated with the",
        "Calling this test function finds and runs all"
    ],
    [
        "Full path to the package to test.",
        "Full path to the package to"
    ],
    [
        "The name of the module to test.",
        "The name of the module to"
    ],
    [
        "Unlike the previous ``nose``-based implementation, this class is not",
        "Unlike the previous ``nose``-based implementation,"
    ],
    [
        "publicly exposed as it performs some ``numpy``-specific warning",
        "publicly exposed as it performs"
    ],
    [
        "Run tests for module using pytest.",
        "Run tests for"
    ],
    [
        "Identifies the tests to run. When set to 'fast', tests decorated",
        "Identifies the tests to run. When set"
    ],
    [
        "with `pytest.mark.slow` are skipped, when 'full', the slow marker",
        "with `pytest.mark.slow` are skipped, when 'full',"
    ],
    [
        "List with any extra arguments to pass to pytests.",
        "List with any extra arguments to pass to"
    ],
    [
        "If True, report coverage of NumPy code. Default is False.",
        "If True, report coverage of"
    ],
    [
        "tests : test or list of tests",
        "tests : test or list"
    ],
    [
        "Tests to be executed with pytest '--pyargs'",
        "Tests to be executed"
    ],
    [
        "Return True on success, false otherwise.",
        "Return True on"
    ],
    [
        "Each NumPy module exposes `test` in its namespace to run all tests for",
        "Each NumPy module exposes `test` in its namespace to run all"
    ],
    [
        "it. For example, to run all tests for numpy.lib:",
        "it. For example, to run all tests"
    ],
    [
        "\"-W ignore:the matrix subclass is not\",",
        "\"-W ignore:the matrix subclass is"
    ],
    [
        "pytest_args += [\"-m\", \"not slow and not slow_pypy\"]",
        "pytest_args += [\"-m\", \"not slow"
    ],
    [
        "unixccompiler - can handle very long argument lists for ar.",
        "unixccompiler - can handle very"
    ],
    [
        "from distutils.errors import CompileError, DistutilsExecError, LibError",
        "from distutils.errors import CompileError,"
    ],
    [
        "def UnixCCompiler__compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts):",
        "def UnixCCompiler__compile(self, obj, src, ext, cc_args, extra_postargs,"
    ],
    [
        "\"\"\"Compile a single source files with a Unix-style compiler.\"\"\"",
        "\"\"\"Compile a single source files with a"
    ],
    [
        "deps = ['-MMD', '-MF', obj + '.d']",
        "deps = ['-MMD', '-MF', obj"
    ],
    [
        "self.spawn(self.compiler_so + cc_args + [src, '-o', obj] + deps +",
        "self.spawn(self.compiler_so + cc_args + [src, '-o', obj] + deps"
    ],
    [
        "with open(obj + '.d', 'a') as f:",
        "with open(obj + '.d', 'a') as"
    ],
    [
        "Build a static library in a separate sub-process.",
        "Build a static library in a separate"
    ],
    [
        "objects : list or tuple of str",
        "objects : list or tuple of"
    ],
    [
        "List of paths to object files used to build the static library.",
        "List of paths to object files used to build"
    ],
    [
        "The library name as an absolute or relative (if `output_dir` is used)",
        "The library name as an absolute or relative"
    ],
    [
        "The path to the output directory. Default is None, in which case",
        "The path to the output directory. Default is None, in which"
    ],
    [
        "the ``output_dir`` attribute of the UnixCCompiler instance.",
        "the ``output_dir`` attribute of the UnixCCompiler"
    ],
    [
        "display = '%s: adding %d object files to %s' % (",
        "display = '%s: adding %d object files to %s' %"
    ],
    [
        "takes templated file .xxx.src and produces .xxx file  where .xxx is",
        "takes templated file .xxx.src and produces .xxx file where"
    ],
    [
        ".i or .c or .h, using the following template rules",
        ".i or .c or .h, using the"
    ],
    [
        "/**begin repeat  -- on a line by itself marks the start of a repeated code",
        "/**begin repeat -- on a line by itself"
    ],
    [
        "/**end repeat**/ -- on a line by itself marks it's end",
        "/**end repeat**/ -- on a line by itself marks it's"
    ],
    [
        "After the /**begin repeat and before the */, all the named templates are placed",
        "After the /**begin repeat and before the"
    ],
    [
        "these should all have the same number of replacements",
        "these should all have the"
    ],
    [
        "Repeat blocks can be nested, with each nested block labeled with its depth,",
        "Repeat blocks can be nested, with each nested block labeled with"
    ],
    [
        "When using nested loops, you can optionally exclude particular",
        "When using nested loops, you can optionally"
    ],
    [
        "combinations of the variables using (inside the comment portion of the inner loop):",
        "combinations of the variables using (inside the comment portion of the inner"
    ],
    [
        "In the main body each replace will use one entry from the list of named replacements",
        "In the main body each replace will use one"
    ],
    [
        "**       This file was autogenerated from a template  DO NOT EDIT!!**",
        "** This file was autogenerated from"
    ],
    [
        "**       Changes should be made to the original source (.src) file **",
        "** Changes should be made to the original"
    ],
    [
        "**       This file was autogenerated from a template  DO NOT EDIT!!!!      **",
        "** This file was autogenerated from a template DO NOT EDIT!!!!"
    ],
    [
        "**       Changes should be made to the original source (.src) file         **",
        "** Changes should be made to the original source (.src)"
    ],
    [
        "The returned line number is from the beginning of the string, starting",
        "The returned line number is from the beginning of the"
    ],
    [
        "at zero. Returns an empty list if no loops found.",
        "at zero. Returns an empty list if no"
    ],
    [
        "loopbeg = \"/**begin repeat%d\" % level",
        "loopbeg = \"/**begin repeat%d\""
    ],
    [
        "loopend = \"/**end repeat%d**/\" % level",
        "loopend = \"/**end"
    ],
    [
        "\"\"\"Find all named replacements in the header",
        "\"\"\"Find all named replacements in"
    ],
    [
        "Returns a list of dictionaries, one for each loop iteration,",
        "Returns a list of dictionaries,"
    ],
    [
        "where each key is a name to be substituted and the corresponding",
        "where each key is a name to"
    ],
    [
        "Also return a list of exclusions.  The exclusions are dictionaries",
        "Also return a list of exclusions. The exclusions are"
    ],
    [
        "of key value pairs. There can be more than one exclusion.",
        "of key value pairs. There can"
    ],
    [
        "msg = \"Mismatch in number of values, %d != %d\\n%s = %s\"",
        "msg = \"Mismatch in number of values, %d != %d\\n%s"
    ],
    [
        "raise ValueError(msg % (nsub, size, name, vals))",
        "raise ValueError(msg % (nsub, size, name,"
    ],
    [
        "tmp = {name: vals[i] for name, vals in names}",
        "tmp = {name: vals[i] for name, vals in"
    ],
    [
        "def parse_string(astr, env, level, line) :",
        "def parse_string(astr, env, level, line)"
    ],
    [
        "msg = 'line %d: no definition of key \"%s\"'%(line, name)",
        "msg = 'line %d: no"
    ],
    [
        "msg = \"line %d: %s\" % (newline, e)",
        "msg = \"line %d: %s\" %"
    ],
    [
        "newcode = parse_string(text, newenv, newlevel, newline)",
        "newcode = parse_string(text,"
    ],
    [
        "raise ValueError('In \"%s\" loop at %s' % (sourcefile, e)) from None",
        "raise ValueError('In \"%s\" loop at %s'"
    ],
    [
        "newkey = \"\".join([x[:n] for x in allkeys])",
        "newkey = \"\".join([x[:n] for"
    ],
    [
        "raise ValueError(\"In %s loop at %s\" % (file, e)) from None",
        "raise ValueError(\"In %s loop at %s\" %"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is given"
    ],
    [
        "terms of the NumPy (BSD style) license.  See LICENSE.txt that came with",
        "terms of the NumPy (BSD style) license. See"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE AT YOUR"
    ],
    [
        "if os.WIFEXITED(status) and os.WEXITSTATUS(status) in successful_status:",
        "if os.WIFEXITED(status) and os.WEXITSTATUS(status) in"
    ],
    [
        "\"\"\"Holds CPU information and provides methods for requiring",
        "\"\"\"Holds CPU information and"
    ],
    [
        "the availability of various CPU features.",
        "the availability of various"
    ],
    [
        "return self.info.get('MACHINE').lower() == 'ip%s' % (n)",
        "return self.info.get('MACHINE').lower() =="
    ],
    [
        "m = re.match(r'\\s*The (?P<p>[\\w\\d]+) processor operates at', line)",
        "m = re.match(r'\\s*The (?P<p>[\\w\\d]+) processor operates at',"
    ],
    [
        "return re.match(r'SUNW', self.info['uname_i']) is not None",
        "return re.match(r'SUNW', self.info['uname_i']) is"
    ],
    [
        "return re.match(r'.*Ultra-Enterprise', self.info['uname_i']) is not None",
        "return re.match(r'.*Ultra-Enterprise', self.info['uname_i'])"
    ],
    [
        "return re.match(r'.*Sun-Fire', self.info['uname_i']) is not None",
        "return re.match(r'.*Sun-Fire', self.info['uname_i'])"
    ],
    [
        "return re.match(r'.*Ultra', self.info['uname_i']) is not None",
        "return re.match(r'.*Ultra', self.info['uname_i'])"
    ],
    [
        "Check if an objects needs to be rebuild based on its dependencies",
        "Check if an objects needs to be rebuild based on"
    ],
    [
        "deps = [x for x in shlex.split(contents, posix=True)",
        "deps = [x for x in"
    ],
    [
        "if x != \"\\n\" and not x.endswith(\":\")]",
        "if x != \"\\n\" and not"
    ],
    [
        "m = lambda self, *args, **kw: func(self, *args, **kw)",
        "m = lambda self, *args,"
    ],
    [
        "Does nothing here, but is called by the get_version method and can be",
        "Does nothing here, but is called by the get_version"
    ],
    [
        "overridden by subclasses. In particular it is redefined in the `FCompiler`",
        "overridden by subclasses. In particular it"
    ],
    [
        "class where more documentation can be found.",
        "class where more documentation"
    ],
    [
        "Execute a command in a sub-process.",
        "Execute a command in"
    ],
    [
        "display : str or sequence of str, optional",
        "display : str or sequence of str,"
    ],
    [
        "The text to add to the log file kept by `numpy.distutils`.",
        "The text to add to the log file kept"
    ],
    [
        "If not given, `display` is equal to `cmd`.",
        "If not given, `display`"
    ],
    [
        "env : a dictionary for environment variables, optional",
        "env : a dictionary for environment variables,"
    ],
    [
        "env = env if env is not None else dict(os.environ)",
        "env = env if env is not None else"
    ],
    [
        "if re.search(b'Too many open files', o):",
        "if re.search(b'Too many open files',"
    ],
    [
        "msg = '\\nTry rerunning setup command until build succeeds.'",
        "msg = '\\nTry rerunning setup command until"
    ],
    [
        "raise DistutilsExecError('Command \"%s\" failed with exit status %d%s' %",
        "raise DistutilsExecError('Command \"%s\" failed with exit status %d%s'"
    ],
    [
        "Return the name of the object files for the given source files.",
        "Return the name of the object files for the given source"
    ],
    [
        "The list of paths to source files. Paths can be either relative or",
        "The list of paths to source files. Paths"
    ],
    [
        "Whether to strip the directory from the returned paths. If True,",
        "Whether to strip the directory from"
    ],
    [
        "the file name prepended by `output_dir` is returned. Default is False.",
        "the file name prepended by `output_dir` is returned. Default is"
    ],
    [
        "If given, this path is prepended to the returned paths to the",
        "If given, this path is prepended to the returned"
    ],
    [
        "The list of paths to the object files corresponding to the source",
        "The list of paths to the object files corresponding to"
    ],
    [
        "raise UnknownFileError(\"unknown file type '%s' (from '%s')\" % (ext, src_name))",
        "raise UnknownFileError(\"unknown file type '%s' (from '%s')\""
    ],
    [
        "obj_name = os.path.join(output_dir, base + self.obj_extension)",
        "obj_name = os.path.join(output_dir, base"
    ],
    [
        "Compile one or more source files.",
        "Compile one or"
    ],
    [
        "Please refer to the Python distutils API reference for more details.",
        "Please refer to the Python distutils"
    ],
    [
        "include_dirs : list of str, optional",
        "include_dirs : list of"
    ],
    [
        "The directories to add to the default include file search path for",
        "The directories to add to the default"
    ],
    [
        "Whether or not to output debug symbols in or alongside the object",
        "Whether or not to output debug symbols in or alongside the"
    ],
    [
        "depends : list of str, optional",
        "depends : list of"
    ],
    [
        "A list of file names that all targets depend on.",
        "A list of file names that all"
    ],
    [
        "A list of object file names, one per source file `sources`.",
        "A list of object file names,"
    ],
    [
        "display.append(\"Fortran %s compiler: %s\" % (fc, ' '.join(fcomp)))",
        "display.append(\"Fortran %s compiler: %s\" %"
    ],
    [
        "display = \"C compiler: %s\\n\" % (' '.join(ccomp),)",
        "display = \"C compiler: %s\\n\" %"
    ],
    [
        "macros, objects, extra_postargs, pp_opts, build = \\",
        "macros, objects, extra_postargs, pp_opts, build ="
    ],
    [
        "display = \"compile options: '%s'\" % (' '.join(cc_args))",
        "display = \"compile options: '%s'\" % ('"
    ],
    [
        "display += \"\\nextra options: '%s'\" % (' '.join(extra_postargs))",
        "display += \"\\nextra options: '%s'\""
    ],
    [
        "if not _needs_build(obj, cc_args, extra_postargs, pp_opts):",
        "if not _needs_build(obj, cc_args, extra_postargs,"
    ],
    [
        "self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)",
        "self._compile(obj, src, ext,"
    ],
    [
        "ignore : sequence of str, optional",
        "ignore : sequence"
    ],
    [
        "List of ``distutils.ccompiler.CCompiler`` commands (without ``'set_'``) that should not be",
        "List of ``distutils.ccompiler.CCompiler`` commands (without ``'set_'``) that should"
    ],
    [
        "altered. Strings that are checked for are:",
        "altered. Strings that are"
    ],
    [
        "log.info('customize %s using %s' % (self.__class__.__name__,",
        "log.info('customize %s using %s'"
    ],
    [
        "return getattr(cmd, attr, None) is not None and attr not in ignore",
        "return getattr(cmd, attr, None) is not None and attr not"
    ],
    [
        "for key in ['version', 'libraries', 'library_dirs',",
        "for key in"
    ],
    [
        "lines = [fmt % prop for prop in props]",
        "lines = [fmt % prop for prop in"
    ],
    [
        "Print the compiler customizations to stdout.",
        "Print the compiler"
    ],
    [
        "Do any platform-specific customization of a compiler instance.",
        "Do any platform-specific customization of a compiler"
    ],
    [
        "platform-specific customization, as well as optionally remove a flag",
        "platform-specific customization, as well as optionally remove a"
    ],
    [
        "to suppress spurious warnings in case C++ code is being compiled.",
        "to suppress spurious warnings in case C++ code is"
    ],
    [
        "This parameter is not used for anything.",
        "This parameter is not"
    ],
    [
        "Whether or not C++ has to be compiled. If so (True), the",
        "Whether or not C++ has to"
    ],
    [
        "``\"-Wstrict-prototypes\"`` option is removed to prevent spurious",
        "``\"-Wstrict-prototypes\"`` option is removed"
    ],
    [
        "All the default options used by distutils can be extracted with::",
        "All the default options used by distutils can be extracted"
    ],
    [
        "log.warn('Missing compiler_cxx fix for ' + self.__class__.__name__)",
        "log.warn('Missing compiler_cxx fix for"
    ],
    [
        "Simple matching of version numbers, for use in CCompiler and FCompiler.",
        "Simple matching of version numbers, for use"
    ],
    [
        "A regular expression matching version numbers.",
        "A regular expression matching"
    ],
    [
        "A regular expression matching patterns to skip.",
        "A regular expression matching patterns"
    ],
    [
        "Default is ``''``, in which case nothing is skipped.",
        "Default is ``''``, in which case"
    ],
    [
        "A regular expression matching the start of where to start looking",
        "A regular expression matching the start of where to"
    ],
    [
        "Default is ``''``, in which case searching is started at the",
        "Default is ``''``, in which case searching is started at"
    ],
    [
        "beginning of the version string given to `matcher`.",
        "beginning of the version string given to"
    ],
    [
        "A function that is appropriate to use as the ``.version_match``",
        "A function that is appropriate to use as"
    ],
    [
        "attribute of a ``distutils.ccompiler.CCompiler`` class. `matcher` takes a single parameter,",
        "attribute of a ``distutils.ccompiler.CCompiler`` class. `matcher` takes a"
    ],
    [
        "Return compiler version, or None if compiler is not available.",
        "Return compiler version, or None if compiler is"
    ],
    [
        "If True, force a new determination of the version, even if the",
        "If True, force a new determination of the version,"
    ],
    [
        "compiler already has a version attribute. Default is False.",
        "compiler already has a version attribute. Default"
    ],
    [
        "ok_status : list of int, optional",
        "ok_status : list"
    ],
    [
        "The list of status values returned by the version look-up process",
        "The list of status values returned"
    ],
    [
        "for which a version string is returned. If the status value is not",
        "for which a version string is returned."
    ],
    [
        "Version string, in the format of ``distutils.version.LooseVersion``.",
        "Version string, in the"
    ],
    [
        "if not force and hasattr(self, 'version'):",
        "if not force and"
    ],
    [
        "The C++ compiler, as a ``distutils.ccompiler.CCompiler`` instance.",
        "The C++ compiler, as"
    ],
    [
        "if self.compiler_type in ('msvc', 'intelw', 'intelemw'):",
        "if self.compiler_type in ('msvc', 'intelw',"
    ],
    [
        "\"Intel C Itanium Compiler for Itanium-based applications\")",
        "\"Intel C Itanium Compiler for Itanium-based"
    ],
    [
        "msg = \"don't know how to compile C/C++ code on platform '%s'\" % plat",
        "msg = \"don't know how to compile C/C++ code"
    ],
    [
        "msg = msg + \" with '%s' compiler\" % compiler",
        "msg = msg + \""
    ],
    [
        "log.info('%s in numpy.distutils; trying from distutils',",
        "log.info('%s in numpy.distutils; trying"
    ],
    [
        "raise DistutilsModuleError(\"can't compile C/C++ code: unable to load \"",
        "raise DistutilsModuleError(\"can't compile C/C++ code:"
    ],
    [
        "raise DistutilsModuleError((\"can't compile C/C++ code: unable to find \"",
        "raise DistutilsModuleError((\"can't compile C/C++ code: unable"
    ],
    [
        "\"class '%s' in module '%s'\") % (class_name, module_name))",
        "\"class '%s' in module '%s'\") % (class_name,"
    ],
    [
        "_m = sys.modules.get('distutils.' + _cc + 'compiler')",
        "_m = sys.modules.get('distutils.' + _cc"
    ],
    [
        "\"\"\"Concatenate two environment paths avoiding repeats.",
        "\"\"\"Concatenate two environment paths"
    ],
    [
        "Here `old` is the environment string before the base class initialize",
        "Here `old` is the environment string before the base class"
    ],
    [
        "function is called and `new` is the string after the call. The new string",
        "function is called and `new` is the string after"
    ],
    [
        "will be a fixed string if it is not obtained from the current environment,",
        "will be a fixed string if it is not obtained from the"
    ],
    [
        "or the same as the old string if obtained from the same environment. The aim",
        "or the same as the old string if obtained from the same"
    ],
    [
        "here is not to append the new string if it is already contained in the old",
        "here is not to append the new string if it is already"
    ],
    [
        "string so as to limit the growth of the environment string.",
        "string so as to limit the growth"
    ],
    [
        "__all__ = ['FormatError', 'PkgNotFound', 'LibraryInfo', 'VariableSet',",
        "__all__ = ['FormatError', 'PkgNotFound',"
    ],
    [
        "Exception thrown when there is a problem parsing a configuration file.",
        "Exception thrown when there is a"
    ],
    [
        "\"\"\"Exception raised when a package can not be located.\"\"\"",
        "\"\"\"Exception raised when a package"
    ],
    [
        "Parse a line from a config file containing compile flags.",
        "Parse a line from a config file"
    ],
    [
        "A single line containing one or more compile flags.",
        "A single line containing one"
    ],
    [
        "Dictionary of parsed flags, split into relevant categories.",
        "Dictionary of parsed flags,"
    ],
    [
        "These categories are the keys of `d`:",
        "These categories are the keys"
    ],
    [
        "d = {'include_dirs': [], 'library_dirs': [], 'libraries': [],",
        "d = {'include_dirs': [], 'library_dirs': [],"
    ],
    [
        "flags = (' ' + line).split(' -')",
        "flags = (' ' + line).split('"
    ],
    [
        "Object containing build information about a library.",
        "Object containing build information"
    ],
    [
        "The sections of the configuration file for the library. The keys are",
        "The sections of the configuration file for the library. The keys"
    ],
    [
        "the section headers, the values the text under each header.",
        "the section headers, the values the"
    ],
    [
        "A `VariableSet` instance, which contains ``(name, value)`` pairs for",
        "A `VariableSet` instance, which contains ``(name, value)`` pairs"
    ],
    [
        "variables defined in the configuration file for the library.",
        "variables defined in the configuration file for"
    ],
    [
        "The required libraries for the library to be installed.",
        "The required libraries for the library to"
    ],
    [
        "All input parameters (except \"sections\" which is a method) are available as",
        "All input parameters (except \"sections\" which is a"
    ],
    [
        "def __init__(self, name, description, version, sections, vars, requires=None):",
        "def __init__(self, name, description, version, sections,"
    ],
    [
        "Return the section headers of the config file.",
        "Return the section headers of the"
    ],
    [
        "m = ['Name: %s' % self.name, 'Description: %s' % self.description]",
        "m = ['Name: %s' %"
    ],
    [
        "Container object for the variables defined in a config file.",
        "Container object for the variables"
    ],
    [
        "`VariableSet` can be used as a plain dictionary, with the variable names",
        "`VariableSet` can be used as a plain dictionary, with the variable"
    ],
    [
        "Dict of items in the \"variables\" section of the configuration file.",
        "Dict of items in the \"variables\""
    ],
    [
        "self._raw_data = dict([(k, v) for k, v in d.items()])",
        "self._raw_data = dict([(k, v) for k, v"
    ],
    [
        "Return the list of variable names.",
        "Return the list"
    ],
    [
        "The names of all variables in the `VariableSet` instance.",
        "The names of all variables in the `VariableSet`"
    ],
    [
        "raise FormatError(\"No meta section found !\")",
        "raise FormatError(\"No meta"
    ],
    [
        "for k in ['name', 'description', 'version']:",
        "for k in ['name', 'description',"
    ],
    [
        "raise FormatError(\"Option %s (section [meta]) is mandatory, \"",
        "raise FormatError(\"Option %s (section"
    ],
    [
        "raise FormatError(\"No variables section found !\")",
        "raise FormatError(\"No variables section"
    ],
    [
        "filenames = [os.path.join(d, filename) for d in dirs]",
        "filenames = [os.path.join(d, filename) for d"
    ],
    [
        "raise PkgNotFound(\"Could not find file(s) %s\" % str(filenames))",
        "raise PkgNotFound(\"Could not find file(s)"
    ],
    [
        "secs = [s for s in config.sections() if not s in ['meta', 'variables']]",
        "secs = [s for s in config.sections() if not"
    ],
    [
        "meta, vars, sections, reqs = parse_config(f, dirs)",
        "meta, vars, sections, reqs"
    ],
    [
        "nmeta, nvars, nsections, nreqs = _read_config(pkg_to_filename(rvalue))",
        "nmeta, nvars, nsections, nreqs ="
    ],
    [
        "sections[rname][oname] += ' %s' % ovalue",
        "sections[rname][oname] += '"
    ],
    [
        "meta, vars, sections, reqs = _read_config(filenames)",
        "meta, vars, sections, reqs"
    ],
    [
        "if not 'pkgdir' in vars and \"pkgname\" in vars:",
        "if not 'pkgdir' in vars"
    ],
    [
        "raise ValueError(\"You should import %s to get information on %s\" %",
        "raise ValueError(\"You should import %s to get information"
    ],
    [
        "Return library info for a package from its configuration file.",
        "Return library info for a package from its"
    ],
    [
        "Name of the package (should match the name of the .ini file, without",
        "Name of the package (should match the name of the"
    ],
    [
        "the extension, e.g. foo for the file foo.ini).",
        "the extension, e.g. foo for"
    ],
    [
        "If given, should be a sequence of directories - usually including",
        "If given, should be a sequence"
    ],
    [
        "the NumPy base directory - where to look for npy-pkg-config files.",
        "the NumPy base directory - where to"
    ],
    [
        "The `LibraryInfo` instance containing the build information.",
        "The `LibraryInfo` instance containing the"
    ],
    [
        "If the package is not found.",
        "If the package"
    ],
    [
        "help=\"output all preprocessor and compiler flags\")",
        "help=\"output all preprocessor and"
    ],
    [
        "help=\"use this section instead of default for options\")",
        "help=\"use this section instead"
    ],
    [
        "help=\"Replace variable with the given value\")",
        "help=\"Replace variable with the"
    ],
    [
        "raise ValueError(\"Expect package name on the command line:\")",
        "raise ValueError(\"Expect package name on the command"
    ],
    [
        "print(\"%s\\t%s - %s\" % (info.name, info.name, info.description))",
        "print(\"%s\\t%s - %s\" %"
    ],
    [
        "raise ValueError(\"--define-variable option should be of \"",
        "raise ValueError(\"--define-variable option should"
    ],
    [
        "from threading import local as tlocal",
        "from threading import"
    ],
    [
        "Container to hold information on an installable library.",
        "Container to hold information on an"
    ],
    [
        "Absolute path specifying where to install the library.",
        "Absolute path specifying where to install the"
    ],
    [
        "The three parameters are stored as attributes with the same names.",
        "The three parameters are stored as"
    ],
    [
        "Get number of parallel build jobs set by the --parallel command line",
        "Get number of parallel build jobs set"
    ],
    [
        "If the command did not receive a setting the environment variable",
        "If the command did not receive a setting the environment"
    ],
    [
        "NPY_NUM_BUILD_JOBS is checked. If that is unset, return the number of",
        "NPY_NUM_BUILD_JOBS is checked. If that is unset, return the"
    ],
    [
        "overloading the system if there a lot of CPUs).",
        "overloading the system if there a lot"
    ],
    [
        "number of parallel jobs that can be run",
        "number of parallel jobs that can"
    ],
    [
        "if all(x is None for x in cmdattr):",
        "if all(x is None for x"
    ],
    [
        "return max(x for x in cmdattr if x is not None)",
        "return max(x for x in cmdattr if x is"
    ],
    [
        "\"Convert a /-separated pathname to one using the OS's path separator.\"",
        "\"Convert a /-separated pathname to one using the OS's"
    ],
    [
        "assert apath[len(pd)] in [os.sep], repr((path, apath[len(pd)]))",
        "assert apath[len(pd)] in"
    ],
    [
        "\"\"\"Return path of the module given a frame object from the call stack.",
        "\"\"\"Return path of the module given a frame"
    ],
    [
        "Returned path is relative to parent_path when given,",
        "Returned path is relative to parent_path when"
    ],
    [
        "\"\"\"Join two or more pathname components +",
        "\"\"\"Join two or more pathname"
    ],
    [
        "- convert a /-separated pathname to one using the OS's path separator.",
        "- convert a /-separated pathname to one using"
    ],
    [
        "- resolve `..` and `.` from path.",
        "- resolve `..` and `.` from"
    ],
    [
        "Either passing n arguments as in njoin('a','b'), or a sequence",
        "Either passing n arguments as in"
    ],
    [
        "of n names as in njoin(['a','b']) is handled, or a mixture of such arguments.",
        "of n names as in njoin(['a','b']) is handled,"
    ],
    [
        "\"\"\"Return the MATHLIB line from numpyconfig.h",
        "\"\"\"Return the MATHLIB line"
    ],
    [
        "raise DistutilsError('_numpyconfig.h not found in numpy include '",
        "raise DistutilsError('_numpyconfig.h not found in numpy include"
    ],
    [
        "\"\"\"Resolve `..` and '.' from path.",
        "\"\"\"Resolve `..` and"
    ],
    [
        "to allow extensions to have reproducible build results\"\"\"",
        "to allow extensions to"
    ],
    [
        "if '*' in n or '?' in n:",
        "if '*' in n or '?' in"
    ],
    [
        "print('could not resolve pattern in %r: %r' %",
        "print('could not resolve pattern in %r:"
    ],
    [
        "print('non-existing path in %r: %r' %",
        "print('non-existing path in %r: %r'"
    ],
    [
        "return [minrelpath(p) for p in new_paths]",
        "return [minrelpath(p) for p"
    ],
    [
        "\"\"\"Apply glob to paths and prepend local_path if needed.",
        "\"\"\"Apply glob to paths and"
    ],
    [
        "if sys.platform=='cygwin' and 'USE_COLOR' not in os.environ:",
        "if sys.platform=='cygwin' and 'USE_COLOR'"
    ],
    [
        "\"\"\"Convert a path from Cygwin-native to Windows-native.",
        "\"\"\"Convert a path from Cygwin-native to"
    ],
    [
        "Uses the cygpath utility (part of the Base install) to do the",
        "Uses the cygpath utility (part of"
    ],
    [
        "actual conversion.  Falls back to returning the original path if",
        "actual conversion. Falls back to"
    ],
    [
        "Handles the default ``/cygdrive`` mount prefix as well as the",
        "Handles the default ``/cygdrive`` mount prefix as well as"
    ],
    [
        "``/proc/cygdrive`` portable prefix, custom cygdrive prefixes such",
        "``/proc/cygdrive`` portable prefix, custom"
    ],
    [
        "as ``/`` or ``/mnt``, and absolute paths such as ``/usr/src/`` or",
        "as ``/`` or ``/mnt``, and absolute paths such as ``/usr/src/``"
    ],
    [
        "Documentation for the C function it wraps:",
        "Documentation for the C"
    ],
    [
        "\"Return version of MSVC runtime library, as defined by __MSC_VER__ macro\"",
        "\"Return version of MSVC runtime library, as defined by"
    ],
    [
        "\"Return major version of MSVC runtime coded like get_build_msvc_version\"",
        "\"Return major version of MSVC"
    ],
    [
        "\"\"\"Return True if all items in lst are string objects. \"\"\"",
        "\"\"\"Return True if all items in lst are"
    ],
    [
        "return all(is_string(item) for item in lst)",
        "return all(is_string(item) for item"
    ],
    [
        "return is_string(s) and ('*' in s or '?' in s)",
        "return is_string(s) and ('*' in s"
    ],
    [
        "\"\"\"Return True if sources contains Fortran files \"\"\"",
        "\"\"\"Return True if sources contains Fortran files"
    ],
    [
        "return any(fortran_ext_match(source) for source in sources)",
        "return any(fortran_ext_match(source) for source in"
    ],
    [
        "\"\"\"Return True if sources contains C++ files \"\"\"",
        "\"\"\"Return True if sources"
    ],
    [
        "return any(cxx_ext_match(source) for source in sources)",
        "return any(cxx_ext_match(source) for source in"
    ],
    [
        "\"\"\"Return four lists of filenames containing",
        "\"\"\"Return four lists of"
    ],
    [
        "Return commandline representation used to determine if a file needs",
        "Return commandline representation used to determine if a"
    ],
    [
        "cmdline += ' '.join(pp_opts) + '\\n'",
        "cmdline += ' '.join(pp_opts)"
    ],
    [
        "\"\"\"Return true if directory is local directory.",
        "\"\"\"Return true if directory"
    ],
    [
        "for dirpath, dirnames, filenames in os.walk(top_path, topdown=True):",
        "for dirpath, dirnames, filenames in"
    ],
    [
        "pruned = [ d for d in dirnames if d not in pruned_directories ]",
        "pruned = [ d for d in"
    ],
    [
        "\"\"\"Return a directory name relative to top_path and",
        "\"\"\"Return a directory name relative to"
    ],
    [
        "for dirpath, dirnames, filenames in os.walk(top_path, topdown=True):",
        "for dirpath, dirnames, filenames"
    ],
    [
        "pruned = [ d for d in dirnames if d not in pruned_directories ]",
        "pruned = [ d for d in dirnames if"
    ],
    [
        "filenames = [os.path.join(dpath, f) for f in os.listdir(dpath) \\",
        "filenames = [os.path.join(dpath, f) for"
    ],
    [
        "files = [f for f in filenames if os.path.isfile(f)]",
        "files = [f for f in filenames"
    ],
    [
        "sources = [_m for _m in ext.sources if is_string(_m)]",
        "sources = [_m for _m"
    ],
    [
        "scripts = [_m for _m in scripts if is_string(_m)]",
        "scripts = [_m for _m in"
    ],
    [
        "sources = [_m for _m in sources if is_string(_m)]",
        "sources = [_m for _m"
    ],
    [
        "\"\"\"Return the correct file extension for shared libraries.",
        "\"\"\"Return the correct file"
    ],
    [
        "Whether the shared library is a Python extension.  Default is False.",
        "Whether the shared library is a Python extension."
    ],
    [
        "For Python shared libs, `so_ext` will typically be '.so' on Linux and OS X,",
        "For Python shared libs, `so_ext` will typically be '.so' on"
    ],
    [
        "return '.'.join([a for a in args if a])",
        "return '.'.join([a for a in args if"
    ],
    [
        "\"\"\"Return frame object from call stack with given level.",
        "\"\"\"Return frame object from call stack with given"
    ],
    [
        "_list_keys = ['packages', 'ext_modules', 'data_files', 'include_dirs',",
        "_list_keys = ['packages',"
    ],
    [
        "\"\"\"Construct configuration instance of a package.",
        "\"\"\"Construct configuration instance"
    ],
    [
        "package_name -- name of the package",
        "package_name -- name"
    ],
    [
        "parent_name  -- name of the parent package",
        "parent_name -- name of"
    ],
    [
        "top_path     -- directory of the toplevel package",
        "top_path -- directory of the toplevel"
    ],
    [
        "Ex.: the directory where the numpy package source sits",
        "Ex.: the directory where the numpy package"
    ],
    [
        "package_path -- directory of package. Will be computed by magic from the",
        "package_path -- directory of package. Will be computed by"
    ],
    [
        "directory of the caller module if not specified",
        "directory of the caller"
    ],
    [
        "Ex.: the directory where numpy.distutils is",
        "Ex.: the directory where"
    ],
    [
        "caller_level -- frame level to caller namespace, internal parameter.",
        "caller_level -- frame level to"
    ],
    [
        "raise ValueError(\"%r is not a directory\" % (package_path,))",
        "raise ValueError(\"%r is not"
    ],
    [
        "Return a dictionary compatible with the keyword arguments of distutils",
        "Return a dictionary compatible with"
    ],
    [
        "known_keys = self.list_keys + self.dict_keys + self.extra_keys",
        "known_keys = self.list_keys +"
    ],
    [
        "\"\"\"Return the distutils distribution object for self.\"\"\"",
        "\"\"\"Return the distutils distribution"
    ],
    [
        "dirs = [_m for _m in sorted_glob(subpackage_path) if os.path.isdir(_m)]",
        "dirs = [_m for _m in"
    ],
    [
        "self.warn('Subpackage %r configuration returned as %r' % \\",
        "self.warn('Subpackage %r configuration returned as %r'"
    ],
    [
        "Name of the subpackage to get the configuration. '*' in",
        "Name of the subpackage to get the configuration."
    ],
    [
        "subpackage_name is handled as a wildcard.",
        "subpackage_name is handled"
    ],
    [
        "If None, then the path is assumed to be the local path plus the",
        "If None, then the path is assumed to be the local"
    ],
    [
        "subpackage_name. If a setup.py file is not found in the",
        "subpackage_name. If a setup.py file is not found in"
    ],
    [
        "subpackage_path, then a default configuration is used.",
        "subpackage_path, then a default"
    ],
    [
        "\"either subpackage_name or subpackage_path must be specified\")",
        "\"either subpackage_name or subpackage_path"
    ],
    [
        "if subpackage_path is None and '*' in subpackage_name:",
        "if subpackage_path is None"
    ],
    [
        "assert '*' not in subpackage_name, repr((subpackage_name, subpackage_path, parent_name))",
        "assert '*' not in subpackage_name, repr((subpackage_name, subpackage_path,"
    ],
    [
        "\"\"\"Add a sub-package to the current Configuration instance.",
        "\"\"\"Add a sub-package to the"
    ],
    [
        "This is useful in a setup.py script for adding sub-packages to a",
        "This is useful in a setup.py script for adding sub-packages"
    ],
    [
        "if given, the subpackage path such as the subpackage is in",
        "if given, the subpackage path such as the"
    ],
    [
        "subpackage_path / subpackage_name. If None,the subpackage is",
        "subpackage_path / subpackage_name. If"
    ],
    [
        "assumed to be located in the local path / subpackage_name.",
        "assumed to be located in the"
    ],
    [
        "self.info('Appending %s configuration to %s' \\",
        "self.info('Appending %s configuration to %s'"
    ],
    [
        "' it may be too late to add a subpackage '+ subpackage_name)",
        "' it may be too late to add a subpackage"
    ],
    [
        "\"\"\"Recursively add files under data_path to data_files list.",
        "\"\"\"Recursively add files under"
    ],
    [
        "Recursively add files under data_path to the list of data_files to be",
        "Recursively add files under data_path to the list"
    ],
    [
        "installed (and distributed). The data_path can be either a relative",
        "installed (and distributed). The data_path"
    ],
    [
        "argument shows where in the install directory the data directory",
        "argument shows where in the install directory the"
    ],
    [
        "* path to data directory where python datadir suffix defaults",
        "* path to data directory"
    ],
    [
        "foo/bar -> (foo/bar, foo/bar) -> parent/foo/bar",
        "foo/bar -> (foo/bar, foo/bar) ->"
    ],
    [
        "foo/* -> (foo/a, foo/a), (foo/b, foo/b) -> parent/foo/a, parent/foo/b",
        "foo/* -> (foo/a, foo/a), (foo/b, foo/b) -> parent/foo/a,"
    ],
    [
        "(gun, foo/*) -> (gun, foo/a), (gun, foo/b) -> gun",
        "(gun, foo/*) -> (gun, foo/a), (gun,"
    ],
    [
        "/foo/bar -> (bar, /foo/bar) -> parent/bar",
        "/foo/bar -> (bar, /foo/bar) ->"
    ],
    [
        "For example suppose the source directory contains fun/foo.dat and",
        "For example suppose the source directory contains"
    ],
    [
        "Will install data-files to the locations::",
        "Will install data-files to the"
    ],
    [
        "[self.add_data_dir((d, p)) for p in data_path]",
        "[self.add_data_dir((d, p)) for"
    ],
    [
        "raise TypeError(\"not a string: %r\" % (data_path,))",
        "raise TypeError(\"not a string: %r\" %"
    ],
    [
        "raise ValueError('cannot fill pattern %r with %r' \\",
        "raise ValueError('cannot fill pattern %r with"
    ],
    [
        "assert s==path_list[i], repr((s, path_list[i], data_path, d, path, rpath))",
        "assert s==path_list[i], repr((s, path_list[i], data_path, d,"
    ],
    [
        "if dist is not None and dist.data_files is not None:",
        "if dist is not None and dist.data_files is not"
    ],
    [
        "self.data_files[:] = [(p, list(files)) for p, files in data_dict.items()]",
        "self.data_files[:] = [(p, list(files)) for p,"
    ],
    [
        "\"\"\"Add data files to configuration data_files.",
        "\"\"\"Add data files to"
    ],
    [
        "* paths to data files where python datadir prefix defaults",
        "* paths to data files where"
    ],
    [
        "The form of each element of the files sequence is very flexible",
        "The form of each element of the files sequence is"
    ],
    [
        "allowing many combinations of where to get the files from the package",
        "allowing many combinations of where to get the"
    ],
    [
        "and where they should ultimately be installed on the system. The most",
        "and where they should ultimately be installed on the system. The"
    ],
    [
        "basic usage is for an element of the files argument sequence to be a",
        "basic usage is for an element of the files argument sequence"
    ],
    [
        "simple filename. This will cause that file from the local path to be",
        "simple filename. This will cause that file from the local path"
    ],
    [
        "installed to the installation path of the self.name package (package",
        "installed to the installation path"
    ],
    [
        "path). The file argument can also be a relative path in which case the",
        "path). The file argument can also be a relative path in"
    ],
    [
        "entire relative path will be installed into the package directory.",
        "entire relative path will be installed"
    ],
    [
        "Finally, the file can be an absolute path name in which case the file",
        "Finally, the file can be an absolute path name in which"
    ],
    [
        "will be found at the absolute path name but installed to the package",
        "will be found at the absolute path name"
    ],
    [
        "file argument. The first element of the tuple should specify the",
        "file argument. The first element of"
    ],
    [
        "relative path (under the package install directory) where the",
        "relative path (under the package install directory) where"
    ],
    [
        "remaining sequence of files should be installed to (it has nothing to",
        "remaining sequence of files should be installed to (it"
    ],
    [
        "do with the file-names in the source distribution). The second element",
        "do with the file-names in the source distribution). The second"
    ],
    [
        "of the tuple is the sequence of files that should be installed. The",
        "of the tuple is the sequence of files that should be"
    ],
    [
        "files in this sequence can be filenames, relative paths, or absolute",
        "files in this sequence can be"
    ],
    [
        "paths. For absolute paths the file will be installed in the top-level",
        "paths. For absolute paths the file will be installed in"
    ],
    [
        "package installation directory (regardless of the first argument).",
        "package installation directory (regardless of the"
    ],
    [
        "Filenames and relative path names will be installed in the package",
        "Filenames and relative path names will be installed in"
    ],
    [
        "install directory under the path name given as the first element of",
        "install directory under the path name given as"
    ],
    [
        "An additional feature is that the path to a data-file can actually be",
        "An additional feature is that the path"
    ],
    [
        "a function that takes no arguments and returns the actual path(s) to",
        "a function that takes no arguments"
    ],
    [
        "the data-files. This is useful when the data files are generated while",
        "the data-files. This is useful when the data files are generated"
    ],
    [
        "Add files to the list of data_files to be included with the package.",
        "Add files to the list of data_files to be included with"
    ],
    [
        "will install these data files to::",
        "will install these data"
    ],
    [
        "where <package install directory> is the package (or sub-package)",
        "where <package install directory> is the package (or"
    ],
    [
        "if dist is not None and dist.data_files is not None:",
        "if dist is not None"
    ],
    [
        "Add the given sequence of macro name and value duples to the beginning",
        "Add the given sequence of macro name and value duples"
    ],
    [
        "of the define_macros list This list will be visible to all extension",
        "of the define_macros list This list will be visible to all"
    ],
    [
        "\"\"\"Add paths to configuration include directories.",
        "\"\"\"Add paths to configuration"
    ],
    [
        "Add the given sequence of paths to the beginning of the include_dirs",
        "Add the given sequence of paths to"
    ],
    [
        "list. This list will be visible to all extension modules of the",
        "list. This list will be visible"
    ],
    [
        "Add the given sequence of files to the beginning of the headers list.",
        "Add the given sequence of files to"
    ],
    [
        "By default, headers will be installed under <python-",
        "By default, headers will be installed"
    ],
    [
        "include>/<self.name.replace('.','/')>/ directory. If an item of files",
        "include>/<self.name.replace('.','/')>/ directory. If an item"
    ],
    [
        "is a tuple, then its first argument specifies the actual installation",
        "is a tuple, then its first argument specifies the actual"
    ],
    [
        "location relative to the <python-include> path.",
        "location relative to the"
    ],
    [
        "* path(s) to header file(s) where python includedir suffix will",
        "* path(s) to header file(s) where python includedir suffix"
    ],
    [
        "[headers.append((self.name, p)) for p in self.paths(path)]",
        "[headers.append((self.name, p)) for p"
    ],
    [
        "\"\"\"Apply glob to paths and prepend local_path if needed.",
        "\"\"\"Apply glob to paths and"
    ],
    [
        "Applies glob.glob(...) to each path in the sequence (if needed) and",
        "Applies glob.glob(...) to each path in the sequence"
    ],
    [
        "prepends the local_path if needed. Because this is called on all",
        "prepends the local_path if needed. Because this"
    ],
    [
        "source lists, this allows wildcard characters to be specified in lists",
        "source lists, this allows wildcard characters"
    ],
    [
        "of sources for extension modules and libraries and scripts and allows",
        "of sources for extension modules and libraries and"
    ],
    [
        "path-names be relative to the source directory.",
        "path-names be relative to the source"
    ],
    [
        "if k in ['sources', 'depends', 'include_dirs', 'library_dirs',",
        "if k in ['sources', 'depends',"
    ],
    [
        "Create and add an Extension instance to the ext_modules list. This",
        "Create and add an Extension instance"
    ],
    [
        "method also takes the following optional keyword arguments that are",
        "method also takes the following optional keyword"
    ],
    [
        "passed on to the Extension constructor.",
        "passed on to the"
    ],
    [
        "list of the sources. The list of sources may contain functions",
        "list of the sources. The list of"
    ],
    [
        "(called source generators) which must take an extension instance",
        "(called source generators) which must"
    ],
    [
        "and a build directory as inputs and return a source file or list of",
        "and a build directory as inputs and return a source file or list"
    ],
    [
        "source files or None. If None is returned then no sources are",
        "source files or None. If None is returned then no sources"
    ],
    [
        "generated. If the Extension instance has no sources after",
        "generated. If the Extension instance"
    ],
    [
        "processing all source generators, then no extension module is",
        "processing all source generators, then"
    ],
    [
        "The depends list contains paths to files or directories that the",
        "The depends list contains paths to"
    ],
    [
        "sources of the extension module depend on. If any path in the",
        "sources of the extension module depend on."
    ],
    [
        "depends list is newer than the extension module, then the module",
        "depends list is newer than the extension module,"
    ],
    [
        "dict or list of dict of keywords to be appended to keywords.",
        "dict or list of dict of keywords to"
    ],
    [
        "The self.paths(...) method is applied to all lists that may contain",
        "The self.paths(...) method is applied to all lists that"
    ],
    [
        "' it may be too late to add an extension '+name)",
        "' it may be too late to add an extension"
    ],
    [
        "List of the sources. The list of sources may contain functions",
        "List of the sources. The list of sources"
    ],
    [
        "(called source generators) which must take an extension instance",
        "(called source generators) which must take an"
    ],
    [
        "and a build directory as inputs and return a source file or list of",
        "and a build directory as inputs and return a source file"
    ],
    [
        "source files or None. If None is returned then no sources are",
        "source files or None. If None"
    ],
    [
        "generated. If the Extension instance has no sources after",
        "generated. If the Extension instance has"
    ],
    [
        "processing all source generators, then no extension module is",
        "processing all source generators, then"
    ],
    [
        "' it may be too late to add a library '+ name)",
        "' it may be too late to add a library"
    ],
    [
        "def _add_library(self, name, sources, install_dir, build_info):",
        "def _add_library(self, name, sources,"
    ],
    [
        "\"\"\"Common implementation for add_library and add_installed_library. Do",
        "\"\"\"Common implementation for add_library"
    ],
    [
        "def add_installed_library(self, name, sources, install_dir, build_info=None):",
        "def add_installed_library(self, name, sources, install_dir,"
    ],
    [
        "Similar to add_library, but the specified library is installed.",
        "Similar to add_library, but the specified"
    ],
    [
        "Most C libraries used with ``distutils`` are only used to build python",
        "Most C libraries used with ``distutils``"
    ],
    [
        "extensions, but libraries built through this method will be installed",
        "extensions, but libraries built through this method"
    ],
    [
        "so that they can be reused by third-party packages.",
        "so that they can be reused"
    ],
    [
        "List of the library's source files. See `add_library` for details.",
        "List of the library's source files. See"
    ],
    [
        "Path to install the library, relative to the current sub-package.",
        "Path to install the library,"
    ],
    [
        "The best way to encode the options required to link against the specified",
        "The best way to encode the options required to link against"
    ],
    [
        "C libraries is to use a \"libname.ini\" file, and use `get_info` to",
        "C libraries is to use a \"libname.ini\""
    ],
    [
        "retrieve the required options (see `add_npy_pkg_config` for more",
        "retrieve the required options (see `add_npy_pkg_config` for"
    ],
    [
        "Generate and install a npy-pkg config file from a template.",
        "Generate and install a npy-pkg config file"
    ],
    [
        "The config file generated from `template` is installed in the",
        "The config file generated from `template` is"
    ],
    [
        "given install directory, using `subst_dict` for variable substitution.",
        "given install directory, using `subst_dict`"
    ],
    [
        "The path of the template, relatively to the current package path.",
        "The path of the template, relatively to the current"
    ],
    [
        "Where to install the npy-pkg config file, relatively to the current",
        "Where to install the npy-pkg config file, relatively to the"
    ],
    [
        "If given, any string of the form ``@key@`` will be replaced by",
        "If given, any string of the form ``@key@``"
    ],
    [
        "``subst_dict[key]`` in the template file when installed. The install",
        "``subst_dict[key]`` in the template file"
    ],
    [
        "prefix is always available through the variable ``@prefix@``, since the",
        "prefix is always available through the variable"
    ],
    [
        "install prefix is not easy to get reliably from setup.py.",
        "install prefix is not easy to get"
    ],
    [
        "This works for both standard installs and in-place builds, i.e. the",
        "This works for both standard installs and in-place"
    ],
    [
        "``@prefix@`` refer to the source directory for in-place builds.",
        "``@prefix@`` refer to the source directory"
    ],
    [
        "Assuming the foo.ini.in file has the following content::",
        "Assuming the foo.ini.in file has the following"
    ],
    [
        "The generated file will have the following content::",
        "The generated file will have the"
    ],
    [
        "and will be installed as foo.ini in the 'lib' subpath.",
        "and will be installed as"
    ],
    [
        "When cross-compiling with numpy distutils, it might be necessary to",
        "When cross-compiling with numpy distutils,"
    ],
    [
        "use modified npy-pkg-config files.  Using the default/generated files",
        "use modified npy-pkg-config files. Using the"
    ],
    [
        "will link with the host libraries (i.e. libnpymath.a).  For",
        "will link with the host"
    ],
    [
        "cross-compilation you of-course need to link with target libraries,",
        "cross-compilation you of-course need to"
    ],
    [
        "while using the host Python installation.",
        "while using the host"
    ],
    [
        "You can copy out the numpy/_core/lib/npy-pkg-config directory, add a",
        "You can copy out the numpy/_core/lib/npy-pkg-config"
    ],
    [
        "pkgdir value to the .ini files and set NPY_PKG_CONFIG_PATH environment",
        "pkgdir value to the .ini"
    ],
    [
        "variable to point to the directory with the modified npy-pkg-config",
        "variable to point to the directory"
    ],
    [
        "Add the sequence of files to the beginning of the scripts list.",
        "Add the sequence of files to the"
    ],
    [
        "Scripts will be installed under the <prefix>/bin/ directory.",
        "Scripts will be installed under the"
    ],
    [
        "known_keys = self.list_keys + self.dict_keys + self.extra_keys",
        "known_keys = self.list_keys + self.dict_keys +"
    ],
    [
        "self.warn('Inheriting attribute %r=%r from %r' \\",
        "self.warn('Inheriting attribute %r=%r from"
    ],
    [
        "self.info('Ignoring attempt to set %r (from %r to %r)' \\",
        "self.info('Ignoring attempt to set %r (from %r to %r)'"
    ],
    [
        "raise ValueError(\"Don't know about key=%r\" % (key))",
        "raise ValueError(\"Don't know about key=%r\" %"
    ],
    [
        "known_keys = self.list_keys + self.dict_keys + self.extra_keys",
        "known_keys = self.list_keys + self.dict_keys +"
    ],
    [
        "s += '%s = %s\\n' % (k, pformat(a))",
        "s += '%s = %s\\n' % (k,"
    ],
    [
        "Returns the numpy.distutils config command instance.",
        "Returns the numpy.distutils"
    ],
    [
        "Return a path to a temporary directory where temporary files should be",
        "Return a path to a temporary directory where temporary"
    ],
    [
        "Use it inside source generating function to ensure that",
        "Use it inside source generating function to"
    ],
    [
        "setup distribution instance has been initialized.",
        "setup distribution instance has been"
    ],
    [
        "code was able to be compiled successfully).",
        "code was able to be"
    ],
    [
        "Use it inside source generating function to ensure that",
        "Use it inside source generating function"
    ],
    [
        "setup distribution instance has been initialized.",
        "setup distribution instance"
    ],
    [
        "\"\"\"Append libraries, include_dirs to extension or library item.",
        "\"\"\"Append libraries, include_dirs to extension or"
    ],
    [
        "\"\"\"Try to get version string of a package.",
        "\"\"\"Try to get version string"
    ],
    [
        "Return a version string of the current package or None if the version",
        "Return a version string of the current package"
    ],
    [
        "__svn_version__.py for string variables version, __version__, and",
        "__svn_version__.py for string variables version,"
    ],
    [
        "<packagename>_version, until a version number is found.",
        "<packagename>_version, until a version"
    ],
    [
        "\"\"\"Appends a data function to the data_files list that will generate",
        "\"\"\"Appends a data function to the data_files list that will"
    ],
    [
        "__svn_version__.py file to the current package directory.",
        "__svn_version__.py file to the"
    ],
    [
        "Generate package __svn_version__.py file from SVN revision number,",
        "Generate package __svn_version__.py file from SVN revision"
    ],
    [
        "it will be removed after python exits but will be available",
        "it will be removed after python"
    ],
    [
        "when sdist, etc commands are executed.",
        "when sdist, etc commands"
    ],
    [
        "If __svn_version__.py existed before, nothing is done.",
        "If __svn_version__.py existed before, nothing"
    ],
    [
        "intended for working with source directories that are in an SVN",
        "intended for working with source directories that"
    ],
    [
        "if os.path.isfile(target) or revision is None:",
        "if os.path.isfile(target) or"
    ],
    [
        "self.info('Creating %s (version=%r)' % (target, version))",
        "self.info('Creating %s (version=%r)' % (target,"
    ],
    [
        "\"\"\"Appends a data function to the data_files list that will generate",
        "\"\"\"Appends a data function to the data_files"
    ],
    [
        "__hg_version__.py file to the current package directory.",
        "__hg_version__.py file to the current"
    ],
    [
        "Generate package __hg_version__.py file from Mercurial revision,",
        "Generate package __hg_version__.py file from"
    ],
    [
        "it will be removed after python exits but will be available",
        "it will be removed after python exits"
    ],
    [
        "when sdist, etc commands are executed.",
        "when sdist, etc"
    ],
    [
        "If __hg_version__.py existed before, nothing is done.",
        "If __hg_version__.py existed before, nothing is"
    ],
    [
        "This is intended for working with source directories that are",
        "This is intended for working with"
    ],
    [
        "if os.path.isfile(target) or revision is None:",
        "if os.path.isfile(target) or"
    ],
    [
        "self.info('Creating %s (version=%r)' % (target, version))",
        "self.info('Creating %s (version=%r)' % (target,"
    ],
    [
        "\"\"\"Generate package __config__.py file containing system_info",
        "\"\"\"Generate package __config__.py file"
    ],
    [
        "information used during building the package.",
        "information used during"
    ],
    [
        "This file is installed to the",
        "This file is"
    ],
    [
        "Return information (from system_info.get_info) for all of the names in",
        "Return information (from system_info.get_info) for all of the"
    ],
    [
        "the argument list in a single dictionary.",
        "the argument list in"
    ],
    [
        "\"\"\"Return the path where to find the npy-pkg-config directory.",
        "\"\"\"Return the path where to find"
    ],
    [
        "If the NPY_PKG_CONFIG_PATH environment variable is set, the value of that",
        "If the NPY_PKG_CONFIG_PATH environment variable is set, the"
    ],
    [
        "is returned.  Otherwise, a path inside the location of the numpy module is",
        "is returned. Otherwise, a path inside the location"
    ],
    [
        "The NPY_PKG_CONFIG_PATH can be useful when cross-compiling, maintaining",
        "The NPY_PKG_CONFIG_PATH can be useful"
    ],
    [
        "customized npy-pkg-config .ini files for the cross-compilation",
        "customized npy-pkg-config .ini files for the"
    ],
    [
        "environment, and using them when cross-compiling.",
        "environment, and using them"
    ],
    [
        "Return library info for the given package.",
        "Return library info for the given"
    ],
    [
        "Name of the package (should match the name of the .ini file, without",
        "Name of the package (should match the name of"
    ],
    [
        "the extension, e.g. foo for the file foo.ini).",
        "the extension, e.g. foo for"
    ],
    [
        "If given, should be a sequence of additional directories where to look",
        "If given, should be a sequence of"
    ],
    [
        "for npy-pkg-config files. Those directories are searched prior to the",
        "for npy-pkg-config files. Those directories"
    ],
    [
        "The `LibraryInfo` instance containing the build information.",
        "The `LibraryInfo` instance containing the build"
    ],
    [
        "If the package is not found.",
        "If the package is"
    ],
    [
        "Return an info dict for a given C library.",
        "Return an info dict for a given"
    ],
    [
        "The info dict contains the necessary options to use the C library.",
        "The info dict contains the necessary options to"
    ],
    [
        "Name of the package (should match the name of the .ini file, without",
        "Name of the package (should match the name of the .ini"
    ],
    [
        "the extension, e.g. foo for the file foo.ini).",
        "the extension, e.g. foo for"
    ],
    [
        "If given, should be a sequence of additional directories where to look",
        "If given, should be a sequence of additional"
    ],
    [
        "for npy-pkg-config files. Those directories are searched prior to the",
        "for npy-pkg-config files. Those directories are"
    ],
    [
        "If the package is not found.",
        "If the package"
    ],
    [
        "To get the necessary information for the npymath library from NumPy:",
        "To get the necessary information for the npymath library"
    ],
    [
        "This info dict can then be used as input to a `Configuration` instance::",
        "This info dict can then be used as input to"
    ],
    [
        "def default_config_dict(name = None, parent_name = None, local_path=None):",
        "def default_config_dict(name = None,"
    ],
    [
        "\"\"\"Return a configuration dictionary for usage in",
        "\"\"\"Return a configuration dictionary"
    ],
    [
        "configuration() function defined in file setup_<name>.py.",
        "configuration() function defined in file"
    ],
    [
        "if os.path.join(absprefix[:len(d)], absprefix[len(d):]) != absprefix \\",
        "if os.path.join(absprefix[:len(d)], absprefix[len(d):]) !="
    ],
    [
        "\"\"\"Generate config.py file containing system_info information",
        "\"\"\"Generate config.py file containing system_info"
    ],
    [
        "return g.get(name, g.get(name + \"_info\", {}))",
        "return g.get(name, g.get(name +"
    ],
    [
        "Show libraries in the system on which NumPy was built.",
        "Show libraries in the system on which"
    ],
    [
        "Print information about various resources (libraries, library",
        "Print information about various resources"
    ],
    [
        "directories, include directories, etc.) in the system on which",
        "directories, include directories, etc.) in"
    ],
    [
        "get_include : Returns the directory containing NumPy C",
        "get_include : Returns the directory"
    ],
    [
        "* ``language``: language used to write the libraries (mostly",
        "* ``language``: language used to"
    ],
    [
        "* ``libraries``: names of libraries found in the system",
        "* ``libraries``: names of libraries found in"
    ],
    [
        "* ``library_dirs``: directories containing the libraries",
        "* ``library_dirs``: directories containing the"
    ],
    [
        "* ``include_dirs``: directories containing library header files",
        "* ``include_dirs``: directories containing library"
    ],
    [
        "* ``src_dirs``: directories containing library source files",
        "* ``src_dirs``: directories containing library"
    ],
    [
        "* ``define_macros``: preprocessor macros used by",
        "* ``define_macros``: preprocessor"
    ],
    [
        "* ``baseline``: minimum CPU features required",
        "* ``baseline``: minimum CPU"
    ],
    [
        "* ``found``: dispatched features supported in the system",
        "* ``found``: dispatched features supported in the"
    ],
    [
        "* ``not found``: dispatched features that are not supported",
        "* ``not found``: dispatched features that are not"
    ],
    [
        "Installing a numpy wheel (``pip install numpy`` or force it",
        "Installing a numpy wheel (``pip install"
    ],
    [
        "via ``pip install numpy --only-binary :numpy: numpy``) includes",
        "via ``pip install numpy --only-binary :numpy: numpy``)"
    ],
    [
        "an OpenBLAS implementation of the BLAS and LAPACK linear algebra",
        "an OpenBLAS implementation of the BLAS and LAPACK linear"
    ],
    [
        "APIs. In this case, ``library_dirs`` reports the original build",
        "APIs. In this case, ``library_dirs``"
    ],
    [
        "time configuration as compiled with gcc/gfortran; at run time",
        "time configuration as compiled with gcc/gfortran; at run"
    ],
    [
        "(``pip install numpy --no-binary numpy``) searches for BLAS and",
        "(``pip install numpy --no-binary numpy``) searches"
    ],
    [
        "LAPACK dynamic link libraries at build time as influenced by",
        "LAPACK dynamic link libraries at build time"
    ],
    [
        "NumPy remembers those locations and expects to load the same",
        "NumPy remembers those locations and expects to load the"
    ],
    [
        "library) is in the default build-time search order after",
        "library) is in the default build-time"
    ],
    [
        "print(\"    %s = %s\" % (k,v))",
        "print(\" %s = %s\" %"
    ],
    [
        "print(\"Supported SIMD extensions in this NumPy install:\")",
        "print(\"Supported SIMD extensions in this"
    ],
    [
        "print(\"    baseline = %s\" % (','.join(__cpu_baseline__)))",
        "print(\" baseline = %s\" %"
    ],
    [
        "print(\"    found = %s\" % (','.join(features_found)))",
        "print(\" found ="
    ],
    [
        "print(\"    not found = %s\" % (','.join(features_not_found)))",
        "print(\" not found ="
    ],
    [
        "\"\"\"Return version major and minor of compiler instance if it is",
        "\"\"\"Return version major and minor of compiler instance"
    ],
    [
        "raise ValueError(\"Compiler instance is not msvc (%s)\"\\",
        "raise ValueError(\"Compiler instance is"
    ],
    [
        "Some flags are valid for C but not C++. Prune them.",
        "Some flags are valid for C but not"
    ],
    [
        "return [flag for flag in cxxflags if flag not in _cxx_ignore_flags]",
        "return [flag for flag in cxxflags if flag not in"
    ],
    [
        "Use importlib machinery to import a module `modname` from the file",
        "Use importlib machinery to import a module `modname` from the"
    ],
    [
        "`modfile`. Depending on the `spec.loader`, the module may not be",
        "`modfile`. Depending on the `spec.loader`, the module"
    ],
    [
        "from distutils.log import Log as old_Log",
        "from distutils.log import"
    ],
    [
        "from numpy.distutils.misc_util import (red_text, default_text, cyan_text,",
        "from numpy.distutils.misc_util import"
    ],
    [
        "If we log WARN messages, log this message as a 'nice' anti-warn",
        "If we log WARN messages, log this"
    ],
    [
        "if prev_level > DEBUG or force:",
        "if prev_level >"
    ],
    [
        "info('set_threshold: setting threshold to DEBUG level,'",
        "info('set_threshold: setting threshold to DEBUG"
    ],
    [
        "' it can be changed only with force argument')",
        "' it can be changed only with"
    ],
    [
        "info('set_threshold: not changing threshold from DEBUG level'",
        "info('set_threshold: not changing threshold from DEBUG"
    ],
    [
        "' %s to %s' % (prev_level, level))",
        "' %s to %s' %"
    ],
    [
        "\"\"\" Functions for converting from DOS to UNIX line endings",
        "\"\"\" Functions for converting from DOS to UNIX"
    ],
    [
        "\"Replace CRLF with LF in argument files.  Print names of changed files.\"",
        "\"Replace CRLF with LF in argument files. Print names"
    ],
    [
        "\"Replace LF with CRLF in argument files.  Print names of changed files.\"",
        "\"Replace LF with CRLF in argument files. Print names of"
    ],
    [
        "__doc__ = \"\"\"This module generates a DEF file from the symbols in",
        "__doc__ = \"\"\"This module generates a DEF file from the symbols"
    ],
    [
        "an MSVC-compiled DLL import library.  It correctly discriminates between",
        "an MSVC-compiled DLL import library. It correctly"
    ],
    [
        "data and functions.  The data is collected from the output of the program",
        "data and functions. The data is collected from the output"
    ],
    [
        "libname.lib defaults to python<py_ver>.lib and output.def defaults to stdout",
        "libname.lib defaults to python<py_ver>.lib and"
    ],
    [
        "FUNC_RE = re.compile(r\"^(.*) in python%s\\.dll\" % py_ver, re.MULTILINE)",
        "FUNC_RE = re.compile(r\"^(.*) in python%s\\.dll\" % py_ver,"
    ],
    [
        "DATA_RE = re.compile(r\"^_imp__(.*) in python%s\\.dll\" % py_ver, re.MULTILINE)",
        "DATA_RE = re.compile(r\"^_imp__(.*) in python%s\\.dll\" % py_ver,"
    ],
    [
        "print(\"I'm assuming that your first argument is the library\")",
        "print(\"I'm assuming that your first argument"
    ],
    [
        "print(\"and the second is the DEF file.\")",
        "print(\"and the second is"
    ],
    [
        "def getnm(nm_cmd=['nm', '-Cs', 'python%s.lib' % py_ver], shell=True):",
        "def getnm(nm_cmd=['nm', '-Cs', 'python%s.lib' %"
    ],
    [
        "\"\"\"Returns the output of nm_cmd via a pipe.",
        "\"\"\"Returns the output of nm_cmd via a"
    ],
    [
        "nm_output = getnm(nm_cmd = 'nm -Cs py_lib')\"\"\"",
        "nm_output = getnm(nm_cmd = 'nm -Cs"
    ],
    [
        "raise RuntimeError('failed to run \"%s\": \"%s\"' % (",
        "raise RuntimeError('failed to run \"%s\": \"%s\"' %"
    ],
    [
        "\"\"\"Returns a tuple of lists: dlist for the list of data",
        "\"\"\"Returns a tuple of lists: dlist for"
    ],
    [
        "symbols and flist for the list of function symbols.",
        "symbols and flist for the list of"
    ],
    [
        "def output_def(dlist, flist, header, file = sys.stdout):",
        "def output_def(dlist, flist, header,"
    ],
    [
        "\"\"\"Outputs the final DEF file to a file defaulting to stdout.",
        "\"\"\"Outputs the final DEF file to"
    ],
    [
        "output_def(dlist, flist, header, file = sys.stdout)\"\"\"",
        "output_def(dlist, flist, header, file"
    ],
    [
        "header = header + '\\t%s DATA\\n' % data_sym",
        "header = header + '\\t%s DATA\\n'"
    ],
    [
        "header = header + '\\t%s\\n' % func_sym",
        "header = header +"
    ],
    [
        "PathScale compiler compatible with an gcc built Python.",
        "PathScale compiler compatible with"
    ],
    [
        "This file defines a set of system_info classes for getting",
        "This file defines a set of system_info"
    ],
    [
        "information about various resources (libraries, library directories,",
        "information about various resources (libraries,"
    ],
    [
        "include directories, etc.) in the system. Usage:",
        "include directories, etc.) in the"
    ],
    [
        "'lapack_src', 'blas_src', etc. For a complete list of allowed names,",
        "'lapack_src', 'blas_src', etc. For a"
    ],
    [
        "see the definition of get_info() function below.",
        "see the definition of get_info()"
    ],
    [
        "Returned info_dict is a dictionary which is compatible with",
        "Returned info_dict is a dictionary"
    ],
    [
        "distutils.setup keyword arguments. If info_dict == {}, then the",
        "distutils.setup keyword arguments. If info_dict =="
    ],
    [
        "asked resource is not available (system_info could not find it).",
        "asked resource is not available (system_info could"
    ],
    [
        "Several *_info classes specify an environment variable to specify",
        "Several *_info classes specify an environment variable"
    ],
    [
        "the locations of software. When setting the corresponding environment",
        "the locations of software. When setting the corresponding"
    ],
    [
        "variable to 'None' then the software will be ignored, even when it",
        "variable to 'None' then the software will be"
    ],
    [
        "system_info.search_static_first - search static libraries (.a)",
        "system_info.search_static_first - search"
    ],
    [
        "in precedence to shared ones (.so, .sl) if enabled.",
        "in precedence to shared ones (.so, .sl) if"
    ],
    [
        "system_info.verbosity - output the results to stdout if enabled.",
        "system_info.verbosity - output the results to stdout if"
    ],
    [
        "The file 'site.cfg' is looked for in",
        "The file 'site.cfg' is looked"
    ],
    [
        "The first one found is used to get system configuration options The",
        "The first one found is used to get system"
    ],
    [
        "format is that used by ConfigParser (i.e., Windows .INI style). The",
        "format is that used by ConfigParser"
    ],
    [
        "section ALL is not intended for general use.",
        "section ALL is not"
    ],
    [
        "Appropriate defaults are used if nothing is specified.",
        "Appropriate defaults are used if"
    ],
    [
        "The order of finding the locations of resources is the following:",
        "The order of finding the locations of resources is"
    ],
    [
        "Only the first complete match is returned.",
        "Only the first complete match"
    ],
    [
        "Currently, the following classes are available, along with their section names:",
        "Currently, the following classes are available, along"
    ],
    [
        "Note that blas_opt_info and lapack_opt_info honor the NPY_BLAS_ORDER",
        "Note that blas_opt_info and lapack_opt_info honor"
    ],
    [
        "and NPY_LAPACK_ORDER environment variables to determine the order in which",
        "and NPY_LAPACK_ORDER environment variables to determine the"
    ],
    [
        "specific BLAS and LAPACK libraries are searched for.",
        "specific BLAS and LAPACK libraries are searched"
    ],
    [
        "This search (or autodetection) can be bypassed by defining the environment",
        "This search (or autodetection) can be bypassed by defining"
    ],
    [
        "variables NPY_BLAS_LIBS and NPY_LAPACK_LIBS, which should then contain the",
        "variables NPY_BLAS_LIBS and NPY_LAPACK_LIBS, which"
    ],
    [
        "Netlib BLAS/LAPACK or stub files, in order to be able to switch BLAS and LAPACK",
        "Netlib BLAS/LAPACK or stub files, in order to be able to"
    ],
    [
        "implementations at runtime. If using this to build NumPy itself, it is",
        "implementations at runtime. If using this to build NumPy itself,"
    ],
    [
        "recommended to also define NPY_CBLAS_LIBS (assuming your BLAS library has a",
        "recommended to also define NPY_CBLAS_LIBS (assuming your BLAS"
    ],
    [
        "CBLAS interface) to enable CBLAS usage for matrix multiplication (unoptimized",
        "CBLAS interface) to enable CBLAS usage for matrix"
    ],
    [
        "Note that the ``libraries`` key is the default setting for libraries.",
        "Note that the ``libraries`` key is the"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is given"
    ],
    [
        "terms of the NumPy (BSD style) license.  See LICENSE.txt that came with",
        "terms of the NumPy (BSD style)"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE"
    ],
    [
        "from configparser import RawConfigParser as ConfigParser",
        "from configparser import RawConfigParser"
    ],
    [
        "from numpy.distutils.command.config import config as cmd_config",
        "from numpy.distutils.command.config import config as"
    ],
    [
        "from numpy.distutils import customized_ccompiler as _customized_ccompiler",
        "from numpy.distutils import customized_ccompiler"
    ],
    [
        "Convert a python string into a literal suitable for inclusion into C code",
        "Convert a python string into a literal suitable for"
    ],
    [
        "A sequence of strings (typically paths)",
        "A sequence of"
    ],
    [
        "_include_dirs = [d.replace('/', os.sep) for d in _include_dirs]",
        "_include_dirs = [d.replace('/', os.sep) for d in"
    ],
    [
        "_lib_dirs = [d.replace('/', os.sep) for d in _lib_dirs]",
        "_lib_dirs = [d.replace('/', os.sep) for d"
    ],
    [
        "\"\"\"Add a package manager root to the include directories\"\"\"",
        "\"\"\"Add a package manager root to the include"
    ],
    [
        "os.path.join(library_root, d) for d in _lib_dirs)",
        "os.path.join(library_root, d) for"
    ],
    [
        "os.path.join(library_root, d) for d in _include_dirs)",
        "os.path.join(library_root, d) for d"
    ],
    [
        "default_src_dirs = ['.', '/usr/local/src', '/opt/src', '/sw/src']",
        "default_src_dirs = ['.',"
    ],
    [
        "if os.path.join(sys.prefix, 'lib') not in default_lib_dirs:",
        "if os.path.join(sys.prefix, 'lib')"
    ],
    [
        "default_lib_dirs = [_m for _m in default_lib_dirs if os.path.isdir(_m)]",
        "default_lib_dirs = [_m for _m in default_lib_dirs if"
    ],
    [
        "default_runtime_dirs = [_m for _m in default_runtime_dirs if os.path.isdir(_m)]",
        "default_runtime_dirs = [_m for _m in default_runtime_dirs"
    ],
    [
        "default_include_dirs = [_m for _m in default_include_dirs if os.path.isdir(_m)]",
        "default_include_dirs = [_m for _m in"
    ],
    [
        "default_src_dirs = [_m for _m in default_src_dirs if os.path.isdir(_m)]",
        "default_src_dirs = [_m for _m in default_src_dirs if"
    ],
    [
        "\"\"\"Returns a list of files named 'fname' from",
        "\"\"\"Returns a list of files"
    ],
    [
        "\"\"\" Parse an environment variable `env` by splitting with \",\" and only returning elements from `base_order`",
        "\"\"\" Parse an environment variable `env` by splitting with \",\" and"
    ],
    [
        "This method will sequence the environment variable and check for their",
        "This method will sequence the environment variable and"
    ],
    [
        "The items in the environment variable may be negated via '^item' or '!itema,itemb'.",
        "The items in the environment variable may be negated"
    ],
    [
        "It must start with ^/! to negate all options.",
        "It must start with ^/! to"
    ],
    [
        "ValueError: for mixed negated and non-negated orders or multiple negated orders",
        "ValueError: for mixed negated and non-negated orders or multiple negated"
    ],
    [
        "the environment variable to be parsed, if none is found, `base_order` is returned",
        "the environment variable to be parsed, if none is found, `base_order`"
    ],
    [
        "for values not overlapping with `base_order`",
        "for values not overlapping with"
    ],
    [
        "base_order = [order.lower() for order in base_order]",
        "base_order = [order.lower() for order in"
    ],
    [
        "raise ValueError(f\"Environment variable '{env}' may only contain a single (prefixed) negation: {order_str}\")",
        "raise ValueError(f\"Environment variable '{env}' may only contain a single"
    ],
    [
        "raise ValueError(f\"Environment variable '{env}' may not mix negated an non-negated items: {order_str}\")",
        "raise ValueError(f\"Environment variable '{env}' may not mix"
    ],
    [
        "\"\"\"Some third-party program or library is not found.\"\"\"",
        "\"\"\"Some third-party program or library"
    ],
    [
        "Aliases entries in config files should not be existing.",
        "Aliases entries in config files should"
    ],
    [
        "In section '{section}' we found multiple appearances of options {options}.\"\"\"",
        "In section '{section}' we found multiple appearances"
    ],
    [
        "Directories to search for the libraries can be specified in the",
        "Directories to search for the libraries"
    ],
    [
        "numpy/distutils/site.cfg file (section [atlas]) or by setting",
        "numpy/distutils/site.cfg file (section [atlas]) or by"
    ],
    [
        "Directories to search for the libraries can be specified in the",
        "Directories to search for the libraries can be"
    ],
    [
        "Directories to search for the libraries can be specified in the",
        "Directories to search for the libraries can be"
    ],
    [
        "numpy/distutils/site.cfg file (section [lapack]) or by setting",
        "numpy/distutils/site.cfg file (section [lapack]) or by"
    ],
    [
        "Directories to search for the sources can be specified in the",
        "Directories to search for the sources can"
    ],
    [
        "numpy/distutils/site.cfg file (section [lapack_src]) or by setting",
        "numpy/distutils/site.cfg file (section [lapack_src])"
    ],
    [
        "Known libraries in numpy/distutils/site.cfg file are:",
        "Known libraries in numpy/distutils/site.cfg"
    ],
    [
        "Optimized (vendor) Blas libraries are not found.",
        "Optimized (vendor) Blas libraries"
    ],
    [
        "Falls back to netlib Blas library which has worse performance.",
        "Falls back to netlib Blas library which"
    ],
    [
        "A better performance should be easily gained by switching",
        "A better performance should be easily"
    ],
    [
        "Directories to search for the libraries can be specified in the",
        "Directories to search for the libraries can be specified"
    ],
    [
        "numpy/distutils/site.cfg file (section [blas]) or by setting",
        "numpy/distutils/site.cfg file (section [blas]) or by"
    ],
    [
        "Known libraries in numpy/distutils/site.cfg file are:",
        "Known libraries in numpy/distutils/site.cfg"
    ],
    [
        "Directories to search for the sources can be specified in the",
        "Directories to search for the sources can be specified"
    ],
    [
        "numpy/distutils/site.cfg file (section [blas_src]) or by setting",
        "numpy/distutils/site.cfg file (section [blas_src]) or by"
    ],
    [
        "Directories to search for the libraries can be specified in the",
        "Directories to search for the libraries can"
    ],
    [
        "numpy/distutils/site.cfg file (section [fftw]) or by setting",
        "numpy/distutils/site.cfg file (section [fftw]) or by"
    ],
    [
        "Directories to search for the libraries can be specified in the",
        "Directories to search for the libraries"
    ],
    [
        "numpy/distutils/site.cfg file (section [djbfft]) or by setting",
        "numpy/distutils/site.cfg file (section [djbfft])"
    ],
    [
        "Get it from above location, install it, and retry setup.py.\"\"\"",
        "Get it from above location, install"
    ],
    [
        "not found. Directories to search for the libraries can be specified in the",
        "not found. Directories to search for the libraries can be specified in"
    ],
    [
        "numpy/distutils/site.cfg file (section [umfpack]) or by setting",
        "numpy/distutils/site.cfg file (section [umfpack])"
    ],
    [
        "\"\"\" get_info() is the only public method. Don't use others.",
        "\"\"\" get_info() is the only public method."
    ],
    [
        "log.info('Library %s was not found. Ignoring' % (lib))",
        "log.info('Library %s was not found."
    ],
    [
        "log.info('Runtime library %s was not found. Ignoring' % (lib))",
        "log.info('Runtime library %s was not found. Ignoring' %"
    ],
    [
        "\"\"\" Ensure that only one of `options` are found in the section",
        "\"\"\" Ensure that only one of `options` are"
    ],
    [
        "a list of options to be found in the section (``self.section``)",
        "a list of options to be found"
    ],
    [
        "the option that is uniquely found in the section",
        "the option that is uniquely"
    ],
    [
        "in case more than one of the options are found",
        "in case more than one"
    ],
    [
        "found = [self.cp.has_option(self.section, opt) for opt in options]",
        "found = [self.cp.has_option(self.section, opt) for"
    ],
    [
        "\"\"\" Updates the information in the current information with",
        "\"\"\" Updates the information in the current information"
    ],
    [
        "\"\"\" Return a dictionary with items that are compatible",
        "\"\"\" Return a dictionary with items that are"
    ],
    [
        "if log.get_threshold() <= log.INFO and flag:",
        "if log.get_threshold() <= log.INFO"
    ],
    [
        "log.info('    %s = %s', k, v)",
        "log.info(' %s ="
    ],
    [
        "if env_var and env_var in os.environ:",
        "if env_var and"
    ],
    [
        "log.debug('( %s = %s )', key, ':'.join(ret))",
        "log.debug('( %s = %s )',"
    ],
    [
        "return [b for b in [a.strip() for a in libs.split(',')] if b]",
        "return [b for b in [a.strip() for a in libs.split(',')] if"
    ],
    [
        "\"\"\"If static or shared libraries are available then return",
        "\"\"\"If static or shared libraries"
    ],
    [
        "Checks for all libraries as shared libraries first, then",
        "Checks for all libraries as shared libraries first,"
    ],
    [
        "static (or vice versa if self.search_static_first is True).",
        "static (or vice versa if self.search_static_first is"
    ],
    [
        "info = self._check_libs(lib_dirs, libs, opt_libs, [ext])",
        "info = self._check_libs(lib_dirs, libs, opt_libs,"
    ],
    [
        "log.info('  libraries %s not found in %s', ','.join(libs),",
        "log.info(' libraries %s not found in %s',"
    ],
    [
        "\"\"\"If static or shared libraries are available then return",
        "\"\"\"If static or shared libraries are available"
    ],
    [
        "Checks each library for shared or static.",
        "Checks each library for"
    ],
    [
        "info = self._check_libs(lib_dirs, libs, opt_libs, exts)",
        "info = self._check_libs(lib_dirs, libs, opt_libs,"
    ],
    [
        "log.info('  libraries %s not found in %s', ','.join(libs),",
        "log.info(' libraries %s not found in %s',"
    ],
    [
        "p = self.combine_paths(lib_dir, prefix + lib + ext)",
        "p = self.combine_paths(lib_dir, prefix + lib"
    ],
    [
        "def _check_libs(self, lib_dirs, libs, opt_libs, exts):",
        "def _check_libs(self, lib_dirs, libs, opt_libs,"
    ],
    [
        "\"\"\"Find mandatory and optional libs in expected paths.",
        "\"\"\"Find mandatory and optional libs in"
    ],
    [
        "Missing optional libraries are silently forgotten.",
        "Missing optional libraries are silently"
    ],
    [
        "found_dirs, found_libs = self._find_libs(lib_dirs, libs, exts)",
        "found_dirs, found_libs = self._find_libs(lib_dirs,"
    ],
    [
        "opt_found_dirs, opt_found_libs = self._find_libs(lib_dirs, opt_libs, exts)",
        "opt_found_dirs, opt_found_libs = self._find_libs(lib_dirs,"
    ],
    [
        "info = {'libraries': found_libs, 'library_dirs': found_dirs}",
        "info = {'libraries': found_libs, 'library_dirs':"
    ],
    [
        "\"\"\"Return a list of existing paths composed by all combinations",
        "\"\"\"Return a list of existing"
    ],
    [
        "\"\"\"Returns True on successful version detection, else False\"\"\"",
        "\"\"\"Returns True on successful version detection, else"
    ],
    [
        "opt = self.get_option_single(self.section + '_libs', 'libraries')",
        "opt = self.get_option_single(self.section + '_libs',"
    ],
    [
        "log.info('  %s not found' % (ver_param['name']))",
        "log.info(' %s not found'"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d"
    ],
    [
        "p = self.combine_paths(d, ['libdjbfft.a', 'libdjbfft' + so_ext])",
        "p = self.combine_paths(d, ['libdjbfft.a', 'libdjbfft' +"
    ],
    [
        "info = {'libraries': ['djbfft'], 'library_dirs': [d]}",
        "info = {'libraries': ['djbfft'],"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d in dirs"
    ],
    [
        "atlas_libs = self.get_libs(opt, self._lib_names + self._lib_atlas)",
        "atlas_libs = self.get_libs(opt, self._lib_names +"
    ],
    [
        "h = (self.combine_paths(lib_dirs + include_dirs, 'cblas.h') or [None])",
        "h = (self.combine_paths(lib_dirs + include_dirs, 'cblas.h')"
    ],
    [
        "Could not find lapack library within the ATLAS installation.",
        "Could not find lapack library"
    ],
    [
        "fn = os.path.join(lapack_dir, prefix + lapack_name + e)",
        "fn = os.path.join(lapack_dir, prefix + lapack_name"
    ],
    [
        "Lapack library (from ATLAS) is probably incomplete:",
        "Lapack library (from ATLAS)"
    ],
    [
        "Follow the instructions in the KNOWN PROBLEMS section of the file",
        "Follow the instructions in the KNOWN PROBLEMS section of the"
    ],
    [
        "atlas_libs = self.get_libs(opt, self._lib_names + self._lib_atlas)",
        "atlas_libs = self.get_libs(opt,"
    ],
    [
        "h = (self.combine_paths(lib_dirs + include_dirs, 'cblas.h') or [None])",
        "h = (self.combine_paths(lib_dirs +"
    ],
    [
        "h = (self.combine_paths(lib_dirs + include_dirs, 'cblas.h') or [None])",
        "h = (self.combine_paths(lib_dirs + include_dirs, 'cblas.h')"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d in"
    ],
    [
        "larra larrc larrd larr larrk larrj larrr laneg laisnan isnan",
        "larra larrc larrd larr larrk larrj larrr"
    ],
    [
        "gges ggesx ggev ggevx ggglm gghrd gglse ggqrf ggrqf ggsvd",
        "gges ggesx ggev ggevx ggglm"
    ],
    [
        "lalsa lalsd langb lange langt lanhs lansb lansp lansy lantb",
        "lalsa lalsd langb lange langt"
    ],
    [
        "lartv larz larzb larzt laswp lasyf latbs latdf latps latrd",
        "lartv larz larzb larzt laswp"
    ],
    [
        "potrf potri potrs ppcon ppequ pprfs ppsv ppsvx pptrf pptri",
        "potrf potri potrs ppcon ppequ pprfs ppsv"
    ],
    [
        "spsv spsvx sptrf sptri sptrs stegr stein sycon syrfs sysv",
        "spsv spsvx sptrf sptri sptrs stegr stein"
    ],
    [
        "ormrq ormrz ormtr rscl sbev sbevd sbevx sbgst sbgv sbgvd sbgvx",
        "ormrq ormrz ormtr rscl sbev sbevd sbevx sbgst sbgv"
    ],
    [
        "sbtrd spev spevd spevx spgst spgv spgvd spgvx sptrd stev stevd",
        "sbtrd spev spevd spevx spgst spgv spgvd spgvx sptrd"
    ],
    [
        "bdsqr hbev hbevd hbevx hbgst hbgv hbgvd hbgvx hbtrd hecon heev",
        "bdsqr hbev hbevd hbevx hbgst hbgv hbgvd hbgvx"
    ],
    [
        "hpevx hpgst hpgv hpgvd hpgvx hprfs hpsv hpsvx hptrd hptrf",
        "hpevx hpgst hpgv hpgvd hpgvx"
    ],
    [
        "laqhp larcm larnv lartg lascl laset lasr lassq pttrf rot spmv",
        "laqhp larcm larnv lartg lascl laset lasr"
    ],
    [
        "sources = ['s%s.f' % f for f in (sclaux + slasrc).split()] \\",
        "sources = ['s%s.f' % f for f"
    ],
    [
        "+ ['d%s.f' % f for f in (dzlaux + dlasrc).split()] \\",
        "+ ['d%s.f' % f for f"
    ],
    [
        "+ ['c%s.f' % f for f in (clasrc).split()] \\",
        "+ ['c%s.f' % f for"
    ],
    [
        "+ ['z%s.f' % f for f in (zlasrc).split()] \\",
        "+ ['z%s.f' % f for"
    ],
    [
        "+ ['%s.f' % f for f in (allaux + oclasrc + ozlasrc).split()]",
        "+ ['%s.f' % f for f"
    ],
    [
        "sources = [os.path.join(src_dir, f) for f in sources]",
        "sources = [os.path.join(src_dir, f) for f"
    ],
    [
        "sources += [os.path.join(src_dir, p + 'larfp.f') for p in 'sdcz']",
        "sources += [os.path.join(src_dir, p +"
    ],
    [
        "sources += [os.path.join(src_dir, 'ila' + p + 'lr.f') for p in 'sdcz']",
        "sources += [os.path.join(src_dir, 'ila' + p + 'lr.f') for p"
    ],
    [
        "sources += [os.path.join(src_dir, 'ila' + p + 'lc.f') for p in 'sdcz']",
        "sources += [os.path.join(src_dir, 'ila' + p"
    ],
    [
        "sources = [f for f in sources if os.path.isfile(f)]",
        "sources = [f for f in sources"
    ],
    [
        "/* This file is generated from numpy/distutils/system_info.py */",
        "/* This file is"
    ],
    [
        "if s and re.search(r'undefined reference to `_gfortran', o, re.M):",
        "if s and re.search(r'undefined reference to `_gfortran', o,"
    ],
    [
        "Linkage with ATLAS requires gfortran. Use",
        "Linkage with ATLAS requires"
    ],
    [
        "when building extension libraries that use ATLAS.",
        "when building extension libraries that"
    ],
    [
        "Make sure that -lgfortran is used for C++ extensions.",
        "Make sure that -lgfortran is used for C++"
    ],
    [
        "m = re.search(r'ATLAS version (?P<version>\\d+[.]\\d+[.]\\d+)', o)",
        "m = re.search(r'ATLAS version"
    ],
    [
        "if re.search(r'undefined symbol: ATL_buildinfo', o, re.M):",
        "if re.search(r'undefined symbol: ATL_buildinfo', o,"
    ],
    [
        "result = _cached_atlas_version[key] = atlas_version, info",
        "result = _cached_atlas_version[key]"
    ],
    [
        "if ('ATLAS_WITH_LAPACK_ATLAS', None) in l \\",
        "if ('ATLAS_WITH_LAPACK_ATLAS', None)"
    ],
    [
        "if self.symbol_prefix not in (None, prefix):",
        "if self.symbol_prefix not in"
    ],
    [
        "if self.symbol_suffix not in (None, suffix):",
        "if self.symbol_suffix not"
    ],
    [
        "print('%s_lapack does not exist' % (name))",
        "print('%s_lapack does not exist' %"
    ],
    [
        "raise ValueError(\"blas_opt_info user defined BLAS order has unacceptable values: {}\".format(unknown_order))",
        "raise ValueError(\"blas_opt_info user defined BLAS order has unacceptable values:"
    ],
    [
        "\"\"\" Check whether we can link with CBLAS interface",
        "\"\"\" Check whether we can"
    ],
    [
        "This method will search through several combinations of libraries",
        "This method will search through"
    ],
    [
        "to check whether CBLAS is present:",
        "to check whether"
    ],
    [
        "system information dictionary for compilation and linking",
        "system information dictionary for compilation and"
    ],
    [
        "libraries : list of str or None",
        "libraries : list of str"
    ],
    [
        "a list of libraries that enables the use of CBLAS interface.",
        "a list of libraries that enables"
    ],
    [
        "Returns None if not found or a compilation error occurs.",
        "Returns None if not found"
    ],
    [
        "int main(int argc, const char *argv[])",
        "int main(int argc,"
    ],
    [
        "for libs in [info['libraries'], ['cblas'] + info['libraries'],",
        "for libs in [info['libraries'], ['cblas'] +"
    ],
    [
        "if c.compiler_type == \"msvc\" and info is None:",
        "if c.compiler_type == \"msvc\""
    ],
    [
        "fullpath = os.path.join(library_dir, library + '.a')",
        "fullpath = os.path.join(library_dir, library +"
    ],
    [
        "fake_lib_file = os.path.join(tmpdir, basename + '.fobjects')",
        "fake_lib_file = os.path.join(tmpdir,"
    ],
    [
        "fake_clib_file = os.path.join(tmpdir, basename + '.cobjects')",
        "fake_clib_file = os.path.join(tmpdir, basename +"
    ],
    [
        "prototypes = \"\\n\".join(\"void %s%s%s();\" % (self.symbol_prefix,",
        "prototypes = \"\\n\".join(\"void %s%s%s();\" %"
    ],
    [
        "int main(int argc, const char *argv[])",
        "int main(int argc, const"
    ],
    [
        "_require_symbols = ['dgemm_', 'cblas_dgemm', 'zungqr_', 'LAPACKE_zungqr']",
        "_require_symbols = ['dgemm_', 'cblas_dgemm',"
    ],
    [
        "\"\"\" Usage of libflame for LAPACK operations",
        "\"\"\" Usage of libflame"
    ],
    [
        "This requires libflame to be compiled with lapack wrappers:",
        "This requires libflame to be compiled"
    ],
    [
        "if you have problems, try the static flame library.",
        "if you have problems, try the static"
    ],
    [
        "\"\"\" libflame does not necessarily have a wrapper for fortran LAPACK, we need to check \"\"\"",
        "\"\"\" libflame does not necessarily have a wrapper for"
    ],
    [
        "int main(int argc, const char *argv[])",
        "int main(int argc, const char"
    ],
    [
        "info[key] = info.get(key, []) + blas_info[key]",
        "info[key] = info.get(key, [])"
    ],
    [
        "info[key] = info.get(key, ()) + blas_info[key]",
        "info[key] = info.get(key,"
    ],
    [
        "info[key] = info.get(key, '') + blas_info[key]",
        "info[key] = info.get(key, '') +"
    ],
    [
        "libraries = [lib.strip().lower() for lib in libraries]",
        "libraries = [lib.strip().lower() for"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d in dirs"
    ],
    [
        "srotmg zdrot cdotu daxpy drotm idamax scopy sscal zdscal crotg",
        "srotmg zdrot cdotu daxpy drotm idamax scopy sscal zdscal"
    ],
    [
        "stbmv zgemv zhpr chemv ctpmv dspmv dtpmv ssbmv stbsv zgerc",
        "stbmv zgemv zhpr chemv ctpmv dspmv"
    ],
    [
        "sources = [os.path.join(src_dir, f + '.f') \\",
        "sources = [os.path.join(src_dir, f + '.f')"
    ],
    [
        "sources = [f for f in sources if os.path.isfile(f)]",
        "sources = [f for f in sources if"
    ],
    [
        "raise ValueError(\"numerix selector must be either 'Numeric' \"",
        "raise ValueError(\"numerix selector must be either"
    ],
    [
        "\"or 'numarray' or 'numpy' but the value obtained\"",
        "\"or 'numarray' or 'numpy' but"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d in dirs if"
    ],
    [
        "srcs_dir = os.path.join(src_dir, 'libs', 'python', 'src')",
        "srcs_dir = os.path.join(src_dir, 'libs', 'python',"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d in"
    ],
    [
        "cmd = config_exe + ' ' + self.append_config_exe + ' ' + option",
        "cmd = config_exe + ' ' + self.append_config_exe + ' '"
    ],
    [
        "log.warn('File not found: %s. Cannot determine %s info.' \\",
        "log.warn('File not found: %s. Cannot"
    ],
    [
        "p = self.combine_paths(d, ['', 'umfpack'], 'umfpack.h')",
        "p = self.combine_paths(d,"
    ],
    [
        "\"\"\" Return a list of existing paths composed by all combinations of",
        "\"\"\" Return a list of existing paths"
    ],
    [
        "[d[k].append(vv) for vv in v if vv not in d[k]]",
        "[d[k].append(vv) for vv in v if"
    ],
    [
        "parser = optparse.OptionParser(\"usage: %prog [-v] [info objs]\")",
        "parser = optparse.OptionParser(\"usage: %prog [-v] [info"
    ],
    [
        "help='be verbose and print more messages')",
        "help='be verbose and print"
    ],
    [
        "if not issubclass(c, system_info) or c is system_info:",
        "if not issubclass(c, system_info) or"
    ],
    [
        "log.info('Info classes not defined: %s', ','.join(show_only))",
        "log.info('Info classes not defined: %s',"
    ],
    [
        "An enhanced distutils, providing support for Fortran compilers, for BLAS,",
        "An enhanced distutils, providing support"
    ],
    [
        "LAPACK and other common libraries for numerical computing, and more.",
        "LAPACK and other common libraries for numerical"
    ],
    [
        "For details, please see the *Packaging* and *NumPy Distutils User Guide*",
        "For details, please see the *Packaging*"
    ],
    [
        "sections of the NumPy Reference Guide.",
        "sections of the NumPy Reference"
    ],
    [
        "For configuring the preference for and location of libraries like BLAS and",
        "For configuring the preference for and location of libraries"
    ],
    [
        "LAPACK, and for setting include paths and similar build options, please see",
        "LAPACK, and for setting include paths and similar build options,"
    ],
    [
        "``site.cfg.example`` in the root of the NumPy repository or sdist.",
        "``site.cfg.example`` in the root of the NumPy"
    ],
    [
        "\"  of the deprecation of `distutils` itself. It will be removed for\\n\"",
        "\" of the deprecation of `distutils` itself. It will"
    ],
    [
        "from setuptools import setup as old_setup",
        "from setuptools import setup as"
    ],
    [
        "from distutils.core import setup as old_setup",
        "from distutils.core import"
    ],
    [
        "from numpy.distutils.command import config, config_compiler, \\",
        "from numpy.distutils.command import"
    ],
    [
        "build, build_py, build_ext, build_clib, build_src, build_scripts, \\",
        "build, build_py, build_ext, build_clib, build_src,"
    ],
    [
        "sdist, install_data, install_headers, install, bdist_rpm, \\",
        "sdist, install_data, install_headers, install,"
    ],
    [
        "\"\"\" Return True if command line does not contain any",
        "\"\"\" Return True if command line does not contain"
    ],
    [
        "display_opts = ['--'+n for n in Distribution.display_option_names]",
        "display_opts = ['--'+n for"
    ],
    [
        "if arg.startswith('--help') or arg=='-h' or arg in display_opts:",
        "if arg.startswith('--help') or arg=='-h' or arg in"
    ],
    [
        "if dist is not None and \\",
        "if dist is not"
    ],
    [
        "if always and dist is None:",
        "if always and dist is"
    ],
    [
        "raise TypeError(\"invalid description of extension module \"",
        "raise TypeError(\"invalid description of"
    ],
    [
        "if ('ext_modules' in new_attr or 'libraries' in new_attr) \\",
        "if ('ext_modules' in new_attr or 'libraries' in new_attr)"
    ],
    [
        "Implements exec_command function that is (almost) equivalent to",
        "Implements exec_command function that"
    ],
    [
        "commands.getstatusoutput function but on NT, DOS systems the",
        "commands.getstatusoutput function but on NT, DOS"
    ],
    [
        "returned status is actually correct (though, the returned status",
        "returned status is actually correct (though, the returned"
    ],
    [
        "values may be different by a factor). In addition, exec_command",
        "values may be different by a factor). In"
    ],
    [
        "takes keyword arguments for (re-)defining environment variables.",
        "takes keyword arguments for (re-)defining environment"
    ],
    [
        "exec_command  --- execute command in a specified directory and",
        "exec_command --- execute command in"
    ],
    [
        "find_executable --- locate a command using info from environment",
        "find_executable --- locate a command using info from"
    ],
    [
        "variable PATH. Equivalent to posix `which`",
        "variable PATH. Equivalent to posix"
    ],
    [
        "fail i.e. redefining environment variables may",
        "fail i.e. redefining"
    ],
    [
        "not work. FIXED: don't use cygwin echo!",
        "not work. FIXED: don't use cygwin"
    ],
    [
        "Comment: also `cmd /c echo` will not work",
        "Comment: also `cmd /c echo` will"
    ],
    [
        "but redefining environment variables do work.",
        "but redefining environment variables do"
    ],
    [
        "* Tests, that send messages to stderr, fail when executed from MSYS prompt",
        "* Tests, that send messages to stderr,"
    ],
    [
        "because the messages are lost at some point.",
        "because the messages are lost"
    ],
    [
        "Convert `bytes` in the encoding used by a subprocess into a filesystem-appropriate `str`.",
        "Convert `bytes` in the encoding used by a subprocess into a filesystem-appropriate"
    ],
    [
        "Inherited from `exec_command`, and possibly incorrect.",
        "Inherited from `exec_command`,"
    ],
    [
        "Forward bytes from a subprocess call to the console, without attempting to",
        "Forward bytes from a subprocess call to"
    ],
    [
        "The assumption is that the subprocess call already returned bytes in",
        "The assumption is that the subprocess call already returned"
    ],
    [
        "assert os.path.isfile(pythonexe), '%r is not a file' % (pythonexe,)",
        "assert os.path.isfile(pythonexe), '%r is not a"
    ],
    [
        "\"\"\"Return full path of a executable or None.",
        "\"\"\"Return full path of"
    ],
    [
        "paths = [ os.path.abspath(p) for p in path.split(os.pathsep) ]",
        "paths = [ os.path.abspath(p) for"
    ],
    [
        "log.warn('Could not locate executable %s' % orig_exe)",
        "log.warn('Could not locate executable"
    ],
    [
        "env = {name: os.environ.get(name) for name in names}",
        "env = {name: os.environ.get(name) for name"
    ],
    [
        "A concatenated string of executable and arguments.",
        "A concatenated string of executable"
    ],
    [
        "Before running command ``cd execute_in`` and after ``cd -``.",
        "Before running command ``cd execute_in``"
    ],
    [
        "If True, execute ``sh -c command``. Default None (True)",
        "If True, execute ``sh -c"
    ],
    [
        "If True use tee. Default None (True)",
        "If True use tee. Default"
    ],
    [
        "On NT, DOS systems the returned status is correct for external commands.",
        "On NT, DOS systems the returned status is correct"
    ],
    [
        "log.debug('Restored cwd to %s' % oldcwd)",
        "log.debug('Restored cwd to"
    ],
    [
        "def _exec_command(command, use_shell=None, use_tee = None, **env):",
        "def _exec_command(command, use_shell=None, use_tee ="
    ],
    [
        "if os.name == 'posix' and use_shell:",
        "if os.name == 'posix' and"
    ],
    [
        "command = [sh, '-c', ' '.join(command)]",
        "command = [sh, '-c', '"
    ],
    [
        "elif os.name == 'nt' and is_sequence(command):",
        "elif os.name == 'nt'"
    ],
    [
        "command = ' '.join(_quote_arg(arg) for arg in command)",
        "command = ' '.join(_quote_arg(arg) for arg"
    ],
    [
        "proc = subprocess.Popen(command, shell=use_shell, env=env, text=False,",
        "proc = subprocess.Popen(command,"
    ],
    [
        "Quote the argument for safe use in a shell command line.",
        "Quote the argument for safe use"
    ],
    [
        "if '\"' not in arg and ' ' in arg:",
        "if '\"' not in arg and ' '"
    ],
    [
        "takes templated file .xxx.src and produces .xxx file where .xxx",
        "takes templated file .xxx.src and produces .xxx"
    ],
    [
        "All function and subroutine blocks in a source file with names that",
        "All function and subroutine blocks in"
    ],
    [
        "contain '<..>' will be replicated according to the rules in '<..>'.",
        "contain '<..>' will be replicated according to the rules in"
    ],
    [
        "The number of comma-separated words in '<..>' will determine the number of",
        "The number of comma-separated words in"
    ],
    [
        "'<..>' may have two different forms, named and short. For example,",
        "'<..>' may have two different forms, named"
    ],
    [
        "<p=d,s,z,c> where anywhere inside a block '<p>' will be replaced with",
        "<p=d,s,z,c> where anywhere inside a block '<p>'"
    ],
    [
        "'d', 's', 'z', and 'c' for each replicate of the block.",
        "'d', 's', 'z', and 'c' for"
    ],
    [
        "<_t>  is already defined: <_t=real,double precision,complex,double complex>",
        "<_t> is already defined: <_t=real,double"
    ],
    [
        "<s,d,c,z>, a short form of the named, useful when no <p> appears inside",
        "<s,d,c,z>, a short form of the named, useful when no <p>"
    ],
    [
        "In general, '<..>' contains a comma separated list of arbitrary",
        "In general, '<..>' contains a comma separated list of"
    ],
    [
        "expressions. If these expression must contain a comma|leftarrow|rightarrow,",
        "expressions. If these expression must"
    ],
    [
        "then prepend the comma|leftarrow|rightarrow with a backslash.",
        "then prepend the comma|leftarrow|rightarrow with a"
    ],
    [
        "If an expression matches '\\\\<index>' then it will be replaced",
        "If an expression matches '\\\\<index>' then it"
    ],
    [
        "Note that all '<..>' forms in a block must have the same number of",
        "Note that all '<..>' forms in a block must have the"
    ],
    [
        "\"\"\" Return a list of tuples for each function or subroutine each",
        "\"\"\" Return a list of tuples"
    ],
    [
        "tuple is the start and end of a subroutine or function to be",
        "tuple is the start and end of"
    ],
    [
        "l = [x.strip() for x in b]",
        "l = [x.strip() for"
    ],
    [
        "\"\"\" Obtain a unique key given a dictionary.\"\"\"",
        "\"\"\" Obtain a unique"
    ],
    [
        "raise ValueError('No replicates found for <%s>' % (r))",
        "raise ValueError('No replicates found for"
    ],
    [
        "if r not in names and not thelist.startswith('_'):",
        "if r not in names"
    ],
    [
        "rule = [i.replace('@comma@', ',') for i in thelist.split(',')]",
        "rule = [i.replace('@comma@', ',') for i"
    ],
    [
        "print(\"Mismatch in number of replacements (base <%s=%s>)\"",
        "print(\"Mismatch in number of"
    ],
    [
        "newstr += template_re.sub(namerepl, substr) + '\\n\\n'",
        "newstr += template_re.sub(namerepl,"
    ],
    [
        "Support code for building Python extensions on Windows.",
        "Support code for building Python"
    ],
    [
        "from distutils.msvccompiler import get_build_version as get_build_msvc_version",
        "from distutils.msvccompiler import get_build_version"
    ],
    [
        "\"\"\"Replacement for outdated version of get_msvcr from cygwinccompiler\"\"\"",
        "\"\"\"Replacement for outdated version"
    ],
    [
        "return [] if msvcr is None else [msvcr]",
        "return [] if msvcr is None"
    ],
    [
        "if output_dir is None: output_dir = ''",
        "if output_dir is None: output_dir ="
    ],
    [
        "if ext not in (self.src_extensions + ['.rc', '.res']):",
        "if ext not in (self.src_extensions"
    ],
    [
        "\"unknown file type '%s' (from '%s')\" % \\",
        "\"unknown file type '%s' (from"
    ],
    [
        "if ext == '.res' or ext == '.rc':",
        "if ext == '.res' or"
    ],
    [
        "raise ValueError(\"%s not found in %s\" % (dllname, lib_dirs))",
        "raise ValueError(\"%s not found in %s\" % (dllname,"
    ],
    [
        "\"\"\"Given a dll file location,  get all its exported symbols and dump them",
        "\"\"\"Given a dll file location, get all its exported symbols and"
    ],
    [
        "The .def file will be overwritten\"\"\"",
        "The .def file will"
    ],
    [
        "log.warn('No symbols found in %s' % dll)",
        "log.warn('No symbols found in %s' %"
    ],
    [
        "for root, dirs, files in os.walk(winsxs_path):",
        "for root, dirs,"
    ],
    [
        "if dll_name in files and arch in root:",
        "if dll_name in files and arch in"
    ],
    [
        "for path in [sys.prefix] + os.environ['PATH'].split(';'):",
        "for path in [sys.prefix] +"
    ],
    [
        "'Runtime is not compiled with MSVC')",
        "'Runtime is not"
    ],
    [
        "log.debug('Skip building msvcr library: \"%s\" exists' %",
        "log.debug('Skip building msvcr library: \"%s\""
    ],
    [
        "log.warn('Cannot build msvcr library: \"%s\" not found' %",
        "log.warn('Cannot build msvcr library: \"%s\" not"
    ],
    [
        "log.info('Building msvcr library: \"%s\" (from %s)' \\",
        "log.info('Building msvcr library: \"%s\" (from %s)'"
    ],
    [
        "cmd = ['dlltool', '-d', def_file, '-l', out_file]",
        "cmd = ['dlltool', '-d', def_file, '-l',"
    ],
    [
        "raise ValueError(\"Unhandled arch %s\" % arch)",
        "raise ValueError(\"Unhandled arch"
    ],
    [
        "\"\"\"Check if an import library for the Python runtime already exists.\"\"\"",
        "\"\"\"Check if an import library for the Python runtime"
    ],
    [
        "if hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix:",
        "if hasattr(sys, 'base_prefix') and sys.base_prefix !="
    ],
    [
        "elif hasattr(sys, 'real_prefix') and sys.real_prefix != sys.prefix:",
        "elif hasattr(sys, 'real_prefix') and"
    ],
    [
        "filename = pat % (major_version, minor_version)",
        "filename = pat"
    ],
    [
        "log.debug('Skip building import library: \"%s\" exists', out_file)",
        "log.debug('Skip building import library: \"%s\""
    ],
    [
        "cmd = ['dlltool', '-d', def_file, '-l', out_file]",
        "cmd = ['dlltool', '-d', def_file, '-l',"
    ],
    [
        "log.debug('Skip building import library: \"%s\" exists', out_file)",
        "log.debug('Skip building import library:"
    ],
    [
        "log.warn('Cannot build import library: \"%s\" not found', lib_file)",
        "log.warn('Cannot build import library: \"%s\" not"
    ],
    [
        "log.warn('Failed to build import library for gcc. Linking will fail.')",
        "log.warn('Failed to build import library for gcc."
    ],
    [
        "log.warn('Cannot import msvcrt: using manifest will not be possible')",
        "log.warn('Cannot import msvcrt: using manifest will"
    ],
    [
        "\"\"\"Given a major and minor version of the MSVCR, returns the",
        "\"\"\"Given a major and minor version of the MSVCR,"
    ],
    [
        "raise ValueError(\"Version %d,%d of MSVCRT not supported yet\" %",
        "raise ValueError(\"Version %d,%d of MSVCRT not"
    ],
    [
        "return template % {'fullver': fullver, 'maj': maj, 'min': min}",
        "return template % {'fullver': fullver, 'maj':"
    ],
    [
        "\"\"\"Return the rc file used to generate the res file which will be embedded",
        "\"\"\"Return the rc file used to generate the res file"
    ],
    [
        "as manifest for given manifest file name, of given type ('dll' or",
        "as manifest for given manifest file name, of"
    ],
    [
        "name of the manifest file to embed",
        "name of the manifest"
    ],
    [
        "type of the binary which will embed the manifest",
        "type of the binary which"
    ],
    [
        "raise ValueError(\"Type %s not supported\" % type)",
        "raise ValueError(\"Type %s not"
    ],
    [
        "%d RT_MANIFEST %s\"\"\" % (rctype, name)",
        "%d RT_MANIFEST %s\"\"\" % (rctype,"
    ],
    [
        "\"\"\"msver is the ms runtime version used for the MANIFEST.\"\"\"",
        "\"\"\"msver is the ms runtime version used for"
    ],
    [
        "\"Discrepancy between linked msvcr \" \\",
        "\"Discrepancy between linked msvcr \""
    ],
    [
        "\"(%d) and the one about to be embedded \" \\",
        "\"(%d) and the one about"
    ],
    [
        "return root + exext + \".manifest\"",
        "return root +"
    ],
    [
        "Provides the Extension class, used to describe C/C++ extension",
        "Provides the Extension class, used to describe C/C++"
    ],
    [
        "from distutils.extension import Extension as old_Extension",
        "from distutils.extension import Extension as"
    ],
    [
        "List of source file locations relative to the top directory of",
        "List of source file locations relative to the top directory"
    ],
    [
        "Extra command line arguments to pass to the compiler.",
        "Extra command line arguments to pass to"
    ],
    [
        "msg = \"swig_opts is specified as a string instead of a list\"",
        "msg = \"swig_opts is specified as a string"
    ],
    [
        "return any(cxx_ext_re(str(source)) for source in self.sources)",
        "return any(cxx_ext_re(str(source)) for source"
    ],
    [
        "return any(fortran_pyf_ext_re(source) for source in self.sources)",
        "return any(fortran_pyf_ext_re(source) for source in"
    ],
    [
        "from distutils.msvccompiler import MSVCCompiler as _MSVCCompiler",
        "from distutils.msvccompiler import MSVCCompiler as"
    ],
    [
        "\"\"\"Concatenate two environment paths avoiding repeats.",
        "\"\"\"Concatenate two environment paths avoiding"
    ],
    [
        "Here `old` is the environment string before the base class initialize",
        "Here `old` is the environment string before the"
    ],
    [
        "function is called and `new` is the string after the call. The new string",
        "function is called and `new` is the string"
    ],
    [
        "will be a fixed string if it is not obtained from the current environment,",
        "will be a fixed string if it is not obtained from the current"
    ],
    [
        "or the same as the old string if obtained from the same environment. The aim",
        "or the same as the old string if obtained from the"
    ],
    [
        "here is not to append the new string if it is already contained in the old",
        "here is not to append the new string if it is already contained"
    ],
    [
        "string so as to limit the growth of the environment string.",
        "string so as to limit the"
    ],
    [
        "\"\"\" Add flags if we are using MSVC compiler",
        "\"\"\" Add flags if we are using MSVC"
    ],
    [
        "We can't see `build_cmd` in our scope, because we have not initialized",
        "We can't see `build_cmd` in our scope, because"
    ],
    [
        "the distutils build command, so use this deferred calculation to run",
        "the distutils build command, so use this deferred calculation"
    ],
    [
        "when we are building the library.",
        "when we are"
    ],
    [
        "\"\"\"A modified Intel compiler compatible with a GCC-built Python.\"\"\"",
        "\"\"\"A modified Intel compiler compatible with"
    ],
    [
        "linker_so=compiler + ' ' + shared_flag +",
        "linker_so=compiler + ' ' +"
    ],
    [
        "linker_so=compiler + ' ' + shared_flag +",
        "linker_so=compiler + ' ' +"
    ],
    [
        "A modified Intel compiler compatible with an MSVC-built Python.",
        "A modified Intel compiler compatible"
    ],
    [
        "Helper functions for interacting with the shell, and consuming shell-style",
        "Helper functions for interacting with the"
    ],
    [
        "An object that knows how to split and join command-line arguments.",
        "An object that knows how to split and join command-line"
    ],
    [
        "It must be true that ``argv == split(join(argv))`` for all ``argv``.",
        "It must be true that ``argv == split(join(argv))`` for"
    ],
    [
        "The reverse neednt be true - `join(split(cmd))` may result in the addition",
        "The reverse neednt be true - `join(split(cmd))` may result in"
    ],
    [
        "\"\"\" Join a list of arguments into a command line string \"\"\"",
        "\"\"\" Join a list of arguments into a command line"
    ],
    [
        "\"\"\" Split a command line string into a list of arguments \"\"\"",
        "\"\"\" Split a command line string into a list of arguments"
    ],
    [
        "The parsing behavior used by `subprocess.call(\"string\")` on Windows, which",
        "The parsing behavior used by `subprocess.call(\"string\")` on Windows,"
    ],
    [
        "Note that this is _not_ the behavior of cmd.",
        "Note that this is _not_"
    ],
    [
        "cmd = 'dummy ' + cmd",
        "cmd = 'dummy '"
    ],
    [
        "args = [lpargs[i] for i in range(nargs.value)]",
        "args = [lpargs[i] for i in"
    ],
    [
        "The parsing behavior used by `subprocess.call(\"string\", shell=True)` on Posix.",
        "The parsing behavior used by `subprocess.call(\"string\", shell=True)` on"
    ],
    [
        "return ' '.join(shlex.quote(arg) for arg in argv)",
        "return ' '.join(shlex.quote(arg) for arg"
    ],
    [
        "\"\"\"Provides the `CCompilerOpt` class, used for handling the CPU/hardware",
        "\"\"\"Provides the `CCompilerOpt` class, used for handling the"
    ],
    [
        "optimization, starting from parsing the command arguments, to managing the",
        "optimization, starting from parsing the command arguments,"
    ],
    [
        "relation between the CPU baseline and dispatch-able features,",
        "relation between the CPU"
    ],
    [
        "also generating the required C headers and ending with compiling",
        "also generating the required C headers and ending with"
    ],
    [
        "the sources with proper compiler's flags.",
        "the sources with proper"
    ],
    [
        "`CCompilerOpt` doesn't provide runtime detection for the CPU features,",
        "`CCompilerOpt` doesn't provide runtime detection"
    ],
    [
        "instead only focuses on the compiler side, but it creates abstract C headers",
        "instead only focuses on the compiler side, but it creates"
    ],
    [
        "that can be used later for the final runtime dispatching process.\"\"\"",
        "that can be used later for the final runtime dispatching"
    ],
    [
        "\"\"\"An abstract class holds all configurable attributes of `CCompilerOpt`,",
        "\"\"\"An abstract class holds all"
    ],
    [
        "these class attributes can be used to change the default behavior",
        "these class attributes can be used to"
    ],
    [
        "of `CCompilerOpt` in order to fit other requirements.",
        "of `CCompilerOpt` in order to"
    ],
    [
        "Set True to disable memory and file cache.",
        "Set True to disable memory and file"
    ],
    [
        "Set True to forces the optimization to be disabled,",
        "Set True to forces the optimization to be"
    ],
    [
        "in this case `CCompilerOpt` tends to generate all",
        "in this case `CCompilerOpt`"
    ],
    [
        "expected headers in order to 'not' break the build.",
        "expected headers in order to 'not'"
    ],
    [
        "Add extra factors to the primary caching factors. The caching factors",
        "Add extra factors to the primary caching factors."
    ],
    [
        "are utilized to determine if there are changes had happened that",
        "are utilized to determine if there are"
    ],
    [
        "requires to discard the cache and re-updating it. The primary factors",
        "requires to discard the cache and re-updating it. The"
    ],
    [
        "are the arguments of `CCompilerOpt` and `CCompiler`'s properties(type, flags, etc).",
        "are the arguments of `CCompilerOpt` and"
    ],
    [
        "Default is list of two items, containing the time of last modification",
        "Default is list of two items,"
    ],
    [
        "of `ccompiler_opt` and value of attribute \"conf_noopt\"",
        "of `ccompiler_opt` and value"
    ],
    [
        "The path of temporary directory. Default is auto-created",
        "The path of temporary directory."
    ],
    [
        "The path of testing files. Each added CPU feature must have a",
        "The path of testing files. Each added"
    ],
    [
        "**C** source file contains at least one intrinsic or instruction that",
        "**C** source file contains at least one intrinsic"
    ],
    [
        "related to this feature, so it can be tested against the compiler.",
        "related to this feature, so it can"
    ],
    [
        "Extra tokens that can be reached from dispatch-able sources through",
        "Extra tokens that can be reached from dispatch-able"
    ],
    [
        "the special mark ``@targets``. Default is an empty dictionary.",
        "the special mark ``@targets``. Default is an"
    ],
    [
        "- case-insensitive for tokens and group names",
        "- case-insensitive for tokens and group"
    ],
    [
        "The prefix of public C definitions. Default is ``\"NPY_\"``.",
        "The prefix of public C definitions."
    ],
    [
        "The prefix of internal C definitions. Default is ``\"NPY__\"``.",
        "The prefix of internal C definitions. Default is"
    ],
    [
        "Nested dictionaries defining several compiler flags",
        "Nested dictionaries defining several"
    ],
    [
        "that linked to some major functions, the main key",
        "that linked to some major functions, the main"
    ],
    [
        "represent the compiler name and sub-keys represent",
        "represent the compiler name"
    ],
    [
        "flags names. Default is already covers all supported",
        "flags names. Default is already covers all"
    ],
    [
        "used by argument option `native`, to detect the current",
        "used by argument option `native`, to detect"
    ],
    [
        "utilized to treat warning as errors during testing CPU features",
        "utilized to treat warning as errors during testing"
    ],
    [
        "against the compiler and also for target's policy `$werror`",
        "against the compiler and also for"
    ],
    [
        "utilized for target's policy '$maxopt' and the value should",
        "utilized for target's policy '$maxopt' and the value"
    ],
    [
        "contains the maximum acceptable optimization by the compiler.",
        "contains the maximum acceptable optimization"
    ],
    [
        "* case-sensitive for compiler names and flags",
        "* case-sensitive for compiler names"
    ],
    [
        "* use space to separate multiple flags",
        "* use space to separate"
    ],
    [
        "* any flag will tested against the compiler and it will skipped",
        "* any flag will tested against the"
    ],
    [
        "A dictionary defines the used CPU features for",
        "A dictionary defines the used CPU features"
    ],
    [
        "argument option ``'min'``, the key represent the CPU architecture",
        "argument option ``'min'``, the key"
    ],
    [
        "on wide range of users platforms.",
        "on wide range of users"
    ],
    [
        "Nested dictionaries used for identifying the CPU features.",
        "Nested dictionaries used for identifying the CPU"
    ],
    [
        "the primary key is represented as a feature name or group name",
        "the primary key is represented as"
    ],
    [
        "that gathers several features. Default values covers all",
        "that gathers several features. Default"
    ],
    [
        "supported features but without the major options like \"flags\",",
        "supported features but without the major options like"
    ],
    [
        "these undefined options handle it by method `conf_features_partial()`.",
        "these undefined options handle"
    ],
    [
        "\"implies\" : str or list, optional,",
        "\"implies\" : str"
    ],
    [
        "List of CPU feature names to be implied by it,",
        "List of CPU feature names"
    ],
    [
        "the feature name must be defined within `conf_features`.",
        "the feature name must"
    ],
    [
        "List of compiler flags. Default is None.",
        "List of compiler flags. Default"
    ],
    [
        "List of CPU feature names that required to be detected",
        "List of CPU feature names"
    ],
    [
        "in runtime. By default, its the feature name or features",
        "in runtime. By default, its the feature name"
    ],
    [
        "If True, all \"detect\" of implied features will be combined.",
        "If True, all \"detect\" of implied features will"
    ],
    [
        "Same as \"implies\" but doesn't require the feature name to be",
        "Same as \"implies\" but doesn't require the feature"
    ],
    [
        "a key for sorting CPU features",
        "a key for sorting CPU"
    ],
    [
        "force disable feature, the string value should contains the",
        "force disable feature, the string value should"
    ],
    [
        "True or False to declare that CPU feature can be auto-vectorized",
        "True or False to declare that CPU feature can"
    ],
    [
        "By default(None), treated as True if the feature contains at",
        "By default(None), treated as True"
    ],
    [
        "least one applicable flag. see `feature_can_autovec()`",
        "least one applicable flag."
    ],
    [
        "Extra test case names for the CPU feature that need to be tested",
        "Extra test case names for the CPU feature that need to be"
    ],
    [
        "Each test case must have a C file named ``extra_xxxx.c``, where",
        "Each test case must have a C"
    ],
    [
        "``xxxx`` is the case name in lower case, under 'conf_check_path'.",
        "``xxxx`` is the case name in"
    ],
    [
        "It should contain at least one intrinsic or function related to the test case.",
        "It should contain at least one intrinsic"
    ],
    [
        "If the compiler able to successfully compile the C file then `CCompilerOpt`",
        "If the compiler able to successfully compile the C"
    ],
    [
        "* space can be used as separator with options that supports \"str or list\"",
        "* space can be used as separator with options that supports \"str"
    ],
    [
        "* case-sensitive for all values and feature name must be in upper-case.",
        "* case-sensitive for all values and feature name must"
    ],
    [
        "* if flags aren't applicable, its will skipped rather than disable the",
        "* if flags aren't applicable, its"
    ],
    [
        "* the CPU feature will disabled if the compiler fail to compile",
        "* the CPU feature will disabled if the compiler fail to"
    ],
    [
        "\"\"\"Return a dictionary of supported CPU features by the platform,",
        "\"\"\"Return a dictionary of supported CPU features by"
    ],
    [
        "and accumulate the rest of undefined options in `conf_features`,",
        "and accumulate the rest of undefined"
    ],
    [
        "the returned dict has same rules and notes in",
        "the returned dict has same"
    ],
    [
        "class attribute `conf_features`, also its override",
        "class attribute `conf_features`, also its"
    ],
    [
        "any options that been set in 'conf_features'.",
        "any options that been"
    ],
    [
        "is_unix = self.cc_is_gcc or self.cc_is_clang or self.cc_is_fcc",
        "is_unix = self.cc_is_gcc or"
    ],
    [
        "XOP    = dict(disable=\"Intel Compiler doesn't support it\"),",
        "XOP = dict(disable=\"Intel Compiler"
    ],
    [
        "XOP    = dict(disable=\"Intel Compiler doesn't support it\"),",
        "XOP = dict(disable=\"Intel Compiler doesn't"
    ],
    [
        "if self.cc_on_armhf and is_unix: return dict(",
        "if self.cc_on_armhf and is_unix:"
    ],
    [
        "\"\"\"A helper class that provides a collection of fundamental methods",
        "\"\"\"A helper class that provides a collection of fundamental"
    ],
    [
        "implemented in a top of Python and NumPy Distutils.",
        "implemented in a top of Python and"
    ],
    [
        "The idea behind this class is to gather all methods that it may",
        "The idea behind this class is to gather all methods"
    ],
    [
        "need to override in case of reuse 'CCompilerOpt' in environment",
        "need to override in case of"
    ],
    [
        "different than of what NumPy has.",
        "different than of what NumPy"
    ],
    [
        "The generate instance that returned from `distutils.ccompiler.new_compiler()`.",
        "The generate instance that"
    ],
    [
        "def dist_compile(self, sources, flags, ccompiler=None, **kwargs):",
        "def dist_compile(self, sources, flags,"
    ],
    [
        "flags = kwargs.pop(\"extra_postargs\", []) + flags",
        "flags = kwargs.pop(\"extra_postargs\","
    ],
    [
        "\"\"\"Return True if 'CCompiler.compile()' able to compile",
        "\"\"\"Return True if 'CCompiler.compile()' able to"
    ],
    [
        "a source file with certain flags.",
        "a source file with"
    ],
    [
        "Return a tuple containing info about (platform, compiler, extra_args),",
        "Return a tuple containing info about (platform,"
    ],
    [
        "required by the abstract class '_CCompiler' for discovering the",
        "required by the abstract class '_CCompiler' for discovering"
    ],
    [
        "platform environment. This is also used as a cache factor in order",
        "platform environment. This is also used as a cache factor in"
    ],
    [
        "to detect any changes happening from outside.",
        "to detect any changes"
    ],
    [
        "elif cc_type in (\"intel\", \"intelw\", \"intele\"):",
        "elif cc_type in"
    ],
    [
        "cc_info = getattr(self._ccompiler, \"compiler\", getattr(self._ccompiler, \"compiler_so\", ''))",
        "cc_info = getattr(self._ccompiler, \"compiler\", getattr(self._ccompiler, \"compiler_so\","
    ],
    [
        "if not cc_type or cc_type == \"unix\":",
        "if not cc_type or cc_type"
    ],
    [
        "\"\"\"Load a module from file, required by the abstract class '_Cache'.\"\"\"",
        "\"\"\"Load a module from file, required by the"
    ],
    [
        "\"\"\"Return a string to print by log and errors.\"\"\"",
        "\"\"\"Return a string to print by log and"
    ],
    [
        "if not isinstance(arg, str) and hasattr(arg, '__iter__'):",
        "if not isinstance(arg, str)"
    ],
    [
        "return '('+ ' '.join(ret) + ')'",
        "return '('+ ' '.join(ret)"
    ],
    [
        "start = \"CCompilerOpt.%s[%d] : \" % (stack.function, stack.lineno)",
        "start = \"CCompilerOpt.%s[%d] : \""
    ],
    [
        "Fix msvc SDK ENV path same as distutils do",
        "Fix msvc SDK ENV path same as"
    ],
    [
        "\"Flags in command\", cmd ,\"aren't supported by the compiler\"",
        "\"Flags in command\", cmd ,\"aren't"
    ],
    [
        "\", output -> \\n%s\" % o",
        "\", output ->"
    ],
    [
        "\"Command\", cmd, \"failed with exit status %d output -> \\n%s\" % (",
        "\"Command\", cmd, \"failed with exit status %d output -> \\n%s\" %"
    ],
    [
        "\"\"\"An abstract class handles caching functionality, provides two",
        "\"\"\"An abstract class handles"
    ],
    [
        "levels of caching, in-memory by share instances attributes among",
        "levels of caching, in-memory by"
    ],
    [
        "each other and by store attributes into files.",
        "each other and by store attributes"
    ],
    [
        "any attributes that start with ``_`` or ``conf_`` will be ignored.",
        "any attributes that start with ``_`` or"
    ],
    [
        "The path of cache file, if None then cache in file will disabled.",
        "The path of cache file, if None then cache in file will"
    ],
    [
        "The caching factors that need to utilize next to `conf_cache_factors`.",
        "The caching factors that need to"
    ],
    [
        "Hold the attributes that need be skipped from \"in-memory cache\".",
        "Hold the attributes that need be skipped"
    ],
    [
        "Utilized during initializing this class, to determine if the cache was able",
        "Utilized during initializing this class, to determine if the"
    ],
    [
        "to loaded from the specified cache path in 'cache_path'.",
        "to loaded from the specified cache path"
    ],
    [
        "self.dist_log(\"load cache from file ->\", cache_path)",
        "self.dist_log(\"load cache from file"
    ],
    [
        "\"unable to load the cache file as a module\",",
        "\"unable to load the cache file as a"
    ],
    [
        "elif not hasattr(cache_mod, \"hash\") or \\",
        "elif not hasattr(cache_mod, \"hash\") or"
    ],
    [
        "if attr in other_cache.cache_private or \\",
        "if attr in other_cache.cache_private"
    ],
    [
        "self.dist_log(\"write cache to path ->\", self._cache_path)",
        "self.dist_log(\"write cache to path ->\","
    ],
    [
        "A static method that can be treated as a decorator to",
        "A static method that can be treated as a"
    ],
    [
        "\"\"\"A helper class for `CCompilerOpt` containing all utilities that",
        "\"\"\"A helper class for `CCompilerOpt` containing"
    ],
    [
        "related to the fundamental compiler's functions.",
        "related to the"
    ],
    [
        "True when the target architecture is IBM/ZARCH on linux",
        "True when the target architecture is IBM/ZARCH"
    ],
    [
        "True when the target architecture is unknown or not supported",
        "True when the target architecture is unknown"
    ],
    [
        "True if the compiler is GNU or",
        "True if the compiler is"
    ],
    [
        "True if the compiler is Clang",
        "True if the compiler"
    ],
    [
        "True if the compiler is Intel compiler (unix like)",
        "True if the compiler is"
    ],
    [
        "True if the compiler is Intel compiler (msvc like)",
        "True if the compiler is"
    ],
    [
        "True if the compiler isn't supported directly,",
        "True if the compiler"
    ],
    [
        "Note: that cause a fail-back to gcc",
        "Note: that cause a fail-back to"
    ],
    [
        "True if the compiler has debug flags",
        "True if the compiler"
    ],
    [
        "True if the compiler has native flags",
        "True if the compiler has"
    ],
    [
        "True if the compiler has definition 'DISABLE_OPT*',",
        "True if the compiler"
    ],
    [
        "The target architecture name, or \"unknown\" if",
        "The target architecture name,"
    ],
    [
        "The compiler name, or \"unknown\" if the compiler isn't supported",
        "The compiler name, or \"unknown\" if the compiler isn't"
    ],
    [
        "Dictionary containing the initialized flags of `_Config.conf_cc_flags`",
        "Dictionary containing the initialized flags"
    ],
    [
        "for section in (detect_arch, detect_compiler, detect_args):",
        "for section in"
    ],
    [
        "for attr, rgex, cexpr in section:",
        "for attr, rgex, cexpr in"
    ],
    [
        "for detect, searchin in ((detect_arch, platform), (detect_compiler, compiler_info)):",
        "for detect, searchin in"
    ],
    [
        "for attr, rgex, cexpr in detect:",
        "for attr, rgex, cexpr"
    ],
    [
        "if rgex and not re.match(rgex, searchin, re.IGNORECASE):",
        "if rgex and not re.match(rgex, searchin,"
    ],
    [
        "for attr, rgex, cexpr in detect_args:",
        "for attr, rgex,"
    ],
    [
        "if rgex and not re.match(rgex, extra_args, re.IGNORECASE):",
        "if rgex and not"
    ],
    [
        "\"unable to detect CPU architecture which lead to disable the optimization. \"",
        "\"unable to detect CPU architecture which"
    ],
    [
        "self.dist_log(\"Optimization is disabled by the Config\", stderr=True)",
        "self.dist_log(\"Optimization is disabled by the Config\","
    ],
    [
        "mingw can be treated as a gcc, and also xlc even if it based on clang,",
        "mingw can be treated as a gcc, and also"
    ],
    [
        "but still has the same gcc optimization flags.",
        "but still has the same gcc"
    ],
    [
        "\"unable to detect compiler type which leads to treating it as GCC. \"",
        "\"unable to detect compiler type which leads"
    ],
    [
        "\"this is a normal behavior if you're using gcc-like compiler such as MinGW or IBM/XLC.\"",
        "\"this is a normal behavior if you're using gcc-like compiler such as"
    ],
    [
        "for name in (\"gcc\", \"clang\", \"iccw\", \"icc\", \"msvc\", \"fcc\"):",
        "for name in (\"gcc\", \"clang\", \"iccw\", \"icc\","
    ],
    [
        "\"undefined flag for compiler '%s', \"",
        "\"undefined flag for"
    ],
    [
        "\"leave an empty dict instead\" % self.cc_name",
        "\"leave an empty dict instead\" %"
    ],
    [
        "Returns True if the compiler supports 'flags'.",
        "Returns True if the compiler"
    ],
    [
        "Same as the above but supports compile-time expressions.",
        "Same as the above but"
    ],
    [
        "Remove the conflicts that caused due gathering implied features flags.",
        "Remove the conflicts that caused due gathering implied"
    ],
    [
        "flags should be sorted from the lowest to the highest interest.",
        "flags should be sorted from the lowest"
    ],
    [
        "if self.cc_is_gcc or self.cc_is_clang or self.cc_is_icc:",
        "if self.cc_is_gcc or self.cc_is_clang"
    ],
    [
        "cur_flag = arch + '+' + '+'.join(subflags)",
        "cur_flag = arch + '+'"
    ],
    [
        "\"\"\"A helper class for `CCompilerOpt` that managing CPU features.",
        "\"\"\"A helper class for `CCompilerOpt`"
    ],
    [
        "Dictionary containing all CPU features that supported",
        "Dictionary containing all CPU features"
    ],
    [
        "by the platform, according to the specified values in attribute",
        "by the platform, according to the specified values"
    ],
    [
        "The minimum support of CPU features, according to",
        "The minimum support of CPU features,"
    ],
    [
        "the specified values in attribute `_Config.conf_min_features`.",
        "the specified values in"
    ],
    [
        "k:v for k,v in cfeature.items() if k not in feature",
        "k:v for k,v in cfeature.items() if k"
    ],
    [
        "\"feature '%s' is disabled,\" % feature_name,",
        "\"feature '%s' is disabled,\""
    ],
    [
        "\"implies\", \"group\", \"detect\", \"headers\", \"flags\", \"extra_checks\"",
        "\"implies\", \"group\", \"detect\", \"headers\", \"flags\","
    ],
    [
        "Returns a set of CPU feature names that supported by platform and the **C** compiler.",
        "Returns a set of CPU feature names that supported by platform and the"
    ],
    [
        "names : sequence or None, optional",
        "names : sequence or None,"
    ],
    [
        "Specify certain CPU features to test it against the **C** compiler.",
        "Specify certain CPU features to test it against the **C**"
    ],
    [
        "if None(default), it will test all current supported features.",
        "if None(default), it will test all"
    ],
    [
        "**Note**: feature names must be in upper-case.",
        "**Note**: feature names must be"
    ],
    [
        "force_flags : list or None, optional",
        "force_flags : list"
    ],
    [
        "If None(default), default compiler flags for every CPU feature will",
        "If None(default), default compiler flags for"
    ],
    [
        "macros : list of tuples, optional",
        "macros : list"
    ],
    [
        "A list of C macro definitions.",
        "A list of C"
    ],
    [
        "assert(force_flags is None or isinstance(force_flags, list))",
        "assert(force_flags is None or"
    ],
    [
        "Returns True if a certain feature is exist and covered within",
        "Returns True if a certain feature is exist"
    ],
    [
        "Sort a list of CPU features ordered by the lowest interest.",
        "Sort a list of CPU features"
    ],
    [
        "sequence of supported feature names in uppercase.",
        "sequence of supported feature names"
    ],
    [
        "If true, the sorted features is reversed. (highest interest)",
        "If true, the sorted features is reversed."
    ],
    [
        "rank = max([self.feature_supported[f][\"interest\"] for f in k])",
        "rank = max([self.feature_supported[f][\"interest\"] for f"
    ],
    [
        "Return a set of CPU features that implied by 'names'",
        "Return a set of CPU features that implied"
    ],
    [
        "names : str or sequence of str",
        "names : str or sequence"
    ],
    [
        "if False(default) then the returned set will not contain any",
        "if False(default) then the returned set will not"
    ],
    [
        "features from 'names'. This case happens only when two features",
        "features from 'names'. This case happens only when"
    ],
    [
        "\"\"\"same as feature_implies() but combining 'names'\"\"\"",
        "\"\"\"same as feature_implies() but combining"
    ],
    [
        "Return list of features in 'names' after remove any",
        "Return list of features in 'names'"
    ],
    [
        "implied features and keep the origins.",
        "implied features and keep"
    ],
    [
        "sequence of CPU feature names in uppercase.",
        "sequence of CPU feature names"
    ],
    [
        "list of CPU features sorted as-is 'names'",
        "list of CPU features"
    ],
    [
        "ahead = [n for n in names if n not in implies]",
        "ahead = [n for n in"
    ],
    [
        "same as 'feature_ahead()' but if both features implied each other",
        "same as 'feature_ahead()' but if both features"
    ],
    [
        "sequence of CPU feature names in uppercase.",
        "sequence of CPU feature names"
    ],
    [
        "list of CPU features sorted as-is 'names'",
        "list of CPU features"
    ],
    [
        "if nn in implies and n in self.feature_implies(nn)",
        "if nn in implies"
    ],
    [
        "same as `feature_implies_c()` but stop collecting implied",
        "same as `feature_implies_c()` but stop"
    ],
    [
        "features when feature's option that provided through",
        "features when feature's option that"
    ],
    [
        "parameter 'keyisfalse' is False, also sorting the returned",
        "parameter 'keyisfalse' is False, also sorting"
    ],
    [
        "names = {t for n in names for t in til(n)}",
        "names = {t for n in names"
    ],
    [
        "Return a list of CPU features that required to be detected",
        "Return a list of CPU features that required to be"
    ],
    [
        "sorted from the lowest to highest interest.",
        "sorted from the lowest to"
    ],
    [
        "Return a list of CPU features flags sorted from the lowest",
        "Return a list of CPU features flags sorted"
    ],
    [
        "if not f or not self.cc_test_flags(f):",
        "if not f"
    ],
    [
        "Test a certain CPU feature against the compiler through its own",
        "Test a certain CPU feature against the compiler"
    ],
    [
        "force_flags : list or None, optional",
        "force_flags : list"
    ],
    [
        "If None(default), the returned flags from `feature_flags()`",
        "If None(default), the returned flags"
    ],
    [
        "macros : list of tuples, optional",
        "macros : list"
    ],
    [
        "A list of C macro definitions.",
        "A list of C macro"
    ],
    [
        "\"testing feature '%s' with flags (%s)\" % (",
        "\"testing feature '%s' with flags (%s)\" %"
    ],
    [
        "self.dist_fatal(\"feature test file is not exist\", test_path)",
        "self.dist_fatal(\"feature test file is not exist\","
    ],
    [
        "Check if a certain CPU feature is supported by the platform and compiler.",
        "Check if a certain CPU feature is supported"
    ],
    [
        "force_flags : list or None, optional",
        "force_flags : list"
    ],
    [
        "If None(default), default compiler flags for every CPU feature will",
        "If None(default), default compiler flags for every"
    ],
    [
        "macros : list of tuples, optional",
        "macros : list of tuples,"
    ],
    [
        "A list of C macro definitions.",
        "A list of"
    ],
    [
        "assert(force_flags is None or isinstance(force_flags, list))",
        "assert(force_flags is None or"
    ],
    [
        "check if the feature can be auto-vectorized by the compiler",
        "check if the feature can be"
    ],
    [
        "self.cc_test_flags([f]) for f in d.get(\"flags\", [])",
        "self.cc_test_flags([f]) for f"
    ],
    [
        "Return a list of supported extra checks after testing them against",
        "Return a list of supported extra checks after"
    ],
    [
        "self.dist_log(\"Testing extra checks for feature '%s'\" % name, extra_checks)",
        "self.dist_log(\"Testing extra checks for feature '%s'\""
    ],
    [
        "self.dist_fatal(\"extra check file does not exist\", test_path)",
        "self.dist_fatal(\"extra check file does not"
    ],
    [
        "is_supported = self.dist_test(test_path, flags + self.cc_flags[\"werror\"])",
        "is_supported = self.dist_test(test_path, flags +"
    ],
    [
        "self.dist_log(\"testing failed for checks\", not_available, stderr=True)",
        "self.dist_log(\"testing failed for checks\", not_available,"
    ],
    [
        "Generate C preprocessor definitions and include headers of a CPU feature.",
        "Generate C preprocessor definitions and include headers of a"
    ],
    [
        "prepr = [('\\t'*tabs) + l for l in prepr]",
        "prepr = [('\\t'*tabs) + l for l in"
    ],
    [
        "\"\"\"A helper class that parsing main arguments of `CCompilerOpt`,",
        "\"\"\"A helper class that parsing main"
    ],
    [
        "also parsing configuration statements in dispatch-able sources.",
        "also parsing configuration statements"
    ],
    [
        "minimal set of required CPU features or special options.",
        "minimal set of required CPU"
    ],
    [
        "dispatched set of additional CPU features or special options.",
        "dispatched set of additional CPU features"
    ],
    [
        "- **MIN**: Enables the minimum CPU features that utilized via `_Config.conf_min_features`",
        "- **MIN**: Enables the minimum CPU"
    ],
    [
        "- **MAX**: Enables all supported CPU features by the Compiler and platform.",
        "- **MAX**: Enables all supported CPU features by the Compiler and"
    ],
    [
        "- **NATIVE**: Enables all CPU features that supported by the current machine.",
        "- **NATIVE**: Enables all CPU features"
    ],
    [
        "- **Operand +/-**: remove or add features, useful with options **MAX**, **MIN** and **NATIVE**.",
        "- **Operand +/-**: remove or add features, useful with options **MAX**, **MIN**"
    ],
    [
        "NOTE: operand + is only added for nominal reason.",
        "NOTE: operand + is only added for nominal"
    ],
    [
        "- Case-insensitive among all CPU features and special options.",
        "- Case-insensitive among all CPU features and"
    ],
    [
        "- Comma or space can be used as a separator.",
        "- Comma or space can be used as a"
    ],
    [
        "- If the CPU feature is not supported by the user platform or compiler,",
        "- If the CPU feature is not supported by the user"
    ],
    [
        "it will be skipped rather than raising a fatal error.",
        "it will be skipped rather than raising"
    ],
    [
        "- Any specified CPU features to 'cpu_dispatch' will be skipped if its part of CPU baseline features",
        "- Any specified CPU features to 'cpu_dispatch' will be skipped if its"
    ],
    [
        "- 'cpu_baseline' force enables implied features.",
        "- 'cpu_baseline' force enables"
    ],
    [
        "Final CPU baseline's feature names(sorted from low to high)",
        "Final CPU baseline's feature names(sorted from"
    ],
    [
        "Final CPU dispatch-able feature names(sorted from low to high)",
        "Final CPU dispatch-able feature names(sorted from low"
    ],
    [
        "Dictionary containing initialized target groups that configured",
        "Dictionary containing initialized target groups"
    ],
    [
        "The key is represent the group name and value is a tuple",
        "The key is represent the group name and"
    ],
    [
        "- bool, True if group has the 'baseline' option.",
        "- bool, True if group"
    ],
    [
        "- list, list of CPU features.",
        "- list, list of"
    ],
    [
        "- list, list of extra compiler flags.",
        "- list, list of extra compiler"
    ],
    [
        "\"skip features\", conflict_baseline, \"since its part of baseline\"",
        "\"skip features\", conflict_baseline, \"since its"
    ],
    [
        "if not tokens or not tokens.strip():",
        "if not tokens or"
    ],
    [
        "Fetch and parse configuration statements that required for",
        "Fetch and parse configuration statements that required"
    ],
    [
        "defining the targeted CPU features, statements should be declared",
        "defining the targeted CPU features, statements should"
    ],
    [
        "in the top of source in between **C** comment and start",
        "in the top of source in"
    ],
    [
        "Configuration statements are sort of keywords representing",
        "Configuration statements are sort of keywords"
    ],
    [
        "CPU features names, group of statements and policies, combined",
        "CPU features names, group of statements"
    ],
    [
        "together to determine the required optimization.",
        "together to determine"
    ],
    [
        "the path of **C** source file.",
        "the path of"
    ],
    [
        "- bool, True if group has the 'baseline' option",
        "- bool, True if group has the"
    ],
    [
        "- list, list of CPU features",
        "- list, list of CPU"
    ],
    [
        "- list, list of extra compiler flags",
        "- list, list of extra compiler"
    ],
    [
        "self.dist_log(\"looking for '@targets' inside -> \", source)",
        "self.dist_log(\"looking for '@targets' inside -> \","
    ],
    [
        "self.dist_fatal(\"expected to find '%s' within a C comment\" % start_with)",
        "self.dist_fatal(\"expected to find '%s' within a C comment\""
    ],
    [
        "self.dist_fatal(\"expected to end with '%s'\" % end_with)",
        "self.dist_fatal(\"expected to end with '%s'\""
    ],
    [
        "self.dist_fatal(\"expected a string in '%s'\" % arg_name)",
        "self.dist_fatal(\"expected a string in"
    ],
    [
        "arg_name, \"target groups and policies \"",
        "arg_name, \"target groups and policies"
    ],
    [
        "\"native option isn't supported by the compiler\"",
        "\"native option isn't supported by"
    ],
    [
        "\", '%s' isn't a known feature or option\" % tok",
        "\", '%s' isn't a known feature or option\""
    ],
    [
        "\"+/- are 'not' allowed from target's groups or @targets, \"",
        "\"+/- are 'not' allowed from target's"
    ],
    [
        "\"only from cpu_baseline and cpu_dispatch parms\"",
        "\"only from cpu_baseline"
    ],
    [
        "\"policies aren't allowed inside multi-target '()'\"",
        "\"policies aren't allowed inside multi-target"
    ],
    [
        "\"target groups aren't allowed inside multi-target '()'\"",
        "\"target groups aren't allowed"
    ],
    [
        "if targets and targets not in final_targets:",
        "if targets and targets"
    ],
    [
        "self.dist_fatal(\"baseline isn't allowed inside multi-target '()'\")",
        "self.dist_fatal(\"baseline isn't allowed inside"
    ],
    [
        "self.dist_fatal(\"invalid target name '%s'\" % TOK)",
        "self.dist_fatal(\"invalid target name '%s'\" %"
    ],
    [
        "\"not part of baseline or dispatch-able features\"",
        "\"not part of baseline or dispatch-able"
    ],
    [
        "\"policy '%s' force enables '%s'\" % (",
        "\"policy '%s' force enables"
    ],
    [
        "for p, (have, nhave, _) in self._parse_policies.items():",
        "for p, (have, nhave, _)"
    ],
    [
        "self.dist_log(\"policy '%s' is ON\" % p)",
        "self.dist_log(\"policy '%s' is ON\""
    ],
    [
        "self.dist_fatal(\"'$' must stuck in the begin of policy name\")",
        "self.dist_fatal(\"'$' must stuck in the begin of policy"
    ],
    [
        "\"'%s' is an invalid policy name, available policies are\" % token,",
        "\"'%s' is an invalid policy name,"
    ],
    [
        "def _parse_token_group(self, token, has_baseline, final_targets, extra_flags):",
        "def _parse_token_group(self, token, has_baseline,"
    ],
    [
        "\"'%s' is an invalid target group name, \" % token + \\",
        "\"'%s' is an invalid target group name, \" % token"
    ],
    [
        "final_targets += [f for f in gtargets if f not in final_targets]",
        "final_targets += [f for f in"
    ],
    [
        "extra_flags += [f for f in gextra_flags if f not in extra_flags]",
        "extra_flags += [f for f in gextra_flags if"
    ],
    [
        "\"\"\"validate multi targets that defined between parentheses()\"\"\"",
        "\"\"\"validate multi targets that defined"
    ],
    [
        "self.dist_fatal(\"invalid target name in multi-target\", targets)",
        "self.dist_fatal(\"invalid target name in"
    ],
    [
        "\"\"\"leave a notice that $keep_sort is on\"\"\"",
        "\"\"\"leave a notice that"
    ],
    [
        "\"policy 'keep_sort' is on, dispatch-able targets\", final_targets, \"\\n\"",
        "\"policy 'keep_sort' is on, dispatch-able"
    ],
    [
        "\"are 'not' sorted depend on the highest interest but\"",
        "\"are 'not' sorted depend on the"
    ],
    [
        "\"as specified in the dispatch-able source or the extra group\"",
        "\"as specified in the dispatch-able source or the"
    ],
    [
        "\"\"\"sorted depend on the highest interest\"\"\"",
        "\"\"\"sorted depend on the"
    ],
    [
        "self.dist_log(\"debug mode is detected, policy 'maxopt' is skipped.\")",
        "self.dist_log(\"debug mode is detected, policy 'maxopt' is"
    ],
    [
        "self.dist_log(\"optimization is disabled, policy 'maxopt' is skipped.\")",
        "self.dist_log(\"optimization is disabled, policy"
    ],
    [
        "\"current compiler doesn't support optimization flags, \"",
        "\"current compiler doesn't support"
    ],
    [
        "\"\"\"force warnings to treated as errors\"\"\"",
        "\"\"\"force warnings to"
    ],
    [
        "\"current compiler doesn't support werror flags, \"",
        "\"current compiler doesn't support werror"
    ],
    [
        "\"warnings will 'not' treated as errors\", stderr=True",
        "\"warnings will 'not' treated as errors\","
    ],
    [
        "self.dist_log(\"compiler warnings are treated as errors\")",
        "self.dist_log(\"compiler warnings are treated as"
    ],
    [
        "\"\"\"skip features that has no auto-vectorized support by compiler\"\"\"",
        "\"\"\"skip features that has no auto-vectorized support"
    ],
    [
        "class CCompilerOpt(_Config, _Distutils, _Cache, _CCompiler, _Feature, _Parse):",
        "class CCompilerOpt(_Config, _Distutils, _Cache, _CCompiler, _Feature,"
    ],
    [
        "A helper class for `CCompiler` aims to provide extra build options",
        "A helper class for `CCompiler` aims to"
    ],
    [
        "to effectively control of compiler optimizations that are directly",
        "to effectively control of compiler optimizations that"
    ],
    [
        "def __init__(self, ccompiler, cpu_baseline=\"min\", cpu_dispatch=\"max\", cache_path=None):",
        "def __init__(self, ccompiler, cpu_baseline=\"min\","
    ],
    [
        "\"native flag is specified through environment variables. \"",
        "\"native flag is specified"
    ],
    [
        "Returns True if the class loaded from the cache file",
        "Returns True if the class loaded from"
    ],
    [
        "Returns a list of final CPU baseline compiler flags",
        "Returns a list of final CPU baseline compiler"
    ],
    [
        "return a list of final CPU baseline feature names",
        "return a list of final"
    ],
    [
        "return a list of final CPU dispatch feature names",
        "return a list of final CPU dispatch"
    ],
    [
        "def try_dispatch(self, sources, src_dir=None, ccompiler=None, **kwargs):",
        "def try_dispatch(self, sources, src_dir=None, ccompiler=None,"
    ],
    [
        "Compile one or more dispatch-able sources and generates object files,",
        "Compile one or more dispatch-able sources"
    ],
    [
        "also generates abstract C config headers and macros that",
        "also generates abstract C config headers and"
    ],
    [
        "used later for the final runtime dispatching process.",
        "used later for the final runtime"
    ],
    [
        "The mechanism behind it is to takes each source file that specified",
        "The mechanism behind it is to takes each source"
    ],
    [
        "in 'sources' and branching it into several files depend on",
        "in 'sources' and branching it"
    ],
    [
        "special configuration statements that must be declared in the",
        "special configuration statements that must be declared"
    ],
    [
        "top of each source which contains targeted CPU features,",
        "top of each source which contains targeted"
    ],
    [
        "then it compiles every branched source with the proper compiler flags.",
        "then it compiles every branched source with"
    ],
    [
        "Must be a list of dispatch-able sources file paths,",
        "Must be a list of dispatch-able"
    ],
    [
        "and configuration statements must be declared inside",
        "and configuration statements must be declared"
    ],
    [
        "Path of parent directory for the generated headers and wrapped sources.",
        "Path of parent directory for the"
    ],
    [
        "If None(default) the files will generated in-place.",
        "If None(default) the files will generated"
    ],
    [
        "Distutils `CCompiler` instance to be used for compilation.",
        "Distutils `CCompiler` instance to be used for"
    ],
    [
        "If None (default), the provided instance during the initialization",
        "If None (default), the provided instance"
    ],
    [
        "Arguments to pass on to the `CCompiler.compile()`",
        "Arguments to pass on to"
    ],
    [
        "Raises by `CCompiler.compile()` on compiling failure.",
        "Raises by `CCompiler.compile()`"
    ],
    [
        "Some errors during checking the sanity of configuration statements.",
        "Some errors during checking the"
    ],
    [
        "Parsing the configuration statements of dispatch-able sources.",
        "Parsing the configuration statements"
    ],
    [
        "nochange = self._generate_config(output_dir, src, targets, has_baseline)",
        "nochange = self._generate_config(output_dir, src, targets,"
    ],
    [
        "tar_src = self._wrap_target(output_dir, src, tar, nochange=nochange)",
        "tar_src = self._wrap_target(output_dir,"
    ],
    [
        "for platform-specific instruction-sets for the enabled CPU baseline and",
        "for platform-specific instruction-sets for the enabled CPU"
    ],
    [
        "Its highly recommended to take a look at the generated header",
        "Its highly recommended to take a look at"
    ],
    [
        "also the generated source files via `try_dispatch()`",
        "also the generated source"
    ],
    [
        "in order to get the full picture.",
        "in order to get the full"
    ],
    [
        "self.dist_log(\"generate CPU dispatch header: (%s)\" % header_path)",
        "self.dist_log(\"generate CPU dispatch header: (%s)\" %"
    ],
    [
        "f\"dispatch header dir {header_dir} does not exist, creating it\",",
        "f\"dispatch header dir {header_dir} does not exist,"
    ],
    [
        "* Please make changes to the code generator (distutils/ccompiler_opt.py)",
        "* Please make changes to the"
    ],
    [
        "\"Enabled\", (' '.join(baseline_names) if baseline_names else \"none\")",
        "\"Enabled\", (' '.join(baseline_names) if baseline_names"
    ],
    [
        "\"Flags\", (' '.join(baseline_flags) if baseline_flags else \"none\")",
        "\"Flags\", (' '.join(baseline_flags) if"
    ],
    [
        "\"Extra checks\", (' '.join(extra_checks) if extra_checks else \"none\")",
        "\"Extra checks\", (' '.join(extra_checks) if extra_checks else"
    ],
    [
        "\"Enabled\", (' '.join(dispatch_names) if dispatch_names else \"none\")",
        "\"Enabled\", (' '.join(dispatch_names) if dispatch_names else"
    ],
    [
        "for source, (_, targets) in self.sources_status.items():",
        "for source, (_, targets) in"
    ],
    [
        "if not full or not target_sources:",
        "if not full or not"
    ],
    [
        "name = tar if isinstance(tar, str) else '(%s)' % ' '.join(tar)",
        "name = tar if isinstance(tar, str) else '(%s)' %"
    ],
    [
        "generated += name + \"[%d] \" % len(sources)",
        "generated += name + \"[%d]"
    ],
    [
        "pretty_name = tar if isinstance(tar, str) else '(%s)' % ' '.join(tar)",
        "pretty_name = tar if isinstance(tar, str) else '(%s)'"
    ],
    [
        "for name in ((tar,) if isinstance(tar, str) else tar):",
        "for name in ((tar,) if isinstance(tar,"
    ],
    [
        "extra_checks = (' '.join(extra_checks) if extra_checks else \"none\")",
        "extra_checks = (' '.join(extra_checks) if"
    ],
    [
        "secs_len = [len(secs) for secs, _ in report]",
        "secs_len = [len(secs) for"
    ],
    [
        "cols_len = [len(col) for _, rows in report for col, _ in rows]",
        "cols_len = [len(col) for _, rows in report for col,"
    ],
    [
        "sec += ' ' * (pad - len(sec))",
        "sec += ' '"
    ],
    [
        "text.append(sec + tab + ': ')",
        "text.append(sec + tab +"
    ],
    [
        "col += ' ' * (pad - len(col))",
        "col += ' '"
    ],
    [
        "text.append(tab + col + ': ' + val)",
        "text.append(tab + col + ': '"
    ],
    [
        "def _wrap_target(self, output_dir, dispatch_src, target, nochange=False):",
        "def _wrap_target(self, output_dir, dispatch_src,"
    ],
    [
        "self.dist_log(\"wrap dispatch-able target -> \", wrap_path)",
        "self.dist_log(\"wrap dispatch-able target"
    ],
    [
        "target_defs = [target_join + f for f in features]",
        "target_defs = [target_join + f"
    ],
    [
        "* Please make changes to the code generator \\",
        "* Please make changes to"
    ],
    [
        "def _generate_config(self, output_dir, dispatch_src, targets, has_baseline=False):",
        "def _generate_config(self, output_dir,"
    ],
    [
        "self.dist_log(\"generate dispatched config -> \", config_path)",
        "self.dist_log(\"generate dispatched config ->"
    ],
    [
        "target_name = '__'.join([t for t in tar])",
        "target_name = '__'.join([t for t"
    ],
    [
        "\"CHK(%s)\" % f for f in req_detect",
        "\"CHK(%s)\" % f for"
    ],
    [
        "* Please make changes to the code generator (distutils/ccompiler_opt.py)",
        "* Please make changes to the"
    ],
    [
        "Create a new instance of 'CCompilerOpt' and generate the dispatch header",
        "Create a new instance of 'CCompilerOpt' and"
    ],
    [
        "the enabled CPU baseline and dispatch-able features.",
        "the enabled CPU baseline and"
    ],
    [
        "if not os.path.exists(dispatch_hpath) or not opt.is_cached():",
        "if not os.path.exists(dispatch_hpath)"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import"
    ],
    [
        "from numpy.distutils.system_info import system_info, ConfigParser, mkl_info",
        "from numpy.distutils.system_info import system_info,"
    ],
    [
        "extra_compile_args = -I/fake/directory -I\"/path with/spaces\" -Os",
        "extra_compile_args = -I/fake/directory"
    ],
    [
        "/* This file is generated from numpy/distutils/testing/test_system_info.py */",
        "/* This file is generated from numpy/distutils/testing/test_system_info.py"
    ],
    [
        "\"\"\" Return True if there appears to be an executable compiler",
        "\"\"\" Return True if there appears to be"
    ],
    [
        "def _check_libs(self, lib_dirs, libs, opt_libs, exts):",
        "def _check_libs(self, lib_dirs,"
    ],
    [
        "\"\"\"Override _check_libs to return with all dirs \"\"\"",
        "\"\"\"Override _check_libs to return with all"
    ],
    [
        "info = {'libraries': libs, 'library_dirs': lib_dirs}",
        "info = {'libraries':"
    ],
    [
        "HAS_MKL = \"mkl_rt\" in mkl_info().calc_libraries_info().get(\"libraries\", [])",
        "HAS_MKL = \"mkl_rt\""
    ],
    [
        "@pytest.mark.xfail(HAS_MKL, reason=(\"`[DEFAULT]` override doesn't work if \"",
        "@pytest.mark.xfail(HAS_MKL, reason=(\"`[DEFAULT]` override doesn't"
    ],
    [
        "\"numpy is built with MKL support\"))",
        "\"numpy is built"
    ],
    [
        "is_standalone = __name__ == '__main__' and __package__ is None",
        "is_standalone = __name__ == '__main__' and"
    ],
    [
        "\"\"\"A hook to check the sanity of configured features",
        "\"\"\"A hook to check the"
    ],
    [
        "-   before it called by the abstract class '_Feature'",
        "- before it called by the abstract class"
    ],
    [
        "def test_feature(self, log, search_in, feature_name, feature_dict):",
        "def test_feature(self, log,"
    ],
    [
        "\"during validate '{}' within feature '{}', \"",
        "\"during validate '{}' within"
    ],
    [
        "\"march '{}' and compiler '{}'\\n>> \"",
        "\"march '{}' and"
    ],
    [
        "raise AssertionError(error_msg + \"feature name must be in uppercase\")",
        "raise AssertionError(error_msg + \"feature name must be in"
    ],
    [
        "\"implies\", \"headers\", \"flags\", \"group\", \"detect\", \"extra_checks\"",
        "\"implies\", \"headers\", \"flags\", \"group\","
    ],
    [
        "error_tp = [t.__name__ for t in (*tp,)]",
        "error_tp = [t.__name__ for"
    ],
    [
        "\"expected '%s' type for option '%s' not '%s'\" % (",
        "\"expected '%s' type for option '%s' not"
    ],
    [
        "raise AssertionError(error_msg + \"invalid option name '%s'\" % option)",
        "raise AssertionError(error_msg + \"invalid option name '%s'\""
    ],
    [
        "\"implies\", \"headers\", \"flags\", \"group\", \"detect\", \"extra_checks\"",
        "\"implies\", \"headers\", \"flags\", \"group\","
    ],
    [
        "raise AssertionError(error_msg + \"duplicated values in option '%s'\" % option)",
        "raise AssertionError(error_msg + \"duplicated values in option '%s'\" %"
    ],
    [
        "def test_implies(self, error_msg, search_in, feature_name, feature_dict):",
        "def test_implies(self, error_msg, search_in, feature_name,"
    ],
    [
        "raise AssertionError(error_msg + \"feature implies itself\")",
        "raise AssertionError(error_msg + \"feature implies"
    ],
    [
        "raise AssertionError(error_msg + \"implies disabled feature '%s'\" % impl)",
        "raise AssertionError(error_msg + \"implies disabled feature '%s'\" %"
    ],
    [
        "raise AssertionError(error_msg + \"implies non-exist feature '%s'\" % impl)",
        "raise AssertionError(error_msg + \"implies non-exist feature"
    ],
    [
        "def test_group(self, error_msg, search_in, feature_name, feature_dict):",
        "def test_group(self, error_msg,"
    ],
    [
        "if not impl_dict or \"disable\" in impl_dict:",
        "if not impl_dict or"
    ],
    [
        "\"in option 'group', '%s' already exists as a feature name\" % f",
        "\"in option 'group', '%s' already exists as"
    ],
    [
        "def test_extra_checks(self, error_msg, search_in, feature_name, feature_dict):",
        "def test_extra_checks(self, error_msg, search_in,"
    ],
    [
        "if not impl_dict or \"disable\" in impl_dict:",
        "if not impl_dict or \"disable\""
    ],
    [
        "\"in option 'extra_checks', extra test case '%s' already exists as a feature name\" % f",
        "\"in option 'extra_checks', extra test case '%s' already"
    ],
    [
        "pytest.skip(\"'nm.exe' not on path, is mingw installed?\")",
        "pytest.skip(\"'nm.exe' not on path, is mingw"
    ],
    [
        "Remove leading and trailing whitespace, and convert internal",
        "Remove leading and trailing whitespace, and"
    ],
    [
        "stretches of whitespace to a single space.",
        "stretches of whitespace to a single"
    ],
    [
        "line = next(line for line in clean_out.splitlines())",
        "line = next(line for"
    ],
    [
        "from os.path import join, sep, dirname",
        "from os.path import join, sep,"
    ],
    [
        "n = lambda path: path.replace('/', sep)",
        "n = lambda path: path.replace('/',"
    ],
    [
        "assert_(join(local_path, 'command', 'build_src.py') in ls, repr(ls))",
        "assert_(join(local_path, 'command', 'build_src.py') in ls,"
    ],
    [
        "reason=\"`get_info` .ini lookup method incompatible with editable install\"",
        "reason=\"`get_info` .ini lookup method"
    ],
    [
        "flag_vars = fc.flag_vars.clone(lambda *args, **kwargs: None)",
        "flag_vars = fc.flag_vars.clone(lambda"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"cannot start subprocess in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"cannot start subprocess in"
    ],
    [
        "Ensures multiple \"fake\" static libraries are correctly linked.",
        "Ensures multiple \"fake\" static libraries are"
    ],
    [
        "with open(tmp_path / '_dummy.c', 'w') as fid:",
        "with open(tmp_path / '_dummy.c',"
    ],
    [
        "with open(tmp_path / 'setup.py', 'w') as fid:",
        "with open(tmp_path / 'setup.py',"
    ],
    [
        "srctree = os.path.join(os.path.dirname(__file__), '..', '..', '..')",
        "srctree = os.path.join(os.path.dirname(__file__), '..', '..',"
    ],
    [
        "pytest.skip('Unable to run with non-native parser')",
        "pytest.skip('Unable to run with"
    ],
    [
        "Test that join produces strings understood by subprocess",
        "Test that join produces strings"
    ],
    [
        "Test that split is the inverse operation of join",
        "Test that split is the"
    ],
    [
        "from numpy.testing import tempdir, assert_, assert_warns, IS_WASM",
        "from numpy.testing import tempdir, assert_,"
    ],
    [
        "\"\"\"Context manager to redirect stdout for exec_command test.\"\"\"",
        "\"\"\"Context manager to redirect"
    ],
    [
        "\"\"\"Context manager to redirect stderr for exec_command test.\"\"\"",
        "\"\"\"Context manager to redirect stderr"
    ],
    [
        "\"\"\"Context manager to emulate os.name != 'posix' \"\"\"",
        "\"\"\"Context manager to emulate os.name"
    ],
    [
        "s, o = exec_command.exec_command('cmd /C echo path=%path%')",
        "s, o = exec_command.exec_command('cmd"
    ],
    [
        "'\"%s\" -c \"import sys;sys.stderr.write(sys.platform)\"' % self.pyexe)",
        "'\"%s\" -c \"import sys;sys.stderr.write(sys.platform)\"' %"
    ],
    [
        "s, o = exec_command.exec_command(\"echo Hello\", **kws)",
        "s, o = exec_command.exec_command(\"echo Hello\","
    ],
    [
        "s, o = exec_command.exec_command('echo $AAA', **kws)",
        "s, o = exec_command.exec_command('echo"
    ],
    [
        "s, o = exec_command.exec_command('echo \"$AAA\"', AAA='Tere', **kws)",
        "s, o = exec_command.exec_command('echo \"$AAA\"',"
    ],
    [
        "s, o = exec_command.exec_command('echo \"$AAA\"', **kws)",
        "s, o = exec_command.exec_command('echo"
    ],
    [
        "s, o = exec_command.exec_command('echo \"$BBB\"', **kws)",
        "s, o = exec_command.exec_command('echo \"$BBB\"',"
    ],
    [
        "s, o = exec_command.exec_command('echo \"$BBB\"', BBB='Hey', **kws)",
        "s, o = exec_command.exec_command('echo \"$BBB\"',"
    ],
    [
        "s, o = exec_command.exec_command('echo \"$BBB\"', **kws)",
        "s, o = exec_command.exec_command('echo \"$BBB\"',"
    ],
    [
        "s, o = exec_command.exec_command('echo \"$BBB\"', **kws)",
        "s, o ="
    ],
    [
        "s, o = exec_command.exec_command('echo path=$PATH', **kws)",
        "s, o = exec_command.exec_command('echo"
    ],
    [
        "'\"%s\" -c \"raise \\'Ignore me.\\'\"' % self.pyexe, **kws)",
        "'\"%s\" -c \"raise \\'Ignore me.\\'\"'"
    ],
    [
        "'\"%s\" -c \"print(\\'Heipa\\'\")' % self.pyexe, **kws)",
        "'\"%s\" -c \"print(\\'Heipa\\'\")'"
    ],
    [
        "'\"%s\" -c \"f = open(\\'%s\\', \\'r\\'); f.close()\"' %",
        "'\"%s\" -c \"f ="
    ],
    [
        "'\"%s\" -c \"f = open(\\'%s\\', \\'r\\'); print(f.read()); '",
        "'\"%s\" -c \"f = open(\\'%s\\', \\'r\\');"
    ],
    [
        "'f.close()\"' % (self.pyexe, fn), execute_in=tmpdir, **kws)",
        "'f.close()\"' % (self.pyexe, fn),"
    ],
    [
        "simple_d = {'cflags': '-I/usr/include', 'libflags': '-L/usr/lib',",
        "simple_d = {'cflags': '-I/usr/include', 'libflags':"
    ],
    [
        "simple_variable_d = {'cflags': '-I/foo/bar/include', 'libflags': '-L/foo/bar/lib',",
        "simple_variable_d = {'cflags': '-I/foo/bar/include', 'libflags':"
    ],
    [
        "d = parse_flags(\"-L/usr/lib -lfoo -L/usr/lib -lbar\")",
        "d = parse_flags(\"-L/usr/lib -lfoo"
    ],
    [
        "d = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib -lbar\")",
        "d = parse_flags(\"-L /usr/lib -lfoo -L/usr/lib"
    ],
    [
        "nag_version_strings = [('nagfor', 'NAG Fortran Compiler Release '",
        "nag_version_strings = [('nagfor', 'NAG Fortran Compiler Release"
    ],
    [
        "('nagfor', 'NAG Fortran Compiler Release '",
        "('nagfor', 'NAG Fortran Compiler"
    ],
    [
        "('nagfor', 'NAG Fortran Compiler Release '",
        "('nagfor', 'NAG Fortran Compiler Release"
    ],
    [
        "('nagfor', 'NAG Fortran Compiler Release '",
        "('nagfor', 'NAG Fortran Compiler"
    ],
    [
        "for comp, vs, version in nag_version_strings:",
        "for comp, vs, version in"
    ],
    [
        "is_standalone = __name__ == '__main__' and __package__ is None",
        "is_standalone = __name__ == '__main__'"
    ],
    [
        "def __init__(self, trap_files=\"\", trap_flags=\"\", *args, **kwargs):",
        "def __init__(self, trap_files=\"\", trap_flags=\"\", *args,"
    ],
    [
        "self.dist_error(\"source is trapped by a fake interface\")",
        "self.dist_error(\"source is trapped by"
    ],
    [
        "self.dist_error(\"flag is trapped by a fake interface\")",
        "self.dist_error(\"flag is trapped by a"
    ],
    [
        "return zip(sources, [' '.join(flags)] * len(sources))",
        "return zip(sources, ['"
    ],
    [
        "targets = targets + [\"baseline\"] if has_baseline else targets",
        "targets = targets + [\"baseline\"] if has_baseline else"
    ],
    [
        "'('+' '.join(tar)+')' if isinstance(tar, tuple) else tar",
        "'('+' '.join(tar)+')' if isinstance(tar, tuple) else"
    ],
    [
        "if len(targets) != len(gtargets) or not all(t in gtargets for t in targets):",
        "if len(targets) != len(gtargets) or not all(t in gtargets for t"
    ],
    [
        "\"'sources_status' returns different targets than the compiled targets\\n\"",
        "\"'sources_status' returns different targets"
    ],
    [
        "\"%s != %s\" % (targets, gtargets)",
        "\"%s != %s\""
    ],
    [
        "march = self.march(); cc_name = self.cc_name()",
        "march = self.march();"
    ],
    [
        "'expected empty features, not \"%s\"' % features",
        "'expected empty features, not \"%s\"'"
    ],
    [
        "'dispatch features \"%s\" not match \"%s\"' % (features, match)",
        "'dispatch features \"%s\" not match \"%s\"' % (features,"
    ],
    [
        "'expected empty features, not \"%s\"' % features",
        "'expected empty features, not \"%s\"'"
    ],
    [
        "'baseline features \"%s\" not match \"%s\"' % (features, match)",
        "'baseline features \"%s\" not match \"%s\"' % (features,"
    ],
    [
        "'expected empty flags not \"%s\"' % flags",
        "'expected empty flags not \"%s\"' %"
    ],
    [
        "'flags \"%s\" not match \"%s\"' % (flags, match)",
        "'flags \"%s\" not match \"%s\"' %"
    ],
    [
        "targets, _ = self.get_targets(targets=targets, groups=groups, **kwargs)",
        "targets, _ = self.get_targets(targets=targets,"
    ],
    [
        "'expected empty targets, not \"%s\"' % targets",
        "'expected empty targets, not \"%s\"'"
    ],
    [
        "'targets \"%s\" not match \"%s\"' % (targets, match)",
        "'targets \"%s\" not match \"%s\"'"
    ],
    [
        "'expected to find target \"%s\"' % match_tar",
        "'expected to find target \"%s\"'"
    ],
    [
        "'expected to find empty flags in target \"%s\"' % match_tar",
        "'expected to find empty flags in"
    ],
    [
        "'\"%s\" flags \"%s\" not match \"%s\"' % (match_tar, flags, match_flags)",
        "'\"%s\" flags \"%s\" not match \"%s\"' %"
    ],
    [
        "wrong_cc   = \"clang\" if self.cc   != \"clang\" else \"icc\"",
        "wrong_cc = \"clang\" if self.cc != \"clang\""
    ],
    [
        "raise AssertionError(\"excepted an exception for invalid arguments\")",
        "raise AssertionError(\"excepted an exception for"
    ],
    [
        "\"sse neon vsx\", baseline=\"sse neon vsx\",",
        "\"sse neon vsx\", baseline=\"sse neon"
    ],
    [
        "if o == \"native\" and self.cc_name() == \"msvc\":",
        "if o == \"native\" and self.cc_name()"
    ],
    [
        "\"excepted an exception for %s\" % self.march()",
        "\"excepted an exception for %s\""
    ],
    [
        "\"excepted an exception for %s\" % self.march()",
        "\"excepted an exception for %s\""
    ],
    [
        "\"/*@targets $keep_baseline sse vsx neon vx*/\",",
        "\"/*@targets $keep_baseline sse vsx neon"
    ],
    [
        "** $keep_baseline, sse vsx, neon, vx",
        "** $keep_baseline, sse"
    ],
    [
        "\"/*@targets baseline %s */\" % policy,",
        "\"/*@targets baseline %s */\" %"
    ],
    [
        "class_name=arch + '_' + cc, arch=arch, cc=cc",
        "class_name=arch + '_' + cc,"
    ],
    [
        "class_name=arch + '_' + cc, arch=arch, cc=cc",
        "class_name=arch + '_' + cc, arch=arch,"
    ],
    [
        "from subprocess import Popen, PIPE, STDOUT",
        "from subprocess import Popen,"
    ],
    [
        "\"\"\"Handle the different versions of GNU fortran compilers\"\"\"",
        "\"\"\"Handle the different versions of GNU"
    ],
    [
        "err = 'A valid Fortran version was not found in this string:\\n'",
        "err = 'A valid Fortran version was not found in"
    ],
    [
        "if os.name != 'nt' and sys.platform != 'cygwin':",
        "if os.name != 'nt'"
    ],
    [
        "s = f'Env. variable MACOSX_DEPLOYMENT_TARGET set to {target}'",
        "s = f'Env. variable"
    ],
    [
        "\"\"\" Return detected arch flags from CFLAGS \"\"\"",
        "\"\"\" Return detected arch flags"
    ],
    [
        "\"\"\"Return a list of -arch flags for every supported architecture.\"\"\"",
        "\"\"\"Return a list of -arch flags for"
    ],
    [
        "if _can_target(cmd, arch) and arch in c_archs:",
        "if _can_target(cmd, arch) and arch in"
    ],
    [
        "if c_compiler and c_compiler.compiler_type == \"msvc\":",
        "if c_compiler and"
    ],
    [
        "if c_compiler and c_compiler.compiler_type == \"msvc\":",
        "if c_compiler and"
    ],
    [
        "if c_compiler and c_compiler.compiler_type == \"msvc\":",
        "if c_compiler and"
    ],
    [
        "output = (stdout or b\"\") + (stderr or b\"\")",
        "output = (stdout or b\"\") +"
    ],
    [
        "\"\"\"Create a wrapper shared library for the given objects",
        "\"\"\"Create a wrapper shared library for the"
    ],
    [
        "raise ValueError(\"This method only supports MSVC\")",
        "raise ValueError(\"This method only supports"
    ],
    [
        "root_name = basename + '.' + object_hash + '.gfortran-' + tag",
        "root_name = basename + '.' +"
    ],
    [
        "objects = ([\"-Wl,--whole-archive\"] + list(objects) +",
        "objects = ([\"-Wl,--whole-archive\"] + list(objects)"
    ],
    [
        "lib_args = ['/def:' + def_path, '/OUT:' + lib_path, specifier]",
        "lib_args = ['/def:' + def_path,"
    ],
    [
        "return compiler.compiler_type not in (\"msvc\", )",
        "return compiler.compiler_type not in (\"msvc\","
    ],
    [
        "Convert a set of object files that are not compatible with the default",
        "Convert a set of object files that are not compatible with"
    ],
    [
        "linker, to a file that is compatible.",
        "linker, to a file"
    ],
    [
        "\"\"\"Return true if the architecture supports the -arch flag\"\"\"",
        "\"\"\"Return true if the architecture supports the -arch"
    ],
    [
        "p = Popen(newcmd, stderr=STDOUT, stdout=PIPE, cwd=d)",
        "p = Popen(newcmd, stderr=STDOUT,"
    ],
    [
        "description = 'DIGITAL or Compaq Visual Fortran Compiler'",
        "description = 'DIGITAL or Compaq Visual"
    ],
    [
        "version_pattern = (r'(DIGITAL|Compaq) Visual Fortran Optimizing Compiler'",
        "version_pattern = (r'(DIGITAL|Compaq) Visual"
    ],
    [
        "print('Ignoring \"%s\" (I think it is msvccompiler.py bug)' % (e))",
        "print('Ignoring \"%s\" (I think it"
    ],
    [
        "f + '.f', '-o', f + '.o']",
        "f + '.f', '-o',"
    ],
    [
        "description = 'Intel Fortran Compiler for Itanium apps'",
        "description = 'Intel Fortran Compiler for Itanium"
    ],
    [
        "f + '.f', '/o', f + '.o']",
        "f + '.f', '/o',"
    ],
    [
        "opt = ['/nologo', '/MD', '/nbs', '/names:lowercase',",
        "opt = ['/nologo', '/MD',"
    ],
    [
        "description = 'Intel Visual Fortran Compiler for Itanium apps'",
        "description = 'Intel Visual Fortran Compiler for Itanium"
    ],
    [
        "return ['-g', '-u', '-nan', '-C=all', '-thread_safe',",
        "return ['-g', '-u', '-nan', '-C=all',"
    ],
    [
        "return ['-g', '-nan', '-C=all', '-u', '-thread_safe']",
        "return ['-g', '-nan', '-C=all', '-u',"
    ],
    [
        "from os.path import join, dirname, normpath",
        "from os.path import join, dirname,"
    ],
    [
        "description = 'Portland Group Fortran Compiler'",
        "description = 'Portland Group Fortran"
    ],
    [
        "description = 'Portland Group Fortran LLVM Compiler'",
        "description = 'Portland Group Fortran"
    ],
    [
        "description = 'IBM XL Fortran Compiler'",
        "description = 'IBM XL"
    ],
    [
        "if version is None and sys.platform.startswith('aix'):",
        "if version is None"
    ],
    [
        "if version is None and os.path.isdir(xlf_dir):",
        "if version is None"
    ],
    [
        "l = [d for d in l if os.path.isfile(os.path.join(xlf_dir, d, 'xlf.cfg'))]",
        "l = [d for d in l if os.path.isfile(os.path.join(xlf_dir,"
    ],
    [
        "\"\"\" NVIDIA High Performance Computing (HPC) SDK Fortran Compiler",
        "\"\"\" NVIDIA High Performance Computing (HPC) SDK Fortran"
    ],
    [
        "version_pattern = r'\\s*(nvfortran|.+ \\(aka nvfortran\\)) (?P<version>[\\d.-]+).*'",
        "version_pattern = r'\\s*(nvfortran|.+ \\(aka nvfortran\\))"
    ],
    [
        "Contains FCompiler, an abstract base class that defines the interface",
        "Contains FCompiler, an abstract base class that defines the"
    ],
    [
        "for the numpy.distutils Fortran compiler abstraction model.",
        "for the numpy.distutils Fortran compiler abstraction"
    ],
    [
        "To be consistent, where the term 'executable' is used, it means the single",
        "To be consistent, where the term 'executable' is used, it"
    ],
    [
        "file, like 'gcc', that is executed, and should be a string. In contrast,",
        "file, like 'gcc', that is executed, and should be"
    ],
    [
        "'command' means the entire command line, like ['gcc', '-c', 'file.c'], and",
        "'command' means the entire command line, like"
    ],
    [
        "But note that FCompiler.executables is actually a dictionary of commands.",
        "But note that FCompiler.executables is"
    ],
    [
        "from numpy.distutils.misc_util import is_string, all_strings, is_sequence, \\",
        "from numpy.distutils.misc_util import is_string, all_strings,"
    ],
    [
        "\"\"\"Abstract base class to define the interface that must be implemented",
        "\"\"\"Abstract base class to define the interface that must be"
    ],
    [
        "DON'T call these methods (except get_version) after",
        "DON'T call these methods (except get_version)"
    ],
    [
        "constructing a compiler instance or inside any other method.",
        "constructing a compiler instance or inside any other"
    ],
    [
        "All methods, except update_executables() and find_executables(),",
        "All methods, except update_executables() and"
    ],
    [
        "After constructing a compiler instance, always call customize(dist=None)",
        "After constructing a compiler instance,"
    ],
    [
        "method that finalizes compiler construction and makes the following",
        "method that finalizes compiler construction and makes"
    ],
    [
        "version_cmd = ('exe.version_cmd', None, None, None, False),",
        "version_cmd = ('exe.version_cmd', None,"
    ],
    [
        "linker_so = ('exe.linker_so', 'LDSHARED', 'ldshared', None, False),",
        "linker_so = ('exe.linker_so', 'LDSHARED', 'ldshared',"
    ],
    [
        "linker_exe = ('exe.linker_exe', 'LD', 'ld', None, False),",
        "linker_exe = ('exe.linker_exe', 'LD', 'ld', None,"
    ],
    [
        "archiver = (None, 'AR', 'ar', None, False),",
        "archiver = (None, 'AR',"
    ],
    [
        "ranlib = (None, 'RANLIB', 'ranlib', None, False),",
        "ranlib = (None, 'RANLIB', 'ranlib', None,"
    ],
    [
        "free = ('flags.free', 'FREEFLAGS', 'freeflags', flaglist, True),",
        "free = ('flags.free', 'FREEFLAGS', 'freeflags',"
    ],
    [
        "fix = ('flags.fix', None, None, flaglist, False),",
        "fix = ('flags.fix', None,"
    ],
    [
        "opt = ('flags.opt', 'FOPT', 'opt', flaglist, True),",
        "opt = ('flags.opt', 'FOPT', 'opt', flaglist,"
    ],
    [
        "arch = ('flags.arch', 'FARCH', 'arch', flaglist, False),",
        "arch = ('flags.arch', 'FARCH', 'arch',"
    ],
    [
        "debug = ('flags.debug', 'FDEBUG', 'fdebug', flaglist, True),",
        "debug = ('flags.debug', 'FDEBUG',"
    ],
    [
        "flags = ('self.get_flags', 'FFLAGS', 'fflags', flaglist, True),",
        "flags = ('self.get_flags', 'FFLAGS', 'fflags', flaglist,"
    ],
    [
        "linker_so = ('flags.linker_so', 'LDFLAGS', 'ldflags', flaglist, True),",
        "linker_so = ('flags.linker_so', 'LDFLAGS',"
    ],
    [
        "linker_exe = ('flags.linker_exe', 'LDFLAGS', 'ldflags', flaglist, True),",
        "linker_exe = ('flags.linker_exe', 'LDFLAGS',"
    ],
    [
        "ar = ('flags.ar', 'ARFLAGS', 'arflags', flaglist, True),",
        "ar = ('flags.ar', 'ARFLAGS', 'arflags', flaglist,"
    ],
    [
        "\"unknown executable '%s' for class %s\" %",
        "\"unknown executable '%s' for class %s\""
    ],
    [
        "\"\"\"Go through the self.executables dictionary, and attempt to",
        "\"\"\"Go through the self.executables dictionary, and attempt"
    ],
    [
        "Executable names are looked for in the environment (environment",
        "Executable names are looked for in the"
    ],
    [
        "the command list, and the self.possible_executables list.",
        "the command list, and"
    ],
    [
        "Subclasses should call this if overridden.",
        "Subclasses should call this"
    ],
    [
        "if value is not None and not is_sequence_of_strings(value):",
        "if value is not None and not"
    ],
    [
        "\"%s value %r is invalid in class %s\" %",
        "\"%s value %r is invalid in"
    ],
    [
        "if not e or e in seen:",
        "if not e or e"
    ],
    [
        "\"\"\"Called at the beginning of customisation. Subclasses should",
        "\"\"\"Called at the beginning of customisation. Subclasses"
    ],
    [
        "override this if they need to set up the executables dictionary.",
        "override this if they need to set"
    ],
    [
        "Note that self.find_executables() is run afterwards, so the",
        "Note that self.find_executables() is run afterwards,"
    ],
    [
        "\"\"\"List of flags common to all compiler types.\"\"\"",
        "\"\"\"List of flags common"
    ],
    [
        "\"\"\"List of linker flags to build a shared library.\"\"\"",
        "\"\"\"List of linker flags to build a shared"
    ],
    [
        "\"\"\"List of linker flags to build an executable.\"\"\"",
        "\"\"\"List of linker flags to build an"
    ],
    [
        "\"\"\"List of architecture independent compiler flags.\"\"\"",
        "\"\"\"List of architecture"
    ],
    [
        "\"\"\"List of architecture dependent compiler flags.\"\"\"",
        "\"\"\"List of architecture dependent"
    ],
    [
        "\"\"\"List of compiler flags to compile with debugging information.\"\"\"",
        "\"\"\"List of compiler flags to compile with"
    ],
    [
        "This method gets Fortran compiler specific information from",
        "This method gets Fortran"
    ],
    [
        "(i) class definition, (ii) environment, (iii) distutils config",
        "(i) class definition, (ii) environment, (iii) distutils"
    ],
    [
        "files, and (iv) command line (later overrides earlier).",
        "files, and (iv) command"
    ],
    [
        "This method should be always called after constructing a",
        "This method should be always called after constructing"
    ],
    [
        "compiler instance. But not in __init__ because Distribution",
        "compiler instance. But not in __init__ because"
    ],
    [
        "instance is needed for (iii) and (iv).",
        "instance is needed for"
    ],
    [
        "oflags, aflags, dflags = [], [], []",
        "oflags, aflags, dflags = [],"
    ],
    [
        "this_get = getattr(self, 'get_flags_' + tag)",
        "this_get = getattr(self,"
    ],
    [
        "t = '%s_%s' % (tag, name)",
        "t = '%s_%s' %"
    ],
    [
        "if c and this_get is not getattr(self, 'get_flags_' + t):",
        "if c and this_get is not getattr(self, 'get_flags_'"
    ],
    [
        "fflags = self.flag_vars.flags + dflags + oflags + aflags",
        "fflags = self.flag_vars.flags + dflags +"
    ],
    [
        "linker_so = [ld_so_aix] + linker_so + ['-bI:'+python_exp]",
        "linker_so = [ld_so_aix] + linker_so +"
    ],
    [
        "linker_so = [ld_so_aix] + linker_so + ['-bI:'+python_exp]",
        "linker_so = [ld_so_aix] + linker_so"
    ],
    [
        "\"\"\"Print out the attributes of a compiler instance.\"\"\"",
        "\"\"\"Print out the attributes of"
    ],
    [
        "for key in list(self.executables.keys()) + \\",
        "for key in"
    ],
    [
        "for l in pretty_printer.generate_help(\"%s instance properties:\" \\",
        "for l in pretty_printer.generate_help(\"%s instance properties:\""
    ],
    [
        "def _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts):",
        "def _compile(self, obj, src, ext, cc_args, extra_postargs,"
    ],
    [
        "log.info('using compile options from source: %r' \\",
        "log.info('using compile options from source: %r'"
    ],
    [
        "command = compiler + cc_args + extra_flags + s_args + o_args \\",
        "command = compiler + cc_args + extra_flags + s_args +"
    ],
    [
        "print('XXX: module_build_dir=%r option ignored' % (module_build_dir))",
        "print('XXX: module_build_dir=%r option ignored' %"
    ],
    [
        "print('XXX: Fix module_dir_switch for ', self.__class__.__name__)",
        "print('XXX: Fix module_dir_switch"
    ],
    [
        "print('XXX: module_dirs=%r option ignored' % (module_dirs))",
        "print('XXX: module_dirs=%r option"
    ],
    [
        "print('XXX: Fix module_include_switch for ', self.__class__.__name__)",
        "print('XXX: Fix module_include_switch"
    ],
    [
        "raise TypeError(\"'output_dir' must be a string or None\")",
        "raise TypeError(\"'output_dir' must be a"
    ],
    [
        "ld_args = ld_args + lib_opts + o_args",
        "ld_args = ld_args +"
    ],
    [
        "hook = getattr(self, 'get_flags_' + hook_name)",
        "hook = getattr(self,"
    ],
    [
        "Check if the given C compiler can link objects produced by",
        "Check if the given C compiler can link"
    ],
    [
        "Convert a set of object files that are not compatible with the default",
        "Convert a set of object files that are not compatible with"
    ],
    [
        "linker, to a file that is compatible.",
        "linker, to a file"
    ],
    [
        "List of object files to include.",
        "List of object files"
    ],
    [
        "Output directory to place generated object files.",
        "Output directory to place"
    ],
    [
        "Output directory to place extra DLL files that need to be",
        "Output directory to place extra DLL"
    ],
    [
        "Note that the number of output files is not necessarily",
        "Note that the number of output files is not"
    ],
    [
        "\"\"\"Cache all the FCompiler classes found in modules in the",
        "\"\"\"Cache all the FCompiler classes found in"
    ],
    [
        "raise ValueError(\"alias %r defined for both %s and %s\"",
        "raise ValueError(\"alias %r defined for both"
    ],
    [
        "log.warn('Trying %r compiler as suggested by %r '",
        "log.warn('Trying %r compiler as"
    ],
    [
        "if re.match(pattern, platform) or re.match(pattern, osname):",
        "if re.match(pattern, platform)"
    ],
    [
        "\"\"\"Determine the default Fortran compiler to use for the given",
        "\"\"\"Determine the default Fortran compiler"
    ],
    [
        "\"\"\"Generate an instance of some FCompiler subclass for the supplied",
        "\"\"\"Generate an instance of some FCompiler"
    ],
    [
        "msg = \"don't know how to compile Fortran code on platform '%s'\" % plat",
        "msg = \"don't know how to compile Fortran"
    ],
    [
        "msg = msg + \" with '%s' compiler.\" % compiler",
        "msg = msg + \" with '%s' compiler.\" %"
    ],
    [
        "msg = msg + \" Supported compilers are: %s)\" \\",
        "msg = msg + \" Supported compilers are:"
    ],
    [
        "\"\"\"Print list of available compilers (used by the \"--help-fcompiler\"",
        "\"\"\"Print list of available compilers (used by"
    ],
    [
        "log.debug(\"show_fcompilers: %s not found\" % (compiler,))",
        "log.debug(\"show_fcompilers: %s not found\" %"
    ],
    [
        "pretty_printer.print_help(\"Compilers not available on this platform:\")",
        "pretty_printer.print_help(\"Compilers not available on"
    ],
    [
        "print(\"For compiler details, run 'config_fc --verbose' setup command.\")",
        "print(\"For compiler details, run 'config_fc"
    ],
    [
        "\"\"\"Check if file is in free format Fortran.\"\"\"",
        "\"\"\"Check if file is in"
    ],
    [
        "from os.path import join, dirname, normpath",
        "from os.path import join, dirname,"
    ],
    [
        "version_pattern =  r'MIPSpro Compilers: Version (?P<version>[^\\s*,]*)'",
        "version_pattern = r'MIPSpro Compilers: Version"
    ],
    [
        "hook, envvar, confvar, convert, append = conf_desc",
        "hook, envvar, confvar, convert, append ="
    ],
    [
        "convert = lambda x : x",
        "convert = lambda"
    ],
    [
        "print('  hook   : %s' % (convert(v),))",
        "print(' hook : %s'"
    ],
    [
        "print('  config : %s' % (convert(v),))",
        "print(' config :"
    ],
    [
        "f\"'EnvironmentConfig' object has no attribute '{name}'\"",
        "f\"'EnvironmentConfig' object has"
    ],
    [
        "hook, envvar, confvar, convert, append = conf_desc",
        "hook, envvar, confvar, convert, append"
    ],
    [
        "if confvar is not None and self._conf:",
        "if confvar is not"
    ],
    [
        "version_pattern =  r'PathScale\\(TM\\) Compiler Suite: Version (?P<version>[\\d.]+)'",
        "version_pattern = r'PathScale\\(TM\\) Compiler Suite: Version"
    ],
    [
        "description = 'Absoft Corp Fortran Compiler'",
        "description = 'Absoft Corp Fortran"
    ],
    [
        "from distutils.command.build import build as old_build",
        "from distutils.command.build import build"
    ],
    [
        "sub_commands = [('config_cc',     lambda *args: True),",
        "sub_commands = [('config_cc',"
    ],
    [
        "\"turn all warnings into errors (-Werror)\"),",
        "\"turn all warnings into"
    ],
    [
        "\"specify a list of enabled baseline CPU optimizations\"),",
        "\"specify a list of enabled"
    ],
    [
        "\"specify a list of dispatched CPU optimizations\"),",
        "\"specify a list of dispatched"
    ],
    [
        "\"specify a list of CPU optimizations to be tested against NumPy SIMD interface\"),",
        "\"specify a list of CPU optimizations to be tested"
    ],
    [
        "('help-fcompiler', None, \"list available Fortran compilers\",",
        "('help-fcompiler', None, \"list available Fortran"
    ],
    [
        "the '_simd' module is a very large. Adding more dispatched features",
        "the '_simd' module is a very large."
    ],
    [
        "will increase binary size and compile time. By default we minimize",
        "will increase binary size and compile time. By default we"
    ],
    [
        "the targeted features to those most commonly used by the NumPy SIMD interface(NPYV),",
        "the targeted features to those most commonly used"
    ],
    [
        "NOTE: any specified features will be ignored if they're:",
        "NOTE: any specified features will"
    ],
    [
        "- not part of dispatch-able features(--cpu-dispatch)",
        "- not part of"
    ],
    [
        "- not supported by compiler or platform",
        "- not supported by compiler"
    ],
    [
        "\"\"\" Distutils command to hold user specified options",
        "\"\"\" Distutils command to hold user specified"
    ],
    [
        "config_fc command is used by the FCompiler.customize() method.",
        "config_fc command is used by the FCompiler.customize()"
    ],
    [
        "('fcompiler=', None, \"specify Fortran compiler type\"),",
        "('fcompiler=', None, \"specify Fortran compiler"
    ],
    [
        "('arch=', None, \"specify architecture specific optimization flags\"),",
        "('arch=', None, \"specify architecture specific optimization"
    ],
    [
        "('debug', 'g', \"compile with debugging information\"),",
        "('debug', 'g', \"compile with"
    ],
    [
        "('noarch', None, \"compile without arch-dependent optimization\"),",
        "('noarch', None, \"compile without arch-dependent"
    ],
    [
        "('help-fcompiler', None, \"list available Fortran compilers\",",
        "('help-fcompiler', None, \"list available Fortran"
    ],
    [
        "log.info('unifying config_fc, config, build_clib, build_ext, build commands --fcompiler options')",
        "log.info('unifying config_fc, config, build_clib, build_ext, build"
    ],
    [
        "cmd_list = [self, config, build_clib, build_ext, build]",
        "cmd_list = [self, config,"
    ],
    [
        "if not isinstance(v, str): v = v.compiler_type",
        "if not isinstance(v, str): v"
    ],
    [
        "if v not in l: l.append(v)",
        "if v not in"
    ],
    [
        "log.warn('  commands have different --%s options: %s'\\",
        "log.warn(' commands have different"
    ],
    [
        "', using first in list as default' % (a, l))",
        "', using first in list as"
    ],
    [
        "\"\"\" Distutils command to hold user specified options",
        "\"\"\" Distutils command to hold"
    ],
    [
        "description = \"specify C/C++ compiler information\"",
        "description = \"specify C/C++"
    ],
    [
        "('compiler=', None, \"specify C/C++ compiler type\"),",
        "('compiler=', None, \"specify C/C++"
    ],
    [
        "log.info('unifying config_cc, config, build_clib, build_ext, build commands --compiler options')",
        "log.info('unifying config_cc, config, build_clib, build_ext, build commands"
    ],
    [
        "cmd_list = [self, config, build_clib, build_ext, build]",
        "cmd_list = [self, config, build_clib, build_ext,"
    ],
    [
        "if not isinstance(v, str): v = v.compiler_type",
        "if not isinstance(v, str): v ="
    ],
    [
        "if v not in l: l.append(v)",
        "if v not in"
    ],
    [
        "log.warn('  commands have different --%s options: %s'\\",
        "log.warn(' commands have different --%s"
    ],
    [
        "', using first in list as default' % (a, l))",
        "', using first in list as default' %"
    ],
    [
        "\"\"\" Modified version of build_ext that handles fortran source files.",
        "\"\"\" Modified version of build_ext"
    ],
    [
        "from distutils.command.build_ext import build_ext as old_build_ext",
        "from distutils.command.build_ext import"
    ],
    [
        "description = \"build C/C++/F extensions (compile/link to build directory)\"",
        "description = \"build C/C++/F extensions"
    ],
    [
        "\"turn all warnings into errors (-Werror)\"),",
        "\"turn all warnings into errors"
    ],
    [
        "\"specify a list of enabled baseline CPU optimizations\"),",
        "\"specify a list of enabled"
    ],
    [
        "\"specify a list of dispatched CPU optimizations\"),",
        "\"specify a list of dispatched"
    ],
    [
        "\"specify a list of CPU optimizations to be tested against NumPy SIMD interface\"),",
        "\"specify a list of CPU optimizations to be"
    ],
    [
        "('help-fcompiler', None, \"list available Fortran compilers\",",
        "('help-fcompiler', None, \"list available"
    ],
    [
        "boolean_options = old_build_ext.boolean_options + ['warn-error', 'disable-optimization']",
        "boolean_options = old_build_ext.boolean_options +"
    ],
    [
        "raise ValueError(\"--parallel/-j argument must be an integer\") from e",
        "raise ValueError(\"--parallel/-j argument must be"
    ],
    [
        "log.warn('build_clib already run, it is too late to '",
        "log.warn('build_clib already run, it is"
    ],
    [
        "dispatch_hpath = os.path.join(\"numpy\", \"distutils\", \"include\", \"npy_cpu_dispatch_config.h\")",
        "dispatch_hpath = os.path.join(\"numpy\","
    ],
    [
        "for libname, build_info in build_clib.libraries or []:",
        "for libname, build_info in"
    ],
    [
        "if libname in clibs and clibs[libname] != build_info:",
        "if libname in clibs and clibs[libname] !="
    ],
    [
        "log.warn('library %r defined more than once,'",
        "log.warn('library %r defined"
    ],
    [
        "for libname, build_info in self.distribution.libraries or []:",
        "for libname, build_info in"
    ],
    [
        "for l in clibs.get(libname, {}).get('source_languages', []):",
        "for l in clibs.get(libname, {}).get('source_languages',"
    ],
    [
        "log.info('updating extension %r libraries from %r to %r'",
        "log.info('updating extension %r libraries from %r to"
    ],
    [
        "log.info('extending extension %r defined_macros with %r'",
        "log.info('extending extension %r defined_macros"
    ],
    [
        "if l and l != ext_language and ext.language:",
        "if l and l"
    ],
    [
        "log.warn('resetting extension %r language from %r to %r.' %",
        "log.warn('resetting extension %r language from"
    ],
    [
        "if sources is None or not is_sequence(sources):",
        "if sources is None or"
    ],
    [
        "(\"in 'ext_modules' option (extension '%s'), \"",
        "(\"in 'ext_modules' option (extension '%s'),"
    ],
    [
        "\"'sources' must be present and must be \"",
        "\"'sources' must be present and must"
    ],
    [
        "\"a list of source filenames\") % ext.name)",
        "\"a list of source"
    ],
    [
        "if not self.disable_optimization and not self.compiler_opt.is_cached():",
        "if not self.disable_optimization and not"
    ],
    [
        "if not (force_rebuild or newer_group(depends, ext_filename, 'newer')):",
        "if not (force_rebuild or"
    ],
    [
        "extra_cflags = getattr(ext, 'extra_c_compile_args', None) or []",
        "extra_cflags = getattr(ext, 'extra_c_compile_args', None) or"
    ],
    [
        "extra_cxxflags = getattr(ext, 'extra_cxx_compile_args', None) or []",
        "extra_cxxflags = getattr(ext, 'extra_cxx_compile_args', None) or"
    ],
    [
        "c_sources, cxx_sources, f_sources, fmodule_sources = \\",
        "c_sources, cxx_sources, f_sources, fmodule_sources"
    ],
    [
        "if cxx_sources and cxx_compiler is None:",
        "if cxx_sources and"
    ],
    [
        "raise DistutilsError(\"extension %r has C++ sources\"",
        "raise DistutilsError(\"extension %r has C++"
    ],
    [
        "\"but no C++ compiler found\" % (ext.name))",
        "\"but no C++ compiler"
    ],
    [
        "if (f_sources or fmodule_sources) and fcompiler is None:",
        "if (f_sources or fmodule_sources) and"
    ],
    [
        "raise DistutilsError(\"extension %r has Fortran sources \"",
        "raise DistutilsError(\"extension %r has"
    ],
    [
        "\"but no Fortran compiler found\" % (ext.name))",
        "\"but no Fortran compiler"
    ],
    [
        "self.warn(\"extension %r has Fortran libraries \"",
        "self.warn(\"extension %r has Fortran libraries"
    ],
    [
        "\"but no Fortran linker found, using default linker\" % (ext.name))",
        "\"but no Fortran linker found, using"
    ],
    [
        "if ext.language == 'c++' and cxx_compiler is None:",
        "if ext.language == 'c++' and"
    ],
    [
        "self.warn(\"extension %r has C++ libraries \"",
        "self.warn(\"extension %r has C++"
    ],
    [
        "\"but no C++ linker found, using default linker\" % (ext.name))",
        "\"but no C++ linker found, using default linker\" %"
    ],
    [
        "for _srcs, _dst, _ext in (",
        "for _srcs, _dst,"
    ],
    [
        "for s in _src[:] if s.endswith(_ext)",
        "for s in"
    ],
    [
        "log.warn('failed to move %r to %r' %",
        "log.warn('failed to move %r"
    ],
    [
        "if self.compiler.compiler_type in ('msvc', 'intelw', 'intelemw'):",
        "if self.compiler.compiler_type in ('msvc', 'intelw',"
    ],
    [
        "for f in glob(d + '/*.dll'):",
        "for f in"
    ],
    [
        "if ext.language == 'c++' and cxx_compiler is not None:",
        "if ext.language == 'c++' and"
    ],
    [
        "fake_lib = os.path.join(libdir, lib + '.fobjects')",
        "fake_lib = os.path.join(libdir, lib +"
    ],
    [
        "c_lib = os.path.join(libdir, lib + '.cobjects')",
        "c_lib = os.path.join(libdir, lib"
    ],
    [
        "fobjects = [os.path.abspath(obj) for obj in unlinkable_fobjects]",
        "fobjects = [os.path.abspath(obj) for obj in"
    ],
    [
        "for libdir in c_library_dirs or []:",
        "for libdir in c_library_dirs"
    ],
    [
        "libfile = os.path.join(libdir, '%s.lib' % (libname))",
        "libfile = os.path.join(libdir,"
    ],
    [
        "libfile = os.path.join(libdir, 'lib%s.a' % (libname))",
        "libfile = os.path.join(libdir,"
    ],
    [
        "log.warn('could not find library %r in directories %s'",
        "log.warn('could not find library %r in"
    ],
    [
        "p = combine_paths(f_lib_dirs, 'lib' + lib + '.a')",
        "p = combine_paths(f_lib_dirs, 'lib' + lib +"
    ],
    [
        "dst_name = os.path.join(self.build_temp, lib + '.lib')",
        "dst_name = os.path.join(self.build_temp,"
    ],
    [
        "from distutils.command.config import config as old_config",
        "from distutils.command.config import config"
    ],
    [
        "('fcompiler=', None, \"specify the Fortran compiler type\"),",
        "('fcompiler=', None, \"specify the Fortran compiler"
    ],
    [
        "Could not initialize compiler instance: do you have Visual Studio",
        "Could not initialize compiler instance:"
    ],
    [
        "installed?  If you are trying to build with MinGW, please use \"python setup.py",
        "installed? If you are trying to build with MinGW,"
    ],
    [
        "Original exception was: %s, and the Compiler class was %s",
        "Original exception was: %s, and the Compiler"
    ],
    [
        "raise CompileError('%s compiler is not set' % (lang,))",
        "raise CompileError('%s compiler is not set' %"
    ],
    [
        "def _compile (self, body, headers, include_dirs, lang):",
        "def _compile (self, body,"
    ],
    [
        "for d in self.fcompiler.library_dirs or []:",
        "for d in"
    ],
    [
        "for libname in self.fcompiler.libraries or []:",
        "for libname in self.fcompiler.libraries or"
    ],
    [
        "for libdir in library_dirs or []:",
        "for libdir in library_dirs"
    ],
    [
        "libfile = os.path.join(libdir, '%s.lib' % (libname))",
        "libfile = os.path.join(libdir,"
    ],
    [
        "libfile = os.path.join(libdir, 'lib%s.a' % (libname))",
        "libfile = os.path.join(libdir, 'lib%s.a'"
    ],
    [
        "log.warn('could not find library %r in directories %s' \\",
        "log.warn('could not find library %r"
    ],
    [
        "def check_header(self, header, include_dirs=None, library_dirs=None, lang='c'):",
        "def check_header(self, header, include_dirs=None,"
    ],
    [
        "\"/* we need a dummy line to make distutils happy */\",",
        "\"/* we need a dummy line to make"
    ],
    [
        "\"\"\"Check type availability. Return True if the type can be compiled,",
        "\"\"\"Check type availability. Return True if the type"
    ],
    [
        "def check_type_size(self, type_name, headers=None, include_dirs=None, library_dirs=None, expected=None):",
        "def check_type_size(self, type_name, headers=None,"
    ],
    [
        "\"\"\"Check size of a given type.\"\"\"",
        "\"\"\"Check size of"
    ],
    [
        "self._compile(body % {'type': type_name, 'size': size},",
        "self._compile(body % {'type': type_name,"
    ],
    [
        "self._compile(body % {'type': type_name, 'size': mid},",
        "self._compile(body % {'type': type_name, 'size':"
    ],
    [
        "self._compile(body % {'type': type_name, 'size': mid},",
        "self._compile(body % {'type': type_name, 'size':"
    ],
    [
        "\"\"\"Check a list of functions at once.",
        "\"\"\"Check a list of functions at"
    ],
    [
        "This is useful to speed up things, since all the functions in the funcs",
        "This is useful to speed up things, since all the functions in"
    ],
    [
        "list will be put in one compilation unit.",
        "list will be put in"
    ],
    [
        "list of libraries to link the code snippet to",
        "list of libraries to link the code"
    ],
    [
        "for every (key, value), the declaration in the value will be",
        "for every (key, value), the declaration in the value will"
    ],
    [
        "used for function in key. If a function is not in the",
        "used for function in key. If a"
    ],
    [
        "dictionary, no declaration will be used.",
        "dictionary, no declaration"
    ],
    [
        "for every item (f, value), if the value is True, a call will be",
        "for every item (f, value), if the value is True, a call"
    ],
    [
        "if f in call and call[f]:",
        "if f in"
    ],
    [
        "if not (call_args and f in call_args and call_args[f]):",
        "if not (call_args and f in call_args and"
    ],
    [
        "\"\"\"Return the inline keyword recognized by the compiler, empty string",
        "\"\"\"Return the inline keyword recognized"
    ],
    [
        "\"\"\"Return the restrict keyword recognized by the compiler, empty string",
        "\"\"\"Return the restrict keyword recognized by the compiler, empty"
    ],
    [
        "\"\"\"Return True if the C compiler is gcc\"\"\"",
        "\"\"\"Return True if the C"
    ],
    [
        "\"\"\"Return True if the GCC version is greater than or equal to the",
        "\"\"\"Return True if the GCC version is greater than or equal to"
    ],
    [
        "\"\"\"Try to compile, link to an executable, and run a program",
        "\"\"\"Try to compile, link to an executable,"
    ],
    [
        "built from 'body' and 'headers'. Returns the exit status code",
        "built from 'body' and 'headers'. Returns"
    ],
    [
        "of the program and its output.",
        "of the program and its"
    ],
    [
        "\"Usage of get_output is deprecated: please do not \\n\"",
        "\"Usage of get_output is deprecated: please"
    ],
    [
        "\"use it anymore, and avoid configuration checks \\n\"",
        "\"use it anymore, and avoid configuration checks"
    ],
    [
        "\"involving running executable on the target machine.\\n\"",
        "\"involving running executable on the"
    ],
    [
        "src, obj, exe = self._link(body, headers, include_dirs,",
        "src, obj, exe = self._link(body, headers,"
    ],
    [
        "log.error('subprocess exited with signal %d' % (sig,))",
        "log.error('subprocess exited with signal"
    ],
    [
        "from distutils.command.install_headers import install_headers as old_install_headers",
        "from distutils.command.install_headers import install_headers"
    ],
    [
        "from distutils.command.build_py import build_py as old_build_py",
        "from distutils.command.build_py import"
    ],
    [
        "if build_src.py_modules_dict and self.packages is None:",
        "if build_src.py_modules_dict and self.packages"
    ],
    [
        "new_py_modules = [_m for _m in self.py_modules if is_string(_m)]",
        "new_py_modules = [_m for _m in self.py_modules if"
    ],
    [
        "from numpy.distutils.from_template import process_file as process_f_file",
        "from numpy.distutils.from_template import process_file"
    ],
    [
        "from numpy.distutils.conv_template import process_file as process_c_file",
        "from numpy.distutils.conv_template import"
    ],
    [
        "\"\"\"Substitute any occurrence of @foo@ by d['foo'] from source file into",
        "\"\"\"Substitute any occurrence of @foo@ by"
    ],
    [
        "('build-src=', 'd', \"directory to \\\"build\\\" sources to\"),",
        "('build-src=', 'd', \"directory to"
    ],
    [
        "('swig=', None, \"path to the SWIG executable\"),",
        "('swig=', None, \"path to the SWIG"
    ],
    [
        "('swig-opts=', None, \"list of SWIG command line options\"),",
        "('swig-opts=', None, \"list of SWIG command line"
    ],
    [
        "('swig-cpp', None, \"make SWIG create C++ files (default is autodetected from sources)\"),",
        "('swig-cpp', None, \"make SWIG create C++ files (default is autodetected from"
    ],
    [
        "('force', 'f', \"forcibly build everything (ignore file timestamps)\"),",
        "('force', 'f', \"forcibly build everything"
    ],
    [
        "\"ignore build-lib and put compiled extensions into the source \"",
        "\"ignore build-lib and put compiled extensions"
    ],
    [
        "\"directory alongside your pure Python modules\"),",
        "\"directory alongside your"
    ],
    [
        "\"change logging level from WARN to INFO which will show all \"",
        "\"change logging level from WARN to INFO which will show"
    ],
    [
        "log.warn('ignoring --swigflags as --swig-opts already used')",
        "log.warn('ignoring --swigflags as --swig-opts already"
    ],
    [
        "log.warn('both build_src and build_ext define %s option' % (o))",
        "log.warn('both build_src and build_ext define %s"
    ],
    [
        "log.info('using \"%s=%s\" option from build_ext command' % (o, v))",
        "log.info('using \"%s=%s\" option from build_ext"
    ],
    [
        "funcs = [f for f in files if hasattr(f, '__call__')]",
        "funcs = [f for f in"
    ],
    [
        "files = [f for f in files if not hasattr(f, '__call__')]",
        "files = [f for f in"
    ],
    [
        "target = os.path.join(build_dir, module_base + '.py')",
        "target = os.path.join(build_dir, module_base"
    ],
    [
        "log.info('building library \"%s\" sources' % (lib_name))",
        "log.info('building library \"%s\" sources' %"
    ],
    [
        "log.info('%s - nothing done with h_files = %s',",
        "log.info('%s - nothing done with h_files"
    ],
    [
        "log.info('building extension \"%s\" sources' % (ext.name))",
        "log.info('building extension \"%s\" sources' %"
    ],
    [
        "log.info('%s - nothing done with h_files = %s',",
        "log.info('%s - nothing done with h_files ="
    ],
    [
        "[log.info(\"  adding '%s' to sources.\" % (s,)) for s in source]",
        "[log.info(\" adding '%s' to sources.\" %"
    ],
    [
        "log.info(\"  adding '%s' to sources.\" % (source,))",
        "log.info(\" adding '%s' to sources.\""
    ],
    [
        "def filter_files(self, sources, exts = []):",
        "def filter_files(self, sources, exts ="
    ],
    [
        "if (self.force or newer_group([source] + depends, target_file)):",
        "if (self.force or newer_group([source] +"
    ],
    [
        "log.info(\"  adding '%s' to include_dirs.\" % (d))",
        "log.info(\" adding '%s' to include_dirs.\""
    ],
    [
        "\"\"\"Pyrex not supported; this remains for Cython support (see below)\"\"\"",
        "\"\"\"Pyrex not supported; this remains for Cython support (see"
    ],
    [
        "def generate_a_pyrex_source(self, base, ext_name, source, extension):",
        "def generate_a_pyrex_source(self, base,"
    ],
    [
        "\"\"\"Pyrex is not supported, but some projects monkeypatch this method.",
        "\"\"\"Pyrex is not supported, but some projects monkeypatch"
    ],
    [
        "This method will remain here for compatibility reasons.",
        "This method will remain here for"
    ],
    [
        "raise DistutilsSetupError('mismatch of extension names: %s '",
        "raise DistutilsSetupError('mismatch of extension"
    ],
    [
        "'provides %r but expected %r' % (",
        "'provides %r but expected %r'"
    ],
    [
        "log.warn('  target %s does not exist:\\n   '\\",
        "log.warn(' target %s does"
    ],
    [
        "'Assuming %smodule.c was generated with '\\",
        "'Assuming %smodule.c was generated"
    ],
    [
        "log.info('   Yes! Using %r as up-to-date target.' \\",
        "log.info(' Yes! Using %r as up-to-date"
    ],
    [
        "'only one .pyf file is allowed per extension module but got'\\",
        "'only one .pyf file is allowed per extension"
    ],
    [
        "if (self.force or newer_group(depends, target_file, 'newer')) \\",
        "if (self.force or newer_group(depends, target_file, 'newer'))"
    ],
    [
        "target_file = os.path.join(target_dir, ext_name + 'module.c')",
        "target_file = os.path.join(target_dir, ext_name +"
    ],
    [
        "if (self.force or newer_group(depends, target_file, 'newer')) \\",
        "if (self.force or newer_group(depends, target_file,"
    ],
    [
        "log.info(\"  adding '%s' to sources.\" % (target_c))",
        "log.info(\" adding '%s' to sources.\""
    ],
    [
        "log.info(\"  adding '%s' to include_dirs.\" % (build_dir))",
        "log.info(\" adding '%s' to"
    ],
    [
        "if newer(source_c, target_c) or newer(source_h, target_h):",
        "if newer(source_c, target_c) or newer(source_h,"
    ],
    [
        "filename = os.path.join(target_dir, ext_name + name_ext)",
        "filename = os.path.join(target_dir, ext_name"
    ],
    [
        "log.info(\"  adding '%s' to sources.\" % (filename))",
        "log.info(\" adding '%s' to sources.\" %"
    ],
    [
        "'mismatch of extension names: %s provides %r'",
        "'mismatch of extension names: %s provides"
    ],
    [
        "log.warn('source %r does not define swig target, assuming %s swig target' \\",
        "log.warn('source %r does not define swig"
    ],
    [
        "log.warn('expected %r but source %r defines %r swig target' \\",
        "log.warn('expected %r but source %r defines %r"
    ],
    [
        "log.warn('resetting swig target to c++ (some targets may have .c extension)')",
        "log.warn('resetting swig target to c++ (some targets may"
    ],
    [
        "log.warn('assuming that %r has c++ swig target' % (source))",
        "log.warn('assuming that %r has c++"
    ],
    [
        "log.warn('  source %s does not exist: skipping swig\\'ing.' \\",
        "log.warn(' source %s does not exist: skipping"
    ],
    [
        "log.warn('  target %s does not exist:\\n   '\\",
        "log.warn(' target %s does not"
    ],
    [
        "'Assuming %s_wrap.{c,cpp} was generated with '\\",
        "'Assuming %s_wrap.{c,cpp} was generated with"
    ],
    [
        "log.warn('   Yes! Using %r as up-to-date target.' \\",
        "log.warn(' Yes! Using %r as up-to-date"
    ],
    [
        "swig_cmd = [swig, \"-python\"] + extension.swig_opts",
        "swig_cmd = [swig, \"-python\"]"
    ],
    [
        "if self.force or newer_group(depends, target, 'newer'):",
        "if self.force or newer_group(depends,"
    ],
    [
        "+ (is_cpp and '++' or ''), source))",
        "+ (is_cpp and '++'"
    ],
    [
        "+ [\"-o\", target, '-outdir', py_target_dir, source])",
        "+ [\"-o\", target, '-outdir', py_target_dir,"
    ],
    [
        "log.debug(\"  skipping '%s' swig interface (up-to-date)\" \\",
        "log.debug(\" skipping '%s' swig interface"
    ],
    [
        "target = os.path.join(target_dir, '%s_wrap%s' % (name, ext))",
        "target = os.path.join(target_dir, '%s_wrap%s' %"
    ],
    [
        "Package containing implementation of all the standard Distutils",
        "Package containing implementation of all"
    ],
    [
        "from setuptools.command.sdist import sdist as old_sdist",
        "from setuptools.command.sdist import sdist"
    ],
    [
        "from distutils.command.sdist import sdist as old_sdist",
        "from distutils.command.sdist import"
    ],
    [
        "\"\"\" Modified version of build_scripts that handles building scripts from functions.",
        "\"\"\" Modified version of build_scripts that handles building"
    ],
    [
        "from distutils.command.build_scripts import build_scripts as old_build_scripts",
        "from distutils.command.build_scripts import build_scripts as"
    ],
    [
        "log.info(\"  adding '%s' to scripts\" % (script,))",
        "log.info(\" adding '%s' to scripts\" %"
    ],
    [
        "[log.info(\"  adding '%s' to scripts\" % (s,)) for s in script]",
        "[log.info(\" adding '%s' to scripts\" % (s,)) for s"
    ],
    [
        "from setuptools.command.bdist_rpm import bdist_rpm as old_bdist_rpm",
        "from setuptools.command.bdist_rpm import"
    ],
    [
        "from distutils.command.bdist_rpm import bdist_rpm as old_bdist_rpm",
        "from distutils.command.bdist_rpm import bdist_rpm as"
    ],
    [
        "description = \"Command to install installable C libraries\"",
        "description = \"Command to install"
    ],
    [
        "\"\"\" Modified version of build_clib that handles fortran source files.",
        "\"\"\" Modified version of build_clib that handles fortran source"
    ],
    [
        "from distutils.command.build_clib import build_clib as old_build_clib",
        "from distutils.command.build_clib import build_clib"
    ],
    [
        "from distutils.errors import DistutilsSetupError, DistutilsError, \\",
        "from distutils.errors import DistutilsSetupError, DistutilsError,"
    ],
    [
        "description = \"build C/C++/F libraries used by Python extensions\"",
        "description = \"build C/C++/F libraries"
    ],
    [
        "\"turn all warnings into errors (-Werror)\"),",
        "\"turn all warnings into errors"
    ],
    [
        "\"specify a list of enabled baseline CPU optimizations\"),",
        "\"specify a list of enabled"
    ],
    [
        "\"specify a list of dispatched CPU optimizations\"),",
        "\"specify a list of"
    ],
    [
        "raise ValueError(\"--parallel/-j argument must be an integer\") from e",
        "raise ValueError(\"--parallel/-j argument must be"
    ],
    [
        "if l and l not in languages:",
        "if l and l not in"
    ],
    [
        "dispatch_hpath = os.path.join(\"numpy\", \"distutils\", \"include\", \"npy_cpu_dispatch_config.h\")",
        "dispatch_hpath = os.path.join(\"numpy\", \"distutils\", \"include\","
    ],
    [
        "\"\"\" Assemble flags from flag list",
        "\"\"\" Assemble flags from flag"
    ],
    [
        "None corresponds to empty list.  Sequence elements can be strings",
        "None corresponds to empty list. Sequence elements can be"
    ],
    [
        "or callables that return lists of strings. Callable takes `self` as",
        "or callables that return lists of strings. Callable"
    ],
    [
        "if sources is None or not is_sequence(sources):",
        "if sources is None or"
    ],
    [
        "raise DistutilsSetupError((\"in 'libraries' option (library '%s'), \"",
        "raise DistutilsSetupError((\"in 'libraries' option (library '%s'),"
    ],
    [
        "\"'sources' must be present and must be \"",
        "\"'sources' must be present"
    ],
    [
        "\"a list of source filenames\") % lib_name)",
        "\"a list of source filenames\") %"
    ],
    [
        "depends = sources + build_info.get('depends', [])",
        "depends = sources"
    ],
    [
        "if not self.disable_optimization and not self.compiler_opt.is_cached():",
        "if not self.disable_optimization and not"
    ],
    [
        "if not (force_rebuild or newer_group(depends, lib_file, 'newer')):",
        "if not (force_rebuild or"
    ],
    [
        "if fcompiler is not None and config_fc:",
        "if fcompiler is not"
    ],
    [
        "log.info('using additional config_fc from setup script '",
        "log.info('using additional config_fc from"
    ],
    [
        "if (f_sources or fmodule_sources) and fcompiler is None:",
        "if (f_sources or fmodule_sources) and fcompiler is"
    ],
    [
        "raise DistutilsError(\"library %s has Fortran sources\"",
        "raise DistutilsError(\"library %s"
    ],
    [
        "\" but no Fortran compiler found\" % (lib_name))",
        "\" but no Fortran compiler found\""
    ],
    [
        "for _srcs, _dst, _ext in (",
        "for _srcs, _dst, _ext"
    ],
    [
        "for s in _src[:] if s.endswith(_ext)",
        "for s in _src[:] if"
    ],
    [
        "log.warn('failed to move %r to %r'",
        "log.warn('failed to move"
    ],
    [
        "\"\"\"This module implements additional tests ala autoconf which can be useful.",
        "\"\"\"This module implements additional tests ala"
    ],
    [
        "\"\"\"Return the inline identifier (may be empty).\"\"\"",
        "\"\"\"Return the inline identifier"
    ],
    [
        "for kw in ['inline', '__inline__', '__inline']:",
        "for kw in ['inline',"
    ],
    [
        "st = cmd.try_compile(body % {'inline': kw}, None, None)",
        "st = cmd.try_compile(body % {'inline': kw}, None,"
    ],
    [
        "\"\"\"Return the restrict identifier (may be empty).\"\"\"",
        "\"\"\"Return the restrict identifier (may be"
    ],
    [
        "static int static_func (char * %(restrict)s a)",
        "static int static_func (char"
    ],
    [
        "for kw in ['restrict', '__restrict__', '__restrict']:",
        "for kw in ['restrict', '__restrict__',"
    ],
    [
        "st = cmd.try_compile(body % {'restrict': kw}, None, None)",
        "st = cmd.try_compile(body % {'restrict': kw},"
    ],
    [
        "\"\"\"Check if the compiler is GCC.\"\"\"",
        "\"\"\"Check if the"
    ],
    [
        "Check that the gcc version is at least the specified version.\"\"\"",
        "Check that the gcc version is at least the"
    ],
    [
        "kw = {'version': version, 'major': major, 'minor': minor,",
        "kw = {'version': version,"
    ],
    [
        "return cmd.try_compile(body % kw, None, None)",
        "return cmd.try_compile(body % kw,"
    ],
    [
        "\"\"\"Return True if the given function attribute is supported.\"\"\"",
        "\"\"\"Return True if the given"
    ],
    [
        "\"\"\"Return True if the given function attribute is supported with",
        "\"\"\"Return True if the given function attribute is supported"
    ],
    [
        "\"\"\") % (include, attribute, name, code)",
        "\"\"\") % (include, attribute,"
    ],
    [
        "\"\"\"Return True if the given variable attribute is supported.\"\"\"",
        "\"\"\"Return True if the given variable attribute"
    ],
    [
        "from setuptools.command.egg_info import egg_info as _egg_info",
        "from setuptools.command.egg_info import egg_info"
    ],
    [
        "`build_src` is being run, this may lead to missing",
        "`build_src` is being run, this may lead"
    ],
    [
        "files in your sdist!  You want to use distutils.sdist",
        "files in your sdist! You"
    ],
    [
        "\"\"\" The setuptools version of the .run() method.",
        "\"\"\" The setuptools version"
    ],
    [
        "We must pull in the entire code so we can override the level used in the",
        "We must pull in the entire code so we can"
    ],
    [
        "_getframe() call since we wrap this call by one more level.",
        "_getframe() call since we wrap this call by one more"
    ],
    [
        "from distutils.command.install import install as distutils_install",
        "from distutils.command.install import"
    ],
    [
        "if caller_module != 'distutils.dist' or caller_name!='run_commands':",
        "if caller_module != 'distutils.dist'"
    ],
    [
        "\"re-writing list of installed files to '%s'\" %",
        "\"re-writing list of installed files"
    ],
    [
        "\"\"\" Override the develop command from setuptools so we can ensure that our",
        "\"\"\" Override the develop command from setuptools so"
    ],
    [
        "generated files (from build_src or build_scripts) are properly converted to real",
        "generated files (from build_src or build_scripts)"
    ],
    [
        "from setuptools.command.develop import develop as old_develop",
        "from setuptools.command.develop import"
    ],
    [
        "from distutils.command.install_data import install_data as old_install_data",
        "from distutils.command.install_data import install_data"
    ],
    [
        "The LooseVersion and StrictVersion classes that distutils provides don't",
        "The LooseVersion and StrictVersion classes that"
    ],
    [
        "work; they don't recognize anything like alpha/beta/rc/dev versions.",
        "work; they don't recognize anything"
    ],
    [
        "[\"epoch\", \"release\", \"dev\", \"pre\", \"post\", \"local\"],",
        "[\"epoch\", \"release\", \"dev\", \"pre\", \"post\","
    ],
    [
        "Parse the given version string and return either a :class:`Version` object",
        "Parse the given version string and return either"
    ],
    [
        "or a :class:`LegacyVersion` object depending on if the given version is",
        "or a :class:`LegacyVersion` object depending on if the given version"
    ],
    [
        "return self._compare(other, lambda s, o: s < o)",
        "return self._compare(other, lambda s,"
    ],
    [
        "return self._compare(other, lambda s, o: s <= o)",
        "return self._compare(other, lambda s, o:"
    ],
    [
        "return self._compare(other, lambda s, o: s == o)",
        "return self._compare(other, lambda s, o: s"
    ],
    [
        "return self._compare(other, lambda s, o: s >= o)",
        "return self._compare(other, lambda s, o: s >="
    ],
    [
        "return self._compare(other, lambda s, o: s > o)",
        "return self._compare(other, lambda s,"
    ],
    [
        "return self._compare(other, lambda s, o: s != o)",
        "return self._compare(other, lambda s, o: s !="
    ],
    [
        "r\"(\\d+ | [a-z]+ | \\.| -)\", re.VERBOSE,",
        "r\"(\\d+ | [a-z]+ | \\.|"
    ],
    [
        "\"pre\": \"c\", \"preview\": \"c\", \"-\": \"final-\", \"rc\": \"c\", \"dev\": \"@\",",
        "\"pre\": \"c\", \"preview\": \"c\", \"-\": \"final-\","
    ],
    [
        "if not part or part == \".\":",
        "if not part or part =="
    ],
    [
        "elif letter in [\"c\", \"pre\", \"preview\"]:",
        "elif letter in"
    ],
    [
        "part.lower() if not part.isdigit() else int(part)",
        "part.lower() if not part.isdigit()"
    ],
    [
        "def _cmpkey(epoch, release, pre, post, dev, local):",
        "def _cmpkey(epoch, release, pre, post, dev,"
    ],
    [
        "if pre is None and post is None and dev is not None:",
        "if pre is None and post is None and dev is not"
    ],
    [
        "(i, \"\") if isinstance(i, int) else (-Infinity, i)",
        "(i, \"\") if isinstance(i, int)"
    ],
    [
        "return epoch, release, pre, post, dev, local",
        "return epoch, release, pre, post,"
    ],
    [
        "This is a module for defining private helpers which do not depend on the",
        "This is a module for defining private"
    ],
    [
        "Everything in here must be self-contained so that it can be",
        "Everything in here must be self-contained"
    ],
    [
        "imported anywhere else without creating circular imports.",
        "imported anywhere else without creating circular"
    ],
    [
        "If a utility requires the import of NumPy, it probably belongs",
        "If a utility requires the import of"
    ],
    [
        "\"\"\"Private decorator for overriding __module__ on a function or class.",
        "\"\"\"Private decorator for overriding __module__ on a function"
    ],
    [
        "Generate decorator for backward-compatible keyword renaming.",
        "Generate decorator for backward-compatible"
    ],
    [
        "Apply the decorator generated by `_rename_parameter` to functions with a",
        "Apply the decorator generated by `_rename_parameter` to functions with"
    ],
    [
        "After decoration, the function behaves as follows:",
        "After decoration, the function behaves"
    ],
    [
        "If only the new parameter is passed into the function, behave as usual.",
        "If only the new parameter is passed"
    ],
    [
        "If only the old parameter is passed into the function (as a keyword), raise",
        "If only the old parameter is passed into the"
    ],
    [
        "a DeprecationWarning if `dep_version` is provided, and behave as usual",
        "a DeprecationWarning if `dep_version` is provided,"
    ],
    [
        "If both old and new parameters are passed into the function, raise a",
        "If both old and new parameters are passed into the"
    ],
    [
        "DeprecationWarning if `dep_version` is provided, and raise the appropriate",
        "DeprecationWarning if `dep_version` is provided, and"
    ],
    [
        "TypeError (function got multiple values for argument).",
        "TypeError (function got multiple values for"
    ],
    [
        "Version of NumPy in which old parameter was deprecated in the format",
        "Version of NumPy in which old parameter was deprecated"
    ],
    [
        "'X.Y.Z'. If supplied, the deprecation message will indicate that",
        "'X.Y.Z'. If supplied, the deprecation message will"
    ],
    [
        "Untested with functions that accept *args. Probably won't work as written.",
        "Untested with functions that accept *args."
    ],
    [
        "for old_name, new_name in zip(old_names, new_names):",
        "for old_name, new_name"
    ],
    [
        "msg = (f\"Use of keyword argument `{old_name}` is \"",
        "msg = (f\"Use of keyword argument `{old_name}` is"
    ],
    [
        "f\"deprecated and replaced by `{new_name}`. \"",
        "f\"deprecated and replaced by `{new_name}`."
    ],
    [
        "f\"Support for `{old_name}` will be removed \"",
        "f\"Support for `{old_name}` will"
    ],
    [
        "msg = (f\"{fun.__name__}() got multiple values for \"",
        "msg = (f\"{fun.__name__}() got multiple"
    ],
    [
        "A set of methods retained from np.compat module that",
        "A set of methods retained from"
    ],
    [
        "\"\"\"Subset of inspect module from upstream python",
        "\"\"\"Subset of inspect module"
    ],
    [
        "We use this instead of upstream because upstream inspect is slow to import, and",
        "We use this instead of upstream because upstream inspect is"
    ],
    [
        "significantly contributes to numpy import times. Importing this copy has almost",
        "significantly contributes to numpy import times. Importing this"
    ],
    [
        "\"\"\"Return true if the object is an instance method.",
        "\"\"\"Return true if the object is"
    ],
    [
        "Instance method objects provide these attributes:",
        "Instance method objects"
    ],
    [
        "__name__        name with which this method was defined",
        "__name__ name with which"
    ],
    [
        "im_class        class object in which this method belongs",
        "im_class class object in which this method"
    ],
    [
        "im_func         function object containing implementation of method",
        "im_func function object containing implementation"
    ],
    [
        "im_self         instance to which this method is bound, or None",
        "im_self instance to which this method"
    ],
    [
        "\"\"\"Return true if the object is a user-defined function.",
        "\"\"\"Return true if the object is a user-defined"
    ],
    [
        "__name__        name with which this function was defined",
        "__name__ name with which this function"
    ],
    [
        "func_code       code object containing compiled function bytecode",
        "func_code code object containing compiled function"
    ],
    [
        "func_defaults   tuple of any default values for arguments",
        "func_defaults tuple of any default values for"
    ],
    [
        "func_globals    global namespace in which this function was defined",
        "func_globals global namespace in which this"
    ],
    [
        "\"\"\"Return true if the object is a code object.",
        "\"\"\"Return true if the object is a code"
    ],
    [
        "co_argcount     number of arguments (not including * or ** args)",
        "co_argcount number of arguments (not including * or **"
    ],
    [
        "co_code         string of raw compiled bytecode",
        "co_code string of raw compiled"
    ],
    [
        "co_consts       tuple of constants used in the bytecode",
        "co_consts tuple of constants"
    ],
    [
        "co_filename     name of file in which this code object was created",
        "co_filename name of file in which"
    ],
    [
        "co_firstlineno  number of first line in Python source code",
        "co_firstlineno number of first line in Python"
    ],
    [
        "co_lnotab       encoded mapping of line numbers to bytecode indices",
        "co_lnotab encoded mapping of line"
    ],
    [
        "co_name         name with which this code object was defined",
        "co_name name with which this"
    ],
    [
        "co_names        tuple of names of local variables",
        "co_names tuple of names of"
    ],
    [
        "co_stacksize    virtual machine stack space required",
        "co_stacksize virtual machine stack space"
    ],
    [
        "co_varnames     tuple of names of arguments and local variables",
        "co_varnames tuple of names of"
    ],
    [
        "\"\"\"Get information about the arguments accepted by a code object.",
        "\"\"\"Get information about the arguments accepted by a"
    ],
    [
        "Three things are returned: (args, varargs, varkw), where 'args' is",
        "Three things are returned: (args, varargs, varkw), where 'args'"
    ],
    [
        "a list of argument names (possibly containing nested lists), and",
        "a list of argument names (possibly containing nested lists),"
    ],
    [
        "'varargs' and 'varkw' are the names of the * and ** arguments or None.",
        "'varargs' and 'varkw' are the names of the"
    ],
    [
        "raise TypeError('arg is not a code object')",
        "raise TypeError('arg is not a code"
    ],
    [
        "raise TypeError(\"tuple function arguments are not supported\")",
        "raise TypeError(\"tuple function arguments"
    ],
    [
        "\"\"\"Get the names and default values of a function's arguments.",
        "\"\"\"Get the names and default values"
    ],
    [
        "A tuple of four things is returned: (args, varargs, varkw, defaults).",
        "A tuple of four things is returned: (args,"
    ],
    [
        "'args' is a list of the argument names (it may contain nested lists).",
        "'args' is a list of the argument names"
    ],
    [
        "'varargs' and 'varkw' are the names of the * and ** arguments or None.",
        "'varargs' and 'varkw' are the names of the * and ** arguments"
    ],
    [
        "'defaults' is an n-tuple of the default values of the last n arguments.",
        "'defaults' is an n-tuple of the default values of the last n"
    ],
    [
        "raise TypeError('arg is not a Python function')",
        "raise TypeError('arg is not a"
    ],
    [
        "\"\"\"Get information about arguments passed into a particular frame.",
        "\"\"\"Get information about arguments passed into a"
    ],
    [
        "A tuple of four things is returned: (args, varargs, varkw, locals).",
        "A tuple of four things is returned: (args, varargs,"
    ],
    [
        "'args' is a list of the argument names (it may contain nested lists).",
        "'args' is a list of the argument names (it may contain nested"
    ],
    [
        "'varargs' and 'varkw' are the names of the * and ** arguments or None.",
        "'varargs' and 'varkw' are the names of"
    ],
    [
        "'locals' is the locals dictionary of the given frame.",
        "'locals' is the locals dictionary of"
    ],
    [
        "return '(' + ', '.join(seq) + ')'",
        "return '(' + ',"
    ],
    [
        "\"\"\"Recursively walk a sequence, stringifying each element.",
        "\"\"\"Recursively walk a sequence,"
    ],
    [
        "return join([strseq(_o, convert, join) for _o in object])",
        "return join([strseq(_o, convert, join) for"
    ],
    [
        "The first four arguments are (args, varargs, varkw, defaults).  The",
        "The first four arguments are (args, varargs, varkw, defaults)."
    ],
    [
        "other four arguments are the corresponding optional formatting functions",
        "other four arguments are the corresponding"
    ],
    [
        "that are called to turn names and values into strings.  The ninth",
        "that are called to turn names and values into strings."
    ],
    [
        "argument is an optional function to format the sequence of arguments.",
        "argument is an optional function to format"
    ],
    [
        "if defaults and i >= firstdefault:",
        "if defaults and"
    ],
    [
        "spec = spec + formatvalue(defaults[i - firstdefault])",
        "spec = spec +"
    ],
    [
        "return '(' + ', '.join(specs) + ')'",
        "return '(' + ', '.join(specs)"
    ],
    [
        "The first four arguments are (args, varargs, varkw, locals).  The",
        "The first four arguments are (args, varargs, varkw, locals)."
    ],
    [
        "next four arguments are the corresponding optional formatting functions",
        "next four arguments are the"
    ],
    [
        "that are called to turn names and values into strings.  The ninth",
        "that are called to turn names"
    ],
    [
        "argument is an optional function to format the sequence of arguments.",
        "argument is an optional function to format the sequence"
    ],
    [
        "specs = [strseq(arg, convert, join) for arg in args]",
        "specs = [strseq(arg, convert, join) for"
    ],
    [
        "return '(' + ', '.join(specs) + ')'",
        "return '(' + ', '.join(specs)"
    ],
    [
        "it is now used to create a compatibility layer between different",
        "it is now used to create a compatibility"
    ],
    [
        "While the active version of numpy may not support a given version of python, we",
        "While the active version of numpy may not"
    ],
    [
        "allow downstream libraries to continue to use these shims for forward",
        "allow downstream libraries to continue to use"
    ],
    [
        "compatibility with numpy while they transition their code to newer versions of",
        "compatibility with numpy while they transition their code to"
    ],
    [
        "__all__ = ['bytes', 'asbytes', 'isfileobj', 'getexception', 'strchar',",
        "__all__ = ['bytes', 'asbytes',"
    ],
    [
        "if not isinstance(f, (io.FileIO, io.BufferedReader, io.BufferedWriter)):",
        "if not isinstance(f, (io.FileIO,"
    ],
    [
        "if hasattr(x, '__iter__') and not isinstance(x, (bytes, unicode)):",
        "if hasattr(x, '__iter__') and not isinstance(x,"
    ],
    [
        "return [asbytes_nested(y) for y in x]",
        "return [asbytes_nested(y) for"
    ],
    [
        "if hasattr(x, '__iter__') and not isinstance(x, (bytes, unicode)):",
        "if hasattr(x, '__iter__') and not"
    ],
    [
        "return [asunicode_nested(y) for y in x]",
        "return [asunicode_nested(y) for y"
    ],
    [
        "Check whether obj is a `pathlib.Path` object.",
        "Check whether obj is a"
    ],
    [
        "Prefer using ``isinstance(obj, os.PathLike)`` instead of this function.",
        "Prefer using ``isinstance(obj, os.PathLike)`` instead of"
    ],
    [
        "\"\"\"Context manager that does no additional processing.",
        "\"\"\"Context manager that does no"
    ],
    [
        "Used as a stand-in for a normal context manager, when a particular",
        "Used as a stand-in for a normal context manager, when"
    ],
    [
        "block of code is only sometimes used with a normal context manager:",
        "block of code is only sometimes used"
    ],
    [
        "cm = optional_cm if condition else nullcontext()",
        "cm = optional_cm if"
    ],
    [
        "Prefer using `contextlib.nullcontext` instead of this context manager.",
        "Prefer using `contextlib.nullcontext` instead of this"
    ],
    [
        "Load a module. Uses ``load_module`` which will be deprecated in python",
        "Load a module. Uses ``load_module`` which"
    ],
    [
        "extensions, which may be included for the following reasons:",
        "extensions, which may be included for the following"
    ],
    [
        "* we may only need a small subset of the copied library/module",
        "* we may only need a small subset of the copied"
    ],
    [
        "f\"module 'numpy.core.umath' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.umath' has no attribute"
    ],
    [
        "f\"module 'numpy.core.fromnumeric' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.fromnumeric' has"
    ],
    [
        "f\"module 'numpy.core._dtype' has no attribute {attr_name}\")",
        "f\"module 'numpy.core._dtype' has"
    ],
    [
        "f\"module 'numpy.core._internal' has no attribute {attr_name}\")",
        "f\"module 'numpy.core._internal' has no"
    ],
    [
        "f\"module 'numpy.core.multiarray' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.multiarray' has no attribute"
    ],
    [
        "f\"module 'numpy.core.records' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.records' has no attribute"
    ],
    [
        "The `numpy.core` submodule exists solely for backward compatibility",
        "The `numpy.core` submodule exists solely for backward"
    ],
    [
        "purposes. The original `core` was renamed to `_core` and made private.",
        "purposes. The original `core` was renamed to"
    ],
    [
        "`numpy.core` will be removed in the future.",
        "`numpy.core` will be removed"
    ],
    [
        "__all__ = [\"arrayprint\", \"defchararray\", \"_dtype_ctypes\", \"_dtype\",",
        "__all__ = [\"arrayprint\", \"defchararray\", \"_dtype_ctypes\","
    ],
    [
        "f\"module 'numpy.core.overrides' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.overrides' has"
    ],
    [
        "f\"module 'numpy.core.getlimits' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.getlimits' has"
    ],
    [
        "f\"module 'numpy.core._dtype_ctypes' has no attribute {attr_name}\")",
        "f\"module 'numpy.core._dtype_ctypes' has no"
    ],
    [
        "f\"module 'numpy.core.defchararray' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.defchararray' has no"
    ],
    [
        "f\"module 'numpy.core.shape_base' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.shape_base' has"
    ],
    [
        "f\"module 'numpy.core.numeric' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.numeric' has no attribute"
    ],
    [
        "f\"module 'numpy.core.function_base' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.function_base' has no"
    ],
    [
        "f\"module 'numpy.core.einsumfunc' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.einsumfunc' has"
    ],
    [
        "f\"module 'numpy.core.numerictypes' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.numerictypes' has no attribute"
    ],
    [
        "def _raise_warning(attr: str, submodule: str | None = None) -> None:",
        "def _raise_warning(attr: str, submodule: str |"
    ],
    [
        "f\"{old_module} is deprecated and has been renamed to {new_module}. \"",
        "f\"{old_module} is deprecated and has"
    ],
    [
        "\"The numpy._core namespace contains private NumPy internals and its \"",
        "\"The numpy._core namespace contains private NumPy internals"
    ],
    [
        "\"use is discouraged, as NumPy internals can change without warning in \"",
        "\"use is discouraged, as NumPy internals can change"
    ],
    [
        "\"any release. In practice, most real-world usage of numpy.core is to \"",
        "\"any release. In practice, most real-world usage of numpy.core is"
    ],
    [
        "\"access functionality in the public NumPy API. If that is the case, \"",
        "\"access functionality in the public NumPy API. If"
    ],
    [
        "\"use the public NumPy API. If not, you are using NumPy internals. \"",
        "\"use the public NumPy API. If not,"
    ],
    [
        "\"If you would still like to access an internal attribute, \"",
        "\"If you would still like to"
    ],
    [
        "f\"module 'numpy.core.arrayprint' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.arrayprint' has no attribute"
    ],
    [
        "If you are a user of the module, the easiest solution will be to",
        "If you are a user of the module, the easiest solution will be"
    ],
    [
        "tb_msg = \"Traceback (most recent call last):\"",
        "tb_msg = \"Traceback (most"
    ],
    [
        "\"module 'numpy.core._multiarray_umath' has no attribute \"",
        "\"module 'numpy.core._multiarray_umath' has"
    ],
    [
        "The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient",
        "The NumPy linear algebra functions rely on"
    ],
    [
        "low level implementations of standard linear algebra algorithms. Those",
        "low level implementations of standard"
    ],
    [
        "libraries may be provided by NumPy itself using C versions of a subset of their",
        "libraries may be provided by NumPy itself using C versions of a"
    ],
    [
        "reference implementations but, when possible, highly optimized libraries that",
        "reference implementations but, when possible, highly optimized libraries"
    ],
    [
        "take advantage of specialized processor functionality are preferred. Examples",
        "take advantage of specialized processor functionality are preferred."
    ],
    [
        "of such libraries are OpenBLAS, MKL (TM), and ATLAS. Because those libraries",
        "of such libraries are OpenBLAS, MKL (TM), and ATLAS. Because those"
    ],
    [
        "are multithreaded and processor dependent, environmental variables and external",
        "are multithreaded and processor dependent, environmental variables and"
    ],
    [
        "packages such as threadpoolctl may be needed to control the number of threads",
        "packages such as threadpoolctl may be needed to control"
    ],
    [
        "Please note that the most-used linear algebra functions in NumPy are present in",
        "Please note that the most-used linear algebra functions in NumPy are"
    ],
    [
        "the main ``numpy`` namespace rather than in ``numpy.linalg``.  There are:",
        "the main ``numpy`` namespace rather than in ``numpy.linalg``."
    ],
    [
        "``dot``, ``vdot``, ``inner``, ``outer``, ``matmul``, ``tensordot``, ``einsum``,",
        "``dot``, ``vdot``, ``inner``, ``outer``, ``matmul``,"
    ],
    [
        "Functions present in numpy.linalg are listed below.",
        "Functions present in numpy.linalg are"
    ],
    [
        "This module is a lite version of the linalg.py module in SciPy which",
        "This module is a lite version of the linalg.py module"
    ],
    [
        "contains high-level Python interface to the LAPACK library.  The lite",
        "contains high-level Python interface to the LAPACK"
    ],
    [
        "version only accesses the following LAPACK functions: dgesv, zgesv,",
        "version only accesses the following"
    ],
    [
        "dgeev, zgeev, dgesdd, zgesdd, dgelsd, zgelsd, dsyevd, zheevd, dgetrf,",
        "dgeev, zgeev, dgesdd, zgesdd, dgelsd, zgelsd, dsyevd,"
    ],
    [
        "zgetrf, dpotrf, zpotrf, dgeqrf, zgeqrf, zungqr, dorgqr.",
        "zgetrf, dpotrf, zpotrf, dgeqrf, zgeqrf, zungqr,"
    ],
    [
        "__all__ = ['matrix_power', 'solve', 'tensorsolve', 'tensorinv', 'inv',",
        "__all__ = ['matrix_power', 'solve', 'tensorsolve',"
    ],
    [
        "'cholesky', 'eigvals', 'eigvalsh', 'pinv', 'slogdet', 'det',",
        "'cholesky', 'eigvals', 'eigvalsh',"
    ],
    [
        "'svd', 'svdvals', 'eig', 'eigh', 'lstsq', 'norm', 'qr', 'cond',",
        "'svd', 'svdvals', 'eig', 'eigh',"
    ],
    [
        "array, asarray, zeros, empty, empty_like, intc, single, double,",
        "array, asarray, zeros, empty, empty_like, intc,"
    ],
    [
        "csingle, cdouble, inexact, complexfloating, newaxis, all, inf, dot,",
        "csingle, cdouble, inexact, complexfloating, newaxis, all, inf,"
    ],
    [
        "add, multiply, sqrt, sum, isfinite, finfo, errstate, moveaxis, amin,",
        "add, multiply, sqrt, sum, isfinite, finfo,"
    ],
    [
        "swapaxes, divide, count_nonzero, isnan, sign, argsort, sort,",
        "swapaxes, divide, count_nonzero, isnan, sign, argsort,"
    ],
    [
        "reciprocal, overrides, diagonal as _core_diagonal, trace as _core_trace,",
        "reciprocal, overrides, diagonal as _core_diagonal,"
    ],
    [
        "cross as _core_cross, outer as _core_outer, tensordot as _core_tensordot,",
        "cross as _core_cross, outer as _core_outer, tensordot"
    ],
    [
        "matmul as _core_matmul, matrix_transpose as _core_matrix_transpose,",
        "matmul as _core_matmul,"
    ],
    [
        "transpose as _core_transpose, vecdot as _core_vecdot,",
        "transpose as _core_transpose, vecdot"
    ],
    [
        "Generic Python-exception-derived object raised by linalg functions.",
        "Generic Python-exception-derived object raised by"
    ],
    [
        "General purpose exception class, derived from Python's ValueError",
        "General purpose exception class, derived from Python's"
    ],
    [
        "class, programmatically raised in linalg functions when a Linear",
        "class, programmatically raised in linalg"
    ],
    [
        "Algebra-related condition would prevent further correct execution of the",
        "Algebra-related condition would prevent further correct execution of"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import"
    ],
    [
        "raise LinAlgError(\"Matrix is not positive definite\")",
        "raise LinAlgError(\"Matrix is"
    ],
    [
        "raise LinAlgError(\"SVD did not converge in Linear Least Squares\")",
        "raise LinAlgError(\"SVD did not converge in Linear Least"
    ],
    [
        "raise LinAlgError(\"Incorrect argument found while performing \"",
        "raise LinAlgError(\"Incorrect argument found while performing"
    ],
    [
        "raise TypeError(\"array type %s is unsupported in linalg\" %",
        "raise TypeError(\"array type %s is unsupported"
    ],
    [
        "if arr.dtype.byteorder not in ('=', '|'):",
        "if arr.dtype.byteorder not"
    ],
    [
        "raise LinAlgError('%d-dimensional array given. Array must be '",
        "raise LinAlgError('%d-dimensional array given. Array must"
    ],
    [
        "raise LinAlgError('%d-dimensional array given. Array must be '",
        "raise LinAlgError('%d-dimensional array given. Array must"
    ],
    [
        "raise LinAlgError(\"Array must not contain infs or NaNs\")",
        "raise LinAlgError(\"Array must not contain infs"
    ],
    [
        "Transpose each matrix in a stack of matrices.",
        "Transpose each matrix in a"
    ],
    [
        "Unlike np.transpose, this only swaps the last two axes, rather than all of",
        "Unlike np.transpose, this only swaps the last two axes, rather"
    ],
    [
        "Solve the tensor equation ``a x = b`` for x.",
        "Solve the tensor equation ``a x"
    ],
    [
        "It is assumed that all indices of `x` are summed over in the product,",
        "It is assumed that all indices of `x` are summed over in the"
    ],
    [
        "together with the rightmost indices of `a`, as is done in, for example,",
        "together with the rightmost indices of `a`, as is done in, for"
    ],
    [
        "Coefficient tensor, of shape ``b.shape + Q``. `Q`, a tuple, equals",
        "Coefficient tensor, of shape ``b.shape + Q``. `Q`, a"
    ],
    [
        "the shape of that sub-tensor of `a` consisting of the appropriate",
        "the shape of that sub-tensor of `a`"
    ],
    [
        "number of its rightmost indices, and must be such that",
        "number of its rightmost indices, and must"
    ],
    [
        "``prod(Q) == prod(b.shape)`` (in which sense `a` is said to be",
        "``prod(Q) == prod(b.shape)`` (in which sense `a`"
    ],
    [
        "Right-hand tensor, which can be of any shape.",
        "Right-hand tensor, which can be of"
    ],
    [
        "axes : tuple of ints, optional",
        "axes : tuple"
    ],
    [
        "Axes in `a` to reorder to the right, before inversion.",
        "Axes in `a` to reorder to the right, before"
    ],
    [
        "If None (default), no reordering is done.",
        "If None (default), no reordering is"
    ],
    [
        "If `a` is singular or not 'square' (in the above sense).",
        "If `a` is singular or not 'square' (in the"
    ],
    [
        "\"Input arrays must satisfy the requirement \\",
        "\"Input arrays must satisfy the requirement"
    ],
    [
        "Solve a linear matrix equation, or system of linear scalar equations.",
        "Solve a linear matrix equation, or system of linear"
    ],
    [
        "Computes the \"exact\" solution, `x`, of the well-determined, i.e., full",
        "Computes the \"exact\" solution, `x`, of"
    ],
    [
        "rank, linear matrix equation `ax = b`.",
        "rank, linear matrix equation `ax"
    ],
    [
        "a : (..., M, M) array_like",
        "a : (...,"
    ],
    [
        "b : {(M,), (..., M, K)}, array_like",
        "b : {(M,), (...,"
    ],
    [
        "x : {(..., M,), (..., M, K)} ndarray",
        "x : {(..., M,), (...,"
    ],
    [
        "Solution to the system a x = b.  Returned shape is (..., M) if b is",
        "Solution to the system a x = b. Returned shape is (..., M)"
    ],
    [
        "shape (M,) and (..., M, K) if b is (..., M, K), where the \"...\" part is",
        "shape (M,) and (..., M, K) if b is"
    ],
    [
        "If `a` is singular or not square.",
        "If `a` is singular or not"
    ],
    [
        "scipy.linalg.solve : Similar function in SciPy.",
        "scipy.linalg.solve : Similar function"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see the"
    ],
    [
        "The solutions are computed using LAPACK routine ``_gesv``.",
        "The solutions are computed using"
    ],
    [
        "`a` must be square and of full-rank, i.e., all rows (or, equivalently,",
        "`a` must be square and of full-rank, i.e., all"
    ],
    [
        "columns) must be linearly independent; if either is not true, use",
        "columns) must be linearly independent; if either is not true,"
    ],
    [
        "`lstsq` for the least-squares best \"solution\" of the",
        "`lstsq` for the least-squares best \"solution\""
    ],
    [
        "The b array is only treated as a shape (M,) column vector if it is",
        "The b array is only treated as a"
    ],
    [
        "of (M, K) matrices. Previously b would be treated as a stack of (M,)",
        "of (M, K) matrices. Previously b would be treated as a"
    ],
    [
        "Check that the solution is correct:",
        "Check that the solution is"
    ],
    [
        "signature = 'DD->D' if isComplexType(t) else 'dd->d'",
        "signature = 'DD->D' if"
    ],
    [
        "Compute the 'inverse' of an N-dimensional array.",
        "Compute the 'inverse' of an N-dimensional"
    ],
    [
        "The result is an inverse for `a` relative to the tensordot operation",
        "The result is an inverse for `a` relative"
    ],
    [
        "``tensordot(a, b, ind)``, i. e., up to floating-point accuracy,",
        "``tensordot(a, b, ind)``, i. e., up to floating-point"
    ],
    [
        "``tensordot(tensorinv(a), a, ind)`` is the \"identity\" tensor for the",
        "``tensordot(tensorinv(a), a, ind)`` is the \"identity\" tensor for"
    ],
    [
        "Tensor to 'invert'. Its shape must be 'square', i. e.,",
        "Tensor to 'invert'. Its shape must be 'square',"
    ],
    [
        "Number of first indices that are involved in the inverse sum.",
        "Number of first indices that are"
    ],
    [
        "`a`'s tensordot inverse, shape ``a.shape[ind:] + a.shape[:ind]``.",
        "`a`'s tensordot inverse, shape ``a.shape[ind:]"
    ],
    [
        "If `a` is singular or not 'square' (in the above sense).",
        "If `a` is singular or not 'square' (in the above"
    ],
    [
        "Compute the inverse of a matrix.",
        "Compute the inverse of a"
    ],
    [
        "Given a square matrix `a`, return the matrix `ainv` satisfying",
        "Given a square matrix `a`, return"
    ],
    [
        "a : (..., M, M) array_like",
        "a : (..., M, M)"
    ],
    [
        "ainv : (..., M, M) ndarray or matrix",
        "ainv : (..., M, M) ndarray or"
    ],
    [
        "If `a` is not square or inversion fails.",
        "If `a` is not square or"
    ],
    [
        "scipy.linalg.inv : Similar function in SciPy.",
        "scipy.linalg.inv : Similar"
    ],
    [
        "numpy.linalg.cond : Compute the condition number of a matrix.",
        "numpy.linalg.cond : Compute the condition"
    ],
    [
        "numpy.linalg.svd : Compute the singular value decomposition of a matrix.",
        "numpy.linalg.svd : Compute the singular value decomposition"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see the `numpy.linalg`"
    ],
    [
        "If `a` is detected to be singular, a `LinAlgError` is raised. If `a` is",
        "If `a` is detected to be singular, a `LinAlgError`"
    ],
    [
        "ill-conditioned, a `LinAlgError` may or may not be raised, and results may",
        "ill-conditioned, a `LinAlgError` may or may"
    ],
    [
        "be inaccurate due to floating-point errors.",
        "be inaccurate due"
    ],
    [
        "If a is a matrix object, then the return value is a matrix as well:",
        "If a is a matrix object, then the return value is a matrix as"
    ],
    [
        "Inverses of several matrices can be computed at once:",
        "Inverses of several matrices can be"
    ],
    [
        "If a matrix is close to singular, the computed inverse may not satisfy",
        "If a matrix is close to singular, the computed"
    ],
    [
        "To detect ill-conditioned matrices, you can use `numpy.linalg.cond` to",
        "To detect ill-conditioned matrices, you can use `numpy.linalg.cond`"
    ],
    [
        "more ill-conditioned the matrix is. As a rule of thumb, if the condition",
        "more ill-conditioned the matrix is. As a rule of thumb,"
    ],
    [
        "accuracy on top of what would be lost to the numerical method due to loss",
        "accuracy on top of what would be lost to the numerical method due to"
    ],
    [
        "It is also possible to detect ill-conditioning by inspecting the matrix's",
        "It is also possible to detect ill-conditioning by inspecting the"
    ],
    [
        "singular values directly. The ratio between the largest and the smallest",
        "singular values directly. The ratio between the largest and the"
    ],
    [
        "singular value is the condition number:",
        "singular value is the"
    ],
    [
        "signature = 'D->D' if isComplexType(t) else 'd->d'",
        "signature = 'D->D' if isComplexType(t)"
    ],
    [
        "Raise a square matrix to the (integer) power `n`.",
        "Raise a square matrix to the (integer) power"
    ],
    [
        "For positive integers `n`, the power is computed by repeated matrix",
        "For positive integers `n`, the power is computed"
    ],
    [
        "is computed and then raised to the ``abs(n)``.",
        "is computed and then"
    ],
    [
        ".. note:: Stacks of object matrices are not currently supported.",
        ".. note:: Stacks of object"
    ],
    [
        "a : (..., M, M) array_like",
        "a : (...,"
    ],
    [
        "The exponent can be any integer or long integer, positive,",
        "The exponent can be any integer or"
    ],
    [
        "a**n : (..., M, M) ndarray or matrix object",
        "a**n : (..., M, M)"
    ],
    [
        "The return value is the same shape and type as `M`;",
        "The return value is the same shape"
    ],
    [
        "if the exponent is positive or zero then the type of the",
        "if the exponent is positive or zero"
    ],
    [
        "elements is the same as those of `M`. If the exponent is",
        "elements is the same as those of `M`. If the"
    ],
    [
        "For matrices that are not square or that (for negative powers) cannot",
        "For matrices that are not square or that (for negative powers)"
    ],
    [
        "raise TypeError(\"exponent must be an integer\") from e",
        "raise TypeError(\"exponent must be an integer\")"
    ],
    [
        "\"matrix_power not supported for stacks of object arrays\")",
        "\"matrix_power not supported for stacks of object"
    ],
    [
        "z = a if z is None else fmatmul(z, z)",
        "z = a if z is None"
    ],
    [
        "result = z if result is None else fmatmul(result, z)",
        "result = z if result is None"
    ],
    [
        "Return the lower or upper Cholesky decomposition, ``L * L.H`` or",
        "Return the lower or upper Cholesky decomposition, ``L * L.H``"
    ],
    [
        "``U.H * U``, of the square matrix ``a``, where ``L`` is lower-triangular,",
        "``U.H * U``, of the square matrix ``a``, where ``L``"
    ],
    [
        "``U`` is upper-triangular, and ``.H`` is the conjugate transpose operator",
        "``U`` is upper-triangular, and ``.H`` is the conjugate"
    ],
    [
        "(which is the ordinary transpose if ``a`` is real-valued). ``a`` must be",
        "(which is the ordinary transpose if ``a`` is real-valued). ``a``"
    ],
    [
        "Hermitian (symmetric if real-valued) and positive-definite. No checking is",
        "Hermitian (symmetric if real-valued) and positive-definite. No checking"
    ],
    [
        "performed to verify whether ``a`` is Hermitian or not. In addition, only",
        "performed to verify whether ``a`` is Hermitian or not. In addition,"
    ],
    [
        "the lower or upper-triangular and diagonal elements of ``a`` are used.",
        "the lower or upper-triangular and diagonal elements of ``a``"
    ],
    [
        "Only ``L`` or ``U`` is actually returned.",
        "Only ``L`` or ``U`` is actually"
    ],
    [
        "a : (..., M, M) array_like",
        "a : (..., M, M)"
    ],
    [
        "Hermitian (symmetric if all elements are real), positive-definite",
        "Hermitian (symmetric if all elements are real),"
    ],
    [
        "If ``True``, the result must be the upper-triangular Cholesky factor.",
        "If ``True``, the result must be"
    ],
    [
        "If ``False``, the result must be the lower-triangular Cholesky factor.",
        "If ``False``, the result must be the lower-triangular Cholesky"
    ],
    [
        "L : (..., M, M) array_like",
        "L : (...,"
    ],
    [
        "Lower or upper-triangular Cholesky factor of `a`. Returns a matrix",
        "Lower or upper-triangular Cholesky factor of `a`."
    ],
    [
        "object if `a` is a matrix object.",
        "object if `a` is a matrix"
    ],
    [
        "If the decomposition fails, for example, if `a` is not",
        "If the decomposition fails, for example,"
    ],
    [
        "scipy.linalg.cholesky : Similar function in SciPy.",
        "scipy.linalg.cholesky : Similar function"
    ],
    [
        "scipy.linalg.cholesky_banded : Cholesky decompose a banded Hermitian",
        "scipy.linalg.cholesky_banded : Cholesky decompose a"
    ],
    [
        "scipy.linalg.cho_factor : Cholesky decomposition of a matrix, to use in",
        "scipy.linalg.cho_factor : Cholesky decomposition of a"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see the `numpy.linalg` documentation"
    ],
    [
        "The Cholesky decomposition is often used as a fast way of solving",
        "The Cholesky decomposition is often used as a"
    ],
    [
        ".. math:: A \\\\mathbf{x} = \\\\mathbf{b}",
        ".. math:: A \\\\mathbf{x}"
    ],
    [
        "(when `A` is both Hermitian/symmetric and positive-definite).",
        "(when `A` is both Hermitian/symmetric"
    ],
    [
        "First, we solve for :math:`\\\\mathbf{y}` in",
        "First, we solve for :math:`\\\\mathbf{y}`"
    ],
    [
        ".. math:: L \\\\mathbf{y} = \\\\mathbf{b},",
        ".. math:: L"
    ],
    [
        ".. math:: L^{H} \\\\mathbf{x} = \\\\mathbf{y}.",
        ".. math:: L^{H}"
    ],
    [
        "gufunc = _umath_linalg.cholesky_up if upper else _umath_linalg.cholesky_lo",
        "gufunc = _umath_linalg.cholesky_up if upper"
    ],
    [
        "signature = 'D->D' if isComplexType(t) else 'd->d'",
        "signature = 'D->D' if isComplexType(t)"
    ],
    [
        "Compute the outer product of two vectors.",
        "Compute the outer product of"
    ],
    [
        "This function is Array API compatible. Compared to ``np.outer``",
        "This function is Array API"
    ],
    [
        "One-dimensional input array of size ``N``.",
        "One-dimensional input array of size"
    ],
    [
        "Must have a numeric data type.",
        "Must have a numeric data"
    ],
    [
        "One-dimensional input array of size ``M``.",
        "One-dimensional input array of size"
    ],
    [
        "Must have a numeric data type.",
        "Must have a numeric"
    ],
    [
        "``out[i, j] = a[i] * b[j]``",
        "``out[i, j] ="
    ],
    [
        "Make a (*very* coarse) grid for computing a Mandelbrot set:",
        "Make a (*very* coarse) grid for computing a Mandelbrot"
    ],
    [
        ">>> grid = rl + im",
        ">>> grid = rl +"
    ],
    [
        "An example using a \"vector\" of letters:",
        "An example using a \"vector\" of"
    ],
    [
        ">>> x = np.array(['a', 'b', 'c'], dtype=object)",
        ">>> x = np.array(['a',"
    ],
    [
        "\"Input arrays must be one-dimensional, but they are \"",
        "\"Input arrays must be one-dimensional, but"
    ],
    [
        "Compute the qr factorization of a matrix.",
        "Compute the qr factorization of"
    ],
    [
        "Factor the matrix `a` as *qr*, where `q` is orthonormal and `r` is",
        "Factor the matrix `a` as *qr*, where `q` is orthonormal and"
    ],
    [
        "a : array_like, shape (..., M, N)",
        "a : array_like, shape"
    ],
    [
        "mode : {'reduced', 'complete', 'r', 'raw'}, optional, default: 'reduced'",
        "mode : {'reduced', 'complete', 'r',"
    ],
    [
        "If K = min(M, N), then",
        "If K ="
    ],
    [
        "* 'reduced'  : returns Q, R with dimensions (..., M, K), (..., K, N)",
        "* 'reduced' : returns Q, R with dimensions (..., M, K),"
    ],
    [
        "* 'complete' : returns Q, R with dimensions (..., M, M), (..., M, N)",
        "* 'complete' : returns Q, R with"
    ],
    [
        "* 'r'        : returns R only with dimensions (..., K, N)",
        "* 'r' : returns R only with dimensions (..., K,"
    ],
    [
        "* 'raw'      : returns h, tau with dimensions (..., N, M), (..., K,)",
        "* 'raw' : returns h, tau with dimensions (..., N, M),"
    ],
    [
        "see the notes for more information. The default is 'reduced', and to",
        "see the notes for more information. The"
    ],
    [
        "maintain backward compatibility with earlier versions of numpy both",
        "maintain backward compatibility with earlier versions"
    ],
    [
        "it and the old default 'full' can be omitted. Note that array h",
        "it and the old default 'full' can"
    ],
    [
        "returned in 'raw' mode is transposed for calling Fortran. The",
        "returned in 'raw' mode is transposed for calling Fortran."
    ],
    [
        "'economic' mode is deprecated.  The modes 'full' and 'economic' may",
        "'economic' mode is deprecated. The modes 'full'"
    ],
    [
        "be passed using only the first letter for backwards compatibility,",
        "be passed using only the first"
    ],
    [
        "but all others must be spelled out. See the Notes for more",
        "but all others must be spelled"
    ],
    [
        "When mode is 'reduced' or 'complete', the result will be a namedtuple with",
        "When mode is 'reduced' or 'complete', the result"
    ],
    [
        "Q : ndarray of float or complex, optional",
        "Q : ndarray of float or complex,"
    ],
    [
        "A matrix with orthonormal columns. When mode = 'complete' the",
        "A matrix with orthonormal columns. When"
    ],
    [
        "result is an orthogonal/unitary matrix depending on whether or not",
        "result is an orthogonal/unitary matrix depending"
    ],
    [
        "case. In case the number of dimensions in the input array is",
        "case. In case the number of dimensions in the"
    ],
    [
        "R : ndarray of float or complex, optional",
        "R : ndarray of float"
    ],
    [
        "The upper-triangular matrix or a stack of upper-triangular",
        "The upper-triangular matrix or"
    ],
    [
        "matrices if the number of dimensions in the input array is greater",
        "matrices if the number of dimensions in"
    ],
    [
        "(h, tau) : ndarrays of np.double or np.cdouble, optional",
        "(h, tau) : ndarrays of np.double or np.cdouble,"
    ],
    [
        "The array h contains the Householder reflectors that generate q",
        "The array h contains the Householder reflectors"
    ],
    [
        "along with r. The tau array contains scaling factors for the",
        "along with r. The tau array contains scaling factors"
    ],
    [
        "reflectors. In the deprecated  'economic' mode only h is returned.",
        "reflectors. In the deprecated 'economic'"
    ],
    [
        "scipy.linalg.qr : Similar function in SciPy.",
        "scipy.linalg.qr : Similar function in"
    ],
    [
        "scipy.linalg.rq : Compute RQ decomposition of a matrix.",
        "scipy.linalg.rq : Compute RQ decomposition of"
    ],
    [
        "This is an interface to the LAPACK routines ``dgeqrf``, ``zgeqrf``,",
        "This is an interface to the"
    ],
    [
        "For more information on the qr factorization, see for example:",
        "For more information on the qr factorization, see for"
    ],
    [
        "Subclasses of `ndarray` are preserved except for the 'raw' mode. So if",
        "Subclasses of `ndarray` are preserved except"
    ],
    [
        "`a` is of type `matrix`, all the return values will be matrices too.",
        "`a` is of type `matrix`, all the return values will"
    ],
    [
        "New 'reduced', 'complete', and 'raw' options for mode were added in",
        "New 'reduced', 'complete', and 'raw' options for mode were added"
    ],
    [
        "addition the options 'full' and 'economic' were deprecated.  Because",
        "addition the options 'full' and 'economic' were"
    ],
    [
        "'full' was the previous default and 'reduced' is the new default,",
        "'full' was the previous default and 'reduced' is"
    ],
    [
        "backward compatibility can be maintained by letting `mode` default.",
        "backward compatibility can be maintained by letting"
    ],
    [
        "The 'raw' option was added so that LAPACK routines that can multiply",
        "The 'raw' option was added so that LAPACK routines that"
    ],
    [
        "arrays by q using the Householder reflectors can be used. Note that in",
        "arrays by q using the Householder reflectors can be used. Note that"
    ],
    [
        "this case the returned arrays are of type np.double or np.cdouble and",
        "this case the returned arrays are"
    ],
    [
        "the h array is transposed to be FORTRAN compatible.  No routines using",
        "the h array is transposed to"
    ],
    [
        "the 'raw' return are currently exposed by numpy, but some are available",
        "the 'raw' return are currently exposed by"
    ],
    [
        "in lapack_lite and just await the necessary work.",
        "in lapack_lite and just await the necessary"
    ],
    [
        "Example illustrating a common use of `qr`: solving of least squares",
        "Example illustrating a common use of `qr`:"
    ],
    [
        "by solving the over-determined matrix equation ``Ax = b``, where::",
        "by solving the over-determined matrix equation ``Ax ="
    ],
    [
        "If A = QR such that Q is orthonormal (which is always possible via",
        "If A = QR such that Q is orthonormal (which"
    ],
    [
        "Gram-Schmidt), then ``x = inv(R) * (Q.T) * b``.  (In numpy practice,",
        "Gram-Schmidt), then ``x = inv(R) * (Q.T) *"
    ],
    [
        "if mode not in ('reduced', 'complete', 'r', 'raw'):",
        "if mode not in ('reduced', 'complete',"
    ],
    [
        "\"The 'full' option is deprecated in favor of 'reduced'.\\n\"",
        "\"The 'full' option is deprecated"
    ],
    [
        "\"For backward compatibility let mode default.\"",
        "\"For backward compatibility let mode"
    ],
    [
        "msg = \"The 'economic' option is deprecated.\"",
        "msg = \"The 'economic' option"
    ],
    [
        "signature = 'D->D' if isComplexType(t) else 'd->d'",
        "signature = 'D->D' if"
    ],
    [
        "if mode == 'complete' and m > n:",
        "if mode == 'complete'"
    ],
    [
        "signature = 'DD->D' if isComplexType(t) else 'dd->d'",
        "signature = 'DD->D' if isComplexType(t)"
    ],
    [
        "Compute the eigenvalues of a general matrix.",
        "Compute the eigenvalues of a"
    ],
    [
        "Main difference between `eigvals` and `eig`: the eigenvectors aren't",
        "Main difference between `eigvals` and `eig`:"
    ],
    [
        "a : (..., M, M) array_like",
        "a : (..., M, M)"
    ],
    [
        "A complex- or real-valued matrix whose eigenvalues will be computed.",
        "A complex- or real-valued matrix whose eigenvalues will be"
    ],
    [
        "The eigenvalues, each repeated according to its multiplicity.",
        "The eigenvalues, each repeated"
    ],
    [
        "They are not necessarily ordered, nor are they necessarily",
        "They are not necessarily ordered, nor are"
    ],
    [
        "If the eigenvalue computation does not converge.",
        "If the eigenvalue computation does"
    ],
    [
        "eig : eigenvalues and right eigenvectors of general arrays",
        "eig : eigenvalues and right eigenvectors of general"
    ],
    [
        "eigvalsh : eigenvalues of real symmetric or complex Hermitian",
        "eigvalsh : eigenvalues of real symmetric or complex"
    ],
    [
        "eigh : eigenvalues and eigenvectors of real symmetric or complex",
        "eigh : eigenvalues and eigenvectors of real"
    ],
    [
        "scipy.linalg.eigvals : Similar function in SciPy.",
        "scipy.linalg.eigvals : Similar function in"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see the `numpy.linalg` documentation"
    ],
    [
        "This is implemented using the ``_geev`` LAPACK routines which compute",
        "This is implemented using the ``_geev``"
    ],
    [
        "the eigenvalues and eigenvectors of general square arrays.",
        "the eigenvalues and eigenvectors of"
    ],
    [
        "Illustration, using the fact that the eigenvalues of a diagonal matrix",
        "Illustration, using the fact that the eigenvalues of"
    ],
    [
        "are its diagonal elements, that multiplying a matrix on the left",
        "are its diagonal elements, that multiplying a matrix"
    ],
    [
        "by an orthogonal matrix, `Q`, and on the right by `Q.T` (the transpose",
        "by an orthogonal matrix, `Q`, and on the right by `Q.T` (the"
    ],
    [
        "of `Q`), preserves the eigenvalues of the \"middle\" matrix. In other words,",
        "of `Q`), preserves the eigenvalues of the"
    ],
    [
        "if `Q` is orthogonal, then ``Q * A * Q.T`` has the same eigenvalues as",
        "if `Q` is orthogonal, then ``Q * A"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import linalg"
    ],
    [
        ">>> Q = np.array([[np.cos(x), -np.sin(x)], [np.sin(x), np.cos(x)]])",
        ">>> Q = np.array([[np.cos(x), -np.sin(x)], [np.sin(x),"
    ],
    [
        "Now multiply a diagonal matrix by ``Q`` on one side and",
        "Now multiply a diagonal matrix by ``Q`` on one"
    ],
    [
        "signature = 'D->D' if isComplexType(t) else 'd->D'",
        "signature = 'D->D' if isComplexType(t) else"
    ],
    [
        "Compute the eigenvalues of a complex Hermitian or real symmetric matrix.",
        "Compute the eigenvalues of a complex"
    ],
    [
        "Main difference from eigh: the eigenvectors are not computed.",
        "Main difference from eigh: the eigenvectors are not"
    ],
    [
        "a : (..., M, M) array_like",
        "a : (..., M, M)"
    ],
    [
        "A complex- or real-valued matrix whose eigenvalues are to be",
        "A complex- or real-valued matrix whose eigenvalues are"
    ],
    [
        "Specifies whether the calculation is done with the lower triangular",
        "Specifies whether the calculation is done"
    ],
    [
        "part of `a` ('L', default) or the upper triangular part ('U').",
        "part of `a` ('L', default) or"
    ],
    [
        "Irrespective of this value only the real parts of the diagonal will",
        "Irrespective of this value only the real parts of the"
    ],
    [
        "be considered in the computation to preserve the notion of a Hermitian",
        "be considered in the computation to preserve"
    ],
    [
        "matrix. It therefore follows that the imaginary part of the diagonal",
        "matrix. It therefore follows that the imaginary part of the"
    ],
    [
        "will always be treated as zero.",
        "will always be treated"
    ],
    [
        "The eigenvalues in ascending order, each repeated according to",
        "The eigenvalues in ascending order, each repeated according"
    ],
    [
        "If the eigenvalue computation does not converge.",
        "If the eigenvalue computation does"
    ],
    [
        "eigh : eigenvalues and eigenvectors of real symmetric or complex Hermitian",
        "eigh : eigenvalues and eigenvectors of real symmetric or"
    ],
    [
        "eigvals : eigenvalues of general real or complex arrays.",
        "eigvals : eigenvalues of general real or"
    ],
    [
        "eig : eigenvalues and right eigenvectors of general real or complex",
        "eig : eigenvalues and right eigenvectors of general real"
    ],
    [
        "scipy.linalg.eigvalsh : Similar function in SciPy.",
        "scipy.linalg.eigvalsh : Similar function"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see the"
    ],
    [
        "The eigenvalues are computed using LAPACK routines ``_syevd``, ``_heevd``.",
        "The eigenvalues are computed using"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import"
    ],
    [
        "if UPLO not in ('L', 'U'):",
        "if UPLO not"
    ],
    [
        "raise ValueError(\"UPLO argument must be 'L' or 'U'\")",
        "raise ValueError(\"UPLO argument must be"
    ],
    [
        "signature = 'D->d' if isComplexType(t) else 'd->d'",
        "signature = 'D->d' if"
    ],
    [
        "Compute the eigenvalues and right eigenvectors of a square array.",
        "Compute the eigenvalues and right"
    ],
    [
        "a : (..., M, M) array",
        "a : (..., M, M)"
    ],
    [
        "Matrices for which the eigenvalues and right eigenvectors will",
        "Matrices for which the eigenvalues and"
    ],
    [
        "A namedtuple with the following attributes:",
        "A namedtuple with the"
    ],
    [
        "The eigenvalues, each repeated according to its multiplicity.",
        "The eigenvalues, each repeated according to its"
    ],
    [
        "The eigenvalues are not necessarily ordered. The resulting",
        "The eigenvalues are not necessarily"
    ],
    [
        "array will be of complex type, unless the imaginary part is",
        "array will be of complex type,"
    ],
    [
        "zero in which case it will be cast to a real type. When `a`",
        "zero in which case it will be cast to"
    ],
    [
        "part) or occur in conjugate pairs",
        "part) or occur in"
    ],
    [
        "eigenvectors : (..., M, M) array",
        "eigenvectors : (..., M,"
    ],
    [
        "The normalized (unit \"length\") eigenvectors, such that the",
        "The normalized (unit \"length\")"
    ],
    [
        "column ``eigenvectors[:,i]`` is the eigenvector corresponding to the",
        "column ``eigenvectors[:,i]`` is the eigenvector corresponding to"
    ],
    [
        "If the eigenvalue computation does not converge.",
        "If the eigenvalue computation does not"
    ],
    [
        "eigvals : eigenvalues of a non-symmetric array.",
        "eigvals : eigenvalues of"
    ],
    [
        "eigh : eigenvalues and eigenvectors of a real symmetric or complex",
        "eigh : eigenvalues and eigenvectors of a"
    ],
    [
        "eigvalsh : eigenvalues of a real symmetric or complex Hermitian",
        "eigvalsh : eigenvalues of a real symmetric"
    ],
    [
        "scipy.linalg.eig : Similar function in SciPy that also solves the",
        "scipy.linalg.eig : Similar function in SciPy that also"
    ],
    [
        "scipy.linalg.schur : Best choice for unitary and other non-Hermitian",
        "scipy.linalg.schur : Best choice for unitary and other"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see the `numpy.linalg`"
    ],
    [
        "This is implemented using the ``_geev`` LAPACK routines which compute",
        "This is implemented using the ``_geev``"
    ],
    [
        "the eigenvalues and eigenvectors of general square arrays.",
        "the eigenvalues and eigenvectors"
    ],
    [
        "The number `w` is an eigenvalue of `a` if there exists a vector `v` such",
        "The number `w` is an eigenvalue of `a` if there"
    ],
    [
        "that ``a @ v = w * v``. Thus, the arrays `a`, `eigenvalues`, and",
        "that ``a @ v = w * v``. Thus,"
    ],
    [
        "`eigenvectors` satisfy the equations ``a @ eigenvectors[:,i] =",
        "`eigenvectors` satisfy the equations ``a @"
    ],
    [
        "The array `eigenvectors` may not be of maximum rank, that is, some of the",
        "The array `eigenvectors` may not be of"
    ],
    [
        "columns may be linearly dependent, although round-off error may obscure",
        "columns may be linearly dependent, although"
    ],
    [
        "that fact. If the eigenvalues are all different, then theoretically the",
        "that fact. If the eigenvalues are all"
    ],
    [
        "eigenvectors are linearly independent and `a` can be diagonalized by a",
        "eigenvectors are linearly independent and `a` can be diagonalized by"
    ],
    [
        "similarity transformation using `eigenvectors`, i.e, ``inv(eigenvectors) @",
        "similarity transformation using `eigenvectors`, i.e, ``inv(eigenvectors)"
    ],
    [
        "For non-Hermitian normal matrices the SciPy function `scipy.linalg.schur`",
        "For non-Hermitian normal matrices the"
    ],
    [
        "is preferred because the matrix `eigenvectors` is guaranteed to be",
        "is preferred because the matrix"
    ],
    [
        "unitary, which is not the case when using `eig`. The Schur factorization",
        "unitary, which is not the case when using `eig`."
    ],
    [
        "produces an upper triangular matrix rather than a diagonal matrix, but for",
        "produces an upper triangular matrix rather than a"
    ],
    [
        "normal matrices only the diagonal of the upper triangular matrix is",
        "normal matrices only the diagonal of the upper triangular matrix"
    ],
    [
        "needed, the rest is roundoff error.",
        "needed, the rest"
    ],
    [
        "Finally, it is emphasized that `eigenvectors` consists of the *right* (as",
        "Finally, it is emphasized that `eigenvectors` consists of the"
    ],
    [
        "in right-hand side) eigenvectors of `a`. A vector `y` satisfying ``y.T @ a",
        "in right-hand side) eigenvectors of `a`. A vector"
    ],
    [
        "= z * y.T`` for some number `z` is called a *left* eigenvector of `a`,",
        "= z * y.T`` for some number `z` is"
    ],
    [
        "and, in general, the left and right eigenvectors of a matrix are not",
        "and, in general, the left and right eigenvectors of"
    ],
    [
        "necessarily the (perhaps conjugate) transposes of each other.",
        "necessarily the (perhaps conjugate) transposes of"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import"
    ],
    [
        "(Almost) trivial example with real eigenvalues and eigenvectors.",
        "(Almost) trivial example with"
    ],
    [
        "Real matrix possessing complex eigenvalues and eigenvectors;",
        "Real matrix possessing complex eigenvalues"
    ],
    [
        "note that the eigenvalues are complex conjugates of each other.",
        "note that the eigenvalues are complex conjugates of each"
    ],
    [
        "Complex-valued matrix with real eigenvalues (but complex-valued",
        "Complex-valued matrix with real eigenvalues"
    ],
    [
        "eigenvectors); note that ``a.conj().T == a``, i.e., `a` is Hermitian.",
        "eigenvectors); note that ``a.conj().T == a``, i.e., `a` is"
    ],
    [
        "signature = 'D->DD' if isComplexType(t) else 'd->DD'",
        "signature = 'D->DD' if"
    ],
    [
        "Return the eigenvalues and eigenvectors of a complex Hermitian",
        "Return the eigenvalues and eigenvectors of a complex"
    ],
    [
        "(conjugate symmetric) or a real symmetric matrix.",
        "(conjugate symmetric) or a"
    ],
    [
        "a : (..., M, M) array",
        "a : (..., M, M)"
    ],
    [
        "Hermitian or real symmetric matrices whose eigenvalues and",
        "Hermitian or real symmetric matrices whose eigenvalues"
    ],
    [
        "Specifies whether the calculation is done with the lower triangular",
        "Specifies whether the calculation is done with the lower"
    ],
    [
        "part of `a` ('L', default) or the upper triangular part ('U').",
        "part of `a` ('L', default) or the upper triangular part"
    ],
    [
        "Irrespective of this value only the real parts of the diagonal will",
        "Irrespective of this value only the real parts of the"
    ],
    [
        "be considered in the computation to preserve the notion of a Hermitian",
        "be considered in the computation to preserve the notion of"
    ],
    [
        "matrix. It therefore follows that the imaginary part of the diagonal",
        "matrix. It therefore follows that the"
    ],
    [
        "will always be treated as zero.",
        "will always be"
    ],
    [
        "A namedtuple with the following attributes:",
        "A namedtuple with"
    ],
    [
        "The eigenvalues in ascending order, each repeated according to",
        "The eigenvalues in ascending order, each repeated according"
    ],
    [
        "eigenvectors : {(..., M, M) ndarray, (..., M, M) matrix}",
        "eigenvectors : {(..., M, M) ndarray, (..., M,"
    ],
    [
        "The column ``eigenvectors[:, i]`` is the normalized eigenvector",
        "The column ``eigenvectors[:, i]`` is the"
    ],
    [
        "corresponding to the eigenvalue ``eigenvalues[i]``.  Will return a",
        "corresponding to the eigenvalue ``eigenvalues[i]``. Will"
    ],
    [
        "matrix object if `a` is a matrix object.",
        "matrix object if `a`"
    ],
    [
        "If the eigenvalue computation does not converge.",
        "If the eigenvalue computation"
    ],
    [
        "eigvalsh : eigenvalues of real symmetric or complex Hermitian",
        "eigvalsh : eigenvalues of real symmetric"
    ],
    [
        "eig : eigenvalues and right eigenvectors for non-symmetric arrays.",
        "eig : eigenvalues and right eigenvectors for non-symmetric"
    ],
    [
        "eigvals : eigenvalues of non-symmetric arrays.",
        "eigvals : eigenvalues"
    ],
    [
        "scipy.linalg.eigh : Similar function in SciPy (but also solves the",
        "scipy.linalg.eigh : Similar function in SciPy (but"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see"
    ],
    [
        "The eigenvalues/eigenvectors are computed using LAPACK routines ``_syevd``,",
        "The eigenvalues/eigenvectors are computed using"
    ],
    [
        "The eigenvalues of real symmetric or complex Hermitian matrices are always",
        "The eigenvalues of real symmetric or complex Hermitian"
    ],
    [
        "`a`, `eigenvalues`, and `eigenvectors` satisfy the equations ``dot(a,",
        "`a`, `eigenvalues`, and `eigenvectors` satisfy the"
    ],
    [
        "eigenvectors[:, i]) = eigenvalues[i] * eigenvectors[:, i]``.",
        "eigenvectors[:, i]) = eigenvalues[i] * eigenvectors[:,"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import linalg as"
    ],
    [
        "if UPLO not in ('L', 'U'):",
        "if UPLO not in"
    ],
    [
        "raise ValueError(\"UPLO argument must be 'L' or 'U'\")",
        "raise ValueError(\"UPLO argument must"
    ],
    [
        "signature = 'D->dD' if isComplexType(t) else 'd->dd'",
        "signature = 'D->dD' if"
    ],
    [
        "factorized as ``u @ np.diag(s) @ vh = (u * s) @ vh``, where",
        "factorized as ``u @ np.diag(s) @ vh ="
    ],
    [
        "values. When `a` is higher-dimensional, SVD is applied in",
        "values. When `a` is higher-dimensional, SVD"
    ],
    [
        "a : (..., M, N) array_like",
        "a : (..., M,"
    ],
    [
        "If True (default), `u` and `vh` have the shapes ``(..., M, M)`` and",
        "If True (default), `u` and `vh` have the shapes"
    ],
    [
        "``(..., N, N)``, respectively.  Otherwise, the shapes are",
        "``(..., N, N)``, respectively."
    ],
    [
        "``(..., M, K)`` and ``(..., K, N)``, respectively, where",
        "``(..., M, K)`` and ``(...,"
    ],
    [
        "Whether or not to compute `u` and `vh` in addition to `s`.  True",
        "Whether or not to compute `u` and `vh` in addition"
    ],
    [
        "If True, `a` is assumed to be Hermitian (symmetric if real-valued),",
        "If True, `a` is assumed to be"
    ],
    [
        "enabling a more efficient method for finding singular values.",
        "enabling a more efficient method for finding singular"
    ],
    [
        "When `compute_uv` is True, the result is a namedtuple with the following",
        "When `compute_uv` is True, the result"
    ],
    [
        "U : { (..., M, M), (..., M, K) } array",
        "U : { (..., M, M), (...,"
    ],
    [
        "size as those of the input `a`. The size of the last two dimensions",
        "size as those of the input `a`. The"
    ],
    [
        "depends on the value of `full_matrices`. Only returned when",
        "depends on the value of `full_matrices`."
    ],
    [
        "Vector(s) with the singular values, within each vector sorted in",
        "Vector(s) with the singular values, within each vector sorted"
    ],
    [
        "size as those of the input `a`.",
        "size as those of the"
    ],
    [
        "Vh : { (..., N, N), (..., K, N) } array",
        "Vh : { (..., N, N),"
    ],
    [
        "size as those of the input `a`. The size of the last two dimensions",
        "size as those of the input `a`. The size"
    ],
    [
        "depends on the value of `full_matrices`. Only returned when",
        "depends on the value of `full_matrices`. Only returned"
    ],
    [
        "If SVD computation does not converge.",
        "If SVD computation"
    ],
    [
        "scipy.linalg.svd : Similar function in SciPy.",
        "scipy.linalg.svd : Similar function in"
    ],
    [
        "scipy.linalg.svdvals : Compute singular values of a matrix.",
        "scipy.linalg.svdvals : Compute singular values of"
    ],
    [
        "The decomposition is performed using LAPACK routine ``_gesdd``.",
        "The decomposition is performed using LAPACK"
    ],
    [
        "written as :math:`A = U S V^H`, where :math:`A = a`, :math:`U= u`,",
        "written as :math:`A = U S V^H`, where :math:`A"
    ],
    [
        "contains the singular values of `a` and `u` and `vh` are unitary. The rows",
        "contains the singular values of `a` and `u`"
    ],
    [
        "of `vh` are the eigenvectors of :math:`A^H A` and the columns of `u` are",
        "of `vh` are the eigenvectors of :math:`A^H A`"
    ],
    [
        "the eigenvectors of :math:`A A^H`. In both cases the corresponding",
        "the eigenvectors of :math:`A A^H`. In both"
    ],
    [
        "If `a` has more than two dimensions, then broadcasting rules apply, as",
        "If `a` has more than two dimensions, then broadcasting rules"
    ],
    [
        "explained in :ref:`routines.linalg-broadcasting`. This means that SVD is",
        "explained in :ref:`routines.linalg-broadcasting`. This"
    ],
    [
        "working in \"stacked\" mode: it iterates over all indices of the first",
        "working in \"stacked\" mode: it iterates over all indices of the"
    ],
    [
        "last two indices. The matrix `a` can be reconstructed from the",
        "last two indices. The matrix `a` can"
    ],
    [
        "decomposition with either ``(u * s[..., None, :]) @ vh`` or",
        "decomposition with either ``(u * s[..., None, :]) @ vh``"
    ],
    [
        "``u @ (s[..., None] * vh)``. (The ``@`` operator can be replaced by the",
        "``u @ (s[..., None] * vh)``. (The"
    ],
    [
        "If `a` is a ``matrix`` object (as opposed to an ``ndarray``), then so are",
        "If `a` is a ``matrix`` object (as opposed"
    ],
    [
        ">>> U, S, Vh = np.linalg.svd(a, full_matrices=True)",
        ">>> U, S, Vh = np.linalg.svd(a,"
    ],
    [
        ">>> U, S, Vh = np.linalg.svd(a, full_matrices=False)",
        ">>> U, S, Vh = np.linalg.svd(a,"
    ],
    [
        ">>> np.allclose(a, np.dot(U * S, Vh))",
        ">>> np.allclose(a, np.dot(U *"
    ],
    [
        ">>> U, S, Vh = np.linalg.svd(b, full_matrices=True)",
        ">>> U, S, Vh"
    ],
    [
        ">>> U, S, Vh = np.linalg.svd(b, full_matrices=False)",
        ">>> U, S, Vh ="
    ],
    [
        ">>> np.allclose(b, np.matmul(U * S[..., None, :], Vh))",
        ">>> np.allclose(b, np.matmul(U *"
    ],
    [
        ">>> np.allclose(b, np.matmul(U, S[..., None] * Vh))",
        ">>> np.allclose(b, np.matmul(U, S[...,"
    ],
    [
        "vt = transpose(u * sgn[..., None, :]).conjugate()",
        "vt = transpose(u * sgn[..., None,"
    ],
    [
        "signature = 'D->DdD' if isComplexType(t) else 'd->ddd'",
        "signature = 'D->DdD' if isComplexType(t) else"
    ],
    [
        "u, s, vh = gufunc(a, signature=signature)",
        "u, s, vh = gufunc(a,"
    ],
    [
        "signature = 'D->d' if isComplexType(t) else 'd->d'",
        "signature = 'D->d' if isComplexType(t) else"
    ],
    [
        "Returns the singular values of a matrix (or a stack of matrices) ``x``.",
        "Returns the singular values of a matrix (or a stack of matrices)"
    ],
    [
        "When x is a stack of matrices, the function will compute the singular",
        "When x is a stack of matrices, the function will"
    ],
    [
        "values for each matrix in the stack.",
        "values for each matrix"
    ],
    [
        "This function is Array API compatible.",
        "This function is"
    ],
    [
        "Calling ``np.svdvals(x)`` to get singular values is the same as",
        "Calling ``np.svdvals(x)`` to get singular values is the same"
    ],
    [
        "x : (..., M, N) array_like",
        "x : (..., M, N)"
    ],
    [
        "Input array having shape (..., M, N) and whose last two",
        "Input array having shape (..., M, N)"
    ],
    [
        "dimensions form matrices on which to perform singular value",
        "dimensions form matrices on which to perform singular"
    ],
    [
        "decomposition. Should have a floating-point data type.",
        "decomposition. Should have a"
    ],
    [
        "An array with shape (..., K) that contains the vector(s)",
        "An array with shape (..., K) that"
    ],
    [
        "of singular values of length K, where K = min(M, N).",
        "of singular values of length K, where K"
    ],
    [
        "scipy.linalg.svdvals : Compute singular values of a matrix.",
        "scipy.linalg.svdvals : Compute singular values of a"
    ],
    [
        "Determine the rank of a matrix using singular values:",
        "Determine the rank of a matrix using"
    ],
    [
        "Compute the condition number of a matrix.",
        "Compute the condition number of a"
    ],
    [
        "This function is capable of returning the condition number using",
        "This function is capable of"
    ],
    [
        "one of seven different norms, depending on the value of `p` (see",
        "one of seven different norms, depending on the value of"
    ],
    [
        "x : (..., M, N) array_like",
        "x : (..., M,"
    ],
    [
        "The matrix whose condition number is sought.",
        "The matrix whose condition"
    ],
    [
        "Order of the norm used in the condition number computation:",
        "Order of the norm used in the condition"
    ],
    [
        "inf means the `numpy.inf` object, and the Frobenius norm is",
        "inf means the `numpy.inf` object, and"
    ],
    [
        "The condition number of the matrix. May be infinite.",
        "The condition number of the matrix. May be"
    ],
    [
        "The condition number of `x` is defined as the norm of `x` times the",
        "The condition number of `x` is defined as the norm of"
    ],
    [
        "(root-of-sum-of-squares) or one of a number of other matrix norms.",
        "(root-of-sum-of-squares) or one of a number of other matrix"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import"
    ],
    [
        "raise LinAlgError(\"cond is not defined on empty arrays\")",
        "raise LinAlgError(\"cond is not defined on"
    ],
    [
        "signature = 'D->D' if isComplexType(t) else 'd->d'",
        "signature = 'D->D' if isComplexType(t)"
    ],
    [
        "def _matrix_rank_dispatcher(A, tol=None, hermitian=None, *, rtol=None):",
        "def _matrix_rank_dispatcher(A, tol=None, hermitian=None,"
    ],
    [
        "def matrix_rank(A, tol=None, hermitian=False, *, rtol=None):",
        "def matrix_rank(A, tol=None, hermitian=False,"
    ],
    [
        "Return matrix rank of array using SVD method",
        "Return matrix rank of"
    ],
    [
        "Rank of the array is the number of singular values of the array that are",
        "Rank of the array is the number of singular"
    ],
    [
        "A : {(M,), (..., M, N)} array_like",
        "A : {(M,), (...,"
    ],
    [
        "Input vector or stack of matrices.",
        "Input vector or"
    ],
    [
        "tol : (...) array_like, float, optional",
        "tol : (...) array_like, float,"
    ],
    [
        "Threshold below which SVD values are considered zero. If `tol` is",
        "Threshold below which SVD values are"
    ],
    [
        "None, and ``S`` is an array with singular values for `M`, and",
        "None, and ``S`` is an array with singular values for"
    ],
    [
        "``eps`` is the epsilon value for datatype of ``S``, then `tol` is",
        "``eps`` is the epsilon value for datatype of ``S``, then"
    ],
    [
        "set to ``S.max() * max(M, N) * eps``.",
        "set to ``S.max() * max(M,"
    ],
    [
        "If True, `A` is assumed to be Hermitian (symmetric if real-valued),",
        "If True, `A` is assumed to"
    ],
    [
        "enabling a more efficient method for finding singular values.",
        "enabling a more efficient method for finding singular"
    ],
    [
        "rtol : (...) array_like, float, optional",
        "rtol : (...) array_like,"
    ],
    [
        "Parameter for the relative tolerance component. Only ``tol`` or",
        "Parameter for the relative tolerance component. Only ``tol``"
    ],
    [
        "``rtol`` can be set at a time. Defaults to ``max(M, N) * eps``.",
        "``rtol`` can be set at a time. Defaults to ``max(M,"
    ],
    [
        "The default threshold to detect rank deficiency is a test on the magnitude",
        "The default threshold to detect rank deficiency is a test on the"
    ],
    [
        "of the singular values of `A`.  By default, we identify singular values",
        "of the singular values of `A`. By default, we"
    ],
    [
        "less than ``S.max() * max(M, N) * eps`` as indicating rank deficiency",
        "less than ``S.max() * max(M, N) * eps`` as indicating"
    ],
    [
        "It also appears in *Numerical recipes* in the discussion of SVD solutions",
        "It also appears in *Numerical recipes* in the discussion"
    ],
    [
        "This default threshold is designed to detect rank deficiency accounting",
        "This default threshold is designed"
    ],
    [
        "for the numerical errors of the SVD computation. Imagine that there",
        "for the numerical errors of the SVD"
    ],
    [
        "is a column in `A` that is an exact (in floating point) linear combination",
        "is a column in `A` that is an exact"
    ],
    [
        "of other columns in `A`. Computing the SVD on `A` will not produce",
        "of other columns in `A`. Computing the SVD on `A` will not"
    ],
    [
        "in the calculation of the SVD. Our threshold for small SVD values takes",
        "in the calculation of the SVD. Our"
    ],
    [
        "this numerical imprecision into account, and the default threshold will",
        "this numerical imprecision into account, and the default"
    ],
    [
        "detect such numerical rank deficiency. The threshold may declare a matrix",
        "detect such numerical rank deficiency. The threshold may declare"
    ],
    [
        "`A` rank deficient even if the linear combination of some columns of `A`",
        "`A` rank deficient even if the linear combination"
    ],
    [
        "is not exactly equal to another column of `A` but only numerically very",
        "is not exactly equal to another column of `A` but only numerically"
    ],
    [
        "close to another column of `A`.",
        "close to another column"
    ],
    [
        "We chose our default threshold because it is in wide use. Other thresholds",
        "We chose our default threshold because it is in"
    ],
    [
        "recipes* there is an alternative threshold of ``S.max() *",
        "recipes* there is an alternative threshold of ``S.max()"
    ],
    [
        "The thresholds above deal with floating point roundoff error in the",
        "The thresholds above deal with floating point roundoff"
    ],
    [
        "calculation of the SVD.  However, you may have more information about",
        "calculation of the SVD. However, you"
    ],
    [
        "the sources of error in `A` that would make you consider other tolerance",
        "the sources of error in `A` that would make you consider"
    ],
    [
        "values to detect *effective* rank deficiency. The most useful measure",
        "values to detect *effective* rank"
    ],
    [
        "of the tolerance depends on the operations you intend to use on your",
        "of the tolerance depends on the operations you intend to use"
    ],
    [
        "matrix. For example, if your data come from uncertain measurements with",
        "matrix. For example, if your data"
    ],
    [
        "uncertainties greater than floating point epsilon, choosing a tolerance",
        "uncertainties greater than floating point epsilon, choosing"
    ],
    [
        "near that uncertainty may be preferable. The tolerance may be absolute",
        "near that uncertainty may be preferable. The"
    ],
    [
        "if the uncertainties are absolute rather than relative.",
        "if the uncertainties are absolute"
    ],
    [
        "if rtol is not None and tol is not None:",
        "if rtol is not None"
    ],
    [
        "raise ValueError(\"`tol` and `rtol` can't be both set.\")",
        "raise ValueError(\"`tol` and `rtol` can't be"
    ],
    [
        "def _pinv_dispatcher(a, rcond=None, hermitian=None, *, rtol=None):",
        "def _pinv_dispatcher(a, rcond=None, hermitian=None,"
    ],
    [
        "def pinv(a, rcond=None, hermitian=False, *, rtol=_NoValue):",
        "def pinv(a, rcond=None,"
    ],
    [
        "Compute the (Moore-Penrose) pseudo-inverse of a matrix.",
        "Compute the (Moore-Penrose) pseudo-inverse of a"
    ],
    [
        "Calculate the generalized inverse of a matrix using its",
        "Calculate the generalized inverse of a matrix using"
    ],
    [
        "singular-value decomposition (SVD) and including all",
        "singular-value decomposition (SVD) and including"
    ],
    [
        "a : (..., M, N) array_like",
        "a : (..., M,"
    ],
    [
        "Matrix or stack of matrices to be pseudo-inverted.",
        "Matrix or stack of matrices"
    ],
    [
        "rcond : (...) array_like of float, optional",
        "rcond : (...) array_like of"
    ],
    [
        "Singular values less than or equal to",
        "Singular values less than or"
    ],
    [
        "``rcond * largest_singular_value`` are set to zero.",
        "``rcond * largest_singular_value`` are set to"
    ],
    [
        "If True, `a` is assumed to be Hermitian (symmetric if real-valued),",
        "If True, `a` is assumed to be Hermitian (symmetric"
    ],
    [
        "enabling a more efficient method for finding singular values.",
        "enabling a more efficient method for finding"
    ],
    [
        "rtol : (...) array_like of float, optional",
        "rtol : (...) array_like"
    ],
    [
        "Same as `rcond`, but it's an Array API compatible parameter name.",
        "Same as `rcond`, but it's an Array API"
    ],
    [
        "Only `rcond` or `rtol` can be set at a time. If none of them are",
        "Only `rcond` or `rtol` can be set at a time. If none of them"
    ],
    [
        "is passed then the API standard default is used.",
        "is passed then the API standard default is"
    ],
    [
        "B : (..., N, M) ndarray",
        "B : (...,"
    ],
    [
        "The pseudo-inverse of `a`. If `a` is a `matrix` instance, then so",
        "The pseudo-inverse of `a`. If `a` is a"
    ],
    [
        "If the SVD computation does not converge.",
        "If the SVD computation"
    ],
    [
        "scipy.linalg.pinv : Similar function in SciPy.",
        "scipy.linalg.pinv : Similar function"
    ],
    [
        "scipy.linalg.pinvh : Compute the (Moore-Penrose) pseudo-inverse of a",
        "scipy.linalg.pinvh : Compute the (Moore-Penrose) pseudo-inverse"
    ],
    [
        "The pseudo-inverse of a matrix A, denoted :math:`A^+`, is",
        "The pseudo-inverse of a matrix A, denoted :math:`A^+`,"
    ],
    [
        "defined as: \"the matrix that 'solves' [the least-squares problem]",
        "defined as: \"the matrix that 'solves' [the least-squares"
    ],
    [
        ":math:`Ax = b`,\" i.e., if :math:`\\\\bar{x}` is said solution, then",
        ":math:`Ax = b`,\" i.e., if :math:`\\\\bar{x}` is said solution,"
    ],
    [
        ":math:`A^+` is that matrix such that :math:`\\\\bar{x} = A^+b`.",
        ":math:`A^+` is that matrix such that :math:`\\\\bar{x}"
    ],
    [
        "orthogonal matrices, :math:`\\\\Sigma` is a diagonal matrix consisting",
        "orthogonal matrices, :math:`\\\\Sigma` is a diagonal matrix"
    ],
    [
        "of A's so-called singular values, (followed, typically, by",
        "of A's so-called singular"
    ],
    [
        "zeros), and then :math:`\\\\Sigma^+` is simply the diagonal matrix",
        "zeros), and then :math:`\\\\Sigma^+` is simply the diagonal"
    ],
    [
        "consisting of the reciprocals of A's singular values",
        "consisting of the reciprocals of A's singular"
    ],
    [
        "The following example checks that ``a * a+ * a == a`` and",
        "The following example checks that ``a * a+"
    ],
    [
        "``a+ * a * a+ == a+``:",
        "``a+ * a * a+ =="
    ],
    [
        "raise ValueError(\"`rtol` and `rcond` can't be both set.\")",
        "raise ValueError(\"`rtol` and `rcond` can't be"
    ],
    [
        "u, s, vt = svd(a, full_matrices=False, hermitian=hermitian)",
        "u, s, vt = svd(a,"
    ],
    [
        "res = matmul(transpose(vt), multiply(s[..., newaxis], transpose(u)))",
        "res = matmul(transpose(vt), multiply(s[...,"
    ],
    [
        "Compute the sign and (natural) logarithm of the determinant of an array.",
        "Compute the sign and (natural) logarithm of the determinant of"
    ],
    [
        "If an array has a very small or very large determinant, then a call to",
        "If an array has a very small or very large determinant, then"
    ],
    [
        "`det` may overflow or underflow. This routine is more robust against such",
        "`det` may overflow or underflow. This routine is more robust against"
    ],
    [
        "issues, because it computes the logarithm of the determinant rather than",
        "issues, because it computes the logarithm of the"
    ],
    [
        "a : (..., M, M) array_like",
        "a : (...,"
    ],
    [
        "A namedtuple with the following attributes:",
        "A namedtuple with the following"
    ],
    [
        "A number representing the sign of the determinant. For a real matrix,",
        "A number representing the sign of"
    ],
    [
        "The natural log of the absolute value of the determinant.",
        "The natural log of the absolute value of"
    ],
    [
        "will be -inf. In all cases, the determinant is equal to",
        "will be -inf. In all cases, the determinant"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see the `numpy.linalg`"
    ],
    [
        "The determinant is computed via LU factorization using the LAPACK",
        "The determinant is computed via LU factorization"
    ],
    [
        "Computing log-determinants for a stack of matrices:",
        "Computing log-determinants for a"
    ],
    [
        "This routine succeeds where ordinary `det` does not:",
        "This routine succeeds where ordinary `det` does"
    ],
    [
        "signature = 'D->Dd' if isComplexType(t) else 'd->dd'",
        "signature = 'D->Dd' if isComplexType(t)"
    ],
    [
        "Compute the determinant of an array.",
        "Compute the determinant of"
    ],
    [
        "a : (..., M, M) array_like",
        "a : (...,"
    ],
    [
        "Input array to compute determinants for.",
        "Input array to compute"
    ],
    [
        "slogdet : Another way to represent the determinant, more suitable",
        "slogdet : Another way to represent the determinant,"
    ],
    [
        "for large matrices where underflow/overflow may occur.",
        "for large matrices where"
    ],
    [
        "scipy.linalg.det : Similar function in SciPy.",
        "scipy.linalg.det : Similar function in"
    ],
    [
        "Broadcasting rules apply, see the `numpy.linalg` documentation for",
        "Broadcasting rules apply, see the"
    ],
    [
        "The determinant is computed via LU factorization using the LAPACK",
        "The determinant is computed via"
    ],
    [
        "Computing determinants for a stack of matrices:",
        "Computing determinants for a"
    ],
    [
        "signature = 'D->D' if isComplexType(t) else 'd->d'",
        "signature = 'D->D' if"
    ],
    [
        "Return the least-squares solution to a linear matrix equation.",
        "Return the least-squares solution to"
    ],
    [
        "Computes the vector `x` that approximately solves the equation",
        "Computes the vector `x` that"
    ],
    [
        "``a @ x = b``. The equation may be under-, well-, or over-determined",
        "``a @ x = b``. The equation may be under-, well-, or"
    ],
    [
        "(i.e., the number of linearly independent rows of `a` can be less than,",
        "(i.e., the number of linearly independent rows of `a` can"
    ],
    [
        "equal to, or greater than its number of linearly independent columns).",
        "equal to, or greater than its"
    ],
    [
        "If `a` is square and of full rank, then `x` (but for round-off error)",
        "If `a` is square and of full"
    ],
    [
        "is the \"exact\" solution of the equation. Else, `x` minimizes the",
        "is the \"exact\" solution of the equation. Else,"
    ],
    [
        "b : {(M,), (M, K)} array_like",
        "b : {(M,), (M, K)}"
    ],
    [
        "Ordinate or \"dependent variable\" values. If `b` is two-dimensional,",
        "Ordinate or \"dependent variable\" values. If `b`"
    ],
    [
        "the least-squares solution is calculated for each of the `K` columns",
        "the least-squares solution is calculated for"
    ],
    [
        "Cut-off ratio for small singular values of `a`.",
        "Cut-off ratio for small singular values of"
    ],
    [
        "For the purposes of rank determination, singular values are treated",
        "For the purposes of rank determination,"
    ],
    [
        "as zero if they are smaller than `rcond` times the largest singular",
        "as zero if they are smaller than `rcond` times the"
    ],
    [
        "The default uses the machine precision times ``max(M, N)``.  Passing",
        "The default uses the machine precision times ``max(M,"
    ],
    [
        "x : {(N,), (N, K)} ndarray",
        "x : {(N,), (N,"
    ],
    [
        "Least-squares solution. If `b` is two-dimensional,",
        "Least-squares solution. If `b`"
    ],
    [
        "the solutions are in the `K` columns of `x`.",
        "the solutions are in the `K` columns"
    ],
    [
        "If the rank of `a` is < N or M <= N, this is an empty array.",
        "If the rank of `a` is < N or M <= N,"
    ],
    [
        "scipy.linalg.lstsq : Similar function in SciPy.",
        "scipy.linalg.lstsq : Similar function in"
    ],
    [
        "If `b` is a matrix, then all array results are returned as matrices.",
        "If `b` is a matrix, then all"
    ],
    [
        "Fit a line, ``y = mx + c``, through some noisy data-points:",
        "Fit a line, ``y = mx +"
    ],
    [
        "By examining the coefficients, we see that the line should have a",
        "By examining the coefficients, we see that"
    ],
    [
        "and ``p = [[m], [c]]``.  Now use `lstsq` to solve for `p`:",
        "and ``p = [[m], [c]]``. Now use `lstsq` to solve for"
    ],
    [
        "Plot the data along with the fitted line:",
        "Plot the data along with"
    ],
    [
        ">>> _ = plt.plot(x, m*x + c, 'r', label='Fitted line')",
        ">>> _ = plt.plot(x, m*x +"
    ],
    [
        "rcond = finfo(t).eps * max(n, m)",
        "rcond = finfo(t).eps *"
    ],
    [
        "signature = 'DDd->Ddid' if isComplexType(t) else 'ddd->ddid'",
        "signature = 'DDd->Ddid' if isComplexType(t)"
    ],
    [
        "x, resids, rank, s = _umath_linalg.lstsq(a, b, rcond,",
        "x, resids, rank, s"
    ],
    [
        "if rank != n or m <= n:",
        "if rank != n"
    ],
    [
        "This is a private utility function used by `numpy.linalg.norm()`.",
        "This is a private utility function used by"
    ],
    [
        "This should be either numpy.amin or `numpy.amax` or `numpy.sum`.",
        "This should be either numpy.amin or `numpy.amax`"
    ],
    [
        "The return values are either the minimum or maximum or sum of the",
        "The return values are either the minimum or maximum or sum of"
    ],
    [
        "singular values of the matrices, depending on whether `op`",
        "singular values of the matrices, depending on whether"
    ],
    [
        "is `numpy.amin` or `numpy.amax` or `numpy.sum`.",
        "is `numpy.amin` or"
    ],
    [
        "This function is able to return one of eight different matrix norms,",
        "This function is able to return one"
    ],
    [
        "or one of an infinite number of vector norms (described below), depending",
        "or one of an infinite number of vector norms (described"
    ],
    [
        "on the value of the ``ord`` parameter.",
        "on the value of the"
    ],
    [
        "ord : {int, float, inf, -inf, 'fro', 'nuc'}, optional",
        "ord : {int, float, inf, -inf, 'fro', 'nuc'},"
    ],
    [
        "Order of the norm (see table under ``Notes`` for what values are",
        "Order of the norm (see table under ``Notes`` for what"
    ],
    [
        "supported for matrices and vectors respectively). inf means numpy's",
        "supported for matrices and vectors"
    ],
    [
        "`inf` object. The default is None.",
        "`inf` object. The default"
    ],
    [
        "If `axis` is an integer, it specifies the axis of `x` along which to",
        "If `axis` is an integer, it specifies"
    ],
    [
        "are computed.  If `axis` is None then either a vector norm (when `x`",
        "are computed. If `axis` is None then either"
    ],
    [
        "If this is set to True, the axes which are normed over are left in the",
        "If this is set to True, the axes which are"
    ],
    [
        "result as dimensions with size one.  With this option the result will",
        "result as dimensions with size one."
    ],
    [
        "broadcast correctly against the original `x`.",
        "broadcast correctly against the original"
    ],
    [
        "Norm of the matrix or vector(s).",
        "Norm of the"
    ],
    [
        "scipy.linalg.norm : Similar function in SciPy.",
        "scipy.linalg.norm : Similar function"
    ],
    [
        "mathematical 'norm', but it may still be useful for various numerical",
        "mathematical 'norm', but it may still"
    ],
    [
        "The following norms can be calculated:",
        "The following norms can be"
    ],
    [
        "ord    norm for matrices             norm for vectors",
        "ord norm for matrices norm"
    ],
    [
        "The nuclear norm is the sum of the singular values.",
        "The nuclear norm is the sum of the"
    ],
    [
        "Both the Frobenius and nuclear norm orders are only defined for",
        "Both the Frobenius and nuclear norm orders are only"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import linalg"
    ],
    [
        "Using the `axis` argument to compute vector norms:",
        "Using the `axis` argument to compute vector"
    ],
    [
        "Using the `axis` argument to compute matrix norms:",
        "Using the `axis` argument"
    ],
    [
        "\"'axis' must be None, an integer or a tuple of integers\"",
        "\"'axis' must be None, an integer or a tuple of"
    ],
    [
        "raise ValueError(f\"Invalid norm order '{ord}' for vectors\")",
        "raise ValueError(f\"Invalid norm order"
    ],
    [
        "ret = _multi_svd_norm(x, row_axis, col_axis, amax)",
        "ret = _multi_svd_norm(x,"
    ],
    [
        "ret = _multi_svd_norm(x, row_axis, col_axis, amin)",
        "ret = _multi_svd_norm(x,"
    ],
    [
        "elif ord in [None, 'fro', 'f']:",
        "elif ord in [None, 'fro',"
    ],
    [
        "ret = sqrt(add.reduce((x.conj() * x).real, axis=axis))",
        "ret = sqrt(add.reduce((x.conj() * x).real,"
    ],
    [
        "ret = _multi_svd_norm(x, row_axis, col_axis, sum)",
        "ret = _multi_svd_norm(x, row_axis,"
    ],
    [
        "raise ValueError(\"Invalid norm order for matrices.\")",
        "raise ValueError(\"Invalid norm"
    ],
    [
        "raise ValueError(\"Improper number of dimensions to norm.\")",
        "raise ValueError(\"Improper number of dimensions"
    ],
    [
        "Compute the dot product of two or more arrays in a single function call,",
        "Compute the dot product of two or more arrays in a single"
    ],
    [
        "while automatically selecting the fastest evaluation order.",
        "while automatically selecting the fastest"
    ],
    [
        "`multi_dot` chains `numpy.dot` and uses optimal parenthesization",
        "`multi_dot` chains `numpy.dot` and"
    ],
    [
        "this can speed up the multiplication a lot.",
        "this can speed up the"
    ],
    [
        "Output argument. This must have the exact kind that would be returned",
        "Output argument. This must have the exact kind"
    ],
    [
        "if it was not used. In particular, it must have the right type, must be",
        "if it was not used. In particular, it must have the right"
    ],
    [
        "C-contiguous, and its dtype must be the dtype that would be returned",
        "C-contiguous, and its dtype must be the dtype that would"
    ],
    [
        "for `dot(a, b)`. This is a performance feature. Therefore, if these",
        "for `dot(a, b)`. This is a performance feature. Therefore, if"
    ],
    [
        "conditions are not met, an exception is raised, instead of attempting",
        "conditions are not met, an exception is raised, instead"
    ],
    [
        "Returns the dot product of the supplied arrays.",
        "Returns the dot product of the"
    ],
    [
        "numpy.dot : dot multiplication with two arguments.",
        "numpy.dot : dot multiplication with"
    ],
    [
        ">>> _ = multi_dot([A, B, C, D])",
        ">>> _ = multi_dot([A, B, C,"
    ],
    [
        ">>> _ = np.dot(np.dot(np.dot(A, B), C), D)",
        ">>> _ = np.dot(np.dot(np.dot(A, B),"
    ],
    [
        "The cost for a matrix multiplication can be calculated with the",
        "The cost for a matrix multiplication"
    ],
    [
        "The costs for the two different parenthesizations are as follows::",
        "The costs for the two different parenthesizations"
    ],
    [
        "raise ValueError(\"Expecting at least two arrays.\")",
        "raise ValueError(\"Expecting at least"
    ],
    [
        "arrays = [asanyarray(a) for a in arrays]",
        "arrays = [asanyarray(a) for a"
    ],
    [
        "Find the best order for three arrays and do the multiplication.",
        "Find the best order for three arrays and do"
    ],
    [
        "Return a np.array that encodes the optimal order of multiplications.",
        "Return a np.array that encodes the optimal order of"
    ],
    [
        "The optimal order array is then used by `_multi_dot()` to do the",
        "The optimal order array is then used by `_multi_dot()`"
    ],
    [
        "Also return the cost matrix if `return_costs` is `True`",
        "Also return the cost matrix if `return_costs` is"
    ],
    [
        "The implementation CLOSELY follows Cormen, \"Introduction to Algorithms\",",
        "The implementation CLOSELY follows"
    ],
    [
        "cost[prefix] + cost[suffix] + cost_mult(prefix, suffix)",
        "cost[prefix] + cost[suffix]"
    ],
    [
        "for i in range(n - l):",
        "for i in range(n"
    ],
    [
        "return (s, m) if return_costs else s",
        "return (s, m) if return_costs"
    ],
    [
        "def _multi_dot(arrays, order, i, j, out=None):",
        "def _multi_dot(arrays, order,"
    ],
    [
        "\"\"\"Actually do the multiplication with the given order.\"\"\"",
        "\"\"\"Actually do the multiplication with the"
    ],
    [
        "return dot(_multi_dot(arrays, order, i, order[i, j]),",
        "return dot(_multi_dot(arrays, order,"
    ],
    [
        "Returns specified diagonals of a matrix (or a stack of matrices) ``x``.",
        "Returns specified diagonals of a matrix (or a stack of matrices)"
    ],
    [
        "This function is Array API compatible, contrary to",
        "This function is Array API compatible, contrary"
    ],
    [
        "to be defined by the last two dimensions.",
        "to be defined by the"
    ],
    [
        "Input array having shape (..., M, N) and whose innermost two",
        "Input array having shape (..., M, N) and whose innermost"
    ],
    [
        "Offset specifying the off-diagonal relative to the main diagonal,",
        "Offset specifying the off-diagonal relative"
    ],
    [
        "An array containing the diagonals and whose shape is determined by",
        "An array containing the diagonals and whose shape"
    ],
    [
        "removing the last two dimensions and appending a dimension equal to",
        "removing the last two dimensions and appending a"
    ],
    [
        "the size of the resulting diagonals. The returned array must have",
        "the size of the resulting diagonals."
    ],
    [
        "the same data type as ``x``.",
        "the same data type as"
    ],
    [
        "Diagonals adjacent to the main diagonal can be obtained by using the",
        "Diagonals adjacent to the main diagonal can"
    ],
    [
        "The anti-diagonal can be obtained by reversing the order of elements",
        "The anti-diagonal can be obtained by"
    ],
    [
        "Note that the order in which the diagonal is retrieved varies depending",
        "Note that the order in which the diagonal"
    ],
    [
        "def _trace_dispatcher(x, /, *, offset=None, dtype=None):",
        "def _trace_dispatcher(x, /,"
    ],
    [
        "Returns the sum along the specified diagonals of a matrix",
        "Returns the sum along the"
    ],
    [
        "(or a stack of matrices) ``x``.",
        "(or a stack"
    ],
    [
        "This function is Array API compatible, contrary to",
        "This function is Array API"
    ],
    [
        "Input array having shape (..., M, N) and whose innermost two",
        "Input array having shape (..., M, N) and whose innermost"
    ],
    [
        "Offset specifying the off-diagonal relative to the main diagonal,",
        "Offset specifying the off-diagonal relative to the main"
    ],
    [
        "Data type of the returned array.",
        "Data type of the"
    ],
    [
        "An array containing the traces and whose shape is determined by",
        "An array containing the traces and whose shape is"
    ],
    [
        "removing the last two dimensions and storing the traces in the last",
        "removing the last two dimensions and storing the traces"
    ],
    [
        "array dimension. For example, if x has rank k and shape:",
        "array dimension. For example, if x has rank"
    ],
    [
        "(I, J, K, ..., L) where::",
        "(I, J, K, ..., L)"
    ],
    [
        "out[i, j, k, ..., l] = trace(a[i, j, k, ..., l, :, :])",
        "out[i, j, k, ..., l] = trace(a[i, j, k, ...,"
    ],
    [
        "The returned array must have a data type as described by the dtype",
        "The returned array must have a data type as described by"
    ],
    [
        "This behavior differs from :py:func:`numpy.trace` which uses the first two",
        "This behavior differs from :py:func:`numpy.trace` which uses"
    ],
    [
        "Traces adjacent to the main diagonal can be obtained by using the",
        "Traces adjacent to the main diagonal can be obtained by using"
    ],
    [
        "This function is Array API compatible, contrary to",
        "This function is Array API"
    ],
    [
        "non-compute axes. The size of the axis over which to compute",
        "non-compute axes. The size of the"
    ],
    [
        "the cross-product must be the same size as the respective axis",
        "the cross-product must be the same size as the"
    ],
    [
        "An array containing the cross products.",
        "An array containing the cross"
    ],
    [
        "Multiple vector cross-products. Note that the direction of the cross",
        "Multiple vector cross-products. Note that the direction of the"
    ],
    [
        "product vector is defined by the *right-hand rule*.",
        "product vector is defined"
    ],
    [
        "This function is Array API compatible, contrary to",
        "This function is Array API compatible, contrary"
    ],
    [
        "The matrix product of the inputs.",
        "The matrix product"
    ],
    [
        "If a scalar value is passed in.",
        "If a scalar value is passed"
    ],
    [
        "Broadcasting is conventional for stacks of arrays",
        "Broadcasting is conventional for stacks"
    ],
    [
        "Vector, vector returns the scalar inner product, but neither argument",
        "Vector, vector returns the scalar inner product, but neither"
    ],
    [
        "def _matrix_norm_dispatcher(x, /, *, keepdims=None, ord=None):",
        "def _matrix_norm_dispatcher(x, /, *, keepdims=None,"
    ],
    [
        "def matrix_norm(x, /, *, keepdims=False, ord=\"fro\"):",
        "def matrix_norm(x, /, *,"
    ],
    [
        "Computes the matrix norm of a matrix (or a stack of matrices) ``x``.",
        "Computes the matrix norm of a matrix (or a stack"
    ],
    [
        "This function is Array API compatible.",
        "This function is"
    ],
    [
        "Input array having shape (..., M, N) and whose two innermost",
        "Input array having shape (..., M,"
    ],
    [
        "If this is set to True, the axes which are normed over are left in",
        "If this is set to True, the axes which are normed over"
    ],
    [
        "the result as dimensions with size one. Default: False.",
        "the result as dimensions with size one."
    ],
    [
        "The order of the norm. For details see the table under ``Notes``",
        "The order of the norm. For"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import linalg"
    ],
    [
        "def _vector_norm_dispatcher(x, /, *, axis=None, keepdims=None, ord=None):",
        "def _vector_norm_dispatcher(x, /, *,"
    ],
    [
        "Computes the vector norm of a vector (or batch of vectors) ``x``.",
        "Computes the vector norm of a"
    ],
    [
        "This function is Array API compatible.",
        "This function is Array API"
    ],
    [
        "If an integer, ``axis`` specifies the axis (dimension) along which",
        "If an integer, ``axis`` specifies"
    ],
    [
        "to compute vector norms. If an n-tuple, ``axis`` specifies the axes",
        "to compute vector norms. If an n-tuple, ``axis`` specifies"
    ],
    [
        "(dimensions) along which to compute batched vector norms. If ``None``,",
        "(dimensions) along which to compute batched vector norms."
    ],
    [
        "the vector norm must be computed over all array values (i.e.,",
        "the vector norm must be computed"
    ],
    [
        "equivalent to computing the vector norm of a flattened array).",
        "equivalent to computing the vector"
    ],
    [
        "If this is set to True, the axes which are normed over are left in",
        "If this is set to True, the axes"
    ],
    [
        "the result as dimensions with size one. Default: False.",
        "the result as dimensions with size"
    ],
    [
        "ord : {int, float, inf, -inf}, optional",
        "ord : {int, float, inf,"
    ],
    [
        "The order of the norm. For details see the table under ``Notes``",
        "The order of the norm. For details see the"
    ],
    [
        ">>> from numpy import linalg as LA",
        ">>> from numpy import linalg"
    ],
    [
        "rest = tuple(i for i in range(x.ndim) if i not in normalized_axis)",
        "rest = tuple(i for i in range(x.ndim) if i not"
    ],
    [
        "prod([x.shape[i] for i in axis], dtype=int),",
        "prod([x.shape[i] for i in axis],"
    ],
    [
        "range(len(shape)) if axis is None else axis, len(shape)",
        "range(len(shape)) if axis is None else"
    ],
    [
        "This function is restricted to arguments compatible with the Array API,",
        "This function is restricted to arguments"
    ],
    [
        "over the dimension specified by ``axis`` and where :math:`\\\\overline{a_i}`",
        "over the dimension specified by ``axis``"
    ],
    [
        "denotes the complex conjugate if :math:`a_i` is complex and the identity",
        "denotes the complex conjugate if :math:`a_i` is complex and"
    ],
    [
        "The vector dot product of the input.",
        "The vector dot product"
    ],
    [
        "Get the projected size along a given normal for an array of vectors.",
        "Get the projected size along a given normal for an array"
    ],
    [
        "f\"module 'numpy.linalg.linalg' has no attribute {attr_name}\")",
        "f\"module 'numpy.linalg.linalg' has no"
    ],
    [
        "\"The numpy.linalg.linalg has been made private and renamed to \"",
        "\"The numpy.linalg.linalg has been made private and"
    ],
    [
        "\"numpy.linalg._linalg. All public functions exported by it are \"",
        "\"numpy.linalg._linalg. All public functions exported by it"
    ],
    [
        "f\"available from numpy.linalg. Please use numpy.linalg.{attr_name} \"",
        "f\"available from numpy.linalg. Please use"
    ],
    [
        "\"\"\" Test functions for linalg module",
        "\"\"\" Test functions"
    ],
    [
        "from numpy import array, single, double, csingle, cdouble, dot, identity, matmul",
        "from numpy import array, single, double,"
    ],
    [
        "from numpy.linalg import matrix_power, norm, matrix_rank, multi_dot, LinAlgError",
        "from numpy.linalg import matrix_power, norm,"
    ],
    [
        "return type(out) is (type(in_) if isinstance(in_, np.ndarray)",
        "return type(out) is (type(in_) if"
    ],
    [
        "def __init__(self, name, a, b, tags=set()):",
        "def __init__(self, name, a,"
    ],
    [
        "A bundle of arguments to be passed to a test case, with an identifying",
        "A bundle of arguments to be passed to a test"
    ],
    [
        "name, the operands a and b, and a set of tags to filter the tests",
        "name, the operands a and b, and a set of tags to filter the"
    ],
    [
        "Run the function `do` on this test case, expanding arguments",
        "Run the function `do` on this test"
    ],
    [
        "Add the given tag (a string) to each of the cases (a list of LinalgCase",
        "Add the given tag (a string) to each of the cases (a"
    ],
    [
        "assert tag in all_tags, \"Invalid tag\"",
        "assert tag in all_tags, \"Invalid"
    ],
    [
        "Generate cartesian product of strides for all axes",
        "Generate cartesian product of strides for all"
    ],
    [
        "new_shape = [abs(a * b) for a, b in zip(x.shape, repeats)]",
        "new_shape = [abs(a * b) for a, b in"
    ],
    [
        "slices = tuple(slice(None, None, repeat) for repeat in repeats)",
        "slices = tuple(slice(None, None, repeat) for repeat"
    ],
    [
        "yield xi, \"stride_\" + \"_\".join([\"%+d\" % j for j in repeats])",
        "yield xi, \"stride_\" + \"_\".join([\"%+d\" % j for j"
    ],
    [
        "new_case = LinalgCase(case.name + \"_\" + a_label + \"_\" + b_label, a, b,",
        "new_case = LinalgCase(case.name + \"_\" + a_label + \"_\" + b_label, a,"
    ],
    [
        "Run func on each of the cases with all of the tags in require, and none",
        "Run func on each of the cases with all of the tags"
    ],
    [
        "if case.tags & require != require:",
        "if case.tags & require"
    ],
    [
        "msg = f'In test case: {case!r}\\n\\n'",
        "msg = f'In"
    ],
    [
        "U, S, Vh = res.U, res.S, res.Vh",
        "U, S, Vh = res.U,"
    ],
    [
        "u, s, vt = linalg.svd(a, False)",
        "u, s, vt ="
    ],
    [
        "assert_allclose(a, matmul(np.asarray(u) * np.asarray(s)[..., None, :],",
        "assert_allclose(a, matmul(np.asarray(u) * np.asarray(s)[..., None,"
    ],
    [
        "\"\"\" Empty input should put an identity matrix in u or vh \"\"\"",
        "\"\"\" Empty input should put an identity matrix in u or vh"
    ],
    [
        "u, s, vh = linalg.svd(x, compute_uv=True, hermitian=self.hermitian)",
        "u, s, vh = linalg.svd(x, compute_uv=True,"
    ],
    [
        "u, s, vh = linalg.svd(x, compute_uv=True, hermitian=self.hermitian)",
        "u, s, vh ="
    ],
    [
        "u, s, vt = linalg.svd(a, False, hermitian=True)",
        "u, s, vt = linalg.svd(a,"
    ],
    [
        "assert_allclose(a, matmul(np.asarray(u) * np.asarray(s)[..., None, :],",
        "assert_allclose(a, matmul(np.asarray(u) * np.asarray(s)[...,"
    ],
    [
        "for A, p in itertools.product(As, p_pos):",
        "for A, p in itertools.product(As,"
    ],
    [
        "for A, p in itertools.product(As, p_neg):",
        "for A, p"
    ],
    [
        "ValueError, match=r\"`rtol` and `rcond` can't be both set.\"",
        "ValueError, match=r\"`rtol` and `rcond` can't"
    ],
    [
        "u, s, vt = linalg.svd(a, False)",
        "u, s, vt ="
    ],
    [
        "if rank == n and m > n:",
        "if rank == n"
    ],
    [
        "x, residuals, rank, s = linalg.lstsq(a, b)",
        "x, residuals, rank, s"
    ],
    [
        "x, residuals, rank, s = linalg.lstsq(a, b, rcond=None)",
        "x, residuals, rank, s"
    ],
    [
        "a = np.arange(m * n).reshape(m, n)",
        "a = np.arange(m * n).reshape(m,"
    ],
    [
        "x, residuals, rank, s = linalg.lstsq(a, b, rcond=None)",
        "x, residuals, rank, s = linalg.lstsq(a,"
    ],
    [
        "r = b - np.dot(a, x)",
        "r = b -"
    ],
    [
        "@pytest.mark.parametrize('dt', [np.dtype(c) for c in '?bBhHiIqQefdgFDGO'])",
        "@pytest.mark.parametrize('dt', [np.dtype(c) for c in"
    ],
    [
        "dtnoinv = [object, np.dtype('e'), np.dtype('g'), np.dtype('G')]",
        "dtnoinv = [object,"
    ],
    [
        "mmul = matmul if mat.dtype != object else dot",
        "mmul = matmul if mat.dtype != object else"
    ],
    [
        "mmul = matmul if mat.dtype != object else dot",
        "mmul = matmul if mat.dtype != object else"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "for v in (a, b, c,):",
        "for v in (a,"
    ],
    [
        "for v in (array(a, dtype=self.dt), array(b, dtype=self.dt),",
        "for v in (array(a,"
    ],
    [
        "k_index = nd - (row_axis + col_axis)",
        "k_index = nd - (row_axis"
    ],
    [
        "found = norm(A, ord=None, axis=None, keepdims=True)",
        "found = norm(A, ord=None, axis=None,"
    ],
    [
        "found = norm(A, ord=order, axis=k, keepdims=True)",
        "found = norm(A, ord=order, axis=k,"
    ],
    [
        "found = norm(A, ord=order, axis=k, keepdims=True)",
        "found = norm(A, ord=order, axis=k,"
    ],
    [
        "ValueError, \"`tol` and `rtol` can\\'t be both set.\"",
        "ValueError, \"`tol` and `rtol` can\\'t"
    ],
    [
        "ValueError, \"Input arrays must be one-dimensional\"",
        "ValueError, \"Input arrays must be"
    ],
    [
        "for routine in (linalg.inv, linalg.det, linalg.pinv):",
        "for routine in (linalg.inv,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "reason=\"skipping test that uses fork because there are multiple threads\")",
        "reason=\"skipping test that uses fork because there"
    ],
    [
        "reason=\"Cannot safely use fork in tests on the free-threaded build\")",
        "reason=\"Cannot safely use fork in tests on the"
    ],
    [
        "code = template.format(before=\"import numpy as np\", after=\"\",",
        "code = template.format(before=\"import numpy"
    ],
    [
        "code = template.format(after=\"import numpy as np\", before=\"\",",
        "code = template.format(after=\"import numpy"
    ],
    [
        "assert_almost_equal(multi_dot([A, B, C]), np.dot(A, np.dot(B, C)))",
        "assert_almost_equal(multi_dot([A, B, C]),"
    ],
    [
        "ret = multi_dot([A, B, C], out=out)",
        "ret = multi_dot([A,"
    ],
    [
        "ret = multi_dot([A, B, C, D], out=out)",
        "ret = multi_dot([A, B,"
    ],
    [
        "@pytest.mark.skip(reason=\"Bad memory reports lead to OOM in ci testing\")",
        "@pytest.mark.skip(reason=\"Bad memory reports lead to OOM in ci"
    ],
    [
        "deprecated. The release date will probably be sometime in the summer",
        "deprecated. The release date will probably be sometime in"
    ],
    [
        "\"\"\" Test functions for linalg module",
        "\"\"\" Test functions for"
    ],
    [
        "u_lstsq, res, rank, sv = linalg.lstsq(G, b, rcond=None)",
        "u_lstsq, res, rank, sv = linalg.lstsq(G, b,"
    ],
    [
        "assert False, (\"unexpected result from matmul, \"",
        "assert False, (\"unexpected result"
    ],
    [
        "\"probably due to OpenBLAS threading issues\")",
        "\"probably due to"
    ],
    [
        "from plex import Scanner, Str, Lexicon, Opt, Bol, State, AnyChar, TEXT, IGNORE",
        "from plex import Scanner, Str, Lexicon, Opt, Bol,"
    ],
    [
        "from plex.traditional import re as Re",
        "from plex.traditional import re"
    ],
    [
        "a char * argument to hold the length of the passed string. This is just",
        "a char * argument to hold the length of"
    ],
    [
        "iofunctions = Str(\"s_cat\", \"s_copy\", \"s_stop\", \"s_cmp\",",
        "iofunctions = Str(\"s_cat\", \"s_copy\", \"s_stop\","
    ],
    [
        "keep_ftnlen = (Str('ilaenv_') | Str('iparmq_') | Str('s_rnge')) + Str('(')",
        "keep_ftnlen = (Str('ilaenv_') | Str('iparmq_') | Str('s_rnge'))"
    ],
    [
        "(cS + Str('ftnlen') + Opt(S + len_),          IGNORE),",
        "(cS + Str('ftnlen') +"
    ],
    [
        "(cS + sep_seq(['(', 'ftnlen', ')'], S) + S + digits,      IGNORE),",
        "(cS + sep_seq(['(', 'ftnlen', ')'], S) + S"
    ],
    [
        "(Bol + Str('ftnlen ') + len_ + Str(';\\n'),    IGNORE),",
        "(Bol + Str('ftnlen ') + len_"
    ],
    [
        "source = re.sub(r'[\\t ]+\\n', '\\n', source)",
        "source = re.sub(r'[\\t"
    ],
    [
        "source = re.sub(r'(?m)^[\\t ]*/\\* *\\.\\. .*?\\n', '', source)",
        "source = re.sub(r'(?m)^[\\t ]*/\\* *\\.\\."
    ],
    [
        "if line.strip() == '/* Builtin functions */':",
        "if line.strip() == '/* Builtin functions"
    ],
    [
        "\"\"\"Replace dlamch_ calls with appropriate macros\"\"\"",
        "\"\"\"Replace dlamch_ calls with"
    ],
    [
        "return {'E': 'EPSILON', 'P': 'PRECISION', 'S': 'SAFEMINIMUM',",
        "return {'E': 'EPSILON', 'P': 'PRECISION',"
    ],
    [
        "source = re.sub(r'^\\s+extern.*? dlamch_.*?;$(?m)', '', source)",
        "source = re.sub(r'^\\s+extern.*? dlamch_.*?;$(?m)', '',"
    ],
    [
        "Requires the following to be on the path:",
        "Requires the following to be on"
    ],
    [
        "* NOTE: This is generated code. Look in numpy/linalg/lapack_lite for",
        "* NOTE: This is generated code. Look in"
    ],
    [
        "*       information on remaking this file.",
        "* information on"
    ],
    [
        "strictly necessary. Since this is generated code, we don't really care if",
        "strictly necessary. Since this is generated code, we"
    ],
    [
        "it's readable, and we know what is written is correct. So don't warn about",
        "it's readable, and we know what is written is correct. So don't warn"
    ],
    [
        "\"\"\"Wrapper for a Fortran routine in a file.",
        "\"\"\"Wrapper for a Fortran"
    ],
    [
        "self._dependencies = [d.lower() for d in deps]",
        "self._dependencies = [d.lower() for d"
    ],
    [
        "\"\"\"Wrapper for a Fortran routine for which the corresponding file",
        "\"\"\"Wrapper for a Fortran routine for which the"
    ],
    [
        "\"\"\"Container for a bunch of Fortran routines.",
        "\"\"\"Container for a bunch of"
    ],
    [
        "ffilename = os.path.join(s, rname + '.f')",
        "ffilename = os.path.join(s, rname +"
    ],
    [
        "\"\"\"Add a routine that we don't want to consider when looking at",
        "\"\"\"Add a routine that we don't want to consider when looking"
    ],
    [
        "\"\"\"Add a routine to the library.",
        "\"\"\"Add a routine to"
    ],
    [
        "\"\"\"Get a routine from the library. Will add if it's not found.",
        "\"\"\"Get a routine from the library. Will add"
    ],
    [
        "\"\"\"Return the names of all the routines.",
        "\"\"\"Return the names of all the"
    ],
    [
        "\"\"\"Try to add routines to the library to satisfy all the dependencies",
        "\"\"\"Try to add routines to the library to satisfy"
    ],
    [
        "for each routine in the library.",
        "for each routine in"
    ],
    [
        "Returns a set of routine names that have the dependencies unresolved.",
        "Returns a set of routine names that have the dependencies"
    ],
    [
        "routines = sorted((r.name, r) for r in self.allRoutines() if r.type == typename)",
        "routines = sorted((r.name, r) for r in self.allRoutines() if"
    ],
    [
        "types = {'blas', 'lapack', 'd_lapack', 's_lapack', 'z_lapack', 'c_lapack', 'config'}",
        "types = {'blas', 'lapack', 'd_lapack',"
    ],
    [
        "for typename in {'unknown'} | types:",
        "for typename in {'unknown'} |"
    ],
    [
        "filename = os.path.join(output_dir, typename + '_routines.lst')",
        "filename = os.path.join(output_dir, typename"
    ],
    [
        "fo.write('%s: %s\\n' % (r.name, ' '.join(deps)))",
        "fo.write('%s: %s\\n' %"
    ],
    [
        "raise SystemExit(name + ' not found')",
        "raise SystemExit(name +"
    ],
    [
        "with open(os.path.join(output_dir, 'lapack_lite_names.h'), 'w') as f:",
        "with open(os.path.join(output_dir, 'lapack_lite_names.h'),"
    ],
    [
        "\" * dynamic symbol name conflicts, in cases where e.g.\\n\"",
        "\" * dynamic symbol name conflicts,"
    ],
    [
        "\" * integer sizes do not match with 'standard' ABI.\\n\"",
        "\" * integer sizes do not"
    ],
    [
        "if fname.endswith('.c') or fname == 'lapack_lite_names.h':",
        "if fname.endswith('.c') or fname =="
    ],
    [
        "\"\"\"Return the type of a line of Fortran code.\"\"\"",
        "\"\"\"Return the type of a line of Fortran"
    ],
    [
        "Return rstrip()'d lines from iterable, while keeping a count of the",
        "Return rstrip()'d lines from iterable, while keeping"
    ],
    [
        "line number in the .lineno attribute.",
        "line number in the"
    ],
    [
        "Return an iterator for which items can be pushed back into.",
        "Return an iterator for which items can be"
    ],
    [
        "Call the .pushback(item) method to have item returned as the next",
        "Call the .pushback(item) method to have item returned as the"
    ],
    [
        "\"\"\"Return an iterator over statement lines of a Fortran source file.",
        "\"\"\"Return an iterator over statement lines"
    ],
    [
        "Comment and blank lines are stripped out, and continuation lines are",
        "Comment and blank lines are stripped out, and continuation lines"
    ],
    [
        "raise ValueError(\"jammed: continuation line not expected: %s:%d\" %",
        "raise ValueError(\"jammed: continuation line not expected:"
    ],
    [
        "\"\"\"For a Fortran source file, return a list of routines declared as EXTERNAL",
        "\"\"\"For a Fortran source file, return a list of routines declared"
    ],
    [
        "names = [n.strip().lower() for n in names]",
        "names = [n.strip().lower() for n"
    ],
    [
        "names = [n for n in names if n]",
        "names = [n for n in names if"
    ],
    [
        "load_library : Load a C library.",
        "load_library : Load a"
    ],
    [
        "ndpointer : Array restype/argtype with verification.",
        "ndpointer : Array"
    ],
    [
        "as_ctypes : Create a ctypes array from an ndarray.",
        "as_ctypes : Create a ctypes array from"
    ],
    [
        "as_array : Create an ndarray from a ctypes array.",
        "as_array : Create an ndarray"
    ],
    [
        "Our C-function typically takes an array and updates its values",
        "Our C-function typically takes an"
    ],
    [
        "Then, we're ready to call ``foo_func``:",
        "Then, we're ready"
    ],
    [
        "__all__ = ['load_library', 'ndpointer', 'c_intp', 'as_ctypes', 'as_array',",
        "__all__ = ['load_library', 'ndpointer', 'c_intp', 'as_ctypes',"
    ],
    [
        "Dummy object that raises an ImportError if ctypes is not available.",
        "Dummy object that raises an ImportError if"
    ],
    [
        "from numpy import intp as c_intp",
        "from numpy import"
    ],
    [
        "It is possible to load a library using",
        "It is possible to"
    ],
    [
        "But there are cross-platform considerations, such as library file extensions,",
        "But there are cross-platform considerations, such as library"
    ],
    [
        "plus the fact Windows will just load the first library it finds with that name.",
        "plus the fact Windows will just load the first library it"
    ],
    [
        "NumPy supplies the load_library function as a convenience.",
        "NumPy supplies the load_library"
    ],
    [
        "Allow libname and loader_path to take any",
        "Allow libname and loader_path to take"
    ],
    [
        "Name of the library, which can have 'lib' as a prefix,",
        "Name of the library, which can have 'lib' as a"
    ],
    [
        "Where the library can be found.",
        "Where the library"
    ],
    [
        "If there is no library with the expected extension, or the",
        "If there is no library with the expected extension,"
    ],
    [
        "library is defective and cannot be loaded.",
        "library is defective and cannot"
    ],
    [
        "raise OSError(\"no file with expected extension\")",
        "raise OSError(\"no file with expected"
    ],
    [
        "_flagnames = ['C_CONTIGUOUS', 'F_CONTIGUOUS', 'ALIGNED', 'WRITEABLE',",
        "_flagnames = ['C_CONTIGUOUS', 'F_CONTIGUOUS', 'ALIGNED',"
    ],
    [
        "raise TypeError(\"argument must be an ndarray\")",
        "raise TypeError(\"argument must"
    ],
    [
        "if cls._dtype_ is not None \\",
        "if cls._dtype_ is not None"
    ],
    [
        "raise TypeError(\"array must have data type %s\" % cls._dtype_)",
        "raise TypeError(\"array must have data type %s\" %"
    ],
    [
        "if cls._ndim_ is not None \\",
        "if cls._ndim_ is"
    ],
    [
        "raise TypeError(\"array must have %d dimension(s)\" % cls._ndim_)",
        "raise TypeError(\"array must have %d dimension(s)\""
    ],
    [
        "if cls._shape_ is not None \\",
        "if cls._shape_ is"
    ],
    [
        "raise TypeError(\"array must have shape %s\" % str(cls._shape_))",
        "raise TypeError(\"array must have"
    ],
    [
        "if cls._flags_ is not None \\",
        "if cls._flags_ is not None"
    ],
    [
        "and ((obj.flags.num & cls._flags_) != cls._flags_):",
        "and ((obj.flags.num &"
    ],
    [
        "raise TypeError(\"array must have flags %s\" %",
        "raise TypeError(\"array must have flags %s\""
    ],
    [
        "Like _ndptr, but with `_shape_` and `_dtype_` specified.",
        "Like _ndptr, but with `_shape_` and"
    ],
    [
        "Notably, this means the pointer has enough information to reconstruct",
        "Notably, this means the pointer"
    ],
    [
        "the array, which is not generally true.",
        "the array, which is not"
    ],
    [
        "This method is called when this class is used as the .restype",
        "This method is called when this class"
    ],
    [
        "attribute for a shared-library function, to automatically wrap the",
        "attribute for a shared-library function, to automatically wrap"
    ],
    [
        "Get an ndarray viewing the data pointed to by this pointer.",
        "Get an ndarray viewing the data pointed"
    ],
    [
        "This mirrors the `contents` attribute of a normal ctypes pointer",
        "This mirrors the `contents` attribute of"
    ],
    [
        "An ndpointer instance is used to describe an ndarray in restypes",
        "An ndpointer instance is used to describe"
    ],
    [
        "and argtypes specifications.  This approach is more flexible than",
        "and argtypes specifications. This approach is"
    ],
    [
        "using, for example, ``POINTER(c_double)``, since several restrictions",
        "using, for example, ``POINTER(c_double)``, since"
    ],
    [
        "can be specified, which are verified upon calling the ctypes function.",
        "can be specified, which are verified upon calling"
    ],
    [
        "These include data type, number of dimensions, shape and flags.  If a",
        "These include data type, number of dimensions, shape and flags."
    ],
    [
        "given array does not satisfy the specified restrictions,",
        "given array does not satisfy the"
    ],
    [
        "shape : tuple of ints, optional",
        "shape : tuple of"
    ],
    [
        "flags : str or tuple of str",
        "flags : str or"
    ],
    [
        "Array flags; may be one or more of:",
        "Array flags; may be one or"
    ],
    [
        "- C_CONTIGUOUS / C / CONTIGUOUS",
        "- C_CONTIGUOUS / C /"
    ],
    [
        "- F_CONTIGUOUS / F / FORTRAN",
        "- F_CONTIGUOUS / F"
    ],
    [
        "A type object, which is an ``_ndtpr`` instance containing",
        "A type object, which is an ``_ndtpr`` instance"
    ],
    [
        "dtype, ndim, shape and flags information.",
        "dtype, ndim, shape and flags"
    ],
    [
        "If a given array does not satisfy the specified restrictions.",
        "If a given array does not satisfy"
    ],
    [
        "flags = [x.strip().upper() for x in flags]",
        "flags = [x.strip().upper() for"
    ],
    [
        "raise TypeError(\"invalid flags specification\") from e",
        "raise TypeError(\"invalid flags"
    ],
    [
        "cache_key = (dtype, ndim, shape, num)",
        "cache_key = (dtype,"
    ],
    [
        "name += \"_\" + \"x\".join(str(x) for x in shape)",
        "name += \"_\" + \"x\".join(str(x) for x"
    ],
    [
        "if dtype is not None and shape is not None:",
        "if dtype is not None"
    ],
    [
        "klass = type(\"ndpointer_%s\" % name, (base,),",
        "klass = type(\"ndpointer_%s\""
    ],
    [
        "\"\"\" Create an ndarray of the given element type and shape \"\"\"",
        "\"\"\" Create an ndarray of the given element type and shape"
    ],
    [
        "Return a dictionary mapping native endian scalar dtype to ctypes types",
        "Return a dictionary mapping native endian"
    ],
    [
        "return {np.dtype(ctype): ctype for ctype in simple_types}",
        "return {np.dtype(ctype): ctype for ctype in"
    ],
    [
        "\"Converting {!r} to a ctypes type\".format(dtype)",
        "\"Converting {!r} to a ctypes"
    ],
    [
        "for offset, name, ctype in field_data:",
        "for offset, name, ctype in"
    ],
    [
        "for offset, name, ctype in field_data:",
        "for offset, name,"
    ],
    [
        "Convert a dtype into a ctypes type.",
        "Convert a dtype into a"
    ],
    [
        "A ctype scalar, union, array, or struct",
        "A ctype scalar, union, array, or"
    ],
    [
        "If the conversion is not possible",
        "If the conversion"
    ],
    [
        "This function does not losslessly round-trip in either direction.",
        "This function does not losslessly"
    ],
    [
        "- reorder fields to be sorted by offset",
        "- reorder fields to"
    ],
    [
        "- discard the class names of `ctypes.Structure`\\ s and",
        "- discard the class names of"
    ],
    [
        "- convert single-element `ctypes.Union`\\ s into single-element",
        "- convert single-element `ctypes.Union`\\ s"
    ],
    [
        "Create a numpy array from a ctypes array or POINTER.",
        "Create a numpy array from a ctypes array or"
    ],
    [
        "The numpy array shares the memory with the ctypes object.",
        "The numpy array shares the memory with the ctypes"
    ],
    [
        "The shape parameter must be given if converting from a ctypes POINTER.",
        "The shape parameter must be given if converting from a ctypes"
    ],
    [
        "The shape parameter is ignored if converting from a ctypes array",
        "The shape parameter is ignored if"
    ],
    [
        "'as_array() requires a shape argument when called on a '",
        "'as_array() requires a shape argument when called on"
    ],
    [
        "Create and return a ctypes object from a numpy array.  Actually",
        "Create and return a ctypes object from"
    ],
    [
        "anything that exposes the __array_interface__ is accepted.",
        "anything that exposes the __array_interface__"
    ],
    [
        "Create ctypes object from inferred int ``np.array``:",
        "Create ctypes object from inferred int"
    ],
    [
        "A collection of utilities for `numpy.ma`.",
        "A collection of"
    ],
    [
        "from . import core as ma",
        "from . import core as"
    ],
    [
        "MaskedArray, MAError, add, array, asarray, concatenate, filled, count,",
        "MaskedArray, MAError, add, array, asarray, concatenate, filled,"
    ],
    [
        "getmask, getmaskarray, make_mask_descr, masked, masked_array, mask_or,",
        "getmask, getmaskarray, make_mask_descr, masked,"
    ],
    [
        "nomask, ones, sort, zeros, getdata, get_masked_subclass, dot",
        "nomask, ones, sort, zeros,"
    ],
    [
        "from numpy import ndarray, array as nxarray",
        "from numpy import ndarray, array as"
    ],
    [
        "Is seq a sequence (ndarray, list or tuple)?",
        "Is seq a sequence (ndarray,"
    ],
    [
        "Count the number of masked elements along the given axis.",
        "Count the number of masked elements"
    ],
    [
        "An array with (possibly) masked elements.",
        "An array with (possibly) masked"
    ],
    [
        "Axis along which to count. If None (default), a flattened",
        "Axis along which to count. If None (default), a"
    ],
    [
        "version of the array is used.",
        "version of the"
    ],
    [
        "The total number of masked elements (axis=None) or the number",
        "The total number of masked"
    ],
    [
        "of masked elements along each slice of the given axis.",
        "of masked elements along each slice of the given"
    ],
    [
        "When the `axis` keyword is used an array is returned.",
        "When the `axis` keyword is"
    ],
    [
        "Empty masked array with all elements masked.",
        "Empty masked array with"
    ],
    [
        "Return an empty masked array of the given shape and dtype, where all the",
        "Return an empty masked array of the given shape and dtype, where"
    ],
    [
        "shape : int or tuple of ints",
        "shape : int or tuple of"
    ],
    [
        "A masked array with all data masked.",
        "A masked array with"
    ],
    [
        "masked_all_like : Empty masked array modelled on an existing array.",
        "masked_all_like : Empty masked array modelled on"
    ],
    [
        "Unlike other masked array creation functions (e.g. `numpy.ma.zeros`,",
        "Unlike other masked array creation functions (e.g."
    ],
    [
        "`numpy.ma.ones`, `numpy.ma.full`), `masked_all` does not initialize the",
        "`numpy.ma.ones`, `numpy.ma.full`), `masked_all` does not initialize"
    ],
    [
        "values of the array, and may therefore be marginally faster. However,",
        "values of the array, and may therefore"
    ],
    [
        "the values stored in the newly allocated array are arbitrary. For",
        "the values stored in the newly allocated"
    ],
    [
        "reproducible behavior, be sure to set each element of the array before",
        "reproducible behavior, be sure to set each element"
    ],
    [
        "The `dtype` parameter defines the underlying data type.",
        "The `dtype` parameter defines the underlying"
    ],
    [
        "Empty masked array with the properties of an existing array.",
        "Empty masked array with the"
    ],
    [
        "Return an empty masked array of the same shape and dtype as",
        "Return an empty masked array of the same shape"
    ],
    [
        "the array `arr`, where all the data are masked.",
        "the array `arr`, where all the"
    ],
    [
        "An array describing the shape and dtype of the required MaskedArray.",
        "An array describing the shape and dtype of the"
    ],
    [
        "A masked array with all data masked.",
        "A masked array with all data"
    ],
    [
        "If `arr` doesn't have a shape attribute (i.e. not an ndarray)",
        "If `arr` doesn't have a shape attribute (i.e. not"
    ],
    [
        "masked_all : Empty masked array with all elements masked.",
        "masked_all : Empty masked array with all"
    ],
    [
        "Unlike other masked array creation functions (e.g. `numpy.ma.zeros_like`,",
        "Unlike other masked array creation functions"
    ],
    [
        "initialize the values of the array, and may therefore be marginally",
        "initialize the values of the array, and"
    ],
    [
        "faster. However, the values stored in the newly allocated array are",
        "faster. However, the values stored in"
    ],
    [
        "arbitrary. For reproducible behavior, be sure to set each element of the",
        "arbitrary. For reproducible behavior, be sure to set"
    ],
    [
        "The dtype of the masked array matches the dtype of `arr`.",
        "The dtype of the masked array matches the"
    ],
    [
        "Defines a wrapper to adapt NumPy functions to masked arrays.",
        "Defines a wrapper to adapt NumPy functions to masked"
    ],
    [
        "An instance of `_fromnxfunction` can be called with the same parameters",
        "An instance of `_fromnxfunction` can be called"
    ],
    [
        "as the wrapped NumPy function. The docstring of `newfunc` is adapted from",
        "as the wrapped NumPy function. The docstring of `newfunc`"
    ],
    [
        "the wrapped function as well, see `getdoc`.",
        "the wrapped function as well, see"
    ],
    [
        "This class should not be used directly. Instead, one of its extensions that",
        "This class should not be used directly. Instead,"
    ],
    [
        "provides support for a specific type of input should be used.",
        "provides support for a specific type of input should be"
    ],
    [
        "The name of the function to be adapted. The function should be",
        "The name of the function to"
    ],
    [
        "in the NumPy namespace (i.e. ``np.funcname``).",
        "in the NumPy"
    ],
    [
        "Retrieve the docstring and signature from the function.",
        "Retrieve the docstring and"
    ],
    [
        "The ``__doc__`` attribute of the function is used as the docstring for",
        "The ``__doc__`` attribute of the function is used as the"
    ],
    [
        "the new masked array version of the function. A note on application",
        "the new masked array version of the function. A note"
    ],
    [
        "of the function to the mask is appended.",
        "of the function to the"
    ],
    [
        "doc = ma.doc_note(doc, \"The function is applied to both the _data \"",
        "doc = ma.doc_note(doc, \"The function is"
    ],
    [
        "sig = self.__name__ + sig + \"\\n\\n\"",
        "sig = self.__name__ + sig"
    ],
    [
        "A version of `_fromnxfunction` that is called with a single array",
        "A version of `_fromnxfunction` that is called with a"
    ],
    [
        "argument followed by auxiliary args that are passed verbatim for",
        "argument followed by auxiliary args that"
    ],
    [
        "both the data and mask calls.",
        "both the data and"
    ],
    [
        "A version of `_fromnxfunction` that is called with a single sequence",
        "A version of `_fromnxfunction` that is called with a single"
    ],
    [
        "of arrays followed by auxiliary args that are passed verbatim for",
        "of arrays followed by auxiliary args that are"
    ],
    [
        "both the data and mask calls.",
        "both the data and mask"
    ],
    [
        "_d = func(tuple(np.asarray(a) for a in x), *args, **params)",
        "_d = func(tuple(np.asarray(a) for a"
    ],
    [
        "_m = func(tuple(getmaskarray(a) for a in x), *args, **params)",
        "_m = func(tuple(getmaskarray(a) for a in"
    ],
    [
        "A version of `_fromnxfunction` that is called with multiple array",
        "A version of `_fromnxfunction` that"
    ],
    [
        "arguments. The first non-array-like input marks the beginning of the",
        "arguments. The first non-array-like input marks the"
    ],
    [
        "arguments that are passed verbatim for both the data and mask calls.",
        "arguments that are passed verbatim for both"
    ],
    [
        "Array arguments are processed independently and the results are",
        "Array arguments are processed independently"
    ],
    [
        "returned in a list. If only one array is found, the return value is",
        "returned in a list. If only one array is"
    ],
    [
        "just the processed array instead of a list.",
        "just the processed array instead"
    ],
    [
        "A version of `_fromnxfunction` that is called with multiple array",
        "A version of `_fromnxfunction` that is called"
    ],
    [
        "arguments. Similar to `_fromnxfunction_args` except that all args",
        "arguments. Similar to `_fromnxfunction_args`"
    ],
    [
        "are converted to arrays even if they are not so already. This makes",
        "are converted to arrays even if they are not"
    ],
    [
        "are passed through verbatim for the data and mask calls. Arrays",
        "are passed through verbatim for the data and"
    ],
    [
        "arguments are processed independently and the results are returned",
        "arguments are processed independently and the results"
    ],
    [
        "in a list. If only one arg is present, the return value is just the",
        "in a list. If only one arg is present, the"
    ],
    [
        "processed array instead of a list.",
        "processed array instead"
    ],
    [
        "j[axis] = ([slice(None, None)] * res.ndim)",
        "j[axis] = ([slice(None, None)] *"
    ],
    [
        "raise ValueError(\"function is not returning \"",
        "raise ValueError(\"function is not returning"
    ],
    [
        "\"an array of the correct shape\")",
        "\"an array of"
    ],
    [
        "Tuple axis arguments to ufuncs are equivalent:",
        "Tuple axis arguments to ufuncs"
    ],
    [
        "def average(a, axis=None, weights=None, returned=False, *,",
        "def average(a, axis=None, weights=None,"
    ],
    [
        "Return the weighted average of array over the given axis.",
        "Return the weighted average of array over the given"
    ],
    [
        "Masked entries are not taken into account in the computation.",
        "Masked entries are not taken into account in the"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple"
    ],
    [
        "Axis or axes along which to average `a`.  The default,",
        "Axis or axes along which to average `a`."
    ],
    [
        "`axis=None`, will average over all of the elements of the input array.",
        "`axis=None`, will average over all of the elements"
    ],
    [
        "If axis is a tuple of ints, averaging is performed on all of the axes",
        "If axis is a tuple of ints, averaging is performed on all of the"
    ],
    [
        "specified in the tuple instead of a single axis or all the axes as",
        "specified in the tuple instead of a single axis or all the axes"
    ],
    [
        "An array of weights associated with the values in `a`. Each value in",
        "An array of weights associated with the values in `a`. Each value"
    ],
    [
        "`a` contributes to the average according to its associated weight.",
        "`a` contributes to the average"
    ],
    [
        "The array of weights must be the same shape as `a` if no axis is",
        "The array of weights must be the same shape as"
    ],
    [
        "specified, otherwise the weights must have dimensions and shape",
        "specified, otherwise the weights must"
    ],
    [
        "consistent with `a` along the specified axis.",
        "consistent with `a` along the specified"
    ],
    [
        "If `weights=None`, then all data in `a` are assumed to have a",
        "If `weights=None`, then all data in `a`"
    ],
    [
        "avg = sum(a * weights) / sum(weights)",
        "avg = sum(a * weights) /"
    ],
    [
        "where the sum is over all included elements.",
        "where the sum is over"
    ],
    [
        "The only constraint on the values of `weights` is that `sum(weights)`",
        "The only constraint on the values of"
    ],
    [
        "Flag indicating whether a tuple ``(result, sum of weights)``",
        "Flag indicating whether a tuple"
    ],
    [
        "should be returned as output (True), or just the result (False).",
        "should be returned as output (True), or just the"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly against the"
    ],
    [
        "*Note:* `keepdims` will not work with instances of `numpy.matrix`",
        "*Note:* `keepdims` will not work with"
    ],
    [
        "or other classes whose methods do not support `keepdims`.",
        "or other classes whose methods"
    ],
    [
        "average, [sum_of_weights] : (tuple of) scalar or MaskedArray",
        "average, [sum_of_weights] : (tuple of) scalar"
    ],
    [
        "The average along the specified axis. When returned is `True`,",
        "The average along the specified axis. When returned is"
    ],
    [
        "return a tuple with the average as the first element and the sum",
        "return a tuple with the average as the first element and the"
    ],
    [
        "input data-type, otherwise. If returned, `sum_of_weights` is always",
        "input data-type, otherwise. If returned,"
    ],
    [
        "When all weights along axis are zero. See `numpy.ma.average` for a",
        "When all weights along axis are zero. See `numpy.ma.average` for"
    ],
    [
        "version robust to this type of error.",
        "version robust to this"
    ],
    [
        "When `weights` does not have the same shape as `a`, and `axis=None`.",
        "When `weights` does not have the same shape as"
    ],
    [
        "When `weights` does not have dimensions and shape consistent with `a`",
        "When `weights` does not have dimensions and shape consistent with"
    ],
    [
        "ValueError: Shape of weights must be consistent",
        "ValueError: Shape of weights must"
    ],
    [
        "with shape of a along specified axis.",
        "with shape of a"
    ],
    [
        "\"Axis must be specified when shapes of a and weights \"",
        "\"Axis must be specified when shapes of a"
    ],
    [
        "if wgt.shape != tuple(a.shape[ax] for ax in axis):",
        "if wgt.shape != tuple(a.shape[ax] for ax"
    ],
    [
        "\"Shape of weights must be consistent with \"",
        "\"Shape of weights must be consistent with"
    ],
    [
        "\"shape of a along specified axis.\")",
        "\"shape of a"
    ],
    [
        "def median(a, axis=None, out=None, overwrite_input=False, keepdims=False):",
        "def median(a, axis=None, out=None,"
    ],
    [
        "Compute the median along the specified axis.",
        "Compute the median along the"
    ],
    [
        "Returns the median of the array elements.",
        "Returns the median of the array"
    ],
    [
        "Input array or object that can be converted to an array.",
        "Input array or object that can be"
    ],
    [
        "Axis along which the medians are computed. The default (None) is",
        "Axis along which the medians are computed."
    ],
    [
        "to compute the median along a flattened version of the array.",
        "to compute the median along a flattened"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the result."
    ],
    [
        "have the same shape and buffer length as the expected output",
        "have the same shape and buffer"
    ],
    [
        "but the type will be cast if necessary.",
        "but the type will be"
    ],
    [
        "If True, then allow use of memory of input array (a) for",
        "If True, then allow use of memory of input array (a)"
    ],
    [
        "calculations. The input array will be modified by the call to",
        "calculations. The input array will be modified by the call"
    ],
    [
        "median. This will save memory when you do not need to preserve",
        "median. This will save memory when you do not need"
    ],
    [
        "the contents of the input array. Treat the input as undefined,",
        "the contents of the input array. Treat the"
    ],
    [
        "but it will probably be fully or partially sorted. Default is",
        "but it will probably be fully"
    ],
    [
        "False. Note that, if `overwrite_input` is True, and the input",
        "False. Note that, if `overwrite_input`"
    ],
    [
        "is not already an `ndarray`, an error will be raised.",
        "is not already an `ndarray`, an error will be"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With this"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against"
    ],
    [
        "A new array holding the result is returned unless out is",
        "A new array holding the result is"
    ],
    [
        "specified, in which case a reference to out is returned.",
        "specified, in which case a"
    ],
    [
        "Given a vector ``V`` with ``N`` non masked values, the median of ``V``",
        "Given a vector ``V`` with ``N`` non masked values, the median"
    ],
    [
        "is the middle value of a sorted copy of ``V`` (``Vs``) - i.e.",
        "is the middle value of a sorted"
    ],
    [
        "return _ureduce(a, func=_median, keepdims=keepdims, axis=axis, out=out,",
        "return _ureduce(a, func=_median, keepdims=keepdims,"
    ],
    [
        "rep = (~np.all(asorted.mask, axis=axis, keepdims=True)) & s.mask",
        "rep = (~np.all(asorted.mask, axis=axis, keepdims=True)) &"
    ],
    [
        "\"\"\"Suppress slices from multiple dimensions which contain masked values.",
        "\"\"\"Suppress slices from multiple dimensions which"
    ],
    [
        "The array to operate on. If not a MaskedArray instance (or if no array",
        "The array to operate on. If not"
    ],
    [
        "elements are masked), `x` is interpreted as a MaskedArray with `mask`",
        "elements are masked), `x` is interpreted as a MaskedArray with"
    ],
    [
        "axis : tuple of ints or int, optional",
        "axis : tuple of ints or int,"
    ],
    [
        "Which dimensions to suppress slices from can be configured with this",
        "Which dimensions to suppress slices from can be configured with"
    ],
    [
        "- If axis is a tuple of ints, those are the axes to suppress slices from.",
        "- If axis is a tuple of ints, those are the axes to suppress"
    ],
    [
        "- If axis is an int, then that is the only axis to suppress slices from.",
        "- If axis is an int, then that is the only axis to suppress slices"
    ],
    [
        "- If axis is None, all axis are selected.",
        "- If axis is None,"
    ],
    [
        "if m is nomask or not m.any():",
        "if m is nomask or not"
    ],
    [
        "data = data[(slice(None),) * ax + (~m.any(axis=axes),)]",
        "data = data[(slice(None),) * ax +"
    ],
    [
        "The suppression behavior is selected with the `axis` parameter.",
        "The suppression behavior is selected with"
    ],
    [
        "- If axis is None, both rows and columns are suppressed.",
        "- If axis is None, both rows and"
    ],
    [
        "The array to operate on.  If not a MaskedArray instance (or if no array",
        "The array to operate on. If not a MaskedArray instance"
    ],
    [
        "elements are masked), `x` is interpreted as a MaskedArray with",
        "elements are masked), `x` is interpreted as a MaskedArray"
    ],
    [
        "Axis along which to perform the operation. Default is None.",
        "Axis along which to perform the"
    ],
    [
        "The array to operate on. If not a MaskedArray instance (or if no array",
        "The array to operate on. If not a MaskedArray"
    ],
    [
        "elements are masked), `x` is interpreted as a MaskedArray with",
        "elements are masked), `x` is interpreted as a"
    ],
    [
        "The array to operate on.  If not a MaskedArray instance (or if no array",
        "The array to operate on. If not a MaskedArray"
    ],
    [
        "elements are masked), `x` is interpreted as a MaskedArray with",
        "elements are masked), `x` is interpreted as a"
    ],
    [
        "masked values.  The masking behavior is selected using the",
        "masked values. The masking behavior is selected"
    ],
    [
        "- If `axis` is None, rows *and* columns are masked.",
        "- If `axis` is None,"
    ],
    [
        "The array to mask.  If not a MaskedArray instance (or if no array",
        "The array to mask. If not a"
    ],
    [
        "elements are masked), the result is a MaskedArray with `mask` set",
        "elements are masked), the result is a MaskedArray with"
    ],
    [
        "Axis along which to perform the operation. If None, applies to a",
        "Axis along which to perform the operation. If None, applies to"
    ],
    [
        "A modified version of the input array, masked depending on the value",
        "A modified version of the input array, masked depending"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a condition"
    ],
    [
        "The input array's mask is modified by this function.",
        "The input array's mask is modified"
    ],
    [
        "if m is nomask or not m.any():",
        "if m is nomask or not"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where"
    ],
    [
        "\"The axis argument has always been ignored, in future passing it \"",
        "\"The axis argument has always been ignored, in"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a condition"
    ],
    [
        "\"The axis argument has always been ignored, in future passing it \"",
        "\"The axis argument has always been"
    ],
    [
        "Compute the differences between consecutive elements of an array.",
        "Compute the differences between consecutive elements of"
    ],
    [
        "Finds the unique elements of an array.",
        "Finds the unique elements of"
    ],
    [
        "Masked values are considered the same element (masked). The output array",
        "Masked values are considered the same"
    ],
    [
        "is always a masked array. See `numpy.unique` for more details.",
        "is always a masked array. See"
    ],
    [
        "numpy.unique : Equivalent function for ndarrays.",
        "numpy.unique : Equivalent function for"
    ],
    [
        "Returns the unique elements common to both arrays.",
        "Returns the unique elements common"
    ],
    [
        "Masked values are considered equal one to the other.",
        "Masked values are considered equal"
    ],
    [
        "The output is always a masked array.",
        "The output is always a"
    ],
    [
        "Test whether each element of an array is also present in a second",
        "Test whether each element of an array is also present in"
    ],
    [
        "masked_array(data=[ True, False,  True, False,  True],",
        "masked_array(data=[ True, False,"
    ],
    [
        "Calculates `element in test_elements`, broadcasting over",
        "Calculates `element in"
    ],
    [
        "The output is always a masked array of the same shape as `element`.",
        "The output is always a masked array of the same shape as"
    ],
    [
        "numpy.isin : Equivalent function for ndarrays.",
        "numpy.isin : Equivalent function for"
    ],
    [
        "masked_array(data=[False,  True, False, False, False, False],",
        "masked_array(data=[False, True, False, False, False,"
    ],
    [
        "Private function for the computation of covariance and correlation",
        "Private function for the computation"
    ],
    [
        "xmask = x._mask = y._mask = ymask = common_mask",
        "xmask = x._mask = y._mask"
    ],
    [
        "def cov(x, y=None, rowvar=True, bias=False, allow_masked=True, ddof=None):",
        "def cov(x, y=None, rowvar=True, bias=False, allow_masked=True,"
    ],
    [
        "Except for the handling of missing data this function does the same as",
        "Except for the handling of missing data this function"
    ],
    [
        "`numpy.cov`. For more details and examples, see `numpy.cov`.",
        "`numpy.cov`. For more details and examples,"
    ],
    [
        "By default, masked values are recognized as such. If `x` and `y` have the",
        "By default, masked values are recognized as such. If `x` and"
    ],
    [
        "same shape, a common mask is allocated: if ``x[i,j]`` is masked, then",
        "same shape, a common mask is"
    ],
    [
        "Setting `allow_masked` to False will raise an exception if values are",
        "Setting `allow_masked` to False will raise an exception"
    ],
    [
        "missing in either of the input arrays.",
        "missing in either of the"
    ],
    [
        "Each row of `x` represents a variable, and each column a single",
        "Each row of `x` represents a variable,"
    ],
    [
        "observation of all those variables. Also see `rowvar` below.",
        "observation of all those variables."
    ],
    [
        "An additional set of variables and observations. `y` has the same",
        "An additional set of variables and observations. `y`"
    ],
    [
        "If `rowvar` is True (default), then each row represents a",
        "If `rowvar` is True (default), then"
    ],
    [
        "variable, with observations in the columns. Otherwise, the relationship",
        "variable, with observations in the columns. Otherwise,"
    ],
    [
        "is transposed: each column represents a variable, while the rows",
        "is transposed: each column represents a"
    ],
    [
        "number of observations given (unbiased estimate). If `bias` is True,",
        "number of observations given (unbiased estimate). If `bias` is"
    ],
    [
        "then normalization is by ``N``. This keyword can be overridden by",
        "then normalization is by ``N``. This keyword can be"
    ],
    [
        "If True, masked values are propagated pair-wise: if a value is masked",
        "If True, masked values are propagated"
    ],
    [
        "in `x`, the corresponding value is masked in `y`.",
        "in `x`, the corresponding value is"
    ],
    [
        "If False, raises a `ValueError` exception when some values are missing.",
        "If False, raises a `ValueError` exception"
    ],
    [
        "If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is",
        "If not ``None`` normalization is by ``(N - ddof)``,"
    ],
    [
        "the number of observations; this overrides the value implied by",
        "the number of observations; this overrides the value"
    ],
    [
        "``bias``. The default value is ``None``.",
        "``bias``. The default value"
    ],
    [
        "Raised if some values are missing and `allow_masked` is False.",
        "Raised if some values are missing and `allow_masked`"
    ],
    [
        "if ddof is not None and ddof != int(ddof):",
        "if ddof is not None and"
    ],
    [
        "raise ValueError(\"ddof must be an integer\")",
        "raise ValueError(\"ddof must be"
    ],
    [
        "(x, xnotmask, rowvar) = _covhelper(x, y, rowvar, allow_masked)",
        "(x, xnotmask, rowvar) ="
    ],
    [
        "fact = np.dot(xnotmask.T, xnotmask) - ddof",
        "fact = np.dot(xnotmask.T, xnotmask)"
    ],
    [
        "fact = np.dot(xnotmask, xnotmask.T) - ddof",
        "fact = np.dot(xnotmask, xnotmask.T)"
    ],
    [
        "def corrcoef(x, y=None, rowvar=True, bias=np._NoValue, allow_masked=True,",
        "def corrcoef(x, y=None, rowvar=True, bias=np._NoValue,"
    ],
    [
        "Except for the handling of missing data this function does the same as",
        "Except for the handling of missing data this function"
    ],
    [
        "`numpy.corrcoef`. For more details and examples, see `numpy.corrcoef`.",
        "`numpy.corrcoef`. For more details"
    ],
    [
        "Each row of `x` represents a variable, and each column a single",
        "Each row of `x` represents a"
    ],
    [
        "observation of all those variables. Also see `rowvar` below.",
        "observation of all those variables. Also see `rowvar`"
    ],
    [
        "An additional set of variables and observations. `y` has the same",
        "An additional set of variables and observations. `y`"
    ],
    [
        "If `rowvar` is True (default), then each row represents a",
        "If `rowvar` is True (default), then each"
    ],
    [
        "variable, with observations in the columns. Otherwise, the relationship",
        "variable, with observations in the columns. Otherwise, the"
    ],
    [
        "is transposed: each column represents a variable, while the rows",
        "is transposed: each column represents"
    ],
    [
        "Has no effect, do not use.",
        "Has no effect, do"
    ],
    [
        "If True, masked values are propagated pair-wise: if a value is masked",
        "If True, masked values are propagated"
    ],
    [
        "in `x`, the corresponding value is masked in `y`.",
        "in `x`, the corresponding value"
    ],
    [
        "If False, raises an exception.  Because `bias` is deprecated, this",
        "If False, raises an exception. Because `bias` is deprecated,"
    ],
    [
        "argument needs to be treated as keyword only to avoid a warning.",
        "argument needs to be treated as keyword only"
    ],
    [
        "Has no effect, do not use.",
        "Has no effect,"
    ],
    [
        "numpy.corrcoef : Equivalent function in top-level NumPy module.",
        "numpy.corrcoef : Equivalent function"
    ],
    [
        "cov : Estimate the covariance matrix.",
        "cov : Estimate"
    ],
    [
        "This function accepts but discards arguments `bias` and `ddof`.  This is",
        "This function accepts but discards arguments `bias` and"
    ],
    [
        "for backwards compatibility with previous versions of this function.  These",
        "for backwards compatibility with previous versions of this function."
    ],
    [
        "arguments had no effect on the return values of the function and can be",
        "arguments had no effect on the return values of the function"
    ],
    [
        "safely ignored in this and previous versions of numpy.",
        "safely ignored in this and previous versions of"
    ],
    [
        "msg = 'bias and ddof have no effect and are deprecated'",
        "msg = 'bias and ddof have no effect"
    ],
    [
        "if bias is not np._NoValue or ddof is not np._NoValue:",
        "if bias is not np._NoValue or ddof is not"
    ],
    [
        "corr = cov(x, y, rowvar, allow_masked=allow_masked)",
        "corr = cov(x,"
    ],
    [
        "Translate slice objects to concatenation along an axis.",
        "Translate slice objects to concatenation along"
    ],
    [
        "For documentation on usage, see `mr_class`.",
        "For documentation on"
    ],
    [
        "Translate slice objects to concatenation along the first axis.",
        "Translate slice objects to concatenation along the"
    ],
    [
        "This is the masked array version of `r_`.",
        "This is the masked array version"
    ],
    [
        "Return an iterator yielding pairs of array coordinates and values,",
        "Return an iterator yielding pairs of"
    ],
    [
        "skipping elements that are masked. With `compressed=False`,",
        "skipping elements that are masked."
    ],
    [
        "`ma.masked` is yielded as the value of masked elements. This",
        "`ma.masked` is yielded as the value of"
    ],
    [
        "behavior differs from that of `numpy.ndenumerate`, which yields the",
        "behavior differs from that of `numpy.ndenumerate`, which"
    ],
    [
        "value of the underlying data array.",
        "value of the underlying data"
    ],
    [
        "An array with (possibly) masked elements.",
        "An array with (possibly)"
    ],
    [
        "If True (default), masked elements are skipped.",
        "If True (default), masked elements"
    ],
    [
        "numpy.ndenumerate : Equivalent function ignoring any mask.",
        "numpy.ndenumerate : Equivalent function ignoring any"
    ],
    [
        ">>> for index, x in np.ma.ndenumerate(a):",
        ">>> for index, x in"
    ],
    [
        ">>> for index, x in np.ma.ndenumerate(a, compressed=False):",
        ">>> for index, x"
    ],
    [
        "for it, mask in zip(np.ndenumerate(a), getmaskarray(a).flat):",
        "for it, mask in"
    ],
    [
        "Find the indices of the first and last unmasked values.",
        "Find the indices of the"
    ],
    [
        "The indices of first and last non-masked value in the array.",
        "The indices of first and last non-masked value"
    ],
    [
        "Returns None if all values are masked.",
        "Returns None if all"
    ],
    [
        "if m is nomask or not np.any(m):",
        "if m is nomask or"
    ],
    [
        "Find the indices of the first and last unmasked values along an axis.",
        "Find the indices of the first and last"
    ],
    [
        "If all values are masked, return None.  Otherwise, return a list",
        "If all values are masked, return"
    ],
    [
        "of two tuples, corresponding to the indices of the first and last",
        "of two tuples, corresponding to the"
    ],
    [
        "Axis along which to perform the operation.",
        "Axis along which to perform the"
    ],
    [
        "If None (default), applies to a flattened version of the array.",
        "If None (default), applies to a flattened"
    ],
    [
        "An array of start and end indexes if there are any masked data in",
        "An array of start and end indexes if there"
    ],
    [
        "the array. If there are no masked data in the array, `edges` is a",
        "the array. If there are no masked"
    ],
    [
        "list of the first and last index.",
        "list of the first"
    ],
    [
        "idx = array(np.indices(a.shape), mask=np.asarray([m] * a.ndim))",
        "idx = array(np.indices(a.shape), mask=np.asarray([m] *"
    ],
    [
        "return [tuple(idx[i].min(axis).compressed() for i in range(a.ndim)),",
        "return [tuple(idx[i].min(axis).compressed() for i in"
    ],
    [
        "tuple(idx[i].max(axis).compressed() for i in range(a.ndim)), ]",
        "tuple(idx[i].max(axis).compressed() for i in range(a.ndim)),"
    ],
    [
        "Find contiguous unmasked data in a masked array.",
        "Find contiguous unmasked data"
    ],
    [
        "A sorted sequence of `slice` objects (start index, end index).",
        "A sorted sequence of `slice` objects (start index,"
    ],
    [
        "Find contiguous unmasked data in a masked array along the given axis.",
        "Find contiguous unmasked data in a"
    ],
    [
        "Axis along which to perform the operation.",
        "Axis along which to perform the"
    ],
    [
        "If None (default), applies to a flattened version of the array, and this",
        "If None (default), applies to a flattened version of the"
    ],
    [
        "A list of slices (start and end indexes) of unmasked indexes",
        "A list of slices (start and end"
    ],
    [
        "(A \"clump\" is defined as a contiguous region of the array).",
        "(A \"clump\" is defined as a contiguous region"
    ],
    [
        "The list of slices, one for each continuous region of unmasked",
        "The list of slices, one for"
    ],
    [
        "(A \"clump\" is defined as a contiguous region of the array).",
        "(A \"clump\" is defined as a contiguous region of the"
    ],
    [
        "The list of slices, one for each continuous region of masked elements",
        "The list of slices, one for each continuous region of"
    ],
    [
        "Masked values in the input array result in rows of zeros.",
        "Masked values in the input array result in"
    ],
    [
        "def polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False):",
        "def polyfit(x, y, deg,"
    ],
    [
        "Any masked values in x is propagated in y, and vice-versa.",
        "Any masked values in x is propagated in"
    ],
    [
        "raise TypeError(\"expected w and y to have the same length\")",
        "raise TypeError(\"expected w and y to have the"
    ],
    [
        "return np.polyfit(x[not_m], y[not_m], deg, rcond, full, w, cov)",
        "return np.polyfit(x[not_m], y[not_m], deg,"
    ],
    [
        "return np.polyfit(x, y, deg, rcond, full, w, cov)",
        "return np.polyfit(x, y, deg, rcond,"
    ],
    [
        "\"\"\"Miscellaneous functions for testing masked arrays and subclasses",
        "\"\"\"Miscellaneous functions for testing"
    ],
    [
        "from .core import mask_or, getmask, masked_array, nomask, masked, filled",
        "from .core import mask_or, getmask,"
    ],
    [
        "Returns true if all components of a and b are equal to given tolerances.",
        "Returns true if all components of a and b are"
    ],
    [
        "If fill_value is True, masked values considered equal. Otherwise,",
        "If fill_value is True, masked values considered"
    ],
    [
        "masked values are considered unequal.  The relative error rtol should",
        "masked values are considered unequal. The"
    ],
    [
        "those elements of b that are very small or zero; it says how small a",
        "those elements of b that are very small or zero; it"
    ],
    [
        "d = np.less_equal(umath.absolute(x - y), atol + rtol * umath.absolute(y))",
        "d = np.less_equal(umath.absolute(x - y), atol"
    ],
    [
        "Returns True if a and b are equal up to decimal places.",
        "Returns True if a and b are"
    ],
    [
        "If fill_value is True, masked values considered equal. Otherwise,",
        "If fill_value is True, masked values considered"
    ],
    [
        "Asserts the equality of two non-array sequences.",
        "Asserts the equality of two non-array"
    ],
    [
        "Asserts that two records are equal.",
        "Asserts that two"
    ],
    [
        "(af, bf) = (operator.getitem(a, f), operator.getitem(b, f))",
        "(af, bf) = (operator.getitem(a,"
    ],
    [
        "if not (af is masked) and not (bf is masked):",
        "if not (af is masked)"
    ],
    [
        "Asserts that two items are equal.",
        "Asserts that two items are"
    ],
    [
        "if isinstance(desired, (list, tuple)) and isinstance(actual, (list, tuple)):",
        "if isinstance(desired, (list, tuple)) and"
    ],
    [
        "if not (isinstance(actual, ndarray) or isinstance(desired, ndarray)):",
        "if not (isinstance(actual, ndarray) or isinstance(desired,"
    ],
    [
        "if ((actual is masked) and not (desired is masked)) or \\",
        "if ((actual is masked) and not (desired is masked)) or"
    ],
    [
        "((desired is masked) and not (actual is masked)):",
        "((desired is masked) and not (actual"
    ],
    [
        "if actual_dtype.char == \"S\" and desired_dtype.char == \"S\":",
        "if actual_dtype.char == \"S\" and"
    ],
    [
        "Raises an assertion error if two items are equal.",
        "Raises an assertion error if two items are"
    ],
    [
        "if isinstance(desired, (list, tuple)) and isinstance(actual, (list, tuple)):",
        "if isinstance(desired, (list, tuple)) and isinstance(actual, (list,"
    ],
    [
        "if isinstance(actual, np.ndarray) or isinstance(desired, np.ndarray):",
        "if isinstance(actual, np.ndarray) or isinstance(desired,"
    ],
    [
        "Asserts that two items are almost equal.",
        "Asserts that two items are almost"
    ],
    [
        "if isinstance(actual, np.ndarray) or isinstance(desired, np.ndarray):",
        "if isinstance(actual, np.ndarray)"
    ],
    [
        "def assert_array_compare(comparison, x, y, err_msg='', verbose=True, header='',",
        "def assert_array_compare(comparison, x, y, err_msg='', verbose=True,"
    ],
    [
        "Asserts that comparison between two masked arrays is satisfied.",
        "Asserts that comparison between two masked"
    ],
    [
        "x = masked_array(x, copy=False, mask=m, keep_mask=False, subok=False)",
        "x = masked_array(x, copy=False,"
    ],
    [
        "y = masked_array(y, copy=False, mask=m, keep_mask=False, subok=False)",
        "y = masked_array(y, copy=False,"
    ],
    [
        "if ((x is masked) and not (y is masked)) or \\",
        "if ((x is masked) and not (y"
    ],
    [
        "((y is masked) and not (x is masked)):",
        "((y is masked) and not"
    ],
    [
        "msg = build_err_msg([x, y], err_msg=err_msg, verbose=verbose,",
        "msg = build_err_msg([x, y], err_msg=err_msg,"
    ],
    [
        "Checks the elementwise equality of two masked arrays.",
        "Checks the elementwise equality of two masked"
    ],
    [
        "Raises an assertion error if two masked arrays are not equal elementwise.",
        "Raises an assertion error if two masked arrays are not"
    ],
    [
        "Checks the equality of two masked arrays, up to given number odecimals.",
        "Checks the equality of two masked arrays, up to given"
    ],
    [
        "\"Returns the result of the loose comparison between x and y).\"",
        "\"Returns the result of the loose comparison between x"
    ],
    [
        "Checks the equality of two masked arrays, up to given number odecimals.",
        "Checks the equality of two masked"
    ],
    [
        "\"Returns the result of the loose comparison between x and y).\"",
        "\"Returns the result of the loose"
    ],
    [
        "Checks that x is smaller than y elementwise.",
        "Checks that x is smaller than y"
    ],
    [
        "Asserts the equality of two masks.",
        "Asserts the equality of two"
    ],
    [
        "Arrays sometimes contain invalid or missing data.  When doing operations",
        "Arrays sometimes contain invalid or"
    ],
    [
        "on such arrays, we wish to suppress invalid values, which is the purpose masked",
        "on such arrays, we wish to suppress invalid values, which is the"
    ],
    [
        "arrays fulfill (an example of typical use is given below).",
        "arrays fulfill (an example of typical use is given"
    ],
    [
        "For example, examine the following array:",
        "For example, examine the"
    ],
    [
        "When we try to calculate the mean of the data, the result is undetermined:",
        "When we try to calculate the mean of"
    ],
    [
        "The mean is calculated using roughly ``np.sum(x)/len(x)``, but since",
        "The mean is calculated using roughly ``np.sum(x)/len(x)``, but"
    ],
    [
        "mask=[False, False, False, True, False, False, False, True],",
        "mask=[False, False, False, True,"
    ],
    [
        "Here, we construct a masked array that suppress all ``NaN`` values.  We",
        "Here, we construct a masked array that suppress all ``NaN``"
    ],
    [
        "may now proceed to calculate the mean of the other values:",
        "may now proceed to calculate the mean of"
    ],
    [
        "numpy.ma : a package to handle missing or invalid values.",
        "numpy.ma : a package to handle missing"
    ],
    [
        "This package was initially written for numarray by Paul F. Dubois",
        "This package was initially written for"
    ],
    [
        "(University of Georgia) to make the MaskedArray class a subclass of ndarray,",
        "(University of Georgia) to make the MaskedArray class a"
    ],
    [
        "and to improve support of structured arrays.",
        "and to improve support"
    ],
    [
        "* Improvements suggested by Reggie Dugard (reggie_AT_merfinllc_DOT_com)",
        "* Improvements suggested by Reggie Dugard"
    ],
    [
        "from numpy._core import multiarray as mu",
        "from numpy._core import"
    ],
    [
        "from numpy import ndarray, amax, amin, iscomplexobj, bool_, _NoValue, angle",
        "from numpy import ndarray, amax, amin,"
    ],
    [
        "from numpy import array as narray, expand_dims, iinfo, finfo",
        "from numpy import array as narray, expand_dims, iinfo,"
    ],
    [
        "'MAError', 'MaskError', 'MaskType', 'MaskedArray', 'abs', 'absolute',",
        "'MAError', 'MaskError', 'MaskType', 'MaskedArray',"
    ],
    [
        "'add', 'all', 'allclose', 'allequal', 'alltrue', 'amax', 'amin',",
        "'add', 'all', 'allclose', 'allequal', 'alltrue',"
    ],
    [
        "'angle', 'anom', 'anomalies', 'any', 'append', 'arange', 'arccos',",
        "'angle', 'anom', 'anomalies', 'any', 'append',"
    ],
    [
        "'argmax', 'argmin', 'argsort', 'around', 'array', 'asanyarray',",
        "'argmax', 'argmin', 'argsort', 'around', 'array',"
    ],
    [
        "'asarray', 'bitwise_and', 'bitwise_or', 'bitwise_xor', 'bool_', 'ceil',",
        "'asarray', 'bitwise_and', 'bitwise_or', 'bitwise_xor', 'bool_',"
    ],
    [
        "'concatenate', 'conjugate', 'convolve', 'copy', 'correlate', 'cos', 'cosh',",
        "'concatenate', 'conjugate', 'convolve', 'copy',"
    ],
    [
        "'count', 'cumprod', 'cumsum', 'default_fill_value', 'diag', 'diagonal',",
        "'count', 'cumprod', 'cumsum', 'default_fill_value', 'diag',"
    ],
    [
        "'diff', 'divide', 'empty', 'empty_like', 'equal', 'exp',",
        "'diff', 'divide', 'empty', 'empty_like', 'equal',"
    ],
    [
        "'identity', 'ids', 'indices', 'inner', 'innerproduct', 'isMA',",
        "'identity', 'ids', 'indices', 'inner', 'innerproduct',"
    ],
    [
        "'mod', 'multiply', 'mvoid', 'ndim', 'negative', 'nomask', 'nonzero',",
        "'mod', 'multiply', 'mvoid', 'ndim', 'negative',"
    ],
    [
        "'not_equal', 'ones', 'ones_like', 'outer', 'outerproduct', 'power', 'prod',",
        "'not_equal', 'ones', 'ones_like', 'outer',"
    ],
    [
        "'product', 'ptp', 'put', 'putmask', 'ravel', 'remainder',",
        "'product', 'ptp', 'put',"
    ],
    [
        "'repeat', 'reshape', 'resize', 'right_shift', 'round', 'round_',",
        "'repeat', 'reshape', 'resize', 'right_shift', 'round',"
    ],
    [
        "'set_fill_value', 'shape', 'sin', 'sinh', 'size', 'soften_mask',",
        "'set_fill_value', 'shape', 'sin', 'sinh',"
    ],
    [
        "'sometrue', 'sort', 'sqrt', 'squeeze', 'std', 'subtract', 'sum',",
        "'sometrue', 'sort', 'sqrt', 'squeeze', 'std', 'subtract',"
    ],
    [
        "'swapaxes', 'take', 'tan', 'tanh', 'trace', 'transpose', 'true_divide',",
        "'swapaxes', 'take', 'tan', 'tanh', 'trace', 'transpose',"
    ],
    [
        "Adjust the axis passed to argsort, warning if necessary",
        "Adjust the axis passed to argsort,"
    ],
    [
        "The array which argsort was called on",
        "The array which argsort was called"
    ],
    [
        "np.ma.argsort has a long-term bug where the default of the axis argument",
        "np.ma.argsort has a long-term bug where the"
    ],
    [
        "dimensional, so we only need a warning then.",
        "dimensional, so we only"
    ],
    [
        "\"current None, to match its documentation and np.argsort. \"",
        "\"current None, to match its documentation"
    ],
    [
        "Adds a Notes section to an existing docstring.",
        "Adds a Notes section to"
    ],
    [
        "Class for masked array related errors.",
        "Class for masked array related"
    ],
    [
        "for v in [\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \"ps\",",
        "for v in [\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\","
    ],
    [
        "float_types_list = [np.half, np.single, np.double, np.longdouble,",
        "float_types_list = [np.half, np.single,"
    ],
    [
        "Recursively produce a fill value for `dtype`, calling f on scalar dtypes",
        "Recursively produce a fill value for `dtype`,"
    ],
    [
        "\"\"\" Convert the argument for *_fill_value into a dtype \"\"\"",
        "\"\"\" Convert the argument for"
    ],
    [
        "Return the default fill value for the argument object.",
        "Return the default fill value for the argument"
    ],
    [
        "The default filling value depends on the datatype of the input",
        "The default filling value depends on the datatype of the"
    ],
    [
        "array or the type of the input scalar:",
        "array or the type of the input"
    ],
    [
        "For structured types, a structured scalar is returned, with each field the",
        "For structured types, a structured scalar is"
    ],
    [
        "default fill value for its type.",
        "default fill value"
    ],
    [
        "For subarray types, the fill value is an array of the same size containing",
        "For subarray types, the fill value is an array of"
    ],
    [
        "obj : ndarray, dtype or scalar",
        "obj : ndarray, dtype or"
    ],
    [
        "The array data-type or scalar for which the default fill value",
        "The array data-type or scalar for which"
    ],
    [
        "f\"Unsuitable type {dtype} for calculating {extremum_name}.\"",
        "f\"Unsuitable type {dtype}"
    ],
    [
        "Return the maximum value that can be represented by the dtype of an object.",
        "Return the maximum value that can be represented by the dtype of"
    ],
    [
        "This function is useful for calculating a fill value suitable for",
        "This function is useful for calculating a fill value suitable"
    ],
    [
        "taking the minimum of an array with a given dtype.",
        "taking the minimum of an array with a given"
    ],
    [
        "obj : ndarray, dtype or scalar",
        "obj : ndarray, dtype or"
    ],
    [
        "An object that can be queried for it's numeric type.",
        "An object that can be queried for it's numeric"
    ],
    [
        "If `obj` isn't a suitable numeric type.",
        "If `obj` isn't a"
    ],
    [
        "set_fill_value : Set the filling value of a masked array.",
        "set_fill_value : Set the filling value of a"
    ],
    [
        "MaskedArray.fill_value : Return current fill value.",
        "MaskedArray.fill_value : Return current fill"
    ],
    [
        "An array of numeric data can also be passed.",
        "An array of numeric data can also"
    ],
    [
        "Return the minimum value that can be represented by the dtype of an object.",
        "Return the minimum value that can be represented by the"
    ],
    [
        "This function is useful for calculating a fill value suitable for",
        "This function is useful for calculating a"
    ],
    [
        "taking the maximum of an array with a given dtype.",
        "taking the maximum of an array with a"
    ],
    [
        "obj : ndarray, dtype or scalar",
        "obj : ndarray,"
    ],
    [
        "An object that can be queried for it's numeric type.",
        "An object that can be queried"
    ],
    [
        "If `obj` isn't a suitable numeric type.",
        "If `obj` isn't a"
    ],
    [
        "set_fill_value : Set the filling value of a masked array.",
        "set_fill_value : Set the filling value"
    ],
    [
        "MaskedArray.fill_value : Return current fill value.",
        "MaskedArray.fill_value : Return current fill"
    ],
    [
        "An array of numeric data can also be passed.",
        "An array of numeric data can"
    ],
    [
        "Create a fill value for a structured dtype.",
        "Create a fill value"
    ],
    [
        "Scalar or array representing the fill value. If it is of shorter",
        "Scalar or array representing the fill value. If it is"
    ],
    [
        "length than the number of fields in dt, it will be resized.",
        "length than the number of fields in dt, it"
    ],
    [
        "The structured dtype for which to create the fill value.",
        "The structured dtype for which to create"
    ],
    [
        "A tuple of values corresponding to the structured fill value.",
        "A tuple of values corresponding to the structured"
    ],
    [
        "for (fval, name) in zip(fillvalue, dt.names):",
        "for (fval, name)"
    ],
    [
        "Private function validating the given `fill_value` for the given dtype.",
        "Private function validating the given `fill_value` for"
    ],
    [
        "If fill_value is None, it is set to the default corresponding to the dtype.",
        "If fill_value is None, it is set"
    ],
    [
        "If fill_value is not None, its value is forced to the given dtype.",
        "If fill_value is not None, its value is forced to"
    ],
    [
        "err_msg = \"Unable to transform %s to dtype %s\"",
        "err_msg = \"Unable to transform"
    ],
    [
        "raise ValueError(err_msg % (fill_value, ndtype)) from e",
        "raise ValueError(err_msg % (fill_value, ndtype)) from"
    ],
    [
        "if isinstance(fill_value, str) and (ndtype.char not in 'OSVU'):",
        "if isinstance(fill_value, str) and"
    ],
    [
        "err_msg = \"Cannot set fill value of string with array of dtype %s\"",
        "err_msg = \"Cannot set fill value of"
    ],
    [
        "err_msg = \"Cannot convert fill_value %s to dtype %s\"",
        "err_msg = \"Cannot convert fill_value"
    ],
    [
        "raise TypeError(err_msg % (fill_value, ndtype)) from e",
        "raise TypeError(err_msg % (fill_value, ndtype)) from"
    ],
    [
        "Set the filling value of a, if a is a masked array.",
        "Set the filling value of a, if a is a"
    ],
    [
        "This function changes the fill value of the masked array `a` in place.",
        "This function changes the fill value of the masked array `a`"
    ],
    [
        "If `a` is not a masked array, the function returns silently, without",
        "If `a` is not a masked array, the function returns silently,"
    ],
    [
        "Filling value. A consistency test is performed to make sure",
        "Filling value. A consistency test is performed"
    ],
    [
        "the value is compatible with the dtype of `a`.",
        "the value is compatible with the dtype of"
    ],
    [
        "maximum_fill_value : Return the default fill value for a dtype.",
        "maximum_fill_value : Return the default fill value"
    ],
    [
        "MaskedArray.fill_value : Return current fill value.",
        "MaskedArray.fill_value : Return"
    ],
    [
        "mask=[ True,  True,  True, False, False],",
        "mask=[ True, True, True, False,"
    ],
    [
        "mask=[ True,  True,  True, False, False],",
        "mask=[ True, True,"
    ],
    [
        "Nothing happens if `a` is not a masked array.",
        "Nothing happens if `a` is not a masked"
    ],
    [
        "Return the filling value of a, if any.  Otherwise, returns the",
        "Return the filling value of a, if"
    ],
    [
        "default filling value for that type.",
        "default filling value for"
    ],
    [
        "Return the common filling value of two masked arrays, if any.",
        "Return the common filling value of"
    ],
    [
        "If ``a.fill_value == b.fill_value``, return the fill value,",
        "If ``a.fill_value == b.fill_value``, return"
    ],
    [
        "The masked arrays for which to compare fill values.",
        "The masked arrays for which to compare fill"
    ],
    [
        "The common fill value, or None.",
        "The common fill value, or"
    ],
    [
        "Return input as an `~numpy.ndarray`, with masked values replaced by",
        "Return input as an `~numpy.ndarray`, with masked"
    ],
    [
        "If `a` is not a `MaskedArray`, `a` itself is returned.",
        "If `a` is not a"
    ],
    [
        "If `a` is a `MaskedArray` with no masked values, then ``a.data`` is",
        "If `a` is a `MaskedArray` with no masked values, then ``a.data``"
    ],
    [
        "If `a` is a `MaskedArray` and `fill_value` is None, `fill_value` is set to",
        "If `a` is a `MaskedArray` and `fill_value` is None, `fill_value`"
    ],
    [
        "Can be scalar or non-scalar. If non-scalar, the",
        "Can be scalar or non-scalar. If"
    ],
    [
        "resulting filled array should be broadcastable",
        "resulting filled array should"
    ],
    [
        "over input array. Default is None.",
        "over input array. Default is"
    ],
    [
        "Return the youngest subclass of MaskedArray from a list of (masked) arrays.",
        "Return the youngest subclass of MaskedArray from"
    ],
    [
        "In case of siblings, the first listed takes over.",
        "In case of siblings, the first"
    ],
    [
        "arrcls = [type(a) for a in arrays]",
        "arrcls = [type(a) for"
    ],
    [
        "Return the data of a masked array as an ndarray.",
        "Return the data of a masked"
    ],
    [
        "Return the data of `a` (if any) as an ndarray if `a` is a ``MaskedArray``,",
        "Return the data of `a` (if any) as an ndarray if `a` is a"
    ],
    [
        "else return `a` as a ndarray or subclass (depending on `subok`) if not.",
        "else return `a` as a ndarray or subclass (depending on `subok`) if"
    ],
    [
        "Input ``MaskedArray``, alternatively a ndarray or a subclass thereof.",
        "Input ``MaskedArray``, alternatively a ndarray or"
    ],
    [
        "Whether to force the output to be a `pure` ndarray (False) or to",
        "Whether to force the output to be a `pure` ndarray (False)"
    ],
    [
        "return a subclass of ndarray if appropriate (True, default).",
        "return a subclass of ndarray if appropriate (True,"
    ],
    [
        "getmask : Return the mask of a masked array, or nomask.",
        "getmask : Return the mask of a"
    ],
    [
        "getmaskarray : Return the mask of a masked array, or full array of False.",
        "getmaskarray : Return the mask of a masked array, or full array of"
    ],
    [
        "Equivalently use the ``MaskedArray`` `data` attribute.",
        "Equivalently use the ``MaskedArray`` `data`"
    ],
    [
        "Return input with invalid data masked and replaced by a fill value.",
        "Return input with invalid data masked and"
    ],
    [
        "Invalid data means values of `nan`, `inf`, etc.",
        "Invalid data means values of `nan`, `inf`,"
    ],
    [
        "Input array, a (subclass of) ndarray.",
        "Input array, a (subclass of)"
    ],
    [
        "Mask. Must be convertible to an array of booleans with the same",
        "Mask. Must be convertible to an array"
    ],
    [
        "shape as `data`. True indicates a masked (i.e. invalid) data.",
        "shape as `data`. True indicates a"
    ],
    [
        "Whether to use a copy of `a` (True) or to fix `a` in place (False).",
        "Whether to use a copy of `a` (True) or to fix `a` in"
    ],
    [
        "Value used for fixing invalid data. Default is None, in which case",
        "Value used for fixing invalid data. Default"
    ],
    [
        "The input array with invalid entries fixed.",
        "The input array with"
    ],
    [
        "A copy is performed by default.",
        "A copy is"
    ],
    [
        "a = masked_array(a, copy=copy, mask=mask, subok=True)",
        "a = masked_array(a, copy=copy,"
    ],
    [
        "builtins.all(isinstance(s, str) for s in val)))",
        "builtins.all(isinstance(s, str) for"
    ],
    [
        "Define a valid interval, so that :",
        "Define a valid interval, so"
    ],
    [
        "``x < a`` or ``x > b``.",
        "``x < a`` or ``x"
    ],
    [
        "\"domain_check_interval(a,b)(x) = true where x < a or y > b\"",
        "\"domain_check_interval(a,b)(x) = true where x < a or y >"
    ],
    [
        "Define a valid interval for the `tan` function, so that:",
        "Define a valid interval for the `tan`"
    ],
    [
        "``domain_tan(eps) = True`` where ``abs(cos(x)) < eps``",
        "``domain_tan(eps) = True`` where ``abs(cos(x))"
    ],
    [
        "\"domain_tan(eps) = true where abs(cos(x)) < eps)\"",
        "\"domain_tan(eps) = true where"
    ],
    [
        "Define a domain for safe division.",
        "Define a domain for safe"
    ],
    [
        "return umath.absolute(a) * self.tolerance >= umath.absolute(b)",
        "return umath.absolute(a) *"
    ],
    [
        "DomainGreater(v)(x) is True where x <= v.",
        "DomainGreater(v)(x) is True where x"
    ],
    [
        "\"DomainGreater(v)(x) = true where x <= v\"",
        "\"DomainGreater(v)(x) = true where x <="
    ],
    [
        "DomainGreaterEqual(v)(x) is True where x < v.",
        "DomainGreaterEqual(v)(x) is True where"
    ],
    [
        "\"DomainGreaterEqual(v)(x) = true where x < v\"",
        "\"DomainGreaterEqual(v)(x) = true where x <"
    ],
    [
        "Defines masked version of unary operations, where invalid values are",
        "Defines masked version of unary operations, where"
    ],
    [
        "The function for which to define a masked version. Made available",
        "The function for which to define a"
    ],
    [
        "Domain for the function. Should be one of the ``_Domain*``",
        "Domain for the function. Should be one of"
    ],
    [
        "Define masked version of binary operations, where invalid",
        "Define masked version of binary operations, where"
    ],
    [
        "The function for which to define a masked version. Made available",
        "The function for which to define a"
    ],
    [
        "Default domain for the function. Should be one of the ``_Domain*``",
        "Default domain for the function. Should"
    ],
    [
        "abfunc(x, filly) = x for all x to enable reduce.",
        "abfunc(x, filly) = x for all x"
    ],
    [
        "def __call__(self, a, b, *args, **kwargs):",
        "def __call__(self, a,"
    ],
    [
        "result = self.f(da, db, *args, **kwargs)",
        "result = self.f(da, db,"
    ],
    [
        "if m is not nomask and m.any():",
        "if m is not nomask"
    ],
    [
        "Reduce `target` along the given `axis`.",
        "Reduce `target` along"
    ],
    [
        "Return the function applied to the outer product of a and b.",
        "Return the function applied to the outer product of"
    ],
    [
        "if ma is nomask and mb is nomask:",
        "if ma is nomask and mb"
    ],
    [
        "\"\"\"Accumulate `target` along `axis` after filling with y fill",
        "\"\"\"Accumulate `target` along `axis` after filling with y"
    ],
    [
        "Define binary operations that have a domain, like divide.",
        "Define binary operations that have"
    ],
    [
        "They have no reduce, outer or accumulate.",
        "They have no reduce,"
    ],
    [
        "The function for which to define a masked version. Made available",
        "The function for which to define a masked"
    ],
    [
        "Default domain for the function. Should be one of the ``_Domain*``",
        "Default domain for the function. Should be one of the"
    ],
    [
        "abfunc(x, filly) = x for all x to enable reduce.",
        "abfunc(x, filly) = x for all"
    ],
    [
        "def __call__(self, a, b, *args, **kwargs):",
        "def __call__(self, a, b,"
    ],
    [
        "result = self.f(da, db, *args, **kwargs)",
        "result = self.f(da,"
    ],
    [
        "\"Private function allowing recursion in _replace_dtype_fields.\"",
        "\"Private function allowing recursion in"
    ],
    [
        "Construct a dtype description list from a given dtype.",
        "Construct a dtype description list from"
    ],
    [
        "Returns a new dtype object, with all fields and subtypes in the given type",
        "Returns a new dtype object, with all fields"
    ],
    [
        "Arguments are coerced to dtypes first.",
        "Arguments are coerced"
    ],
    [
        "Construct a dtype description list from a given dtype.",
        "Construct a dtype description list"
    ],
    [
        "Returns a new dtype object, with the type of all fields in `ndtype` to a",
        "Returns a new dtype object, with the type"
    ],
    [
        "boolean type. Field names are not altered.",
        "boolean type. Field names"
    ],
    [
        "A dtype that looks like `ndtype`, the type of all fields is boolean.",
        "A dtype that looks like `ndtype`, the type of all fields is"
    ],
    [
        "Return the mask of a masked array, or nomask.",
        "Return the mask of a masked array,"
    ],
    [
        "Return the mask of `a` as an ndarray if `a` is a `MaskedArray` and the",
        "Return the mask of `a` as an ndarray if"
    ],
    [
        "mask is not `nomask`, else return `nomask`. To guarantee a full array",
        "mask is not `nomask`, else return `nomask`."
    ],
    [
        "of booleans of the same shape as a, use `getmaskarray`.",
        "of booleans of the same shape"
    ],
    [
        "Input `MaskedArray` for which the mask is required.",
        "Input `MaskedArray` for which the"
    ],
    [
        "getdata : Return the data of a masked array as an ndarray.",
        "getdata : Return the data of a masked array as an"
    ],
    [
        "getmaskarray : Return the mask of a masked array, or full array of False.",
        "getmaskarray : Return the mask of a masked array, or full array of"
    ],
    [
        "Equivalently use the `MaskedArray` `mask` attribute.",
        "Equivalently use the `MaskedArray`"
    ],
    [
        "Return the mask of a masked array, or full boolean array of False.",
        "Return the mask of a masked array, or full boolean array"
    ],
    [
        "Return the mask of `arr` as an ndarray if `arr` is a `MaskedArray` and",
        "Return the mask of `arr` as an ndarray"
    ],
    [
        "the mask is not `nomask`, else return a full boolean array of False of",
        "the mask is not `nomask`, else return"
    ],
    [
        "Input `MaskedArray` for which the mask is required.",
        "Input `MaskedArray` for which the mask is"
    ],
    [
        "getmask : Return the mask of a masked array, or nomask.",
        "getmask : Return the mask of a masked"
    ],
    [
        "getdata : Return the data of a masked array as an ndarray.",
        "getdata : Return the data of a masked"
    ],
    [
        "mask = make_mask_none(np.shape(arr), getattr(arr, 'dtype', None))",
        "mask = make_mask_none(np.shape(arr), getattr(arr, 'dtype',"
    ],
    [
        "Return True if m is a valid, standard mask.",
        "Return True if m is a valid, standard"
    ],
    [
        "This function does not check the contents of the input, only that the",
        "This function does not check the contents of the input, only that"
    ],
    [
        "type is MaskType. In particular, this function returns False if the",
        "type is MaskType. In particular, this function"
    ],
    [
        "True if `m.dtype.type` is MaskType, False otherwise.",
        "True if `m.dtype.type` is MaskType,"
    ],
    [
        "ma.isMaskedArray : Test whether input is an instance of MaskedArray.",
        "ma.isMaskedArray : Test whether input is"
    ],
    [
        "mask=[ True, False,  True, False, False],",
        "mask=[ True, False, True,"
    ],
    [
        "Input must be an ndarray (or have similar attributes)",
        "Input must be an ndarray"
    ],
    [
        "for it to be considered a valid mask.",
        "for it to be considered a"
    ],
    [
        ">>> m = [False, True, False]",
        ">>> m = [False,"
    ],
    [
        ">>> m = np.array([False, True, False])",
        ">>> m ="
    ],
    [
        "Arrays with complex dtypes don't return True.",
        "Arrays with complex dtypes don't"
    ],
    [
        ">>> m = np.array([(True, False), (False, True), (True, False)],",
        ">>> m = np.array([(True, False), (False, True), (True,"
    ],
    [
        "array([( True, False), (False,  True), ( True, False)],",
        "array([( True, False), (False, True), ( True,"
    ],
    [
        "Shrink a mask to nomask if possible",
        "Shrink a mask to nomask"
    ],
    [
        "if m.dtype.names is None and not m.any():",
        "if m.dtype.names is None and"
    ],
    [
        "Create a boolean mask from an array.",
        "Create a boolean mask"
    ],
    [
        "Return `m` as a boolean mask, creating a copy if necessary or requested.",
        "Return `m` as a boolean mask, creating a copy if necessary"
    ],
    [
        "The function can accept any sequence that is convertible to integers,",
        "The function can accept any sequence that is convertible to"
    ],
    [
        "Whether to return a copy of `m` (True) or `m` itself (False).",
        "Whether to return a copy of `m`"
    ],
    [
        "Whether to shrink `m` to ``nomask`` if all its values are False.",
        "Whether to shrink `m` to ``nomask`` if all"
    ],
    [
        "Data-type of the output mask. By default, the output mask has a",
        "Data-type of the output mask. By default,"
    ],
    [
        "dtype of MaskType (bool). If the dtype is flexible, each field has",
        "dtype of MaskType (bool). If the dtype"
    ],
    [
        "a boolean dtype. This is ignored when `m` is ``nomask``, in which",
        "a boolean dtype. This is ignored when `m` is"
    ],
    [
        "A boolean mask derived from `m`.",
        "A boolean mask derived"
    ],
    [
        ">>> m = [True, False, True, True]",
        ">>> m = [True, False, True,"
    ],
    [
        ">>> for man, mouse in zip(m, n):",
        ">>> for man, mouse"
    ],
    [
        "array([(True, False), (False, True), (True, False), (True, False)],",
        "array([(True, False), (False, True), (True, False),"
    ],
    [
        "if isinstance(m, ndarray) and m.dtype.fields and dtype == np.bool:",
        "if isinstance(m, ndarray) and m.dtype.fields and dtype"
    ],
    [
        "copy = None if not copy else True",
        "copy = None if not"
    ],
    [
        "result = np.array(filled(m, True), copy=copy, dtype=dtype, subok=True)",
        "result = np.array(filled(m, True), copy=copy,"
    ],
    [
        "Return a boolean mask of the given shape, filled with False.",
        "Return a boolean mask of the"
    ],
    [
        "This function returns a boolean ndarray with all entries False, that can",
        "This function returns a boolean ndarray with all"
    ],
    [
        "be used in common mask manipulations. If a complex dtype is specified, the",
        "be used in common mask manipulations. If a complex dtype is specified,"
    ],
    [
        "type of each field is converted to a boolean type.",
        "type of each field is converted to a"
    ],
    [
        "A tuple indicating the shape of the mask.",
        "A tuple indicating the shape of"
    ],
    [
        "If None, use a MaskType instance. Otherwise, use a new datatype with",
        "If None, use a MaskType instance. Otherwise,"
    ],
    [
        "the same fields as `dtype`, converted to boolean types.",
        "the same fields as `dtype`, converted"
    ],
    [
        "An ndarray of appropriate shape and dtype, filled with False.",
        "An ndarray of appropriate shape and"
    ],
    [
        "make_mask : Create a boolean mask from an array.",
        "make_mask : Create a boolean mask from an"
    ],
    [
        "make_mask_descr : Construct a dtype description list from a given dtype.",
        "make_mask_descr : Construct a dtype description list from a"
    ],
    [
        "array([(False, False), (False, False), (False, False)],",
        "array([(False, False), (False,"
    ],
    [
        "Combine two masks with the ``logical_or`` operator.",
        "Combine two masks with the"
    ],
    [
        "If copy is False and one of the inputs is `nomask`, return a view",
        "If copy is False and one of the inputs is `nomask`,"
    ],
    [
        "of the other input mask. Defaults to False.",
        "of the other input mask."
    ],
    [
        "Whether to shrink the output to `nomask` if all its values are",
        "Whether to shrink the output to `nomask` if all its values"
    ],
    [
        "Returns a completely flattened version of the mask, where nested fields",
        "Returns a completely flattened version of"
    ],
    [
        "Input array, which will be interpreted as booleans.",
        "Input array, which will be interpreted"
    ],
    [
        ">>> mdtype = [('a', bool), ('b', [('ba', bool), ('bb', bool)])]",
        ">>> mdtype = [('a', bool),"
    ],
    [
        "array([False, False, False, False, False,  True])",
        "array([False, False, False, False, False,"
    ],
    [
        "\"Flatten the mask and returns a (maybe nested) sequence of booleans.\"",
        "\"Flatten the mask and returns a"
    ],
    [
        "return [flatten_mask(mask[name]) for name in mnames]",
        "return [flatten_mask(mask[name]) for"
    ],
    [
        "\"Generates a flattened version of the sequence.\"",
        "\"Generates a flattened version of"
    ],
    [
        "\"Check whether there are masked values along the given axis\"",
        "\"Check whether there are masked values along the"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue"
    ],
    [
        "Mask an array where a condition is met.",
        "Mask an array where"
    ],
    [
        "Return `a` as an array masked where `condition` is True.",
        "Return `a` as an array masked"
    ],
    [
        "Any masked values of `a` or `condition` are also masked in the output.",
        "Any masked values of `a` or `condition`"
    ],
    [
        "Masking condition.  When `condition` tests floating point values for",
        "Masking condition. When `condition` tests floating"
    ],
    [
        "If True (default) make a copy of `a` in the result.  If False modify",
        "If True (default) make a copy of `a`"
    ],
    [
        "`a` in place and return a view.",
        "`a` in place and"
    ],
    [
        "The result of masking `a` where `condition` is True.",
        "The result of masking `a`"
    ],
    [
        "masked_values : Mask using floating point equality.",
        "masked_values : Mask using floating"
    ],
    [
        "masked_equal : Mask where equal to a given value.",
        "masked_equal : Mask where equal to a given"
    ],
    [
        "masked_not_equal : Mask where *not* equal to a given value.",
        "masked_not_equal : Mask where *not* equal to"
    ],
    [
        "masked_less_equal : Mask where less than or equal to a given value.",
        "masked_less_equal : Mask where less than or equal"
    ],
    [
        "masked_greater_equal : Mask where greater than or equal to a given value.",
        "masked_greater_equal : Mask where greater than or equal"
    ],
    [
        "masked_less : Mask where less than a given value.",
        "masked_less : Mask where less than"
    ],
    [
        "masked_greater : Mask where greater than a given value.",
        "masked_greater : Mask where greater"
    ],
    [
        "masked_inside : Mask inside a given interval.",
        "masked_inside : Mask inside a"
    ],
    [
        "masked_outside : Mask outside a given interval.",
        "masked_outside : Mask outside"
    ],
    [
        "masked_invalid : Mask invalid values (NaNs or infs).",
        "masked_invalid : Mask invalid"
    ],
    [
        "Mask array `b` conditional on `a`.",
        "Mask array `b`"
    ],
    [
        ">>> b = ['a', 'b', 'c', 'd']",
        ">>> b = ['a', 'b', 'c',"
    ],
    [
        "When `condition` or `a` contain masked values.",
        "When `condition` or `a` contain masked"
    ],
    [
        "if cshape and cshape != ashape:",
        "if cshape and cshape"
    ],
    [
        "raise IndexError(\"Inconsistent shape between the condition and the input\"",
        "raise IndexError(\"Inconsistent shape between the condition and the"
    ],
    [
        "\" (got %s and %s)\" % (cshape, ashape))",
        "\" (got %s and %s)\" % (cshape,"
    ],
    [
        "if not copy and hasattr(a, '_mask') and getmask(a) is nomask:",
        "if not copy and hasattr(a, '_mask') and"
    ],
    [
        "Mask an array where greater than a given value.",
        "Mask an array where greater than a"
    ],
    [
        "This function is a shortcut to ``masked_where``, with",
        "This function is a"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a condition is"
    ],
    [
        "Mask an array where greater than or equal to a given value.",
        "Mask an array where greater than or equal"
    ],
    [
        "This function is a shortcut to ``masked_where``, with",
        "This function is a"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a condition is"
    ],
    [
        "Mask an array where less than a given value.",
        "Mask an array where less"
    ],
    [
        "This function is a shortcut to ``masked_where``, with",
        "This function is a"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a condition"
    ],
    [
        "Mask an array where less than or equal to a given value.",
        "Mask an array where less than"
    ],
    [
        "This function is a shortcut to ``masked_where``, with",
        "This function is a"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a condition"
    ],
    [
        "Mask an array where *not* equal to a given value.",
        "Mask an array where *not* equal to a given"
    ],
    [
        "This function is a shortcut to ``masked_where``, with",
        "This function is a"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where"
    ],
    [
        "Mask an array where equal to a given value.",
        "Mask an array where equal to a given"
    ],
    [
        "Return a MaskedArray, masked where the data in array `x` are",
        "Return a MaskedArray, masked where the data"
    ],
    [
        "equal to `value`. The fill_value of the returned MaskedArray",
        "equal to `value`. The fill_value of"
    ],
    [
        "For floating point arrays, consider using ``masked_values(x, value)``.",
        "For floating point arrays, consider"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a"
    ],
    [
        "masked_values : Mask using floating point equality.",
        "masked_values : Mask using floating"
    ],
    [
        "output = masked_where(equal(x, value), x, copy=copy)",
        "output = masked_where(equal(x, value),"
    ],
    [
        "Mask an array inside a given interval.",
        "Mask an array inside a"
    ],
    [
        "Shortcut to ``masked_where``, where `condition` is True for `x` inside",
        "Shortcut to ``masked_where``, where `condition` is True for"
    ],
    [
        "can be given in either order.",
        "can be given"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a"
    ],
    [
        "The array `x` is prefilled with its filling value.",
        "The array `x` is prefilled with its"
    ],
    [
        "mask=[False, False,  True,  True, False, False],",
        "mask=[False, False, True, True,"
    ],
    [
        "mask=[False, False,  True,  True, False, False],",
        "mask=[False, False, True, True,"
    ],
    [
        "Mask an array outside a given interval.",
        "Mask an array outside a"
    ],
    [
        "Shortcut to ``masked_where``, where `condition` is True for `x` outside",
        "Shortcut to ``masked_where``, where `condition`"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a condition is"
    ],
    [
        "The array `x` is prefilled with its filling value.",
        "The array `x` is prefilled"
    ],
    [
        "mask=[ True,  True, False, False,  True,  True],",
        "mask=[ True, True, False, False,"
    ],
    [
        "mask=[ True,  True, False, False,  True,  True],",
        "mask=[ True, True, False, False, True,"
    ],
    [
        "Mask the array `x` where the data are exactly equal to value.",
        "Mask the array `x` where the data are exactly"
    ],
    [
        "This function is similar to `masked_values`, but only suitable",
        "This function is similar to"
    ],
    [
        "for object arrays: for floating point, use `masked_values` instead.",
        "for object arrays: for floating point, use `masked_values`"
    ],
    [
        "Whether to return a copy of `x`.",
        "Whether to return a"
    ],
    [
        "Whether to collapse a mask full of False to nomask",
        "Whether to collapse a mask full of False to"
    ],
    [
        "The result of masking `x` where equal to `value`.",
        "The result of masking `x` where equal"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where"
    ],
    [
        "masked_equal : Mask where equal to a given value (integers).",
        "masked_equal : Mask where equal to"
    ],
    [
        "masked_values : Mask using floating point equality.",
        "masked_values : Mask using floating"
    ],
    [
        ">>> food = np.array(['green_eggs', 'ham'], dtype=object)",
        ">>> food = np.array(['green_eggs',"
    ],
    [
        ">>> fresh_food = np.array(['cheese', 'ham', 'pineapple'], dtype=object)",
        ">>> fresh_food = np.array(['cheese',"
    ],
    [
        "Note that `mask` is set to ``nomask`` if possible.",
        "Note that `mask` is set to ``nomask`` if"
    ],
    [
        "Return a MaskedArray, masked where the data in array `x` are approximately",
        "Return a MaskedArray, masked where the data in"
    ],
    [
        "equal to `value`, determined using `isclose`. The default tolerances for",
        "equal to `value`, determined using"
    ],
    [
        "`masked_values` are the same as those for `isclose`.",
        "`masked_values` are the same as"
    ],
    [
        "For integer types, exact equality is used, in the same way as",
        "For integer types, exact equality is"
    ],
    [
        "The fill_value is set to `value` and the mask is set to ``nomask`` if",
        "The fill_value is set to `value` and the mask is set to ``nomask``"
    ],
    [
        "Tolerance parameters passed on to `isclose`",
        "Tolerance parameters passed"
    ],
    [
        "Whether to return a copy of `x`.",
        "Whether to return a copy of"
    ],
    [
        "Whether to collapse a mask full of False to ``nomask``.",
        "Whether to collapse a mask full of False"
    ],
    [
        "The result of masking `x` where approximately equal to `value`.",
        "The result of masking `x` where approximately equal"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a"
    ],
    [
        "masked_equal : Mask where equal to a given value (integers).",
        "masked_equal : Mask where equal"
    ],
    [
        "Note that `mask` is set to ``nomask`` if possible.",
        "Note that `mask` is set to ``nomask``"
    ],
    [
        "Unlike `masked_equal`, `masked_values` can perform approximate equalities.",
        "Unlike `masked_equal`, `masked_values` can"
    ],
    [
        "mask = np.isclose(xnew, value, atol=atol, rtol=rtol)",
        "mask = np.isclose(xnew, value, atol=atol,"
    ],
    [
        "ret = masked_array(xnew, mask=mask, copy=copy, fill_value=value)",
        "ret = masked_array(xnew, mask=mask,"
    ],
    [
        "Mask an array where invalid values occur (NaNs or infs).",
        "Mask an array where invalid values"
    ],
    [
        "This function is a shortcut to ``masked_where``, with",
        "This function is a shortcut to ``masked_where``,"
    ],
    [
        "`condition` = ~(np.isfinite(a)). Any pre-existing mask is conserved.",
        "`condition` = ~(np.isfinite(a)). Any"
    ],
    [
        "Only applies to arrays with a dtype where NaNs or infs make sense",
        "Only applies to arrays with a dtype where NaNs or infs make"
    ],
    [
        "(i.e. floating point types), but accepts any array_like object.",
        "(i.e. floating point types), but accepts"
    ],
    [
        "masked_where : Mask where a condition is met.",
        "masked_where : Mask where a"
    ],
    [
        "Handle the string used to represent missing data in a masked array.",
        "Handle the string used to represent missing data"
    ],
    [
        "Display the string to print for masked values.",
        "Display the string to print"
    ],
    [
        "Set the string to print for masked values.",
        "Set the string to print"
    ],
    [
        "Is the use of the display value enabled?",
        "Is the use of the display value"
    ],
    [
        "Set the enabling shrink to `shrink`.",
        "Set the enabling shrink"
    ],
    [
        "Puts printoptions in result where mask is True.",
        "Puts printoptions in result where mask is"
    ],
    [
        "The data type of the output is chosen such that it can represent all of the",
        "The data type of the output is chosen such that it can represent all of"
    ],
    [
        "output : masked array or ndarray",
        "output : masked array or"
    ],
    [
        "A flattened masked array if the input is a masked array, otherwise a",
        "A flattened masked array if the input is a masked array, otherwise"
    ],
    [
        ">>> ndtype = [('a', int), ('b', float)]",
        ">>> ndtype = [('a',"
    ],
    [
        "Flattens a compound of nested iterables.",
        "Flattens a compound"
    ],
    [
        "out = np.array([tuple(flatten_sequence(d.item())) for d in a._data])",
        "out = np.array([tuple(flatten_sequence(d.item())) for"
    ],
    [
        "out = np.array([tuple(flatten_sequence(d.item())) for d in a])",
        "out = np.array([tuple(flatten_sequence(d.item())) for d in"
    ],
    [
        "Return a class method wrapper around a basic array method.",
        "Return a class method wrapper around a basic"
    ],
    [
        "Creates a class method which returns a masked array, where the new",
        "Creates a class method which returns a masked array, where the"
    ],
    [
        "``_data`` array is the output of the corresponding basic method called",
        "``_data`` array is the output of the corresponding basic method"
    ],
    [
        "If `onmask` is True, the new mask is the output of the method called",
        "If `onmask` is True, the new mask is the output of"
    ],
    [
        "on the initial mask. Otherwise, the new mask is just a reference",
        "on the initial mask. Otherwise, the new mask"
    ],
    [
        "Name of the function to apply on data.",
        "Name of the function to apply on"
    ],
    [
        "Whether the mask must be processed also (True) or left",
        "Whether the mask must be"
    ],
    [
        "alone (False). Default is True. Make available as `_onmask`",
        "alone (False). Default is True. Make available as"
    ],
    [
        "Class method wrapper of the specified basic array method.",
        "Class method wrapper of the specified basic"
    ],
    [
        "methdoc = getattr(ndarray, funcname, None) or getattr(np, funcname, None)",
        "methdoc = getattr(ndarray, funcname, None) or getattr(np,"
    ],
    [
        "Flat iterator object to iterate over masked arrays.",
        "Flat iterator object to iterate over masked"
    ],
    [
        "A `MaskedIterator` iterator is returned by ``x.flat`` for any masked array",
        "A `MaskedIterator` iterator is returned by ``x.flat`` for any masked"
    ],
    [
        "either in a for-loop or by calling its `next` method.",
        "either in a for-loop or by"
    ],
    [
        "Iteration is done in C-contiguous style, with the last index varying the",
        "Iteration is done in C-contiguous style, with"
    ],
    [
        "fastest. The iterator can also be indexed using basic slicing or",
        "fastest. The iterator can also be indexed using"
    ],
    [
        "MaskedArray.flat : Return a flat iterator over an array.",
        "MaskedArray.flat : Return a flat iterator over an"
    ],
    [
        "MaskedArray.flatten : Returns a flattened copy of an array.",
        "MaskedArray.flatten : Returns a flattened copy of an"
    ],
    [
        "`MaskedIterator` is not exported by the `ma` module. Instead of",
        "`MaskedIterator` is not exported by the"
    ],
    [
        "instantiating a `MaskedIterator` directly, use `MaskedArray.flat`.",
        "instantiating a `MaskedIterator` directly,"
    ],
    [
        "Extracting more than a single element b indexing the `MaskedIterator`",
        "Extracting more than a single"
    ],
    [
        "Return the next value, or raise StopIteration.",
        "Return the next value,"
    ],
    [
        "An array class with possibly masked values.",
        "An array class with possibly"
    ],
    [
        "Masked values of True exclude the corresponding element from any",
        "Masked values of True exclude the corresponding element"
    ],
    [
        "x = MaskedArray(data, mask=nomask, dtype=None, copy=False, subok=True,",
        "x = MaskedArray(data, mask=nomask, dtype=None, copy=False,"
    ],
    [
        "Mask. Must be convertible to an array of booleans with the same",
        "Mask. Must be convertible to an array"
    ],
    [
        "shape as `data`. True indicates a masked (i.e. invalid) data.",
        "shape as `data`. True indicates a masked"
    ],
    [
        "If `dtype` is None, the type of the data argument (``data.dtype``)",
        "If `dtype` is None, the type"
    ],
    [
        "is used. If `dtype` is not None and different from ``data.dtype``,",
        "is used. If `dtype` is not None"
    ],
    [
        "Whether to copy the input data (True), or to use a reference instead.",
        "Whether to copy the input data (True), or to"
    ],
    [
        "Whether to return a subclass of `MaskedArray` if possible (True) or a",
        "Whether to return a subclass of `MaskedArray` if"
    ],
    [
        "Value used to fill in the masked values when necessary.",
        "Value used to fill in the masked"
    ],
    [
        "If None, a default based on the data-type is used.",
        "If None, a default based on the data-type"
    ],
    [
        "Whether to combine `mask` with the mask of the input data, if any",
        "Whether to combine `mask` with the mask of the"
    ],
    [
        "(True), or to use only `mask` for the output (False). Default is True.",
        "(True), or to use only `mask` for the output (False). Default"
    ],
    [
        "Whether to use a hard mask or not. With a hard mask, masked values",
        "Whether to use a hard mask or"
    ],
    [
        "cannot be unmasked. Default is False.",
        "cannot be unmasked."
    ],
    [
        "Whether to force compression of an empty mask. Default is True.",
        "Whether to force compression of an empty mask."
    ],
    [
        "order : {'C', 'F', 'A'}, optional",
        "order : {'C', 'F',"
    ],
    [
        "Specify the order of the array.  If order is 'C', then the array",
        "Specify the order of the array. If order is 'C',"
    ],
    [
        "will be in C-contiguous order (last-index varies the fastest).",
        "will be in C-contiguous order (last-index varies"
    ],
    [
        "If order is 'F', then the returned array will be in",
        "If order is 'F', then the returned array"
    ],
    [
        "Fortran-contiguous order (first-index varies the fastest).",
        "Fortran-contiguous order (first-index varies"
    ],
    [
        "If order is 'A' (default), then the returned array may be",
        "If order is 'A' (default), then the"
    ],
    [
        "in any order (either C-, Fortran-contiguous, or even discontiguous),",
        "in any order (either C-,"
    ],
    [
        "unless a copy is required, in which case it will be C-contiguous.",
        "unless a copy is required, in which case it will be"
    ],
    [
        "The ``mask`` can be initialized with an array of boolean values",
        "The ``mask`` can be initialized with an"
    ],
    [
        "with the same shape as ``data``.",
        "with the same"
    ],
    [
        "Alternatively, the ``mask`` can be initialized to homogeneous boolean",
        "Alternatively, the ``mask`` can be initialized"
    ],
    [
        "array with the same shape as ``data`` by passing in a scalar",
        "array with the same shape as ``data`` by passing in a"
    ],
    [
        "The recommended practice for initializing ``mask`` with a scalar",
        "The recommended practice for initializing ``mask`` with a"
    ],
    [
        "boolean value is to use ``True``/``False`` rather than",
        "boolean value is to use ``True``/``False``"
    ],
    [
        "def __new__(cls, data=None, mask=nomask, dtype=None, copy=False,",
        "def __new__(cls, data=None, mask=nomask,"
    ],
    [
        "Create a new masked array from scratch.",
        "Create a new masked"
    ],
    [
        "A masked array can also be created by taking a .view(MaskedArray).",
        "A masked array can also be created by"
    ],
    [
        "copy = None if not copy else True",
        "copy = None if"
    ],
    [
        "if isinstance(data, MaskedArray) and (data.shape != _data.shape):",
        "if isinstance(data, MaskedArray) and (data.shape"
    ],
    [
        "if isinstance(data, cls) and subok and not isinstance(data, MaskedConstant):",
        "if isinstance(data, cls) and subok and"
    ],
    [
        "if hasattr(data, '_mask') and not isinstance(data, ndarray):",
        "if hasattr(data, '_mask') and"
    ],
    [
        "if (mdtype == MaskType) and mask.any():",
        "if (mdtype == MaskType) and"
    ],
    [
        "if mask is True and mdtype == MaskType:",
        "if mask is True and mdtype =="
    ],
    [
        "elif mask is False and mdtype == MaskType:",
        "elif mask is False"
    ],
    [
        "mask = np.array([tuple([m] * len(mdtype)) for m in mask],",
        "mask = np.array([tuple([m] * len(mdtype)) for m in"
    ],
    [
        "msg = \"Mask and data not compatible: data size is %i, \"\\",
        "msg = \"Mask and data not compatible: data"
    ],
    [
        "\"do a|=b on each field of a, recursively\"",
        "\"do a|=b on each field of a,"
    ],
    [
        "Copies some attributes of obj to self.",
        "Copies some attributes of obj to"
    ],
    [
        "_dict = {'_fill_value': getattr(obj, '_fill_value', None),",
        "_dict = {'_fill_value': getattr(obj, '_fill_value',"
    ],
    [
        "Wraps the numpy array and sets the mask according to context.",
        "Wraps the numpy array and sets"
    ],
    [
        "m = functools.reduce(mask_or, [getmaskarray(arg) for arg in input_args])",
        "m = functools.reduce(mask_or, [getmaskarray(arg)"
    ],
    [
        "if result is not self and result.shape == () and m:",
        "if result is not self and"
    ],
    [
        "Return a view of the MaskedArray data.",
        "Return a view of the MaskedArray"
    ],
    [
        "dtype : data-type or ndarray sub-class, optional",
        "dtype : data-type or ndarray"
    ],
    [
        "The default, None, results in the view having the same data-type",
        "The default, None, results in the view"
    ],
    [
        "as `a`. As with ``ndarray.view``, dtype can also be specified as",
        "as `a`. As with ``ndarray.view``, dtype can also be"
    ],
    [
        "an ndarray sub-class, which then specifies the type of the",
        "an ndarray sub-class, which then specifies the"
    ],
    [
        "returned object (this is equivalent to setting the ``type``",
        "returned object (this is equivalent to setting the"
    ],
    [
        "Type of the returned view, either ndarray or a subclass.  The",
        "Type of the returned view, either ndarray or a"
    ],
    [
        "default None results in type preservation.",
        "default None results in"
    ],
    [
        "The value to use for invalid entries (None by default).",
        "The value to use for invalid entries"
    ],
    [
        "If None, then this argument is inferred from the passed `dtype`, or",
        "If None, then this argument is"
    ],
    [
        "in its absence the original array, as discussed in the notes below.",
        "in its absence the original array,"
    ],
    [
        "numpy.ndarray.view : Equivalent method on ndarray object.",
        "numpy.ndarray.view : Equivalent method on"
    ],
    [
        "``a.view()`` is used two different ways:",
        "``a.view()`` is used"
    ],
    [
        "``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view",
        "``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a"
    ],
    [
        "of the array's memory with a different data-type.  This can cause a",
        "of the array's memory with a different data-type. This"
    ],
    [
        "reinterpretation of the bytes of memory.",
        "reinterpretation of the"
    ],
    [
        "returns an instance of `ndarray_subclass` that looks at the same array",
        "returns an instance of `ndarray_subclass` that"
    ],
    [
        "(same shape, dtype, etc.)  This does not cause a reinterpretation of the",
        "(same shape, dtype, etc.) This does not"
    ],
    [
        "If `fill_value` is not specified, but `dtype` is specified (and is not",
        "If `fill_value` is not specified, but `dtype` is specified"
    ],
    [
        "an ndarray sub-class), the `fill_value` of the MaskedArray will be",
        "an ndarray sub-class), the `fill_value`"
    ],
    [
        "reset. If neither `fill_value` nor `dtype` are specified (or if",
        "reset. If neither `fill_value` nor"
    ],
    [
        "`dtype` is an ndarray sub-class), then the fill value is preserved.",
        "`dtype` is an ndarray sub-class), then the"
    ],
    [
        "Finally, if `fill_value` is specified, but `dtype` is not, the fill",
        "Finally, if `fill_value` is specified, but `dtype` is"
    ],
    [
        "value is set to the specified value.",
        "value is set to the specified"
    ],
    [
        "For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of",
        "For ``a.view(some_dtype)``, if ``some_dtype`` has a different"
    ],
    [
        "bytes per entry than the previous dtype (for example, converting a",
        "bytes per entry than the previous dtype"
    ],
    [
        "regular array to a structured array), then the behavior of the view",
        "regular array to a structured array), then the behavior of"
    ],
    [
        "cannot be predicted just from the superficial appearance of ``a`` (shown",
        "cannot be predicted just from the"
    ],
    [
        "by ``print(a)``). It also depends on exactly how ``a`` is stored in",
        "by ``print(a)``). It also depends on exactly how ``a`` is stored"
    ],
    [
        "memory. Therefore if ``a`` is C-ordered versus fortran-ordered, versus",
        "memory. Therefore if ``a`` is C-ordered versus"
    ],
    [
        "defined as a slice or transpose, etc., the view may give different",
        "defined as a slice or transpose,"
    ],
    [
        "if getattr(output, '_fill_value', None) is not None:",
        "if getattr(output, '_fill_value', None) is not"
    ],
    [
        "Return the item described by i, as a masked array.",
        "Return the item described by"
    ],
    [
        "Return whether `elem` is a scalar result of indexing `arr`, or None",
        "Return whether `elem` is a scalar result of indexing `arr`, or"
    ],
    [
        "if undecidable without promoting nomask to a full mask",
        "if undecidable without promoting nomask to"
    ],
    [
        "f\"{indx!s}, need to keep dimensionality \"",
        "f\"{indx!s}, need to keep"
    ],
    [
        "Set item described by index. If value is masked, masks those",
        "Set item described by index. If value is masked,"
    ],
    [
        "raise MaskError('Cannot alter the masked element.')",
        "raise MaskError('Cannot alter"
    ],
    [
        "self._mask = _mask = make_mask_none(self.shape, self.dtype)",
        "self._mask = _mask"
    ],
    [
        "_mask = self._mask = make_mask_none(self.shape, _dtype)",
        "_mask = self._mask ="
    ],
    [
        "if _dtype.names is not None and mval is nomask:",
        "if _dtype.names is not None and mval"
    ],
    [
        "_mask = self._mask = make_mask_none(self.shape, _dtype)",
        "_mask = self._mask ="
    ],
    [
        "elif hasattr(indx, 'dtype') and (indx.dtype == MaskType):",
        "elif hasattr(indx, 'dtype') and (indx.dtype"
    ],
    [
        "err_msg = \"Flexible 'hard' masks are not yet supported.\"",
        "err_msg = \"Flexible 'hard' masks are"
    ],
    [
        "current_mask = self._mask = make_mask_none(self.shape, idtype)",
        "current_mask = self._mask = make_mask_none(self.shape,"
    ],
    [
        "elif isinstance(mask, (int, float, np.bool, np.number)):",
        "elif isinstance(mask, (int, float, np.bool,"
    ],
    [
        "copy = None if not copy else True",
        "copy = None if not"
    ],
    [
        "mask = np.array([tuple([m] * len(mdtype)) for m in mask],",
        "mask = np.array([tuple([m] * len(mdtype)) for m"
    ],
    [
        "elif isinstance(mask, (int, float, np.bool, np.number)):",
        "elif isinstance(mask, (int, float, np.bool,"
    ],
    [
        "Get or set the mask of the array if it has no named fields. For",
        "Get or set the mask of the array"
    ],
    [
        "structured arrays, returns a ndarray of booleans where entries are",
        "structured arrays, returns a ndarray of booleans where entries"
    ],
    [
        "``True`` if **all** the fields are masked, ``False`` otherwise:",
        "``True`` if **all** the fields are masked,"
    ],
    [
        "raise NotImplementedError(\"Coming soon: setting the mask per records!\")",
        "raise NotImplementedError(\"Coming soon: setting the mask per"
    ],
    [
        "Force the mask to hard, preventing unmasking by assignment.",
        "Force the mask to hard,"
    ],
    [
        "Whether the mask of a masked array is hard or soft is determined by",
        "Whether the mask of a masked array is"
    ],
    [
        "`~ma.MaskedArray.hardmask` to ``True`` (and returns the modified",
        "`~ma.MaskedArray.hardmask` to ``True`` (and returns"
    ],
    [
        "Force the mask to soft (default), allowing unmasking by assignment.",
        "Force the mask to soft (default), allowing unmasking by"
    ],
    [
        "Whether the mask of a masked array is hard or soft is determined by",
        "Whether the mask of a masked array"
    ],
    [
        "`~ma.MaskedArray.hardmask` to ``False`` (and returns the modified",
        "`~ma.MaskedArray.hardmask` to ``False`` (and"
    ],
    [
        "Specifies whether values can be unmasked through assignments.",
        "Specifies whether values can"
    ],
    [
        "By default, assigning definite values to masked array entries will",
        "By default, assigning definite values to"
    ],
    [
        "unmask them.  When `hardmask` is ``True``, the mask will not change",
        "unmask them. When `hardmask` is ``True``, the mask will not"
    ],
    [
        "Since `m` has a soft mask, assigning an element value unmasks that",
        "Since `m` has a soft mask, assigning"
    ],
    [
        "mask=[False, False, False, False, False, False,",
        "mask=[False, False, False, False,"
    ],
    [
        "After hardening, the mask is not affected by assignments:",
        "After hardening, the mask is not"
    ],
    [
        ">>> assert m.hardmask and hardened is m",
        ">>> assert m.hardmask and hardened"
    ],
    [
        "mask=[False, False, False, False, False, False,",
        "mask=[False, False, False, False,"
    ],
    [
        "Copy the mask and set the `sharedmask` flag to ``False``.",
        "Copy the mask and set the"
    ],
    [
        "Whether the mask is shared between masked arrays can be seen from",
        "Whether the mask is shared between masked"
    ],
    [
        "the `sharedmask` property. `unshare_mask` ensures the mask is not",
        "the `sharedmask` property. `unshare_mask` ensures the mask"
    ],
    [
        "shared. A copy of the mask is only made if it was shared.",
        "shared. A copy of the mask is only made if"
    ],
    [
        "\"\"\" Share status of the mask (read-only). \"\"\"",
        "\"\"\" Share status of the"
    ],
    [
        "Reduce a mask to nomask when possible.",
        "Reduce a mask to nomask when"
    ],
    [
        "\"\"\" Class of the underlying data (read-only). \"\"\"",
        "\"\"\" Class of the"
    ],
    [
        "Returns the underlying data, as a view of the masked array.",
        "Returns the underlying data, as a view"
    ],
    [
        "If the underlying data is a subclass of :class:`numpy.ndarray`, it is",
        "If the underlying data is a subclass of :class:`numpy.ndarray`,"
    ],
    [
        "The type of the data can be accessed through the :attr:`baseclass`",
        "The type of the data can be accessed through"
    ],
    [
        "\"\"\" Return a flat iterator, or set a flattened version of self to value. \"\"\"",
        "\"\"\" Return a flat iterator, or set a"
    ],
    [
        "The filling value of the masked array is a scalar. When setting, None",
        "The filling value of the masked array is a scalar."
    ],
    [
        "will set to a default based on the data type.",
        "will set to a default"
    ],
    [
        "\"Non-scalar arrays for the fill value are deprecated. Use \"",
        "\"Non-scalar arrays for the fill"
    ],
    [
        "\"arrays with scalar values instead. The filled function \"",
        "\"arrays with scalar values instead. The"
    ],
    [
        "\"still supports any array as `fill_value`.\",",
        "\"still supports any"
    ],
    [
        "Return a copy of self, with masked values filled with a given value.",
        "Return a copy of self, with masked values filled with"
    ],
    [
        "**However**, if there are no masked values to fill, self will be",
        "**However**, if there are no masked values"
    ],
    [
        "The value to use for invalid entries. Can be scalar or non-scalar.",
        "The value to use for invalid entries. Can"
    ],
    [
        "If non-scalar, the resulting ndarray must be broadcastable over",
        "If non-scalar, the resulting ndarray must"
    ],
    [
        "input array. Default is None, in which case, the `fill_value`",
        "input array. Default is None, in which case,"
    ],
    [
        "attribute of the array is used instead.",
        "attribute of the array"
    ],
    [
        "A copy of ``self`` with invalid entries replaced by *fill_value*",
        "A copy of ``self`` with"
    ],
    [
        "(be it the function argument or the attribute of ``self``), or",
        "(be it the function argument or the"
    ],
    [
        "``self`` itself as an ndarray if there are no invalid entries to",
        "``self`` itself as an ndarray if there are"
    ],
    [
        "The result is **not** a MaskedArray!",
        "The result is **not** a"
    ],
    [
        "Subclassing is preserved. This means that if, e.g., the data part of",
        "Subclassing is preserved. This means that if,"
    ],
    [
        "the masked array is a recarray, `filled` returns a recarray:",
        "the masked array is a recarray, `filled` returns"
    ],
    [
        ">>> m = np.ma.array(x, mask=[(True, False), (False, True)])",
        ">>> m = np.ma.array(x, mask=[(True, False), (False,"
    ],
    [
        "A new `ndarray` holding the non-masked data is returned.",
        "A new `ndarray` holding the non-masked"
    ],
    [
        "The result is **not** a MaskedArray!",
        "The result is **not**"
    ],
    [
        "Return `a` where condition is ``True``.",
        "Return `a` where condition"
    ],
    [
        "If condition is a `~ma.MaskedArray`, missing values are considered",
        "If condition is a `~ma.MaskedArray`, missing values are"
    ],
    [
        "is less than the size of a along the axis, then output is truncated",
        "is less than the size of a along"
    ],
    [
        "Axis along which the operation must be performed.",
        "Axis along which the operation must be"
    ],
    [
        "Alternative output array in which to place the result. It must have",
        "Alternative output array in which to place the result. It must"
    ],
    [
        "the same shape as the expected output but the type will be cast if",
        "the same shape as the expected output but"
    ],
    [
        "Please note the difference with :meth:`compressed` !",
        "Please note the difference with :meth:`compressed`"
    ],
    [
        "The output of :meth:`compress` has a mask, the output of",
        "The output of :meth:`compress` has a mask, the"
    ],
    [
        "Replace masked values with masked_print_option, casting all innermost",
        "Replace masked values with masked_print_option,"
    ],
    [
        "arr = np.split(data, (ind, -ind), axis=axis)",
        "arr = np.split(data,"
    ],
    [
        "arr = np.split(mask, (ind, -ind), axis=axis)",
        "arr = np.split(mask, (ind,"
    ],
    [
        "indents[k] = ' ' * n",
        "indents[k] = ' ' *"
    ],
    [
        "indents = dict.fromkeys(keys, ' ' * min_indent)",
        "indents = dict.fromkeys(keys, '"
    ],
    [
        "elif self._fill_value.dtype == self.dtype and not self.dtype == object:",
        "elif self._fill_value.dtype == self.dtype and not"
    ],
    [
        "return prefix + result + ')'",
        "return prefix +"
    ],
    [
        "\"\"\"Compare self with other using operator.eq or operator.ne.",
        "\"\"\"Compare self with other using operator.eq"
    ],
    [
        "When either of the elements is masked, the result is masked as well,",
        "When either of the elements is masked, the result is masked"
    ],
    [
        "but the underlying boolean data are still set, with self and other",
        "but the underlying boolean data are"
    ],
    [
        "considered equal if both are masked, and unequal otherwise.",
        "considered equal if both are"
    ],
    [
        "For structured arrays, all fields are combined, with masked values",
        "For structured arrays, all fields are"
    ],
    [
        "ignored. The result is masked if all fields were masked, with self",
        "ignored. The result is masked if all fields were masked,"
    ],
    [
        "and other considered equal only if both were fully masked.",
        "and other considered equal only"
    ],
    [
        "if compare not in (operator.eq, operator.ne):",
        "if compare not in (operator.eq,"
    ],
    [
        "mask = (mask == np.ones((), mask.dtype))",
        "mask = (mask =="
    ],
    [
        "return masked if mask else check",
        "return masked if mask"
    ],
    [
        "check = np.where(mask, compare(smask, omask), check)",
        "check = np.where(mask, compare(smask,"
    ],
    [
        "\"\"\"Check whether other equals self elementwise.",
        "\"\"\"Check whether other equals self"
    ],
    [
        "When either of the elements is masked, the result is masked as well,",
        "When either of the elements is masked, the result"
    ],
    [
        "but the underlying boolean data are still set, with self and other",
        "but the underlying boolean data are"
    ],
    [
        "considered equal if both are masked, and unequal otherwise.",
        "considered equal if both are masked, and unequal"
    ],
    [
        "For structured arrays, all fields are combined, with masked values",
        "For structured arrays, all fields"
    ],
    [
        "ignored. The result is masked if all fields were masked, with self",
        "ignored. The result is masked if all fields were masked, with"
    ],
    [
        "and other considered equal only if both were fully masked.",
        "and other considered equal only if both were fully"
    ],
    [
        "\"\"\"Check whether other does not equal self elementwise.",
        "\"\"\"Check whether other does"
    ],
    [
        "When either of the elements is masked, the result is masked as well,",
        "When either of the elements is masked, the result is"
    ],
    [
        "but the underlying boolean data are still set, with self and other",
        "but the underlying boolean data are still"
    ],
    [
        "considered equal if both are masked, and unequal otherwise.",
        "considered equal if both are masked, and unequal"
    ],
    [
        "For structured arrays, all fields are combined, with masked values",
        "For structured arrays, all fields are combined, with"
    ],
    [
        "ignored. The result is masked if all fields were masked, with self",
        "ignored. The result is masked if all"
    ],
    [
        "and other considered equal only if both were fully masked.",
        "and other considered equal only if both were"
    ],
    [
        "Add self to other, and return a new masked array.",
        "Add self to other, and"
    ],
    [
        "Add other to self, and return a new masked array.",
        "Add other to self, and return a"
    ],
    [
        "Subtract other from self, and return a new masked array.",
        "Subtract other from self, and"
    ],
    [
        "Subtract self from other, and return a new masked array.",
        "Subtract self from other, and return a new masked"
    ],
    [
        "\"Multiply self by other, and return a new masked array.\"",
        "\"Multiply self by other, and return a"
    ],
    [
        "Multiply other by self, and return a new masked array.",
        "Multiply other by self, and return a new masked"
    ],
    [
        "Divide other into self, and return a new masked array.",
        "Divide other into self, and return a new masked"
    ],
    [
        "Divide other into self, and return a new masked array.",
        "Divide other into self, and"
    ],
    [
        "Divide self into other, and return a new masked array.",
        "Divide self into other, and return a new"
    ],
    [
        "Divide other into self, and return a new masked array.",
        "Divide other into self, and return"
    ],
    [
        "Divide self into other, and return a new masked array.",
        "Divide self into other, and"
    ],
    [
        "Raise self to the power other, masking the potential NaNs/Infs",
        "Raise self to the power"
    ],
    [
        "Raise other to the power self, masking the potential NaNs/Infs",
        "Raise other to the power self,"
    ],
    [
        "if m is not nomask and m.any():",
        "if m is not nomask and"
    ],
    [
        "if m is not nomask and m.any():",
        "if m is not"
    ],
    [
        "if m is not nomask and m.any():",
        "if m is not nomask"
    ],
    [
        "Floor divide self by other in-place.",
        "Floor divide self by other"
    ],
    [
        "True divide self by other in-place.",
        "True divide self"
    ],
    [
        "Raise self to the power other, in place.",
        "Raise self to the power"
    ],
    [
        "raise MaskError('Cannot convert masked element to a Python int.')",
        "raise MaskError('Cannot convert masked element to a"
    ],
    [
        "The imaginary part of the masked array.",
        "The imaginary part of"
    ],
    [
        "This property is a view on the imaginary part of this `MaskedArray`.",
        "This property is a view on"
    ],
    [
        "The real part of the masked array.",
        "The real part of"
    ],
    [
        "This property is a view on the real part of this `MaskedArray`.",
        "This property is a view on the real part of"
    ],
    [
        "Count the non-masked elements of the array along the given axis.",
        "Count the non-masked elements of the array along the"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int"
    ],
    [
        "Axis or axes along which the count is performed.",
        "Axis or axes along which the count"
    ],
    [
        "The default, None, performs the count over all",
        "The default, None, performs the count"
    ],
    [
        "the dimensions of the input array. `axis` may be negative, in",
        "the dimensions of the input array. `axis` may be negative,"
    ],
    [
        "which case it counts from the last to the first axis.",
        "which case it counts from the"
    ],
    [
        "If this is a tuple of ints, the count is performed on multiple",
        "If this is a tuple of ints,"
    ],
    [
        "axes, instead of a single axis or all the axes as before.",
        "axes, instead of a single axis or all"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size"
    ],
    [
        "the result will broadcast correctly against the array.",
        "the result will broadcast"
    ],
    [
        "An array with the same shape as the input array, with the specified",
        "An array with the same shape as"
    ],
    [
        "ma.count_masked : Count masked elements in array or along a given axis.",
        "ma.count_masked : Count masked elements in array or along a"
    ],
    [
        "When the `axis` keyword is specified an array of appropriate size is",
        "When the `axis` keyword is specified"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue else"
    ],
    [
        "out_dims = [d for n, d in enumerate(self.shape)",
        "out_dims = [d for n,"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A',"
    ],
    [
        "The elements of `a` are read using this index order. 'C' means to",
        "The elements of `a` are read using this index order. 'C' means"
    ],
    [
        "index the elements in C-like order, with the last axis index",
        "index the elements in C-like order,"
    ],
    [
        "changing fastest, back to the first axis index changing slowest.",
        "changing fastest, back to the"
    ],
    [
        "'F' means to index the elements in Fortran-like index order, with",
        "'F' means to index the elements in Fortran-like"
    ],
    [
        "the first index changing fastest, and the last index changing",
        "the first index changing fastest, and the last index"
    ],
    [
        "slowest. Note that the 'C' and 'F' options take no account of the",
        "slowest. Note that the 'C' and 'F' options take no account"
    ],
    [
        "memory layout of the underlying array, and only refer to the order",
        "memory layout of the underlying array, and only refer to the"
    ],
    [
        "of axis indexing.  'A' means to read the elements in Fortran-like",
        "of axis indexing. 'A' means to read the elements"
    ],
    [
        "index order if `m` is Fortran *contiguous* in memory, C-like order",
        "index order if `m` is Fortran *contiguous*"
    ],
    [
        "otherwise.  'K' means to read the elements in the order they occur",
        "otherwise. 'K' means to read the elements in the order they"
    ],
    [
        "in memory, except for reversing the data when strides are negative.",
        "in memory, except for reversing the data"
    ],
    [
        "By default, 'C' index order is used.",
        "By default, 'C' index"
    ],
    [
        "(Masked arrays currently use 'A' on the data when 'K' is passed.)",
        "(Masked arrays currently use 'A' on the data"
    ],
    [
        "Output view is of shape ``(self.size,)`` (or",
        "Output view is of shape ``(self.size,)``"
    ],
    [
        "mask=[False,  True, False,  True, False,  True, False,  True,",
        "mask=[False, True, False, True, False, True,"
    ],
    [
        "order = \"F\" if self._data.flags.fnc else \"C\"",
        "order = \"F\" if"
    ],
    [
        "Give a new shape to the array without changing its data.",
        "Give a new shape to the array without changing"
    ],
    [
        "Returns a masked array containing the same data, but with a new shape.",
        "Returns a masked array containing the same data, but"
    ],
    [
        "The result is a view on the original array; if this is not possible, a",
        "The result is a view on the original"
    ],
    [
        "shape : int or tuple of ints",
        "shape : int or"
    ],
    [
        "The new shape should be compatible with the original shape. If an",
        "The new shape should be compatible with the"
    ],
    [
        "Determines whether the array data should be viewed as in C",
        "Determines whether the array data should be"
    ],
    [
        "A new view on the array.",
        "A new view on the"
    ],
    [
        "reshape : Equivalent function in the masked array module.",
        "reshape : Equivalent function in the"
    ],
    [
        "numpy.ndarray.reshape : Equivalent method on ndarray object.",
        "numpy.ndarray.reshape : Equivalent method on ndarray"
    ],
    [
        "numpy.reshape : Equivalent function in the NumPy module.",
        "numpy.reshape : Equivalent function in the"
    ],
    [
        "The reshaping operation cannot guarantee that a copy will not be made,",
        "The reshaping operation cannot guarantee that a copy will not be"
    ],
    [
        "to modify the shape in place, use ``a.shape = s``",
        "to modify the shape in place,"
    ],
    [
        "This method does nothing, except raise a ValueError exception. A",
        "This method does nothing, except"
    ],
    [
        "masked array does not own its data and therefore cannot safely be",
        "masked array does not own its data"
    ],
    [
        "resized in place. Use the `numpy.ma.resize` function instead.",
        "resized in place. Use the `numpy.ma.resize`"
    ],
    [
        "This method is difficult to implement safely and may be deprecated in",
        "This method is difficult to implement safely and may be deprecated"
    ],
    [
        "errmsg = \"A masked array does not own its data \"\\",
        "errmsg = \"A masked array does not"
    ],
    [
        "\"and therefore cannot be resized.\\n\" \\",
        "\"and therefore cannot"
    ],
    [
        "Set storage-indexed locations to corresponding values.",
        "Set storage-indexed locations"
    ],
    [
        "Sets self._data.flat[n] = values[n] for each n in indices.",
        "Sets self._data.flat[n] = values[n] for each"
    ],
    [
        "If `values` is shorter than `indices` then it will repeat.",
        "If `values` is shorter than"
    ],
    [
        "If `values` has some masked values, the initial mask is updated",
        "If `values` has some masked values, the initial mask"
    ],
    [
        "in consequence, else the corresponding values are unmasked.",
        "in consequence, else the"
    ],
    [
        "Values to place in self._data copy at target indices.",
        "Values to place in self._data copy at target"
    ],
    [
        "mode : {'raise', 'wrap', 'clip'}, optional",
        "mode : {'raise',"
    ],
    [
        "Specifies how out-of-bounds indices will behave.",
        "Specifies how out-of-bounds indices"
    ],
    [
        "'clip' : clip to the range.",
        "'clip' : clip to"
    ],
    [
        "if self._hardmask and self._mask is not nomask:",
        "if self._hardmask and self._mask is not"
    ],
    [
        "if self._mask is nomask and getmask(values) is nomask:",
        "if self._mask is nomask"
    ],
    [
        "Return the addresses of the data and mask areas.",
        "Return the addresses of the data and mask"
    ],
    [
        "If the array has no mask, the address of `nomask` is returned. This address",
        "If the array has no mask, the"
    ],
    [
        "is typically not close to the data in memory:",
        "is typically not close to the data"
    ],
    [
        "Return a boolean indicating whether the data is contiguous.",
        "Return a boolean indicating whether the data is"
    ],
    [
        "`iscontiguous` returns one of the flags of the masked array:",
        "`iscontiguous` returns one of the flags of the"
    ],
    [
        "Returns True if all elements evaluate to True.",
        "Returns True if all elements evaluate to"
    ],
    [
        "The output array is masked where all the values along the given axis",
        "The output array is masked where all the values along the"
    ],
    [
        "are masked: if the output would have been a scalar and that all the",
        "are masked: if the output would have been"
    ],
    [
        "values are masked, then the output is `masked`.",
        "values are masked, then the output is"
    ],
    [
        "Refer to `numpy.all` for full documentation.",
        "Refer to `numpy.all` for"
    ],
    [
        "numpy.ndarray.all : corresponding function for ndarrays",
        "numpy.ndarray.all : corresponding"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims"
    ],
    [
        "Returns True if any of the elements of `a` evaluate to True.",
        "Returns True if any of the elements of `a` evaluate to"
    ],
    [
        "Masked values are considered as False during computation.",
        "Masked values are considered as"
    ],
    [
        "Refer to `numpy.any` for full documentation.",
        "Refer to `numpy.any` for"
    ],
    [
        "numpy.ndarray.any : corresponding function for ndarrays",
        "numpy.ndarray.any : corresponding function for"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue else"
    ],
    [
        "Return the indices of unmasked elements that are not zero.",
        "Return the indices of unmasked"
    ],
    [
        "Returns a tuple of arrays, one for each dimension, containing the",
        "Returns a tuple of arrays, one for each dimension,"
    ],
    [
        "indices of the non-zero elements in that dimension. The corresponding",
        "indices of the non-zero elements in that"
    ],
    [
        "non-zero values can be obtained with::",
        "non-zero values can be obtained"
    ],
    [
        "To group the indices by element, rather than dimension, use",
        "To group the indices by element, rather"
    ],
    [
        "Indices of elements that are non-zero.",
        "Indices of elements that are"
    ],
    [
        "Return indices that are non-zero in the flattened version of the input",
        "Return indices that are non-zero in the flattened version of"
    ],
    [
        "Counts the number of non-zero elements in the input array.",
        "Counts the number of non-zero elements in"
    ],
    [
        "Indices can also be grouped by element.",
        "Indices can also be"
    ],
    [
        "A common use for ``nonzero`` is to find the indices of an array, where",
        "A common use for ``nonzero`` is to find the indices of an array,"
    ],
    [
        "yields the indices of the `a` where the condition is true.",
        "yields the indices of the `a` where the"
    ],
    [
        "The ``nonzero`` method of the condition array can also be called.",
        "The ``nonzero`` method of the condition array can also be"
    ],
    [
        "Masked dot product of two arrays. Note that `out` and `strict` are",
        "Masked dot product of two arrays. Note"
    ],
    [
        "located in different positions than in `ma.dot`. In order to",
        "located in different positions than in `ma.dot`."
    ],
    [
        "maintain compatibility with the functional version, it is",
        "maintain compatibility with the functional version,"
    ],
    [
        "recommended that the optional arguments be treated as keyword only.",
        "recommended that the optional arguments be treated as"
    ],
    [
        "At some point that may be mandatory.",
        "At some point that"
    ],
    [
        "Output argument. This must have the exact kind that would be",
        "Output argument. This must have the exact"
    ],
    [
        "returned if it was not used. In particular, it must have the",
        "returned if it was not used."
    ],
    [
        "right type, must be C-contiguous, and its dtype must be the",
        "right type, must be C-contiguous, and"
    ],
    [
        "dtype that would be returned for `ma.dot(a,b)`. This is a",
        "dtype that would be returned for `ma.dot(a,b)`. This"
    ],
    [
        "performance feature. Therefore, if these conditions are not",
        "performance feature. Therefore, if these conditions are"
    ],
    [
        "met, an exception is raised, instead of attempting to be",
        "met, an exception is raised, instead"
    ],
    [
        "for the computation. Default is False.  Propagating the mask",
        "for the computation. Default is False. Propagating the"
    ],
    [
        "means that if a masked value appears in a row or column, the",
        "means that if a masked value appears in a row or column,"
    ],
    [
        "whole row or column is considered masked.",
        "whole row or column"
    ],
    [
        "def sum(self, axis=None, dtype=None, out=None, keepdims=np._NoValue):",
        "def sum(self, axis=None,"
    ],
    [
        "Return the sum of the array elements over the given axis.",
        "Return the sum of the array"
    ],
    [
        "Refer to `numpy.sum` for full documentation.",
        "Refer to `numpy.sum`"
    ],
    [
        "numpy.ndarray.sum : corresponding function for ndarrays",
        "numpy.ndarray.sum : corresponding function for"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue else {'keepdims':"
    ],
    [
        "Return the cumulative sum of the array elements over the given axis.",
        "Return the cumulative sum of the array elements over the given"
    ],
    [
        "However, their position is saved, and the result will be masked at",
        "However, their position is saved, and the"
    ],
    [
        "Refer to `numpy.cumsum` for full documentation.",
        "Refer to `numpy.cumsum` for"
    ],
    [
        "The mask is lost if `out` is not a valid :class:`ma.MaskedArray` !",
        "The mask is lost if `out` is"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is",
        "Arithmetic is modular when using integer types, and"
    ],
    [
        "numpy.ndarray.cumsum : corresponding function for ndarrays",
        "numpy.ndarray.cumsum : corresponding function"
    ],
    [
        "mask=[False, False, False,  True,  True,  True, False, False,",
        "mask=[False, False, False, True, True, True,"
    ],
    [
        "def prod(self, axis=None, dtype=None, out=None, keepdims=np._NoValue):",
        "def prod(self, axis=None,"
    ],
    [
        "Return the product of the array elements over the given axis.",
        "Return the product of the array"
    ],
    [
        "Refer to `numpy.prod` for full documentation.",
        "Refer to `numpy.prod` for full"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is raised",
        "Arithmetic is modular when using integer types, and no error"
    ],
    [
        "numpy.ndarray.prod : corresponding function for ndarrays",
        "numpy.ndarray.prod : corresponding function"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue else {'keepdims':"
    ],
    [
        "Return the cumulative product of the array elements over the given axis.",
        "Return the cumulative product of the array elements"
    ],
    [
        "However, their position is saved, and the result will be masked at",
        "However, their position is saved, and the result will be masked"
    ],
    [
        "Refer to `numpy.cumprod` for full documentation.",
        "Refer to `numpy.cumprod` for"
    ],
    [
        "The mask is lost if `out` is not a valid MaskedArray !",
        "The mask is lost if `out` is not"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is",
        "Arithmetic is modular when using integer"
    ],
    [
        "numpy.ndarray.cumprod : corresponding function for ndarrays",
        "numpy.ndarray.cumprod : corresponding function for"
    ],
    [
        "def mean(self, axis=None, dtype=None, out=None, keepdims=np._NoValue):",
        "def mean(self, axis=None, dtype=None, out=None,"
    ],
    [
        "Returns the average of the array elements along given axis.",
        "Returns the average of the array elements along"
    ],
    [
        "Masked entries are ignored, and result elements which are not",
        "Masked entries are ignored, and result elements which are"
    ],
    [
        "Refer to `numpy.mean` for full documentation.",
        "Refer to `numpy.mean` for full"
    ],
    [
        "numpy.ndarray.mean : corresponding function for ndarrays",
        "numpy.ndarray.mean : corresponding function for"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue else {'keepdims':"
    ],
    [
        "Compute the anomalies (deviations from the arithmetic mean)",
        "Compute the anomalies (deviations from the arithmetic"
    ],
    [
        "Returns an array of anomalies, with the same shape as the input and",
        "Returns an array of anomalies, with the"
    ],
    [
        "where the arithmetic mean is computed along the given axis.",
        "where the arithmetic mean is computed"
    ],
    [
        "Axis over which the anomalies are taken.",
        "Axis over which the anomalies"
    ],
    [
        "The default is to use the mean of the flattened array as reference.",
        "The default is to use the mean of the"
    ],
    [
        "Type to use in computing the variance. For arrays of integer type",
        "Type to use in computing the variance. For"
    ],
    [
        "mean : Compute the mean of the array.",
        "mean : Compute the mean"
    ],
    [
        "Returns the variance of the array elements along given axis.",
        "Returns the variance of the array"
    ],
    [
        "Masked entries are ignored, and result elements which are not",
        "Masked entries are ignored, and result elements which"
    ],
    [
        "Refer to `numpy.var` for full documentation.",
        "Refer to `numpy.var` for"
    ],
    [
        "numpy.ndarray.var : corresponding function for ndarrays",
        "numpy.ndarray.var : corresponding function for"
    ],
    [
        "ret = super().var(axis=axis, dtype=dtype, out=out, ddof=ddof,",
        "ret = super().var(axis=axis,"
    ],
    [
        "cnt = self.count(axis=axis, **kwargs) - ddof",
        "cnt = self.count(axis=axis, **kwargs)"
    ],
    [
        "danom = self - self.mean(axis, dtype, keepdims=True)",
        "danom = self -"
    ],
    [
        "errmsg = \"Masked data information would be lost in one or \"\\",
        "errmsg = \"Masked data information would be lost in"
    ],
    [
        "Returns the standard deviation of the array elements along given axis.",
        "Returns the standard deviation of the array elements"
    ],
    [
        "Refer to `numpy.std` for full documentation.",
        "Refer to `numpy.std`"
    ],
    [
        "numpy.ndarray.std : corresponding function for ndarrays",
        "numpy.ndarray.std : corresponding function"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is"
    ],
    [
        "dvar = self.var(axis, dtype, out, ddof, **kwargs)",
        "dvar = self.var(axis, dtype, out,"
    ],
    [
        "Return each element rounded to the given number of decimals.",
        "Return each element rounded to"
    ],
    [
        "Refer to `numpy.around` for full documentation.",
        "Refer to `numpy.around` for"
    ],
    [
        "numpy.ndarray.round : corresponding function for ndarrays",
        "numpy.ndarray.round : corresponding function"
    ],
    [
        "mask=[False, False, False,  True, False, False],",
        "mask=[False, False, False, True,"
    ],
    [
        "def argsort(self, axis=np._NoValue, kind=None, order=None, endwith=True,",
        "def argsort(self, axis=np._NoValue, kind=None,"
    ],
    [
        "Return an ndarray of indices that sort the array along the",
        "Return an ndarray of indices that sort the"
    ],
    [
        "specified axis.  Masked values are filled beforehand to",
        "specified axis. Masked values are filled"
    ],
    [
        "Axis along which to sort. If None, the default, the flattened array",
        "Axis along which to sort. If None, the default,"
    ],
    [
        "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional",
        "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'},"
    ],
    [
        "When `a` is an array with fields defined, this argument specifies",
        "When `a` is an array with fields defined, this argument"
    ],
    [
        "which fields to compare first, second, etc.  Not all fields need be",
        "which fields to compare first, second, etc."
    ],
    [
        "Whether missing values (if any) should be treated as the largest values",
        "Whether missing values (if any) should be treated"
    ],
    [
        "(True) or the smallest values (False)",
        "(True) or the smallest"
    ],
    [
        "When the array contains unmasked values at the same extremes of the",
        "When the array contains unmasked values at the same"
    ],
    [
        "datatype, the ordering of these values and the masked values is",
        "datatype, the ordering of these values and the masked"
    ],
    [
        "fill_value : scalar or None, optional",
        "fill_value : scalar or None,"
    ],
    [
        "Value used internally for the masked values.",
        "Value used internally for"
    ],
    [
        "If ``fill_value`` is not None, it supersedes ``endwith``.",
        "If ``fill_value`` is not None, it supersedes"
    ],
    [
        "Only for compatibility with ``np.argsort``. Ignored.",
        "Only for compatibility with ``np.argsort``."
    ],
    [
        "Array of indices that sort `a` along the specified axis.",
        "Array of indices that sort `a`"
    ],
    [
        "In other words, ``a[index_array]`` yields a sorted `a`.",
        "In other words, ``a[index_array]`` yields"
    ],
    [
        "ma.MaskedArray.sort : Describes sorting algorithms used.",
        "ma.MaskedArray.sort : Describes sorting algorithms"
    ],
    [
        "lexsort : Indirect stable sort with multiple keys.",
        "lexsort : Indirect stable sort"
    ],
    [
        "See `sort` for notes on the different sorting algorithms.",
        "See `sort` for notes on"
    ],
    [
        "\"`stable` parameter is not supported for masked arrays.\"",
        "\"`stable` parameter is not supported"
    ],
    [
        "def argmin(self, axis=None, fill_value=None, out=None, *,",
        "def argmin(self, axis=None, fill_value=None,"
    ],
    [
        "Return array of indices to the minimum values along the given axis.",
        "Return array of indices to the minimum values"
    ],
    [
        "If None, the index is into the flattened array, otherwise along",
        "If None, the index is into the flattened array,"
    ],
    [
        "fill_value : scalar or None, optional",
        "fill_value : scalar or None,"
    ],
    [
        "Value used to fill in the masked values.  If None, the output of",
        "Value used to fill in the masked values. If None,"
    ],
    [
        "Array into which the result can be placed. Its type is preserved",
        "Array into which the result can"
    ],
    [
        "and it must be of the right shape to hold the output.",
        "and it must be of the right"
    ],
    [
        "If multi-dimension input, returns a new ndarray of indices to the",
        "If multi-dimension input, returns a new"
    ],
    [
        "minimum values along the given axis.  Otherwise, returns a scalar",
        "minimum values along the given axis. Otherwise, returns"
    ],
    [
        "of index to the minimum values along the given axis.",
        "of index to the minimum values along"
    ],
    [
        "keepdims = False if keepdims is np._NoValue else bool(keepdims)",
        "keepdims = False if keepdims is"
    ],
    [
        "def argmax(self, axis=None, fill_value=None, out=None, *,",
        "def argmax(self, axis=None, fill_value=None, out=None,"
    ],
    [
        "Returns array of indices of the maximum values along the given axis.",
        "Returns array of indices of the maximum values along the given"
    ],
    [
        "Masked values are treated as if they had the value fill_value.",
        "Masked values are treated as if they had the value"
    ],
    [
        "If None, the index is into the flattened array, otherwise along",
        "If None, the index is into the flattened array,"
    ],
    [
        "fill_value : scalar or None, optional",
        "fill_value : scalar or None,"
    ],
    [
        "Value used to fill in the masked values.  If None, the output of",
        "Value used to fill in the masked values."
    ],
    [
        "Array into which the result can be placed. Its type is preserved",
        "Array into which the result can be placed. Its type"
    ],
    [
        "and it must be of the right shape to hold the output.",
        "and it must be of the right shape"
    ],
    [
        "keepdims = False if keepdims is np._NoValue else bool(keepdims)",
        "keepdims = False if keepdims is np._NoValue"
    ],
    [
        "Axis along which to sort. If None, the array is flattened before",
        "Axis along which to sort. If None, the array is flattened"
    ],
    [
        "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional",
        "kind : {'quicksort', 'mergesort',"
    ],
    [
        "When `a` is a structured array, this argument specifies which fields",
        "When `a` is a structured array, this argument specifies which"
    ],
    [
        "to compare first, second, and so on.  This list does not need to",
        "to compare first, second, and so on. This list does"
    ],
    [
        "Whether missing values (if any) should be treated as the largest values",
        "Whether missing values (if any) should be"
    ],
    [
        "(True) or the smallest values (False)",
        "(True) or the smallest values"
    ],
    [
        "When the array contains unmasked values sorting at the same extremes of the",
        "When the array contains unmasked values sorting at the same extremes"
    ],
    [
        "datatype, the ordering of these values and the masked values is",
        "datatype, the ordering of these values and"
    ],
    [
        "fill_value : scalar or None, optional",
        "fill_value : scalar or None,"
    ],
    [
        "Value used internally for the masked values.",
        "Value used internally for the"
    ],
    [
        "If ``fill_value`` is not None, it supersedes ``endwith``.",
        "If ``fill_value`` is not None,"
    ],
    [
        "Only for compatibility with ``np.sort``. Ignored.",
        "Only for compatibility with ``np.sort``."
    ],
    [
        "Array of the same type and shape as `a`.",
        "Array of the same type and shape"
    ],
    [
        "numpy.ndarray.sort : Method to sort an array in-place.",
        "numpy.ndarray.sort : Method to sort"
    ],
    [
        "lexsort : Indirect stable sort on multiple keys.",
        "lexsort : Indirect stable sort"
    ],
    [
        "searchsorted : Find elements in a sorted array.",
        "searchsorted : Find elements"
    ],
    [
        "See ``sort`` for notes on the different sorting algorithms.",
        "See ``sort`` for notes on"
    ],
    [
        "mask=[ True,  True, False, False, False],",
        "mask=[ True, True, False,"
    ],
    [
        "\"`stable` parameter is not supported for masked arrays.\"",
        "\"`stable` parameter is not"
    ],
    [
        "def min(self, axis=None, out=None, fill_value=None, keepdims=np._NoValue):",
        "def min(self, axis=None, out=None, fill_value=None,"
    ],
    [
        "Return the minimum along a given axis.",
        "Return the minimum along a"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple of ints,"
    ],
    [
        "Axis along which to operate.  By default, ``axis`` is None and the",
        "Axis along which to operate. By default, ``axis`` is None"
    ],
    [
        "If this is a tuple of ints, the minimum is selected over multiple",
        "If this is a tuple of ints, the minimum"
    ],
    [
        "axes, instead of a single axis or all the axes as before.",
        "axes, instead of a single axis or all the"
    ],
    [
        "Alternative output array in which to place the result.  Must be of",
        "Alternative output array in which to place"
    ],
    [
        "the same shape and buffer length as the expected output.",
        "the same shape and buffer length as the"
    ],
    [
        "fill_value : scalar or None, optional",
        "fill_value : scalar"
    ],
    [
        "Value used to fill in the masked values.",
        "Value used to fill in"
    ],
    [
        "If None, use the output of `minimum_fill_value`.",
        "If None, use the output of"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced are"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With"
    ],
    [
        "the result will broadcast correctly against the array.",
        "the result will broadcast correctly against the"
    ],
    [
        "If ``out`` was specified, ``out`` is returned.",
        "If ``out`` was specified,"
    ],
    [
        "Returns the minimum filling value for a given datatype.",
        "Returns the minimum filling value for"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue"
    ],
    [
        "errmsg = \"Masked data information would be lost in one or more\"\\",
        "errmsg = \"Masked data information would be lost in one"
    ],
    [
        "def max(self, axis=None, out=None, fill_value=None, keepdims=np._NoValue):",
        "def max(self, axis=None,"
    ],
    [
        "Return the maximum along a given axis.",
        "Return the maximum along a"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or"
    ],
    [
        "Axis along which to operate.  By default, ``axis`` is None and the",
        "Axis along which to operate. By default, ``axis``"
    ],
    [
        "If this is a tuple of ints, the maximum is selected over multiple",
        "If this is a tuple of ints,"
    ],
    [
        "axes, instead of a single axis or all the axes as before.",
        "axes, instead of a single axis"
    ],
    [
        "Alternative output array in which to place the result.  Must",
        "Alternative output array in which to place the"
    ],
    [
        "be of the same shape and buffer length as the expected output.",
        "be of the same shape and buffer length"
    ],
    [
        "fill_value : scalar or None, optional",
        "fill_value : scalar"
    ],
    [
        "Value used to fill in the masked values.",
        "Value used to fill"
    ],
    [
        "If None, use the output of maximum_fill_value().",
        "If None, use the output"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with"
    ],
    [
        "the result will broadcast correctly against the array.",
        "the result will broadcast correctly against the"
    ],
    [
        "If ``out`` was specified, ``out`` is returned.",
        "If ``out`` was specified, ``out`` is"
    ],
    [
        "Returns the maximum filling value for a given datatype.",
        "Returns the maximum filling value for a given"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue else"
    ],
    [
        "errmsg = \"Masked data information would be lost in one or more\"\\",
        "errmsg = \"Masked data information would be lost in one or"
    ],
    [
        "def ptp(self, axis=None, out=None, fill_value=None, keepdims=False):",
        "def ptp(self, axis=None,"
    ],
    [
        "Return (maximum - minimum) along the given dimension",
        "Return (maximum - minimum) along the given"
    ],
    [
        "`ptp` preserves the data type of the array. This means the",
        "`ptp` preserves the data type of the array. This means"
    ],
    [
        "return value for an input of signed integers with n bits",
        "return value for an input of signed integers"
    ],
    [
        "with n bits.  In that case, peak-to-peak values greater than",
        "with n bits. In that case,"
    ],
    [
        "with a work-around is shown below.",
        "with a work-around is shown"
    ],
    [
        "Axis along which to find the peaks.  If None (default) the",
        "Axis along which to find the peaks. If None"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the result. It"
    ],
    [
        "have the same shape and buffer length as the expected output",
        "have the same shape and buffer"
    ],
    [
        "but the type will be cast if necessary.",
        "but the type will"
    ],
    [
        "fill_value : scalar or None, optional",
        "fill_value : scalar or None,"
    ],
    [
        "Value used to fill in the masked values.",
        "Value used to fill in the"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with"
    ],
    [
        "the result will broadcast correctly against the array.",
        "the result will broadcast correctly against the"
    ],
    [
        "A new array holding the result, unless ``out`` was",
        "A new array holding the result,"
    ],
    [
        "specified, in which case a reference to ``out`` is returned.",
        "specified, in which case a reference"
    ],
    [
        "This example shows that a negative value can be returned when",
        "This example shows that a negative"
    ],
    [
        "the input is an array of signed integers.",
        "the input is an array of"
    ],
    [
        "A work-around is to use the `view()` method to view the result as",
        "A work-around is to use the `view()` method to view"
    ],
    [
        "unsigned integers with the same bit width:",
        "unsigned integers with the same bit"
    ],
    [
        "warnings.warn(\"Warning: 'partition' will ignore the 'mask' \"",
        "warnings.warn(\"Warning: 'partition' will ignore the 'mask'"
    ],
    [
        "warnings.warn(\"Warning: 'argpartition' will ignore the 'mask' \"",
        "warnings.warn(\"Warning: 'argpartition' will ignore the 'mask'"
    ],
    [
        "def take(self, indices, axis=None, out=None, mode='raise'):",
        "def take(self, indices, axis=None, out=None,"
    ],
    [
        "Take elements from a masked array along an axis.",
        "Take elements from a masked array along an"
    ],
    [
        "This function does the same thing as \"fancy\" indexing (indexing arrays",
        "This function does the same thing as \"fancy\""
    ],
    [
        "using arrays) for masked arrays. It can be easier to use if you need",
        "using arrays) for masked arrays. It can be easier to"
    ],
    [
        "The indices of the values to extract. Also allow scalars for indices.",
        "The indices of the values to extract."
    ],
    [
        "The axis over which to select values. By default, the flattened",
        "The axis over which to select values. By default,"
    ],
    [
        "If provided, the result will be placed in this array. It should",
        "If provided, the result will be placed in this array."
    ],
    [
        "be of the appropriate shape and dtype. Note that `out` is always",
        "be of the appropriate shape and dtype."
    ],
    [
        "buffered if `mode='raise'`; use other modes for better performance.",
        "buffered if `mode='raise'`; use other modes for better"
    ],
    [
        "mode : {'raise', 'wrap', 'clip'}, optional",
        "mode : {'raise', 'wrap',"
    ],
    [
        "Specifies how out-of-bounds indices will behave.",
        "Specifies how out-of-bounds indices will"
    ],
    [
        "* 'raise' -- raise an error (default)",
        "* 'raise' -- raise"
    ],
    [
        "* 'clip' -- clip to the range",
        "* 'clip' -- clip to"
    ],
    [
        "'clip' mode means that all indices that are too large are replaced",
        "'clip' mode means that all indices that are"
    ],
    [
        "by the index that addresses the last element along that axis. Note",
        "by the index that addresses the last element along"
    ],
    [
        "that this disables indexing with negative numbers.",
        "that this disables indexing with"
    ],
    [
        "The returned array has the same type as `a`.",
        "The returned array has the"
    ],
    [
        "numpy.take : Equivalent function for ndarrays.",
        "numpy.take : Equivalent"
    ],
    [
        "compress : Take elements using a boolean mask.",
        "compress : Take elements"
    ],
    [
        "take_along_axis : Take elements by matching the array and the index arrays.",
        "take_along_axis : Take elements by matching the array and"
    ],
    [
        "This function behaves similarly to `numpy.take`, but it handles masked",
        "This function behaves similarly to `numpy.take`, but"
    ],
    [
        "values. The mask is retained in the output array, and masked values",
        "values. The mask is retained in"
    ],
    [
        "in the input array remain masked in the output.",
        "in the input array remain masked in"
    ],
    [
        "When `indices` is not one-dimensional, the output also has these dimensions:",
        "When `indices` is not one-dimensional, the"
    ],
    [
        "Return the matrix-transpose of the masked array.",
        "Return the matrix-transpose of"
    ],
    [
        "The matrix transpose is the transpose of the last two dimensions, even",
        "The matrix transpose is the transpose"
    ],
    [
        "if the array is of higher dimension.",
        "if the array is"
    ],
    [
        "The masked array with the last two dimensions transposed",
        "The masked array with the last two"
    ],
    [
        "Return the data portion of the masked array as a hierarchical Python list.",
        "Return the data portion of the masked array as a hierarchical"
    ],
    [
        "Data items are converted to the nearest compatible Python type.",
        "Data items are converted to the nearest compatible Python"
    ],
    [
        "Masked values are converted to `fill_value`. If `fill_value` is None,",
        "Masked values are converted to `fill_value`."
    ],
    [
        "the corresponding entries in the output list will be ``None``.",
        "the corresponding entries in the output list will"
    ],
    [
        "The value to use for invalid entries. Default is None.",
        "The value to use for invalid entries."
    ],
    [
        "The Python list representation of the masked array.",
        "The Python list representation of"
    ],
    [
        "result = self._data.astype([(_, object) for _ in names])",
        "result = self._data.astype([(_, object) for"
    ],
    [
        "Return the array data as a string containing the raw bytes in the array.",
        "Return the array data as a string containing the raw bytes"
    ],
    [
        "The array is filled with a fill value before the string conversion.",
        "The array is filled with a fill value"
    ],
    [
        "Value used to fill in the masked values. Default is None, in which",
        "Value used to fill in the masked values. Default is"
    ],
    [
        "Order of the data item in the copy. Default is 'C'.",
        "Order of the data item in the copy."
    ],
    [
        "- 'C'   -- C order (row major).",
        "- 'C' -- C order (row"
    ],
    [
        "- 'F'   -- Fortran order (column major).",
        "- 'F' -- Fortran order"
    ],
    [
        "- 'A'   -- Any, current order of array.",
        "- 'A' -- Any, current order of"
    ],
    [
        "- None  -- Same as 'A'.",
        "- None -- Same"
    ],
    [
        "As for `ndarray.tobytes`, information about the shape, dtype, etc.,",
        "As for `ndarray.tobytes`, information about the"
    ],
    [
        "but also about `fill_value`, will be lost.",
        "but also about `fill_value`,"
    ],
    [
        "Save a masked array to a file in binary format.",
        "Save a masked array to a file in binary"
    ],
    [
        "This function is not implemented yet.",
        "This function is not implemented"
    ],
    [
        "Transforms a masked array into a flexible-type array.",
        "Transforms a masked array into"
    ],
    [
        "The flexible type array that is returned will have two fields:",
        "The flexible type array that is returned"
    ],
    [
        "* the ``_data`` field stores the ``_data`` part of the array.",
        "* the ``_data`` field stores the ``_data`` part"
    ],
    [
        "* the ``_mask`` field stores the ``_mask`` part of the array.",
        "* the ``_mask`` field stores the ``_mask`` part"
    ],
    [
        "A new flexible-type `ndarray` with two fields: the first element",
        "A new flexible-type `ndarray` with two fields: the"
    ],
    [
        "containing a value, the second element containing the corresponding",
        "containing a value, the second element containing"
    ],
    [
        "mask boolean. The returned record shape matches self.shape.",
        "mask boolean. The returned"
    ],
    [
        "A side-effect of transforming a masked array into a flexible `ndarray` is",
        "A side-effect of transforming a masked array into a flexible `ndarray`"
    ],
    [
        "that meta information (``fill_value``, ...) will be lost.",
        "that meta information (``fill_value``, ...)"
    ],
    [
        "\"\"\"Return the internal state of the masked array, for pickling",
        "\"\"\"Return the internal state of the masked array, for"
    ],
    [
        "\"\"\"Restore the internal state of the masked array, for",
        "\"\"\"Restore the internal state of the masked"
    ],
    [
        "pickling purposes.  ``state`` is typically the output of the",
        "pickling purposes. ``state`` is typically the output of"
    ],
    [
        "- a tuple giving the shape of the data",
        "- a tuple giving the"
    ],
    [
        "- a typecode for the data",
        "- a typecode"
    ],
    [
        "- a binary string for the data",
        "- a binary string for"
    ],
    [
        "- a binary string for the mask.",
        "- a binary string"
    ],
    [
        "(_, shp, typ, isf, raw, msk, flv) = state",
        "(_, shp, typ, isf, raw,"
    ],
    [
        "\"\"\"Internal function that builds a new MaskedArray from the",
        "\"\"\"Internal function that builds a"
    ],
    [
        "Fake a 'void' object to use for masked array with structured dtypes.",
        "Fake a 'void' object to use"
    ],
    [
        "def __new__(self, data, mask=nomask, dtype=None, fill_value=None,",
        "def __new__(self, data, mask=nomask, dtype=None,"
    ],
    [
        "copy = None if not copy else True",
        "copy = None if not copy else"
    ],
    [
        "_data = np.array(data, copy=copy, subok=subok, dtype=dtype)",
        "_data = np.array(data, copy=copy,"
    ],
    [
        "if m is not nomask and m[indx]:",
        "if m is not"
    ],
    [
        "for (d, m) in zip(_data, _mask):",
        "for (d, m) in zip(_data,"
    ],
    [
        "Return a copy with masked fields filled with a given value.",
        "Return a copy with masked fields filled with a given"
    ],
    [
        "The value to use for invalid entries. Can be scalar or",
        "The value to use for invalid entries. Can be"
    ],
    [
        "non-scalar. If latter is the case, the filled array should",
        "non-scalar. If latter is the case, the filled"
    ],
    [
        "be broadcastable over input array. Default is None, in",
        "be broadcastable over input array. Default"
    ],
    [
        "which case the `fill_value` attribute is used instead.",
        "which case the `fill_value` attribute is used"
    ],
    [
        "Transforms the mvoid object into a tuple.",
        "Transforms the mvoid object"
    ],
    [
        "Masked fields are replaced by None.",
        "Masked fields are replaced"
    ],
    [
        "for (d, m) in zip(self._data, self._mask):",
        "for (d, m) in zip(self._data,"
    ],
    [
        "Test whether input is an instance of MaskedArray.",
        "Test whether input is an instance of"
    ],
    [
        "This function returns True if `x` is an instance of MaskedArray",
        "This function returns True if `x` is an instance"
    ],
    [
        "and returns False otherwise.  Any object is accepted as input.",
        "and returns False otherwise. Any object"
    ],
    [
        "True if `x` is a MaskedArray.",
        "True if `x` is a"
    ],
    [
        "return cls.__singleton is not None and type(cls.__singleton) is cls",
        "return cls.__singleton is not None and type(cls.__singleton) is"
    ],
    [
        "\"Format strings passed to MaskedConstant are ignored, but in future may \"",
        "\"Format strings passed to MaskedConstant are ignored, but in"
    ],
    [
        "\"\"\" Copy is a no-op on the maskedconstant, as it is a scalar \"\"\"",
        "\"\"\" Copy is a no-op on the maskedconstant, as it is"
    ],
    [
        "f\"attributes of {self!r} are not writeable\")",
        "f\"attributes of {self!r} are not"
    ],
    [
        "The options are in a different order for convenience and backwards",
        "The options are in a different order for convenience and"
    ],
    [
        "Determine whether input has masked values.",
        "Determine whether input has"
    ],
    [
        "Accepts any object as input, but always returns False unless the",
        "Accepts any object as input, but always returns False unless"
    ],
    [
        "input is a MaskedArray containing masked values.",
        "input is a MaskedArray"
    ],
    [
        "Array to check for masked values.",
        "Array to check"
    ],
    [
        "True if `x` is a MaskedArray with masked values, False otherwise.",
        "True if `x` is a MaskedArray with masked values, False"
    ],
    [
        "mask=[ True, False,  True, False, False],",
        "mask=[ True, False, True,"
    ],
    [
        "Always returns False if `x` isn't a MaskedArray.",
        "Always returns False if `x` isn't"
    ],
    [
        ">>> x = [False, True, False]",
        ">>> x = [False, True,"
    ],
    [
        "This is the base class for `_maximum_operation` and",
        "This is the base class for"
    ],
    [
        "\"Reduce target along the given axis.\"",
        "\"Reduce target along"
    ],
    [
        "f\"not the current None, to match np.{self.__name__}.reduce. \"",
        "f\"not the current None, to match"
    ],
    [
        "\"Return the function applied to the outer product of a and b.\"",
        "\"Return the function applied to the outer product of a and"
    ],
    [
        "if ma is nomask and mb is nomask:",
        "if ma is nomask"
    ],
    [
        "def min(obj, axis=None, out=None, fill_value=None, keepdims=np._NoValue):",
        "def min(obj, axis=None, out=None,"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is"
    ],
    [
        "def max(obj, axis=None, out=None, fill_value=None, keepdims=np._NoValue):",
        "def max(obj, axis=None,"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims"
    ],
    [
        "def ptp(obj, axis=None, out=None, fill_value=None, keepdims=np._NoValue):",
        "def ptp(obj, axis=None, out=None, fill_value=None,"
    ],
    [
        "kwargs = {} if keepdims is np._NoValue else {'keepdims': keepdims}",
        "kwargs = {} if keepdims is np._NoValue else {'keepdims':"
    ],
    [
        "Define functions from existing MaskedArray methods.",
        "Define functions from existing"
    ],
    [
        "Name of the method to transform.",
        "Name of the"
    ],
    [
        "\"Return the doc of the function (from the doc of the method).\"",
        "\"Return the doc of the function (from the doc"
    ],
    [
        "meth = getattr(MaskedArray, self.__name__, None) or\\",
        "meth = getattr(MaskedArray, self.__name__,"
    ],
    [
        "doc = \"\"\"    %s\\n%s\"\"\" % (",
        "doc = \"\"\""
    ],
    [
        "def take(a, indices, axis=None, out=None, mode='raise'):",
        "def take(a, indices, axis=None,"
    ],
    [
        "Returns element-wise base array raised to power from second array.",
        "Returns element-wise base array raised"
    ],
    [
        "This is the masked array version of `numpy.power`. For details see",
        "This is the masked array version of `numpy.power`."
    ],
    [
        "The *out* argument to `numpy.power` is not supported, `third` has to be",
        "The *out* argument to `numpy.power` is"
    ],
    [
        "result = np.where(m, fa, umath.power(fa, fb)).view(basetype)",
        "result = np.where(m,"
    ],
    [
        "def argsort(a, axis=np._NoValue, kind=None, order=None, endwith=True,",
        "def argsort(a, axis=np._NoValue,"
    ],
    [
        "\"Function version of the eponymous method.\"",
        "\"Function version of"
    ],
    [
        "Return a sorted copy of the masked array.",
        "Return a sorted copy"
    ],
    [
        "Equivalent to creating a copy of the array",
        "Equivalent to creating a copy of the"
    ],
    [
        "and applying the  MaskedArray ``sort()`` method.",
        "and applying the"
    ],
    [
        "Refer to ``MaskedArray.sort`` for the full documentation",
        "Refer to ``MaskedArray.sort`` for the full"
    ],
    [
        "This function is equivalent to calling the \"compressed\" method of a",
        "This function is equivalent to calling"
    ],
    [
        "Create an array with negative values masked:",
        "Create an array with negative"
    ],
    [
        "Concatenate a sequence of arrays along the given axis.",
        "Concatenate a sequence of arrays"
    ],
    [
        "The arrays must have the same shape, except in the dimension",
        "The arrays must have the same shape,"
    ],
    [
        "corresponding to `axis` (the first, by default).",
        "corresponding to `axis` (the first,"
    ],
    [
        "The concatenated array with any masked entries preserved.",
        "The concatenated array with any masked entries"
    ],
    [
        "numpy.concatenate : Equivalent function in the top-level NumPy module.",
        "numpy.concatenate : Equivalent function in the"
    ],
    [
        "mask=[False,  True, False, False, False, False],",
        "mask=[False, True, False, False, False,"
    ],
    [
        "d = np.concatenate([getdata(a) for a in arrays], axis)",
        "d = np.concatenate([getdata(a) for a"
    ],
    [
        "dm = np.concatenate([getmaskarray(a) for a in arrays], axis)",
        "dm = np.concatenate([getmaskarray(a) for a in"
    ],
    [
        "Extract a diagonal or construct a diagonal array.",
        "Extract a diagonal or construct a diagonal"
    ],
    [
        "This function is the equivalent of `numpy.diag` that takes masked",
        "This function is the equivalent"
    ],
    [
        "values into account, see `numpy.diag` for details.",
        "values into account, see `numpy.diag` for"
    ],
    [
        "numpy.diag : Equivalent function for ndarrays.",
        "numpy.diag : Equivalent"
    ],
    [
        "Create an array with negative values masked:",
        "Create an array with negative values"
    ],
    [
        "Isolate the main diagonal from the masked array:",
        "Isolate the main diagonal from"
    ],
    [
        "Isolate the first diagonal below the main diagonal:",
        "Isolate the first diagonal below"
    ],
    [
        "Shift the bits of an integer to the left.",
        "Shift the bits of an integer to the"
    ],
    [
        "This is the masked array version of `numpy.left_shift`, for details",
        "This is the masked array version of `numpy.left_shift`,"
    ],
    [
        "Shift with a scalar and an array:",
        "Shift with a scalar and"
    ],
    [
        "Shift the bits of an integer to the right.",
        "Shift the bits of an integer to"
    ],
    [
        "This is the masked array version of `numpy.right_shift`, for details",
        "This is the masked array version of `numpy.right_shift`,"
    ],
    [
        "Set storage-indexed locations to corresponding values.",
        "Set storage-indexed locations to"
    ],
    [
        "This function is equivalent to `MaskedArray.put`, see that method",
        "This function is equivalent to `MaskedArray.put`, see"
    ],
    [
        "Putting values in a masked array:",
        "Putting values in a masked"
    ],
    [
        "Changes elements of an array based on conditional and input values.",
        "Changes elements of an array based on conditional and"
    ],
    [
        "This is the masked array version of `numpy.putmask`, for details see",
        "This is the masked array version of `numpy.putmask`, for"
    ],
    [
        "Using a masked array as `values` will **not** transform a `ndarray` into",
        "Using a masked array as `values` will"
    ],
    [
        "Permute the dimensions of an array.",
        "Permute the dimensions"
    ],
    [
        "This function is exactly equivalent to `numpy.transpose`.",
        "This function is exactly equivalent to"
    ],
    [
        "numpy.transpose : Equivalent function in top-level NumPy module.",
        "numpy.transpose : Equivalent function in top-level NumPy"
    ],
    [
        "Returns an array containing the same data with a new shape.",
        "Returns an array containing the same"
    ],
    [
        "Refer to `MaskedArray.reshape` for full documentation.",
        "Refer to `MaskedArray.reshape` for"
    ],
    [
        "Return a new masked array with the specified size and shape.",
        "Return a new masked array with the specified size"
    ],
    [
        "This is the masked equivalent of the `numpy.resize` function. The new",
        "This is the masked equivalent of"
    ],
    [
        "array is filled with repeated copies of `x` (in the order that the",
        "array is filled with repeated copies of"
    ],
    [
        "data are stored in memory). If `x` is masked, the new array will be",
        "data are stored in memory). If `x` is masked, the new array will"
    ],
    [
        "masked, and the new mask will be a repetition of the old one.",
        "masked, and the new mask will be a"
    ],
    [
        "numpy.resize : Equivalent function in the top level NumPy module.",
        "numpy.resize : Equivalent function in the top"
    ],
    [
        "A MaskedArray is always returned, regardless of the input type.",
        "A MaskedArray is always returned, regardless of the"
    ],
    [
        "maskedarray version of the numpy function.",
        "maskedarray version of the numpy"
    ],
    [
        "\"maskedarray version of the numpy function.\"",
        "\"maskedarray version of the"
    ],
    [
        "\"maskedarray version of the numpy function.\"",
        "\"maskedarray version of the numpy"
    ],
    [
        "Calculate the n-th discrete difference along the given axis.",
        "Calculate the n-th discrete difference"
    ],
    [
        "the given axis, higher differences are calculated by using `diff`",
        "the given axis, higher differences are calculated by"
    ],
    [
        "The number of times values are differenced. If zero, the input",
        "The number of times values are differenced. If zero,"
    ],
    [
        "The axis along which the difference is taken, default is the",
        "The axis along which the difference"
    ],
    [
        "Values to prepend or append to `a` along axis prior to",
        "Values to prepend or append to `a` along axis"
    ],
    [
        "performing the difference.  Scalar values are expanded to",
        "performing the difference. Scalar values are expanded"
    ],
    [
        "of the input array in along all other axes.  Otherwise the",
        "of the input array in along"
    ],
    [
        "dimension and shape must match `a` except along axis.",
        "dimension and shape must match `a`"
    ],
    [
        "The n-th differences. The shape of the output is the same as `a`",
        "The n-th differences. The shape of the output is the same as"
    ],
    [
        "except along `axis` where the dimension is smaller by `n`. The",
        "except along `axis` where the dimension is smaller by"
    ],
    [
        "type of the output is the same as the type of the difference",
        "type of the output is the same as the type of"
    ],
    [
        "between any two elements of `a`. This is the same as the type of",
        "between any two elements of `a`. This is the same as the"
    ],
    [
        "numpy.diff : Equivalent function in the top-level NumPy module.",
        "numpy.diff : Equivalent function in the"
    ],
    [
        "Type is preserved for boolean arrays, so the result will contain",
        "Type is preserved for boolean arrays, so the"
    ],
    [
        "`False` when consecutive elements are the same and `True` when they",
        "`False` when consecutive elements are the same and"
    ],
    [
        "For unsigned integer arrays, the results will also be unsigned. This",
        "For unsigned integer arrays, the results will"
    ],
    [
        "should not be surprising, as the result is consistent with",
        "should not be surprising, as"
    ],
    [
        "If this is not desirable, then the array should be cast to a larger",
        "If this is not desirable, then the array should be cast"
    ],
    [
        "mask=[ True, False, False, False,  True,  True, False],",
        "mask=[ True, False, False, False, True,"
    ],
    [
        "mask=[ True, False, False,  True,  True,  True],",
        "mask=[ True, False, False,"
    ],
    [
        "mask=[[ True,  True,  True, False, False]],",
        "mask=[[ True, True, True, False,"
    ],
    [
        "raise ValueError(\"order must be non-negative but got \" + repr(n))",
        "raise ValueError(\"order must be non-negative but got"
    ],
    [
        "\"diff requires input that is at least one dimensional\"",
        "\"diff requires input that is at least one"
    ],
    [
        "Return a masked array with elements from `x` or `y`, depending on condition.",
        "Return a masked array with elements from"
    ],
    [
        "When only `condition` is provided, this function is identical to",
        "When only `condition` is provided,"
    ],
    [
        "`nonzero`. The rest of this documentation covers only the case where",
        "`nonzero`. The rest of this documentation covers only"
    ],
    [
        "Where True, yield `x`, otherwise yield `y`.",
        "Where True, yield `x`,"
    ],
    [
        "Values from which to choose. `x`, `y` and `condition` need to be",
        "Values from which to choose. `x`, `y`"
    ],
    [
        "An masked array with `masked` elements where the condition is masked,",
        "An masked array with `masked` elements where"
    ],
    [
        "elements from `x` where `condition` is True, and elements from `y`",
        "elements from `x` where `condition` is"
    ],
    [
        "numpy.where : Equivalent function in the top-level NumPy module.",
        "numpy.where : Equivalent function in"
    ],
    [
        "nonzero : The function that is called when x and y are omitted",
        "nonzero : The function that is called when x and y"
    ],
    [
        "missing = (x is _NoValue, y is _NoValue).count(True)",
        "missing = (x is"
    ],
    [
        "raise ValueError(\"Must provide both 'x' and 'y' or neither.\")",
        "raise ValueError(\"Must provide both 'x' and 'y'"
    ],
    [
        "if x is masked and y is not masked:",
        "if x is masked and y is not"
    ],
    [
        "elif y is masked and x is not masked:",
        "elif y is masked and x is not"
    ],
    [
        "mask = np.where(cm, np.ones((), dtype=mask.dtype), mask)",
        "mask = np.where(cm, np.ones((), dtype=mask.dtype),"
    ],
    [
        "Use an index array to construct a new array from a list of choices.",
        "Use an index array to construct a new array from"
    ],
    [
        "Given an array of integers and a list of n choice arrays, this method",
        "Given an array of integers and a list"
    ],
    [
        "will create a new array that merges each of the choice arrays.  Where a",
        "will create a new array that merges each"
    ],
    [
        "value in `index` is i, the new array will have the value that choices[i]",
        "value in `index` is i, the new array"
    ],
    [
        "Choice arrays. The index array and all of the choices should be",
        "Choice arrays. The index array and all of the"
    ],
    [
        "If provided, the result will be inserted into this array. It should",
        "If provided, the result will be inserted"
    ],
    [
        "be of the appropriate shape and `dtype`.",
        "be of the appropriate"
    ],
    [
        "mode : {'raise', 'wrap', 'clip'}, optional",
        "mode : {'raise', 'wrap', 'clip'},"
    ],
    [
        "Specifies how out-of-bounds indices will behave.",
        "Specifies how out-of-bounds indices"
    ],
    [
        "* 'raise' : raise an error",
        "* 'raise' : raise"
    ],
    [
        "* 'clip' : clip to the range",
        "* 'clip' : clip"
    ],
    [
        "\"Returns the filled array, or True if masked.\"",
        "\"Returns the filled array, or"
    ],
    [
        "\"Returns the mask, True if ``masked``, False if ``nomask``.\"",
        "\"Returns the mask, True if ``masked``, False"
    ],
    [
        "masks = [nmask(x) for x in choices]",
        "masks = [nmask(x) for x"
    ],
    [
        "data = [fmask(x) for x in choices]",
        "data = [fmask(x) for x in"
    ],
    [
        "d = np.choose(c, data, mode=mode, out=out).view(MaskedArray)",
        "d = np.choose(c, data, mode=mode,"
    ],
    [
        "Return a copy of a, rounded to 'decimals' places.",
        "Return a copy of a, rounded"
    ],
    [
        "When 'decimals' is negative, it specifies the number of positions",
        "When 'decimals' is negative, it specifies the number of"
    ],
    [
        "to the left of the decimal point.  The real and imaginary parts of",
        "to the left of the decimal point."
    ],
    [
        "complex numbers are rounded separately. Nothing is done if the",
        "complex numbers are rounded separately. Nothing is"
    ],
    [
        "array is not of float type and 'decimals' is greater than or equal",
        "array is not of float type and 'decimals' is"
    ],
    [
        "Number of decimals to round to. May be negative.",
        "Number of decimals to round to. May be"
    ],
    [
        "Existing array to use for output.",
        "Existing array to use for"
    ],
    [
        "If not given, returns a default copy of a.",
        "If not given, returns a"
    ],
    [
        "If out is given and does not have a mask attribute, the mask of a",
        "If out is given and does not have a mask attribute, the"
    ],
    [
        "if m is nomask or not m.any() or axis is None:",
        "if m is nomask or not"
    ],
    [
        "Return the dot product of two arrays.",
        "Return the dot product of"
    ],
    [
        "This function is the equivalent of `numpy.dot` that takes masked values",
        "This function is the equivalent of `numpy.dot` that"
    ],
    [
        "into account. Note that `strict` and `out` are in different position",
        "into account. Note that `strict` and `out`"
    ],
    [
        "than in the method version. In order to maintain compatibility with the",
        "than in the method version. In order to maintain compatibility"
    ],
    [
        "corresponding method, it is recommended that the optional arguments be",
        "corresponding method, it is recommended"
    ],
    [
        "treated as keyword only.  At some point that may be mandatory.",
        "treated as keyword only. At some point that may"
    ],
    [
        "the computation. Default is False.  Propagating the mask means that",
        "the computation. Default is False."
    ],
    [
        "if a masked value appears in a row or column, the whole row or",
        "if a masked value appears in a row"
    ],
    [
        "Output argument. This must have the exact kind that would be returned",
        "Output argument. This must have the exact kind that would"
    ],
    [
        "if it was not used. In particular, it must have the right type, must be",
        "if it was not used. In particular, it must have"
    ],
    [
        "C-contiguous, and its dtype must be the dtype that would be returned",
        "C-contiguous, and its dtype must be the dtype that"
    ],
    [
        "for `dot(a,b)`. This is a performance feature. Therefore, if these",
        "for `dot(a,b)`. This is a performance feature. Therefore,"
    ],
    [
        "conditions are not met, an exception is raised, instead of attempting",
        "conditions are not met, an exception is raised, instead"
    ],
    [
        "numpy.dot : Equivalent function for ndarrays.",
        "numpy.dot : Equivalent function"
    ],
    [
        "Returns the inner product of a and b for arrays of floating point types.",
        "Returns the inner product of a and b for arrays of"
    ],
    [
        "Like the generic NumPy equivalent the product sum is over the last dimension",
        "Like the generic NumPy equivalent the product"
    ],
    [
        "of a and b. The first argument is not conjugated.",
        "of a and b. The"
    ],
    [
        "\"maskedarray version of the numpy function.\"",
        "\"maskedarray version of"
    ],
    [
        "if ma is nomask and mb is nomask:",
        "if ma is nomask"
    ],
    [
        "def _convolve_or_correlate(f, a, v, mode, propagate_mask):",
        "def _convolve_or_correlate(f, a,"
    ],
    [
        "Helper function for ma.correlate and ma.convolve",
        "Helper function for ma.correlate"
    ],
    [
        "mode : {'valid', 'same', 'full'}, optional",
        "mode : {'valid', 'same', 'full'},"
    ],
    [
        "Refer to the `np.convolve` docstring.  Note that the default",
        "Refer to the `np.convolve` docstring."
    ],
    [
        "is 'valid', unlike `convolve`, which uses 'full'.",
        "is 'valid', unlike `convolve`,"
    ],
    [
        "If True, then a result element is masked if any masked element contributes towards it.",
        "If True, then a result element is masked if any masked"
    ],
    [
        "If False, then a result element is only masked if no non-masked element",
        "If False, then a result element is only masked"
    ],
    [
        "Discrete cross-correlation of `a` and `v`.",
        "Discrete cross-correlation of `a`"
    ],
    [
        "numpy.correlate : Equivalent function in the top-level NumPy module.",
        "numpy.correlate : Equivalent function in the top-level NumPy"
    ],
    [
        "Correlation with different modes and mixed array types:",
        "Correlation with different modes and mixed array"
    ],
    [
        "return _convolve_or_correlate(np.correlate, a, v, mode, propagate_mask)",
        "return _convolve_or_correlate(np.correlate, a, v, mode,"
    ],
    [
        "Returns the discrete, linear convolution of two one-dimensional sequences.",
        "Returns the discrete, linear convolution of two one-dimensional"
    ],
    [
        "mode : {'valid', 'same', 'full'}, optional",
        "mode : {'valid', 'same',"
    ],
    [
        "If True, then if any masked element is included in the sum for a result",
        "If True, then if any masked element is"
    ],
    [
        "element, then the result is masked.",
        "element, then the result"
    ],
    [
        "If False, then the result element is only masked if no non-masked cells",
        "If False, then the result element is only masked if no"
    ],
    [
        "Discrete, linear convolution of `a` and `v`.",
        "Discrete, linear convolution of `a`"
    ],
    [
        "numpy.convolve : Equivalent function in the top-level NumPy module.",
        "numpy.convolve : Equivalent function in the top-level NumPy"
    ],
    [
        "return _convolve_or_correlate(np.convolve, a, v, mode, propagate_mask)",
        "return _convolve_or_correlate(np.convolve, a, v,"
    ],
    [
        "Return True if all entries of a and b are equal, using",
        "Return True if all entries of"
    ],
    [
        "fill_value as a truth value where either or both are masked.",
        "fill_value as a truth value where either or"
    ],
    [
        "Whether masked values in a or b are considered equal (True) or not",
        "Whether masked values in a or b are considered"
    ],
    [
        "Returns True if the two arrays are equal within the given",
        "Returns True if the two arrays are equal"
    ],
    [
        "tolerance, False otherwise. If either array contains NaN,",
        "tolerance, False otherwise. If"
    ],
    [
        "Returns True if two arrays are element-wise equal within a tolerance.",
        "Returns True if two arrays are element-wise equal within a"
    ],
    [
        "This function is equivalent to `allclose` except that masked values",
        "This function is equivalent to"
    ],
    [
        "are treated as equal (default) or unequal, depending on the `masked_equal`",
        "are treated as equal (default) or unequal, depending on the"
    ],
    [
        "Whether masked values in `a` and `b` are considered equal (True) or not",
        "Whether masked values in `a` and `b` are considered equal (True)"
    ],
    [
        "(False). They are considered equal by default.",
        "(False). They are considered equal"
    ],
    [
        "Relative tolerance. The relative difference is equal to ``rtol * b``.",
        "Relative tolerance. The relative difference is equal to ``rtol *"
    ],
    [
        "Absolute tolerance. The absolute difference is equal to `atol`.",
        "Absolute tolerance. The absolute difference is"
    ],
    [
        "Returns True if the two arrays are equal within the given",
        "Returns True if the two arrays are equal within"
    ],
    [
        "tolerance, False otherwise. If either array contains NaN, then",
        "tolerance, False otherwise. If either array contains NaN,"
    ],
    [
        "If the following equation is element-wise True, then `allclose` returns",
        "If the following equation is"
    ],
    [
        "absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))",
        "absolute(`a` - `b`) <= (`atol` + `rtol`"
    ],
    [
        "Return True if all elements of `a` and `b` are equal subject to",
        "Return True if all elements of `a` and `b` are"
    ],
    [
        "Masked values are not compared directly.",
        "Masked values are not compared"
    ],
    [
        "if not np.all(xinf == filled(np.isinf(y), False)):",
        "if not np.all(xinf =="
    ],
    [
        "d = filled(less_equal(absolute(x - y), atol + rtol * absolute(y)),",
        "d = filled(less_equal(absolute(x - y), atol + rtol *"
    ],
    [
        "if not np.all(filled(x[xinf] == y[xinf], masked_equal)):",
        "if not np.all(filled(x[xinf] == y[xinf],"
    ],
    [
        "d = filled(less_equal(absolute(x - y), atol + rtol * absolute(y)),",
        "d = filled(less_equal(absolute(x - y), atol"
    ],
    [
        "Convert the input to a masked array of the given data-type.",
        "Convert the input to a masked array of the given"
    ],
    [
        "No copy is performed if the input is already an `ndarray`. If `a` is",
        "No copy is performed if the input is already an"
    ],
    [
        "a subclass of `MaskedArray`, a base class `MaskedArray` is returned.",
        "a subclass of `MaskedArray`, a base class"
    ],
    [
        "Input data, in any form that can be converted to a masked array. This",
        "Input data, in any form that can be converted to a masked array."
    ],
    [
        "includes lists, lists of tuples, tuples, tuples of tuples, tuples",
        "includes lists, lists of tuples, tuples, tuples of tuples,"
    ],
    [
        "of lists, ndarrays and masked arrays.",
        "of lists, ndarrays"
    ],
    [
        "By default, the data-type is inferred from the input data.",
        "By default, the data-type is inferred"
    ],
    [
        "Whether to use row-major ('C') or column-major ('FORTRAN') memory",
        "Whether to use row-major ('C') or"
    ],
    [
        "asanyarray : Similar to `asarray`, but conserves subclasses.",
        "asanyarray : Similar to"
    ],
    [
        "Convert the input to a masked array, conserving subclasses.",
        "Convert the input to a masked array,"
    ],
    [
        "If `a` is a subclass of `MaskedArray`, its class is conserved.",
        "If `a` is a subclass of `MaskedArray`, its class is"
    ],
    [
        "No copy is performed if the input is already an `ndarray`.",
        "No copy is performed if the input is"
    ],
    [
        "Input data, in any form that can be converted to an array.",
        "Input data, in any form that can be converted to"
    ],
    [
        "By default, the data-type is inferred from the input data.",
        "By default, the data-type is inferred from the"
    ],
    [
        "Whether to use row-major ('C') or column-major ('FORTRAN') memory",
        "Whether to use row-major ('C') or"
    ],
    [
        "asarray : Similar to `asanyarray`, but does not conserve subclass.",
        "asarray : Similar to `asanyarray`, but does not conserve"
    ],
    [
        "if isinstance(a, MaskedArray) and (dtype is None or dtype == a.dtype):",
        "if isinstance(a, MaskedArray) and (dtype is None or dtype =="
    ],
    [
        "return masked_array(a, dtype=dtype, copy=False, keep_mask=True, subok=True)",
        "return masked_array(a, dtype=dtype,"
    ],
    [
        "\"fromfile() not yet implemented for a MaskedArray.\")",
        "\"fromfile() not yet implemented for"
    ],
    [
        "Build a masked array from a suitable flexible-type array.",
        "Build a masked array from"
    ],
    [
        "The input array has to have a data-type with ``_data`` and ``_mask``",
        "The input array has to have a data-type with"
    ],
    [
        "fields. This type of array is output by `MaskedArray.toflex`.",
        "fields. This type of array"
    ],
    [
        "The structured input array, containing ``_data`` and ``_mask``",
        "The structured input array, containing"
    ],
    [
        "fields. If present, other fields are discarded.",
        "fields. If present, other fields are"
    ],
    [
        "MaskedArray.toflex : Build a flexible-type array from a masked array.",
        "MaskedArray.toflex : Build a flexible-type array from a masked"
    ],
    [
        "Extra fields can be present in the structured array but are discarded:",
        "Extra fields can be present in the structured array"
    ],
    [
        "Convert functions from numpy to numpy.ma.",
        "Convert functions from"
    ],
    [
        "Name of the method to transform.",
        "Name of the method"
    ],
    [
        "def __init__(self, funcname, np_ret, np_ma_ret, params=None):",
        "def __init__(self, funcname, np_ret,"
    ],
    [
        "\"Return the doc of the function (from the doc of the method).\"",
        "\"Return the doc of the function"
    ],
    [
        "sig = \"%s%s\\n\" % (self._func.__name__, sig)",
        "sig = \"%s%s\\n\" % (self._func.__name__,"
    ],
    [
        "Replace documentation of ``np`` function's return type.",
        "Replace documentation of ``np`` function's return"
    ],
    [
        "Replaces it with the proper type for the ``np.ma`` function.",
        "Replaces it with the proper type for the"
    ],
    [
        "The documentation of the ``np`` method.",
        "The documentation of the ``np``"
    ],
    [
        "The return type string of the ``np`` method that we want to",
        "The return type string of the ``np`` method that we want"
    ],
    [
        "The return type string of the ``np.ma`` method.",
        "The return type string of the ``np.ma``"
    ],
    [
        "f\"Failed to replace `{np_ret}` with `{np_ma_ret}`. \"",
        "f\"Failed to replace `{np_ret}` with `{np_ma_ret}`."
    ],
    [
        "f\"The documentation string for return type, {np_ret}, is not \"",
        "f\"The documentation string for return type,"
    ],
    [
        "f\"found in the docstring for `np.{self._func.__name__}`. \"",
        "f\"found in the docstring for"
    ],
    [
        "f\"Fix the docstring for `np.{self._func.__name__}` or \"",
        "f\"Fix the docstring for `np.{self._func.__name__}` or"
    ],
    [
        "\"update the expected string for return type.\"",
        "\"update the expected string"
    ],
    [
        "np_ret='grid : one ndarray or tuple of ndarrays',",
        "np_ret='grid : one ndarray or tuple of"
    ],
    [
        "np_ma_ret='grid : one MaskedArray or tuple of MaskedArrays',",
        "np_ma_ret='grid : one MaskedArray or"
    ],
    [
        "\"\"\"Append values to the end of an array.",
        "\"\"\"Append values to the end of"
    ],
    [
        "Values are appended to a copy of this array.",
        "Values are appended to a copy"
    ],
    [
        "These values are appended to a copy of `a`.  It must be of the",
        "These values are appended to a copy of `a`. It"
    ],
    [
        "correct shape (the same shape as `a`, excluding `axis`).  If `axis`",
        "correct shape (the same shape as"
    ],
    [
        "is not specified, `b` can be any shape and will be flattened",
        "is not specified, `b` can be any shape and will be"
    ],
    [
        "The axis along which `v` are appended.  If `axis` is not given,",
        "The axis along which `v` are appended. If `axis`"
    ],
    [
        "both `a` and `b` are flattened before use.",
        "both `a` and `b` are"
    ],
    [
        "A copy of `a` with `b` appended to `axis`.  Note that `append`",
        "A copy of `a` with `b` appended to"
    ],
    [
        "does not occur in-place: a new array is allocated and filled.  If",
        "does not occur in-place: a new"
    ],
    [
        "`axis` is None, the result is a flattened array.",
        "`axis` is None, the result is"
    ],
    [
        "numpy.append : Equivalent function in the top-level NumPy module.",
        "numpy.append : Equivalent function in the top-level"
    ],
    [
        "mask=[False,  True, False, False, False, False,  True, False,",
        "mask=[False, True, False, False, False,"
    ],
    [
        "def assert_array_compare(self, comparison, x, y, err_msg='', header='',",
        "def assert_array_compare(self, comparison, x, y,"
    ],
    [
        "Assert that a comparison of two masked arrays is satisfied elementwise.",
        "Assert that a comparison of two masked"
    ],
    [
        "cond = (x.shape == () or y.shape == ()) or x.shape == y.shape",
        "cond = (x.shape == () or y.shape == ()) or x.shape =="
    ],
    [
        "if m is not self.nomask and fill_value:",
        "if m is not self.nomask"
    ],
    [
        "msg = build_err_msg([x, y], err_msg, header=header, names=('x', 'y'))",
        "msg = build_err_msg([x, y],"
    ],
    [
        "Checks the elementwise equality of two masked arrays.",
        "Checks the elementwise equality"
    ],
    [
        "assert xm.size == functools.reduce(lambda x, y: x * y, s)",
        "assert xm.size == functools.reduce(lambda x, y: x *"
    ],
    [
        "Test of take, transpose, inner, outer products.",
        "Test of take, transpose, inner,"
    ],
    [
        "setup_base = (\"from __main__ import ModuleTester \\n\"",
        "setup_base = (\"from __main__ import"
    ],
    [
        "setup_cur = \"import numpy.ma.core as module\\n\" + setup_base",
        "setup_cur = \"import numpy.ma.core as module\\n\" +"
    ],
    [
        "Defines the equivalent of :class:`numpy.recarrays` for masked arrays,",
        "Defines the equivalent of :class:`numpy.recarrays` for masked"
    ],
    [
        "where fields can be accessed as attributes.",
        "where fields can be accessed"
    ],
    [
        "Note that :class:`numpy.ma.MaskedArray` already supports structured datatypes",
        "Note that :class:`numpy.ma.MaskedArray` already supports"
    ],
    [
        "and the masking of individual fields.",
        "and the masking"
    ],
    [
        "reserved_fields = ['_data', '_mask', '_fieldmask', 'dtype']",
        "reserved_fields = ['_data',"
    ],
    [
        "Checks that field names ``descr`` are not reserved keywords.",
        "Checks that field names ``descr`` are"
    ],
    [
        "If this is the case, a default 'f%i' is substituted.  If the argument",
        "If this is the case, a default 'f%i' is substituted. If"
    ],
    [
        "`names` is not None, updates the field names to valid names.",
        "`names` is not None, updates the field"
    ],
    [
        "default_names = ['f%i' % i for i in range(ndescr)]",
        "default_names = ['f%i' % i for"
    ],
    [
        "for (n, d, t) in zip(new_names, default_names, descr.descr):",
        "for (n, d, t) in zip(new_names, default_names,"
    ],
    [
        "Underlying data, as a record array.",
        "Underlying data, as a record"
    ],
    [
        "Mask of the records. A record is masked when all its fields are",
        "Mask of the records. A record is masked when all its fields"
    ],
    [
        "Record array of booleans, setting the mask of each individual field",
        "Record array of booleans, setting the"
    ],
    [
        "self = np.recarray.__new__(cls, shape, dtype=dtype, buf=buf, offset=offset,",
        "self = np.recarray.__new__(cls, shape, dtype=dtype, buf=buf,"
    ],
    [
        "if mask is ma.nomask or not np.size(mask):",
        "if mask is ma.nomask"
    ],
    [
        "msg = \"Mask and data not compatible: data size is %i, \"\\",
        "msg = \"Mask and data not compatible: data size is %i,"
    ],
    [
        "_mask = np.array([tuple([m] * len(mdtype)) for m in mask],",
        "_mask = np.array([tuple([m] * len(mdtype)) for m"
    ],
    [
        "_mask = np.array([tuple([m] * len(mdescr)) for m in objmask],",
        "_mask = np.array([tuple([m] * len(mdescr)) for m"
    ],
    [
        "Returns the data as a recarray.",
        "Returns the data"
    ],
    [
        "f'record array has no attribute {attr}') from e",
        "f'record array has no attribute {attr}')"
    ],
    [
        "raise NotImplementedError(\"MaskedRecords is currently limited to\"",
        "raise NotImplementedError(\"MaskedRecords is"
    ],
    [
        "hasmasked = _mask.view((bool, ((tp_len,) if tp_len else ()))).any()",
        "hasmasked = _mask.view((bool, ((tp_len,) if tp_len else"
    ],
    [
        "Sets the attribute attr to the value val.",
        "Sets the attribute attr to the"
    ],
    [
        "newattr = attr not in _localdict",
        "newattr = attr not in"
    ],
    [
        "fielddict = np.ndarray.__getattribute__(self, 'dtype').fields or {}",
        "fielddict = np.ndarray.__getattribute__(self,"
    ],
    [
        "optinfo = np.ndarray.__getattribute__(self, '_optinfo') or {}",
        "optinfo = np.ndarray.__getattribute__(self, '_optinfo') or"
    ],
    [
        "if not (attr in fielddict or attr in optinfo):",
        "if not (attr in fielddict or"
    ],
    [
        "fielddict = np.ndarray.__getattribute__(self, 'dtype').fields or {}",
        "fielddict = np.ndarray.__getattribute__(self, 'dtype').fields"
    ],
    [
        "f'record array has no attribute {attr}') from e",
        "f'record array has no"
    ],
    [
        "Returns all the fields sharing the same fieldname base.",
        "Returns all the fields sharing the same"
    ],
    [
        "The fieldname base is either `_data` or `_mask`.",
        "The fieldname base is either `_data` or"
    ],
    [
        "Sets the given record to value.",
        "Sets the given record"
    ],
    [
        "mstr = [f\"({','.join([str(i) for i in s])})\"",
        "mstr = [f\"({','.join([str(i) for i in"
    ],
    [
        "for s in zip(*[getattr(self, f) for f in self.dtype.names])]",
        "for s in zip(*[getattr(self, f) for"
    ],
    [
        "mstr = [f\"{','.join([str(i) for i in s])}\"",
        "mstr = [f\"{','.join([str(i) for"
    ],
    [
        "for s in zip([getattr(self, f) for f in self.dtype.names])]",
        "for s in zip([getattr(self, f) for f in"
    ],
    [
        "reprstr = [fmt % (f, getattr(self, f)) for f in self.dtype.names]",
        "reprstr = [fmt % (f, getattr(self, f))"
    ],
    [
        "Returns a view of the mrecarray.",
        "Returns a view of"
    ],
    [
        "if (getattr(output, '_mask', ma.nomask) is not ma.nomask):",
        "if (getattr(output, '_mask', ma.nomask) is"
    ],
    [
        "Returns a copy of the masked record.",
        "Returns a copy of"
    ],
    [
        "Return the data portion of the array as a list.",
        "Return the data portion of the array as a"
    ],
    [
        "Data items are converted to the nearest compatible Python type.",
        "Data items are converted to"
    ],
    [
        "Masked values are converted to fill_value. If fill_value is None,",
        "Masked values are converted to fill_value."
    ],
    [
        "the corresponding entries in the output list will be ``None``.",
        "the corresponding entries in the"
    ],
    [
        "\"\"\"Return the internal state of the masked array.",
        "\"\"\"Return the internal state"
    ],
    [
        "Restore the internal state of the masked array.",
        "Restore the internal state of"
    ],
    [
        "This is for pickling.  ``state`` is typically the output of the",
        "This is for pickling. ``state`` is"
    ],
    [
        "- a tuple giving the shape of the data",
        "- a tuple giving the shape of"
    ],
    [
        "- a typecode for the data",
        "- a typecode"
    ],
    [
        "- a binary string for the data",
        "- a binary string for"
    ],
    [
        "- a binary string for the mask.",
        "- a binary string for"
    ],
    [
        "(ver, shp, typ, isf, raw, msk, flv) = state",
        "(ver, shp, typ, isf, raw, msk, flv) ="
    ],
    [
        "mdtype = np.dtype([(k, np.bool) for (k, _) in self.dtype.descr])",
        "mdtype = np.dtype([(k, np.bool) for"
    ],
    [
        "Build a new MaskedArray from the information stored in a pickle.",
        "Build a new MaskedArray from the information stored in a"
    ],
    [
        "Creates a mrecarray from a (flat) list of masked arrays.",
        "Creates a mrecarray from a (flat) list of"
    ],
    [
        "A list of (masked) arrays. Each element of the sequence is first converted",
        "A list of (masked) arrays. Each element of the"
    ],
    [
        "Number of records. If None, shape is defined from the shape of the",
        "Number of records. If None, shape is"
    ],
    [
        "Sequence of formats for each individual field. If None, the formats will",
        "Sequence of formats for each individual field. If"
    ],
    [
        "be autodetected by inspecting the fields and selecting the highest dtype",
        "be autodetected by inspecting the fields and selecting"
    ],
    [
        "Sequence of the names of each field.",
        "Sequence of the names of"
    ],
    [
        "Sequence of data to be used as filling values.",
        "Sequence of data to be used"
    ],
    [
        "Lists of tuples should be preferred over lists of lists for faster processing.",
        "Lists of tuples should be preferred over lists of lists for"
    ],
    [
        "datalist = [ma.getdata(x) for x in arraylist]",
        "datalist = [ma.getdata(x) for x in"
    ],
    [
        "def fromrecords(reclist, dtype=None, shape=None, formats=None, names=None,",
        "def fromrecords(reclist, dtype=None,"
    ],
    [
        "Creates a MaskedRecords from a list of records.",
        "Creates a MaskedRecords from a list of"
    ],
    [
        "A list of records. Each element of the sequence is first converted",
        "A list of records. Each element of the sequence is"
    ],
    [
        "Number of records. If None, ``shape`` is defined from the shape of the",
        "Number of records. If None, ``shape`` is defined from"
    ],
    [
        "Sequence of formats for each individual field. If None, the formats will",
        "Sequence of formats for each individual field. If"
    ],
    [
        "be autodetected by inspecting the fields and selecting the highest dtype",
        "be autodetected by inspecting the fields and selecting the highest"
    ],
    [
        "Sequence of the names of each field.",
        "Sequence of the names of"
    ],
    [
        "Sequence of data to be used as filling values.",
        "Sequence of data to be"
    ],
    [
        "External mask to apply on the data.",
        "External mask to apply on the"
    ],
    [
        "Lists of tuples should be preferred over lists of lists for faster processing.",
        "Lists of tuples should be preferred over lists"
    ],
    [
        "mrec = np.rec.fromrecords(reclist, dtype=dtype, shape=shape, formats=formats,",
        "mrec = np.rec.fromrecords(reclist, dtype=dtype,"
    ],
    [
        "mrec._mask.flat = [tuple(m) for m in mask]",
        "mrec._mask.flat = [tuple(m) for m"
    ],
    [
        "Tries to guess the dtypes of the str_ ndarray `arr`.",
        "Tries to guess the dtypes of"
    ],
    [
        "Guesses by testing element-wise conversion. Returns a list of dtypes.",
        "Guesses by testing element-wise conversion."
    ],
    [
        "is performed on the first line. An exception is raised if the file is",
        "is performed on the first line. An exception is raised if the"
    ],
    [
        "Opens the file handle of file `fname`.",
        "Opens the file handle of file"
    ],
    [
        "raise FileNotFoundError(f\"No such file: '{fname}'\") from e",
        "raise FileNotFoundError(f\"No such file: '{fname}'\")"
    ],
    [
        "Creates a mrecarray from data stored in the file `filename`.",
        "Creates a mrecarray from data stored in"
    ],
    [
        "Alphanumeric character used to separate columns in the file.",
        "Alphanumeric character used to separate columns"
    ],
    [
        "If None, any (group of) white spacestring(s) will be used.",
        "If None, any (group of)"
    ],
    [
        "Alphanumeric character used to mark the start of a comment.",
        "Alphanumeric character used to mark the"
    ],
    [
        "String indicating missing data, and used to create the masks.",
        "String indicating missing data, and used to"
    ],
    [
        "Sequence of the variable names. If None, a list will be created from",
        "Sequence of the variable names. If None, a list will be"
    ],
    [
        "the first non empty line of the file.",
        "the first non empty"
    ],
    [
        "Sequence of the variables dtypes. If None, it will be estimated from",
        "Sequence of the variables dtypes. If None,"
    ],
    [
        "Ultra simple: the varnames are in the header, one line\"\"\"",
        "Ultra simple: the varnames are in the header, one"
    ],
    [
        "raise TypeError(\"fromtextfile() got multiple values for argument \"",
        "raise TypeError(\"fromtextfile() got multiple values for argument"
    ],
    [
        "warnings.warn(\"The 'delimitor' keyword argument of \"",
        "warnings.warn(\"The 'delimitor' keyword argument"
    ],
    [
        "_variables = ma.masked_array([line.strip().split(delimiter) for line in ftext",
        "_variables = ma.masked_array([line.strip().split(delimiter) for line"
    ],
    [
        "vartypes = [np.dtype(v) for v in vartypes]",
        "vartypes = [np.dtype(v) for v in"
    ],
    [
        "msg = \"Attempting to %i dtypes for %i fields!\"",
        "msg = \"Attempting to %i dtypes"
    ],
    [
        "msg += \" Reverting to default.\"",
        "msg += \" Reverting"
    ],
    [
        "mfillv = [ma.default_fill_value(f) for f in vartypes]",
        "mfillv = [ma.default_fill_value(f) for f"
    ],
    [
        "_datalist = [ma.masked_array(a, mask=m, dtype=t, fill_value=f)",
        "_datalist = [ma.masked_array(a, mask=m,"
    ],
    [
        "for (a, m, t, f) in zip(_variables.T, _mask, vartypes, mfillv)]",
        "for (a, m, t, f)"
    ],
    [
        "\"\"\"Adds a new field to the masked record array",
        "\"\"\"Adds a new field to"
    ],
    [
        "Uses `newfield` as data and `newfieldname` as name. If `newfieldname`",
        "Uses `newfield` as data and"
    ],
    [
        "is None, the new field name is set to 'fi', where `i` is the number of",
        "is None, the new field name is set to 'fi',"
    ],
    [
        "if newfieldname is None or newfieldname in reserved_fields:",
        "if newfieldname is None"
    ],
    [
        "newdtype = np.dtype(_data.dtype.descr + [(newfieldname, newfield.dtype)])",
        "newdtype = np.dtype(_data.dtype.descr"
    ],
    [
        "newmdtype = np.dtype([(n, np.bool) for n in newdtype.names])",
        "newmdtype = np.dtype([(n, np.bool)"
    ],
    [
        "MaskType, MaskedArray, absolute, add, all, allclose, allequal, alltrue,",
        "MaskType, MaskedArray, absolute, add, all, allclose, allequal,"
    ],
    [
        "concatenate, conjugate, cos, cosh, count, divide, equal, exp, filled,",
        "concatenate, conjugate, cos, cosh, count, divide, equal, exp,"
    ],
    [
        "getmask, greater, greater_equal, inner, isMaskedArray, less,",
        "getmask, greater, greater_equal, inner,"
    ],
    [
        "multiply, nomask, nonzero, not_equal, ones, outer, product, put, ravel,",
        "multiply, nomask, nonzero, not_equal, ones, outer,"
    ],
    [
        "repeat, resize, shape, sin, sinh, sometrue, sort, sqrt, subtract, sum,",
        "repeat, resize, shape, sin, sinh, sometrue, sort,"
    ],
    [
        "take, tan, tanh, transpose, where, zeros,",
        "take, tan, tanh, transpose, where,"
    ],
    [
        "assert_equal(xm.size, reduce(lambda x, y: x * y, s))",
        "assert_equal(xm.size, reduce(lambda x, y: x * y,"
    ],
    [
        "assert_equal(xm.size, reduce(lambda x, y: x * y, s))",
        "assert_equal(xm.size, reduce(lambda x, y: x *"
    ],
    [
        "assert_(eq(x + y, xm + ym))",
        "assert_(eq(x + y, xm +"
    ],
    [
        "assert_(eq(x - y, xm - ym))",
        "assert_(eq(x - y, xm"
    ],
    [
        "assert_(eq(x * y, xm * ym))",
        "assert_(eq(x * y, xm *"
    ],
    [
        "assert_(eq(x / y, xm / ym))",
        "assert_(eq(x / y, xm /"
    ],
    [
        "assert_(eq(x ** y, xm ** ym))",
        "assert_(eq(x ** y, xm **"
    ],
    [
        "assert_(eq(np.concatenate((x, y, x)), concatenate((x, ym, x))))",
        "assert_(eq(np.concatenate((x, y, x)), concatenate((x,"
    ],
    [
        "assert_(eq(minimum(x, y), where(less(x, y), x, y)))",
        "assert_(eq(minimum(x, y), where(less(x, y),"
    ],
    [
        "assert_(eq(maximum(x, y), where(greater(x, y), x, y)))",
        "assert_(eq(maximum(x, y), where(greater(x, y),"
    ],
    [
        "assert_(not [m for m in dir(np.ndarray)",
        "assert_(not [m for m in"
    ],
    [
        "if m not in dir(MaskedArray) and",
        "if m not in dir(MaskedArray)"
    ],
    [
        "self.d = (x, X, XX, m, mx, mX, mXX)",
        "self.d = (x, X, XX, m, mx,"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX,"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX,"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX, mXX,) ="
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX, mXX,)"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx,"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX, mXX,) ="
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX, mXX,)"
    ],
    [
        "\"\"\"Tests suite for MaskedArray & subclassing.",
        "\"\"\"Tests suite for MaskedArray"
    ],
    [
        "MAError, MaskError, MaskType, MaskedArray, abs, absolute, add, all,",
        "MAError, MaskError, MaskType, MaskedArray,"
    ],
    [
        "arcsin, arctan, argsort, array, asarray, choose, concatenate,",
        "arcsin, arctan, argsort, array,"
    ],
    [
        "conjugate, cos, cosh, count, default_fill_value, diag, divide, doc_note,",
        "conjugate, cos, cosh, count, default_fill_value,"
    ],
    [
        "empty, empty_like, equal, exp, flatten_mask, filled, fix_invalid,",
        "empty, empty_like, equal, exp,"
    ],
    [
        "greater_equal, identity, inner, isMaskedArray, less, less_equal, log,",
        "greater_equal, identity, inner, isMaskedArray, less,"
    ],
    [
        "maximum_fill_value, min, minimum, minimum_fill_value, mod, multiply,",
        "maximum_fill_value, min, minimum, minimum_fill_value,"
    ],
    [
        "mvoid, nomask, not_equal, ones, ones_like, outer, power, product, put,",
        "mvoid, nomask, not_equal, ones, ones_like,"
    ],
    [
        "putmask, ravel, repeat, reshape, resize, shape, sin, sinh, sometrue, sort,",
        "putmask, ravel, repeat, reshape, resize, shape, sin,"
    ],
    [
        "sqrt, subtract, sum, take, tan, tanh, transpose, where, zeros, zeros_like,",
        "sqrt, subtract, sum, take, tan, tanh, transpose, where,"
    ],
    [
        "\"setting an item on a masked array which has a shared mask will not copy\")",
        "\"setting an item on a masked array which has a shared mask will"
    ],
    [
        "num_dts = [np.dtype(dt_) for dt_ in '?bhilqBHILQefdgFD']",
        "num_dts = [np.dtype(dt_) for"
    ],
    [
        "num_ids = [dt_.char for dt_ in num_dts]",
        "num_ids = [dt_.char for dt_"
    ],
    [
        "assert_equal(xm.size, reduce(lambda x, y: x * y, s))",
        "assert_equal(xm.size, reduce(lambda x, y: x"
    ],
    [
        "assert_equal(xm.size, reduce(lambda x, y: x * y, s))",
        "assert_equal(xm.size, reduce(lambda x, y: x *"
    ],
    [
        "assert_equal(np.concatenate((x, y, x)), concatenate((x, ym, x)))",
        "assert_equal(np.concatenate((x, y, x)), concatenate((x, ym,"
    ],
    [
        "x.shape = y.shape = xm.shape = ym.shape = s",
        "x.shape = y.shape = xm.shape ="
    ],
    [
        "masked_str = np.ma.masked_array(['a', 'b'], mask=[True, False])",
        "masked_str = np.ma.masked_array(['a', 'b'], mask=[True,"
    ],
    [
        "masked_obj = np.ma.masked_array([NotBool(), 'b'], mask=[True, False])",
        "masked_obj = np.ma.masked_array([NotBool(),"
    ],
    [
        "mask=[False,  True,  True, ..., False, False, False],",
        "mask=[False, True, True, ...,"
    ],
    [
        "'             mask = [False  True False],\\n'",
        "' mask = [False True"
    ],
    [
        "'             mask = [False  True  True ..., False False False],\\n'",
        "' mask = [False True True"
    ],
    [
        "for dtype in (int, float, str, object):",
        "for dtype in (int,"
    ],
    [
        "a = masked_array(x, mask=[(True, False), (False, True)])",
        "a = masked_array(x, mask=[(True, False),"
    ],
    [
        "sup.filter(UserWarning, 'Warning: converting a masked element')",
        "sup.filter(UserWarning, 'Warning: converting a masked"
    ],
    [
        "ndtype = [('a', int), ('b', float)]",
        "ndtype = [('a', int), ('b',"
    ],
    [
        "ndtype = [('A', int), ('B', [('BA', int), ('BB', int)])]",
        "ndtype = [('A', int), ('B', [('BA', int), ('BB',"
    ],
    [
        "fancydtype = np.dtype([('x', int), ('y', [('t', int), ('s', float)])])",
        "fancydtype = np.dtype([('x', int), ('y',"
    ],
    [
        "mask = (False, [[True, False, True],",
        "mask = (False,"
    ],
    [
        "ndtype = [('a', int), ('b', float)]",
        "ndtype = [('a', int),"
    ],
    [
        "ndtype = [('a', int), ('b', [('ba', int), ('bb', float)])]",
        "ndtype = [('a', int), ('b', [('ba',"
    ],
    [
        "ndtype = [('a', int), ('b', float)]",
        "ndtype = [('a',"
    ],
    [
        "ndtype = [('a', int), ('b', int)]",
        "ndtype = [('a', int), ('b',"
    ],
    [
        "ndtype = [('a', int), ('b', int)]",
        "ndtype = [('a',"
    ],
    [
        "ndtype = [('a', int), ('b', int)]",
        "ndtype = [('a', int),"
    ],
    [
        "mask = [([[False, True], [True, False]],)],",
        "mask = [([[False,"
    ],
    [
        "mask = [([[False, True], [True, False]], False)],",
        "mask = [([[False, True], [True,"
    ],
    [
        "assert_equal(x + y, xm + ym)",
        "assert_equal(x + y, xm +"
    ],
    [
        "assert_equal(x - y, xm - ym)",
        "assert_equal(x - y, xm"
    ],
    [
        "assert_equal(x * y, xm * ym)",
        "assert_equal(x * y, xm *"
    ],
    [
        "assert_equal(x / y, xm / ym)",
        "assert_equal(x / y,"
    ],
    [
        "assert_equal(x ** y, xm ** ym)",
        "assert_equal(x ** y, xm"
    ],
    [
        "z = x / y[None, :]",
        "z = x /"
    ],
    [
        "z = x / y[:, None]",
        "z = x /"
    ],
    [
        "assert_equal(minimum(x, y), where(less(x, y), x, y))",
        "assert_equal(minimum(x, y), where(less(x,"
    ],
    [
        "assert_equal(maximum(x, y), where(greater(x, y), x, y))",
        "assert_equal(maximum(x, y), where(greater(x, y),"
    ],
    [
        "(_, _, _, _, _, xm, _, _, _, _) = self.d",
        "(_, _, _, _, _, xm, _, _, _,"
    ],
    [
        "x.shape = y.shape = xm.shape = ym.shape = s",
        "x.shape = y.shape = xm.shape ="
    ],
    [
        "funclist = ('sum', 'prod', 'var', 'std', 'max', 'min', 'ptp', 'mean',)",
        "funclist = ('sum', 'prod', 'var', 'std', 'max', 'min', 'ptp',"
    ],
    [
        "ndtype = [('A', int), ('B', int)]",
        "ndtype = [('A',"
    ],
    [
        "ndtype = [('A', int), ('B', [('BA', int), ('BB', int)])]",
        "ndtype = [('A', int), ('B', [('BA', int), ('BB',"
    ],
    [
        "ndtype = [('A', int), ('B', int)]",
        "ndtype = [('A', int),"
    ],
    [
        "ndtype = [('A', int), ('B', [('BA', int), ('BB', int)])]",
        "ndtype = [('A', int), ('B', [('BA', int), ('BB',"
    ],
    [
        "expected_mask = a.mask == np.ones((), a.mask.dtype)",
        "expected_mask = a.mask == np.ones((),"
    ],
    [
        "xs = array(d, mask=m, hard_mask=False, copy=True)",
        "xs = array(d,"
    ],
    [
        "for timecode in (\"as\", \"fs\", \"ps\", \"ns\", \"us\", \"ms\", \"s\", \"m\",",
        "for timecode in (\"as\", \"fs\", \"ps\","
    ],
    [
        "dtype=[('A', int), ('B', [('BA', int), ('BB', int)])])",
        "dtype=[('A', int), ('B', [('BA', int),"
    ],
    [
        "ndtype = [('a', int), ('b', int)]",
        "ndtype = [('a',"
    ],
    [
        "assert_(me * a == \"My mul\")",
        "assert_(me * a"
    ],
    [
        "assert_(a * me == \"My rmul\")",
        "assert_(a * me == \"My"
    ],
    [
        "self.othertypes = [np.dtype(_).type for _ in self.othertypes]",
        "self.othertypes = [np.dtype(_).type for _"
    ],
    [
        "unsupported = {np.dtype(t).type for t in np.typecodes[\"Complex\"]}",
        "unsupported = {np.dtype(t).type for t"
    ],
    [
        "msg = f\"Supported type {t} throwing TypeError\"",
        "msg = f\"Supported type {t} throwing"
    ],
    [
        "unsupported = {np.dtype(t).type for t in np.typecodes[\"Complex\"]}",
        "unsupported = {np.dtype(t).type for t in"
    ],
    [
        "msg = f\"Supported type {t} throwing TypeError\"",
        "msg = f\"Supported type {t} throwing"
    ],
    [
        "mindices = array(indices, mask=(indices >= len(a)))",
        "mindices = array(indices, mask=(indices >="
    ],
    [
        "assert (foo.mean() == bar.mean()) is np.bool(True)",
        "assert (foo.mean() == bar.mean()) is"
    ],
    [
        "match=\"diff requires input that is at least one dimensional\"",
        "match=\"diff requires input that is at"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "dt = np.dtype([('a', int), ('b', int)])",
        "dt = np.dtype([('a',"
    ],
    [
        "dt = np.dtype([('a', int), ('b', int)])",
        "dt = np.dtype([('a', int), ('b',"
    ],
    [
        "match=\"not supported for the input types\"):",
        "match=\"not supported for the input"
    ],
    [
        "chosen = choose(indices_, choices, mode='wrap', out=store)",
        "chosen = choose(indices_, choices, mode='wrap',"
    ],
    [
        "chosen = choose(indices_, choices, mode='wrap', out=store)",
        "chosen = choose(indices_, choices, mode='wrap',"
    ],
    [
        "ntype = [('a', float), ('b', float)]",
        "ntype = [('a', float),"
    ],
    [
        "ntype = [('a', float), ('b', [('ba', float), ('bb', float)])]",
        "ntype = [('a', float), ('b', [('ba', float), ('bb',"
    ],
    [
        "sub_type = np.dtype([('a', int), ('b', base_mtype)])",
        "sub_type = np.dtype([('a', int),"
    ],
    [
        "mdtype = [('a', bool), ('b', bool)]",
        "mdtype = [('a', bool),"
    ],
    [
        "mdtype = [('a', bool), ('b', bool)]",
        "mdtype = [('a',"
    ],
    [
        "mdtype = [('a', float), ('b', float)]",
        "mdtype = [('a', float),"
    ],
    [
        "bdtype = [('a', bool), ('b', bool)]",
        "bdtype = [('a',"
    ],
    [
        "for cpy, shr, dt in itertools.product(bools, bools, dtypes):",
        "for cpy, shr, dt in itertools.product(bools,"
    ],
    [
        "res = make_mask(nomask, copy=cpy, shrink=shr, dtype=dt)",
        "res = make_mask(nomask, copy=cpy, shrink=shr,"
    ],
    [
        "assert_(res is nomask, msgformat % (cpy, shr, dt))",
        "assert_(res is nomask, msgformat % (cpy,"
    ],
    [
        "mtype = [('a', bool), ('b', bool)]",
        "mtype = [('a', bool), ('b',"
    ],
    [
        "othertype = [('A', bool), ('B', bool)]",
        "othertype = [('A', bool), ('B',"
    ],
    [
        "dtype = [('a', bool), ('b', [('ba', bool), ('bb', bool)])]",
        "dtype = [('a', bool), ('b',"
    ],
    [
        "mdtype = [('a', bool), ('b', [('ba', bool), ('bb', bool)])]",
        "mdtype = [('a', bool), ('b', [('ba', bool),"
    ],
    [
        "cond = np.array([True, False, True, True])",
        "cond = np.array([True, False,"
    ],
    [
        "test = np.ma.convolve(a, b, mode='full', propagate_mask=False)",
        "test = np.ma.convolve(a,"
    ],
    [
        "test = np.ma.convolve(a, b, mode='same', propagate_mask=False)",
        "test = np.ma.convolve(a,"
    ],
    [
        "test = np.ma.convolve(a, b, mode='valid', propagate_mask=False)",
        "test = np.ma.convolve(a, b, mode='valid',"
    ],
    [
        "slist = ['one', 'two', 'three', 'four', 'five']",
        "slist = ['one', 'two', 'three',"
    ],
    [
        "mdtype = [('a', bool), ('b', bool), ('c', bool)]",
        "mdtype = [('a', bool), ('b', bool),"
    ],
    [
        "base = array(list(zip(ilist, flist, slist)), mask=mask, dtype=ddtype)",
        "base = array(list(zip(ilist, flist, slist)), mask=mask,"
    ],
    [
        "self.data = {\"base\": base, \"mask\": mask, \"ddtype\": ddtype, \"mdtype\": mdtype}",
        "self.data = {\"base\": base, \"mask\":"
    ],
    [
        "(base_a, base_b, base_c) = (base['a'], base['b'], base['c'])",
        "(base_a, base_b, base_c) ="
    ],
    [
        "(base_a, base_b, base_c) = (base['a'], base['b'], base['c'])",
        "(base_a, base_b, base_c) ="
    ],
    [
        "for n in ('a', 'b', 'c'):",
        "for n in ('a',"
    ],
    [
        "ndtype = [('a', int), ('b', float)]",
        "ndtype = [('a',"
    ],
    [
        "a = array(iterator, dtype=[('a', float), ('b', float)])",
        "a = array(iterator, dtype=[('a', float),"
    ],
    [
        "ndtype = [('a', float), ('b', float)]",
        "ndtype = [('a', float),"
    ],
    [
        "ndtype = np.dtype([('a', float), ('b', int)])",
        "ndtype = np.dtype([('a', float),"
    ],
    [
        "mdtype = np.dtype([('a', bool), ('b', bool)])",
        "mdtype = np.dtype([('a', bool),"
    ],
    [
        "control = np.array([(False, True), (True, True)], dtype=mdtype)",
        "control = np.array([(False, True), (True,"
    ],
    [
        "control = np.array([(True, True), (True, True)], dtype=mdtype)",
        "control = np.array([(True, True),"
    ],
    [
        "a = array(iterator, dtype=[('a', float), ('b', float)])",
        "a = array(iterator, dtype=[('a', float), ('b',"
    ],
    [
        "test = a.view([('A', float), ('B', float)])",
        "test = a.view([('A',"
    ],
    [
        "for f in ['sum', 'prod', 'mean', 'var', 'std']:",
        "for f in ['sum', 'prod',"
    ],
    [
        "self._do_add_test(lambda a, b: a + b)",
        "self._do_add_test(lambda a, b: a"
    ],
    [
        "assert_array_equal(a.mask, [True, False, False, False, False])",
        "assert_array_equal(a.mask, [True, False,"
    ],
    [
        "expected_mask = [False, True, False, False, False, True]",
        "expected_mask = [False, True, False, False,"
    ],
    [
        "assert_(x is np.array(x, dtype=descr, copy=None, subok=True))",
        "assert_(x is np.array(x, dtype=descr,"
    ],
    [
        "\"\"\"Tests suite for MaskedArray & subclassing.",
        "\"\"\"Tests suite for"
    ],
    [
        "array, arange, masked, MaskedArray, masked_array, log, add, hypot,",
        "array, arange, masked, MaskedArray,"
    ],
    [
        "\"\"\"Pure subclass of MaskedArray, keeping some info on subclass.\"\"\"",
        "\"\"\"Pure subclass of MaskedArray, keeping some info on"
    ],
    [
        "Flat iterator object that uses its own setter/getter",
        "Flat iterator object that uses its"
    ],
    [
        "(works around ndarray.flat not propagating subclass setters/getters",
        "(works around ndarray.flat not propagating subclass"
    ],
    [
        "raise ValueError(\"Can only set to MySubArray values\")",
        "raise ValueError(\"Can only set to"
    ],
    [
        "Wrapping a MaskedArray rather than subclassing to test that",
        "Wrapping a MaskedArray rather than"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc,"
    ],
    [
        "inputs = [arg._array if isinstance(arg, self.__class__) else arg",
        "inputs = [arg._array if isinstance(arg, self.__class__) else"
    ],
    [
        "xsub = MSubArray(x, mask=m, info={'xsub': xinfo})",
        "xsub = MSubArray(x, mask=m,"
    ],
    [
        "\"\"\"test that getter and setter go via baseclass\"\"\"",
        "\"\"\"test that getter and setter go via"
    ],
    [
        "mxcsub = masked_array(xcsub, mask=[True, False, True, False, False])",
        "mxcsub = masked_array(xcsub, mask=[True, False,"
    ],
    [
        "\"\"\"test that repr uses the name of the subclass",
        "\"\"\"test that repr uses the name"
    ],
    [
        "mx = masked_array(x, mask=[True, False, True, False, False])",
        "mx = masked_array(x, mask=[True, False,"
    ],
    [
        "mxsub = masked_array(xsub, mask=[True, False, True, False, False])",
        "mxsub = masked_array(xsub, mask=[True, False, True,"
    ],
    [
        "\"\"\"test str with subclass that has overridden str, setitem\"\"\"",
        "\"\"\"test str with subclass that"
    ],
    [
        "mxsub = masked_array(xsub, mask=[True, False, True, False, False])",
        "mxsub = masked_array(xsub, mask=[True, False,"
    ],
    [
        "mxcsub = masked_array(xcsub, mask=[True, False, True, False, False])",
        "mxcsub = masked_array(xcsub, mask=[True, False, True, False,"
    ],
    [
        "\"\"\"Quantity-like class that does not inherit from ndarray\"\"\"",
        "\"\"\"Quantity-like class that does not"
    ],
    [
        "assert_equal(np.divide(wm, m) * m, np.divide(m, m) * wm)",
        "assert_equal(np.divide(wm, m) * m, np.divide(m, m) *"
    ],
    [
        "Adapted from the original test_ma by Pierre Gerard-Marchant",
        "Adapted from the original test_ma by"
    ],
    [
        "array, arange, masked, MaskedArray, masked_array, getmaskarray, shape,",
        "array, arange, masked, MaskedArray,"
    ],
    [
        "dt = np.dtype({'names': ['a', 'b'], 'formats': ['f', 'f']})",
        "dt = np.dtype({'names': ['a',"
    ],
    [
        "dt = np.dtype([('a', 'f'), ('b', [('ba', 'f'), ('bb', 'f')])])",
        "dt = np.dtype([('a', 'f'), ('b', [('ba', 'f'),"
    ],
    [
        "dt = np.dtype({'names': ['a', 'b'], 'formats': ['f', 'f']})",
        "dt = np.dtype({'names': ['a',"
    ],
    [
        "dt = np.dtype([('a', 'f'), ('b', [('ba', 'f'), ('bb', 'f')])])",
        "dt = np.dtype([('a', 'f'), ('b', [('ba',"
    ],
    [
        "b = np.ma.array(x, mask=[[False], [False], [True]])",
        "b = np.ma.array(x,"
    ],
    [
        "match=\"Shape of weights must be consistent with \"",
        "match=\"Shape of weights must"
    ],
    [
        "\"shape of a along specified axis\"):",
        "\"shape of a along"
    ],
    [
        "match=\"Shape of weights must be consistent with \"",
        "match=\"Shape of weights must"
    ],
    [
        "\"shape of a along specified axis\"):",
        "\"shape of a"
    ],
    [
        "'x, axis, expected_avg, weights, expected_wavg, expected_wsum',",
        "'x, axis, expected_avg, weights,"
    ],
    [
        "wavg = np.ma.average(x, axis=axis, weights=weights, keepdims=True)",
        "wavg = np.ma.average(x, axis=axis, weights=weights,"
    ],
    [
        "wavg, wsum = np.ma.average(x, axis=axis, weights=weights,",
        "wavg, wsum = np.ma.average(x, axis=axis,"
    ],
    [
        "\"test the examples given in the docstring of ma.median\"",
        "\"test the examples given in"
    ],
    [
        "msg = \"mask = %s, ndim = %s, axis = %s, overwrite_input = %s\"",
        "msg = \"mask = %s, ndim = %s,"
    ],
    [
        "args = itertools.product(range(-ndmin, ndmin), [False, True])",
        "args = itertools.product(range(-ndmin,"
    ],
    [
        "raise AssertionError(msg % (mask, ndmin, axis, over))",
        "raise AssertionError(msg % (mask,"
    ],
    [
        "raise AssertionError(msg % (mask, ndmin, axis, over))",
        "raise AssertionError(msg % (mask,"
    ],
    [
        "result = median(d, axis=axis, keepdims=True, out=out)",
        "result = median(d,"
    ],
    [
        "a = np.array([[inf,  np.nan], [np.nan, np.nan]])",
        "a = np.array([[inf, np.nan], [np.nan,"
    ],
    [
        "a = np.array([[np.nan, np.nan, inf], [np.nan, np.nan, inf]])",
        "a = np.array([[np.nan, np.nan, inf], [np.nan, np.nan,"
    ],
    [
        "a = np.array([[inf, inf], [inf, inf]])",
        "a = np.array([[inf,"
    ],
    [
        "([np.nan] * i) + [inf] * j)",
        "([np.nan] * i) + [inf] *"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof"
    ],
    [
        "assert_warns(DeprecationWarning, corrcoef, x, y, True, False)",
        "assert_warns(DeprecationWarning, corrcoef, x, y,"
    ],
    [
        "assert_warns(DeprecationWarning, corrcoef, x, y, True, True)",
        "assert_warns(DeprecationWarning, corrcoef, x, y, True,"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof have"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof have"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof have"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof have no"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof"
    ],
    [
        "for (a, a_) in zip((C, R, K, S, D), (c, r, k, s, d)):",
        "for (a, a_) in zip((C, R, K, S, D),"
    ],
    [
        "for (a, a_) in zip((C, R, K, S, D), (c, r, k, s, d)):",
        "for (a, a_) in zip((C, R, K, S, D), (c, r, k, s,"
    ],
    [
        "for (a, a_) in zip((C, R, K, S, D), (c, r, k, s, d)):",
        "for (a, a_) in zip((C, R, K, S, D),"
    ],
    [
        "for (a, a_) in zip((C, R, K, S, D), (c, r, k, s, d)):",
        "for (a, a_) in zip((C, R, K, S, D), (c,"
    ],
    [
        "for (a, a_) in zip((C, R, K, S, D), (c, r, k, s, d)):",
        "for (a, a_) in zip((C, R, K, S, D), (c, r, k,"
    ],
    [
        "d = np.isin(a, b[~b.mask]) & ~a.mask",
        "d = np.isin(a,"
    ],
    [
        "assert_equal(test, [True, True, True, False, True])",
        "assert_equal(test, [True, True,"
    ],
    [
        "assert_equal(test, [True, True, False, True, True])",
        "assert_equal(test, [True, True, False, True,"
    ],
    [
        "for coordinate, value in ndenumerate(a, compressed=False):",
        "for coordinate, value in"
    ],
    [
        "recarray, fromrecords as recfromrecords, fromarrays as recfromarrays",
        "recarray, fromrecords as recfromrecords,"
    ],
    [
        "slist = [b'one', b'two', b'three', b'four', b'five']",
        "slist = [b'one', b'two',"
    ],
    [
        "base = ma.array(list(zip(ilist, flist, slist)), mask=mask, dtype=ddtype)",
        "base = ma.array(list(zip(ilist, flist, slist)), mask=mask,"
    ],
    [
        "for field in ('a', 'b', 'c'):",
        "for field in"
    ],
    [
        "for field in ('a', 'b', 'c'):",
        "for field in ('a',"
    ],
    [
        "for field in ('a', 'b', 'c'):",
        "for field in ('a',"
    ],
    [
        "dtype=[('a', bool), ('b', bool), ('c', bool)])",
        "dtype=[('a', bool), ('b', bool),"
    ],
    [
        "raise Exception(\"Flexible hard masks should be supported !\")",
        "raise Exception(\"Flexible hard masks"
    ],
    [
        "raise TypeError(\"Should have expected a readable buffer object!\")",
        "raise TypeError(\"Should have expected a readable buffer"
    ],
    [
        "mrec = fromarrays([_a, _b, _c], dtype=ddtype,",
        "mrec = fromarrays([_a, _b, _c],"
    ],
    [
        "mrec = fromarrays([_a, _b, _c], dtype=ddtype,",
        "mrec = fromarrays([_a, _b, _c],"
    ],
    [
        "ndtype = [('a', float), ('b', float)]",
        "ndtype = [('a', float),"
    ],
    [
        "self.data = (mrec, a, b, arr)",
        "self.data = (mrec, a, b,"
    ],
    [
        "(mrec, a, b, arr) = self.data",
        "(mrec, a, b,"
    ],
    [
        "(mrec, a, b, arr) = self.data",
        "(mrec, a, b, arr)"
    ],
    [
        "(mrec, a, b, arr) = self.data",
        "(mrec, a, b, arr)"
    ],
    [
        "alttype = [('A', float), ('B', float)]",
        "alttype = [('A',"
    ],
    [
        "mrec = fromarrays([_a, _b, _c], dtype=ddtype,",
        "mrec = fromarrays([_a, _b,"
    ],
    [
        "nrec = recfromarrays((_a._data, _b._data, _c._data), dtype=ddtype)",
        "nrec = recfromarrays((_a._data, _b._data,"
    ],
    [
        "for (f, l) in zip(('a', 'b', 'c'), (_a, _b, _c)):",
        "for (f, l) in zip(('a', 'b',"
    ],
    [
        "'One (S)','Two (I)','Three (F)','Four (M)','Five (-)','Six (C)'",
        "'One (S)','Two (I)','Three (F)','Four"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof have"
    ],
    [
        "the multiarray and umath c-extension modules were merged into a single",
        "the multiarray and umath c-extension modules were merged"
    ],
    [
        "_multiarray_umath extension module. So we replicate the old namespace",
        "_multiarray_umath extension module. So we replicate the old"
    ],
    [
        "by importing from the extension module.",
        "by importing from"
    ],
    [
        "_expandtabs, _center, _ljust, _rjust, _zfill, _partition, _partition_index,",
        "_expandtabs, _center, _ljust, _rjust, _zfill, _partition,"
    ],
    [
        "'bitwise_and', 'bitwise_or', 'bitwise_xor', 'cbrt', 'ceil', 'conj',",
        "'bitwise_and', 'bitwise_or', 'bitwise_xor', 'cbrt',"
    ],
    [
        "'fmod', 'frexp', 'frompyfunc', 'gcd', 'greater', 'greater_equal',",
        "'fmod', 'frexp', 'frompyfunc', 'gcd', 'greater',"
    ],
    [
        "'heaviside', 'hypot', 'invert', 'isfinite', 'isinf', 'isnan', 'isnat',",
        "'heaviside', 'hypot', 'invert', 'isfinite',"
    ],
    [
        "'logical_or', 'logical_xor', 'matvec', 'maximum', 'minimum', 'mod', 'modf',",
        "'logical_or', 'logical_xor', 'matvec', 'maximum',"
    ],
    [
        "'multiply', 'negative', 'nextafter', 'not_equal', 'pi', 'positive',",
        "'multiply', 'negative', 'nextafter', 'not_equal',"
    ],
    [
        "'rint', 'sign', 'signbit', 'sin', 'sinh', 'spacing', 'sqrt', 'square',",
        "'rint', 'sign', 'signbit', 'sin',"
    ],
    [
        "'subtract', 'tan', 'tanh', 'true_divide', 'trunc', 'vecdot', 'vecmat']",
        "'subtract', 'tan', 'tanh', 'true_divide', 'trunc', 'vecdot',"
    ],
    [
        "\"\"\"Module containing non-deprecated functions borrowed from Numeric.",
        "\"\"\"Module containing non-deprecated functions borrowed from"
    ],
    [
        "from . import multiarray as mu",
        "from . import multiarray as"
    ],
    [
        "from . import umath as um",
        "from . import"
    ],
    [
        "from . import numerictypes as nt",
        "from . import numerictypes"
    ],
    [
        "from .multiarray import asarray, array, asanyarray, concatenate",
        "from .multiarray import asarray, array,"
    ],
    [
        "'argmin', 'argpartition', 'argsort', 'around', 'choose', 'clip',",
        "'argmin', 'argpartition', 'argsort', 'around', 'choose',"
    ],
    [
        "'ndim', 'nonzero', 'partition', 'prod', 'ptp', 'put',",
        "'ndim', 'nonzero', 'partition',"
    ],
    [
        "'std', 'sum', 'swapaxes', 'take', 'trace', 'transpose', 'var',",
        "'std', 'sum', 'swapaxes', 'take', 'trace', 'transpose',"
    ],
    [
        "def _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs):",
        "def _wrapreduction(obj, ufunc, method,"
    ],
    [
        "passkwargs = {k: v for k, v in kwargs.items()",
        "passkwargs = {k: v for k, v in"
    ],
    [
        "return ufunc.reduce(obj, axis, dtype, out, **passkwargs)",
        "return ufunc.reduce(obj, axis,"
    ],
    [
        "def _wrapreduction_any_all(obj, ufunc, method, axis, out, **kwargs):",
        "def _wrapreduction_any_all(obj, ufunc, method, axis, out,"
    ],
    [
        "passkwargs = {k: v for k, v in kwargs.items()",
        "passkwargs = {k: v for"
    ],
    [
        "return ufunc.reduce(obj, axis, bool, out, **passkwargs)",
        "return ufunc.reduce(obj, axis, bool, out,"
    ],
    [
        "def _take_dispatcher(a, indices, axis=None, out=None, mode=None):",
        "def _take_dispatcher(a, indices, axis=None, out=None,"
    ],
    [
        "def take(a, indices, axis=None, out=None, mode='raise'):",
        "def take(a, indices, axis=None, out=None,"
    ],
    [
        "Take elements from an array along an axis.",
        "Take elements from an"
    ],
    [
        "When axis is not None, this function does the same thing as \"fancy\"",
        "When axis is not None, this function does"
    ],
    [
        "indexing (indexing arrays using arrays); however, it can be easier to use",
        "indexing (indexing arrays using arrays); however, it can"
    ],
    [
        "if you need elements along a given axis. A call such as",
        "if you need elements along a given"
    ],
    [
        "Explained without fancy indexing, this is equivalent to the following use",
        "Explained without fancy indexing, this is equivalent to"
    ],
    [
        "of `ndindex`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of",
        "of `ndindex`, which sets each of ``ii``, ``jj``, and ``kk`` to a"
    ],
    [
        "out[ii + jj + kk] = a[ii + (indices[jj],) + kk]",
        "out[ii + jj + kk] ="
    ],
    [
        "a : array_like (Ni..., M, Nk...)",
        "a : array_like"
    ],
    [
        "The indices of the values to extract.",
        "The indices of the values"
    ],
    [
        "The axis over which to select values. By default, the flattened",
        "The axis over which to select values. By"
    ],
    [
        "out : ndarray, optional (Ni..., Nj..., Nk...)",
        "out : ndarray, optional"
    ],
    [
        "If provided, the result will be placed in this array. It should",
        "If provided, the result will be placed in this array."
    ],
    [
        "be of the appropriate shape and dtype. Note that `out` is always",
        "be of the appropriate shape and dtype. Note that"
    ],
    [
        "buffered if `mode='raise'`; use other modes for better performance.",
        "buffered if `mode='raise'`; use other modes"
    ],
    [
        "mode : {'raise', 'wrap', 'clip'}, optional",
        "mode : {'raise', 'wrap', 'clip'},"
    ],
    [
        "Specifies how out-of-bounds indices will behave.",
        "Specifies how out-of-bounds indices"
    ],
    [
        "* 'raise' -- raise an error (default)",
        "* 'raise' -- raise"
    ],
    [
        "* 'clip' -- clip to the range",
        "* 'clip' -- clip"
    ],
    [
        "'clip' mode means that all indices that are too large are replaced",
        "'clip' mode means that all indices that are"
    ],
    [
        "by the index that addresses the last element along that axis. Note",
        "by the index that addresses the last element"
    ],
    [
        "that this disables indexing with negative numbers.",
        "that this disables indexing with"
    ],
    [
        "out : ndarray (Ni..., Nj..., Nk...)",
        "out : ndarray (Ni..., Nj...,"
    ],
    [
        "The returned array has the same type as `a`.",
        "The returned array has the same type as"
    ],
    [
        "compress : Take elements using a boolean mask",
        "compress : Take elements using"
    ],
    [
        "take_along_axis : Take elements by matching the array and the index arrays",
        "take_along_axis : Take elements by matching the array and the"
    ],
    [
        "By eliminating the inner loop in the description above, and using `s_` to",
        "By eliminating the inner loop in the"
    ],
    [
        "build simple slice objects, `take` can be expressed  in terms of applying",
        "build simple slice objects, `take` can be expressed in terms"
    ],
    [
        "out[ii + s_[...,] + kk] = a[ii + s_[:,] + kk][indices]",
        "out[ii + s_[...,] + kk] = a[ii + s_[:,] +"
    ],
    [
        "For this reason, it is equivalent to (but faster than) the following use",
        "For this reason, it is equivalent to (but faster than) the"
    ],
    [
        "In this example if `a` is an ndarray, \"fancy\" indexing can be used.",
        "In this example if `a` is an ndarray,"
    ],
    [
        "If `indices` is not one dimensional, the output also has these dimensions.",
        "If `indices` is not one dimensional, the"
    ],
    [
        "return _wrapfunc(a, 'take', indices, axis=axis, out=out, mode=mode)",
        "return _wrapfunc(a, 'take', indices,"
    ],
    [
        "def _reshape_dispatcher(a, /, shape=None, order=None, *, newshape=None,",
        "def _reshape_dispatcher(a, /, shape=None, order=None,"
    ],
    [
        "def reshape(a, /, shape=None, order='C', *, newshape=None, copy=None):",
        "def reshape(a, /, shape=None,"
    ],
    [
        "Gives a new shape to an array without changing its data.",
        "Gives a new shape to an array without"
    ],
    [
        "shape : int or tuple of ints",
        "shape : int or"
    ],
    [
        "The new shape should be compatible with the original shape. If",
        "The new shape should be compatible with the original shape."
    ],
    [
        "inferred from the length of the array and remaining dimensions.",
        "inferred from the length of the array and"
    ],
    [
        "order : {'C', 'F', 'A'}, optional",
        "order : {'C', 'F', 'A'},"
    ],
    [
        "Read the elements of ``a`` using this index order, and place the",
        "Read the elements of ``a`` using this index order, and place"
    ],
    [
        "elements into the reshaped array using this index order. 'C'",
        "elements into the reshaped array using this"
    ],
    [
        "means to read / write the elements using C-like index order,",
        "means to read / write the"
    ],
    [
        "with the last axis index changing fastest, back to the first",
        "with the last axis index changing"
    ],
    [
        "axis index changing slowest. 'F' means to read / write the",
        "axis index changing slowest. 'F' means to"
    ],
    [
        "elements using Fortran-like index order, with the first index",
        "elements using Fortran-like index order, with the"
    ],
    [
        "changing fastest, and the last index changing slowest. Note that",
        "changing fastest, and the last index changing slowest."
    ],
    [
        "the 'C' and 'F' options take no account of the memory layout of",
        "the 'C' and 'F' options take no account of the memory"
    ],
    [
        "the underlying array, and only refer to the order of indexing.",
        "the underlying array, and only refer to the"
    ],
    [
        "'A' means to read / write the elements in Fortran-like index",
        "'A' means to read / write"
    ],
    [
        "order if ``a`` is Fortran *contiguous* in memory, C-like order",
        "order if ``a`` is Fortran *contiguous*"
    ],
    [
        "newshape : int or tuple of ints",
        "newshape : int or"
    ],
    [
        "Replaced by ``shape`` argument. Retained for backward",
        "Replaced by ``shape`` argument."
    ],
    [
        "If ``True``, then the array data is copied. If ``None``, a copy will",
        "If ``True``, then the array data is copied. If ``None``, a"
    ],
    [
        "only be made if it's required by ``order``. For ``False`` it raises",
        "only be made if it's required by ``order``. For"
    ],
    [
        "a ``ValueError`` if a copy cannot be avoided. Default: ``None``.",
        "a ``ValueError`` if a copy"
    ],
    [
        "This will be a new view object if possible; otherwise, it will",
        "This will be a new view object if possible; otherwise,"
    ],
    [
        "be a copy.  Note there is no guarantee of the *memory layout* (C- or",
        "be a copy. Note there is no guarantee"
    ],
    [
        "Fortran- contiguous) of the returned array.",
        "Fortran- contiguous) of the"
    ],
    [
        "It is not always possible to change the shape of an array without copying",
        "It is not always possible to change the shape of"
    ],
    [
        "The ``order`` keyword gives the index ordering both for *fetching*",
        "The ``order`` keyword gives the index ordering both"
    ],
    [
        "the values from ``a``, and then *placing* the values into the output",
        "the values from ``a``, and then *placing* the values into the"
    ],
    [
        "array. For example, let's say you have an array:",
        "array. For example, let's say you"
    ],
    [
        "You can think of reshaping as first raveling the array (using the given",
        "You can think of reshaping as first raveling the array (using the"
    ],
    [
        "index order), then inserting the elements from the raveled array into the",
        "index order), then inserting the elements from the raveled"
    ],
    [
        "new array using the same kind of index ordering as was used for the",
        "new array using the same kind of index ordering as was"
    ],
    [
        "if newshape is None and shape is None:",
        "if newshape is None and"
    ],
    [
        "\"You cannot specify 'newshape' and 'shape' arguments \"",
        "\"You cannot specify 'newshape' and 'shape'"
    ],
    [
        "\"`newshape` keyword argument is deprecated, \"",
        "\"`newshape` keyword argument is"
    ],
    [
        "\"use `shape=...` or pass shape positionally instead. \"",
        "\"use `shape=...` or pass shape positionally instead."
    ],
    [
        "return _wrapfunc(a, 'reshape', shape, order=order, copy=copy)",
        "return _wrapfunc(a, 'reshape', shape,"
    ],
    [
        "Construct an array from an index array and a list of arrays to choose from.",
        "Construct an array from an index array and a list of arrays to choose"
    ],
    [
        "First of all, if confused or uncertain, definitely look at the Examples -",
        "First of all, if confused or uncertain, definitely look"
    ],
    [
        "in its full generality, this function is less simple than it might",
        "in its full generality, this function is"
    ],
    [
        "seem from the following code description::",
        "seem from the"
    ],
    [
        "np.choose(a,c) == np.array([c[a[I]][I] for I in np.ndindex(a.shape)])",
        "np.choose(a,c) == np.array([c[a[I]][I] for I in"
    ],
    [
        "But this omits some subtleties.  Here is a fully general summary:",
        "But this omits some subtleties. Here is"
    ],
    [
        "Given an \"index\" array (`a`) of integers and a sequence of ``n`` arrays",
        "Given an \"index\" array (`a`) of integers and a sequence"
    ],
    [
        "(`choices`), `a` and each choice array are first broadcast, as necessary,",
        "(`choices`), `a` and each choice array are"
    ],
    [
        "to arrays of a common shape; calling these *Ba* and *Bchoices[i], i =",
        "to arrays of a common shape; calling these *Ba* and"
    ],
    [
        "for each ``i``.  Then, a new array with shape ``Ba.shape`` is created as",
        "for each ``i``. Then, a new array with shape ``Ba.shape``"
    ],
    [
        "* if ``mode='raise'`` (the default), then, first of all, each element of",
        "* if ``mode='raise'`` (the default), then, first of"
    ],
    [
        "position in ``Ba`` - then the value at the same position in the new array",
        "position in ``Ba`` - then the value at"
    ],
    [
        "is the value in ``Bchoices[i]`` at that same position;",
        "is the value in ``Bchoices[i]`` at"
    ],
    [
        "* if ``mode='wrap'``, values in `a` (and thus `Ba`) may be any (signed)",
        "* if ``mode='wrap'``, values in `a` (and thus `Ba`) may be any"
    ],
    [
        "integer; modular arithmetic is used to map integers outside the range",
        "integer; modular arithmetic is used to map integers outside the"
    ],
    [
        "* if ``mode='clip'``, values in `a` (and thus ``Ba``) may be any (signed)",
        "* if ``mode='clip'``, values in `a` (and thus ``Ba``) may be any"
    ],
    [
        "number of choices, unless ``mode=wrap`` or ``mode=clip``, in which",
        "number of choices, unless ``mode=wrap`` or ``mode=clip``, in"
    ],
    [
        "Choice arrays. `a` and all of the choices must be broadcastable to the",
        "Choice arrays. `a` and all of the choices must be broadcastable to"
    ],
    [
        "same shape.  If `choices` is itself an array (not recommended), then",
        "same shape. If `choices` is itself an"
    ],
    [
        "its outermost dimension (i.e., the one corresponding to",
        "its outermost dimension (i.e., the one"
    ],
    [
        "If provided, the result will be inserted into this array. It should",
        "If provided, the result will be"
    ],
    [
        "be of the appropriate shape and dtype. Note that `out` is always",
        "be of the appropriate shape and dtype. Note that"
    ],
    [
        "buffered if ``mode='raise'``; use other modes for better performance.",
        "buffered if ``mode='raise'``; use other modes for"
    ],
    [
        "mode : {'raise' (default), 'wrap', 'clip'}, optional",
        "mode : {'raise' (default), 'wrap', 'clip'},"
    ],
    [
        "* 'raise' : an exception is raised",
        "* 'raise' : an exception is"
    ],
    [
        "* 'wrap' : value becomes value mod ``n``",
        "* 'wrap' : value becomes value mod"
    ],
    [
        "If `a` and each choice array are not all broadcastable to the same",
        "If `a` and each choice array are not all broadcastable"
    ],
    [
        "numpy.take_along_axis : Preferable if `choices` is an array",
        "numpy.take_along_axis : Preferable if"
    ],
    [
        "To reduce the chance of misinterpretation, even though the following",
        "To reduce the chance of misinterpretation, even though the"
    ],
    [
        "\"abuse\" is nominally supported, `choices` should neither be, nor be",
        "\"abuse\" is nominally supported, `choices` should neither be, nor"
    ],
    [
        "thought of as, a single array, i.e., the outermost sequence-like container",
        "thought of as, a single array, i.e., the"
    ],
    [
        "should be either a list or a tuple.",
        "should be either a list or a"
    ],
    [
        "A couple examples illustrating how choose broadcasts:",
        "A couple examples illustrating"
    ],
    [
        "return _wrapfunc(a, 'choose', choices, out=out, mode=mode)",
        "return _wrapfunc(a, 'choose', choices, out=out,"
    ],
    [
        "Repeat each element of an array after themselves",
        "Repeat each element of"
    ],
    [
        "repeats : int or array of ints",
        "repeats : int or array of"
    ],
    [
        "The number of repetitions for each element.  `repeats` is broadcasted",
        "The number of repetitions for each element. `repeats` is"
    ],
    [
        "to fit the shape of the given axis.",
        "to fit the shape of the given"
    ],
    [
        "The axis along which to repeat values.  By default, use the",
        "The axis along which to repeat values."
    ],
    [
        "flattened input array, and return a flat output array.",
        "flattened input array, and return a"
    ],
    [
        "Output array which has the same shape as `a`, except along",
        "Output array which has the same shape"
    ],
    [
        "unique : Find the unique elements of an array.",
        "unique : Find the unique"
    ],
    [
        "Replaces specified elements of an array with given values.",
        "Replaces specified elements of an array with given"
    ],
    [
        "The indexing works on the flattened target array. `put` is roughly",
        "The indexing works on the flattened target array."
    ],
    [
        "Values to place in `a` at target indices. If `v` is shorter than",
        "Values to place in `a` at target indices. If `v`"
    ],
    [
        "`ind` it will be repeated as necessary.",
        "`ind` it will be"
    ],
    [
        "mode : {'raise', 'wrap', 'clip'}, optional",
        "mode : {'raise',"
    ],
    [
        "Specifies how out-of-bounds indices will behave.",
        "Specifies how out-of-bounds indices"
    ],
    [
        "* 'raise' -- raise an error (default)",
        "* 'raise' -- raise"
    ],
    [
        "* 'clip' -- clip to the range",
        "* 'clip' -- clip"
    ],
    [
        "'clip' mode means that all indices that are too large are replaced",
        "'clip' mode means that all indices that are"
    ],
    [
        "by the index that addresses the last element along that axis. Note",
        "by the index that addresses the last"
    ],
    [
        "that this disables indexing with negative numbers. In 'raise' mode,",
        "that this disables indexing with negative"
    ],
    [
        "if an exception occurs the target array may still be modified.",
        "if an exception occurs the target array may"
    ],
    [
        "put_along_axis : Put elements by matching the array and the index arrays",
        "put_along_axis : Put elements by matching the array and the index"
    ],
    [
        "Interchange two axes of an array.",
        "Interchange two axes of an"
    ],
    [
        "returned; otherwise a new array is created. For earlier NumPy",
        "returned; otherwise a new array is created. For earlier"
    ],
    [
        "versions a view of `a` is returned only if the order of the",
        "versions a view of `a` is returned only if the order"
    ],
    [
        "axes is changed, otherwise the input array is returned.",
        "axes is changed, otherwise the input array is"
    ],
    [
        "Returns an array with axes transposed.",
        "Returns an array"
    ],
    [
        "transposed vector is simply the same vector.",
        "transposed vector is simply the"
    ],
    [
        "For an n-D array, if axes are given, their order indicates how the",
        "For an n-D array, if axes are given, their order"
    ],
    [
        "axes are permuted (see Examples). If axes are not provided, then",
        "axes are permuted (see Examples). If"
    ],
    [
        "axes : tuple or list of ints, optional",
        "axes : tuple or"
    ],
    [
        "If specified, it must be a tuple or list which contains a permutation",
        "If specified, it must be a tuple or"
    ],
    [
        "indices can also be used to specify axes. The i-th axis of the returned",
        "indices can also be used to specify axes."
    ],
    [
        "array will correspond to the axis numbered ``axes[i]`` of the input.",
        "array will correspond to the axis numbered ``axes[i]``"
    ],
    [
        "`a` with its axes permuted. A view is returned whenever possible.",
        "`a` with its axes permuted. A view is returned whenever"
    ],
    [
        "moveaxis : Move axes of an array to new positions.",
        "moveaxis : Move axes of an array"
    ],
    [
        "argsort : Return the indices that would sort an array.",
        "argsort : Return the indices that"
    ],
    [
        "Use ``transpose(a, argsort(axes))`` to invert the transposition of tensors",
        "Use ``transpose(a, argsort(axes))`` to invert"
    ],
    [
        "when using the `axes` keyword argument.",
        "when using the `axes`"
    ],
    [
        "Transposes a matrix (or a stack of matrices) ``x``.",
        "Transposes a matrix (or a stack of"
    ],
    [
        "This function is Array API compatible.",
        "This function is Array API"
    ],
    [
        "Input array having shape (..., M, N) and whose two innermost",
        "Input array having shape (..., M, N) and whose two"
    ],
    [
        "An array containing the transpose for each matrix and having shape",
        "An array containing the transpose for each matrix and having"
    ],
    [
        "def _partition_dispatcher(a, kth, axis=None, kind=None, order=None):",
        "def _partition_dispatcher(a, kth, axis=None,"
    ],
    [
        "Return a partitioned copy of an array.",
        "Return a partitioned copy of"
    ],
    [
        "Creates a copy of the array and partially sorts it in such a way that",
        "Creates a copy of the array and partially sorts it in such"
    ],
    [
        "the value of the element in k-th position is in the position it would be",
        "the value of the element in k-th position"
    ],
    [
        "in a sorted array. In the output array, all elements smaller than the k-th",
        "in a sorted array. In the output array, all"
    ],
    [
        "element are located to the left of this element and all equal or greater",
        "element are located to the left of this element"
    ],
    [
        "are located to its right. The ordering of the elements in the two",
        "are located to its right. The ordering of the elements in the"
    ],
    [
        "partitions on the either side of the k-th element in the output array is",
        "partitions on the either side of the k-th"
    ],
    [
        "kth : int or sequence of ints",
        "kth : int or"
    ],
    [
        "Element index to partition by. The k-th value of the element",
        "Element index to partition by. The k-th value"
    ],
    [
        "will be in its final sorted position and all smaller elements",
        "will be in its final sorted"
    ],
    [
        "will be moved before it and all equal or greater elements behind",
        "will be moved before it and all equal or"
    ],
    [
        "it. The order of all elements in the partitions is undefined. If",
        "it. The order of all elements in the"
    ],
    [
        "provided with a sequence of k-th it will partition all elements",
        "provided with a sequence of k-th"
    ],
    [
        "indexed by k-th  of them into their sorted position at once.",
        "indexed by k-th of them into their sorted position"
    ],
    [
        "Passing booleans as index is deprecated.",
        "Passing booleans as"
    ],
    [
        "axis : int or None, optional",
        "axis : int"
    ],
    [
        "Axis along which to sort. If None, the array is flattened before",
        "Axis along which to sort. If None, the array is flattened"
    ],
    [
        "order : str or list of str, optional",
        "order : str or list of str,"
    ],
    [
        "When `a` is an array with fields defined, this argument",
        "When `a` is an array with fields"
    ],
    [
        "specifies which fields to compare first, second, etc.  A single",
        "specifies which fields to compare"
    ],
    [
        "field can be specified as a string.  Not all fields need be",
        "field can be specified as a"
    ],
    [
        "specified, but unspecified fields will still be used, in the",
        "specified, but unspecified fields will still be used,"
    ],
    [
        "order in which they come up in the dtype, to break ties.",
        "order in which they come up in the"
    ],
    [
        "Array of the same type and shape as `a`.",
        "Array of the same type"
    ],
    [
        "ndarray.partition : Method to sort an array in-place.",
        "ndarray.partition : Method to sort"
    ],
    [
        "The various selection algorithms are characterized by their average",
        "The various selection algorithms are characterized"
    ],
    [
        "speed, worst case performance, work space size, and whether they are",
        "speed, worst case performance, work space size,"
    ],
    [
        "stable. A stable sort keeps items with the same key in the same",
        "stable. A stable sort keeps items with the same key in the"
    ],
    [
        "relative order. The available algorithms have the following",
        "relative order. The available algorithms have"
    ],
    [
        "kind            speed   worst case    work space  stable",
        "kind speed worst case work space"
    ],
    [
        "All the partition algorithms make temporary copies of the data when",
        "All the partition algorithms make temporary copies"
    ],
    [
        "partitioning along any but the last axis.  Consequently,",
        "partitioning along any but the"
    ],
    [
        "partitioning along the last axis is faster and uses less space than",
        "partitioning along the last axis is faster and uses less"
    ],
    [
        "The sort order for complex numbers is lexicographic. If both the",
        "The sort order for complex numbers is lexicographic. If both"
    ],
    [
        "real and imaginary parts are non-nan then the order is determined by",
        "real and imaginary parts are non-nan then"
    ],
    [
        "the real parts except when they are equal, in which case the order",
        "the real parts except when they are equal, in which"
    ],
    [
        "is determined by the imaginary parts.",
        "is determined by"
    ],
    [
        "The sort order of ``np.nan`` is bigger than ``np.inf``.",
        "The sort order of ``np.nan``"
    ],
    [
        "The next example shows the use of multiple values passed to `kth`.",
        "The next example shows the use of multiple"
    ],
    [
        "def _argpartition_dispatcher(a, kth, axis=None, kind=None, order=None):",
        "def _argpartition_dispatcher(a, kth, axis=None,"
    ],
    [
        "Perform an indirect partition along the given axis using the",
        "Perform an indirect partition along the given axis"
    ],
    [
        "algorithm specified by the `kind` keyword. It returns an array of",
        "algorithm specified by the `kind` keyword. It returns an array"
    ],
    [
        "indices of the same shape as `a` that index data along the given",
        "indices of the same shape as `a` that"
    ],
    [
        "kth : int or sequence of ints",
        "kth : int or sequence of"
    ],
    [
        "Element index to partition by. The k-th element will be in its",
        "Element index to partition by. The k-th element"
    ],
    [
        "final sorted position and all smaller elements will be moved",
        "final sorted position and all smaller elements will be"
    ],
    [
        "before it and all larger elements behind it. The order of all",
        "before it and all larger elements behind it. The order"
    ],
    [
        "elements in the partitions is undefined. If provided with a",
        "elements in the partitions is undefined."
    ],
    [
        "sequence of k-th it will partition all of them into their sorted",
        "sequence of k-th it will partition"
    ],
    [
        "Passing booleans as index is deprecated.",
        "Passing booleans as index"
    ],
    [
        "axis : int or None, optional",
        "axis : int or"
    ],
    [
        "None, the flattened array is used.",
        "None, the flattened array"
    ],
    [
        "order : str or list of str, optional",
        "order : str or list of str,"
    ],
    [
        "When `a` is an array with fields defined, this argument",
        "When `a` is an array with fields"
    ],
    [
        "specifies which fields to compare first, second, etc. A single",
        "specifies which fields to compare first, second, etc."
    ],
    [
        "field can be specified as a string, and not all fields need be",
        "field can be specified as a string,"
    ],
    [
        "specified, but unspecified fields will still be used, in the",
        "specified, but unspecified fields will still be used,"
    ],
    [
        "order in which they come up in the dtype, to break ties.",
        "order in which they come up in the dtype, to break"
    ],
    [
        "Array of indices that partition `a` along the specified axis.",
        "Array of indices that partition"
    ],
    [
        "If `a` is one-dimensional, ``a[index_array]`` yields a partitioned `a`.",
        "If `a` is one-dimensional, ``a[index_array]`` yields"
    ],
    [
        "always yields the partitioned `a`, irrespective of dimensionality.",
        "always yields the partitioned `a`, irrespective of"
    ],
    [
        "partition : Describes partition algorithms used.",
        "partition : Describes partition algorithms"
    ],
    [
        "take_along_axis : Apply ``index_array`` from argpartition",
        "take_along_axis : Apply"
    ],
    [
        "to an array as if by calling partition.",
        "to an array as if by"
    ],
    [
        "The returned indices are not guaranteed to be sorted according to",
        "The returned indices are not guaranteed"
    ],
    [
        "the values. Furthermore, the default selection algorithm ``introselect``",
        "the values. Furthermore, the default selection"
    ],
    [
        "is unstable, and hence the returned indices are not guaranteed",
        "is unstable, and hence the returned"
    ],
    [
        "to be the earliest/latest occurrence of the element.",
        "to be the earliest/latest"
    ],
    [
        "`argpartition` works for real/complex inputs with nan values,",
        "`argpartition` works for real/complex inputs with"
    ],
    [
        "see `partition` for notes on the enhanced sort order and",
        "see `partition` for notes on the enhanced"
    ],
    [
        "return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)",
        "return _wrapfunc(a, 'argpartition', kth,"
    ],
    [
        "def _sort_dispatcher(a, axis=None, kind=None, order=None, *, stable=None):",
        "def _sort_dispatcher(a, axis=None, kind=None, order=None, *,"
    ],
    [
        "Return a sorted copy of an array.",
        "Return a sorted copy"
    ],
    [
        "axis : int or None, optional",
        "axis : int or"
    ],
    [
        "Axis along which to sort. If None, the array is flattened before",
        "Axis along which to sort. If None, the"
    ],
    [
        "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional",
        "kind : {'quicksort', 'mergesort', 'heapsort',"
    ],
    [
        "Sorting algorithm. The default is 'quicksort'. Note that both 'stable'",
        "Sorting algorithm. The default is 'quicksort'. Note that"
    ],
    [
        "and 'mergesort' use timsort or radix sort under the covers and,",
        "and 'mergesort' use timsort or radix sort under the covers"
    ],
    [
        "in general, the actual implementation will vary with data type.",
        "in general, the actual implementation will vary"
    ],
    [
        "The 'mergesort' option is retained for backwards compatibility.",
        "The 'mergesort' option is"
    ],
    [
        "order : str or list of str, optional",
        "order : str or list"
    ],
    [
        "When `a` is an array with fields defined, this argument specifies",
        "When `a` is an array with fields"
    ],
    [
        "which fields to compare first, second, etc.  A single field can",
        "which fields to compare first, second, etc."
    ],
    [
        "be specified as a string, and not all fields need be specified,",
        "be specified as a string, and not"
    ],
    [
        "but unspecified fields will still be used, in the order in which",
        "but unspecified fields will still be used, in the"
    ],
    [
        "they come up in the dtype, to break ties.",
        "they come up in the dtype,"
    ],
    [
        "Sort stability. If ``True``, the returned array will maintain",
        "Sort stability. If ``True``, the returned array"
    ],
    [
        "the relative order of ``a`` values which compare as equal.",
        "the relative order of ``a`` values which"
    ],
    [
        "If ``False`` or ``None``, this is not guaranteed. Internally,",
        "If ``False`` or ``None``, this is not"
    ],
    [
        "this option selects ``kind='stable'``. Default: ``None``.",
        "this option selects ``kind='stable'``."
    ],
    [
        "Array of the same type and shape as `a`.",
        "Array of the same type and"
    ],
    [
        "ndarray.sort : Method to sort an array in-place.",
        "ndarray.sort : Method to sort an array"
    ],
    [
        "lexsort : Indirect stable sort on multiple keys.",
        "lexsort : Indirect stable sort on"
    ],
    [
        "searchsorted : Find elements in a sorted array.",
        "searchsorted : Find elements in"
    ],
    [
        "The various sorting algorithms are characterized by their average speed,",
        "The various sorting algorithms are characterized by"
    ],
    [
        "worst case performance, work space size, and whether they are stable. A",
        "worst case performance, work space size, and whether they are"
    ],
    [
        "stable sort keeps items with the same key in the same relative",
        "stable sort keeps items with the same key in the"
    ],
    [
        "order. The four algorithms implemented in NumPy have the following",
        "order. The four algorithms implemented in NumPy"
    ],
    [
        "kind      speed   worst case    work space   stable",
        "kind speed worst case work space"
    ],
    [
        ".. note:: The datatype determines which of 'mergesort' or 'timsort'",
        ".. note:: The datatype determines which of 'mergesort'"
    ],
    [
        "is actually used, even if 'mergesort' is specified. User selection",
        "is actually used, even if"
    ],
    [
        "at a finer scale is not currently available.",
        "at a finer scale is not currently"
    ],
    [
        "For performance, ``sort`` makes a temporary copy if needed to make the data",
        "For performance, ``sort`` makes a temporary copy"
    ],
    [
        "in memory along the sort axis. For even better performance and reduced",
        "in memory along the sort axis. For even better"
    ],
    [
        "memory consumption, ensure that the array is already contiguous along the",
        "memory consumption, ensure that the array is already contiguous along"
    ],
    [
        "The sort order for complex numbers is lexicographic. If both the real",
        "The sort order for complex numbers"
    ],
    [
        "and imaginary parts are non-nan then the order is determined by the",
        "and imaginary parts are non-nan then the order is determined"
    ],
    [
        "real parts except when they are equal, in which case the order is",
        "real parts except when they are equal, in which case the"
    ],
    [
        "values are sorted to the end. The extended sort order is:",
        "values are sorted to the end. The"
    ],
    [
        "* Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]",
        "* Complex: [R + Rj, R + nanj,"
    ],
    [
        "where R is a non-nan real value. Complex values with the same nan",
        "where R is a non-nan real value. Complex values with the"
    ],
    [
        "placements are sorted according to the non-nan part if it exists.",
        "placements are sorted according to the non-nan"
    ],
    [
        "Non-nan values are sorted as before.",
        "Non-nan values are"
    ],
    [
        "When sorting does not make enough progress it switches to",
        "When sorting does not make enough progress it switches"
    ],
    [
        "This implementation makes quicksort O(n*log(n)) in the worst case.",
        "This implementation makes quicksort O(n*log(n)) in"
    ],
    [
        "'stable' automatically chooses the best stable sorting algorithm",
        "'stable' automatically chooses the"
    ],
    [
        "for the data type being sorted.",
        "for the data"
    ],
    [
        "It, along with 'mergesort' is currently mapped to",
        "It, along with 'mergesort' is currently"
    ],
    [
        "API forward compatibility currently limits the",
        "API forward compatibility currently limits"
    ],
    [
        "ability to select the implementation and it is hardwired for the different",
        "ability to select the implementation and it is"
    ],
    [
        "Timsort is added for better performance on already or nearly",
        "Timsort is added for better performance on already or"
    ],
    [
        "sorted data. On random data timsort is almost identical to",
        "sorted data. On random data timsort is"
    ],
    [
        "mergesort. It is now used for stable sort while quicksort is still the",
        "mergesort. It is now used for stable sort while quicksort is still"
    ],
    [
        "default sort if none is chosen. For timsort details, refer to",
        "default sort if none is chosen. For timsort"
    ],
    [
        "'mergesort' and 'stable' are mapped to radix sort for integer data types.",
        "'mergesort' and 'stable' are mapped to radix sort for integer data"
    ],
    [
        "Radix sort is an O(n) sort instead of O(n log n).",
        "Radix sort is an O(n) sort instead"
    ],
    [
        "NaT now sorts to the end of arrays for consistency with NaN.",
        "NaT now sorts to the end of arrays for"
    ],
    [
        "Use the `order` keyword to specify a field to use when sorting a",
        "Use the `order` keyword to specify a"
    ],
    [
        "Sort by age, then height if ages are equal:",
        "Sort by age, then height if ages are"
    ],
    [
        "def _argsort_dispatcher(a, axis=None, kind=None, order=None, *, stable=None):",
        "def _argsort_dispatcher(a, axis=None, kind=None, order=None, *,"
    ],
    [
        "Returns the indices that would sort an array.",
        "Returns the indices that"
    ],
    [
        "Perform an indirect sort along the given axis using the algorithm specified",
        "Perform an indirect sort along the given"
    ],
    [
        "by the `kind` keyword. It returns an array of indices of the same shape as",
        "by the `kind` keyword. It returns an array of indices of the"
    ],
    [
        "`a` that index data along the given axis in sorted order.",
        "`a` that index data along the given axis"
    ],
    [
        "axis : int or None, optional",
        "axis : int or None,"
    ],
    [
        "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional",
        "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'},"
    ],
    [
        "Sorting algorithm. The default is 'quicksort'. Note that both 'stable'",
        "Sorting algorithm. The default is 'quicksort'."
    ],
    [
        "and 'mergesort' use timsort under the covers and, in general, the",
        "and 'mergesort' use timsort under the covers and,"
    ],
    [
        "actual implementation will vary with data type. The 'mergesort' option",
        "actual implementation will vary with"
    ],
    [
        "order : str or list of str, optional",
        "order : str or list"
    ],
    [
        "When `a` is an array with fields defined, this argument specifies",
        "When `a` is an array with fields"
    ],
    [
        "which fields to compare first, second, etc.  A single field can",
        "which fields to compare first, second, etc. A single"
    ],
    [
        "be specified as a string, and not all fields need be specified,",
        "be specified as a string, and not"
    ],
    [
        "but unspecified fields will still be used, in the order in which",
        "but unspecified fields will still be used, in the"
    ],
    [
        "they come up in the dtype, to break ties.",
        "they come up in the dtype,"
    ],
    [
        "Sort stability. If ``True``, the returned array will maintain",
        "Sort stability. If ``True``, the returned array will"
    ],
    [
        "the relative order of ``a`` values which compare as equal.",
        "the relative order of ``a`` values which compare as"
    ],
    [
        "If ``False`` or ``None``, this is not guaranteed. Internally,",
        "If ``False`` or ``None``, this"
    ],
    [
        "this option selects ``kind='stable'``. Default: ``None``.",
        "this option selects ``kind='stable'``."
    ],
    [
        "Array of indices that sort `a` along the specified `axis`.",
        "Array of indices that sort `a`"
    ],
    [
        "If `a` is one-dimensional, ``a[index_array]`` yields a sorted `a`.",
        "If `a` is one-dimensional, ``a[index_array]`` yields a sorted"
    ],
    [
        "always yields the sorted `a`, irrespective of dimensionality.",
        "always yields the sorted `a`, irrespective"
    ],
    [
        "sort : Describes sorting algorithms used.",
        "sort : Describes"
    ],
    [
        "lexsort : Indirect stable sort with multiple keys.",
        "lexsort : Indirect stable"
    ],
    [
        "take_along_axis : Apply ``index_array`` from argsort",
        "take_along_axis : Apply ``index_array``"
    ],
    [
        "to an array as if by calling sort.",
        "to an array as if by calling"
    ],
    [
        "See `sort` for notes on the different sorting algorithms.",
        "See `sort` for notes on the different sorting"
    ],
    [
        "nan values. The enhanced sort order is documented in `sort`.",
        "nan values. The enhanced sort order is"
    ],
    [
        "Indices of the sorted elements of a N-dimensional array:",
        "Indices of the sorted elements"
    ],
    [
        ">>> ind = np.unravel_index(np.argsort(x, axis=None), x.shape)",
        ">>> ind = np.unravel_index(np.argsort(x, axis=None),"
    ],
    [
        "a, 'argsort', axis=axis, kind=kind, order=order, stable=stable",
        "a, 'argsort', axis=axis, kind=kind,"
    ],
    [
        "def _argmax_dispatcher(a, axis=None, out=None, *, keepdims=np._NoValue):",
        "def _argmax_dispatcher(a, axis=None,"
    ],
    [
        "def argmax(a, axis=None, out=None, *, keepdims=np._NoValue):",
        "def argmax(a, axis=None, out=None, *,"
    ],
    [
        "Returns the indices of the maximum values along an axis.",
        "Returns the indices of the"
    ],
    [
        "By default, the index is into the flattened array, otherwise",
        "By default, the index is into the"
    ],
    [
        "If provided, the result will be inserted into this array. It should",
        "If provided, the result will be inserted into this array. It"
    ],
    [
        "be of the appropriate shape and dtype.",
        "be of the appropriate shape and"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With this"
    ],
    [
        "the result will broadcast correctly against the array.",
        "the result will broadcast correctly"
    ],
    [
        "Array of indices into the array. It has the same shape as ``a.shape``",
        "Array of indices into the array. It has the same shape"
    ],
    [
        "with the dimension along `axis` removed. If `keepdims` is set to True,",
        "with the dimension along `axis` removed. If `keepdims` is"
    ],
    [
        "amax : The maximum value along a given axis.",
        "amax : The maximum value"
    ],
    [
        "unravel_index : Convert a flat index into an index tuple.",
        "unravel_index : Convert a flat index"
    ],
    [
        "from argmax to an array as if by calling max.",
        "from argmax to an array as if"
    ],
    [
        "In case of multiple occurrences of the maximum values, the indices",
        "In case of multiple occurrences of the maximum"
    ],
    [
        "corresponding to the first occurrence are returned.",
        "corresponding to the first occurrence are"
    ],
    [
        "Indexes of the maximal elements of a N-dimensional array:",
        "Indexes of the maximal elements"
    ],
    [
        ">>> ind = np.unravel_index(np.argmax(a, axis=None), a.shape)",
        ">>> ind = np.unravel_index(np.argmax(a,"
    ],
    [
        "kwds = {'keepdims': keepdims} if keepdims is not np._NoValue else {}",
        "kwds = {'keepdims': keepdims} if keepdims is not np._NoValue"
    ],
    [
        "return _wrapfunc(a, 'argmax', axis=axis, out=out, **kwds)",
        "return _wrapfunc(a, 'argmax', axis=axis, out=out,"
    ],
    [
        "def _argmin_dispatcher(a, axis=None, out=None, *, keepdims=np._NoValue):",
        "def _argmin_dispatcher(a, axis=None,"
    ],
    [
        "def argmin(a, axis=None, out=None, *, keepdims=np._NoValue):",
        "def argmin(a, axis=None,"
    ],
    [
        "Returns the indices of the minimum values along an axis.",
        "Returns the indices of the minimum"
    ],
    [
        "By default, the index is into the flattened array, otherwise",
        "By default, the index is"
    ],
    [
        "If provided, the result will be inserted into this array. It should",
        "If provided, the result will be inserted into this array."
    ],
    [
        "be of the appropriate shape and dtype.",
        "be of the appropriate shape"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one."
    ],
    [
        "the result will broadcast correctly against the array.",
        "the result will broadcast correctly against"
    ],
    [
        "Array of indices into the array. It has the same shape as `a.shape`",
        "Array of indices into the array. It has the"
    ],
    [
        "with the dimension along `axis` removed. If `keepdims` is set to True,",
        "with the dimension along `axis` removed."
    ],
    [
        "amin : The minimum value along a given axis.",
        "amin : The minimum value along a given"
    ],
    [
        "unravel_index : Convert a flat index into an index tuple.",
        "unravel_index : Convert a flat index"
    ],
    [
        "from argmin to an array as if by calling min.",
        "from argmin to an array as if"
    ],
    [
        "In case of multiple occurrences of the minimum values, the indices",
        "In case of multiple occurrences of the minimum values, the"
    ],
    [
        "corresponding to the first occurrence are returned.",
        "corresponding to the first occurrence are"
    ],
    [
        "Indices of the minimum elements of a N-dimensional array:",
        "Indices of the minimum elements of a N-dimensional"
    ],
    [
        ">>> ind = np.unravel_index(np.argmin(a, axis=None), a.shape)",
        ">>> ind ="
    ],
    [
        "kwds = {'keepdims': keepdims} if keepdims is not np._NoValue else {}",
        "kwds = {'keepdims': keepdims} if keepdims is not"
    ],
    [
        "return _wrapfunc(a, 'argmin', axis=axis, out=out, **kwds)",
        "return _wrapfunc(a, 'argmin', axis=axis, out=out,"
    ],
    [
        "Find indices where elements should be inserted to maintain order.",
        "Find indices where elements should be"
    ],
    [
        "Find the indices into a sorted array `a` such that, if the",
        "Find the indices into a sorted array `a` such that,"
    ],
    [
        "corresponding elements in `v` were inserted before the indices, the",
        "corresponding elements in `v` were inserted before"
    ],
    [
        "order of `a` would be preserved.",
        "order of `a` would"
    ],
    [
        "Input array. If `sorter` is None, then it must be sorted in",
        "Input array. If `sorter` is None, then it must"
    ],
    [
        "ascending order, otherwise `sorter` must be an array of indices",
        "ascending order, otherwise `sorter` must be an"
    ],
    [
        "If 'left', the index of the first suitable location found is given.",
        "If 'left', the index of the first suitable location found"
    ],
    [
        "If 'right', return the last such index.  If there is no suitable",
        "If 'right', return the last such index. If there is no"
    ],
    [
        "Optional array of integer indices that sort array a into ascending",
        "Optional array of integer indices that sort array a"
    ],
    [
        "order. They are typically the result of argsort.",
        "order. They are typically the result of"
    ],
    [
        "indices : int or array of ints",
        "indices : int or array of"
    ],
    [
        "Array of insertion points with the same shape as `v`,",
        "Array of insertion points with the same"
    ],
    [
        "or an integer if `v` is a scalar.",
        "or an integer if `v` is a"
    ],
    [
        "sort : Return a sorted copy of an array.",
        "sort : Return a sorted copy of an"
    ],
    [
        "Binary search is used to find the required insertion points.",
        "Binary search is used to find"
    ],
    [
        "`nan` values. The enhanced sort order is documented in `sort`.",
        "`nan` values. The enhanced sort order is"
    ],
    [
        "This function uses the same algorithm as the builtin python",
        "This function uses the same algorithm as the"
    ],
    [
        "(``side='right'``) functions, which is also vectorized",
        "(``side='right'``) functions, which"
    ],
    [
        "When `sorter` is used, the returned indices refer to the sorted",
        "When `sorter` is used, the returned indices refer"
    ],
    [
        "array of `a` and not `a` itself:",
        "array of `a` and not"
    ],
    [
        "return _wrapfunc(a, 'searchsorted', v, side=side, sorter=sorter)",
        "return _wrapfunc(a, 'searchsorted',"
    ],
    [
        "Return a new array with the specified shape.",
        "Return a new array with the specified"
    ],
    [
        "If the new array is larger than the original array, then the new",
        "If the new array is larger than the original array, then the"
    ],
    [
        "array is filled with repeated copies of `a`.  Note that this behavior",
        "array is filled with repeated copies of `a`. Note that"
    ],
    [
        "is different from a.resize(new_shape) which fills with zeros instead",
        "is different from a.resize(new_shape) which fills with"
    ],
    [
        "new_shape : int or tuple of int",
        "new_shape : int or tuple of"
    ],
    [
        "The new array is formed from the data in the old array, repeated",
        "The new array is formed from the data in the"
    ],
    [
        "if necessary to fill out the required number of elements.  The",
        "if necessary to fill out the"
    ],
    [
        "data are repeated iterating over the array in C-order.",
        "data are repeated iterating over"
    ],
    [
        "numpy.reshape : Reshape an array without changing the total size.",
        "numpy.reshape : Reshape an array without changing"
    ],
    [
        "numpy.pad : Enlarge and pad an array.",
        "numpy.pad : Enlarge and"
    ],
    [
        "numpy.repeat : Repeat elements of an array.",
        "numpy.repeat : Repeat elements"
    ],
    [
        "ndarray.resize : resize an array in-place.",
        "ndarray.resize : resize"
    ],
    [
        "When the total size of the array does not change `~numpy.reshape` should",
        "When the total size of the array does not change"
    ],
    [
        "be used.  In most other cases either indexing (to reduce the size)",
        "be used. In most other cases either indexing (to reduce"
    ],
    [
        "or padding (to increase the size) may be a more appropriate solution.",
        "or padding (to increase the size) may be"
    ],
    [
        "Warning: This functionality does **not** consider axes separately,",
        "Warning: This functionality does **not** consider axes"
    ],
    [
        "i.e. it does not apply interpolation/extrapolation.",
        "i.e. it does"
    ],
    [
        "It fills the return array with the required number of elements, iterating",
        "It fills the return array with the required number"
    ],
    [
        "over `a` in C-order, disregarding axes (and cycling back from the start if",
        "over `a` in C-order, disregarding axes (and cycling back from"
    ],
    [
        "the new shape is larger).  This functionality is therefore not suitable to",
        "the new shape is larger). This functionality is therefore not suitable"
    ],
    [
        "resize images, or data where each axis represents a separate and distinct",
        "resize images, or data where each"
    ],
    [
        "'all elements of `new_shape` must be non-negative'",
        "'all elements of `new_shape` must"
    ],
    [
        "Remove axes of length one from `a`.",
        "Remove axes of length one from"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or"
    ],
    [
        "Selects a subset of the entries of length one in the",
        "Selects a subset of the entries"
    ],
    [
        "shape. If an axis is selected with shape entry greater than",
        "shape. If an axis is selected"
    ],
    [
        "The input array, but with all or a subset of the",
        "The input array, but with all or a subset of"
    ],
    [
        "or a view into `a`. Note that if all axes are squeezed,",
        "or a view into `a`. Note that if"
    ],
    [
        "expand_dims : The inverse operation, adding entries of length one",
        "expand_dims : The inverse operation, adding entries of"
    ],
    [
        "reshape : Insert, remove, and combine dimensions, and resize existing ones",
        "reshape : Insert, remove, and combine dimensions, and resize"
    ],
    [
        "ValueError: cannot select an axis to squeeze out which has size",
        "ValueError: cannot select an axis to squeeze"
    ],
    [
        "i.e., the collection of elements of the form ``a[i, i+offset]``.  If",
        "i.e., the collection of elements of the form ``a[i, i+offset]``."
    ],
    [
        "returned.  The shape of the resulting array can be determined by",
        "returned. The shape of the resulting array"
    ],
    [
        "to the size of the resulting diagonals.",
        "to the size of the resulting"
    ],
    [
        "independent array containing a copy of the values in the diagonal.",
        "independent array containing a copy of the values"
    ],
    [
        "but depending on this fact is deprecated. Writing to the resulting",
        "but depending on this fact is deprecated. Writing to"
    ],
    [
        "array continues to work as it used to, but a FutureWarning is issued.",
        "array continues to work as it used to, but a"
    ],
    [
        "Attempting to write to the resulting array will produce an error.",
        "Attempting to write to the resulting array will produce"
    ],
    [
        "In some future release, it will return a read/write view and writing to",
        "In some future release, it will return a read/write view and"
    ],
    [
        "the returned array will alter your original array.  The returned array",
        "the returned array will alter your original array. The"
    ],
    [
        "will have the same type as the input array.",
        "will have the same type as the input"
    ],
    [
        "If you don't write to the array returned by this function, then you can",
        "If you don't write to the array returned by this function, then"
    ],
    [
        "just ignore all of the above.",
        "just ignore all"
    ],
    [
        "If you depend on the current behavior, then we suggest copying the",
        "If you depend on the current"
    ],
    [
        "returned array explicitly, i.e., use ``np.diagonal(a).copy()`` instead",
        "returned array explicitly, i.e., use"
    ],
    [
        "of just ``np.diagonal(a)``. This will work with both past and future",
        "of just ``np.diagonal(a)``. This will work with"
    ],
    [
        "Array from which the diagonals are taken.",
        "Array from which the"
    ],
    [
        "Offset of the diagonal from the main diagonal.  Can be positive or",
        "Offset of the diagonal from the main diagonal."
    ],
    [
        "same type as `a` is returned unless `a` is a `matrix`, in which case",
        "same type as `a` is returned unless `a`"
    ],
    [
        "are removed, and a new axis inserted at the end corresponding to the",
        "are removed, and a new axis inserted at the"
    ],
    [
        "The sub-arrays whose main diagonals we just obtained; note that each",
        "The sub-arrays whose main diagonals we"
    ],
    [
        "corresponds to fixing the right-most (column) axis, and that the",
        "corresponds to fixing the right-most"
    ],
    [
        "The anti-diagonal can be obtained by reversing the order of elements",
        "The anti-diagonal can be obtained by reversing"
    ],
    [
        "Note that the order in which the diagonal is retrieved varies depending",
        "Note that the order in which the diagonal is"
    ],
    [
        "Return the sum along diagonals of the array.",
        "Return the sum along diagonals of"
    ],
    [
        "is returned, i.e., the sum of elements ``a[i,i+offset]`` for all i.",
        "is returned, i.e., the sum of elements ``a[i,i+offset]`` for all"
    ],
    [
        "Input array, from which the diagonals are taken.",
        "Input array, from which the diagonals"
    ],
    [
        "Offset of the diagonal from the main diagonal. Can be both positive",
        "Offset of the diagonal from the main"
    ],
    [
        "from which the diagonals should be taken. Defaults are the first two",
        "from which the diagonals should be taken. Defaults are"
    ],
    [
        "Determines the data-type of the returned array and of the accumulator",
        "Determines the data-type of the returned"
    ],
    [
        "where the elements are summed. If dtype has the value None and `a` is",
        "where the elements are summed. If dtype"
    ],
    [
        "of integer type of precision less than the default integer",
        "of integer type of precision less than"
    ],
    [
        "precision, then the default integer precision is used. Otherwise,",
        "precision, then the default integer precision is used."
    ],
    [
        "the precision is the same as that of `a`.",
        "the precision is the same as that"
    ],
    [
        "Array into which the output is placed. Its type is preserved and",
        "Array into which the output is placed."
    ],
    [
        "it must be of the right shape to hold the output.",
        "it must be of the right"
    ],
    [
        "larger dimensions, then an array of sums along diagonals is returned.",
        "larger dimensions, then an array of sums along diagonals is"
    ],
    [
        "array. (for example, a masked array will be returned for a masked array",
        "array. (for example, a masked array will be returned"
    ],
    [
        "Input array.  The elements in `a` are read in the order specified by",
        "Input array. The elements in `a` are read"
    ],
    [
        "order : {'C','F', 'A', 'K'}, optional",
        "order : {'C','F', 'A', 'K'},"
    ],
    [
        "The elements of `a` are read using this index order. 'C' means",
        "The elements of `a` are read using this index order. 'C'"
    ],
    [
        "to index the elements in row-major, C-style order,",
        "to index the elements in row-major, C-style"
    ],
    [
        "with the last axis index changing fastest, back to the first",
        "with the last axis index changing"
    ],
    [
        "axis index changing slowest.  'F' means to index the elements",
        "axis index changing slowest. 'F' means to index"
    ],
    [
        "in column-major, Fortran-style order, with the",
        "in column-major, Fortran-style order, with"
    ],
    [
        "first index changing fastest, and the last index changing",
        "first index changing fastest, and"
    ],
    [
        "slowest. Note that the 'C' and 'F' options take no account of",
        "slowest. Note that the 'C' and 'F'"
    ],
    [
        "the memory layout of the underlying array, and only refer to",
        "the memory layout of the underlying array, and"
    ],
    [
        "the order of axis indexing.  'A' means to read the elements in",
        "the order of axis indexing. 'A' means to read the"
    ],
    [
        "Fortran-like index order if `a` is Fortran *contiguous* in",
        "Fortran-like index order if `a` is Fortran"
    ],
    [
        "memory, C-like order otherwise.  'K' means to read the",
        "memory, C-like order otherwise. 'K' means to"
    ],
    [
        "elements in the order they occur in memory, except for",
        "elements in the order they occur in memory,"
    ],
    [
        "reversing the data when strides are negative.  By default, 'C'",
        "reversing the data when strides are"
    ],
    [
        "Note that matrices are special cased for backward compatibility,",
        "Note that matrices are special"
    ],
    [
        "ndarray.reshape : Change the shape of an array without changing its data.",
        "ndarray.reshape : Change the shape of an array"
    ],
    [
        "In row-major, C-style order, in two dimensions, the row index",
        "In row-major, C-style order, in two"
    ],
    [
        "varies the slowest, and the column index the quickest.  This can",
        "varies the slowest, and the column index the quickest. This"
    ],
    [
        "be generalized to multiple dimensions, where row-major order",
        "be generalized to multiple dimensions, where row-major"
    ],
    [
        "implies that the index along the first axis varies slowest, and",
        "implies that the index along the first axis varies slowest,"
    ],
    [
        "the index along the last quickest.  The opposite holds for",
        "the index along the last"
    ],
    [
        "may be preferable. However, ``ravel`` supports ``K`` in the optional",
        "may be preferable. However, ``ravel`` supports ``K``"
    ],
    [
        "``order`` argument while ``reshape`` does not.",
        "``order`` argument while ``reshape``"
    ],
    [
        "When ``order`` is 'A', it will preserve the array's 'C' or 'F' ordering:",
        "When ``order`` is 'A', it will preserve the"
    ],
    [
        "When ``order`` is 'K', it will preserve orderings that are neither 'C'",
        "When ``order`` is 'K', it will preserve orderings that"
    ],
    [
        "nor 'F', but won't reverse axes:",
        "nor 'F', but won't reverse"
    ],
    [
        "Return the indices of the elements that are non-zero.",
        "Return the indices of the elements"
    ],
    [
        "Returns a tuple of arrays, one for each dimension of `a`,",
        "Returns a tuple of arrays, one"
    ],
    [
        "containing the indices of the non-zero elements in that",
        "containing the indices of the"
    ],
    [
        "dimension. The values in `a` are always tested and returned in",
        "dimension. The values in `a` are always tested and returned"
    ],
    [
        "To group the indices by element, rather than dimension, use `argwhere`,",
        "To group the indices by element, rather than"
    ],
    [
        "which returns a row for each non-zero element.",
        "which returns a row for each non-zero"
    ],
    [
        "When called on a zero-d array or scalar, ``nonzero(a)`` is treated",
        "When called on a zero-d array or scalar, ``nonzero(a)`` is"
    ],
    [
        "Indices of elements that are non-zero.",
        "Indices of elements that"
    ],
    [
        "Return indices that are non-zero in the flattened version of the input",
        "Return indices that are non-zero in"
    ],
    [
        "Counts the number of non-zero elements in the input array.",
        "Counts the number of non-zero elements in the"
    ],
    [
        "While the nonzero values can be obtained with ``a[nonzero(a)]``, it is",
        "While the nonzero values can be obtained with ``a[nonzero(a)]``, it"
    ],
    [
        "A common use for ``nonzero`` is to find the indices of an array, where",
        "A common use for ``nonzero`` is to find"
    ],
    [
        "yields the indices of the `a` where the condition is true.",
        "yields the indices of the `a` where the"
    ],
    [
        "Using this result to index `a` is equivalent to using the mask directly:",
        "Using this result to index `a` is equivalent to using the mask"
    ],
    [
        "``nonzero`` can also be called as a method of the array.",
        "``nonzero`` can also be called as a"
    ],
    [
        "Return the shape of an array.",
        "Return the shape of an"
    ],
    [
        "The elements of the shape tuple give the lengths of the",
        "The elements of the shape tuple give"
    ],
    [
        "Return selected slices of an array along given axis.",
        "Return selected slices of an"
    ],
    [
        "When working along a given axis, a slice along that axis is returned in",
        "When working along a given axis, a slice along that axis is"
    ],
    [
        "`output` for each index where `condition` evaluates to True. When",
        "`output` for each index where `condition` evaluates to"
    ],
    [
        "Array that selects which entries to return. If len(condition)",
        "Array that selects which entries"
    ],
    [
        "is less than the size of `a` along the given axis, then output is",
        "is less than the size of `a` along the"
    ],
    [
        "truncated to the length of the condition array.",
        "truncated to the length of the condition"
    ],
    [
        "Array from which to extract a part.",
        "Array from which to extract"
    ],
    [
        "Axis along which to take slices. If None (default), work on the",
        "Axis along which to take slices."
    ],
    [
        "Output array.  Its type is preserved and it must be of the right",
        "Output array. Its type is preserved and it must be of"
    ],
    [
        "A copy of `a` without the slices along axis for which `condition`",
        "A copy of `a` without the slices"
    ],
    [
        "ndarray.compress : Equivalent method in ndarray",
        "ndarray.compress : Equivalent"
    ],
    [
        "Working on the flattened array does not return slices along an axis but",
        "Working on the flattened array does not return"
    ],
    [
        "return _wrapfunc(a, 'compress', condition, axis=axis, out=out)",
        "return _wrapfunc(a, 'compress', condition, axis=axis,"
    ],
    [
        "def _clip_dispatcher(a, a_min=None, a_max=None, out=None, *, min=None,",
        "def _clip_dispatcher(a, a_min=None, a_max=None, out=None,"
    ],
    [
        "return (a, a_min, a_max, out, min, max)",
        "return (a, a_min, a_max, out, min,"
    ],
    [
        "def clip(a, a_min=np._NoValue, a_max=np._NoValue, out=None, *,",
        "def clip(a, a_min=np._NoValue,"
    ],
    [
        "Clip (limit) the values in an array.",
        "Clip (limit) the values in an"
    ],
    [
        "Given an interval, values outside the interval are clipped to",
        "Given an interval, values outside"
    ],
    [
        "Equivalent to but faster than ``np.minimum(a_max, np.maximum(a, a_min))``.",
        "Equivalent to but faster than ``np.minimum(a_max,"
    ],
    [
        "No check is performed to ensure ``a_min < a_max``.",
        "No check is performed to ensure ``a_min <"
    ],
    [
        "a_min, a_max : array_like or None",
        "a_min, a_max :"
    ],
    [
        "Minimum and maximum value. If ``None``, clipping is not performed on",
        "Minimum and maximum value. If ``None``, clipping is not"
    ],
    [
        "the corresponding edge. If both ``a_min`` and ``a_max`` are ``None``,",
        "the corresponding edge. If both"
    ],
    [
        "the elements of the returned array stay the same. Both are broadcasted",
        "the elements of the returned array stay the same."
    ],
    [
        "The results will be placed in this array. It may be the input",
        "The results will be placed in this array. It may be"
    ],
    [
        "array for in-place clipping.  `out` must be of the right shape",
        "array for in-place clipping. `out` must be of the right"
    ],
    [
        "to hold the output.  Its type is preserved.",
        "to hold the output. Its type"
    ],
    [
        "min, max : array_like or None",
        "min, max : array_like"
    ],
    [
        "Array API compatible alternatives for ``a_min`` and ``a_max``",
        "Array API compatible alternatives for ``a_min`` and"
    ],
    [
        "arguments. Either ``a_min`` and ``a_max`` or ``min`` and ``max``",
        "arguments. Either ``a_min`` and ``a_max`` or"
    ],
    [
        "can be passed at the same time. Default: ``None``.",
        "can be passed at the"
    ],
    [
        "For other keyword-only arguments, see the",
        "For other keyword-only arguments,"
    ],
    [
        "An array with the elements of `a`, but where values",
        "An array with the elements of"
    ],
    [
        "< `a_min` are replaced with `a_min`, and those > `a_max`",
        "< `a_min` are replaced with"
    ],
    [
        "When `a_min` is greater than `a_max`, `clip` returns an",
        "When `a_min` is greater than `a_max`, `clip` returns"
    ],
    [
        "array in which all values are equal to `a_max`,",
        "array in which all values"
    ],
    [
        "as shown in the second example.",
        "as shown in the"
    ],
    [
        "if a_min is np._NoValue and a_max is np._NoValue:",
        "if a_min is np._NoValue"
    ],
    [
        "a_min = None if min is np._NoValue else min",
        "a_min = None if min is np._NoValue"
    ],
    [
        "a_max = None if max is np._NoValue else max",
        "a_max = None if max is"
    ],
    [
        "elif min is not np._NoValue or max is not np._NoValue:",
        "elif min is not np._NoValue or max is"
    ],
    [
        "raise ValueError(\"Passing `min` or `max` keyword argument when \"",
        "raise ValueError(\"Passing `min` or `max` keyword argument"
    ],
    [
        "\"`a_min` and `a_max` are provided is forbidden.\")",
        "\"`a_min` and `a_max` are"
    ],
    [
        "return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)",
        "return _wrapfunc(a, 'clip', a_min, a_max,"
    ],
    [
        "def _sum_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,",
        "def _sum_dispatcher(a, axis=None, dtype=None, out=None,"
    ],
    [
        "def sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,",
        "def sum(a, axis=None, dtype=None,"
    ],
    [
        "Sum of array elements over a given axis.",
        "Sum of array elements over a given"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int"
    ],
    [
        "Axis or axes along which a sum is performed.  The default,",
        "Axis or axes along which a sum is performed. The"
    ],
    [
        "axis=None, will sum all of the elements of the input array.  If",
        "axis=None, will sum all of the"
    ],
    [
        "axis is negative it counts from the last to the first axis. If",
        "axis is negative it counts from the last to the first axis."
    ],
    [
        "axis is a tuple of ints, a sum is performed on all of the axes",
        "axis is a tuple of ints, a sum is performed on all of"
    ],
    [
        "specified in the tuple instead of a single axis or all the axes as",
        "specified in the tuple instead of a single axis or"
    ],
    [
        "The type of the returned array and of the accumulator in which the",
        "The type of the returned array and of the accumulator in"
    ],
    [
        "elements are summed.  The dtype of `a` is used by default unless `a`",
        "elements are summed. The dtype of `a`"
    ],
    [
        "has an integer dtype of less precision than the default platform",
        "has an integer dtype of less"
    ],
    [
        "integer.  In that case, if `a` is signed then the platform integer",
        "integer. In that case, if `a` is"
    ],
    [
        "is used while if `a` is unsigned then an unsigned integer of the",
        "is used while if `a` is unsigned then an unsigned"
    ],
    [
        "same precision as the platform integer is used.",
        "same precision as the platform integer"
    ],
    [
        "Alternative output array in which to place the result. It must have",
        "Alternative output array in which to place the result. It"
    ],
    [
        "the same shape as the expected output, but the type of the output",
        "the same shape as the expected output,"
    ],
    [
        "values will be cast if necessary.",
        "values will be cast if"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against the"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed, then"
    ],
    [
        "passed through to the `sum` method of sub-classes of",
        "passed through to the `sum` method"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value"
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not"
    ],
    [
        "Starting value for the sum. See `~numpy.ufunc.reduce` for details.",
        "Starting value for the sum."
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like"
    ],
    [
        "Elements to include in the sum. See `~numpy.ufunc.reduce` for details.",
        "Elements to include in the sum. See `~numpy.ufunc.reduce` for"
    ],
    [
        "An array with the same shape as `a`, with the specified",
        "An array with the same shape as `a`,"
    ],
    [
        "is returned.  If an output array is specified, a reference to",
        "is returned. If an output array is specified, a"
    ],
    [
        "cumsum : Cumulative sum of array elements.",
        "cumsum : Cumulative sum of array"
    ],
    [
        "trapezoid : Integration of array values using composite trapezoidal rule.",
        "trapezoid : Integration of array values using composite trapezoidal"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is",
        "Arithmetic is modular when using integer types,"
    ],
    [
        "For floating point numbers the numerical precision of sum (and",
        "For floating point numbers the numerical precision of sum"
    ],
    [
        "``np.add.reduce``) is in general limited by directly adding each number",
        "``np.add.reduce``) is in general limited by directly adding each"
    ],
    [
        "individually to the result causing rounding errors in every step.",
        "individually to the result causing rounding"
    ],
    [
        "However, often numpy will use a  numerically better approach (partial",
        "However, often numpy will use a numerically"
    ],
    [
        "pairwise summation) leading to improved precision in many use-cases.",
        "pairwise summation) leading to improved precision in"
    ],
    [
        "This improved precision is always provided when no ``axis`` is given.",
        "This improved precision is always provided when no ``axis`` is"
    ],
    [
        "When ``axis`` is given, it will depend on which axis is summed.",
        "When ``axis`` is given, it will depend on which axis"
    ],
    [
        "Technically, to provide the best speed possible, the improved precision",
        "Technically, to provide the best speed possible,"
    ],
    [
        "is only used when the summation is along the fast axis in memory.",
        "is only used when the summation is"
    ],
    [
        "Note that the exact precision may vary depending on other parameters.",
        "Note that the exact precision may vary"
    ],
    [
        "In contrast to NumPy, Python's ``math.fsum`` function uses a slower but",
        "In contrast to NumPy, Python's ``math.fsum`` function"
    ],
    [
        "Especially when summing a large number of lower precision floating point",
        "Especially when summing a large number of lower precision floating"
    ],
    [
        "If the accumulator is too small, overflow occurs:",
        "If the accumulator is too small,"
    ],
    [
        "You can also start the sum with a value other than zero:",
        "You can also start the sum with"
    ],
    [
        "\"Calling np.sum(generator) is deprecated, and in the future will \"",
        "\"Calling np.sum(generator) is deprecated, and in the future"
    ],
    [
        "\"give a different result. Use np.sum(np.fromiter(generator)) or \"",
        "\"give a different result. Use"
    ],
    [
        "a, np.add, 'sum', axis, dtype, out,",
        "a, np.add, 'sum',"
    ],
    [
        "def _any_dispatcher(a, axis=None, out=None, keepdims=None, *,",
        "def _any_dispatcher(a, axis=None, out=None, keepdims=None,"
    ],
    [
        "def any(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):",
        "def any(a, axis=None, out=None,"
    ],
    [
        "Test whether any array element along a given axis evaluates to True.",
        "Test whether any array element along a given axis"
    ],
    [
        "Returns single boolean if `axis` is ``None``",
        "Returns single boolean if `axis` is"
    ],
    [
        "Input array or object that can be converted to an array.",
        "Input array or object that can be converted to an"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int"
    ],
    [
        "Axis or axes along which a logical OR reduction is performed.",
        "Axis or axes along which a logical OR reduction"
    ],
    [
        "The default (``axis=None``) is to perform a logical OR over all",
        "The default (``axis=None``) is to perform"
    ],
    [
        "the dimensions of the input array. `axis` may be negative, in",
        "the dimensions of the input array."
    ],
    [
        "which case it counts from the last to the first axis. If this",
        "which case it counts from the last to the first axis. If"
    ],
    [
        "is a tuple of ints, a reduction is performed on multiple",
        "is a tuple of ints, a reduction"
    ],
    [
        "axes, instead of a single axis or all the axes as before.",
        "axes, instead of a single axis or"
    ],
    [
        "Alternate output array in which to place the result.  It must have",
        "Alternate output array in which to place"
    ],
    [
        "the same shape as the expected output and its type is preserved",
        "the same shape as the expected output and its type is"
    ],
    [
        "(e.g., if it is of type float, then it will remain so, returning",
        "(e.g., if it is of type float, then it will"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against the"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed, then `keepdims`"
    ],
    [
        "passed through to the `any` method of sub-classes of",
        "passed through to the `any`"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value will be."
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like"
    ],
    [
        "Elements to include in checking for any `True` values.",
        "Elements to include in checking for"
    ],
    [
        "A new boolean or `ndarray` is returned unless `out` is specified,",
        "A new boolean or `ndarray` is"
    ],
    [
        "in which case a reference to `out` is returned.",
        "in which case a reference to `out` is"
    ],
    [
        "all : Test whether all elements along a given axis evaluate to True.",
        "all : Test whether all elements along a given axis evaluate to"
    ],
    [
        "Not a Number (NaN), positive infinity and negative infinity evaluate",
        "Not a Number (NaN), positive infinity"
    ],
    [
        "to `True` because these are not equal to zero.",
        "to `True` because these are not equal to"
    ],
    [
        "This behavior is still available via ``np.logical_or.reduce``.",
        "This behavior is still available via"
    ],
    [
        ">>> np.any([[True, False], [False, False]], where=[[False], [True]])",
        ">>> np.any([[True, False], [False,"
    ],
    [
        "return _wrapreduction_any_all(a, np.logical_or, 'any', axis, out,",
        "return _wrapreduction_any_all(a, np.logical_or, 'any', axis,"
    ],
    [
        "def _all_dispatcher(a, axis=None, out=None, keepdims=None, *,",
        "def _all_dispatcher(a, axis=None, out=None,"
    ],
    [
        "def all(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):",
        "def all(a, axis=None, out=None,"
    ],
    [
        "Test whether all array elements along a given axis evaluate to True.",
        "Test whether all array elements along a given axis evaluate"
    ],
    [
        "Input array or object that can be converted to an array.",
        "Input array or object that can be converted to"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple of ints,"
    ],
    [
        "Axis or axes along which a logical AND reduction is performed.",
        "Axis or axes along which a"
    ],
    [
        "The default (``axis=None``) is to perform a logical AND over all",
        "The default (``axis=None``) is to perform a logical"
    ],
    [
        "the dimensions of the input array. `axis` may be negative, in",
        "the dimensions of the input array. `axis` may be"
    ],
    [
        "which case it counts from the last to the first axis. If this",
        "which case it counts from the last to the first axis."
    ],
    [
        "is a tuple of ints, a reduction is performed on multiple",
        "is a tuple of ints, a"
    ],
    [
        "axes, instead of a single axis or all the axes as before.",
        "axes, instead of a single axis or all"
    ],
    [
        "Alternate output array in which to place the result.",
        "Alternate output array in which to"
    ],
    [
        "It must have the same shape as the expected output and its",
        "It must have the same shape as the expected output and"
    ],
    [
        "type is preserved (e.g., if ``dtype(out)`` is float, the result",
        "type is preserved (e.g., if ``dtype(out)``"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against the"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed, then"
    ],
    [
        "passed through to the `all` method of sub-classes of",
        "passed through to the `all` method of sub-classes"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value"
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not implement `keepdims`"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of"
    ],
    [
        "Elements to include in checking for all `True` values.",
        "Elements to include in checking"
    ],
    [
        "A new boolean or array is returned unless `out` is specified,",
        "A new boolean or array is"
    ],
    [
        "in which case a reference to `out` is returned.",
        "in which case a reference to `out` is"
    ],
    [
        "any : Test whether any element along a given axis evaluates to True.",
        "any : Test whether any element along a given axis evaluates"
    ],
    [
        "Not a Number (NaN), positive infinity and negative infinity",
        "Not a Number (NaN), positive infinity"
    ],
    [
        "evaluate to `True` because these are not equal to zero.",
        "evaluate to `True` because these are not"
    ],
    [
        "This behavior is still available via ``np.logical_and.reduce``.",
        "This behavior is still available via"
    ],
    [
        ">>> np.all([[True, True], [False, True]], where=[[True], [False]])",
        ">>> np.all([[True, True], [False, True]],"
    ],
    [
        "return _wrapreduction_any_all(a, np.logical_and, 'all', axis, out,",
        "return _wrapreduction_any_all(a, np.logical_and, 'all',"
    ],
    [
        "def _cumulative_func(x, func, axis, dtype, out, include_initial):",
        "def _cumulative_func(x, func, axis, dtype, out,"
    ],
    [
        "raise ValueError(\"For arrays which have more than one dimension \"",
        "raise ValueError(\"For arrays which have"
    ],
    [
        "if out is not None and include_initial:",
        "if out is not None and"
    ],
    [
        "res = func.accumulate(x, axis=axis, dtype=dtype, out=out)",
        "res = func.accumulate(x,"
    ],
    [
        "def _cumulative_prod_dispatcher(x, /, *, axis=None, dtype=None, out=None,",
        "def _cumulative_prod_dispatcher(x, /, *, axis=None,"
    ],
    [
        "def cumulative_prod(x, /, *, axis=None, dtype=None, out=None,",
        "def cumulative_prod(x, /, *, axis=None,"
    ],
    [
        "Return the cumulative product of elements along a given axis.",
        "Return the cumulative product of elements along"
    ],
    [
        "This function is an Array API compatible alternative to `numpy.cumprod`.",
        "This function is an Array API compatible alternative to"
    ],
    [
        "Axis along which the cumulative product is computed. The default",
        "Axis along which the cumulative"
    ],
    [
        "(None) is only allowed for one-dimensional arrays. For arrays",
        "(None) is only allowed for one-dimensional"
    ],
    [
        "with more than one dimension ``axis`` is required.",
        "with more than one"
    ],
    [
        "Type of the returned array, as well as of the accumulator in which",
        "Type of the returned array, as well as of the accumulator"
    ],
    [
        "the elements are multiplied.  If ``dtype`` is not specified, it",
        "the elements are multiplied. If ``dtype``"
    ],
    [
        "defaults to the dtype of ``x``, unless ``x`` has an integer dtype",
        "defaults to the dtype of ``x``, unless ``x`` has"
    ],
    [
        "with a precision less than that of the default platform integer.",
        "with a precision less than that of the"
    ],
    [
        "In that case, the default platform integer is used instead.",
        "In that case, the default platform integer is"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the result."
    ],
    [
        "have the same shape and buffer length as the expected output",
        "have the same shape and buffer length as the expected"
    ],
    [
        "but the type of the resulting values will be cast if necessary.",
        "but the type of the resulting values will be"
    ],
    [
        "Boolean indicating whether to include the initial value (ones) as",
        "Boolean indicating whether to include the initial value (ones)"
    ],
    [
        "the first value in the output. With ``include_initial=True``",
        "the first value in the output."
    ],
    [
        "the shape of the output is different than the shape of the input.",
        "the shape of the output is different than the shape"
    ],
    [
        "A new array holding the result is returned unless ``out`` is",
        "A new array holding the result is"
    ],
    [
        "specified, in which case a reference to ``out`` is returned. The",
        "specified, in which case a reference to"
    ],
    [
        "result has the same shape as ``x`` if ``include_initial=False``.",
        "result has the same shape as"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is",
        "Arithmetic is modular when using integer"
    ],
    [
        "The cumulative product for each column (i.e., over the rows) of ``b``:",
        "The cumulative product for each column"
    ],
    [
        "The cumulative product for each row (i.e. over the columns) of ``b``:",
        "The cumulative product for each row (i.e."
    ],
    [
        "return _cumulative_func(x, um.multiply, axis, dtype, out, include_initial)",
        "return _cumulative_func(x, um.multiply, axis, dtype,"
    ],
    [
        "def _cumulative_sum_dispatcher(x, /, *, axis=None, dtype=None, out=None,",
        "def _cumulative_sum_dispatcher(x, /, *, axis=None,"
    ],
    [
        "def cumulative_sum(x, /, *, axis=None, dtype=None, out=None,",
        "def cumulative_sum(x, /, *, axis=None,"
    ],
    [
        "Return the cumulative sum of the elements along a given axis.",
        "Return the cumulative sum of the elements along a"
    ],
    [
        "This function is an Array API compatible alternative to `numpy.cumsum`.",
        "This function is an Array API compatible"
    ],
    [
        "Axis along which the cumulative sum is computed. The default",
        "Axis along which the cumulative"
    ],
    [
        "(None) is only allowed for one-dimensional arrays. For arrays",
        "(None) is only allowed for one-dimensional arrays."
    ],
    [
        "with more than one dimension ``axis`` is required.",
        "with more than one"
    ],
    [
        "Type of the returned array and of the accumulator in which the",
        "Type of the returned array and of the accumulator in"
    ],
    [
        "elements are summed.  If ``dtype`` is not specified, it defaults",
        "elements are summed. If ``dtype`` is not"
    ],
    [
        "to the dtype of ``x``, unless ``x`` has an integer dtype with",
        "to the dtype of ``x``, unless ``x``"
    ],
    [
        "a precision less than that of the default platform integer.",
        "a precision less than that of the default"
    ],
    [
        "In that case, the default platform integer is used.",
        "In that case, the default platform integer is"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the"
    ],
    [
        "have the same shape and buffer length as the expected output",
        "have the same shape and buffer"
    ],
    [
        "but the type will be cast if necessary. See :ref:`ufuncs-output-type`",
        "but the type will be cast if necessary. See"
    ],
    [
        "Boolean indicating whether to include the initial value (zeros) as",
        "Boolean indicating whether to include the"
    ],
    [
        "the first value in the output. With ``include_initial=True``",
        "the first value in the output."
    ],
    [
        "the shape of the output is different than the shape of the input.",
        "the shape of the output is different than the shape of"
    ],
    [
        "A new array holding the result is returned unless ``out`` is",
        "A new array holding the result is returned unless"
    ],
    [
        "specified, in which case a reference to ``out`` is returned. The",
        "specified, in which case a reference to ``out``"
    ],
    [
        "result has the same shape as ``x`` if ``include_initial=False``.",
        "result has the same shape as ``x`` if"
    ],
    [
        "trapezoid : Integration of array values using composite trapezoidal rule.",
        "trapezoid : Integration of array values using composite"
    ],
    [
        "diff : Calculate the n-th discrete difference along given axis.",
        "diff : Calculate the n-th"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is",
        "Arithmetic is modular when using integer types, and no"
    ],
    [
        "floating-point values since ``sum`` may use a pairwise summation routine,",
        "floating-point values since ``sum`` may use a pairwise summation"
    ],
    [
        "reducing the roundoff-error. See `sum` for more information.",
        "reducing the roundoff-error. See `sum` for"
    ],
    [
        "return _cumulative_func(x, um.add, axis, dtype, out, include_initial)",
        "return _cumulative_func(x, um.add, axis, dtype, out,"
    ],
    [
        "Return the cumulative sum of the elements along a given axis.",
        "Return the cumulative sum of the elements along"
    ],
    [
        "Axis along which the cumulative sum is computed. The default",
        "Axis along which the cumulative sum"
    ],
    [
        "(None) is to compute the cumsum over the flattened array.",
        "(None) is to compute the cumsum"
    ],
    [
        "Type of the returned array and of the accumulator in which the",
        "Type of the returned array and"
    ],
    [
        "elements are summed.  If `dtype` is not specified, it defaults",
        "elements are summed. If `dtype`"
    ],
    [
        "to the dtype of `a`, unless `a` has an integer dtype with a",
        "to the dtype of `a`, unless `a` has an integer dtype"
    ],
    [
        "precision less than that of the default platform integer.  In",
        "precision less than that of"
    ],
    [
        "that case, the default platform integer is used.",
        "that case, the default platform integer"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the result."
    ],
    [
        "have the same shape and buffer length as the expected output",
        "have the same shape and buffer length"
    ],
    [
        "but the type will be cast if necessary. See :ref:`ufuncs-output-type`",
        "but the type will be cast if necessary. See"
    ],
    [
        "A new array holding the result is returned unless `out` is",
        "A new array holding the result is returned unless"
    ],
    [
        "specified, in which case a reference to `out` is returned. The",
        "specified, in which case a reference to `out` is returned."
    ],
    [
        "result has the same size as `a`, and the same shape as `a` if",
        "result has the same size as `a`, and the same shape as `a`"
    ],
    [
        "cumulative_sum : Array API compatible alternative for ``cumsum``.",
        "cumulative_sum : Array API compatible alternative for"
    ],
    [
        "trapezoid : Integration of array values using composite trapezoidal rule.",
        "trapezoid : Integration of array values using composite"
    ],
    [
        "diff : Calculate the n-th discrete difference along given axis.",
        "diff : Calculate the n-th discrete"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is",
        "Arithmetic is modular when using integer"
    ],
    [
        "values since ``sum`` may use a pairwise summation routine, reducing",
        "values since ``sum`` may use"
    ],
    [
        "the roundoff-error. See `sum` for more information.",
        "the roundoff-error. See `sum`"
    ],
    [
        "return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)",
        "return _wrapfunc(a, 'cumsum', axis=axis,"
    ],
    [
        "Range of values (maximum - minimum) along an axis.",
        "Range of values (maximum - minimum) along an"
    ],
    [
        "The name of the function comes from the acronym for 'peak to peak'.",
        "The name of the function comes from the acronym for"
    ],
    [
        "`ptp` preserves the data type of the array. This means the",
        "`ptp` preserves the data type of the array. This means"
    ],
    [
        "return value for an input of signed integers with n bits",
        "return value for an input of signed integers with"
    ],
    [
        "with n bits.  In that case, peak-to-peak values greater than",
        "with n bits. In that case, peak-to-peak"
    ],
    [
        "with a work-around is shown below.",
        "with a work-around is shown"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple"
    ],
    [
        "Axis along which to find the peaks.  By default, flatten the",
        "Axis along which to find the peaks. By default,"
    ],
    [
        "array.  `axis` may be negative, in",
        "array. `axis` may be negative,"
    ],
    [
        "which case it counts from the last to the first axis.",
        "which case it counts from the last"
    ],
    [
        "If this is a tuple of ints, a reduction is performed on multiple",
        "If this is a tuple of ints,"
    ],
    [
        "axes, instead of a single axis or all the axes as before.",
        "axes, instead of a single axis"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to"
    ],
    [
        "have the same shape and buffer length as the expected output,",
        "have the same shape and buffer"
    ],
    [
        "but the type of the output values will be cast if necessary.",
        "but the type of the output values"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed,"
    ],
    [
        "passed through to the `ptp` method of sub-classes of",
        "passed through to the `ptp`"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value"
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not implement `keepdims`"
    ],
    [
        "The range of a given array - `scalar` if array is one-dimensional",
        "The range of a given array"
    ],
    [
        "or a new array holding the result along the given axis",
        "or a new array holding the"
    ],
    [
        "This example shows that a negative value can be returned when",
        "This example shows that a negative value"
    ],
    [
        "the input is an array of signed integers.",
        "the input is an array of signed"
    ],
    [
        "A work-around is to use the `view()` method to view the result as",
        "A work-around is to use the `view()` method to view the"
    ],
    [
        "unsigned integers with the same bit width:",
        "unsigned integers with the same"
    ],
    [
        "def _max_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,",
        "def _max_dispatcher(a, axis=None, out=None, keepdims=None,"
    ],
    [
        "def max(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,",
        "def max(a, axis=None, out=None, keepdims=np._NoValue,"
    ],
    [
        "Return the maximum of an array or maximum along an axis.",
        "Return the maximum of an array or maximum along an"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple"
    ],
    [
        "Axis or axes along which to operate.  By default, flattened input is",
        "Axis or axes along which to operate. By default, flattened input"
    ],
    [
        "used. If this is a tuple of ints, the maximum is selected over",
        "used. If this is a tuple of ints,"
    ],
    [
        "multiple axes, instead of a single axis or all the axes as before.",
        "multiple axes, instead of a single axis"
    ],
    [
        "Alternative output array in which to place the result.  Must",
        "Alternative output array in which"
    ],
    [
        "be of the same shape and buffer length as the expected output.",
        "be of the same shape and"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced are"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed, then `keepdims` will"
    ],
    [
        "passed through to the ``max`` method of sub-classes of",
        "passed through to the ``max`` method of sub-classes"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value will be."
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not implement `keepdims`"
    ],
    [
        "The minimum value of an output element. Must be present to allow",
        "The minimum value of an output element. Must"
    ],
    [
        "computation on empty slice. See `~numpy.ufunc.reduce` for details.",
        "computation on empty slice. See"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like"
    ],
    [
        "Elements to compare for the maximum. See `~numpy.ufunc.reduce`",
        "Elements to compare for"
    ],
    [
        "Maximum of `a`. If `axis` is None, the result is a scalar value.",
        "Maximum of `a`. If `axis` is None, the result is a scalar"
    ],
    [
        "If `axis` is an int, the result is an array of dimension",
        "If `axis` is an int, the result is an"
    ],
    [
        "The minimum value of an array along a given axis, propagating any NaNs.",
        "The minimum value of an array along a given axis, propagating"
    ],
    [
        "The maximum value of an array along a given axis, ignoring any NaNs.",
        "The maximum value of an array along a given axis,"
    ],
    [
        "Element-wise maximum of two arrays, propagating any NaNs.",
        "Element-wise maximum of two arrays,"
    ],
    [
        "Element-wise maximum of two arrays, ignoring any NaNs.",
        "Element-wise maximum of two"
    ],
    [
        "Return the indices of the maximum values.",
        "Return the indices of"
    ],
    [
        "NaN values are propagated, that is if at least one item is NaN, the",
        "NaN values are propagated, that is if at least one item"
    ],
    [
        "corresponding max value will be NaN as well. To ignore NaN values",
        "corresponding max value will be NaN as well. To ignore"
    ],
    [
        "You can use an initial value to compute the maximum of an empty slice, or",
        "You can use an initial value to compute the maximum of"
    ],
    [
        "to initialize it to a different value:",
        "to initialize it to a"
    ],
    [
        "Notice that the initial value is used as one of the elements for which the",
        "Notice that the initial value is used as one of the elements for"
    ],
    [
        "maximum is determined, unlike for the default argument Python's max",
        "maximum is determined, unlike for the default"
    ],
    [
        "function, which is only used for empty iterables.",
        "function, which is only used"
    ],
    [
        "return _wrapreduction(a, np.maximum, 'max', axis, None, out,",
        "return _wrapreduction(a, np.maximum, 'max', axis,"
    ],
    [
        "def amax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,",
        "def amax(a, axis=None,"
    ],
    [
        "Return the maximum of an array or maximum along an axis.",
        "Return the maximum of an array or maximum along an"
    ],
    [
        "`amax` is an alias of `~numpy.max`.",
        "`amax` is an alias of"
    ],
    [
        "max : alias of this function",
        "max : alias of this"
    ],
    [
        "return _wrapreduction(a, np.maximum, 'max', axis, None, out,",
        "return _wrapreduction(a, np.maximum, 'max', axis, None,"
    ],
    [
        "def _min_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,",
        "def _min_dispatcher(a, axis=None, out=None,"
    ],
    [
        "def min(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,",
        "def min(a, axis=None, out=None, keepdims=np._NoValue,"
    ],
    [
        "Return the minimum of an array or minimum along an axis.",
        "Return the minimum of an array or minimum along"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple"
    ],
    [
        "Axis or axes along which to operate.  By default, flattened input is",
        "Axis or axes along which to operate. By default,"
    ],
    [
        "If this is a tuple of ints, the minimum is selected over multiple axes,",
        "If this is a tuple of ints,"
    ],
    [
        "instead of a single axis or all the axes as before.",
        "instead of a single axis or all the axes"
    ],
    [
        "Alternative output array in which to place the result.  Must",
        "Alternative output array in which"
    ],
    [
        "be of the same shape and buffer length as the expected output.",
        "be of the same shape and buffer length as"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against the input"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed, then `keepdims` will"
    ],
    [
        "passed through to the ``min`` method of sub-classes of",
        "passed through to the ``min`` method of"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value will"
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not implement `keepdims`"
    ],
    [
        "The maximum value of an output element. Must be present to allow",
        "The maximum value of an output element."
    ],
    [
        "computation on empty slice. See `~numpy.ufunc.reduce` for details.",
        "computation on empty slice. See `~numpy.ufunc.reduce` for"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of bool,"
    ],
    [
        "Elements to compare for the minimum. See `~numpy.ufunc.reduce`",
        "Elements to compare for the minimum."
    ],
    [
        "Minimum of `a`. If `axis` is None, the result is a scalar value.",
        "Minimum of `a`. If `axis` is None, the result is a"
    ],
    [
        "If `axis` is an int, the result is an array of dimension",
        "If `axis` is an int, the result is"
    ],
    [
        "The maximum value of an array along a given axis, propagating any NaNs.",
        "The maximum value of an array along"
    ],
    [
        "The minimum value of an array along a given axis, ignoring any NaNs.",
        "The minimum value of an array along a given"
    ],
    [
        "Element-wise minimum of two arrays, propagating any NaNs.",
        "Element-wise minimum of two arrays,"
    ],
    [
        "Element-wise minimum of two arrays, ignoring any NaNs.",
        "Element-wise minimum of two arrays, ignoring"
    ],
    [
        "Return the indices of the minimum values.",
        "Return the indices of the"
    ],
    [
        "NaN values are propagated, that is if at least one item is NaN, the",
        "NaN values are propagated, that is if at least one"
    ],
    [
        "corresponding min value will be NaN as well. To ignore NaN values",
        "corresponding min value will be NaN as well."
    ],
    [
        "Notice that the initial value is used as one of the elements for which the",
        "Notice that the initial value is used as one of"
    ],
    [
        "minimum is determined, unlike for the default argument Python's max",
        "minimum is determined, unlike for"
    ],
    [
        "function, which is only used for empty iterables.",
        "function, which is only"
    ],
    [
        "Notice that this isn't the same as Python's ``default`` argument.",
        "Notice that this isn't the same as"
    ],
    [
        "return _wrapreduction(a, np.minimum, 'min', axis, None, out,",
        "return _wrapreduction(a, np.minimum, 'min', axis, None,"
    ],
    [
        "def amin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,",
        "def amin(a, axis=None, out=None,"
    ],
    [
        "Return the minimum of an array or minimum along an axis.",
        "Return the minimum of an array or"
    ],
    [
        "`amin` is an alias of `~numpy.min`.",
        "`amin` is an"
    ],
    [
        "min : alias of this function",
        "min : alias of"
    ],
    [
        "return _wrapreduction(a, np.minimum, 'min', axis, None, out,",
        "return _wrapreduction(a, np.minimum, 'min', axis, None,"
    ],
    [
        "def _prod_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,",
        "def _prod_dispatcher(a, axis=None, dtype=None, out=None,"
    ],
    [
        "def prod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,",
        "def prod(a, axis=None, dtype=None, out=None,"
    ],
    [
        "Return the product of array elements over a given axis.",
        "Return the product of array elements over"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple"
    ],
    [
        "Axis or axes along which a product is performed.  The default,",
        "Axis or axes along which a product is"
    ],
    [
        "axis=None, will calculate the product of all the elements in the",
        "axis=None, will calculate the product of all the"
    ],
    [
        "input array. If axis is negative it counts from the last to the",
        "input array. If axis is negative it counts from"
    ],
    [
        "If axis is a tuple of ints, a product is performed on all of the",
        "If axis is a tuple of ints, a"
    ],
    [
        "axes specified in the tuple instead of a single axis or all the",
        "axes specified in the tuple instead of a single"
    ],
    [
        "The type of the returned array, as well as of the accumulator in",
        "The type of the returned array, as well as of the accumulator"
    ],
    [
        "which the elements are multiplied.  The dtype of `a` is used by",
        "which the elements are multiplied. The dtype of `a`"
    ],
    [
        "default unless `a` has an integer dtype of less precision than the",
        "default unless `a` has an integer dtype of less"
    ],
    [
        "default platform integer.  In that case, if `a` is signed then the",
        "default platform integer. In that case, if `a` is"
    ],
    [
        "platform integer is used while if `a` is unsigned then an unsigned",
        "platform integer is used while if `a`"
    ],
    [
        "integer of the same precision as the platform integer is used.",
        "integer of the same precision as the platform integer"
    ],
    [
        "Alternative output array in which to place the result. It must have",
        "Alternative output array in which to"
    ],
    [
        "the same shape as the expected output, but the type of the output",
        "the same shape as the expected output, but the type"
    ],
    [
        "values will be cast if necessary.",
        "values will be"
    ],
    [
        "If this is set to True, the axes which are reduced are left in the",
        "If this is set to True, the axes which are reduced are"
    ],
    [
        "result as dimensions with size one. With this option, the result",
        "result as dimensions with size one. With"
    ],
    [
        "will broadcast correctly against the input array.",
        "will broadcast correctly against the"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed, then `keepdims` will"
    ],
    [
        "passed through to the `prod` method of sub-classes of",
        "passed through to the `prod` method of"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value will"
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not implement `keepdims`"
    ],
    [
        "The starting value for this product. See `~numpy.ufunc.reduce`",
        "The starting value for"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of"
    ],
    [
        "Elements to include in the product. See `~numpy.ufunc.reduce`",
        "Elements to include in the product."
    ],
    [
        "product_along_axis : ndarray, see `dtype` parameter above.",
        "product_along_axis : ndarray, see `dtype`"
    ],
    [
        "An array shaped as `a` but with the specified axis removed.",
        "An array shaped as `a` but with"
    ],
    [
        "Returns a reference to `out` if specified.",
        "Returns a reference to"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is",
        "Arithmetic is modular when using integer types, and no error"
    ],
    [
        "By default, calculate the product of all elements:",
        "By default, calculate the product"
    ],
    [
        "Even when the input array is two-dimensional:",
        "Even when the input array is"
    ],
    [
        "But we can also specify the axis over which to multiply:",
        "But we can also specify the axis"
    ],
    [
        "Or select specific elements to include:",
        "Or select specific"
    ],
    [
        "If the type of `x` is unsigned, then the output type is",
        "If the type of `x` is unsigned, then the output"
    ],
    [
        "If `x` is of a signed integer type, then the output type",
        "If `x` is of a signed integer type, then the"
    ],
    [
        "You can also start the product with a value other than one:",
        "You can also start the product with a value"
    ],
    [
        "return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,",
        "return _wrapreduction(a, np.multiply, 'prod', axis,"
    ],
    [
        "Return the cumulative product of elements along a given axis.",
        "Return the cumulative product of"
    ],
    [
        "Axis along which the cumulative product is computed.  By default",
        "Axis along which the cumulative product"
    ],
    [
        "Type of the returned array, as well as of the accumulator in which",
        "Type of the returned array, as well as of the accumulator"
    ],
    [
        "the elements are multiplied.  If *dtype* is not specified, it",
        "the elements are multiplied. If"
    ],
    [
        "defaults to the dtype of `a`, unless `a` has an integer dtype with",
        "defaults to the dtype of `a`, unless `a` has an integer"
    ],
    [
        "a precision less than that of the default platform integer.  In",
        "a precision less than that of the default platform integer."
    ],
    [
        "that case, the default platform integer is used instead.",
        "that case, the default platform integer is"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place"
    ],
    [
        "have the same shape and buffer length as the expected output",
        "have the same shape and buffer length as the"
    ],
    [
        "but the type of the resulting values will be cast if necessary.",
        "but the type of the resulting values"
    ],
    [
        "A new array holding the result is returned unless `out` is",
        "A new array holding the result is returned unless `out`"
    ],
    [
        "specified, in which case a reference to out is returned.",
        "specified, in which case a reference to out"
    ],
    [
        "cumulative_prod : Array API compatible alternative for ``cumprod``.",
        "cumulative_prod : Array API compatible alternative for"
    ],
    [
        "Arithmetic is modular when using integer types, and no error is",
        "Arithmetic is modular when using integer types,"
    ],
    [
        "The cumulative product for each column (i.e., over the rows) of `a`:",
        "The cumulative product for each column (i.e.,"
    ],
    [
        "The cumulative product for each row (i.e. over the columns) of `a`:",
        "The cumulative product for each row (i.e. over"
    ],
    [
        "return _wrapfunc(a, 'cumprod', axis=axis, dtype=dtype, out=out)",
        "return _wrapfunc(a, 'cumprod',"
    ],
    [
        "Return the number of dimensions of an array.",
        "Return the number of dimensions of"
    ],
    [
        "Input array.  If it is not already an ndarray, a conversion is",
        "Input array. If it is not already an"
    ],
    [
        "The number of dimensions in `a`.  Scalars are zero-dimensional.",
        "The number of dimensions in"
    ],
    [
        "Return the number of elements along a given axis.",
        "Return the number of elements along a given"
    ],
    [
        "Axis along which the elements are counted.  By default, give",
        "Axis along which the elements are"
    ],
    [
        "Number of elements along the specified axis.",
        "Number of elements along"
    ],
    [
        "ndarray.size : number of elements in array",
        "ndarray.size : number of elements in"
    ],
    [
        "Evenly round to the given number of decimals.",
        "Evenly round to the given number of"
    ],
    [
        "decimals is negative, it specifies the number of positions to",
        "decimals is negative, it specifies the number of"
    ],
    [
        "the left of the decimal point.",
        "the left of the"
    ],
    [
        "Alternative output array in which to place the result. It must have",
        "Alternative output array in which to"
    ],
    [
        "the same shape as the expected output, but the type of the output",
        "the same shape as the expected output, but the type"
    ],
    [
        "values will be cast if necessary. See :ref:`ufuncs-output-type`",
        "values will be cast if necessary."
    ],
    [
        "An array of the same type as `a`, containing the rounded values.",
        "An array of the same type as `a`, containing"
    ],
    [
        "Unless `out` was specified, a new array is created.  A reference to",
        "Unless `out` was specified, a new array"
    ],
    [
        "The real and imaginary parts of complex numbers are rounded",
        "The real and imaginary parts"
    ],
    [
        "separately.  The result of rounding a float is a float.",
        "separately. The result of rounding a float is"
    ],
    [
        "around : an alias for this function",
        "around : an alias"
    ],
    [
        "For values exactly halfway between rounded decimal values, NumPy",
        "For values exactly halfway between"
    ],
    [
        "``np.round`` uses a fast but sometimes inexact algorithm to round",
        "``np.round`` uses a fast but sometimes"
    ],
    [
        "floating-point datatypes. For positive `decimals` it is equivalent to",
        "floating-point datatypes. For positive `decimals` it is equivalent"
    ],
    [
        "error due to the inexact representation of decimal fractions in the IEEE",
        "error due to the inexact representation of decimal fractions in the"
    ],
    [
        "If your goal is to print such values with a fixed number of decimals, it is",
        "If your goal is to print such values"
    ],
    [
        "preferable to use numpy's float printing routines to limit the number of",
        "preferable to use numpy's float printing routines to limit the"
    ],
    [
        "The float printing routines use an accurate but much more computationally",
        "The float printing routines use an accurate but much more"
    ],
    [
        "demanding algorithm to compute the number of digits after the decimal",
        "demanding algorithm to compute the number of digits after the"
    ],
    [
        "Alternatively, Python's builtin `round` function uses a more accurate",
        "Alternatively, Python's builtin `round` function"
    ],
    [
        "Round an array to the given number of decimals.",
        "Round an array to the given"
    ],
    [
        "`around` is an alias of `~numpy.round`.",
        "`around` is an alias of"
    ],
    [
        "round : alias for this function",
        "round : alias for"
    ],
    [
        "def _mean_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None, *,",
        "def _mean_dispatcher(a, axis=None, dtype=None, out=None,"
    ],
    [
        "def mean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue, *,",
        "def mean(a, axis=None, dtype=None, out=None,"
    ],
    [
        "Compute the arithmetic mean along the specified axis.",
        "Compute the arithmetic mean along the"
    ],
    [
        "Returns the average of the array elements.  The average is taken over",
        "Returns the average of the array elements. The average is taken"
    ],
    [
        "the flattened array by default, otherwise over the specified axis.",
        "the flattened array by default,"
    ],
    [
        "Array containing numbers whose mean is desired. If `a` is not an",
        "Array containing numbers whose mean is desired. If `a`"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or"
    ],
    [
        "Axis or axes along which the means are computed. The default is to",
        "Axis or axes along which the means are"
    ],
    [
        "compute the mean of the flattened array.",
        "compute the mean of the flattened"
    ],
    [
        "If this is a tuple of ints, a mean is performed over multiple axes,",
        "If this is a tuple of ints, a mean is"
    ],
    [
        "instead of a single axis or all the axes as before.",
        "instead of a single axis or all the"
    ],
    [
        "Type to use in computing the mean.  For integer inputs, the default",
        "Type to use in computing the mean. For integer inputs,"
    ],
    [
        "Alternate output array in which to place the result.  The default",
        "Alternate output array in which to place the result."
    ],
    [
        "is ``None``; if provided, it must have the same shape as the",
        "is ``None``; if provided, it must have"
    ],
    [
        "expected output, but the type will be cast if necessary.",
        "expected output, but the type will be cast if"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed, then"
    ],
    [
        "passed through to the `mean` method of sub-classes of",
        "passed through to the `mean` method of sub-classes"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value will"
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like"
    ],
    [
        "Elements to include in the mean. See `~numpy.ufunc.reduce` for details.",
        "Elements to include in the mean. See `~numpy.ufunc.reduce` for"
    ],
    [
        "m : ndarray, see dtype parameter above",
        "m : ndarray, see dtype"
    ],
    [
        "If `out=None`, returns a new array containing the mean values,",
        "If `out=None`, returns a new array"
    ],
    [
        "otherwise a reference to the output array is returned.",
        "otherwise a reference to the"
    ],
    [
        "The arithmetic mean is the sum of the elements along the axis divided",
        "The arithmetic mean is the sum of the elements along the axis"
    ],
    [
        "Note that for floating-point input, the mean is computed using the",
        "Note that for floating-point input, the mean"
    ],
    [
        "same precision the input has.  Depending on the input data, this can",
        "same precision the input has. Depending on the input data, this"
    ],
    [
        "example below).  Specifying a higher-precision accumulator using the",
        "example below). Specifying a higher-precision"
    ],
    [
        "`dtype` keyword can alleviate this issue.",
        "`dtype` keyword can alleviate this"
    ],
    [
        "In single precision, `mean` can be inaccurate:",
        "In single precision, `mean` can"
    ],
    [
        "def _std_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,",
        "def _std_dispatcher(a, axis=None,"
    ],
    [
        "Compute the standard deviation along the specified axis.",
        "Compute the standard deviation along"
    ],
    [
        "Returns the standard deviation, a measure of the spread of a distribution,",
        "Returns the standard deviation, a measure of the spread"
    ],
    [
        "of the array elements. The standard deviation is computed for the",
        "of the array elements. The standard"
    ],
    [
        "flattened array by default, otherwise over the specified axis.",
        "flattened array by default, otherwise over the"
    ],
    [
        "Calculate the standard deviation of these values.",
        "Calculate the standard deviation of"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or"
    ],
    [
        "Axis or axes along which the standard deviation is computed. The",
        "Axis or axes along which the standard deviation"
    ],
    [
        "default is to compute the standard deviation of the flattened array.",
        "default is to compute the standard"
    ],
    [
        "If this is a tuple of ints, a standard deviation is performed over",
        "If this is a tuple of ints,"
    ],
    [
        "multiple axes, instead of a single axis or all the axes as before.",
        "multiple axes, instead of a single axis or all the"
    ],
    [
        "Type to use in computing the standard deviation. For arrays of",
        "Type to use in computing the standard deviation."
    ],
    [
        "the same as the array type.",
        "the same as"
    ],
    [
        "Alternative output array in which to place the result. It must have",
        "Alternative output array in which to place"
    ],
    [
        "the same shape as the expected output but the type (of the calculated",
        "the same shape as the expected output but the"
    ],
    [
        "values) will be cast if necessary.",
        "values) will be"
    ],
    [
        "Means Delta Degrees of Freedom.  The divisor used in calculations",
        "Means Delta Degrees of Freedom. The divisor used"
    ],
    [
        "is ``N - ddof``, where ``N`` represents the number of elements.",
        "is ``N - ddof``, where ``N`` represents the"
    ],
    [
        "By default `ddof` is zero. See Notes for details about use of `ddof`.",
        "By default `ddof` is zero. See Notes"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed,"
    ],
    [
        "passed through to the `std` method of sub-classes of",
        "passed through to the `std` method"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value will be. If"
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not implement `keepdims`"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of"
    ],
    [
        "Elements to include in the standard deviation.",
        "Elements to include in the"
    ],
    [
        "Provide the mean to prevent its recalculation. The mean should have",
        "Provide the mean to prevent its recalculation."
    ],
    [
        "a shape as if it was calculated with ``keepdims=True``.",
        "a shape as if it"
    ],
    [
        "The axis for the calculation of the mean should be the same as used in",
        "The axis for the calculation of the mean should be the same"
    ],
    [
        "the call to this std function.",
        "the call to this"
    ],
    [
        "Array API compatible name for the ``ddof`` parameter. Only one of them",
        "Array API compatible name for the"
    ],
    [
        "can be provided at the same time.",
        "can be provided at the same"
    ],
    [
        "standard_deviation : ndarray, see dtype parameter above.",
        "standard_deviation : ndarray, see dtype"
    ],
    [
        "If `out` is None, return a new array containing the standard deviation,",
        "If `out` is None, return a new array containing the"
    ],
    [
        "otherwise return a reference to the output array.",
        "otherwise return a reference to the output"
    ],
    [
        "There are several common variants of the array standard deviation",
        "There are several common variants of the array"
    ],
    [
        "calculation. Assuming the input `a` is a one-dimensional NumPy array",
        "calculation. Assuming the input `a` is"
    ],
    [
        "and ``mean`` is either provided as an argument or computed as",
        "and ``mean`` is either provided as"
    ],
    [
        "``a.mean()``, NumPy computes the standard deviation of an array as::",
        "``a.mean()``, NumPy computes the standard deviation"
    ],
    [
        "Different values of the argument `ddof` are useful in different",
        "Different values of the argument"
    ],
    [
        "which is sometimes called the \"population standard deviation\" in the field",
        "which is sometimes called the \"population standard deviation\""
    ],
    [
        "of statistics because it applies the definition of standard deviation to",
        "of statistics because it applies the definition of standard deviation"
    ],
    [
        "`a` as if `a` were a complete population of possible observations.",
        "`a` as if `a` were a"
    ],
    [
        "Many other libraries define the standard deviation of an array",
        "Many other libraries define the standard"
    ],
    [
        "In statistics, the resulting quantity is sometimes called the \"sample",
        "In statistics, the resulting quantity is sometimes called"
    ],
    [
        "standard deviation\" because if `a` is a random sample from a larger",
        "standard deviation\" because if `a` is a random sample from"
    ],
    [
        "population, this calculation provides the square root of an unbiased",
        "population, this calculation provides the"
    ],
    [
        "denominator is often called \"Bessel's correction\" because it corrects for",
        "denominator is often called \"Bessel's correction\" because"
    ],
    [
        "bias (toward lower values) in the variance estimate introduced when the",
        "bias (toward lower values) in the variance estimate"
    ],
    [
        "sample mean of `a` is used in place of the true mean of the population.",
        "sample mean of `a` is used in place of the"
    ],
    [
        "The resulting estimate of the standard deviation is still biased, but less",
        "The resulting estimate of the standard deviation is"
    ],
    [
        "than it would have been without the correction. For this quantity, use",
        "than it would have been without"
    ],
    [
        "Note that, for complex numbers, `std` takes the absolute",
        "Note that, for complex numbers, `std`"
    ],
    [
        "value before squaring, so that the result is always real and nonnegative.",
        "value before squaring, so that the result is always"
    ],
    [
        "For floating-point input, the standard deviation is computed using the same",
        "For floating-point input, the standard deviation is"
    ],
    [
        "precision the input has. Depending on the input data, this can cause",
        "precision the input has. Depending on the input"
    ],
    [
        "Specifying a higher-accuracy accumulator using the `dtype` keyword can",
        "Specifying a higher-accuracy accumulator using"
    ],
    [
        "In single precision, std() can be inaccurate:",
        "In single precision, std() can be"
    ],
    [
        "Using the mean keyword to save computation time:",
        "Using the mean keyword to"
    ],
    [
        "\"ddof and correction can't be provided simultaneously.\"",
        "\"ddof and correction can't be provided"
    ],
    [
        "return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)",
        "return std(axis=axis, dtype=dtype, out=out,"
    ],
    [
        "return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,",
        "return _methods._std(a, axis=axis,"
    ],
    [
        "def _var_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,",
        "def _var_dispatcher(a, axis=None, dtype=None, out=None,"
    ],
    [
        "Compute the variance along the specified axis.",
        "Compute the variance along"
    ],
    [
        "Returns the variance of the array elements, a measure of the spread of a",
        "Returns the variance of the array elements, a measure of"
    ],
    [
        "distribution.  The variance is computed for the flattened array by",
        "distribution. The variance is computed"
    ],
    [
        "default, otherwise over the specified axis.",
        "default, otherwise over"
    ],
    [
        "Array containing numbers whose variance is desired.  If `a` is not an",
        "Array containing numbers whose variance is desired. If `a` is not"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or"
    ],
    [
        "Axis or axes along which the variance is computed.  The default is to",
        "Axis or axes along which the variance is computed."
    ],
    [
        "compute the variance of the flattened array.",
        "compute the variance of the flattened"
    ],
    [
        "If this is a tuple of ints, a variance is performed over multiple axes,",
        "If this is a tuple of ints, a variance"
    ],
    [
        "instead of a single axis or all the axes as before.",
        "instead of a single axis or all"
    ],
    [
        "Type to use in computing the variance.  For arrays of integer type",
        "Type to use in computing the variance. For arrays"
    ],
    [
        "Alternate output array in which to place the result.  It must have",
        "Alternate output array in which to place the result. It must"
    ],
    [
        "the same shape as the expected output, but the type is cast if",
        "the same shape as the expected output, but the type is"
    ],
    [
        "\"Delta Degrees of Freedom\": the divisor used in the calculation is",
        "\"Delta Degrees of Freedom\": the divisor used in the calculation"
    ],
    [
        "``N - ddof``, where ``N`` represents the number of elements. By",
        "``N - ddof``, where ``N`` represents"
    ],
    [
        "default `ddof` is zero. See notes for details about use of `ddof`.",
        "default `ddof` is zero. See notes"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against"
    ],
    [
        "If the default value is passed, then `keepdims` will not be",
        "If the default value is passed, then"
    ],
    [
        "passed through to the `var` method of sub-classes of",
        "passed through to the `var` method of"
    ],
    [
        "`ndarray`, however any non-default value will be.  If the",
        "`ndarray`, however any non-default value"
    ],
    [
        "sub-class' method does not implement `keepdims` any",
        "sub-class' method does not implement"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like"
    ],
    [
        "Elements to include in the variance. See `~numpy.ufunc.reduce` for",
        "Elements to include in the variance. See `~numpy.ufunc.reduce`"
    ],
    [
        "Provide the mean to prevent its recalculation. The mean should have",
        "Provide the mean to prevent its recalculation."
    ],
    [
        "a shape as if it was calculated with ``keepdims=True``.",
        "a shape as if it was calculated"
    ],
    [
        "The axis for the calculation of the mean should be the same as used in",
        "The axis for the calculation of the mean"
    ],
    [
        "the call to this var function.",
        "the call to this"
    ],
    [
        "Array API compatible name for the ``ddof`` parameter. Only one of them",
        "Array API compatible name for the"
    ],
    [
        "can be provided at the same time.",
        "can be provided at the same"
    ],
    [
        "variance : ndarray, see dtype parameter above",
        "variance : ndarray, see dtype parameter"
    ],
    [
        "If ``out=None``, returns a new array containing the variance;",
        "If ``out=None``, returns a new array containing"
    ],
    [
        "otherwise, a reference to the output array is returned.",
        "otherwise, a reference to the output array is"
    ],
    [
        "There are several common variants of the array variance calculation.",
        "There are several common variants of the array"
    ],
    [
        "Assuming the input `a` is a one-dimensional NumPy array and ``mean`` is",
        "Assuming the input `a` is a"
    ],
    [
        "either provided as an argument or computed as ``a.mean()``, NumPy",
        "either provided as an argument or computed as"
    ],
    [
        "computes the variance of an array as::",
        "computes the variance of"
    ],
    [
        "Different values of the argument `ddof` are useful in different",
        "Different values of the argument `ddof` are useful in"
    ],
    [
        "which is sometimes called the \"population variance\" in the field of",
        "which is sometimes called the \"population variance\" in"
    ],
    [
        "statistics because it applies the definition of variance to `a` as if `a`",
        "statistics because it applies the definition of"
    ],
    [
        "were a complete population of possible observations.",
        "were a complete population of"
    ],
    [
        "Many other libraries define the variance of an array differently, e.g.:",
        "Many other libraries define the variance of an array"
    ],
    [
        "In statistics, the resulting quantity is sometimes called the \"sample",
        "In statistics, the resulting quantity"
    ],
    [
        "variance\" because if `a` is a random sample from a larger population,",
        "variance\" because if `a` is a random sample"
    ],
    [
        "this calculation provides an unbiased estimate of the variance of the",
        "this calculation provides an unbiased estimate of the"
    ],
    [
        "\"Bessel's correction\" because it corrects for bias (toward lower values)",
        "\"Bessel's correction\" because it corrects for bias (toward lower"
    ],
    [
        "in the variance estimate introduced when the sample mean of `a` is used",
        "in the variance estimate introduced when the sample mean of `a` is"
    ],
    [
        "in place of the true mean of the population. For this quantity, use",
        "in place of the true mean of the population. For this"
    ],
    [
        "Note that for complex numbers, the absolute value is taken before",
        "Note that for complex numbers, the"
    ],
    [
        "squaring, so that the result is always real and nonnegative.",
        "squaring, so that the result"
    ],
    [
        "For floating-point input, the variance is computed using the same",
        "For floating-point input, the variance is computed using"
    ],
    [
        "precision the input has.  Depending on the input data, this can cause",
        "precision the input has. Depending on the"
    ],
    [
        "below).  Specifying a higher-accuracy accumulator using the ``dtype``",
        "below). Specifying a higher-accuracy"
    ],
    [
        "In single precision, var() can be inaccurate:",
        "In single precision, var() can"
    ],
    [
        "Using the mean keyword to save computation time:",
        "Using the mean keyword to save"
    ],
    [
        "\"ddof and correction can't be provided simultaneously.\"",
        "\"ddof and correction can't"
    ],
    [
        "return var(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)",
        "return var(axis=axis, dtype=dtype, out=out, ddof=ddof,"
    ],
    [
        "return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,",
        "return _methods._var(a, axis=axis, dtype=dtype, out=out,"
    ],
    [
        "A place for code to be called from the implementation of np.dtype",
        "A place for code to be"
    ],
    [
        "String handling is much easier to do correctly in python.",
        "String handling is much easier to do correctly"
    ],
    [
        "\"internal dtype error, unknown kind {!r}\"",
        "\"internal dtype error, unknown"
    ],
    [
        "elif issubclass(dtype.type, np.flexible) or not dtype.isnative:",
        "elif issubclass(dtype.type, np.flexible)"
    ],
    [
        "arg_str = arg_str + \", align=True\"",
        "arg_str = arg_str +"
    ],
    [
        "Helper function to normalize the items in dtype.fields.",
        "Helper function to normalize"
    ],
    [
        "Creates a string repr of the dtype, excluding the 'dtype()' part",
        "Creates a string repr of the dtype, excluding the"
    ],
    [
        "surrounding the object. This object may be a string, a list, or",
        "surrounding the object. This object may be a string, a list,"
    ],
    [
        "a dict depending on the nature of the dtype. This",
        "a dict depending on the"
    ],
    [
        "is the object passed as the first parameter to the dtype",
        "is the object passed as the first parameter to"
    ],
    [
        "constructor, and if no additional constructor parameters are",
        "constructor, and if no additional"
    ],
    [
        "given, will reproduce the exact memory layout.",
        "given, will reproduce the exact memory"
    ],
    [
        "If true, this creates a shorter repr using 'kind' and 'itemsize',",
        "If true, this creates a shorter repr using 'kind' and"
    ],
    [
        "instead of the longer type name.",
        "instead of the longer type"
    ],
    [
        "If true, this includes the 'align=True' parameter",
        "If true, this includes the 'align=True'"
    ],
    [
        "inside the struct dtype construction dict when needed. Use this flag",
        "inside the struct dtype construction dict when needed. Use"
    ],
    [
        "if you want a proper repr string without the 'dtype()' part around it.",
        "if you want a proper repr string without"
    ],
    [
        "If false, this does not preserve the",
        "If false, this does not"
    ],
    [
        "'align=True' parameter or sticky NPY_ALIGNED_STRUCT flag for",
        "'align=True' parameter or sticky NPY_ALIGNED_STRUCT"
    ],
    [
        "struct arrays like the regular repr does, because the 'align'",
        "struct arrays like the regular repr"
    ],
    [
        "flag is not part of first dtype constructor parameter. This",
        "flag is not part of first dtype constructor parameter."
    ],
    [
        "mode is intended for a full 'repr', where the 'align=True' is",
        "mode is intended for a full 'repr', where the 'align=True'"
    ],
    [
        "if short or dtype.byteorder not in ('=', '|'):",
        "if short or dtype.byteorder not in ('=',"
    ],
    [
        "return \"'%s%c%d'\" % (byteorder, dtype.kind, dtype.itemsize)",
        "return \"'%s%c%d'\" % (byteorder, dtype.kind,"
    ],
    [
        "\"Internal error: NumPy dtype unrecognized type number\")",
        "\"Internal error: NumPy dtype unrecognized type"
    ],
    [
        "\"\"\" Normalize byteorder to '<' or '>' \"\"\"",
        "\"\"\" Normalize byteorder to"
    ],
    [
        "ret += fieldsep.join(repr(name) for name in names)",
        "ret += fieldsep.join(repr(name) for"
    ],
    [
        "ret += \"], 'formats'%s[\" % colon",
        "ret += \"], 'formats'%s[\""
    ],
    [
        "_construction_repr(fld_dtype, short=True) for fld_dtype in fld_dtypes)",
        "_construction_repr(fld_dtype, short=True) for fld_dtype"
    ],
    [
        "ret += \"], 'offsets'%s[\" % colon",
        "ret += \"], 'offsets'%s[\" %"
    ],
    [
        "ret += fieldsep.join(\"%d\" % offset for offset in offsets)",
        "ret += fieldsep.join(\"%d\" % offset"
    ],
    [
        "if any(title is not None for title in titles):",
        "if any(title is not None for"
    ],
    [
        "ret += \"], 'titles'%s[\" % colon",
        "ret += \"], 'titles'%s[\" %"
    ],
    [
        "ret += fieldsep.join(repr(title) for title in titles)",
        "ret += fieldsep.join(repr(title) for"
    ],
    [
        "ret += \"], 'itemsize'%s%d\" % (colon, dtype.itemsize)",
        "ret += \"], 'itemsize'%s%d\" %"
    ],
    [
        "ret += \", 'aligned'%sTrue}\" % colon",
        "ret += \","
    ],
    [
        "return - (-offset // alignment) * alignment",
        "return - (-offset //"
    ],
    [
        "Checks whether the structured data type in 'dtype'",
        "Checks whether the structured data"
    ],
    [
        "has a simple layout, where all the fields are in order,",
        "has a simple layout, where all the"
    ],
    [
        "and follow each other with no alignment padding.",
        "and follow each other with"
    ],
    [
        "When this returns true, the dtype can be reconstructed",
        "When this returns true, the dtype can be"
    ],
    [
        "from a list of the field names and dtypes with no additional",
        "from a list of the field names and"
    ],
    [
        "item += \"({!r}, {!r}), \".format(title, name)",
        "item += \"({!r},"
    ],
    [
        "return \"[\" + \", \".join(items) + \"]\"",
        "return \"[\" + \","
    ],
    [
        "if not (include_align and dtype.isalignedstruct) and _is_packed(dtype):",
        "if not (include_align and"
    ],
    [
        "This is only meant to add docs to objects defined in C-extension modules.",
        "This is only meant to add docs"
    ],
    [
        "The purpose is to allow easier editing of the docstrings without",
        "The purpose is to allow easier editing of the"
    ],
    [
        "NOTE: Many of the methods of ndarray have corresponding functions.",
        "NOTE: Many of the methods of ndarray have"
    ],
    [
        "If you update these docstrings, please keep also the ones in",
        "If you update these docstrings, please keep also the"
    ],
    [
        "Flat iterator object to iterate over arrays.",
        "Flat iterator object to iterate over"
    ],
    [
        "A `flatiter` iterator is returned by ``x.flat`` for any array `x`.",
        "A `flatiter` iterator is returned by ``x.flat`` for any array"
    ],
    [
        "either in a for-loop or by calling its `next` method.",
        "either in a for-loop or by calling its"
    ],
    [
        "Iteration is done in row-major, C-style order (the last",
        "Iteration is done in row-major, C-style"
    ],
    [
        "index varying the fastest). The iterator can also be indexed using",
        "index varying the fastest). The iterator can"
    ],
    [
        "ndarray.flat : Return a flat iterator over an array.",
        "ndarray.flat : Return a flat iterator over"
    ],
    [
        "ndarray.flatten : Returns a flattened copy of an array.",
        "ndarray.flatten : Returns a flattened copy of"
    ],
    [
        "A `flatiter` iterator can not be constructed directly from Python code",
        "A `flatiter` iterator can not be constructed directly from"
    ],
    [
        "A reference to the array that is iterated over.",
        "A reference to the array that is"
    ],
    [
        "An N-dimensional tuple of current coordinates.",
        "An N-dimensional tuple of current"
    ],
    [
        "Current flat index into the array.",
        "Current flat index"
    ],
    [
        "Efficient multi-dimensional iterator object to iterate over arrays.",
        "Efficient multi-dimensional iterator object to iterate"
    ],
    [
        "To get started using this object, see the",
        "To get started using this object,"
    ],
    [
        ":ref:`introductory guide to array iteration <arrays.nditer>`.",
        ":ref:`introductory guide to array"
    ],
    [
        "op : ndarray or sequence of array_like",
        "op : ndarray or sequence"
    ],
    [
        "flags : sequence of str, optional",
        "flags : sequence"
    ],
    [
        "Flags to control the behavior of the iterator.",
        "Flags to control the behavior of"
    ],
    [
        "* ``buffered`` enables buffering when required.",
        "* ``buffered`` enables buffering"
    ],
    [
        "* ``c_index`` causes a C-order index to be tracked.",
        "* ``c_index`` causes a C-order index to"
    ],
    [
        "* ``f_index`` causes a Fortran-order index to be tracked.",
        "* ``f_index`` causes a Fortran-order index to be"
    ],
    [
        "* ``multi_index`` causes a multi-index, or a tuple of indices",
        "* ``multi_index`` causes a multi-index, or a tuple of"
    ],
    [
        "with one per iteration dimension, to be tracked.",
        "with one per iteration dimension, to"
    ],
    [
        "* ``common_dtype`` causes all the operands to be converted to",
        "* ``common_dtype`` causes all the operands to be"
    ],
    [
        "a common data type, with copying or buffering as necessary.",
        "a common data type, with"
    ],
    [
        "* ``copy_if_overlap`` causes the iterator to determine if read",
        "* ``copy_if_overlap`` causes the iterator to"
    ],
    [
        "operands have overlap with write operands, and make temporary",
        "operands have overlap with write operands, and"
    ],
    [
        "copies as necessary to avoid overlap. False positives (needless",
        "copies as necessary to avoid overlap."
    ],
    [
        "copying) are possible in some cases.",
        "copying) are possible in"
    ],
    [
        "* ``delay_bufalloc`` delays allocation of the buffers until",
        "* ``delay_bufalloc`` delays allocation"
    ],
    [
        "a reset() call is made. Allows ``allocate`` operands to",
        "a reset() call is made."
    ],
    [
        "be initialized before their values are copied into the buffers.",
        "be initialized before their values are copied into the"
    ],
    [
        "* ``external_loop`` causes the ``values`` given to be",
        "* ``external_loop`` causes the"
    ],
    [
        "one-dimensional arrays with multiple values instead of",
        "one-dimensional arrays with multiple values instead"
    ],
    [
        "* ``grow_inner`` allows the ``value`` array sizes to be made",
        "* ``grow_inner`` allows the ``value`` array"
    ],
    [
        "larger than the buffer size when both ``buffered`` and",
        "larger than the buffer size"
    ],
    [
        "* ``ranged`` allows the iterator to be restricted to a sub-range",
        "* ``ranged`` allows the iterator to be"
    ],
    [
        "* ``refs_ok`` enables iteration of reference types, such as",
        "* ``refs_ok`` enables iteration of reference types,"
    ],
    [
        "* ``reduce_ok`` enables iteration of ``readwrite`` operands",
        "* ``reduce_ok`` enables iteration of ``readwrite``"
    ],
    [
        "which are broadcasted, also known as reduction operands.",
        "which are broadcasted, also known as reduction"
    ],
    [
        "* ``zerosize_ok`` allows `itersize` to be zero.",
        "* ``zerosize_ok`` allows `itersize` to"
    ],
    [
        "op_flags : list of list of str, optional",
        "op_flags : list of"
    ],
    [
        "This is a list of flags for each operand. At minimum, one of",
        "This is a list of flags for each operand. At minimum, one"
    ],
    [
        "``readonly``, ``readwrite``, or ``writeonly`` must be specified.",
        "``readonly``, ``readwrite``, or ``writeonly``"
    ],
    [
        "* ``readonly`` indicates the operand will only be read from.",
        "* ``readonly`` indicates the operand will only"
    ],
    [
        "* ``readwrite`` indicates the operand will be read from and written to.",
        "* ``readwrite`` indicates the operand will be read"
    ],
    [
        "* ``writeonly`` indicates the operand will only be written to.",
        "* ``writeonly`` indicates the operand will only be written"
    ],
    [
        "* ``no_broadcast`` prevents the operand from being broadcasted.",
        "* ``no_broadcast`` prevents the"
    ],
    [
        "* ``contig`` forces the operand data to be contiguous.",
        "* ``contig`` forces the operand data to be"
    ],
    [
        "* ``aligned`` forces the operand data to be aligned.",
        "* ``aligned`` forces the operand"
    ],
    [
        "* ``nbo`` forces the operand data to be in native byte order.",
        "* ``nbo`` forces the operand data to"
    ],
    [
        "* ``copy`` allows a temporary read-only copy if required.",
        "* ``copy`` allows a temporary"
    ],
    [
        "* ``updateifcopy`` allows a temporary read-write copy if required.",
        "* ``updateifcopy`` allows a temporary"
    ],
    [
        "* ``allocate`` causes the array to be allocated if it is None",
        "* ``allocate`` causes the array to"
    ],
    [
        "* ``no_subtype`` prevents an ``allocate`` operand from using a subtype.",
        "* ``no_subtype`` prevents an ``allocate``"
    ],
    [
        "* ``arraymask`` indicates that this operand is the mask to use",
        "* ``arraymask`` indicates that this operand is"
    ],
    [
        "for selecting elements when writing to operands with the",
        "for selecting elements when writing to"
    ],
    [
        "'writemasked' flag set. The iterator does not enforce this,",
        "'writemasked' flag set. The iterator does not"
    ],
    [
        "but when writing from a buffer back to the array, it only",
        "but when writing from a buffer back"
    ],
    [
        "copies those elements indicated by this mask.",
        "copies those elements indicated by"
    ],
    [
        "* ``writemasked`` indicates that only elements where the chosen",
        "* ``writemasked`` indicates that only"
    ],
    [
        "``arraymask`` operand is True will be written to.",
        "``arraymask`` operand is True"
    ],
    [
        "* ``overlap_assume_elementwise`` can be used to mark operands that are",
        "* ``overlap_assume_elementwise`` can be used to mark operands that"
    ],
    [
        "accessed only in the iterator order, to allow less conservative",
        "accessed only in the iterator order,"
    ],
    [
        "op_dtypes : dtype or tuple of dtype(s), optional",
        "op_dtypes : dtype or tuple"
    ],
    [
        "The required data type(s) of the operands. If copying or buffering",
        "The required data type(s) of the operands. If copying"
    ],
    [
        "is enabled, the data will be converted to/from their original types.",
        "is enabled, the data will be converted to/from"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A', 'K'},"
    ],
    [
        "Controls the iteration order. 'C' means C order, 'F' means",
        "Controls the iteration order. 'C' means C"
    ],
    [
        "Fortran order, 'A' means 'F' order if all the arrays are Fortran",
        "Fortran order, 'A' means 'F' order"
    ],
    [
        "contiguous, 'C' order otherwise, and 'K' means as close to the",
        "contiguous, 'C' order otherwise, and 'K' means as"
    ],
    [
        "order the array elements appear in memory as possible. This also",
        "order the array elements appear in memory as"
    ],
    [
        "affects the element memory order of ``allocate`` operands, as they",
        "affects the element memory order of ``allocate``"
    ],
    [
        "are allocated to be compatible with iteration order.",
        "are allocated to be"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv',"
    ],
    [
        "Controls what kind of data casting may occur when making a copy",
        "Controls what kind of data casting"
    ],
    [
        "or buffering.  Setting this to 'unsafe' is not recommended,",
        "or buffering. Setting this to 'unsafe'"
    ],
    [
        "as it can adversely affect accumulations.",
        "as it can"
    ],
    [
        "* 'no' means the data types should not be cast at all.",
        "* 'no' means the data types should not be"
    ],
    [
        "* 'equiv' means only byte-order changes are allowed.",
        "* 'equiv' means only"
    ],
    [
        "* 'safe' means only casts which can preserve values are allowed.",
        "* 'safe' means only casts which can preserve values are"
    ],
    [
        "* 'same_kind' means only safe casts or casts within a kind,",
        "* 'same_kind' means only safe casts or casts within"
    ],
    [
        "* 'unsafe' means any data conversions may be done.",
        "* 'unsafe' means any data conversions"
    ],
    [
        "op_axes : list of list of ints, optional",
        "op_axes : list of list"
    ],
    [
        "If provided, is a list of ints or None for each operands.",
        "If provided, is a list of ints or None"
    ],
    [
        "The list of axes for an operand is a mapping from the dimensions",
        "The list of axes for an operand is a"
    ],
    [
        "of the iterator to the dimensions of the operand. A value of",
        "of the iterator to the dimensions of the"
    ],
    [
        "itershape : tuple of ints, optional",
        "itershape : tuple of ints,"
    ],
    [
        "The desired shape of the iterator. This allows ``allocate`` operands",
        "The desired shape of the iterator. This allows"
    ],
    [
        "with a dimension mapped by op_axes not corresponding to a dimension",
        "with a dimension mapped by op_axes"
    ],
    [
        "When buffering is enabled, controls the size of the temporary",
        "When buffering is enabled, controls the size of the"
    ],
    [
        "The data types of the values provided in `value`. This may be",
        "The data types of the values provided"
    ],
    [
        "different from the operand data types if buffering is enabled.",
        "different from the operand data types if buffering"
    ],
    [
        "Valid only before the iterator is closed.",
        "Valid only before the"
    ],
    [
        "Whether the iteration over the operands is finished or not.",
        "Whether the iteration over the operands is finished"
    ],
    [
        "If True, the iterator was created with the ``delay_bufalloc`` flag,",
        "If True, the iterator was"
    ],
    [
        "and no reset() function was called on it yet.",
        "and no reset() function was called on it"
    ],
    [
        "If True, the iterator was created with either the ``c_index`` or",
        "If True, the iterator was created with either the ``c_index``"
    ],
    [
        "the ``f_index`` flag, and the property `index` can be used to",
        "the ``f_index`` flag, and the property `index` can"
    ],
    [
        "If True, the iterator was created with the ``multi_index`` flag,",
        "If True, the iterator was created with the"
    ],
    [
        "and the property `multi_index` can be used to retrieve it.",
        "and the property `multi_index` can be used to"
    ],
    [
        "When the ``c_index`` or ``f_index`` flag was used, this property",
        "When the ``c_index`` or ``f_index`` flag was used,"
    ],
    [
        "provides access to the index. Raises a ValueError if accessed",
        "provides access to the index. Raises a ValueError"
    ],
    [
        "Whether iteration requires access to the Python API, for example",
        "Whether iteration requires access to the Python API, for"
    ],
    [
        "if one of the operands is an object array.",
        "if one of the operands is an object"
    ],
    [
        "An index which matches the order of iteration.",
        "An index which matches the"
    ],
    [
        "Structured view(s) of `operands` in memory, matching the reordered",
        "Structured view(s) of `operands` in memory,"
    ],
    [
        "and optimized iterator access pattern. Valid only before the iterator",
        "and optimized iterator access pattern. Valid only before the"
    ],
    [
        "When the ``multi_index`` flag was used, this property",
        "When the ``multi_index`` flag was"
    ],
    [
        "provides access to the index. Raises a ValueError if accessed",
        "provides access to the index. Raises a"
    ],
    [
        "The array(s) to be iterated over. Valid only before the iterator is",
        "The array(s) to be iterated over. Valid only"
    ],
    [
        "Shape tuple, the shape of the iterator.",
        "Shape tuple, the shape of the"
    ],
    [
        "Value of ``operands`` at current iteration. Normally, this is a",
        "Value of ``operands`` at current"
    ],
    [
        "tuple of array scalars, but if the flag ``external_loop`` is used,",
        "tuple of array scalars, but if the flag ``external_loop`` is"
    ],
    [
        "it is a tuple of one dimensional arrays.",
        "it is a tuple"
    ],
    [
        "`nditer` supersedes `flatiter`.  The iterator implementation behind",
        "`nditer` supersedes `flatiter`. The"
    ],
    [
        "`nditer` is also exposed by the NumPy C API.",
        "`nditer` is also exposed by the"
    ],
    [
        "The Python exposure supplies two iteration interfaces, one which follows",
        "The Python exposure supplies two iteration"
    ],
    [
        "the Python iterator protocol, and another which mirrors the C-style",
        "the Python iterator protocol, and another which mirrors"
    ],
    [
        "do-while pattern.  The native Python approach is better in most cases, but",
        "do-while pattern. The native Python approach"
    ],
    [
        "if you need the coordinates or index of an iterator, use the C-style pattern.",
        "if you need the coordinates or index"
    ],
    [
        "Here is how we might write an ``iter_add`` function, using the",
        "Here is how we might write an ``iter_add`` function,"
    ],
    [
        "...     it = np.nditer([x, y, out], [],",
        "... it = np.nditer([x, y, out],"
    ],
    [
        "...         for (a, b, c) in it:",
        "... for (a, b, c)"
    ],
    [
        "Here is the same function, but following the C-style pattern:",
        "Here is the same function, but following"
    ],
    [
        "...    it = np.nditer([x, y, out], [],",
        "... it = np.nditer([x,"
    ],
    [
        "Here is an example outer product function:",
        "Here is an example outer"
    ],
    [
        "...     it = np.nditer([x, y, out], ['external_loop'],",
        "... it = np.nditer([x, y, out],"
    ],
    [
        "...         for (a, b, c) in it:",
        "... for (a, b, c)"
    ],
    [
        "Here is an example function which operates like a \"lambda\" ufunc:",
        "Here is an example function which operates like"
    ],
    [
        "...    op = (kwargs.get('out',None),) + args",
        "... op = (kwargs.get('out',None),)"
    ],
    [
        "If operand flags ``\"writeonly\"`` or ``\"readwrite\"`` are used the",
        "If operand flags ``\"writeonly\"`` or ``\"readwrite\"``"
    ],
    [
        "operands may be views into the original data with the",
        "operands may be views into the original data"
    ],
    [
        "`WRITEBACKIFCOPY` flag. In this case `nditer` must be used as a",
        "`WRITEBACKIFCOPY` flag. In this case `nditer` must"
    ],
    [
        "context manager or the `nditer.close` method must be called before",
        "context manager or the `nditer.close` method must be"
    ],
    [
        "using the result. The temporary data will be written back to the",
        "using the result. The temporary data will be written"
    ],
    [
        "original data when the :meth:`~object.__exit__` function is called",
        "original data when the"
    ],
    [
        "It is important to note that once the iterator is exited, dangling",
        "It is important to note that once the iterator is exited,"
    ],
    [
        "references (like `x` in the example) may or may not share data with",
        "references (like `x` in the example) may or may not share"
    ],
    [
        "the original data `a`. If writeback semantics were active, i.e. if",
        "the original data `a`. If writeback semantics"
    ],
    [
        "`x.base.flags.writebackifcopy` is `True`, then exiting the iterator",
        "`x.base.flags.writebackifcopy` is `True`, then exiting the"
    ],
    [
        "will sever the connection between `x` and `a`, writing to `x` will",
        "will sever the connection between `x`"
    ],
    [
        "no longer write to `a`. If writeback semantics are not active, then",
        "no longer write to `a`. If writeback"
    ],
    [
        "`x.data` will still point at some part of `a.data`, and writing to",
        "`x.data` will still point at some part of `a.data`, and writing"
    ],
    [
        "Get a copy of the iterator in its current state.",
        "Get a copy of the"
    ],
    [
        "The array(s) to be iterated over. Valid only before the iterator is closed.",
        "The array(s) to be iterated over. Valid only before the iterator"
    ],
    [
        "Print the current state of the `nditer` instance and debug info to stdout.",
        "Print the current state of the `nditer`"
    ],
    [
        "When the \"external_loop\" was not used during construction, but",
        "When the \"external_loop\" was not used during construction,"
    ],
    [
        "is desired, this modifies the iterator to behave as if the flag",
        "is desired, this modifies the iterator to behave"
    ],
    [
        "Check whether iterations are left, and perform a single internal iteration",
        "Check whether iterations are left, and perform a"
    ],
    [
        "without returning the result.  Used in the C-style pattern do-while",
        "without returning the result. Used in the C-style pattern"
    ],
    [
        "pattern.  For an example, see `nditer`.",
        "pattern. For an example, see"
    ],
    [
        "Whether or not there are iterations left.",
        "Whether or not there are iterations"
    ],
    [
        "Removes axis `i` from the iterator. Requires that the flag \"multi_index\"",
        "Removes axis `i` from the iterator. Requires that"
    ],
    [
        "When the \"multi_index\" flag was specified, this removes it, allowing",
        "When the \"multi_index\" flag was"
    ],
    [
        "the internal iteration structure to be optimized further.",
        "the internal iteration structure to"
    ],
    [
        "Reset the iterator to its initial state.",
        "Reset the iterator to its initial"
    ],
    [
        "nested_iters(op, axes, flags=None, op_flags=None, op_dtypes=None, \\",
        "nested_iters(op, axes, flags=None,"
    ],
    [
        "Create nditers for use in nested loops",
        "Create nditers for use in"
    ],
    [
        "Create a tuple of `nditer` objects which iterate in nested loops over",
        "Create a tuple of `nditer` objects which iterate in nested"
    ],
    [
        "different axes of the op argument. The first iterator is used in the",
        "different axes of the op argument. The first iterator"
    ],
    [
        "outermost loop, the last in the innermost loop. Advancing one will change",
        "outermost loop, the last in the"
    ],
    [
        "the subsequent iterators to point at its new element.",
        "the subsequent iterators to point at"
    ],
    [
        "op : ndarray or sequence of array_like",
        "op : ndarray or"
    ],
    [
        "axes : list of list of int",
        "axes : list of list of"
    ],
    [
        "Each item is used as an \"op_axes\" argument to an nditer",
        "Each item is used as an \"op_axes\""
    ],
    [
        "flags, op_flags, op_dtypes, order, casting, buffersize (optional)",
        "flags, op_flags, op_dtypes, order, casting,"
    ],
    [
        "See `nditer` parameters of the same name",
        "See `nditer` parameters of"
    ],
    [
        "An nditer for each item in `axes`, outermost first",
        "An nditer for each item"
    ],
    [
        "Basic usage. Note how y is the \"flattened\" version of",
        "Basic usage. Note how y"
    ],
    [
        "Resolve all writeback semantics in writeable operands.",
        "Resolve all writeback semantics in writeable"
    ],
    [
        "Produce an object that mimics broadcasting.",
        "Produce an object that"
    ],
    [
        "Broadcast the input parameters against one another, and",
        "Broadcast the input parameters against one another,"
    ],
    [
        "return an object that encapsulates the result.",
        "return an object that"
    ],
    [
        "Amongst others, it has ``shape`` and ``nd`` properties, and",
        "Amongst others, it has ``shape`` and ``nd``"
    ],
    [
        "may be used as an iterator.",
        "may be used as"
    ],
    [
        "Manually adding two vectors, using broadcasting:",
        "Manually adding two vectors, using"
    ],
    [
        ">>> out.flat = [u+v for (u,v) in b]",
        ">>> out.flat = [u+v for"
    ],
    [
        "tuple of iterators along ``self``'s \"components.\"",
        "tuple of iterators"
    ],
    [
        "Returns a tuple of `numpy.flatiter` objects, one for each \"component\"",
        "Returns a tuple of `numpy.flatiter` objects, one for each"
    ],
    [
        "Number of dimensions of broadcasted result. Alias for `nd`.",
        "Number of dimensions of broadcasted"
    ],
    [
        "Number of dimensions of broadcasted result. For code intended for NumPy",
        "Number of dimensions of broadcasted result. For code intended for"
    ],
    [
        "Number of iterators possessed by the broadcasted result.",
        "Number of iterators possessed by the broadcasted"
    ],
    [
        "An array, any object exposing the array interface, an object whose",
        "An array, any object exposing the array interface, an"
    ],
    [
        "``__array__`` method returns an array, or any (nested) sequence.",
        "``__array__`` method returns an array, or any"
    ],
    [
        "The desired data-type for the array. If not given, NumPy will try to use",
        "The desired data-type for the array. If not given, NumPy will try to"
    ],
    [
        "a default ``dtype`` that can represent the values (by applying promotion",
        "a default ``dtype`` that can represent"
    ],
    [
        "If ``True`` (default), then the array data is copied. If ``None``,",
        "If ``True`` (default), then the array"
    ],
    [
        "a copy will only be made if ``__array__`` returns a copy, if obj is",
        "a copy will only be made if ``__array__`` returns a copy, if obj"
    ],
    [
        "a nested sequence, or if a copy is needed to satisfy any of the other",
        "a nested sequence, or if a copy is needed to satisfy any"
    ],
    [
        "requirements (``dtype``, ``order``, etc.). Note that any copy of",
        "requirements (``dtype``, ``order``, etc.). Note that any"
    ],
    [
        "the data is shallow, i.e., for arrays with object dtype, the new",
        "the data is shallow, i.e., for arrays with object"
    ],
    [
        "array will point to the same objects. See Examples for `ndarray.copy`.",
        "array will point to the same objects. See"
    ],
    [
        "For ``False`` it raises a ``ValueError`` if a copy cannot be avoided.",
        "For ``False`` it raises a ``ValueError``"
    ],
    [
        "order : {'K', 'A', 'C', 'F'}, optional",
        "order : {'K', 'A', 'C',"
    ],
    [
        "Specify the memory layout of the array. If object is not an array, the",
        "Specify the memory layout of the array. If object is not an"
    ],
    [
        "newly created array will be in C order (row major) unless 'F' is",
        "newly created array will be in C"
    ],
    [
        "specified, in which case it will be in Fortran order (column major).",
        "specified, in which case it will be in"
    ],
    [
        "If object is an array the following holds.",
        "If object is an array the"
    ],
    [
        "'K'   unchanged F & C order preserved, otherwise most similar order",
        "'K' unchanged F & C order preserved, otherwise most"
    ],
    [
        "'A'   unchanged F order if input is F and not C, otherwise C order",
        "'A' unchanged F order if input is F and not C, otherwise"
    ],
    [
        "When ``copy=None`` and a copy is made for other reasons, the result is",
        "When ``copy=None`` and a copy is made for"
    ],
    [
        "the same as if ``copy=True``, with some exceptions for 'A', see the",
        "the same as if ``copy=True``, with some exceptions for"
    ],
    [
        "Notes section. The default order is 'K'.",
        "Notes section. The default order"
    ],
    [
        "If True, then sub-classes will be passed-through, otherwise",
        "If True, then sub-classes"
    ],
    [
        "the returned array will be forced to be a base-class array (default).",
        "the returned array will be forced to be a base-class array"
    ],
    [
        "Specifies the minimum number of dimensions that the resulting",
        "Specifies the minimum number of dimensions that the"
    ],
    [
        "array should have.  Ones will be prepended to the shape as",
        "array should have. Ones will be prepended to the shape"
    ],
    [
        "An array object satisfying the specified requirements.",
        "An array object satisfying the specified"
    ],
    [
        "empty_like : Return an empty array with shape and type of input.",
        "empty_like : Return an empty array with shape"
    ],
    [
        "ones_like : Return an array of ones with shape and type of input.",
        "ones_like : Return an array of ones with shape and type of"
    ],
    [
        "zeros_like : Return an array of zeros with shape and type of input.",
        "zeros_like : Return an array of zeros with shape and type"
    ],
    [
        "full_like : Return a new array with shape of input filled with value.",
        "full_like : Return a new array with shape of input filled"
    ],
    [
        "empty : Return a new uninitialized array.",
        "empty : Return a new uninitialized"
    ],
    [
        "ones : Return a new array setting values to one.",
        "ones : Return a new array setting"
    ],
    [
        "zeros : Return a new array setting values to zero.",
        "zeros : Return a new array setting values"
    ],
    [
        "full : Return a new array of given shape filled with value.",
        "full : Return a new array of given"
    ],
    [
        "copy: Return an array copy of the given object.",
        "copy: Return an array copy of"
    ],
    [
        "When order is 'A' and ``object`` is an array in neither 'C' nor 'F' order,",
        "When order is 'A' and ``object`` is an array in"
    ],
    [
        "and a copy is forced by a change in dtype, then the order of the result is",
        "and a copy is forced by a change in dtype,"
    ],
    [
        "not necessarily 'C' as expected. This is likely a bug.",
        "not necessarily 'C' as expected. This"
    ],
    [
        "Data-type consisting of more than one element:",
        "Data-type consisting of more"
    ],
    [
        "asarray(a, dtype=None, order=None, *, device=None, copy=None, like=None)",
        "asarray(a, dtype=None, order=None, *,"
    ],
    [
        "Convert the input to an array.",
        "Convert the input"
    ],
    [
        "Input data, in any form that can be converted to an array.  This",
        "Input data, in any form that can"
    ],
    [
        "includes lists, lists of tuples, tuples, tuples of tuples, tuples",
        "includes lists, lists of tuples,"
    ],
    [
        "By default, the data-type is inferred from the input data.",
        "By default, the data-type is inferred from the"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A', 'K'},"
    ],
    [
        "Memory layout.  'A' and 'K' depend on the order of input array a.",
        "Memory layout. 'A' and 'K' depend on the order"
    ],
    [
        "'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise",
        "'A' (any) means 'F' if `a` is"
    ],
    [
        "The device on which to place the created array. Default: ``None``.",
        "The device on which to place"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be ``\"cpu\"`` if"
    ],
    [
        "If ``True``, then the object is copied. If ``None`` then the object is",
        "If ``True``, then the object is copied. If ``None`` then the"
    ],
    [
        "copied only if needed, i.e. if ``__array__`` returns a copy, if obj",
        "copied only if needed, i.e. if ``__array__``"
    ],
    [
        "is a nested sequence, or if a copy is needed to satisfy any of",
        "is a nested sequence, or if a copy"
    ],
    [
        "the other requirements (``dtype``, ``order``, etc.).",
        "the other requirements"
    ],
    [
        "For ``False`` it raises a ``ValueError`` if a copy cannot be avoided.",
        "For ``False`` it raises a ``ValueError`` if a"
    ],
    [
        "Array interpretation of ``a``.  No copy is performed if the input",
        "Array interpretation of ``a``. No copy is performed if the"
    ],
    [
        "is already an ndarray with matching dtype and order.  If ``a`` is a",
        "is already an ndarray with matching dtype and order. If ``a``"
    ],
    [
        "subclass of ndarray, a base class ndarray is returned.",
        "subclass of ndarray, a base"
    ],
    [
        "asanyarray : Similar function which passes through subclasses.",
        "asanyarray : Similar function which"
    ],
    [
        "ascontiguousarray : Convert input to a contiguous array.",
        "ascontiguousarray : Convert input to a contiguous"
    ],
    [
        "asfortranarray : Convert input to an ndarray with column-major",
        "asfortranarray : Convert input to an ndarray"
    ],
    [
        "asarray_chkfinite : Similar function which checks input for NaNs and Infs.",
        "asarray_chkfinite : Similar function which checks input for NaNs and"
    ],
    [
        "fromiter : Create an array from an iterator.",
        "fromiter : Create an array from"
    ],
    [
        "fromfunction : Construct an array by executing a function on grid",
        "fromfunction : Construct an array by"
    ],
    [
        "Convert a list into an array:",
        "Convert a list into an"
    ],
    [
        "If `dtype` is set, array is copied only if dtype does not match:",
        "If `dtype` is set, array is copied"
    ],
    [
        "Contrary to `asanyarray`, ndarray subclasses are not passed through:",
        "Contrary to `asanyarray`, ndarray subclasses are not"
    ],
    [
        "asanyarray(a, dtype=None, order=None, *, device=None, copy=None, like=None)",
        "asanyarray(a, dtype=None, order=None, *,"
    ],
    [
        "Convert the input to an ndarray, but pass ndarray subclasses through.",
        "Convert the input to an ndarray, but pass ndarray subclasses"
    ],
    [
        "Input data, in any form that can be converted to an array.  This",
        "Input data, in any form that can be converted to an array."
    ],
    [
        "includes scalars, lists, lists of tuples, tuples, tuples of tuples,",
        "includes scalars, lists, lists of tuples,"
    ],
    [
        "By default, the data-type is inferred from the input data.",
        "By default, the data-type is inferred from"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F',"
    ],
    [
        "Memory layout.  'A' and 'K' depend on the order of input array a.",
        "Memory layout. 'A' and 'K' depend on the order of input"
    ],
    [
        "'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise",
        "'A' (any) means 'F' if `a` is Fortran"
    ],
    [
        "The device on which to place the created array. Default: ``None``.",
        "The device on which to place the created array."
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so"
    ],
    [
        "If ``True``, then the object is copied. If ``None`` then the object is",
        "If ``True``, then the object is copied. If"
    ],
    [
        "copied only if needed, i.e. if ``__array__`` returns a copy, if obj",
        "copied only if needed, i.e. if ``__array__`` returns"
    ],
    [
        "is a nested sequence, or if a copy is needed to satisfy any of",
        "is a nested sequence, or if a copy is needed to satisfy"
    ],
    [
        "the other requirements (``dtype``, ``order``, etc.).",
        "the other requirements (``dtype``, ``order``,"
    ],
    [
        "For ``False`` it raises a ``ValueError`` if a copy cannot be avoided.",
        "For ``False`` it raises a ``ValueError``"
    ],
    [
        "out : ndarray or an ndarray subclass",
        "out : ndarray or"
    ],
    [
        "Array interpretation of `a`.  If `a` is an ndarray or a subclass",
        "Array interpretation of `a`. If `a` is an ndarray or a"
    ],
    [
        "of ndarray, it is returned as-is and no copy is performed.",
        "of ndarray, it is returned as-is and"
    ],
    [
        "asarray : Similar function which always returns ndarrays.",
        "asarray : Similar function"
    ],
    [
        "ascontiguousarray : Convert input to a contiguous array.",
        "ascontiguousarray : Convert input to a"
    ],
    [
        "asfortranarray : Convert input to an ndarray with column-major",
        "asfortranarray : Convert input to"
    ],
    [
        "asarray_chkfinite : Similar function which checks input for NaNs and",
        "asarray_chkfinite : Similar function which checks"
    ],
    [
        "fromiter : Create an array from an iterator.",
        "fromiter : Create an array from"
    ],
    [
        "fromfunction : Construct an array by executing a function on grid",
        "fromfunction : Construct an array by executing a"
    ],
    [
        "Convert a list into an array:",
        "Convert a list"
    ],
    [
        "Instances of `ndarray` subclasses are passed through as-is:",
        "Instances of `ndarray` subclasses are passed"
    ],
    [
        "dtype : str or dtype object, optional",
        "dtype : str or"
    ],
    [
        "Contiguous array of same shape and content as `a`, with type `dtype`",
        "Contiguous array of same shape and content"
    ],
    [
        "asfortranarray : Convert input to an ndarray with column-major",
        "asfortranarray : Convert input to an ndarray"
    ],
    [
        "require : Return an ndarray that satisfies requirements.",
        "require : Return an ndarray that"
    ],
    [
        "ndarray.flags : Information about the memory layout of the array.",
        "ndarray.flags : Information about the memory layout of"
    ],
    [
        "Calling ``ascontiguousarray`` makes a C-contiguous copy:",
        "Calling ``ascontiguousarray`` makes a"
    ],
    [
        "Now, starting with a C-contiguous array:",
        "Now, starting with a"
    ],
    [
        "Then, calling ``ascontiguousarray`` returns the same object:",
        "Then, calling ``ascontiguousarray`` returns the"
    ],
    [
        "dtype : str or dtype object, optional",
        "dtype : str or dtype object,"
    ],
    [
        "By default, the data-type is inferred from the input data.",
        "By default, the data-type is"
    ],
    [
        "The input `a` in Fortran, or column-major, order.",
        "The input `a` in"
    ],
    [
        "ascontiguousarray : Convert input to a contiguous (C order) array.",
        "ascontiguousarray : Convert input to a contiguous (C order)"
    ],
    [
        "asanyarray : Convert input to an ndarray with either row or",
        "asanyarray : Convert input to an ndarray with either"
    ],
    [
        "require : Return an ndarray that satisfies requirements.",
        "require : Return an ndarray that"
    ],
    [
        "ndarray.flags : Information about the memory layout of the array.",
        "ndarray.flags : Information about the memory"
    ],
    [
        "Calling ``asfortranarray`` makes a Fortran-contiguous copy:",
        "Calling ``asfortranarray`` makes"
    ],
    [
        "Now, starting with a Fortran-contiguous array:",
        "Now, starting with a"
    ],
    [
        "Then, calling ``asfortranarray`` returns the same object:",
        "Then, calling ``asfortranarray`` returns the"
    ],
    [
        "empty(shape, dtype=float, order='C', *, device=None, like=None)",
        "empty(shape, dtype=float, order='C', *, device=None,"
    ],
    [
        "Return a new array of given shape and type, without initializing entries.",
        "Return a new array of given shape and type,"
    ],
    [
        "shape : int or tuple of int",
        "shape : int or tuple of"
    ],
    [
        "order : {'C', 'F'}, optional, default: 'C'",
        "order : {'C', 'F'}, optional,"
    ],
    [
        "Whether to store multi-dimensional data in row-major",
        "Whether to store multi-dimensional data"
    ],
    [
        "(C-style) or column-major (Fortran-style) order in",
        "(C-style) or column-major"
    ],
    [
        "The device on which to place the created array. Default: ``None``.",
        "The device on which to place"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must"
    ],
    [
        "Array of uninitialized (arbitrary) data of the given shape, dtype, and",
        "Array of uninitialized (arbitrary) data of the given shape, dtype,"
    ],
    [
        "order.  Object arrays will be initialized to None.",
        "order. Object arrays will be initialized to"
    ],
    [
        "empty_like : Return an empty array with shape and type of input.",
        "empty_like : Return an empty array with shape and type of"
    ],
    [
        "ones : Return a new array setting values to one.",
        "ones : Return a new array setting values"
    ],
    [
        "zeros : Return a new array setting values to zero.",
        "zeros : Return a new array"
    ],
    [
        "full : Return a new array of given shape filled with value.",
        "full : Return a new array of given shape filled with"
    ],
    [
        "Unlike other array creation functions (e.g. `zeros`, `ones`, `full`),",
        "Unlike other array creation functions (e.g. `zeros`, `ones`,"
    ],
    [
        "`empty` does not initialize the values of the array, and may therefore be",
        "`empty` does not initialize the values of the array,"
    ],
    [
        "marginally faster. However, the values stored in the newly allocated array",
        "marginally faster. However, the values stored"
    ],
    [
        "are arbitrary. For reproducible behavior, be sure to set each element of",
        "are arbitrary. For reproducible behavior, be sure to set each element"
    ],
    [
        "Return a new scalar array of the given type initialized with obj.",
        "Return a new scalar array of the"
    ],
    [
        "This function is meant mainly for pickle support. `dtype` must be a",
        "This function is meant mainly for pickle support. `dtype` must be"
    ],
    [
        "valid data-type descriptor. If `dtype` corresponds to an object",
        "valid data-type descriptor. If `dtype` corresponds"
    ],
    [
        "descriptor, then `obj` can be any object, otherwise `obj` must be a",
        "descriptor, then `obj` can be any object, otherwise"
    ],
    [
        "string. If `obj` is not given, it will be interpreted as None for object",
        "string. If `obj` is not given, it will be interpreted as None for"
    ],
    [
        "type and as zeros for all other types.",
        "type and as zeros for all other"
    ],
    [
        "Return a new array of given shape and type, filled with zeros.",
        "Return a new array of given shape and type,"
    ],
    [
        "shape : int or tuple of ints",
        "shape : int or tuple"
    ],
    [
        "order : {'C', 'F'}, optional, default: 'C'",
        "order : {'C', 'F'},"
    ],
    [
        "Whether to store multi-dimensional data in row-major",
        "Whether to store multi-dimensional data"
    ],
    [
        "(C-style) or column-major (Fortran-style) order in",
        "(C-style) or column-major (Fortran-style) order"
    ],
    [
        "Array of zeros with the given shape, dtype, and order.",
        "Array of zeros with the given shape,"
    ],
    [
        "zeros_like : Return an array of zeros with shape and type of input.",
        "zeros_like : Return an array of zeros with shape"
    ],
    [
        "empty : Return a new uninitialized array.",
        "empty : Return a new uninitialized"
    ],
    [
        "ones : Return a new array setting values to one.",
        "ones : Return a new array setting"
    ],
    [
        "full : Return a new array of given shape filled with value.",
        "full : Return a new array of given shape filled"
    ],
    [
        "Set the internal dictionary that can look up an array type using a",
        "Set the internal dictionary that can look up an array type using"
    ],
    [
        "The data type of the array; default: float.  For binary input data,",
        "The data type of the array; default: float."
    ],
    [
        "the data must be in exactly this format. Most builtin numeric types are",
        "the data must be in exactly this"
    ],
    [
        "supported and extension types may be supported.",
        "supported and extension types"
    ],
    [
        "Read this number of `dtype` elements from the data.  If this is",
        "Read this number of `dtype` elements from the"
    ],
    [
        "negative (the default), the count will be determined from the",
        "negative (the default), the count will be determined"
    ],
    [
        "The string separating numbers in the data; extra whitespace between",
        "The string separating numbers in the data; extra"
    ],
    [
        "Passing ``sep=''``, the default, is deprecated since it will",
        "Passing ``sep=''``, the default, is"
    ],
    [
        "trigger the deprecated binary mode of this function. This mode",
        "trigger the deprecated binary mode"
    ],
    [
        "interprets `string` as binary bytes, rather than ASCII text with",
        "interprets `string` as binary bytes,"
    ],
    [
        "decimal numbers, an operation which is better spelt",
        "decimal numbers, an operation which"
    ],
    [
        "``frombuffer(string, dtype, count)``. If `string` contains unicode",
        "``frombuffer(string, dtype, count)``. If `string` contains"
    ],
    [
        "text, the binary mode of `fromstring` will first encode it into",
        "text, the binary mode of `fromstring` will first"
    ],
    [
        "If the string is not the correct size to satisfy the requested",
        "If the string is not the correct size to"
    ],
    [
        "Performs element-wise comparison of two string arrays using the",
        "Performs element-wise comparison of two string arrays using"
    ],
    [
        "cmp : {\"<\", \"<=\", \"==\", \">=\", \">\", \"!=\"}",
        "cmp : {\"<\", \"<=\", \"==\","
    ],
    [
        "If True, the spaces at the end of Strings are removed before the comparison.",
        "If True, the spaces at the end of Strings are removed before the"
    ],
    [
        "The output array of type Boolean with the same shape as a and b.",
        "The output array of type Boolean with"
    ],
    [
        "If at least one of `a` or `b` is a non-string array",
        "If at least one of `a` or `b`"
    ],
    [
        ">>> a = np.array([\"a\", \"b\", \"cde\"])",
        ">>> a = np.array([\"a\","
    ],
    [
        ">>> b = np.array([\"a\", \"a\", \"dec\"])",
        ">>> b = np.array([\"a\","
    ],
    [
        "An iterable object providing data for the array.",
        "An iterable object providing data"
    ],
    [
        "The data-type of the returned array.",
        "The data-type of the"
    ],
    [
        "Object and subarray dtypes are now supported (note that the final",
        "Object and subarray dtypes are now supported (note that the"
    ],
    [
        "which means all data is read.",
        "which means all data is"
    ],
    [
        "Specify `count` to improve performance.  It allows ``fromiter`` to",
        "Specify `count` to improve performance. It allows"
    ],
    [
        "pre-allocate the output array, instead of resizing it on demand.",
        "pre-allocate the output array, instead of resizing it"
    ],
    [
        "A carefully constructed subarray dtype will lead to higher dimensional",
        "A carefully constructed subarray dtype will lead to higher"
    ],
    [
        "Construct an array from data in a text or binary file.",
        "Construct an array from data in"
    ],
    [
        "A highly efficient way of reading binary data with a known data-type,",
        "A highly efficient way of reading"
    ],
    [
        "as well as parsing simply formatted text files.  Data written using the",
        "as well as parsing simply formatted text"
    ],
    [
        "`tofile` method can be read using this function.",
        "`tofile` method can be"
    ],
    [
        "file : file or str or Path",
        "file : file or"
    ],
    [
        "Data type of the returned array.",
        "Data type of the"
    ],
    [
        "For binary files, it is used to determine the size and byte-order",
        "For binary files, it is used to"
    ],
    [
        "of the items in the file.",
        "of the items in"
    ],
    [
        "Most builtin numeric types are supported and extension types may be supported.",
        "Most builtin numeric types are supported and extension types may"
    ],
    [
        "Separator between items if file is a text file.",
        "Separator between items if file is"
    ],
    [
        "Empty (\"\") separator means the file should be treated as binary.",
        "Empty (\"\") separator means the file"
    ],
    [
        "Spaces (\" \") in the separator match zero or more whitespace characters.",
        "Spaces (\" \") in the separator match zero or more"
    ],
    [
        "A separator consisting only of spaces must match at least one",
        "A separator consisting only of spaces must match at least"
    ],
    [
        "loadtxt : More flexible way of loading data from a text file.",
        "loadtxt : More flexible way of loading data"
    ],
    [
        "Do not rely on the combination of `tofile` and `fromfile` for",
        "Do not rely on the combination of `tofile` and `fromfile`"
    ],
    [
        "data storage, as the binary files generated are not platform",
        "data storage, as the binary"
    ],
    [
        "independent.  In particular, no byte-order or data-type information is",
        "independent. In particular, no byte-order"
    ],
    [
        "saved.  Data can be stored in the platform independent ``.npy`` format",
        "saved. Data can be stored in the platform"
    ],
    [
        "Save the raw data to disk:",
        "Save the raw data"
    ],
    [
        "Read the raw data from disk:",
        "Read the raw"
    ],
    [
        "The recommended way to store and load data:",
        "The recommended way to store and load"
    ],
    [
        "An object that exposes the buffer interface.",
        "An object that exposes the buffer"
    ],
    [
        "Data-type of the returned array; default: float.",
        "Data-type of the returned array;"
    ],
    [
        "Inverse of this operation, construct Python bytes from the raw data",
        "Inverse of this operation, construct Python bytes from the raw"
    ],
    [
        "If the buffer has data that is not in machine byte-order, this should",
        "If the buffer has data that is not in machine byte-order,"
    ],
    [
        "be specified as part of the data-type, e.g.::",
        "be specified as part of the"
    ],
    [
        "The data of the resulting array will not be byteswapped, but will be",
        "The data of the resulting array will not be"
    ],
    [
        "This function creates a view into the original object.  This should be safe",
        "This function creates a view into the"
    ],
    [
        "in general, but it may make sense to copy the result when the original",
        "in general, but it may make sense to copy the result when"
    ],
    [
        "Create a NumPy array from an object implementing the ``__dlpack__``",
        "Create a NumPy array from an object"
    ],
    [
        "protocol. Generally, the returned NumPy array is a read-only view",
        "protocol. Generally, the returned NumPy array is"
    ],
    [
        "A Python object that implements the ``__dlpack__`` and",
        "A Python object that implements"
    ],
    [
        "Device on which to place the created array. Default: ``None``.",
        "Device on which to place"
    ],
    [
        "Must be ``\"cpu\"`` if passed which may allow importing an array",
        "Must be ``\"cpu\"`` if passed which may allow importing"
    ],
    [
        "that is not already CPU available.",
        "that is not already CPU"
    ],
    [
        "Boolean indicating whether or not to copy the input. If ``True``,",
        "Boolean indicating whether or not to copy the input."
    ],
    [
        "the copy will be made. If ``False``, the function will never copy,",
        "the copy will be made. If ``False``, the function"
    ],
    [
        "and will raise ``BufferError`` in case a copy is deemed necessary.",
        "and will raise ``BufferError`` in case a copy is deemed"
    ],
    [
        "Passing it requests a copy from the exporter who may or may not",
        "Passing it requests a copy from the"
    ],
    [
        "If ``None``, the function will reuse the existing memory buffer if",
        "If ``None``, the function will reuse the"
    ],
    [
        "possible and copy otherwise. Default: ``None``.",
        "possible and copy otherwise."
    ],
    [
        "arange([start,] stop[, step,], dtype=None, *, device=None, like=None)",
        "arange([start,] stop[, step,], dtype=None, *,"
    ],
    [
        "Return evenly spaced values within a given interval.",
        "Return evenly spaced values within a"
    ],
    [
        "``arange`` can be called with a varying number of positional arguments:",
        "``arange`` can be called with a varying number"
    ],
    [
        "* ``arange(stop)``: Values are generated within the half-open interval",
        "* ``arange(stop)``: Values are generated within the half-open"
    ],
    [
        "* ``arange(start, stop)``: Values are generated within the half-open",
        "* ``arange(start, stop)``: Values are generated"
    ],
    [
        "* ``arange(start, stop, step)`` Values are generated within the half-open",
        "* ``arange(start, stop, step)`` Values are generated"
    ],
    [
        "interval ``[start, stop)``, with spacing between values given by",
        "interval ``[start, stop)``, with spacing between"
    ],
    [
        "For integer arguments the function is roughly equivalent to the Python",
        "For integer arguments the function is roughly"
    ],
    [
        "built-in :py:class:`range`, but returns an ndarray rather than a ``range``",
        "built-in :py:class:`range`, but returns an ndarray rather than a"
    ],
    [
        "See the Warning sections below for more information.",
        "See the Warning sections below for"
    ],
    [
        "start : integer or real, optional",
        "start : integer or real,"
    ],
    [
        "Start of interval.  The interval includes this value.  The default",
        "Start of interval. The interval includes"
    ],
    [
        "End of interval.  The interval does not include this value, except",
        "End of interval. The interval does not include this value,"
    ],
    [
        "in some cases where `step` is not an integer and floating point",
        "in some cases where `step` is not an integer"
    ],
    [
        "round-off affects the length of `out`.",
        "round-off affects the length"
    ],
    [
        "step : integer or real, optional",
        "step : integer or"
    ],
    [
        "Spacing between values.  For any output `out`, this is the distance",
        "Spacing between values. For any output `out`, this"
    ],
    [
        "The type of the output array.  If `dtype` is not given, infer the data",
        "The type of the output array. If `dtype` is not given,"
    ],
    [
        "type from the other input arguments.",
        "type from the other"
    ],
    [
        "The device on which to place the created array. Default: ``None``.",
        "The device on which to place the"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be ``\"cpu\"`` if"
    ],
    [
        "For floating point arguments, the length of the result is",
        "For floating point arguments, the length of the result"
    ],
    [
        "``ceil((stop - start)/step)``.  Because of floating point overflow,",
        "``ceil((stop - start)/step)``. Because of"
    ],
    [
        "this rule may result in the last element of `out` being greater",
        "this rule may result in the last element"
    ],
    [
        "The length of the output might not be numerically stable.",
        "The length of the output"
    ],
    [
        "Another stability issue is due to the internal implementation of",
        "Another stability issue is due to the internal"
    ],
    [
        "The actual step value used to populate the array is",
        "The actual step value used to populate the"
    ],
    [
        "``dtype(start + step) - dtype(start)`` and not `step`. Precision loss",
        "``dtype(start + step) - dtype(start)`` and not `step`."
    ],
    [
        "can occur here, due to casting or due to using floating points when",
        "can occur here, due to casting or due to"
    ],
    [
        "`start` is much larger than `step`. This can lead to unexpected",
        "`start` is much larger than `step`. This can lead to"
    ],
    [
        "In such cases, the use of `numpy.linspace` should be preferred.",
        "In such cases, the use of"
    ],
    [
        "The built-in :py:class:`range` generates :std:doc:`Python built-in integers",
        "The built-in :py:class:`range` generates :std:doc:`Python built-in"
    ],
    [
        "that have arbitrary size <python:c-api/long>`, while `numpy.arange`",
        "that have arbitrary size <python:c-api/long>`,"
    ],
    [
        "incorrect results for large integer values::",
        "incorrect results for"
    ],
    [
        "numpy.linspace : Evenly spaced numbers with careful handling of endpoints.",
        "numpy.linspace : Evenly spaced numbers with careful handling of"
    ],
    [
        "numpy.ogrid: Arrays of evenly spaced numbers in N-dimensions.",
        "numpy.ogrid: Arrays of evenly spaced numbers in"
    ],
    [
        "numpy.mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.",
        "numpy.mgrid: Grid-shaped arrays of evenly"
    ],
    [
        "Return the compile time NPY_VERSION (formerly called NDARRAY_VERSION) number.",
        "Return the compile time NPY_VERSION (formerly"
    ],
    [
        "Construct an empty array. Used by Pickles.",
        "Construct an empty array."
    ],
    [
        "Returns the data type with the smallest size and smallest scalar",
        "Returns the data type with the smallest size"
    ],
    [
        "The returned data type is always considered \"canonical\", this mainly",
        "The returned data type is"
    ],
    [
        "means that the promoted dtype will always be in native byte order.",
        "means that the promoted dtype will always be in native byte"
    ],
    [
        "This function is symmetric, but rarely associative.",
        "This function is symmetric, but"
    ],
    [
        "Please see `numpy.result_type` for additional information about promotion.",
        "Please see `numpy.result_type` for"
    ],
    [
        "length when given an integer or float dtype as one argument and a string",
        "length when given an integer or float dtype as one argument and"
    ],
    [
        "dtype as another argument. Previously it always returned the input string",
        "dtype as another argument. Previously it"
    ],
    [
        "dtype, even if it wasn't long enough to store the max integer/float value",
        "dtype, even if it wasn't long enough to store"
    ],
    [
        "NumPy now supports promotion for more structured dtypes.  It will now",
        "NumPy now supports promotion for more structured dtypes. It"
    ],
    [
        "remove unnecessary padding from a structure dtype and promote included",
        "remove unnecessary padding from a structure dtype and promote"
    ],
    [
        "An example of a non-associative case:",
        "An example of"
    ],
    [
        "*This documentation shadows that of the native python implementation of the `einsum` function,",
        "*This documentation shadows that of the native python implementation of"
    ],
    [
        "Evaluates the Einstein summation convention on the operands.",
        "Evaluates the Einstein summation convention"
    ],
    [
        "Using the Einstein summation convention, many common multi-dimensional,",
        "Using the Einstein summation convention,"
    ],
    [
        "linear algebraic array operations can be represented in a simple fashion.",
        "linear algebraic array operations can be represented"
    ],
    [
        "In *implicit* mode `einsum` computes these values.",
        "In *implicit* mode `einsum`"
    ],
    [
        "In *explicit* mode, `einsum` provides further flexibility to compute",
        "In *explicit* mode, `einsum` provides further flexibility to"
    ],
    [
        "other array operations that might not be considered classical Einstein",
        "other array operations that might not be"
    ],
    [
        "summation operations, by disabling, or forcing summation over specified",
        "summation operations, by disabling, or forcing summation"
    ],
    [
        "See the notes and examples for clarification.",
        "See the notes and"
    ],
    [
        "Specifies the subscripts for summation as comma separated list of",
        "Specifies the subscripts for summation as comma"
    ],
    [
        "subscript labels. An implicit (classical Einstein summation)",
        "subscript labels. An implicit (classical Einstein"
    ],
    [
        "calculation is performed unless the explicit indicator '->' is",
        "calculation is performed unless the"
    ],
    [
        "included as well as subscript labels of the precise output form.",
        "included as well as subscript labels of the"
    ],
    [
        "These are the arrays for the operation.",
        "These are the arrays for"
    ],
    [
        "If provided, the calculation is done into this array.",
        "If provided, the calculation is"
    ],
    [
        "If provided, forces the calculation to use the data type specified.",
        "If provided, forces the calculation to use the data type"
    ],
    [
        "Note that you may have to also give a more liberal `casting`",
        "Note that you may have to also"
    ],
    [
        "parameter to allow the conversions. Default is None.",
        "parameter to allow the conversions. Default is"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A', 'K'},"
    ],
    [
        "Controls the memory layout of the output. 'C' means it should",
        "Controls the memory layout of the output. 'C' means it"
    ],
    [
        "be C contiguous. 'F' means it should be Fortran contiguous,",
        "be C contiguous. 'F' means it should be Fortran"
    ],
    [
        "'A' means it should be 'F' if the inputs are all 'F', 'C' otherwise.",
        "'A' means it should be 'F' if"
    ],
    [
        "'K' means it should be as close to the layout of the inputs as",
        "'K' means it should be as close"
    ],
    [
        "is possible, including arbitrarily permuted axes.",
        "is possible, including arbitrarily"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe',"
    ],
    [
        "Controls what kind of data casting may occur.  Setting this to",
        "Controls what kind of data casting may occur. Setting"
    ],
    [
        "'unsafe' is not recommended, as it can adversely affect accumulations.",
        "'unsafe' is not recommended, as it can adversely"
    ],
    [
        "* 'no' means the data types should not be cast at all.",
        "* 'no' means the data types should not be cast at"
    ],
    [
        "* 'equiv' means only byte-order changes are allowed.",
        "* 'equiv' means only byte-order changes"
    ],
    [
        "* 'safe' means only casts which can preserve values are allowed.",
        "* 'safe' means only casts which can preserve"
    ],
    [
        "* 'same_kind' means only safe casts or casts within a kind,",
        "* 'same_kind' means only safe casts or casts"
    ],
    [
        "* 'unsafe' means any data conversions may be done.",
        "* 'unsafe' means any data conversions"
    ],
    [
        "optimize : {False, True, 'greedy', 'optimal'}, optional",
        "optimize : {False, True, 'greedy', 'optimal'},"
    ],
    [
        "Controls if intermediate optimization should occur. No optimization",
        "Controls if intermediate optimization"
    ],
    [
        "will occur if False and True will default to the 'greedy' algorithm.",
        "will occur if False and True will default"
    ],
    [
        "Also accepts an explicit contraction list from the ``np.einsum_path``",
        "Also accepts an explicit contraction list from"
    ],
    [
        "function. See ``np.einsum_path`` for more details. Defaults to False.",
        "function. See ``np.einsum_path`` for more"
    ],
    [
        "The calculation based on the Einstein summation convention.",
        "The calculation based on the Einstein"
    ],
    [
        "einsum_path, dot, inner, outer, tensordot, linalg.multi_dot",
        "einsum_path, dot, inner, outer, tensordot,"
    ],
    [
        "The Einstein summation convention can be used to compute",
        "The Einstein summation convention can"
    ],
    [
        "many multi-dimensional, linear algebraic array operations. `einsum`",
        "many multi-dimensional, linear algebraic"
    ],
    [
        "provides a succinct way of representing these.",
        "provides a succinct way of representing"
    ],
    [
        "A non-exhaustive list of these operations,",
        "A non-exhaustive list"
    ],
    [
        "which can be computed by `einsum`, is shown below along with examples:",
        "which can be computed by `einsum`, is shown"
    ],
    [
        "* Trace of an array, :py:func:`numpy.trace`.",
        "* Trace of"
    ],
    [
        "* Matrix multiplication and dot product, :py:func:`numpy.matmul` :py:func:`numpy.dot`.",
        "* Matrix multiplication and dot"
    ],
    [
        "* Vector inner and outer products, :py:func:`numpy.inner` :py:func:`numpy.outer`.",
        "* Vector inner and"
    ],
    [
        "* Broadcasting, element-wise and scalar multiplication, :py:func:`numpy.multiply`.",
        "* Broadcasting, element-wise and"
    ],
    [
        "* Chained array operations, in efficient calculation order, :py:func:`numpy.einsum_path`.",
        "* Chained array operations, in efficient calculation"
    ],
    [
        "The subscripts string is a comma-separated list of subscript labels,",
        "The subscripts string is a comma-separated"
    ],
    [
        "where each label refers to a dimension of the corresponding operand.",
        "where each label refers to a"
    ],
    [
        "Whenever a label is repeated it is summed, so ``np.einsum('i,i', a, b)``",
        "Whenever a label is repeated it is"
    ],
    [
        "is equivalent to :py:func:`np.inner(a,b) <numpy.inner>`. If a label",
        "is equivalent to :py:func:`np.inner(a,b)"
    ],
    [
        "appears only once, it is not summed, so ``np.einsum('i', a)`` produces a",
        "appears only once, it is not summed, so"
    ],
    [
        "view of ``a`` with no changes. A further example ``np.einsum('ij,jk', a, b)``",
        "view of ``a`` with no changes. A further example"
    ],
    [
        "describes traditional matrix multiplication and is equivalent to",
        "describes traditional matrix multiplication"
    ],
    [
        ":py:func:`np.matmul(a,b) <numpy.matmul>`. Repeated subscript labels in one",
        ":py:func:`np.matmul(a,b) <numpy.matmul>`. Repeated subscript"
    ],
    [
        "operand take the diagonal. For example, ``np.einsum('ii', a)`` is equivalent",
        "operand take the diagonal. For"
    ],
    [
        "In *implicit mode*, the chosen subscripts are important",
        "In *implicit mode*, the chosen"
    ],
    [
        "since the axes of the output are reordered alphabetically.  This",
        "since the axes of the output are reordered alphabetically."
    ],
    [
        "``np.einsum('ji', a)`` takes its transpose. Additionally,",
        "``np.einsum('ji', a)`` takes its transpose."
    ],
    [
        "``np.einsum('ij,jk', a, b)`` returns a matrix multiplication, while,",
        "``np.einsum('ij,jk', a, b)`` returns"
    ],
    [
        "``np.einsum('ij,jh', a, b)`` returns the transpose of the",
        "``np.einsum('ij,jh', a, b)`` returns"
    ],
    [
        "multiplication since subscript 'h' precedes subscript 'i'.",
        "multiplication since subscript 'h' precedes subscript"
    ],
    [
        "In *explicit mode* the output can be directly controlled by",
        "In *explicit mode* the output can be"
    ],
    [
        "specifying output subscript labels.  This requires the",
        "specifying output subscript labels."
    ],
    [
        "identifier '->' as well as the list of output subscript labels.",
        "identifier '->' as well as the list of"
    ],
    [
        "This feature increases the flexibility of the function since",
        "This feature increases the flexibility of the"
    ],
    [
        "summing can be disabled or forced when required. The call",
        "summing can be disabled or"
    ],
    [
        "``np.einsum('i->', a)`` is like :py:func:`np.sum(a) <numpy.sum>`",
        "``np.einsum('i->', a)`` is like"
    ],
    [
        "The difference is that `einsum` does not allow broadcasting by default.",
        "The difference is that `einsum` does not allow broadcasting"
    ],
    [
        "Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies the",
        "Additionally ``np.einsum('ij,jh->ih', a, b)`` directly"
    ],
    [
        "order of the output subscript labels and therefore returns matrix",
        "order of the output subscript labels"
    ],
    [
        "multiplication, unlike the example above in implicit mode.",
        "multiplication, unlike the example above"
    ],
    [
        "To enable and control broadcasting, use an ellipsis.  Default",
        "To enable and control broadcasting,"
    ],
    [
        "NumPy-style broadcasting is done by adding an ellipsis",
        "NumPy-style broadcasting is done by"
    ],
    [
        "to the left of each term, like ``np.einsum('...ii->...i', a)``.",
        "to the left of each term,"
    ],
    [
        "To take the trace along the first and last axes,",
        "To take the trace along the"
    ],
    [
        "you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix",
        "you can do ``np.einsum('i...i', a)``,"
    ],
    [
        "product with the left-most indices instead of rightmost, one can do",
        "product with the left-most indices instead of rightmost, one can"
    ],
    [
        "When there is only one operand, no axes are summed, and no output",
        "When there is only one operand, no axes are summed, and no"
    ],
    [
        "parameter is provided, a view into the operand is returned instead",
        "parameter is provided, a view into the operand"
    ],
    [
        "of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``",
        "of a new array. Thus, taking the diagonal"
    ],
    [
        "`einsum` also provides an alternative way to provide the subscripts",
        "`einsum` also provides an alternative way to"
    ],
    [
        "If the output shape is not provided in this format `einsum` will be",
        "If the output shape is not provided in this format"
    ],
    [
        "calculated in implicit mode, otherwise it will be performed explicitly.",
        "calculated in implicit mode, otherwise"
    ],
    [
        "The examples below have corresponding `einsum` calls with the two",
        "The examples below have corresponding `einsum` calls with the"
    ],
    [
        "Views returned from einsum are now writeable whenever the input array",
        "Views returned from einsum are now writeable"
    ],
    [
        "is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will now",
        "is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will"
    ],
    [
        "and ``np.einsum('ii->i', a)`` will return a writeable view of the diagonal",
        "and ``np.einsum('ii->i', a)`` will return a writeable view of the"
    ],
    [
        "Extract the diagonal (requires explicit form):",
        "Extract the diagonal"
    ],
    [
        "Sum over an axis (requires explicit form):",
        "Sum over an axis (requires"
    ],
    [
        "For higher dimensional arrays summing a single axis can be done with ellipsis:",
        "For higher dimensional arrays summing a single"
    ],
    [
        "Compute a matrix transpose, or reorder any number of axes:",
        "Compute a matrix transpose, or reorder any number"
    ],
    [
        "An array object represents a multidimensional, homogeneous array",
        "An array object represents"
    ],
    [
        "of fixed-size items.  An associated data-type object describes the",
        "of fixed-size items. An associated data-type"
    ],
    [
        "format of each element in the array (its byte-order, how many bytes it",
        "format of each element in the array (its byte-order, how"
    ],
    [
        "occupies in memory, whether it is an integer, a floating point number,",
        "occupies in memory, whether it is an integer, a floating point"
    ],
    [
        "Arrays should be constructed using `array`, `zeros` or `empty` (refer",
        "Arrays should be constructed using"
    ],
    [
        "to the See Also section below).  The parameters given here refer to",
        "to the See Also section below). The"
    ],
    [
        "a low-level method (`ndarray(...)`) for instantiating an array.",
        "a low-level method (`ndarray(...)`) for instantiating an"
    ],
    [
        "For more information, refer to the `numpy` module and examine the",
        "For more information, refer to the `numpy` module"
    ],
    [
        "methods and attributes of an array.",
        "methods and attributes of"
    ],
    [
        "(for the __new__ method; see Notes below)",
        "(for the __new__ method;"
    ],
    [
        "Any object that can be interpreted as a numpy data type.",
        "Any object that can be interpreted as a numpy"
    ],
    [
        "buffer : object exposing buffer interface, optional",
        "buffer : object exposing buffer interface,"
    ],
    [
        "Used to fill the array with data.",
        "Used to fill the array"
    ],
    [
        "Offset of array data in buffer.",
        "Offset of array data"
    ],
    [
        "strides : tuple of ints, optional",
        "strides : tuple of"
    ],
    [
        "Row-major (C-style) or column-major (Fortran-style) order.",
        "Row-major (C-style) or column-major (Fortran-style)"
    ],
    [
        "Describes the format of the elements in the array.",
        "Describes the format of the elements in"
    ],
    [
        "Dictionary containing information related to memory use, e.g.,",
        "Dictionary containing information related"
    ],
    [
        "Flattened version of the array as an iterator.  The iterator",
        "Flattened version of the array as an iterator."
    ],
    [
        "Number of elements in the array.",
        "Number of elements in the"
    ],
    [
        "The memory use of each array element in bytes.",
        "The memory use of each array"
    ],
    [
        "The total number of bytes required to store the array data,",
        "The total number of bytes required to"
    ],
    [
        "The step-size required to move from one element to the next in",
        "The step-size required to move from"
    ],
    [
        "Class containing properties of the array needed for interaction",
        "Class containing properties of the array needed"
    ],
    [
        "If the array is a view into another array, that array is its `base`",
        "If the array is a view into another array, that array is"
    ],
    [
        "(unless that array is also a view).  The `base` array is where the",
        "(unless that array is also a view). The `base` array"
    ],
    [
        "zeros : Create an array, each element of which is zero.",
        "zeros : Create an array, each element of which is"
    ],
    [
        "empty : Create an array, but leave its allocated memory unchanged (i.e.,",
        "empty : Create an array, but leave its allocated"
    ],
    [
        "numpy.typing.NDArray : An ndarray alias :term:`generic <generic type>`",
        "numpy.typing.NDArray : An ndarray"
    ],
    [
        "There are two modes of creating an array using ``__new__``:",
        "There are two modes of"
    ],
    [
        "No ``__init__`` method is needed because the array is fully initialized",
        "No ``__init__`` method is needed because"
    ],
    [
        "These examples illustrate the low-level `ndarray` constructor.  Refer",
        "These examples illustrate the low-level `ndarray` constructor."
    ],
    [
        "to the `See Also` section above for easier ways of constructing an",
        "to the `See Also` section above for"
    ],
    [
        "DLPack Protocol: Part of the Array API.",
        "DLPack Protocol: Part of"
    ],
    [
        "DLPack Protocol: Part of the Array API.",
        "DLPack Protocol: Part of"
    ],
    [
        "Base object if memory is from some other object.",
        "Base object if memory is from"
    ],
    [
        "The base of an array that owns its memory is None:",
        "The base of an array that owns its"
    ],
    [
        "Slicing creates a view, whose memory is shared with x:",
        "Slicing creates a view, whose memory is shared with"
    ],
    [
        "An object to simplify the interaction of the array with the ctypes",
        "An object to simplify the interaction of the"
    ],
    [
        "This attribute creates an object that makes it easier to use arrays",
        "This attribute creates an object that makes it easier to"
    ],
    [
        "when calling shared libraries with the ctypes module. The returned",
        "when calling shared libraries with the ctypes"
    ],
    [
        "object has, among others, data, shape, and strides attributes (see",
        "object has, among others, data,"
    ],
    [
        "Notes below) which themselves return ctypes objects that can be used",
        "Notes below) which themselves return ctypes objects that can be"
    ],
    [
        "as arguments to a shared library.",
        "as arguments to"
    ],
    [
        "Possessing attributes data, shape, strides, etc.",
        "Possessing attributes data, shape,"
    ],
    [
        "Below are the public attributes of this object which were documented",
        "Below are the public attributes of"
    ],
    [
        "in \"Guide to NumPy\" (we have omitted undocumented public attributes,",
        "in \"Guide to NumPy\" (we have omitted undocumented public"
    ],
    [
        "as well as documented private attributes):",
        "as well as documented private"
    ],
    [
        "If the ctypes module is not available, then the ctypes attribute",
        "If the ctypes module is not available, then"
    ],
    [
        "of array objects still returns something useful, but ctypes objects",
        "of array objects still returns something useful, but"
    ],
    [
        "are not returned and errors may be raised instead. In particular,",
        "are not returned and errors may be raised"
    ],
    [
        "the object will still have the ``as_parameter`` attribute which will",
        "the object will still have"
    ],
    [
        "return an integer equal to the data attribute.",
        "return an integer equal to the"
    ],
    [
        "\"\"\"Python buffer object pointing to the start of the array's data.\"\"\"))",
        "\"\"\"Python buffer object pointing to the"
    ],
    [
        "Setting ``arr.dtype`` is discouraged and may be deprecated in the",
        "Setting ``arr.dtype`` is discouraged and may be deprecated in"
    ],
    [
        "future.  Setting will replace the ``dtype`` without modifying the",
        "future. Setting will replace the"
    ],
    [
        "memory (see also `ndarray.view` and `ndarray.astype`).",
        "memory (see also `ndarray.view`"
    ],
    [
        "ndarray.astype : Cast the values contained in the array to a new data-type.",
        "ndarray.astype : Cast the values contained in the array to"
    ],
    [
        "ndarray.view : Create a view of the same data but a different data-type.",
        "ndarray.view : Create a view of the same data"
    ],
    [
        "The imaginary part of the array.",
        "The imaginary part"
    ],
    [
        "Length of one array element in bytes.",
        "Length of one array element"
    ],
    [
        "Information about the memory layout of the array.",
        "Information about the memory"
    ],
    [
        "The data is in a single, C-style contiguous segment.",
        "The data is in a single, C-style contiguous"
    ],
    [
        "The data is in a single, Fortran-style contiguous segment.",
        "The data is in a single,"
    ],
    [
        "The array owns the memory it uses or borrows it from another object.",
        "The array owns the memory it uses or borrows it from another"
    ],
    [
        "The data area can be written to.  Setting this to False locks",
        "The data area can be written to. Setting this"
    ],
    [
        "the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE",
        "the data, making it read-only. A"
    ],
    [
        "from its base array at creation time, but a view of a writeable",
        "from its base array at creation time,"
    ],
    [
        "array may be subsequently locked while the base array remains writeable.",
        "array may be subsequently locked while the base"
    ],
    [
        "(The opposite is not true, in that a view of a locked array may not",
        "(The opposite is not true, in that a view of"
    ],
    [
        "be made writeable.  However, currently, locking a base object does not",
        "be made writeable. However, currently, locking a"
    ],
    [
        "lock any views that already reference it, so under that circumstance it",
        "lock any views that already reference it,"
    ],
    [
        "is possible to alter the contents of a locked array via a previously",
        "is possible to alter the contents of a locked"
    ],
    [
        "created writeable view onto it.)  Attempting to change a non-writeable",
        "created writeable view onto it.) Attempting to change"
    ],
    [
        "The data and all elements are aligned appropriately for the hardware.",
        "The data and all elements are aligned"
    ],
    [
        "This array is a copy of some other array. The C-API function",
        "This array is a copy of some"
    ],
    [
        "PyArray_ResolveWritebackIfCopy must be called before deallocating",
        "PyArray_ResolveWritebackIfCopy must be called before"
    ],
    [
        "to the base array will be updated with the contents of this array.",
        "to the base array will be updated with the contents"
    ],
    [
        "BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.",
        "BEHAVED and F_CONTIGUOUS"
    ],
    [
        "The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),",
        "The `flags` object can be accessed dictionary-like (as in"
    ],
    [
        "or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag",
        "or by using lowercased attribute names (as in ``a.flags.writeable``). Short"
    ],
    [
        "names are only supported in dictionary access.",
        "names are only supported"
    ],
    [
        "Only the WRITEBACKIFCOPY, WRITEABLE, and ALIGNED flags can be",
        "Only the WRITEBACKIFCOPY, WRITEABLE, and ALIGNED"
    ],
    [
        "changed by the user, via direct assignment to the attribute or dictionary",
        "changed by the user, via direct assignment to"
    ],
    [
        "The array flags cannot be set arbitrarily:",
        "The array flags cannot be"
    ],
    [
        "- WRITEBACKIFCOPY can only be set ``False``.",
        "- WRITEBACKIFCOPY can only be set"
    ],
    [
        "- ALIGNED can only be set ``True`` if the data is truly aligned.",
        "- ALIGNED can only be set ``True`` if the data"
    ],
    [
        "- WRITEABLE can only be set ``True`` if the array owns its own memory",
        "- WRITEABLE can only be set ``True``"
    ],
    [
        "or the ultimate owner of the memory exposes a writeable buffer",
        "or the ultimate owner of the memory exposes a"
    ],
    [
        "Arrays can be both C-style and Fortran-style contiguous simultaneously.",
        "Arrays can be both C-style and Fortran-style"
    ],
    [
        "Even for contiguous arrays a stride for a given dimension",
        "Even for contiguous arrays a"
    ],
    [
        "or the array has no elements.",
        "or the array has no"
    ],
    [
        "This is a `numpy.flatiter` instance, which acts similarly to, but is not",
        "This is a `numpy.flatiter` instance, which acts similarly to, but"
    ],
    [
        "a subclass of, Python's built-in iterator object.",
        "a subclass of, Python's built-in"
    ],
    [
        "flatten : Return a copy of the array collapsed into one dimension.",
        "flatten : Return a copy of the array collapsed"
    ],
    [
        "Total bytes consumed by the elements of the array.",
        "Total bytes consumed by the elements"
    ],
    [
        "Does not include memory consumed by non-element attributes of the",
        "Does not include memory consumed by non-element attributes of"
    ],
    [
        "Memory consumed by the object itself without parents in case view.",
        "Memory consumed by the object itself without"
    ],
    [
        "This does include memory consumed by non-element attributes.",
        "This does include memory consumed by"
    ],
    [
        "The real part of the array.",
        "The real part"
    ],
    [
        "The shape property is usually used to get the current shape of an array,",
        "The shape property is usually used to get the current shape of an"
    ],
    [
        "but may also be used to reshape the array in-place by assigning a tuple of",
        "but may also be used to reshape the array in-place"
    ],
    [
        "array dimensions to it.  As with `numpy.reshape`, one of the new shape",
        "array dimensions to it. As with `numpy.reshape`, one of the new"
    ],
    [
        "the array and the remaining dimensions. Reshaping an array in-place will",
        "the array and the remaining dimensions. Reshaping an array"
    ],
    [
        "fail if a copy is required.",
        "fail if a"
    ],
    [
        "Setting ``arr.shape`` is discouraged and may be deprecated in the",
        "Setting ``arr.shape`` is discouraged and may"
    ],
    [
        "future.  Using `ndarray.reshape` is the preferred approach.",
        "future. Using `ndarray.reshape` is the preferred"
    ],
    [
        "AttributeError: Incompatible shape for in-place modification. Use",
        "AttributeError: Incompatible shape for in-place"
    ],
    [
        "`.reshape()` to make a copy with the desired shape.",
        "`.reshape()` to make a copy with the"
    ],
    [
        "numpy.reshape : Function similar to setting ``shape``.",
        "numpy.reshape : Function similar to"
    ],
    [
        "ndarray.reshape : Method similar to setting ``shape``.",
        "ndarray.reshape : Method similar to"
    ],
    [
        "Number of elements in the array.",
        "Number of elements"
    ],
    [
        "Equal to ``np.prod(a.shape)``, i.e., the product of the array's",
        "Equal to ``np.prod(a.shape)``, i.e., the"
    ],
    [
        "`a.size` returns a standard arbitrary precision Python integer. This",
        "`a.size` returns a standard arbitrary precision Python"
    ],
    [
        "may not be the case with other methods of obtaining the same value",
        "may not be the case with other methods"
    ],
    [
        "(like the suggested ``np.prod(a.shape)``, which returns an instance",
        "(like the suggested ``np.prod(a.shape)``, which"
    ],
    [
        "of ``np.int_``), and may be relevant if the value is used further in",
        "of ``np.int_``), and may be relevant if the value is used"
    ],
    [
        "calculations that may overflow a fixed size integer type.",
        "calculations that may overflow a"
    ],
    [
        "Tuple of bytes to step in each dimension when traversing an array.",
        "Tuple of bytes to step in each dimension when traversing"
    ],
    [
        "A more detailed explanation of strides can be found in",
        "A more detailed explanation of strides can be"
    ],
    [
        "Setting ``arr.strides`` is discouraged and may be deprecated in the",
        "Setting ``arr.strides`` is discouraged and may be"
    ],
    [
        "to create a new view of the same data in a safer way.",
        "to create a new view of the same"
    ],
    [
        "(known as a contiguous block of memory).  The strides of an array tell",
        "(known as a contiguous block of memory). The strides of"
    ],
    [
        "us how many bytes we have to skip in memory to move to the next position",
        "us how many bytes we have to skip in memory to move to"
    ],
    [
        "position in the next row.  As such, the strides for the array `x` will be",
        "position in the next row. As such, the strides for the"
    ],
    [
        ">>> offset = sum(i * x.strides)",
        ">>> offset ="
    ],
    [
        "View of the matrix transposed array.",
        "View of the matrix transposed"
    ],
    [
        "The matrix transpose is the transpose of the last two dimensions, even",
        "The matrix transpose is the transpose of the last two"
    ],
    [
        "if the array is of higher dimension.",
        "if the array is"
    ],
    [
        "For ``dtype`` parameter it returns a new reference to self if",
        "For ``dtype`` parameter it returns a new reference to self"
    ],
    [
        "``dtype`` is not given or it matches array's data type.",
        "``dtype`` is not given or it matches array's"
    ],
    [
        "A new array of provided data type is returned if ``dtype``",
        "A new array of provided data type is"
    ],
    [
        "is different from the current data type of the array.",
        "is different from the current data type of"
    ],
    [
        "For ``copy`` parameter it returns a new reference to self if",
        "For ``copy`` parameter it returns a"
    ],
    [
        "``copy=False`` or ``copy=None`` and copying isn't enforced by ``dtype``",
        "``copy=False`` or ``copy=None`` and copying isn't"
    ],
    [
        "parameter. The method returns a new array for ``copy=True``, regardless of",
        "parameter. The method returns a new array for"
    ],
    [
        "A more detailed explanation of the ``__array__`` interface",
        "A more detailed explanation of the"
    ],
    [
        "Present so subclasses can call super. Does nothing.",
        "Present so subclasses can call"
    ],
    [
        "Returns a view of `array` with the same type as self.",
        "Returns a view of `array` with"
    ],
    [
        "Used if :func:`copy.copy` is called on an array. Returns a copy of the array.",
        "Used if :func:`copy.copy` is called on an array. Returns a copy of the"
    ],
    [
        "Return a parametrized wrapper around the `~numpy.ndarray` type.",
        "Return a parametrized wrapper around the"
    ],
    [
        "numpy.typing.NDArray : An ndarray alias :term:`generic <generic type>`",
        "numpy.typing.NDArray : An ndarray"
    ],
    [
        "Used if :func:`copy.deepcopy` is called on an array.",
        "Used if :func:`copy.deepcopy` is"
    ],
    [
        "The `state` argument must be a sequence that contains the following",
        "The `state` argument must be a sequence that"
    ],
    [
        "a binary string with the data (or a list if 'a' is an object array)",
        "a binary string with the data (or a list"
    ],
    [
        "Returns True if all elements evaluate to True.",
        "Returns True if all elements evaluate"
    ],
    [
        "Refer to `numpy.all` for full documentation.",
        "Refer to `numpy.all`"
    ],
    [
        "Returns True if any of the elements of `a` evaluate to True.",
        "Returns True if any of the"
    ],
    [
        "Refer to `numpy.any` for full documentation.",
        "Refer to `numpy.any`"
    ],
    [
        "Return indices of the maximum values along the given axis.",
        "Return indices of the maximum values"
    ],
    [
        "Refer to `numpy.argmax` for full documentation.",
        "Refer to `numpy.argmax` for full"
    ],
    [
        "Return indices of the minimum values along the given axis.",
        "Return indices of the minimum values along"
    ],
    [
        "Refer to `numpy.argmin` for detailed documentation.",
        "Refer to `numpy.argmin`"
    ],
    [
        "Returns the indices that would sort this array.",
        "Returns the indices that would sort this"
    ],
    [
        "Refer to `numpy.argsort` for full documentation.",
        "Refer to `numpy.argsort` for full"
    ],
    [
        "Returns the indices that would partition this array.",
        "Returns the indices that would partition this"
    ],
    [
        "Refer to `numpy.argpartition` for full documentation.",
        "Refer to `numpy.argpartition`"
    ],
    [
        "Copy of the array, cast to a specified type.",
        "Copy of the array, cast to"
    ],
    [
        "Typecode or data-type to which the array is cast.",
        "Typecode or data-type to which the array"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F',"
    ],
    [
        "Controls the memory layout order of the result.",
        "Controls the memory layout order of"
    ],
    [
        "'C' means C order, 'F' means Fortran order, 'A'",
        "'C' means C order, 'F' means Fortran order,"
    ],
    [
        "means 'F' order if all the arrays are Fortran contiguous,",
        "means 'F' order if all the arrays are"
    ],
    [
        "'C' order otherwise, and 'K' means as close to the",
        "'C' order otherwise, and 'K' means as close"
    ],
    [
        "order the array elements appear in memory as possible.",
        "order the array elements appear in memory as"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe', 'same_kind',"
    ],
    [
        "Controls what kind of data casting may occur. Defaults to 'unsafe'",
        "Controls what kind of data casting"
    ],
    [
        "* 'no' means the data types should not be cast at all.",
        "* 'no' means the data types should not be cast at"
    ],
    [
        "* 'equiv' means only byte-order changes are allowed.",
        "* 'equiv' means only"
    ],
    [
        "* 'safe' means only casts which can preserve values are allowed.",
        "* 'safe' means only casts which can"
    ],
    [
        "* 'same_kind' means only safe casts or casts within a kind,",
        "* 'same_kind' means only safe casts or casts"
    ],
    [
        "* 'unsafe' means any data conversions may be done.",
        "* 'unsafe' means any data"
    ],
    [
        "If True, then sub-classes will be passed-through (default), otherwise",
        "If True, then sub-classes will be"
    ],
    [
        "the returned array will be forced to be a base-class array.",
        "the returned array will be forced to be a"
    ],
    [
        "By default, astype always returns a newly allocated array. If this",
        "By default, astype always returns a newly allocated array."
    ],
    [
        "is set to false, and the `dtype`, `order`, and `subok`",
        "is set to false, and the"
    ],
    [
        "requirements are satisfied, the input array is returned instead",
        "requirements are satisfied, the input array is"
    ],
    [
        "Unless `copy` is False and the other conditions for returning the input",
        "Unless `copy` is False and the other conditions for returning the"
    ],
    [
        "array are satisfied (see description for `copy` input parameter), `arr_t`",
        "array are satisfied (see description for `copy` input"
    ],
    [
        "is a new array of the same shape as the input array, with dtype, order",
        "is a new array of the same shape as the"
    ],
    [
        "When casting from complex to float or int. To avoid this,",
        "When casting from complex to float or int."
    ],
    [
        "Swap the bytes of the array elements",
        "Swap the bytes of the array"
    ],
    [
        "Toggle between low-endian and big-endian data representation by",
        "Toggle between low-endian and big-endian data"
    ],
    [
        "returning a byteswapped array, optionally swapped in-place.",
        "returning a byteswapped array, optionally swapped"
    ],
    [
        "Arrays of byte-strings are not swapped. The real and imaginary",
        "Arrays of byte-strings are not swapped."
    ],
    [
        "parts of a complex number are swapped individually.",
        "parts of a complex"
    ],
    [
        "If ``True``, swap bytes in-place, default is ``False``.",
        "If ``True``, swap bytes in-place,"
    ],
    [
        "The byteswapped array. If `inplace` is ``True``, this is",
        "The byteswapped array. If `inplace` is"
    ],
    [
        "Arrays of byte-strings are not swapped",
        "Arrays of byte-strings are"
    ],
    [
        "the same values but different representation in memory",
        "the same values but different representation"
    ],
    [
        "Use an index array to construct a new array from a set of choices.",
        "Use an index array to construct a new array"
    ],
    [
        "Refer to `numpy.choose` for full documentation.",
        "Refer to `numpy.choose`"
    ],
    [
        "Return an array whose values are limited to ``[min, max]``.",
        "Return an array whose values are limited to ``[min,"
    ],
    [
        "One of max or min must be given.",
        "One of max or min must be"
    ],
    [
        "Refer to `numpy.clip` for full documentation.",
        "Refer to `numpy.clip` for"
    ],
    [
        "Return selected slices of this array along given axis.",
        "Return selected slices of this array along given"
    ],
    [
        "Refer to `numpy.compress` for full documentation.",
        "Refer to `numpy.compress` for full"
    ],
    [
        "Refer to `numpy.conjugate` for full documentation.",
        "Refer to `numpy.conjugate`"
    ],
    [
        "Refer to `numpy.conjugate` for full documentation.",
        "Refer to `numpy.conjugate` for full"
    ],
    [
        "Return a copy of the array.",
        "Return a copy of"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A', 'K'},"
    ],
    [
        "Controls the memory layout of the copy. 'C' means C-order,",
        "Controls the memory layout of"
    ],
    [
        "'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,",
        "'F' means F-order, 'A' means 'F' if"
    ],
    [
        "'C' otherwise. 'K' means match the layout of `a` as closely",
        "'C' otherwise. 'K' means match the layout of"
    ],
    [
        "as possible. (Note that this function and :func:`numpy.copy` are very",
        "as possible. (Note that this"
    ],
    [
        "similar but have different default values for their order=",
        "similar but have different default values for their"
    ],
    [
        "arguments, and this function always passes sub-classes through.)",
        "arguments, and this function"
    ],
    [
        "numpy.copy : Similar function with different default behavior",
        "numpy.copy : Similar function"
    ],
    [
        "This function is the preferred method for creating an array copy.  The",
        "This function is the preferred method for"
    ],
    [
        "function :func:`numpy.copy` is similar, but it defaults to using order 'K',",
        "function :func:`numpy.copy` is similar, but it defaults to using order"
    ],
    [
        "and will not pass sub-classes through by default.",
        "and will not pass sub-classes through by"
    ],
    [
        "For arrays containing Python objects (e.g. dtype=object),",
        "For arrays containing Python objects (e.g."
    ],
    [
        "the copy is a shallow one. The new array will contain the",
        "the copy is a shallow one. The new array will"
    ],
    [
        "same object which may lead to surprises if that object can",
        "same object which may lead to"
    ],
    [
        "To ensure all elements within an ``object`` array are copied,",
        "To ensure all elements within an"
    ],
    [
        "Return the cumulative product of the elements along the given axis.",
        "Return the cumulative product of the elements along the given"
    ],
    [
        "Refer to `numpy.cumprod` for full documentation.",
        "Refer to `numpy.cumprod` for"
    ],
    [
        "Return the cumulative sum of the elements along the given axis.",
        "Return the cumulative sum of the elements along"
    ],
    [
        "Refer to `numpy.cumsum` for full documentation.",
        "Refer to `numpy.cumsum` for"
    ],
    [
        "read-only view instead of a copy as in previous NumPy versions.  In",
        "read-only view instead of a copy as"
    ],
    [
        "a future version the read-only restriction will be removed.",
        "a future version the read-only restriction will be"
    ],
    [
        "Refer to :func:`numpy.diagonal` for full documentation.",
        "Refer to :func:`numpy.diagonal` for full"
    ],
    [
        "Dump a pickle of the array to the specified file.",
        "Dump a pickle of the array to the specified"
    ],
    [
        "The array can be read back with pickle.load or numpy.load.",
        "The array can be read back with pickle.load or"
    ],
    [
        "A string naming the dump file.",
        "A string naming the"
    ],
    [
        "Returns the pickle of the array as a string.",
        "Returns the pickle of the array as a"
    ],
    [
        "pickle.loads will convert the string back to an array.",
        "pickle.loads will convert the string back to an"
    ],
    [
        "Fill the array with a scalar value.",
        "Fill the array with a"
    ],
    [
        "All elements of `a` will be assigned this value.",
        "All elements of `a` will be assigned this"
    ],
    [
        "Fill expects a scalar value and always behaves the same as assigning",
        "Fill expects a scalar value and"
    ],
    [
        "to a single array element.  The following is a rare example where this",
        "to a single array element. The following is a rare"
    ],
    [
        ">>> a = np.array([None, None], dtype=object)",
        ">>> a = np.array([None, None],"
    ],
    [
        "Where other forms of assignments will unpack the array being assigned:",
        "Where other forms of assignments will unpack"
    ],
    [
        "Return a copy of the array collapsed into one dimension.",
        "Return a copy of the array collapsed into one"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A',"
    ],
    [
        "'C' means to flatten in row-major (C-style) order.",
        "'C' means to flatten in row-major"
    ],
    [
        "'F' means to flatten in column-major (Fortran-",
        "'F' means to flatten"
    ],
    [
        "style) order. 'A' means to flatten in column-major",
        "style) order. 'A' means to flatten in"
    ],
    [
        "order if `a` is Fortran *contiguous* in memory,",
        "order if `a` is Fortran *contiguous*"
    ],
    [
        "row-major order otherwise. 'K' means to flatten",
        "row-major order otherwise. 'K' means to"
    ],
    [
        "`a` in the order the elements occur in memory.",
        "`a` in the order the elements occur"
    ],
    [
        "A copy of the input array, flattened to one dimension.",
        "A copy of the input array,"
    ],
    [
        "ravel : Return a flattened array.",
        "ravel : Return"
    ],
    [
        "Returns a field of the given array as a certain type.",
        "Returns a field of the given array"
    ],
    [
        "A field is a view of the array data with a given data-type. The values in",
        "A field is a view of the array data"
    ],
    [
        "the view are determined by the given type and the offset into the current",
        "the view are determined by the given type and the offset"
    ],
    [
        "array in bytes. The offset needs to be such that the view dtype fits in the",
        "array in bytes. The offset needs to be such that the view"
    ],
    [
        "The data type of the view. The dtype size of the view can not be larger",
        "The data type of the view. The dtype size of the view"
    ],
    [
        "than that of the array itself.",
        "than that of the array"
    ],
    [
        "Number of bytes to skip before beginning the element view.",
        "Number of bytes to skip before beginning"
    ],
    [
        "Copy an element of an array to a standard Python scalar and return it.",
        "Copy an element of an array to a"
    ],
    [
        "\\\\*args : Arguments (variable number and type)",
        "\\\\*args : Arguments (variable number"
    ],
    [
        "* none: in this case, the method only works for arrays",
        "* none: in this case, the method only works"
    ],
    [
        "copied into a standard Python scalar object and returned.",
        "copied into a standard Python scalar object and"
    ],
    [
        "* int_type: this argument is interpreted as a flat index into",
        "* int_type: this argument is interpreted as a"
    ],
    [
        "the array, specifying which element to copy and return.",
        "the array, specifying which element to copy and"
    ],
    [
        "* tuple of int_types: functions as does a single int_type argument,",
        "* tuple of int_types: functions as"
    ],
    [
        "except that the argument is interpreted as an nd-index into the",
        "except that the argument is interpreted as an nd-index into"
    ],
    [
        "z : Standard Python scalar object",
        "z : Standard Python"
    ],
    [
        "A copy of the specified element of the array as a suitable",
        "A copy of the specified element of the array as a"
    ],
    [
        "When the data type of `a` is longdouble or clongdouble, item() returns",
        "When the data type of `a` is longdouble"
    ],
    [
        "a scalar array object because there is no available Python scalar that",
        "a scalar array object because there"
    ],
    [
        "would not lose information. Void arrays return a buffer object for item(),",
        "would not lose information. Void arrays return a"
    ],
    [
        "unless fields are defined, in which case a tuple is returned.",
        "unless fields are defined, in which case a tuple is"
    ],
    [
        "`item` is very similar to a[args], except, instead of an array scalar,",
        "`item` is very similar to a[args], except, instead of an"
    ],
    [
        "a standard Python scalar is returned. This can be useful for speeding up",
        "a standard Python scalar is returned. This can be useful for speeding"
    ],
    [
        "access to elements of the array and doing arithmetic on elements of the",
        "access to elements of the array and doing arithmetic"
    ],
    [
        "For an array with object dtype, elements are returned as-is.",
        "For an array with object dtype, elements"
    ],
    [
        "a.max(axis=None, out=None, keepdims=False, initial=<no value>, where=True)",
        "a.max(axis=None, out=None, keepdims=False, initial=<no value>,"
    ],
    [
        "Return the maximum along a given axis.",
        "Return the maximum along"
    ],
    [
        "Refer to `numpy.amax` for full documentation.",
        "Refer to `numpy.amax` for full"
    ],
    [
        "a.mean(axis=None, dtype=None, out=None, keepdims=False, *, where=True)",
        "a.mean(axis=None, dtype=None, out=None, keepdims=False,"
    ],
    [
        "Returns the average of the array elements along given axis.",
        "Returns the average of the array elements along"
    ],
    [
        "Refer to `numpy.mean` for full documentation.",
        "Refer to `numpy.mean`"
    ],
    [
        "a.min(axis=None, out=None, keepdims=False, initial=<no value>, where=True)",
        "a.min(axis=None, out=None, keepdims=False, initial=<no"
    ],
    [
        "Return the minimum along a given axis.",
        "Return the minimum along a"
    ],
    [
        "Refer to `numpy.amin` for full documentation.",
        "Refer to `numpy.amin` for full"
    ],
    [
        "Return the indices of the elements that are non-zero.",
        "Return the indices of the elements that are"
    ],
    [
        "Refer to `numpy.nonzero` for full documentation.",
        "Refer to `numpy.nonzero` for full"
    ],
    [
        "Return the product of the array elements over the given axis",
        "Return the product of the array"
    ],
    [
        "Refer to `numpy.prod` for full documentation.",
        "Refer to `numpy.prod`"
    ],
    [
        "Set ``a.flat[n] = values[n]`` for all `n` in indices.",
        "Set ``a.flat[n] = values[n]`` for"
    ],
    [
        "Refer to `numpy.put` for full documentation.",
        "Refer to `numpy.put` for"
    ],
    [
        "Refer to `numpy.ravel` for full documentation.",
        "Refer to `numpy.ravel`"
    ],
    [
        "ndarray.flat : a flat iterator on the array.",
        "ndarray.flat : a flat iterator on"
    ],
    [
        "Refer to `numpy.repeat` for full documentation.",
        "Refer to `numpy.repeat` for"
    ],
    [
        "Returns an array containing the same data with a new shape.",
        "Returns an array containing the same data"
    ],
    [
        "Refer to `numpy.reshape` for full documentation.",
        "Refer to `numpy.reshape` for"
    ],
    [
        "Unlike the free function `numpy.reshape`, this method on `ndarray` allows",
        "Unlike the free function `numpy.reshape`, this method"
    ],
    [
        "the elements of the shape parameter to be passed in as separate arguments.",
        "the elements of the shape parameter to be"
    ],
    [
        "Change shape and size of array in-place.",
        "Change shape and size of"
    ],
    [
        "new_shape : tuple of ints, or `n` ints",
        "new_shape : tuple of ints, or"
    ],
    [
        "If False, reference count will not be checked. Default is True.",
        "If False, reference count will not be checked. Default is"
    ],
    [
        "If `a` does not own its own data or references or views to it exist,",
        "If `a` does not own its own data or references or views"
    ],
    [
        "and the data memory must be changed.",
        "and the data memory must"
    ],
    [
        "PyPy only: will always raise if the data memory must be changed, since",
        "PyPy only: will always raise if the data memory must"
    ],
    [
        "there is no reliable way to determine if references or views to it",
        "there is no reliable way to determine if references or"
    ],
    [
        "If the `order` keyword argument is specified. This behaviour is a",
        "If the `order` keyword argument is"
    ],
    [
        "resize : Return a new array with the specified shape.",
        "resize : Return a new array with"
    ],
    [
        "This reallocates space for the data area if necessary.",
        "This reallocates space for the data"
    ],
    [
        "Only contiguous arrays (data elements consecutive in memory) can be",
        "Only contiguous arrays (data elements consecutive in"
    ],
    [
        "The purpose of the reference count check is to make sure you",
        "The purpose of the reference count check is to"
    ],
    [
        "do not use this array as a buffer for another Python object and then",
        "do not use this array as a"
    ],
    [
        "reallocate the memory. However, reference counts can increase in",
        "reallocate the memory. However, reference"
    ],
    [
        "other ways so if you are sure that you have not shared the memory",
        "other ways so if you are sure"
    ],
    [
        "for this array with another Python object, then you may safely set",
        "for this array with another Python object, then you may safely"
    ],
    [
        "Shrinking an array: array is flattened (in the order that the data are",
        "Shrinking an array: array is flattened (in the order that the"
    ],
    [
        "stored in memory), resized, and reshaped:",
        "stored in memory), resized,"
    ],
    [
        "Enlarging an array: as above, but missing entries are filled with zeros:",
        "Enlarging an array: as above, but missing entries"
    ],
    [
        "ValueError: cannot resize an array that references or is referenced ...",
        "ValueError: cannot resize an array that"
    ],
    [
        "Return `a` with each element rounded to the given number of decimals.",
        "Return `a` with each element rounded to"
    ],
    [
        "Refer to `numpy.around` for full documentation.",
        "Refer to `numpy.around` for"
    ],
    [
        "Find indices where elements of v should be inserted in a to maintain order.",
        "Find indices where elements of v should be inserted"
    ],
    [
        "Put a value into a specified place in a field defined by a data-type.",
        "Put a value into a specified place in a field defined"
    ],
    [
        "Place `val` into `a`'s field defined by `dtype` and beginning `offset`",
        "Place `val` into `a`'s field defined by `dtype` and beginning"
    ],
    [
        "Value to be placed in field.",
        "Value to be"
    ],
    [
        "Data-type of the field in which to place `val`.",
        "Data-type of the field in"
    ],
    [
        "The number of bytes into the field at which to place `val`.",
        "The number of bytes into the field at which to"
    ],
    [
        "Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY,",
        "Set array flags WRITEABLE,"
    ],
    [
        "These Boolean-valued flags affect how numpy interprets the memory",
        "These Boolean-valued flags affect how numpy interprets the"
    ],
    [
        "area used by `a` (see Notes below). The ALIGNED flag can only",
        "area used by `a` (see Notes"
    ],
    [
        "be set to True if the data is actually aligned according to the type.",
        "be set to True if the data is"
    ],
    [
        "The WRITEBACKIFCOPY flag can never be set",
        "The WRITEBACKIFCOPY flag can"
    ],
    [
        "to True. The flag WRITEABLE can only be set to True if the array owns its",
        "to True. The flag WRITEABLE can only be set to"
    ],
    [
        "own memory, or the ultimate owner of the memory exposes a writeable buffer",
        "own memory, or the ultimate owner of the"
    ],
    [
        "interface, or is a string. (The exception for string is made so that",
        "interface, or is a string. (The exception"
    ],
    [
        "unpickling can be done without copying memory.)",
        "unpickling can be done without copying"
    ],
    [
        "Describes whether or not `a` can be written to.",
        "Describes whether or not `a`"
    ],
    [
        "Describes whether or not `a` is aligned properly for its type.",
        "Describes whether or not `a` is aligned properly for its"
    ],
    [
        "Describes whether or not `a` is a copy of another \"base\" array.",
        "Describes whether or not `a` is a"
    ],
    [
        "Array flags provide information about how the memory area used",
        "Array flags provide information about how the"
    ],
    [
        "in use, only three of which can be changed by the user:",
        "in use, only three of which can be changed"
    ],
    [
        "WRITEABLE (W) the data area can be written to;",
        "WRITEABLE (W) the data area"
    ],
    [
        "ALIGNED (A) the data and strides are aligned appropriately for the hardware",
        "ALIGNED (A) the data and strides are aligned appropriately for"
    ],
    [
        "WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced",
        "WRITEBACKIFCOPY (X) this array is a"
    ],
    [
        "by .base). When the C-API function PyArray_ResolveWritebackIfCopy is",
        "by .base). When the C-API"
    ],
    [
        "called, the base array will be updated with the contents of this array.",
        "called, the base array will be updated with"
    ],
    [
        "All flags can be accessed using the single (upper case) letter as well",
        "All flags can be accessed using the single (upper case)"
    ],
    [
        "ValueError: cannot set WRITEBACKIFCOPY flag to True",
        "ValueError: cannot set WRITEBACKIFCOPY flag"
    ],
    [
        "Sort an array in-place. Refer to `numpy.sort` for full documentation.",
        "Sort an array in-place. Refer"
    ],
    [
        "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional",
        "kind : {'quicksort', 'mergesort', 'heapsort', 'stable'},"
    ],
    [
        "Sorting algorithm. The default is 'quicksort'. Note that both 'stable'",
        "Sorting algorithm. The default is 'quicksort'. Note"
    ],
    [
        "and 'mergesort' use timsort under the covers and, in general, the",
        "and 'mergesort' use timsort under the covers and,"
    ],
    [
        "actual implementation will vary with datatype. The 'mergesort' option",
        "actual implementation will vary with datatype. The"
    ],
    [
        "order : str or list of str, optional",
        "order : str or"
    ],
    [
        "When `a` is an array with fields defined, this argument specifies",
        "When `a` is an array with fields defined,"
    ],
    [
        "which fields to compare first, second, etc.  A single field can",
        "which fields to compare first, second, etc. A"
    ],
    [
        "be specified as a string, and not all fields need be specified,",
        "be specified as a string, and"
    ],
    [
        "but unspecified fields will still be used, in the order in which",
        "but unspecified fields will still be used, in the order in"
    ],
    [
        "they come up in the dtype, to break ties.",
        "they come up in the"
    ],
    [
        "numpy.sort : Return a sorted copy of an array.",
        "numpy.sort : Return a sorted copy"
    ],
    [
        "numpy.lexsort : Indirect stable sort on multiple keys.",
        "numpy.lexsort : Indirect stable sort on"
    ],
    [
        "numpy.searchsorted : Find elements in sorted array.",
        "numpy.searchsorted : Find elements in sorted"
    ],
    [
        "See `numpy.sort` for notes on the different sorting algorithms.",
        "See `numpy.sort` for notes on the different sorting"
    ],
    [
        "Use the `order` keyword to specify a field to use when sorting a",
        "Use the `order` keyword to specify a field"
    ],
    [
        "Partially sorts the elements in the array in such a way that the value of",
        "Partially sorts the elements in the array in such a way that the value"
    ],
    [
        "the element in k-th position is in the position it would be in a sorted",
        "the element in k-th position is in the position it would be in a"
    ],
    [
        "array. In the output array, all elements smaller than the k-th element",
        "array. In the output array, all elements smaller than the"
    ],
    [
        "are located to the left of this element and all equal or greater are",
        "are located to the left of this element and all equal"
    ],
    [
        "located to its right. The ordering of the elements in the two partitions",
        "located to its right. The ordering of the elements in the two"
    ],
    [
        "on the either side of the k-th element in the output array is undefined.",
        "on the either side of the k-th element in the output array"
    ],
    [
        "kth : int or sequence of ints",
        "kth : int or sequence"
    ],
    [
        "Element index to partition by. The kth element value will be in its",
        "Element index to partition by. The kth element value will"
    ],
    [
        "final sorted position and all smaller elements will be moved before it",
        "final sorted position and all smaller elements will be moved before"
    ],
    [
        "and all equal or greater elements behind it.",
        "and all equal or"
    ],
    [
        "The order of all elements in the partitions is undefined.",
        "The order of all elements in the"
    ],
    [
        "If provided with a sequence of kth it will partition all elements",
        "If provided with a sequence of"
    ],
    [
        "indexed by kth of them into their sorted position at once.",
        "indexed by kth of them into their sorted position at"
    ],
    [
        "Passing booleans as index is deprecated.",
        "Passing booleans as"
    ],
    [
        "order : str or list of str, optional",
        "order : str or list of str,"
    ],
    [
        "When `a` is an array with fields defined, this argument specifies",
        "When `a` is an array with fields defined,"
    ],
    [
        "which fields to compare first, second, etc. A single field can",
        "which fields to compare first, second,"
    ],
    [
        "be specified as a string, and not all fields need to be specified,",
        "be specified as a string, and not all fields need"
    ],
    [
        "but unspecified fields will still be used, in the order in which",
        "but unspecified fields will still be"
    ],
    [
        "they come up in the dtype, to break ties.",
        "they come up in the dtype, to break"
    ],
    [
        "numpy.partition : Return a partitioned copy of an array.",
        "numpy.partition : Return a partitioned copy of"
    ],
    [
        "See ``np.partition`` for notes on the different algorithms.",
        "See ``np.partition`` for notes on the different"
    ],
    [
        "Remove axes of length one from `a`.",
        "Remove axes of length one from"
    ],
    [
        "Refer to `numpy.squeeze` for full documentation.",
        "Refer to `numpy.squeeze`"
    ],
    [
        "Returns the standard deviation of the array elements along given axis.",
        "Returns the standard deviation of the array"
    ],
    [
        "Refer to `numpy.std` for full documentation.",
        "Refer to `numpy.std` for"
    ],
    [
        "Return the sum of the array elements over the given axis.",
        "Return the sum of the array elements over the given"
    ],
    [
        "Refer to `numpy.sum` for full documentation.",
        "Refer to `numpy.sum`"
    ],
    [
        "Refer to `numpy.swapaxes` for full documentation.",
        "Refer to `numpy.swapaxes` for"
    ],
    [
        "Return an array formed from the elements of `a` at the given indices.",
        "Return an array formed from the elements of `a` at"
    ],
    [
        "Refer to `numpy.take` for full documentation.",
        "Refer to `numpy.take`"
    ],
    [
        "Write array to a file as text or binary (default).",
        "Write array to a file as text or"
    ],
    [
        "Data is always written in 'C' order, independent of the order of `a`.",
        "Data is always written in 'C' order, independent of the order"
    ],
    [
        "The data produced by this method can be recovered using the function",
        "The data produced by this method can be recovered using the"
    ],
    [
        "fid : file or str or Path",
        "fid : file or str or"
    ],
    [
        "An open file object, or a string containing a filename.",
        "An open file object, or a string"
    ],
    [
        "Separator between array items for text output.",
        "Separator between array items"
    ],
    [
        "If \"\" (empty), a binary file is written, equivalent to",
        "If \"\" (empty), a binary file is"
    ],
    [
        "Format string for text file output.",
        "Format string for text file"
    ],
    [
        "Each entry in the array is formatted to text by first converting",
        "Each entry in the array is"
    ],
    [
        "it to the closest Python type, and then using \"format\" % item.",
        "it to the closest Python type, and then using"
    ],
    [
        "This is a convenience function for quick storage of array data.",
        "This is a convenience function for quick storage of"
    ],
    [
        "Information on endianness and precision is lost, so this method is not a",
        "Information on endianness and precision is lost, so this method is not"
    ],
    [
        "good choice for files intended to archive data or transport data between",
        "good choice for files intended to archive data or transport"
    ],
    [
        "machines with different endianness. Some of these problems can be overcome",
        "machines with different endianness. Some of"
    ],
    [
        "by outputting the data as text files, at the expense of speed and file",
        "by outputting the data as text files, at the expense of"
    ],
    [
        "When fid is a file object, array contents are directly written to the",
        "When fid is a file object, array contents are directly written to"
    ],
    [
        "file, bypassing the file object's ``write`` method. As a result, tofile",
        "file, bypassing the file object's ``write`` method."
    ],
    [
        "cannot be used with files objects supporting compression (e.g., GzipFile)",
        "cannot be used with files"
    ],
    [
        "or file-like objects that do not support ``fileno()`` (e.g., BytesIO).",
        "or file-like objects that do not"
    ],
    [
        "Return the array as an ``a.ndim``-levels deep nested list of Python scalars.",
        "Return the array as an ``a.ndim``-levels deep nested list of"
    ],
    [
        "Return a copy of the array data as a (nested) Python list.",
        "Return a copy of the array data as a (nested)"
    ],
    [
        "Data items are converted to the nearest compatible builtin Python type, via",
        "Data items are converted to the nearest compatible builtin"
    ],
    [
        "not be a list at all, but a simple Python scalar.",
        "not be a list at all, but a simple"
    ],
    [
        "y : object, or list of object, or list of list of object, or ...",
        "y : object, or list of object, or list"
    ],
    [
        "The possibly nested list of array elements.",
        "The possibly nested list"
    ],
    [
        "The array may be recreated via ``a = np.array(a.tolist())``, although this",
        "The array may be recreated via ``a = np.array(a.tolist())``,"
    ],
    [
        "except that ``tolist`` changes numpy scalars to Python scalars:",
        "except that ``tolist`` changes numpy scalars"
    ],
    [
        "Construct Python bytes containing the raw data bytes in the array.",
        "Construct Python bytes containing the raw data bytes in"
    ],
    [
        "Constructs Python bytes showing a copy of the raw contents of",
        "Constructs Python bytes showing a copy of the raw contents"
    ],
    [
        "data memory. The bytes object is produced in C-order by default.",
        "data memory. The bytes object is produced in C-order by"
    ],
    [
        "This behavior is controlled by the ``order`` parameter.",
        "This behavior is controlled by the"
    ],
    [
        "order : {'C', 'F', 'A'}, optional",
        "order : {'C', 'F', 'A'},"
    ],
    [
        "Controls the memory layout of the bytes object. 'C' means C-order,",
        "Controls the memory layout of the bytes object. 'C' means"
    ],
    [
        "'F' means F-order, 'A' (short for *Any*) means 'F' if `a` is",
        "'F' means F-order, 'A' (short for"
    ],
    [
        "Fortran contiguous, 'C' otherwise. Default is 'C'.",
        "Fortran contiguous, 'C' otherwise."
    ],
    [
        "Python bytes exhibiting a copy of `a`'s raw data.",
        "Python bytes exhibiting a copy"
    ],
    [
        "Return the sum along diagonals of the array.",
        "Return the sum along"
    ],
    [
        "Refer to `numpy.trace` for full documentation.",
        "Refer to `numpy.trace`"
    ],
    [
        "Returns a view of the array with axes transposed.",
        "Returns a view of the array"
    ],
    [
        "Refer to `numpy.transpose` for full documentation.",
        "Refer to `numpy.transpose` for"
    ],
    [
        "axes : None, tuple of ints, or `n` ints",
        "axes : None, tuple of ints, or"
    ],
    [
        "* None or no argument: reverses the order of the axes.",
        "* None or no argument: reverses the order of"
    ],
    [
        "* tuple of ints: `i` in the `j`-th place in the tuple means that the",
        "* tuple of ints: `i` in the `j`-th place in the tuple means that"
    ],
    [
        "array's `i`-th axis becomes the transposed array's `j`-th axis.",
        "array's `i`-th axis becomes the transposed array's"
    ],
    [
        "* `n` ints: same as an n-tuple of the same ints (this form is",
        "* `n` ints: same as an n-tuple"
    ],
    [
        "intended simply as a \"convenience\" alternative to the tuple form).",
        "intended simply as a \"convenience\" alternative to the"
    ],
    [
        "View of the array with its axes suitably permuted.",
        "View of the array with"
    ],
    [
        "ndarray.T : Array property returning the array transposed.",
        "ndarray.T : Array property returning"
    ],
    [
        "ndarray.reshape : Give a new shape to an array without changing its data.",
        "ndarray.reshape : Give a new shape to an array without"
    ],
    [
        "Returns the variance of the array elements, along given axis.",
        "Returns the variance of the array elements, along given"
    ],
    [
        "Refer to `numpy.var` for full documentation.",
        "Refer to `numpy.var` for full"
    ],
    [
        "New view of array with the same data.",
        "New view of array"
    ],
    [
        "Passing None for ``dtype`` is different from omitting the parameter,",
        "Passing None for ``dtype`` is different from omitting"
    ],
    [
        "since the former invokes ``dtype(None)`` which is an alias for",
        "since the former invokes ``dtype(None)``"
    ],
    [
        "dtype : data-type or ndarray sub-class, optional",
        "dtype : data-type or"
    ],
    [
        "Omitting it results in the view having the same data-type as `a`.",
        "Omitting it results in the view having the"
    ],
    [
        "This argument can also be specified as an ndarray sub-class, which",
        "This argument can also be specified as"
    ],
    [
        "then specifies the type of the returned object (this is equivalent to",
        "then specifies the type of the returned object (this is equivalent"
    ],
    [
        "Type of the returned view, e.g., ndarray or matrix.  Again, omission",
        "Type of the returned view, e.g., ndarray or matrix."
    ],
    [
        "of the parameter results in type preservation.",
        "of the parameter results in type"
    ],
    [
        "``a.view()`` is used two different ways:",
        "``a.view()`` is used two different"
    ],
    [
        "``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view",
        "``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs"
    ],
    [
        "of the array's memory with a different data-type.  This can cause a",
        "of the array's memory with a different data-type."
    ],
    [
        "reinterpretation of the bytes of memory.",
        "reinterpretation of the bytes"
    ],
    [
        "returns an instance of `ndarray_subclass` that looks at the same array",
        "returns an instance of `ndarray_subclass` that looks"
    ],
    [
        "(same shape, dtype, etc.)  This does not cause a reinterpretation of the",
        "(same shape, dtype, etc.) This does not cause a"
    ],
    [
        "For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of",
        "For ``a.view(some_dtype)``, if ``some_dtype`` has"
    ],
    [
        "bytes per entry than the previous dtype (for example, converting a regular",
        "bytes per entry than the previous"
    ],
    [
        "array to a structured array), then the last axis of ``a`` must be",
        "array to a structured array), then the last"
    ],
    [
        "contiguous. This axis will be resized in the result.",
        "contiguous. This axis will be resized in the"
    ],
    [
        "Only the last axis needs to be contiguous. Previously, the entire array",
        "Only the last axis needs to be contiguous. Previously, the entire"
    ],
    [
        "Viewing array data using a different type and dtype:",
        "Viewing array data using a different type"
    ],
    [
        "Creating a view on a structured array so it can be used in calculations",
        "Creating a view on a structured array so it can be used in"
    ],
    [
        "Making changes to the view changes the underlying array",
        "Making changes to the view changes the underlying"
    ],
    [
        "Using a view to convert an array to a recarray:",
        "Using a view to convert an array"
    ],
    [
        "Views that change the dtype size (bytes per entry) should normally be",
        "Views that change the dtype size"
    ],
    [
        "avoided on arrays defined by slices, transposes, fortran-ordering, etc.:",
        "avoided on arrays defined by slices, transposes, fortran-ordering,"
    ],
    [
        "ValueError: To change to a dtype of a different size, the last axis must be contiguous",
        "ValueError: To change to a dtype of a different"
    ],
    [
        "However, views that change dtype are totally fine for arrays with a",
        "However, views that change dtype are totally fine for"
    ],
    [
        "contiguous last axis, even if the rest of the axes are not C-contiguous:",
        "contiguous last axis, even if the rest of the axes are not"
    ],
    [
        "frompyfunc(func, /, nin, nout, *[, identity])",
        "frompyfunc(func, /, nin,"
    ],
    [
        "Takes an arbitrary Python function and returns a NumPy ufunc.",
        "Takes an arbitrary Python function and"
    ],
    [
        "Can be used, for example, to add broadcasting to a built-in Python",
        "Can be used, for example, to"
    ],
    [
        "The number of objects returned by `func`.",
        "The number of objects"
    ],
    [
        "The value to use for the `~numpy.ufunc.identity` attribute of the resulting",
        "The value to use for the `~numpy.ufunc.identity` attribute of"
    ],
    [
        "object. If specified, this is equivalent to setting the underlying",
        "object. If specified, this is equivalent to setting the"
    ],
    [
        "If omitted, the identity is set to ``PyUFunc_None``. Note that this is",
        "If omitted, the identity is set to ``PyUFunc_None``."
    ],
    [
        "_not_ equivalent to setting the identity to ``None``, which implies the",
        "_not_ equivalent to setting the identity to ``None``, which"
    ],
    [
        "Returns a NumPy universal function (``ufunc``) object.",
        "Returns a NumPy universal function (``ufunc``)"
    ],
    [
        "vectorize : Evaluates pyfunc over input arrays using broadcasting rules of numpy.",
        "vectorize : Evaluates pyfunc over input arrays using broadcasting rules"
    ],
    [
        "The returned ufunc always returns PyObject arrays.",
        "The returned ufunc always returns"
    ],
    [
        "Use frompyfunc to add broadcasting to the Python function ``oct``:",
        "Use frompyfunc to add broadcasting to the Python"
    ],
    [
        "Add a docstring to a built-in obj if possible.",
        "Add a docstring to a built-in obj"
    ],
    [
        "If the obj already has a docstring raise a RuntimeError",
        "If the obj already has a docstring raise a"
    ],
    [
        "If this routine does not know how to add a docstring to the object",
        "If this routine does not know how"
    ],
    [
        "Replace the docstring for a ufunc with new_docstring.",
        "Replace the docstring for a ufunc with"
    ],
    [
        "This method will only work if the current docstring for",
        "This method will only work if the current"
    ],
    [
        "the ufunc is NULL. (At the C level, i.e. when ufunc->doc is NULL.)",
        "the ufunc is NULL. (At the C level, i.e."
    ],
    [
        "A ufunc whose current doc is NULL.",
        "A ufunc whose current doc is"
    ],
    [
        "The new docstring for the ufunc.",
        "The new docstring"
    ],
    [
        "This method allocates memory for new_docstring on",
        "This method allocates memory for"
    ],
    [
        "the heap. Technically this creates a memory leak, since this",
        "the heap. Technically this creates a"
    ],
    [
        "memory will not be reclaimed until the end of the program",
        "memory will not be reclaimed until the"
    ],
    [
        "even if the ufunc itself is removed. However this will only",
        "even if the ufunc itself is removed. However this will"
    ],
    [
        "be a problem if the user is repeatedly creating ufuncs with",
        "be a problem if the user is repeatedly creating ufuncs"
    ],
    [
        "no documentation, adding documentation via add_newdoc_ufunc,",
        "no documentation, adding"
    ],
    [
        "and then throwing away the ufunc.",
        "and then throwing away the"
    ],
    [
        "Return the name of the memory handler used by `a`. If not provided, return",
        "Return the name of the memory handler used by `a`. If"
    ],
    [
        "the name of the memory handler that will be used to allocate data for the",
        "the name of the memory handler that will be used to"
    ],
    [
        "next `ndarray` in this context. May return None if `a` does not own its",
        "next `ndarray` in this context. May return None if"
    ],
    [
        "memory, in which case you can traverse ``a.base`` for a memory handler.",
        "memory, in which case you can"
    ],
    [
        "Return the version of the memory handler used by `a`. If not provided,",
        "Return the version of the memory handler used by `a`. If"
    ],
    [
        "return the version of the memory handler that will be used to allocate data",
        "return the version of the memory handler that will"
    ],
    [
        "for the next `ndarray` in this context. May return None if `a` does not own",
        "for the next `ndarray` in this context. May return None if"
    ],
    [
        "its memory, in which case you can traverse ``a.base`` for a memory handler.",
        "its memory, in which case you can"
    ],
    [
        "Helper to convert one or more objects to arrays.  Integrates machinery",
        "Helper to convert one or more objects to arrays. Integrates"
    ],
    [
        "to deal with the ``result_type`` and ``__array_wrap__``.",
        "to deal with the ``result_type``"
    ],
    [
        "The reason for this is that e.g. ``result_type`` needs to convert to arrays",
        "The reason for this is that e.g. ``result_type`` needs to convert to"
    ],
    [
        "to find the ``dtype``.  But converting to an array before calling",
        "to find the ``dtype``. But converting to"
    ],
    [
        "``result_type`` would incorrectly \"forget\" whether it was a Python int,",
        "``result_type`` would incorrectly \"forget\" whether it was a Python"
    ],
    [
        "A tuple which indicates for each input whether it was a scalar that",
        "A tuple which indicates for each input whether it"
    ],
    [
        "converted via a protocol like ``__array__()``).",
        "converted via a protocol like"
    ],
    [
        "Return the inputs as arrays or scalars.",
        "Return the inputs as arrays or"
    ],
    [
        "subok : True or False, optional",
        "subok : True or False,"
    ],
    [
        "pyscalars : {\"convert\", \"preserve\", \"convert_if_no_array\"}, optional",
        "pyscalars : {\"convert\", \"preserve\", \"convert_if_no_array\"},"
    ],
    [
        "Python scalars.  As default, these are preserved unless all inputs",
        "Python scalars. As default, these are"
    ],
    [
        "are Python scalars.  \"convert\" enforces an array return.",
        "are Python scalars. \"convert\""
    ],
    [
        "Find the ``result_type`` just as ``np.result_type`` would, but taking",
        "Find the ``result_type`` just as"
    ],
    [
        "into account that the original inputs (before converting to an array) may",
        "into account that the original inputs (before converting"
    ],
    [
        "have been Python scalars with weak promotion.",
        "have been Python scalars"
    ],
    [
        "extra_dtype : dtype instance or class",
        "extra_dtype : dtype instance"
    ],
    [
        "An additional DType or dtype instance to promote (e.g. could be used",
        "An additional DType or dtype instance to promote (e.g. could"
    ],
    [
        "When ``True``, ensures a floating point (or complex) result replacing",
        "When ``True``, ensures a floating"
    ],
    [
        "Call ``__array_wrap__`` on ``arr`` if ``arr`` is not the same subclass",
        "Call ``__array_wrap__`` on ``arr`` if ``arr`` is not the same"
    ],
    [
        "as the input the ``__array_wrap__`` method was retrieved from.",
        "as the input the ``__array_wrap__``"
    ],
    [
        "The object to be wrapped. Normally an ndarray or subclass,",
        "The object to be wrapped."
    ],
    [
        "although for backward compatibility NumPy scalars are also accepted",
        "although for backward compatibility NumPy scalars are"
    ],
    [
        "(these will be converted to a NumPy array before being passed on to",
        "(these will be converted to a NumPy array"
    ],
    [
        "to_scalar : {True, False, None}, optional",
        "to_scalar : {True,"
    ],
    [
        "(with a fast-path for non-subclasses).  If ``False`` the result should",
        "(with a fast-path for non-subclasses). If ``False``"
    ],
    [
        "be an array-like (as ``__array_wrap__`` is free to return a non-array).",
        "be an array-like (as ``__array_wrap__`` is"
    ],
    [
        "By default (``None``), a scalar is returned if all inputs were scalar.",
        "By default (``None``), a scalar is"
    ],
    [
        "allocating the array data. Returns the currently set value.",
        "allocating the array data. Returns the currently"
    ],
    [
        "allocating the array data. Returns the previously set value.",
        "allocating the array data. Returns the previously"
    ],
    [
        "Functions that operate element by element on whole arrays.",
        "Functions that operate element by element"
    ],
    [
        "To see the documentation for a specific ufunc, use `info`.  For",
        "To see the documentation for a specific ufunc, use `info`."
    ],
    [
        "example, ``np.info(np.sin)``.  Because ufuncs are written in C",
        "example, ``np.info(np.sin)``. Because ufuncs are written in"
    ],
    [
        "(for speed) and linked into Python with NumPy's ufunc facility,",
        "(for speed) and linked into Python with NumPy's ufunc"
    ],
    [
        "Python's help() function finds this page whenever help() is called",
        "Python's help() function finds this page whenever help() is"
    ],
    [
        "A detailed explanation of ufuncs can be found in the docs for :ref:`ufuncs`.",
        "A detailed explanation of ufuncs can be found"
    ],
    [
        "**Calling ufuncs:** ``op(*x[, out], where=True, **kwargs)``",
        "**Calling ufuncs:** ``op(*x[, out], where=True,"
    ],
    [
        "Apply `op` to the arguments `*x` elementwise, broadcasting the arguments.",
        "Apply `op` to the arguments `*x`"
    ],
    [
        "out : ndarray, None, or tuple of ndarray and None, optional",
        "out : ndarray, None, or tuple of ndarray"
    ],
    [
        "Alternate array object(s) in which to put the result; if provided, it",
        "Alternate array object(s) in which to put the result; if provided,"
    ],
    [
        "must have a shape that the inputs broadcast to. A tuple of arrays",
        "must have a shape that the inputs broadcast to. A tuple"
    ],
    [
        "(possible only as a keyword argument) must have length equal to the",
        "(possible only as a keyword argument) must have length equal to"
    ],
    [
        "number of outputs; use None for uninitialized outputs to be",
        "number of outputs; use None for uninitialized outputs"
    ],
    [
        "This condition is broadcast over the input. At locations where the",
        "This condition is broadcast over the"
    ],
    [
        "condition is True, the `out` array will be set to the ufunc result.",
        "condition is True, the `out` array will be set to the ufunc"
    ],
    [
        "Elsewhere, the `out` array will retain its original value.",
        "Elsewhere, the `out` array will retain its original"
    ],
    [
        "Note that if an uninitialized `out` array is created via the default",
        "Note that if an uninitialized `out` array is created"
    ],
    [
        "``out=None``, locations within it where the condition is False will",
        "``out=None``, locations within it where the condition"
    ],
    [
        "For other keyword-only arguments, see the :ref:`ufunc docs <ufuncs.kwargs>`.",
        "For other keyword-only arguments, see the :ref:`ufunc"
    ],
    [
        "r : ndarray or tuple of ndarray",
        "r : ndarray or"
    ],
    [
        "`r` will have the shape that the arrays in `x` broadcast to; if `out` is",
        "`r` will have the shape that the arrays in `x` broadcast to; if"
    ],
    [
        "provided, it will be returned. If not, `r` will be allocated and",
        "provided, it will be returned. If not,"
    ],
    [
        "may contain uninitialized values. If the function has more than one",
        "may contain uninitialized values. If the function has more than"
    ],
    [
        "output, then the result will be a tuple of arrays.",
        "output, then the result will be a tuple of"
    ],
    [
        "Data attribute containing the identity element for the ufunc,",
        "Data attribute containing the identity element for"
    ],
    [
        "if it has one. If it does not, the attribute value is None.",
        "if it has one. If it does not, the attribute value is"
    ],
    [
        "Data attribute containing the number of arguments the ufunc takes, including",
        "Data attribute containing the number of"
    ],
    [
        "Typically this value will be one more than what you might expect",
        "Typically this value will be one"
    ],
    [
        "because all ufuncs take  the optional \"out\" argument.",
        "because all ufuncs take the optional \"out\""
    ],
    [
        "Data attribute containing the number of arguments the ufunc treats as input.",
        "Data attribute containing the number of arguments"
    ],
    [
        "Data attribute containing the number of arguments the ufunc treats as output.",
        "Data attribute containing the number of arguments the ufunc treats"
    ],
    [
        "Returns a list with types grouped input->output.",
        "Returns a list with types grouped"
    ],
    [
        "Data attribute listing the data-type \"Domain-Range\" groupings the ufunc can",
        "Data attribute listing the data-type \"Domain-Range\" groupings the"
    ],
    [
        "deliver. The data-types are given using the character codes.",
        "deliver. The data-types are given using the character"
    ],
    [
        "['??->?', 'bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', ...",
        "['??->?', 'bb->b', 'BB->B', 'hh->h', 'HH->H',"
    ],
    [
        "['bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l', ...",
        "['bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l',"
    ],
    [
        "['e->e', 'f->f', 'd->d', 'f->f', 'd->d', 'g->g', 'F->F', 'D->D', 'G->G', 'O->O']",
        "['e->e', 'f->f', 'd->d', 'f->f', 'd->d', 'g->g', 'F->F', 'D->D', 'G->G',"
    ],
    [
        "['bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l', ...",
        "['bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I',"
    ],
    [
        "Definition of the core elements a generalized ufunc operates on.",
        "Definition of the core elements a generalized ufunc operates"
    ],
    [
        "The signature determines how the dimensions of each input/output array",
        "The signature determines how the dimensions of"
    ],
    [
        "are split into core and loop dimensions:",
        "are split into core and loop"
    ],
    [
        "corresponding passed-in array, starting from the end of the shape tuple.",
        "corresponding passed-in array, starting from the end of the"
    ],
    [
        "exactly matching sizes, no broadcasting is performed.",
        "exactly matching sizes, no"
    ],
    [
        "dimensions are broadcast together, defining the loop dimensions.",
        "dimensions are broadcast together,"
    ],
    [
        "Generalized ufuncs are used internally in many linalg functions, and in",
        "Generalized ufuncs are used internally in many linalg functions,"
    ],
    [
        "the testing suite; the examples below are taken from these.",
        "the testing suite; the examples below are"
    ],
    [
        "For ufuncs that operate on scalars, the signature is None, which is",
        "For ufuncs that operate on scalars, the signature is None,"
    ],
    [
        "equivalent to '()' for every argument.",
        "equivalent to '()'"
    ],
    [
        "Reduces `array`'s dimension by one, by applying ufunc along one axis.",
        "Reduces `array`'s dimension by one, by applying"
    ],
    [
        "the result of iterating `j` over :math:`range(N_i)`, cumulatively applying",
        "the result of iterating `j` over :math:`range(N_i)`, cumulatively"
    ],
    [
        "For a one-dimensional array, reduce produces results equivalent to:",
        "For a one-dimensional array, reduce produces"
    ],
    [
        "For example, add.reduce() is equivalent to sum().",
        "For example, add.reduce() is equivalent"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or"
    ],
    [
        "Axis or axes along which a reduction is performed.",
        "Axis or axes along which a reduction"
    ],
    [
        "dimension of the input array. `axis` may be negative, in",
        "dimension of the input array."
    ],
    [
        "which case it counts from the last to the first axis.",
        "which case it counts from the last to the"
    ],
    [
        "If this is None, a reduction is performed over all the axes.",
        "If this is None, a reduction is performed over"
    ],
    [
        "If this is a tuple of ints, a reduction is performed on multiple",
        "If this is a tuple of ints, a"
    ],
    [
        "axes, instead of a single axis or all the axes as before.",
        "axes, instead of a single axis or all the axes as"
    ],
    [
        "For operations which are either not commutative or not associative,",
        "For operations which are either not commutative or not"
    ],
    [
        "doing a reduction over multiple axes is not well-defined. The",
        "doing a reduction over multiple"
    ],
    [
        "ufuncs do not currently raise an exception in this case, but will",
        "ufuncs do not currently raise an exception in this case,"
    ],
    [
        "likely do so in the future.",
        "likely do so in the"
    ],
    [
        "The data type used to perform the operation. Defaults to that of",
        "The data type used to perform"
    ],
    [
        "``out`` if given, and the data type of ``array`` otherwise (though",
        "``out`` if given, and the data type of"
    ],
    [
        "upcast to conserve precision for some cases, such as",
        "upcast to conserve precision for some"
    ],
    [
        "``numpy.add.reduce`` for integer or boolean input).",
        "``numpy.add.reduce`` for integer or boolean"
    ],
    [
        "out : ndarray, None, or tuple of ndarray and None, optional",
        "out : ndarray, None, or tuple"
    ],
    [
        "A location into which the result is stored. If not provided or None,",
        "A location into which the result is stored. If not"
    ],
    [
        "a freshly-allocated array is returned. For consistency with",
        "a freshly-allocated array is returned."
    ],
    [
        "``ufunc.__call__``, if given as a keyword, this may be wrapped in a",
        "``ufunc.__call__``, if given as a keyword, this may"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size"
    ],
    [
        "the result will broadcast correctly against the original `array`.",
        "the result will broadcast correctly against the original"
    ],
    [
        "The value with which to start the reduction.",
        "The value with which"
    ],
    [
        "If the ufunc has no identity or the dtype is object, this defaults",
        "If the ufunc has no identity or"
    ],
    [
        "to None - otherwise it defaults to ufunc.identity.",
        "to None - otherwise it defaults"
    ],
    [
        "If ``None`` is given, the first element of the reduction is used,",
        "If ``None`` is given, the first element of"
    ],
    [
        "and an error is thrown if the reduction is empty.",
        "and an error is thrown if the reduction"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of"
    ],
    [
        "A boolean array which is broadcasted to match the dimensions",
        "A boolean array which is"
    ],
    [
        "of `array`, and selects elements to include in the reduction. Note",
        "of `array`, and selects elements to include in the reduction."
    ],
    [
        "that for ufuncs like ``minimum`` that do not have an identity",
        "that for ufuncs like ``minimum`` that do not"
    ],
    [
        "defined, one has to pass in also ``initial``.",
        "defined, one has to pass in"
    ],
    [
        "The reduced array. If `out` was supplied, `r` is a reference to it.",
        "The reduced array. If `out` was supplied, `r` is"
    ],
    [
        "You can use the ``initial`` keyword argument to initialize the reduction",
        "You can use the ``initial`` keyword argument to initialize"
    ],
    [
        "with a different value, and ``where`` to select specific elements to include:",
        "with a different value, and ``where`` to select specific elements to"
    ],
    [
        "Allows reductions of empty arrays where they would normally fail, i.e.",
        "Allows reductions of empty arrays where they would normally"
    ],
    [
        "ValueError: zero-size array to reduction operation minimum which has no identity",
        "ValueError: zero-size array to reduction operation minimum which has"
    ],
    [
        "Accumulate the result of applying the operator to all elements.",
        "Accumulate the result of applying the"
    ],
    [
        "For a one-dimensional array, accumulate produces results equivalent to::",
        "For a one-dimensional array, accumulate produces results equivalent"
    ],
    [
        "For example, add.accumulate() is equivalent to np.cumsum().",
        "For example, add.accumulate() is equivalent to"
    ],
    [
        "For a multi-dimensional array, accumulate is applied along only one",
        "For a multi-dimensional array, accumulate"
    ],
    [
        "axis (axis zero by default; see Examples below) so repeated use is",
        "axis (axis zero by default; see Examples"
    ],
    [
        "necessary if one wants to accumulate over multiple axes.",
        "necessary if one wants to accumulate over multiple"
    ],
    [
        "The axis along which to apply the accumulation; default is zero.",
        "The axis along which to apply"
    ],
    [
        "The data-type used to represent the intermediate results. Defaults",
        "The data-type used to represent the intermediate"
    ],
    [
        "to the data-type of the output array if such is provided, or the",
        "to the data-type of the output array if such is provided, or"
    ],
    [
        "data-type of the input array if no output array is provided.",
        "data-type of the input array if no output array is"
    ],
    [
        "out : ndarray, None, or tuple of ndarray and None, optional",
        "out : ndarray, None, or tuple of ndarray"
    ],
    [
        "A location into which the result is stored. If not provided or None,",
        "A location into which the result is stored. If not provided"
    ],
    [
        "a freshly-allocated array is returned. For consistency with",
        "a freshly-allocated array is returned."
    ],
    [
        "``ufunc.__call__``, if given as a keyword, this may be wrapped in a",
        "``ufunc.__call__``, if given as a keyword,"
    ],
    [
        "The accumulated values. If `out` was supplied, `r` is a reference to",
        "The accumulated values. If `out` was supplied,"
    ],
    [
        "Performs a (local) reduce with specified slices over a single axis.",
        "Performs a (local) reduce with specified slices over a"
    ],
    [
        "For i in ``range(len(indices))``, `reduceat` computes",
        "For i in ``range(len(indices))``, `reduceat`"
    ],
    [
        "generalized \"row\" parallel to `axis` in the final result (i.e., in a",
        "generalized \"row\" parallel to `axis` in the final result (i.e., in"
    ],
    [
        "The shape of the output depends on the size of `indices`, and may be",
        "The shape of the output depends on the size"
    ],
    [
        "larger than `array` (this happens if ``len(indices) > array.shape[axis]``).",
        "larger than `array` (this happens if ``len(indices) >"
    ],
    [
        "Paired indices, comma separated (not colon), specifying slices to",
        "Paired indices, comma separated (not colon), specifying slices"
    ],
    [
        "The axis along which to apply the reduceat.",
        "The axis along which to"
    ],
    [
        "The data type used to perform the operation. Defaults to that of",
        "The data type used to perform the operation. Defaults to"
    ],
    [
        "``out`` if given, and the data type of ``array`` otherwise (though",
        "``out`` if given, and the data type of ``array`` otherwise"
    ],
    [
        "upcast to conserve precision for some cases, such as",
        "upcast to conserve precision for"
    ],
    [
        "``numpy.add.reduce`` for integer or boolean input).",
        "``numpy.add.reduce`` for integer or boolean"
    ],
    [
        "out : ndarray, None, or tuple of ndarray and None, optional",
        "out : ndarray, None, or tuple of ndarray and None,"
    ],
    [
        "A location into which the result is stored. If not provided or None,",
        "A location into which the result is stored."
    ],
    [
        "a freshly-allocated array is returned. For consistency with",
        "a freshly-allocated array is returned. For consistency"
    ],
    [
        "``ufunc.__call__``, if given as a keyword, this may be wrapped in a",
        "``ufunc.__call__``, if given as a keyword,"
    ],
    [
        "The reduced values. If `out` was supplied, `r` is a reference to",
        "The reduced values. If `out` was supplied, `r` is a reference"
    ],
    [
        "Don't be fooled by this attribute's name: `reduceat(array)` is not",
        "Don't be fooled by this attribute's name:"
    ],
    [
        "To take the running sum of four successive values:",
        "To take the running sum of four successive"
    ],
    [
        "Apply the ufunc `op` to all pairs (a, b) with a in `A` and b in `B`.",
        "Apply the ufunc `op` to all pairs (a, b) with a in `A`"
    ],
    [
        "Let ``M = A.ndim``, ``N = B.ndim``. Then the result, `C`, of",
        "Let ``M = A.ndim``, ``N = B.ndim``."
    ],
    [
        "``op.outer(A, B)`` is an array of dimension M + N such that:",
        "``op.outer(A, B)`` is an array of"
    ],
    [
        "For `A` and `B` one-dimensional, this is equivalent to::",
        "For `A` and `B` one-dimensional, this is"
    ],
    [
        "Arguments to pass on to the ufunc. Typically `dtype` or `out`.",
        "Arguments to pass on to the ufunc. Typically `dtype` or"
    ],
    [
        "See `ufunc` for a comprehensive overview of all available arguments.",
        "See `ufunc` for a comprehensive overview of all available"
    ],
    [
        "numpy.outer : A less powerful version of ``np.multiply.outer``",
        "numpy.outer : A less powerful version"
    ],
    [
        "primarily for compatibility with old code.",
        "primarily for compatibility with"
    ],
    [
        "tensordot : ``np.tensordot(a, b, axes=((), ()))`` and",
        "tensordot : ``np.tensordot(a, b,"
    ],
    [
        "``np.multiply.outer(a, b)`` behave same for all",
        "``np.multiply.outer(a, b)`` behave"
    ],
    [
        "Performs unbuffered in place operation on operand 'a' for elements",
        "Performs unbuffered in place operation on operand 'a' for"
    ],
    [
        "specified by 'indices'. For addition ufunc, this method is equivalent to",
        "specified by 'indices'. For addition ufunc, this method is"
    ],
    [
        "``a[indices] += b``, except that results are accumulated for elements that",
        "``a[indices] += b``, except that results are accumulated for"
    ],
    [
        "increment the first element once because of buffering, whereas",
        "increment the first element once because of buffering,"
    ],
    [
        "The array to perform in place operation on.",
        "The array to perform in place operation"
    ],
    [
        "Array like index object or slice object for indexing into first",
        "Array like index object or slice object for indexing into"
    ],
    [
        "operand. If first operand has multiple dimensions, indices can be a",
        "operand. If first operand has multiple dimensions,"
    ],
    [
        "tuple of array like index objects or slice objects.",
        "tuple of array like index objects"
    ],
    [
        "Second operand for ufuncs requiring two operands. Operand must be",
        "Second operand for ufuncs requiring two"
    ],
    [
        "broadcastable over first operand after indexing or slicing.",
        "broadcastable over first operand after indexing"
    ],
    [
        "and store results in first array:",
        "and store results"
    ],
    [
        "Find the dtypes NumPy will use for the operation.  Both input and",
        "Find the dtypes NumPy will use for the operation. Both"
    ],
    [
        "output dtypes are returned and may differ from those provided.",
        "output dtypes are returned and"
    ],
    [
        "any actual values.  The Python types ``int``, ``float``, and",
        "any actual values. The Python"
    ],
    [
        "``complex`` thus behave weak and should be passed for \"untyped\"",
        "``complex`` thus behave weak and should be passed for"
    ],
    [
        "dtypes : tuple of dtypes, None, or literal int, float, complex",
        "dtypes : tuple of dtypes, None, or literal int, float,"
    ],
    [
        "The input dtypes for each operand.  Output operands can be",
        "The input dtypes for each operand. Output"
    ],
    [
        "None, indicating that the dtype must be found.",
        "None, indicating that the dtype"
    ],
    [
        "signature : tuple of DTypes or None, optional",
        "signature : tuple of DTypes"
    ],
    [
        "If given, enforces exact DType (classes) of the specific operand.",
        "If given, enforces exact DType (classes) of"
    ],
    [
        "The ufunc ``dtype`` argument is equivalent to passing a tuple with",
        "The ufunc ``dtype`` argument is equivalent"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe',"
    ],
    [
        "The casting mode when casting is necessary.  This is identical to",
        "The casting mode when casting is"
    ],
    [
        "If given, the resolution assumes a reduce operation is happening",
        "If given, the resolution assumes a reduce"
    ],
    [
        "which slightly changes the promotion and type resolution rules.",
        "which slightly changes the promotion and type"
    ],
    [
        "for reductions (first input is also the output).",
        "for reductions (first input is"
    ],
    [
        "The default casting mode is \"same_kind\", however, as of",
        "The default casting mode is \"same_kind\", however,"
    ],
    [
        "The dtypes which NumPy would use for the calculation.  Note that",
        "The dtypes which NumPy would use for the calculation. Note"
    ],
    [
        "dtypes may not match the passed in ones (casting is necessary).",
        "dtypes may not match the passed in"
    ],
    [
        "This API requires passing dtypes, define them for convenience:",
        "This API requires passing dtypes,"
    ],
    [
        "The typical ufunc call does not pass an output dtype.  `numpy.add` has two",
        "The typical ufunc call does not pass an output dtype."
    ],
    [
        "inputs and one output, so leave the output as ``None`` (not provided):",
        "inputs and one output, so leave the output as"
    ],
    [
        "``resolve_dtypes`` supports \"weak\" handling for Python scalars by passing",
        "``resolve_dtypes`` supports \"weak\" handling for Python scalars by"
    ],
    [
        "See `numpy.ufunc.resolve_dtypes` for parameter information.  This",
        "See `numpy.ufunc.resolve_dtypes` for parameter"
    ],
    [
        "function is considered *unstable*.  You may use it, but the returned",
        "function is considered *unstable*. You may use it, but the"
    ],
    [
        "information is NumPy version specific and expected to change.",
        "information is NumPy version specific"
    ],
    [
        "Large API/ABI changes are not expected, but a new NumPy version is",
        "Large API/ABI changes are not expected,"
    ],
    [
        "expected to require updating code using this functionality.",
        "expected to require updating code"
    ],
    [
        "This function is designed to be used in conjunction with",
        "This function is designed to be used in conjunction"
    ],
    [
        "`numpy.ufunc._get_strided_loop`.  The calls are split to mirror the C API",
        "`numpy.ufunc._get_strided_loop`. The calls are split to mirror the C"
    ],
    [
        "PyCapsule with all necessary information to get access to low level",
        "PyCapsule with all necessary information to get"
    ],
    [
        "C calls.  See `numpy.ufunc._get_strided_loop` for more information.",
        "C calls. See `numpy.ufunc._get_strided_loop` for more"
    ],
    [
        "This function fills in the ``call_info`` capsule to include all",
        "This function fills in the ``call_info``"
    ],
    [
        "information necessary to call the low-level strided loop from NumPy.",
        "information necessary to call the low-level strided"
    ],
    [
        "fixed_strides : tuple of int or None, optional",
        "fixed_strides : tuple of"
    ],
    [
        "A tuple with fixed byte strides of all input arrays.  NumPy may use",
        "A tuple with fixed byte strides of"
    ],
    [
        "this information to find specialized loops, so any call must follow",
        "this information to find specialized loops, so any"
    ],
    [
        "the given stride.  Use ``None`` to indicate that the stride is not",
        "the given stride. Use ``None`` to indicate"
    ],
    [
        "known (or not fixed) for all calls.",
        "known (or not fixed) for"
    ],
    [
        "gives low-level access to the NumPy ufunc loops.",
        "gives low-level access to the NumPy"
    ],
    [
        "The first function does general preparation and returns the required",
        "The first function does general"
    ],
    [
        "information. It returns this as a C capsule with the version specific",
        "information. It returns this as a C capsule"
    ],
    [
        "/* Flag information (expected to change) */",
        "/* Flag information (expected to change)"
    ],
    [
        "npy_bool requires_pyapi;  /* GIL is required by loop */",
        "npy_bool requires_pyapi; /* GIL is required by loop"
    ],
    [
        "/* Loop doesn't set FPE flags; if not set check FPE flags */",
        "/* Loop doesn't set FPE flags; if"
    ],
    [
        "Note that the first call only fills in the ``context``.  The call to",
        "Note that the first call only fills in the"
    ],
    [
        "``_get_strided_loop`` fills in all other data.  The main thing to note is",
        "``_get_strided_loop`` fills in all other data. The"
    ],
    [
        "passed context as new first input and ``auxdata`` as (replaced) last.",
        "passed context as new first input"
    ],
    [
        "Only the ``strided_loop``signature is considered guaranteed stable",
        "Only the ``strided_loop``signature is"
    ],
    [
        "for NumPy bug-fix releases.  All other API is tied to the experimental",
        "for NumPy bug-fix releases. All other API is"
    ],
    [
        "The reason for the split call is that cast information is required to",
        "The reason for the split call is that cast information"
    ],
    [
        "decide what the fixed-strides will be.",
        "decide what the fixed-strides"
    ],
    [
        "NumPy ties the lifetime of the ``auxdata`` information to the capsule.",
        "NumPy ties the lifetime of the ``auxdata`` information"
    ],
    [
        "A numpy array is homogeneous, and contains elements described by a",
        "A numpy array is homogeneous, and contains elements"
    ],
    [
        "dtype object. A dtype object can be constructed from different",
        "dtype object. A dtype object"
    ],
    [
        "Object to be converted to a data type object.",
        "Object to be converted to a data"
    ],
    [
        "Add padding to the fields to match what a C compiler would output",
        "Add padding to the fields to match what a C compiler would"
    ],
    [
        "for a similar C-struct. Can be ``True`` only if `obj` is a dictionary",
        "for a similar C-struct. Can be ``True`` only"
    ],
    [
        "or a comma-separated string. If a struct dtype is being created,",
        "or a comma-separated string. If a struct dtype is"
    ],
    [
        "this also sets a sticky alignment flag ``isalignedstruct``.",
        "this also sets a sticky"
    ],
    [
        "Make a new copy of the data-type object. If ``False``, the result",
        "Make a new copy of the data-type object."
    ],
    [
        "may just be a reference to a built-in data-type object.",
        "may just be a reference"
    ],
    [
        "An optional dictionary with dtype metadata.",
        "An optional dictionary"
    ],
    [
        "Structured type, two fields: the first field contains an unsigned int, the",
        "Structured type, two fields: the first field contains an unsigned"
    ],
    [
        "Using dictionaries.  Two fields named 'gender' and 'age':",
        "Using dictionaries. Two fields named 'gender' and"
    ],
    [
        "The required alignment (bytes) of this data-type according to the compiler.",
        "The required alignment (bytes) of this data-type"
    ],
    [
        "More information is available in the C-API section of the manual.",
        "More information is available in the C-API section"
    ],
    [
        "A character indicating the byte-order of this data-type object.",
        "A character indicating the byte-order of"
    ],
    [
        "All built-in data-type objects have byteorder either '=' or '|'.",
        "All built-in data-type objects have byteorder either '='"
    ],
    [
        ">>> sys_is_le = sys.byteorder == 'little'",
        ">>> sys_is_le ="
    ],
    [
        ">>> native_code = '<' if sys_is_le else '>'",
        ">>> native_code = '<' if sys_is_le"
    ],
    [
        ">>> swapped_code = '>' if sys_is_le else '<'",
        ">>> swapped_code = '>' if sys_is_le else"
    ],
    [
        "The format is that required by the 'descr' key in the",
        "The format is that required by the 'descr'"
    ],
    [
        "Warning: This attribute exists specifically for `__array_interface__`,",
        "Warning: This attribute exists"
    ],
    [
        "and passing it directly to `numpy.dtype` will not accurately reconstruct",
        "and passing it directly to `numpy.dtype` will not accurately"
    ],
    [
        "some dtypes (e.g., scalar and subarray dtypes).",
        "some dtypes (e.g., scalar and"
    ],
    [
        "Dictionary of named fields defined for this data type, or ``None``.",
        "Dictionary of named fields defined for"
    ],
    [
        "The dictionary is indexed by keys that are the names of the fields.",
        "The dictionary is indexed by keys that are the names"
    ],
    [
        "Each entry in the dictionary is a tuple fully describing the field::",
        "Each entry in the dictionary is a tuple"
    ],
    [
        "If present, the optional title can be any object (if it is a string",
        "If present, the optional title can be"
    ],
    [
        "or unicode then it will also be a key in the fields dictionary,",
        "or unicode then it will also be a key"
    ],
    [
        "otherwise it's meta-data). Notice also that the first two elements",
        "otherwise it's meta-data). Notice also that the first"
    ],
    [
        "of the tuple can be passed directly as arguments to the",
        "of the tuple can be passed directly as arguments"
    ],
    [
        "Bit-flags describing how this data type is to be interpreted.",
        "Bit-flags describing how this data type is to"
    ],
    [
        "Bit-masks are in ``numpy._core.multiarray`` as the constants",
        "Bit-masks are in ``numpy._core.multiarray`` as the"
    ],
    [
        "`NEEDS_PYAPI`, `USE_GETITEM`, `USE_SETITEM`. A full explanation",
        "`NEEDS_PYAPI`, `USE_GETITEM`, `USE_SETITEM`. A"
    ],
    [
        "of these flags is in C-API documentation; they are largely useful",
        "of these flags is in C-API documentation; they"
    ],
    [
        "The following example demonstrates that operations on this particular",
        "The following example demonstrates that"
    ],
    [
        "Boolean indicating whether this dtype contains any reference-counted",
        "Boolean indicating whether this dtype"
    ],
    [
        "objects in any fields or sub-dtypes.",
        "objects in any fields or"
    ],
    [
        "Recall that what is actually in the ndarray memory representing",
        "Recall that what is actually in the ndarray"
    ],
    [
        "the Python object is the memory address of that object (a pointer).",
        "the Python object is the memory address of that object (a"
    ],
    [
        "Special handling may be required, and this attribute is useful for",
        "Special handling may be required, and this attribute is useful"
    ],
    [
        "distinguishing data types that may contain arbitrary Python objects",
        "distinguishing data types that may"
    ],
    [
        "Integer indicating how this dtype relates to the built-in dtypes.",
        "Integer indicating how this dtype relates to the"
    ],
    [
        "A user-defined type uses the numpy C-API machinery to extend",
        "A user-defined type uses the numpy C-API machinery"
    ],
    [
        "numpy to handle a new array type. See",
        "numpy to handle a new array"
    ],
    [
        "Boolean indicating whether the byte order of this dtype is native",
        "Boolean indicating whether the byte order"
    ],
    [
        "Boolean indicating whether the dtype is a struct which maintains",
        "Boolean indicating whether the dtype is a"
    ],
    [
        "field alignment. This flag is sticky, so when combining multiple",
        "field alignment. This flag is sticky, so"
    ],
    [
        "structs together, it is preserved and produces new dtypes which",
        "structs together, it is preserved and produces new dtypes"
    ],
    [
        "The element size of this data-type object.",
        "The element size of this data-type"
    ],
    [
        "For the flexible data-types, this number can be anything.",
        "For the flexible data-types, this number can be"
    ],
    [
        "A character code (one of 'biufcmMOSTUV') identifying the general kind of data.",
        "A character code (one of 'biufcmMOSTUV') identifying the"
    ],
    [
        "Either ``None`` or a readonly dictionary of metadata (mappingproxy).",
        "Either ``None`` or a readonly dictionary of"
    ],
    [
        "The metadata field can be set using any dictionary at data-type",
        "The metadata field can be set using"
    ],
    [
        "creation. NumPy currently has no uniform approach to propagating",
        "creation. NumPy currently has no uniform"
    ],
    [
        "metadata; although some array operations preserve it, there is no",
        "metadata; although some array operations preserve it,"
    ],
    [
        "Although used in certain projects, this feature was long undocumented",
        "Although used in certain projects, this feature"
    ],
    [
        "and is not well supported. Some aspects of metadata propagation",
        "and is not well supported. Some aspects of metadata"
    ],
    [
        "are expected to change in the future.",
        "are expected to change in the"
    ],
    [
        ">>> dt = np.dtype(float, metadata={\"key\": \"value\"})",
        ">>> dt = np.dtype(float, metadata={\"key\":"
    ],
    [
        "Adding arrays with identical datatypes currently preserves the metadata:",
        "Adding arrays with identical datatypes currently preserves"
    ],
    [
        "If the arrays have different dtype metadata, the first one wins:",
        "If the arrays have different dtype"
    ],
    [
        "A bit-width name for this data-type.",
        "A bit-width name"
    ],
    [
        "Un-sized flexible data-type objects do not have this attribute.",
        "Un-sized flexible data-type objects do not have this"
    ],
    [
        "Ordered list of field names, or ``None`` if there are no fields.",
        "Ordered list of field names, or ``None`` if there are"
    ],
    [
        "The names are ordered according to increasing byte offset. This can be",
        "The names are ordered according to increasing byte offset. This"
    ],
    [
        "used, for example, to walk through all of the named fields in offset order.",
        "used, for example, to walk through all of the named fields"
    ],
    [
        "These are roughly ordered from least-to-most precision.",
        "These are roughly ordered from"
    ],
    [
        "Shape tuple of the sub-array if this data type describes a sub-array,",
        "Shape tuple of the sub-array if"
    ],
    [
        "Number of dimensions of the sub-array if this data type describes a",
        "Number of dimensions of the sub-array if this"
    ],
    [
        "\"\"\"The array-protocol typestring of this data-type object.\"\"\"))",
        "\"\"\"The array-protocol typestring of this"
    ],
    [
        "Tuple ``(item_dtype, shape)`` if this `dtype` describes a sub-array, and",
        "Tuple ``(item_dtype, shape)`` if this"
    ],
    [
        "The *shape* is the fixed shape of the sub-array described by this",
        "The *shape* is the fixed shape of the"
    ],
    [
        "data type, and *item_dtype* the data type of the array.",
        "data type, and *item_dtype* the data"
    ],
    [
        "If a field whose dtype object has this attribute is retrieved,",
        "If a field whose dtype object"
    ],
    [
        "then the extra dimensions implied by *shape* are tacked on to",
        "then the extra dimensions implied by *shape* are"
    ],
    [
        "the end of the retrieved array.",
        "the end of the"
    ],
    [
        "Returns dtype for the base element of the subarrays,",
        "Returns dtype for the base element"
    ],
    [
        "regardless of their dimension or shape.",
        "regardless of their"
    ],
    [
        "\"\"\"The type object used to instantiate a scalar of this data-type.\"\"\"))",
        "\"\"\"The type object used to instantiate a scalar"
    ],
    [
        "Return a new dtype with a different byte order.",
        "Return a new dtype with"
    ],
    [
        "Changes are also made in all fields and sub-arrays of the data type.",
        "Changes are also made in all fields and sub-arrays of"
    ],
    [
        "Byte order to force; a value from the byte order specifications",
        "Byte order to force; a value from the"
    ],
    [
        "below.  The default value ('S') results in swapping the current",
        "below. The default value ('S') results in swapping the"
    ],
    [
        "byte order.  `new_order` codes can be any of:",
        "byte order. `new_order` codes can"
    ],
    [
        "* 'S' - swap dtype from current to opposite endian",
        "* 'S' - swap dtype from current to opposite"
    ],
    [
        "* {'<', 'little'} - little endian",
        "* {'<', 'little'} - little"
    ],
    [
        "* {'>', 'big'} - big endian",
        "* {'>', 'big'}"
    ],
    [
        "* {'=', 'native'} - native order",
        "* {'=', 'native'} -"
    ],
    [
        "* {'|', 'I'} - ignore (no change to byte order)",
        "* {'|', 'I'} - ignore (no change"
    ],
    [
        "New dtype object with the given change to the byte order.",
        "New dtype object with the given"
    ],
    [
        "Changes are also made in all fields and sub-arrays of the data type.",
        "Changes are also made in all fields"
    ],
    [
        ">>> sys_is_le = sys.byteorder == 'little'",
        ">>> sys_is_le = sys.byteorder =="
    ],
    [
        ">>> native_code = '<' if sys_is_le else '>'",
        ">>> native_code = '<' if sys_is_le"
    ],
    [
        ">>> swapped_code = '>' if sys_is_le else '<'",
        ">>> swapped_code = '>'"
    ],
    [
        "Return a parametrized wrapper around the `~numpy.dtype` type.",
        "Return a parametrized wrapper"
    ],
    [
        "can_cast : Returns True if cast between data types can occur according to",
        "can_cast : Returns True if cast between"
    ],
    [
        "can_cast : Returns True if cast between data types can occur according to",
        "can_cast : Returns True if cast between data types can occur according"
    ],
    [
        "``self != value and np.can_cast(value, self, casting=\"safe\")``.",
        "``self != value and"
    ],
    [
        "can_cast : Returns True if cast between data types can occur according to",
        "can_cast : Returns True if cast between data types"
    ],
    [
        "``self != value and np.can_cast(self, value, casting=\"safe\")``.",
        "``self != value and"
    ],
    [
        "can_cast : Returns True if cast between data types can occur according to",
        "can_cast : Returns True if cast between data"
    ],
    [
        "A business day calendar object that efficiently stores information",
        "A business day calendar object that efficiently"
    ],
    [
        "defining valid days for the busday family of functions.",
        "defining valid days for the busday family of"
    ],
    [
        "The default valid days are Monday through Friday (\"business days\").",
        "The default valid days are Monday through Friday (\"business"
    ],
    [
        "A busdaycalendar object can be specified with any set of weekly",
        "A busdaycalendar object can be specified with any set"
    ],
    [
        "valid days, plus an optional \"holiday\" dates that always will be invalid.",
        "valid days, plus an optional \"holiday\" dates that"
    ],
    [
        "Once a busdaycalendar object is created, the weekmask and holidays",
        "Once a busdaycalendar object is created, the"
    ],
    [
        "weekmask : str or array_like of bool, optional",
        "weekmask : str or array_like of"
    ],
    [
        "A seven-element array indicating which of Monday through Sunday are",
        "A seven-element array indicating which of Monday through"
    ],
    [
        "valid days. May be specified as a length-seven list or array, like",
        "valid days. May be specified as a length-seven list or"
    ],
    [
        "weekdays, optionally separated by white space. Valid abbreviations",
        "weekdays, optionally separated by white space."
    ],
    [
        "are: Mon Tue Wed Thu Fri Sat Sun",
        "are: Mon Tue Wed Thu Fri Sat"
    ],
    [
        "An array of dates to consider as invalid dates, no matter which",
        "An array of dates to consider as invalid dates, no matter"
    ],
    [
        "weekday they fall upon.  Holiday dates may be specified in any",
        "weekday they fall upon. Holiday dates may be"
    ],
    [
        "order, and NaT (not-a-time) dates are ignored.  This list is",
        "order, and NaT (not-a-time) dates are ignored. This list"
    ],
    [
        "saved in a normalized form that is suited for fast calculations",
        "saved in a normalized form that"
    ],
    [
        "A business day calendar object containing the specified",
        "A business day calendar object containing"
    ],
    [
        "is_busday : Returns a boolean array indicating valid days.",
        "is_busday : Returns a boolean array indicating"
    ],
    [
        "busday_offset : Applies an offset counted in valid days.",
        "busday_offset : Applies an offset"
    ],
    [
        "busday_count : Counts how many valid days are in a half-open date range.",
        "busday_count : Counts how many valid days are in a"
    ],
    [
        "weekmask : (copy) seven-element array of bool",
        "weekmask : (copy) seven-element"
    ],
    [
        "Once a busdaycalendar object is created, you cannot modify the",
        "Once a busdaycalendar object is created,"
    ],
    [
        "weekmask or holidays.  The attributes return copies of internal data.",
        "weekmask or holidays. The attributes return copies of"
    ],
    [
        "array([ True,  True,  True,  True,  True, False, False])",
        "array([ True, True, True,"
    ],
    [
        "\"\"\"A copy of the seven-element boolean mask indicating valid days.\"\"\"))",
        "\"\"\"A copy of the seven-element boolean mask indicating valid"
    ],
    [
        "\"\"\"A copy of the holiday array indicating additional invalid days.\"\"\"))",
        "\"\"\"A copy of the holiday array indicating additional"
    ],
    [
        "Normalizes an axis index, `axis`, such that is a valid positive index into",
        "Normalizes an axis index, `axis`, such that"
    ],
    [
        "the shape of array with `ndim` dimensions. Raises an AxisError with an",
        "the shape of array with `ndim` dimensions."
    ],
    [
        "appropriate message if this is not possible.",
        "appropriate message if this is"
    ],
    [
        "Used internally by all axis-checking logic.",
        "Used internally by all axis-checking"
    ],
    [
        "The un-normalized index of the axis. Can be negative",
        "The un-normalized index of the"
    ],
    [
        "The number of dimensions of the array that `axis` should be normalized",
        "The number of dimensions of the array that `axis`"
    ],
    [
        "A prefix to put before the message, typically the name of the argument",
        "A prefix to put before the message, typically the"
    ],
    [
        "If the axis index is invalid, when `-ndim <= axis < ndim` is false.",
        "If the axis index is invalid, when `-ndim <= axis"
    ],
    [
        "Get information about the step size of a date or time type.",
        "Get information about the step size of a date"
    ],
    [
        "The :ref:`datetime unit <arrays.dtypes.dateunits>` on which this dtype",
        "The :ref:`datetime unit <arrays.dtypes.dateunits>` on which this"
    ],
    [
        "The number of base units in a step.",
        "The number of base units"
    ],
    [
        "The result can be used to construct a datetime that uses the same units",
        "The result can be used to construct a datetime"
    ],
    [
        "Base class for numpy scalar types.",
        "Base class for"
    ],
    [
        "Class from which most (all?) numpy scalar types are derived.  For",
        "Class from which most (all?) numpy scalar types"
    ],
    [
        "consistency, exposes the same API as `ndarray`, despite many",
        "consistency, exposes the same API"
    ],
    [
        "consequent attributes being either \"get-only,\" or completely irrelevant.",
        "consequent attributes being either \"get-only,\""
    ],
    [
        "This is the class from which it is strongly suggested users should derive",
        "This is the class from which it is"
    ],
    [
        "Scalar {} identical to the corresponding array attribute.",
        "Scalar {} identical to the"
    ],
    [
        "return attr, docstring.format(\"method\" if method else \"attribute\", attr)",
        "return attr, docstring.format(\"method\" if"
    ],
    [
        "\"\"\"The imaginary part of the scalar.\"\"\"))",
        "\"\"\"The imaginary part of"
    ],
    [
        "\"\"\"The length of one element in bytes.\"\"\"))",
        "\"\"\"The length of one element in"
    ],
    [
        "\"\"\"The real part of the scalar.\"\"\"))",
        "\"\"\"The real part"
    ],
    [
        "\"\"\"The number of elements in the gentype.\"\"\"))",
        "\"\"\"The number of elements in the"
    ],
    [
        "\"\"\"Tuple of bytes steps in each dimension.\"\"\"))",
        "\"\"\"Tuple of bytes steps in each"
    ],
    [
        "Return a parametrized wrapper around the `~numpy.number` type.",
        "Return a parametrized wrapper"
    ],
    [
        "Abstract base class of all numeric scalar types.",
        "Abstract base class of all numeric"
    ],
    [
        "Abstract base class of all integer scalar types.",
        "Abstract base class of all"
    ],
    [
        "Abstract base class of all signed integer scalar types.",
        "Abstract base class of all signed"
    ],
    [
        "Abstract base class of all unsigned integer scalar types.",
        "Abstract base class of all unsigned"
    ],
    [
        "Abstract base class of all numeric scalar types with a (potentially)",
        "Abstract base class of all numeric"
    ],
    [
        "inexact representation of the values in its range, such as",
        "inexact representation of the values in its range,"
    ],
    [
        "Abstract base class of all floating-point scalar types.",
        "Abstract base class of all floating-point scalar"
    ],
    [
        "Abstract base class of all complex number scalar types that are made up of",
        "Abstract base class of all complex number scalar types"
    ],
    [
        "Abstract base class of all scalar types without predefined length.",
        "Abstract base class of all"
    ],
    [
        "The actual size of these types depends on the specific `numpy.dtype`",
        "The actual size of these types"
    ],
    [
        "Abstract base class of all character string scalar types.",
        "Abstract base class of all character string"
    ],
    [
        "Object used to represent missing data. If unset, the array will not",
        "Object used to represent missing data. If unset, the array"
    ],
    [
        "Whether or not items in an array-like passed to an array creation",
        "Whether or not items in an array-like passed to"
    ],
    [
        "function that are neither a str or str subtype should be coerced to",
        "function that are neither a str or str subtype should"
    ],
    [
        "str. Defaults to True. If set to False, creating a StringDType",
        "str. Defaults to True. If set to False, creating"
    ],
    [
        "array from an array-like containing entries that are not already",
        "array from an array-like containing entries"
    ],
    [
        ">>> arr = np.array([\"hello\", None, \"world\"],",
        ">>> arr = np.array([\"hello\","
    ],
    [
        ">>> arr = np.array([\"hello\", np.nan, \"world\"],",
        ">>> arr = np.array([\"hello\","
    ],
    [
        "ValueError: StringDType only allows string data when string coercion",
        "ValueError: StringDType only allows string data"
    ],
    [
        "Array methods which are called by both the C-code for the method",
        "Array methods which are called by both the C-code for"
    ],
    [
        "and the Python code for the NumPy-namespace function",
        "and the Python code for the NumPy-namespace"
    ],
    [
        "from numpy._core import multiarray as mu",
        "from numpy._core import multiarray"
    ],
    [
        "from numpy._core import umath as um",
        "from numpy._core import"
    ],
    [
        "from numpy._core import numerictypes as nt",
        "from numpy._core import numerictypes as"
    ],
    [
        "return umr_maximum(a, axis, None, out, keepdims, initial, where)",
        "return umr_maximum(a, axis, None, out, keepdims,"
    ],
    [
        "return umr_minimum(a, axis, None, out, keepdims, initial, where)",
        "return umr_minimum(a, axis, None, out, keepdims,"
    ],
    [
        "def _sum(a, axis=None, dtype=None, out=None, keepdims=False,",
        "def _sum(a, axis=None,"
    ],
    [
        "return umr_sum(a, axis, dtype, out, keepdims, initial, where)",
        "return umr_sum(a, axis, dtype, out, keepdims,"
    ],
    [
        "def _prod(a, axis=None, dtype=None, out=None, keepdims=False,",
        "def _prod(a, axis=None, dtype=None,"
    ],
    [
        "return umr_prod(a, axis, dtype, out, keepdims, initial, where)",
        "return umr_prod(a, axis, dtype, out, keepdims,"
    ],
    [
        "def _any(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):",
        "def _any(a, axis=None, dtype=None, out=None, keepdims=False, *,"
    ],
    [
        "return umr_any(a, axis, dtype, out, keepdims)",
        "return umr_any(a, axis, dtype,"
    ],
    [
        "return umr_any(a, axis, dtype, out, keepdims, where=where)",
        "return umr_any(a, axis, dtype, out, keepdims,"
    ],
    [
        "def _all(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):",
        "def _all(a, axis=None, dtype=None, out=None, keepdims=False,"
    ],
    [
        "return umr_all(a, axis, dtype, out, keepdims)",
        "return umr_all(a, axis, dtype,"
    ],
    [
        "return umr_all(a, axis, dtype, out, keepdims, where=where)",
        "return umr_all(a, axis, dtype,"
    ],
    [
        "items = umr_sum(broadcast_to(where, arr.shape), axis, nt.intp, None,",
        "items = umr_sum(broadcast_to(where, arr.shape), axis, nt.intp,"
    ],
    [
        "def _clip(a, min=None, max=None, out=None, **kwargs):",
        "def _clip(a, min=None, max=None,"
    ],
    [
        "if type(min) is int and min <= np.iinfo(a.dtype).min:",
        "if type(min) is int and min"
    ],
    [
        "if type(max) is int and max >= np.iinfo(a.dtype).max:",
        "if type(max) is int and"
    ],
    [
        "if min is None and max is None:",
        "if min is None and"
    ],
    [
        "return um.clip(a, min, max, out=out, **kwargs)",
        "return um.clip(a, min, max, out=out,"
    ],
    [
        "def _mean(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):",
        "def _mean(a, axis=None, dtype=None,"
    ],
    [
        "rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)",
        "rcount = _count_reduce_items(arr,"
    ],
    [
        "ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)",
        "ret = umr_sum(arr, axis, dtype,"
    ],
    [
        "rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)",
        "rcount = _count_reduce_items(arr, axis, keepdims=keepdims,"
    ],
    [
        "if ddof >= rcount if where is True else umr_any(ddof >= rcount, axis=None):",
        "if ddof >= rcount if where is True else"
    ],
    [
        "if dtype is None and issubclass(arr.dtype.type, (nt.integer, nt.bool)):",
        "if dtype is None and issubclass(arr.dtype.type, (nt.integer,"
    ],
    [
        "arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)",
        "arrmean = umr_sum(arr, axis, dtype,"
    ],
    [
        "ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)",
        "ret = umr_sum(x, axis, dtype, out,"
    ],
    [
        "ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,",
        "ret = _var(a, axis=axis,"
    ],
    [
        "def _bitwise_count(a, out=None, *, where=True, casting='same_kind',",
        "def _bitwise_count(a, out=None, *, where=True,"
    ],
    [
        "Some things are more easily handled Python.",
        "Some things are more easily"
    ],
    [
        "from .multiarray import dtype, array, ndarray, promote_types, StringDType",
        "from .multiarray import dtype, array, ndarray,"
    ],
    [
        "names, formats, offsets, titles = _makenames_list(adict, align)",
        "names, formats, offsets, titles ="
    ],
    [
        "ordered_fields = [fields[x] + (x,) for x in names]",
        "ordered_fields = [fields[x] + (x,)"
    ],
    [
        "\"dtype.descr is not defined for types with overlapping or \"",
        "\"dtype.descr is not defined for types with overlapping"
    ],
    [
        "'format number %d of \"%s\" is not recognized' %",
        "'format number %d of \"%s\" is not recognized'"
    ],
    [
        "'inconsistent byte-order specification %s and %s' %",
        "'inconsistent byte-order specification %s"
    ],
    [
        "if order in ('|', '=', _nbo):",
        "if order in ('|', '=',"
    ],
    [
        "'Passing in a parenthesized single number for repeats '",
        "'Passing in a parenthesized single number for"
    ],
    [
        "'is deprecated; pass either a single number or indicate '",
        "'is deprecated; pass either a"
    ],
    [
        "Return the data pointer cast to a particular c-types object.",
        "Return the data pointer cast to a particular c-types"
    ],
    [
        "For example, calling ``self._as_parameter_`` is equivalent to",
        "For example, calling ``self._as_parameter_``"
    ],
    [
        "``self.data_as(ctypes.c_void_p)``. Perhaps you want to use",
        "``self.data_as(ctypes.c_void_p)``. Perhaps you"
    ],
    [
        "the data as a pointer to a ctypes array of floating-point data:",
        "the data as a pointer to a ctypes array"
    ],
    [
        "The returned pointer will keep a reference to the array.",
        "The returned pointer will keep"
    ],
    [
        "Return the shape tuple as an array of some other c-types",
        "Return the shape tuple as an array"
    ],
    [
        "Return the strides tuple as an array of some other",
        "Return the strides tuple as an array of some"
    ],
    [
        "A pointer to the memory area of the array as a Python integer.",
        "A pointer to the memory area of the array"
    ],
    [
        "This memory area may contain data that is not aligned, or not in",
        "This memory area may contain data that is not aligned, or"
    ],
    [
        "correct byte-order. The memory area may not even be writeable.",
        "correct byte-order. The memory area may not even"
    ],
    [
        "The array flags and data-type of this array should be respected",
        "The array flags and data-type of this array"
    ],
    [
        "when passing this attribute to arbitrary C-code to avoid trouble",
        "when passing this attribute to arbitrary"
    ],
    [
        "that can include Python crashing. User Beware! The value of this",
        "that can include Python crashing. User Beware! The"
    ],
    [
        "attribute is exactly the same as:",
        "attribute is exactly the same"
    ],
    [
        "Note that unlike ``data_as``, a reference won't be kept to the array:",
        "Note that unlike ``data_as``, a reference won't be"
    ],
    [
        "code like ``ctypes.c_void_p((a + b).ctypes.data)`` will result in a",
        "code like ``ctypes.c_void_p((a + b).ctypes.data)`` will"
    ],
    [
        "pointer to a deallocated array, and should be spelt",
        "pointer to a deallocated array, and should"
    ],
    [
        "(c_intp*self.ndim): A ctypes array of length self.ndim where",
        "(c_intp*self.ndim): A ctypes array"
    ],
    [
        "the basetype is the C-integer corresponding to ``dtype('p')`` on this",
        "the basetype is the C-integer"
    ],
    [
        "platform (see `~numpy.ctypeslib.c_intp`). This base-type could be",
        "platform (see `~numpy.ctypeslib.c_intp`). This base-type"
    ],
    [
        "`ctypes.c_int`, `ctypes.c_long`, or `ctypes.c_longlong` depending on",
        "`ctypes.c_int`, `ctypes.c_long`, or `ctypes.c_longlong` depending"
    ],
    [
        "the platform. The ctypes array contains the shape of",
        "the platform. The ctypes array contains the"
    ],
    [
        "(c_intp*self.ndim): A ctypes array of length self.ndim where",
        "(c_intp*self.ndim): A ctypes array of"
    ],
    [
        "the basetype is the same as for the shape attribute. This ctypes",
        "the basetype is the same as for the"
    ],
    [
        "array contains the strides information from the underlying array.",
        "array contains the strides information from"
    ],
    [
        "This strides information is important for showing how many bytes",
        "This strides information is important for"
    ],
    [
        "must be jumped to get to the next element in the array.",
        "must be jumped to get to the next element in the"
    ],
    [
        "\"\"\"Deprecated getter for the `_ctypes.data` property.",
        "\"\"\"Deprecated getter for the"
    ],
    [
        "warnings.warn('\"get_data\" is deprecated. Use \"data\" instead',",
        "warnings.warn('\"get_data\" is deprecated. Use"
    ],
    [
        "\"\"\"Deprecated getter for the `_ctypes.shape` property.",
        "\"\"\"Deprecated getter for"
    ],
    [
        "warnings.warn('\"get_shape\" is deprecated. Use \"shape\" instead',",
        "warnings.warn('\"get_shape\" is deprecated. Use"
    ],
    [
        "\"\"\"Deprecated getter for the `_ctypes.strides` property.",
        "\"\"\"Deprecated getter for"
    ],
    [
        "warnings.warn('\"get_strides\" is deprecated. Use \"strides\" instead',",
        "warnings.warn('\"get_strides\" is deprecated. Use"
    ],
    [
        "\"\"\"Deprecated getter for the `_ctypes._as_parameter_` property.",
        "\"\"\"Deprecated getter for the `_ctypes._as_parameter_`"
    ],
    [
        "'\"get_as_parameter\" is deprecated. Use \"_as_parameter_\" instead',",
        "'\"get_as_parameter\" is deprecated. Use \"_as_parameter_\""
    ],
    [
        "Given a datatype and an order object, return a new names tuple, with the",
        "Given a datatype and an order object, return a new"
    ],
    [
        "raise ValueError(f\"duplicate field name: {name}\") from None",
        "raise ValueError(f\"duplicate field name:"
    ],
    [
        "raise ValueError(f\"unknown field name: {name}\") from None",
        "raise ValueError(f\"unknown field name: {name}\")"
    ],
    [
        "\"\"\"Return copy of structured array with padding between fields removed.",
        "\"\"\"Return copy of structured array with padding"
    ],
    [
        "Structured array from which to remove padding bytes",
        "Structured array from which to remove padding"
    ],
    [
        "Copy of ary with padding bytes removed",
        "Copy of ary with padding bytes"
    ],
    [
        "\"\"\" Perform type promotion for two structured dtypes.",
        "\"\"\" Perform type promotion for two structured"
    ],
    [
        "If one of the inputs is aligned, the result will be.  The titles of",
        "If one of the inputs is aligned, the result"
    ],
    [
        "both descriptors must match (point to the same field).",
        "both descriptors must match (point to"
    ],
    [
        "f\"field titles of field '{name}' mismatch\")",
        "f\"field titles of field"
    ],
    [
        "\"\"\" Checks safety of getfield for object arrays.",
        "\"\"\" Checks safety of getfield"
    ],
    [
        "As in _view_is_safe, we need to check that memory containing objects is not",
        "As in _view_is_safe, we need to check"
    ],
    [
        "reinterpreted as a non-object datatype and vice versa.",
        "reinterpreted as a non-object datatype and"
    ],
    [
        "Data type of the original ndarray.",
        "Data type of"
    ],
    [
        "Data type of the field being accessed by ndarray.getfield",
        "Data type of the field being"
    ],
    [
        "Offset of the field being accessed by ndarray.getfield",
        "Offset of the field being accessed"
    ],
    [
        "If the field access is invalid",
        "If the field"
    ],
    [
        "raise TypeError(\"Cannot get/set field of an object array\")",
        "raise TypeError(\"Cannot get/set field"
    ],
    [
        "\"\"\" Checks safety of a view involving object arrays, for example when",
        "\"\"\" Checks safety of a view involving object arrays, for example"
    ],
    [
        "If the new type is incompatible with the old type.",
        "If the new type is incompatible with the old"
    ],
    [
        "raise TypeError(\"Cannot change data-type for array of references.\")",
        "raise TypeError(\"Cannot change data-type for array of"
    ],
    [
        "while i < len(self.s) and not c(self.s[i]):",
        "while i < len(self.s)"
    ],
    [
        "if stream.next in ('@', '=', '<', '>', '^', '!'):",
        "if stream.next in ('@', '=', '<', '>',"
    ],
    [
        "itemsize_str = stream.consume_until(lambda c: not c.isdigit())",
        "itemsize_str = stream.consume_until(lambda c:"
    ],
    [
        "numpy_byteorder = {'@': '=', '^': '='}.get(",
        "numpy_byteorder = {'@': '=',"
    ],
    [
        "if not (is_padding and name is None):",
        "if not (is_padding and name is"
    ],
    [
        "if name is not None and name in field_spec['names']:",
        "if name is not None and"
    ],
    [
        "\"\"\" Replace names which are None with the next unused f%d name \"\"\"",
        "\"\"\" Replace names which are None with the next unused f%d"
    ],
    [
        "\"\"\"Inject the specified number of padding bytes at the end of a dtype\"\"\"",
        "\"\"\"Inject the specified number of padding bytes"
    ],
    [
        "\"\"\"Calculate the greatest common divisor of a and b\"\"\"",
        "\"\"\"Calculate the greatest common divisor of a"
    ],
    [
        "raise ValueError('Can only find greatest common divisor of '",
        "raise ValueError('Can only find greatest common divisor"
    ],
    [
        "f'finite arguments, found \"{a}\" and \"{b}\"')",
        "f'finite arguments, found"
    ],
    [
        "a, b = b, a % b",
        "a, b = b, a"
    ],
    [
        "return a // _gcd(a, b) * b",
        "return a // _gcd(a, b)"
    ],
    [
        "def array_ufunc_errmsg_formatter(dummy, ufunc, method, *inputs, **kwargs):",
        "def array_ufunc_errmsg_formatter(dummy, ufunc, method, *inputs,"
    ],
    [
        "\"\"\" Format the error message for when __array_ufunc__ gives up. \"\"\"",
        "\"\"\" Format the error message for when __array_ufunc__ gives up."
    ],
    [
        "args_string = ', '.join(['{!r}'.format(arg) for arg in inputs] +",
        "args_string = ', '.join(['{!r}'.format(arg) for arg in inputs]"
    ],
    [
        "args = inputs + kwargs.get('out', ())",
        "args = inputs"
    ],
    [
        "types_string = ', '.join(repr(type(arg).__name__) for arg in args)",
        "types_string = ', '.join(repr(type(arg).__name__) for"
    ],
    [
        "return ('operand type(s) all returned NotImplemented from '",
        "return ('operand type(s) all"
    ],
    [
        "\"\"\" Format the error message for when __array_ufunc__ gives up. \"\"\"",
        "\"\"\" Format the error message for when"
    ],
    [
        "return (\"no implementation found for '{}' on types that implement \"",
        "return (\"no implementation found for '{}' on types that implement"
    ],
    [
        "This is used to construct the first line of the docstring",
        "This is used to construct the first line of"
    ],
    [
        "out_args = '[, {positional}], / [, out={default}]'.format(",
        "out_args = '[, {positional}],"
    ],
    [
        "kwargs += \"[, signature, axes, axis]\"",
        "kwargs += \"[, signature,"
    ],
    [
        "Used primarily to generate type name aliases.",
        "Used primarily to generate type name"
    ],
    [
        "\"\"\" Apply English case rules to convert ASCII strings to all lower case.",
        "\"\"\" Apply English case rules to convert ASCII strings to"
    ],
    [
        "This is an internal utility function to replace calls to str.lower() such",
        "This is an internal utility function to replace calls"
    ],
    [
        "that we can avoid changing behavior with changing locales. In particular,",
        "that we can avoid changing behavior with changing"
    ],
    [
        "Turkish has distinct dotted and dotless variants of the Latin letter \"I\" in",
        "Turkish has distinct dotted and dotless variants of the Latin letter"
    ],
    [
        "both lowercase and uppercase. Thus, \"I\".lower() != \"i\" in a \"tr\" locale.",
        "both lowercase and uppercase. Thus, \"I\".lower() != \"i\" in a \"tr\""
    ],
    [
        "\"\"\" Apply English case rules to convert ASCII strings to all upper case.",
        "\"\"\" Apply English case rules to convert ASCII"
    ],
    [
        "This is an internal utility function to replace calls to str.upper() such",
        "This is an internal utility function to replace calls"
    ],
    [
        "that we can avoid changing behavior with changing locales. In particular,",
        "that we can avoid changing behavior with changing locales. In"
    ],
    [
        "Turkish has distinct dotted and dotless variants of the Latin letter \"I\" in",
        "Turkish has distinct dotted and dotless variants of the Latin"
    ],
    [
        "both lowercase and uppercase. Thus, \"i\".upper() != \"I\" in a \"tr\" locale.",
        "both lowercase and uppercase. Thus, \"i\".upper() != \"I\" in"
    ],
    [
        "\"\"\" Apply English case rules to convert the first character of an ASCII",
        "\"\"\" Apply English case rules to convert the"
    ],
    [
        "This is an internal utility function to replace calls to str.capitalize()",
        "This is an internal utility function to replace"
    ],
    [
        "such that we can avoid changing behavior with changing locales.",
        "such that we can avoid changing"
    ],
    [
        "Create the numpy._core.multiarray namespace for backward compatibility.",
        "Create the numpy._core.multiarray namespace"
    ],
    [
        "a single _multiarray_umath extension module. So we replicate the old",
        "a single _multiarray_umath extension module."
    ],
    [
        "namespace by importing from the extension module.",
        "namespace by importing from the extension"
    ],
    [
        "'empty', 'empty_like', 'error', 'flagsobj', 'flatiter', 'format_longfloat',",
        "'empty', 'empty_like', 'error',"
    ],
    [
        "'absolute', 'arccos', 'arccosh', 'add', 'arcsin', 'arcsinh', 'arctan',",
        "'absolute', 'arccos', 'arccosh', 'add',"
    ],
    [
        "'float_power', 'floor', 'floor_divide', 'fmax', 'fmin', 'fmod',",
        "'float_power', 'floor', 'floor_divide', 'fmax', 'fmin',"
    ],
    [
        "'frexp', 'gcd', 'greater', 'greater_equal', 'heaviside', 'hypot',",
        "'frexp', 'gcd', 'greater',"
    ],
    [
        "'isfinite', 'isinf', 'isnan', 'isnat', 'lcm', 'ldexp', 'less',",
        "'isfinite', 'isinf', 'isnan', 'isnat', 'lcm', 'ldexp',"
    ],
    [
        "'logical_xor', 'matmul', 'matvec', 'maximum', 'minimum', 'remainder',",
        "'logical_xor', 'matmul', 'matvec',"
    ],
    [
        "'modf', 'multiply', 'negative', 'nextafter', 'not_equal', 'positive',",
        "'modf', 'multiply', 'negative', 'nextafter', 'not_equal',"
    ],
    [
        "'sin', 'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',",
        "'sin', 'sinh', 'spacing', 'sqrt', 'square', 'subtract',"
    ],
    [
        "prototype, dtype=None, order=None, subok=None, shape=None, *, device=None",
        "prototype, dtype=None, order=None, subok=None, shape=None, *,"
    ],
    [
        "empty_like(prototype, dtype=None, order='K', subok=True, shape=None, *,",
        "empty_like(prototype, dtype=None, order='K', subok=True,"
    ],
    [
        "Return a new array with the same shape and type as a given array.",
        "Return a new array with the same shape and type"
    ],
    [
        "The shape and data-type of `prototype` define these same attributes",
        "The shape and data-type of `prototype`"
    ],
    [
        "Overrides the data type of the result.",
        "Overrides the data type"
    ],
    [
        "order : {'C', 'F', 'A', or 'K'}, optional",
        "order : {'C', 'F', 'A', or 'K'},"
    ],
    [
        "Overrides the memory layout of the result. 'C' means C-order,",
        "Overrides the memory layout of the result."
    ],
    [
        "'F' means F-order, 'A' means 'F' if `prototype` is Fortran",
        "'F' means F-order, 'A' means 'F' if"
    ],
    [
        "contiguous, 'C' otherwise. 'K' means match the layout of `prototype`",
        "contiguous, 'C' otherwise. 'K' means match"
    ],
    [
        "If True, then the newly created array will use the sub-class",
        "If True, then the newly created array"
    ],
    [
        "type of `prototype`, otherwise it will be a base-class array. Defaults",
        "type of `prototype`, otherwise it will be a base-class array."
    ],
    [
        "shape : int or sequence of ints, optional.",
        "shape : int or sequence"
    ],
    [
        "Overrides the shape of the result. If order='K' and the number of",
        "Overrides the shape of the result. If order='K' and the"
    ],
    [
        "dimensions is unchanged, will try to keep order, otherwise,",
        "dimensions is unchanged, will try to"
    ],
    [
        "The device on which to place the created array. Default: None.",
        "The device on which to place"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so"
    ],
    [
        "Array of uninitialized (arbitrary) data with the same",
        "Array of uninitialized (arbitrary)"
    ],
    [
        "ones_like : Return an array of ones with shape and type of input.",
        "ones_like : Return an array of ones with shape and type of"
    ],
    [
        "zeros_like : Return an array of zeros with shape and type of input.",
        "zeros_like : Return an array of zeros with shape and"
    ],
    [
        "full_like : Return a new array with shape of input filled with value.",
        "full_like : Return a new array with shape of input"
    ],
    [
        "empty : Return a new uninitialized array.",
        "empty : Return a new"
    ],
    [
        "Unlike other array creation functions (e.g. `zeros_like`, `ones_like`,",
        "Unlike other array creation functions"
    ],
    [
        "`full_like`), `empty_like` does not initialize the values of the array,",
        "`full_like`), `empty_like` does not initialize the"
    ],
    [
        "and may therefore be marginally faster. However, the values stored in the",
        "and may therefore be marginally faster. However, the values stored in"
    ],
    [
        "newly allocated array are arbitrary. For reproducible behavior, be sure",
        "newly allocated array are arbitrary. For"
    ],
    [
        "to set each element of the array before reading.",
        "to set each element of the"
    ],
    [
        "def concatenate(arrays, axis=None, out=None, *, dtype=None, casting=None):",
        "def concatenate(arrays, axis=None, out=None, *,"
    ],
    [
        "Join a sequence of arrays along an existing axis.",
        "Join a sequence of arrays along an existing"
    ],
    [
        "The arrays must have the same shape, except in the dimension",
        "The arrays must have the same shape, except in"
    ],
    [
        "corresponding to `axis` (the first, by default).",
        "corresponding to `axis` (the first, by"
    ],
    [
        "The axis along which the arrays will be joined.  If axis is None,",
        "The axis along which the arrays will be joined. If axis"
    ],
    [
        "If provided, the destination to place the result. The shape must be",
        "If provided, the destination to place the result. The"
    ],
    [
        "correct, matching that of what concatenate would have returned if no",
        "correct, matching that of what concatenate would have returned"
    ],
    [
        "If provided, the destination array will have this dtype. Cannot be",
        "If provided, the destination array will have this dtype."
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe',"
    ],
    [
        "Controls what kind of data casting may occur. Defaults to 'same_kind'.",
        "Controls what kind of data casting may occur."
    ],
    [
        "For a description of the options, please see :term:`casting`.",
        "For a description of the options, please see"
    ],
    [
        "ma.concatenate : Concatenate function that preserves input masks.",
        "ma.concatenate : Concatenate function that preserves input"
    ],
    [
        "array_split : Split an array into multiple sub-arrays of equal or",
        "array_split : Split an array into multiple sub-arrays"
    ],
    [
        "split : Split array into a list of multiple sub-arrays of equal size.",
        "split : Split array into a list of multiple sub-arrays of"
    ],
    [
        "hsplit : Split array into multiple sub-arrays horizontally (column wise).",
        "hsplit : Split array into"
    ],
    [
        "vsplit : Split array into multiple sub-arrays vertically (row wise).",
        "vsplit : Split array into multiple sub-arrays"
    ],
    [
        "stack : Stack a sequence of arrays along a new axis.",
        "stack : Stack a sequence of arrays along a"
    ],
    [
        "block : Assemble arrays from blocks.",
        "block : Assemble arrays"
    ],
    [
        "hstack : Stack arrays in sequence horizontally (column wise).",
        "hstack : Stack arrays in sequence horizontally (column"
    ],
    [
        "vstack : Stack arrays in sequence vertically (row wise).",
        "vstack : Stack arrays in sequence vertically (row"
    ],
    [
        "dstack : Stack arrays in sequence depth wise (along third dimension).",
        "dstack : Stack arrays in sequence depth wise"
    ],
    [
        "When one or more of the arrays to be concatenated is a MaskedArray,",
        "When one or more of the arrays to be concatenated is"
    ],
    [
        "this function will return a MaskedArray object instead of an ndarray,",
        "this function will return a MaskedArray object instead of"
    ],
    [
        "but the input masks are *not* preserved. In cases where a MaskedArray",
        "but the input masks are *not* preserved. In cases where a"
    ],
    [
        "is expected as input, use the ma.concatenate function from the masked",
        "is expected as input, use the ma.concatenate function from the"
    ],
    [
        "This function will not preserve masking of MaskedArray inputs.",
        "This function will not preserve masking of"
    ],
    [
        "mask=[False,  True, False, False, False, False],",
        "mask=[False, True, False, False, False,"
    ],
    [
        "conjugation), in higher dimensions a sum product over the last axes.",
        "conjugation), in higher dimensions a sum product over the last"
    ],
    [
        "If `a` and `b` are nonscalar, their last dimensions must match.",
        "If `a` and `b` are nonscalar, their"
    ],
    [
        "If `a` and `b` are both",
        "If `a` and `b` are"
    ],
    [
        "If both `a` and `b` are nonscalar and their last dimensions have",
        "If both `a` and `b` are"
    ],
    [
        "tensordot : Sum products over arbitrary axes.",
        "tensordot : Sum products over"
    ],
    [
        "dot : Generalised matrix product, using second last dimension of `b`.",
        "dot : Generalised matrix product, using second last dimension"
    ],
    [
        "vecdot : Vector dot product of two arrays.",
        "vecdot : Vector dot product"
    ],
    [
        "In addition `a` or `b` may be scalars, in which case::",
        "In addition `a` or `b` may be scalars, in which"
    ],
    [
        "An example where `b` is a scalar:",
        "An example where `b` is a"
    ],
    [
        "Return elements chosen from `x` or `y` depending on `condition`.",
        "Return elements chosen from `x` or `y` depending"
    ],
    [
        "When only `condition` is provided, this function is a shorthand for",
        "When only `condition` is provided, this"
    ],
    [
        "``np.asarray(condition).nonzero()``. Using `nonzero` directly should be",
        "``np.asarray(condition).nonzero()``. Using `nonzero`"
    ],
    [
        "preferred, as it behaves correctly for subclasses. The rest of this",
        "preferred, as it behaves correctly for"
    ],
    [
        "documentation covers only the case where all three arguments are",
        "documentation covers only the case where all"
    ],
    [
        "Where True, yield `x`, otherwise yield `y`.",
        "Where True, yield `x`,"
    ],
    [
        "Values from which to choose. `x`, `y` and `condition` need to be",
        "Values from which to choose. `x`, `y` and"
    ],
    [
        "An array with elements from `x` where `condition` is True, and elements",
        "An array with elements from `x` where `condition`"
    ],
    [
        "nonzero : The function that is called when x and y are omitted",
        "nonzero : The function that is called"
    ],
    [
        "for c, xv, yv in zip(condition, x, y)]",
        "for c, xv, yv in zip(condition,"
    ],
    [
        "This can be used on multidimensional arrays too:",
        "This can be used on multidimensional arrays"
    ],
    [
        "The shapes of x, y, and the condition are broadcast together:",
        "The shapes of x, y, and the condition"
    ],
    [
        "Perform an indirect stable sort using a sequence of keys.",
        "Perform an indirect stable sort using a"
    ],
    [
        "Given multiple sorting keys, lexsort returns an array of integer indices",
        "Given multiple sorting keys, lexsort returns an"
    ],
    [
        "that describes the sort order by multiple keys. The last key in the",
        "that describes the sort order by multiple keys. The last key in"
    ],
    [
        "sequence is used for the primary sort order, ties are broken by the",
        "sequence is used for the primary sort order, ties are"
    ],
    [
        "keys : (k, m, n, ...) array-like",
        "keys : (k, m,"
    ],
    [
        "The `k` keys to be sorted. The *last* key (e.g, the last",
        "The `k` keys to be sorted. The"
    ],
    [
        "Each element of `keys` along the zeroth axis must be",
        "Each element of `keys` along the"
    ],
    [
        "an array-like object of the same shape.",
        "an array-like object of the same"
    ],
    [
        "Axis to be indirectly sorted. By default, sort over the last axis",
        "Axis to be indirectly sorted. By default, sort over the"
    ],
    [
        "of each sequence. Separate slices along `axis` sorted over",
        "of each sequence. Separate slices along"
    ],
    [
        "indices : (m, n, ...) ndarray of ints",
        "indices : (m, n, ...) ndarray of"
    ],
    [
        "Array of indices that sort the keys along the specified axis.",
        "Array of indices that sort the keys along the"
    ],
    [
        "sort : Return a sorted copy of an array.",
        "sort : Return a sorted copy of an"
    ],
    [
        "Sort names: first by surname, then by name.",
        "Sort names: first by surname,"
    ],
    [
        ">>> surnames =    ('Hertz',    'Galilei', 'Hertz')",
        ">>> surnames ="
    ],
    [
        ">>> first_names = ('Heinrich', 'Galileo', 'Gustav')",
        ">>> first_names ="
    ],
    [
        ">>> [surnames[i] + \", \" + first_names[i] for i in ind]",
        ">>> [surnames[i] + \", \" + first_names[i] for i in"
    ],
    [
        "['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']",
        "['Galilei, Galileo', 'Hertz, Gustav', 'Hertz,"
    ],
    [
        "Sort according to two numerical keys, first by elements",
        "Sort according to two numerical keys, first by"
    ],
    [
        "of ``a``, then breaking ties according to elements of ``b``:",
        "of ``a``, then breaking ties"
    ],
    [
        ">>> [(a[i], b[i]) for i in ind]",
        ">>> [(a[i], b[i]) for i"
    ],
    [
        "Compare against `argsort`, which would sort each key independently.",
        "Compare against `argsort`, which would sort each key"
    ],
    [
        "To sort lexicographically with `argsort`, we would need to provide a",
        "To sort lexicographically with `argsort`, we would need to"
    ],
    [
        ">>> x = np.array([(ai, bi) for ai, bi in zip(a, b)],",
        ">>> x = np.array([(ai, bi) for ai, bi"
    ],
    [
        "...              dtype = np.dtype([('x', int), ('y', int)]))",
        "... dtype = np.dtype([('x',"
    ],
    [
        "The zeroth axis of `keys` always corresponds with the sequence of keys,",
        "The zeroth axis of `keys` always corresponds with"
    ],
    [
        "Accordingly, the `axis` parameter refers to an axis of *each* key, not of",
        "Accordingly, the `axis` parameter refers to an axis"
    ],
    [
        "the `keys` argument itself. For instance, the array ``arr`` is treated as",
        "the `keys` argument itself. For instance, the"
    ],
    [
        "For higher-dimensional arrays, the axis parameter begins to matter. The",
        "For higher-dimensional arrays, the axis parameter"
    ],
    [
        "resulting array has the same shape as each key, and the values are what",
        "resulting array has the same shape as each key,"
    ],
    [
        "we would expect if `lexsort` were performed on corresponding slices",
        "we would expect if `lexsort` were"
    ],
    [
        "of the keys independently. For instance,",
        "of the keys independently."
    ],
    [
        "Each row of the result is what we would expect if we were to perform",
        "Each row of the result is what we would expect if"
    ],
    [
        "`lexsort` on the corresponding row of the keys:",
        "`lexsort` on the corresponding row of"
    ],
    [
        "Returns True if cast between data types can occur according to the",
        "Returns True if cast between data types"
    ],
    [
        "from_ : dtype, dtype specifier, NumPy scalar, or array",
        "from_ : dtype, dtype specifier, NumPy"
    ],
    [
        "Data type, NumPy scalar, or array to cast from.",
        "Data type, NumPy scalar, or"
    ],
    [
        "to : dtype or dtype specifier",
        "to : dtype or"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'},"
    ],
    [
        "Controls what kind of data casting may occur.",
        "Controls what kind of data casting"
    ],
    [
        "* 'no' means the data types should not be cast at all.",
        "* 'no' means the data types should"
    ],
    [
        "* 'equiv' means only byte-order changes are allowed.",
        "* 'equiv' means only byte-order changes"
    ],
    [
        "* 'safe' means only casts which can preserve values are allowed.",
        "* 'safe' means only casts which can preserve"
    ],
    [
        "* 'same_kind' means only safe casts or casts within a kind,",
        "* 'same_kind' means only safe casts"
    ],
    [
        "* 'unsafe' means any data conversions may be done.",
        "* 'unsafe' means any data conversions may be"
    ],
    [
        "True if cast can occur according to the casting rule.",
        "True if cast can occur according to"
    ],
    [
        "This function does not support Python scalars anymore and does not",
        "This function does not support Python scalars anymore and"
    ],
    [
        "For scalar ``a``, returns the data type with the smallest size",
        "For scalar ``a``, returns the data type with the"
    ],
    [
        "and smallest scalar kind which can hold its value.  For non-scalar",
        "and smallest scalar kind which can hold"
    ],
    [
        "array ``a``, returns the vector's dtype unmodified.",
        "array ``a``, returns the vector's dtype"
    ],
    [
        "Floating point values are not demoted to integers,",
        "Floating point values are not"
    ],
    [
        "and complex values are not demoted to floats.",
        "and complex values are not demoted"
    ],
    [
        "The value whose minimal data type is to be found.",
        "The value whose minimal data type is to"
    ],
    [
        "Returns the type that results from applying the NumPy",
        "Returns the type that results from applying"
    ],
    [
        "type promotion rules to the arguments.",
        "type promotion rules to the"
    ],
    [
        "Type promotion in NumPy works similarly to the rules in languages",
        "Type promotion in NumPy works similarly to the"
    ],
    [
        "like C++, with some slight differences.  When both scalars and",
        "like C++, with some slight differences. When both"
    ],
    [
        "arrays are used, the array's type takes precedence and the actual value",
        "arrays are used, the array's type takes precedence"
    ],
    [
        "of the scalar is taken into account.",
        "of the scalar is"
    ],
    [
        "arrays_and_dtypes : list of arrays and dtypes",
        "arrays_and_dtypes : list of"
    ],
    [
        "The operands of some operation whose result type is needed.",
        "The operands of some operation whose"
    ],
    [
        "The specific algorithm used is as follows.",
        "The specific algorithm used is"
    ],
    [
        "Categories are determined by first checking which of boolean,",
        "Categories are determined by first checking which of"
    ],
    [
        "integer (int/uint), or floating point (float/complex) the maximum",
        "integer (int/uint), or floating point"
    ],
    [
        "kind of all the arrays and the scalars are.",
        "kind of all the arrays and the scalars"
    ],
    [
        "If there are only scalars or the maximum category of the scalars",
        "If there are only scalars or the maximum category"
    ],
    [
        "is higher than the maximum category of the arrays,",
        "is higher than the maximum category of"
    ],
    [
        "the data types are combined with :func:`promote_types`",
        "the data types are"
    ],
    [
        "Otherwise, `min_scalar_type` is called on each scalar, and",
        "Otherwise, `min_scalar_type` is called on each"
    ],
    [
        "the resulting data types are all combined with :func:`promote_types`",
        "the resulting data types are"
    ],
    [
        "The set of int values is not a subset of the uint values for types",
        "The set of int values is not a subset of the uint values"
    ],
    [
        "with the same number of bits, something not reflected in",
        "with the same number of bits, something not"
    ],
    [
        ":func:`min_scalar_type`, but handled as a special case in `result_type`.",
        ":func:`min_scalar_type`, but handled as a special case in"
    ],
    [
        "Dot product of two arrays. Specifically,",
        "Dot product of two arrays."
    ],
    [
        "but using :func:`matmul` or ``a @ b`` is preferred.",
        "but using :func:`matmul` or ``a"
    ],
    [
        ":func:`multiply` and using ``numpy.multiply(a, b)`` or ``a * b`` is",
        ":func:`multiply` and using ``numpy.multiply(a, b)`` or ``a * b``"
    ],
    [
        "the last axis of `a` and `b`.",
        "the last axis of `a` and"
    ],
    [
        "sum product over the last axis of `a` and the second-to-last axis of",
        "sum product over the last axis of `a` and the second-to-last axis"
    ],
    [
        "dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])",
        "dot(a, b)[i,j,k,m] = sum(a[i,j,:]"
    ],
    [
        "It uses an optimized BLAS library when possible (see `numpy.linalg`).",
        "It uses an optimized BLAS library when possible"
    ],
    [
        "Output argument. This must have the exact kind that would be returned",
        "Output argument. This must have the exact kind that"
    ],
    [
        "if it was not used. In particular, it must have the right type, must be",
        "if it was not used. In particular, it must"
    ],
    [
        "C-contiguous, and its dtype must be the dtype that would be returned",
        "C-contiguous, and its dtype must be the dtype that would"
    ],
    [
        "for `dot(a,b)`. This is a performance feature. Therefore, if these",
        "for `dot(a,b)`. This is a performance feature. Therefore, if"
    ],
    [
        "conditions are not met, an exception is raised, instead of attempting",
        "conditions are not met, an exception is raised,"
    ],
    [
        "Returns the dot product of `a` and `b`.  If `a` and `b` are both",
        "Returns the dot product of `a` and `b`. If `a` and"
    ],
    [
        "If `out` is given, then it is returned.",
        "If `out` is given, then it is"
    ],
    [
        "If the last dimension of `a` is not the same size as",
        "If the last dimension of `a` is not the same"
    ],
    [
        "vecdot : Vector dot product of two arrays.",
        "vecdot : Vector dot"
    ],
    [
        "tensordot : Sum products over arbitrary axes.",
        "tensordot : Sum products over"
    ],
    [
        "matmul : '@' operator as method with out parameter.",
        "matmul : '@' operator as"
    ],
    [
        "Return the dot product of two vectors.",
        "Return the dot product of two"
    ],
    [
        "The `vdot` function handles complex numbers differently than `dot`:",
        "The `vdot` function handles complex numbers"
    ],
    [
        "if the first argument is complex, it is replaced by its complex conjugate",
        "if the first argument is complex, it is replaced by its"
    ],
    [
        "in the dot product calculation. `vdot` also handles multidimensional",
        "in the dot product calculation. `vdot` also"
    ],
    [
        "arrays differently than `dot`: it does not perform a matrix product, but",
        "arrays differently than `dot`: it does not perform a matrix"
    ],
    [
        "(also known as the *trace inner product* or the *standard inner product*",
        "(also known as the *trace inner product*"
    ],
    [
        "on a vector space of matrices).",
        "on a vector"
    ],
    [
        "If `a` is complex the complex conjugate is taken before calculation",
        "If `a` is complex the complex conjugate is"
    ],
    [
        "Second argument to the dot product.",
        "Second argument to"
    ],
    [
        "Dot product of `a` and `b`.  Can be an int, float, or",
        "Dot product of `a` and `b`. Can be an int, float,"
    ],
    [
        "complex depending on the types of `a` and `b`.",
        "complex depending on the types of `a` and"
    ],
    [
        "dot : Return the dot product without using the complex conjugate of the",
        "dot : Return the dot product without using the complex"
    ],
    [
        "Note that higher-dimensional arrays are flattened!",
        "Note that higher-dimensional arrays are"
    ],
    [
        "Count number of occurrences of each value in array of non-negative ints.",
        "Count number of occurrences of each"
    ],
    [
        "`x`. If `minlength` is specified, there will be at least this number",
        "`x`. If `minlength` is specified, there"
    ],
    [
        "of bins in the output array (though it will be longer if necessary,",
        "of bins in the output array (though it will be longer"
    ],
    [
        "depending on the contents of `x`).",
        "depending on the contents"
    ],
    [
        "Each bin gives the number of occurrences of its index value in `x`.",
        "Each bin gives the number of occurrences of its index value in"
    ],
    [
        "If `weights` is specified the input array is weighted by it, i.e. if a",
        "If `weights` is specified the input array is"
    ],
    [
        "value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead",
        "value ``n`` is found at position"
    ],
    [
        "Weights, array of the same shape as `x`.",
        "Weights, array of the same shape as"
    ],
    [
        "A minimum number of bins for the output array.",
        "A minimum number of bins for the"
    ],
    [
        "The result of binning the input array.",
        "The result of binning the"
    ],
    [
        "values, or if `minlength` is negative.",
        "values, or if `minlength`"
    ],
    [
        "If the type of the input is float or complex.",
        "If the type of the input is"
    ],
    [
        "The input array needs to be of integer dtype, otherwise a",
        "The input array needs to be of integer dtype,"
    ],
    [
        "A possible use of ``bincount`` is to perform sums over",
        "A possible use of ``bincount`` is to perform sums"
    ],
    [
        "variable-size chunks of an array, using the ``weights`` keyword.",
        "variable-size chunks of an array,"
    ],
    [
        "Converts a tuple of index arrays into an array of flat",
        "Converts a tuple of index arrays into an array"
    ],
    [
        "indices, applying boundary modes to the multi-index.",
        "indices, applying boundary modes"
    ],
    [
        "A tuple of integer arrays, one array for each dimension.",
        "A tuple of integer arrays, one array for each"
    ],
    [
        "The shape of array into which the indices from ``multi_index`` apply.",
        "The shape of array into which the indices from"
    ],
    [
        "mode : {'raise', 'wrap', 'clip'}, optional",
        "mode : {'raise', 'wrap', 'clip'},"
    ],
    [
        "Specifies how out-of-bounds indices are handled.  Can specify",
        "Specifies how out-of-bounds indices are"
    ],
    [
        "either one mode or a tuple of modes, one mode per index.",
        "either one mode or a tuple of modes,"
    ],
    [
        "* 'raise' -- raise an error (default)",
        "* 'raise' -- raise an error"
    ],
    [
        "* 'clip' -- clip to the range",
        "* 'clip' -- clip"
    ],
    [
        "In 'clip' mode, a negative index which would normally",
        "In 'clip' mode, a negative"
    ],
    [
        "Determines whether the multi-index should be viewed as",
        "Determines whether the multi-index should"
    ],
    [
        "indexing in row-major (C-style) or column-major",
        "indexing in row-major (C-style) or"
    ],
    [
        "An array of indices into the flattened version of an array",
        "An array of indices into the"
    ],
    [
        "Converts a flat index or array of flat indices into a tuple",
        "Converts a flat index or array of flat indices"
    ],
    [
        "An integer array whose elements are indices into the flattened",
        "An integer array whose elements are"
    ],
    [
        "this function accepted just one index value.",
        "this function accepted just"
    ],
    [
        "The shape of the array to use for unraveling ``indices``.",
        "The shape of the array to use"
    ],
    [
        "Determines whether the indices should be viewed as indexing in",
        "Determines whether the indices should be viewed as"
    ],
    [
        "row-major (C-style) or column-major (Fortran-style) order.",
        "row-major (C-style) or column-major (Fortran-style)"
    ],
    [
        "Each array in the tuple has the same shape as the ``indices``",
        "Each array in the tuple has the"
    ],
    [
        "Copies values from one array to another, broadcasting as necessary.",
        "Copies values from one array"
    ],
    [
        "Raises a TypeError if the `casting` rule is violated, and if",
        "Raises a TypeError if the `casting` rule is violated,"
    ],
    [
        "`where` is provided, it selects which elements to copy.",
        "`where` is provided, it selects"
    ],
    [
        "The array into which values are copied.",
        "The array into which values"
    ],
    [
        "The array from which values are copied.",
        "The array from which values"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe', 'same_kind',"
    ],
    [
        "Controls what kind of data casting may occur when copying.",
        "Controls what kind of data casting may"
    ],
    [
        "* 'no' means the data types should not be cast at all.",
        "* 'no' means the data types should not"
    ],
    [
        "* 'equiv' means only byte-order changes are allowed.",
        "* 'equiv' means only byte-order changes are"
    ],
    [
        "* 'safe' means only casts which can preserve values are allowed.",
        "* 'safe' means only casts which can preserve values"
    ],
    [
        "* 'same_kind' means only safe casts or casts within a kind,",
        "* 'same_kind' means only safe casts"
    ],
    [
        "* 'unsafe' means any data conversions may be done.",
        "* 'unsafe' means any data"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of"
    ],
    [
        "A boolean array which is broadcasted to match the dimensions",
        "A boolean array which is broadcasted to"
    ],
    [
        "of `dst`, and selects elements to copy from `src` to `dst`",
        "of `dst`, and selects elements to copy from `src` to"
    ],
    [
        "wherever it contains the value True.",
        "wherever it contains"
    ],
    [
        "Changes elements of an array based on conditional and input values.",
        "Changes elements of an array based on conditional and input"
    ],
    [
        "Sets ``a.flat[n] = values[n]`` for each n where ``mask.flat[n]==True``.",
        "Sets ``a.flat[n] = values[n]`` for"
    ],
    [
        "If `values` is not the same size as `a` and `mask` then it will repeat.",
        "If `values` is not the same size as `a` and `mask`"
    ],
    [
        "This gives behavior different from ``a[mask] = values``.",
        "This gives behavior different"
    ],
    [
        "Boolean mask array. It has to be the same shape as `a`.",
        "Boolean mask array. It has to be"
    ],
    [
        "Values to put into `a` where `mask` is True. If `values` is smaller",
        "Values to put into `a` where `mask` is True. If `values` is"
    ],
    [
        "than `a` it will be repeated.",
        "than `a` it will"
    ],
    [
        "If `values` is smaller than `a` it is repeated:",
        "If `values` is smaller than `a`"
    ],
    [
        "The result is padded to full bytes by inserting zero bits at the end.",
        "The result is padded to full bytes by inserting zero bits at"
    ],
    [
        "An array of integers or booleans whose elements should be packed to",
        "An array of integers or booleans whose elements should be packed"
    ],
    [
        "The dimension over which bit-packing is done.",
        "The dimension over which"
    ],
    [
        "``None`` implies packing the flattened array.",
        "``None`` implies packing"
    ],
    [
        "The order of the input bits. 'big' will mimic bin(val),",
        "The order of the input bits. 'big' will mimic"
    ],
    [
        "`packed` has the same number of dimensions as the input (unless `axis`",
        "`packed` has the same number of"
    ],
    [
        "Each element of `a` represents a bit-field that should be unpacked",
        "Each element of `a` represents a bit-field that should be"
    ],
    [
        "into a binary-valued output array. The shape of the output array is",
        "into a binary-valued output array. The"
    ],
    [
        "array with unpacking done along the axis specified.",
        "array with unpacking done"
    ],
    [
        "The dimension over which bit-unpacking is done.",
        "The dimension over which bit-unpacking is"
    ],
    [
        "``None`` implies unpacking the flattened array.",
        "``None`` implies unpacking the"
    ],
    [
        "count : int or None, optional",
        "count : int or None,"
    ],
    [
        "The number of elements to unpack along `axis`, provided as a way",
        "The number of elements to unpack along `axis`,"
    ],
    [
        "of undoing the effect of packing a size that is not a multiple",
        "of undoing the effect of packing a size that is not"
    ],
    [
        "of eight. A non-negative number means to only unpack `count`",
        "of eight. A non-negative number means to"
    ],
    [
        "bits. A negative number means to trim off that many bits from",
        "bits. A negative number means to trim"
    ],
    [
        "the end. ``None`` means to unpack the entire array (the",
        "the end. ``None`` means to unpack the entire array"
    ],
    [
        "default). Counts larger than the available number of bits will",
        "default). Counts larger than the available number of bits"
    ],
    [
        "add zero padding to the output. Negative counts must not",
        "add zero padding to the output. Negative counts"
    ],
    [
        "exceed the available number of bits.",
        "exceed the available number of"
    ],
    [
        "The order of the returned bits. 'big' will mimic bin(val),",
        "The order of the returned bits. 'big' will"
    ],
    [
        "packbits : Packs the elements of a binary-valued array into bits in",
        "packbits : Packs the elements of a binary-valued array into bits"
    ],
    [
        "Determine if two arrays share memory.",
        "Determine if two"
    ],
    [
        "This function can be exponentially slow for some inputs, unless",
        "This function can be exponentially slow for"
    ],
    [
        "`max_work` is set to zero or a positive integer.",
        "`max_work` is set to zero"
    ],
    [
        "If in doubt, use `numpy.may_share_memory` instead.",
        "If in doubt, use"
    ],
    [
        "Effort to spend on solving the overlap problem (maximum number",
        "Effort to spend on solving the overlap problem"
    ],
    [
        "of candidate solutions to consider). The following special",
        "of candidate solutions to"
    ],
    [
        "The problem is solved exactly. In this case, the function returns",
        "The problem is solved exactly. In this case, the"
    ],
    [
        "True only if there is an element shared between the arrays. Finding",
        "True only if there is an element"
    ],
    [
        "the exact solution may take extremely long in some cases.",
        "the exact solution may take extremely long"
    ],
    [
        "Only the memory bounds of a and b are checked.",
        "Only the memory bounds of a"
    ],
    [
        "This is equivalent to using ``may_share_memory()``.",
        "This is equivalent to"
    ],
    [
        "Checking whether two arrays share memory is NP-complete, and",
        "Checking whether two arrays share memory is NP-complete,"
    ],
    [
        "runtime may increase exponentially in the number of",
        "runtime may increase exponentially in the number"
    ],
    [
        "dimensions. Hence, `max_work` should generally be set to a finite",
        "dimensions. Hence, `max_work` should generally be"
    ],
    [
        "number, as it is possible to construct examples that take",
        "number, as it is possible to"
    ],
    [
        "Determine if two arrays might share memory",
        "Determine if two arrays might"
    ],
    [
        "A return of True does not necessarily mean that the two arrays",
        "A return of True does not necessarily mean"
    ],
    [
        "share any element.  It just means that they *might*.",
        "share any element. It just means that"
    ],
    [
        "Only the memory bounds of a and b are checked by default.",
        "Only the memory bounds of a"
    ],
    [
        "Effort to spend on solving the overlap problem.  See",
        "Effort to spend on solving the"
    ],
    [
        "`shares_memory` for details.  Default for ``may_share_memory``",
        "`shares_memory` for details. Default"
    ],
    [
        "is to do a bounds check.",
        "is to do a bounds"
    ],
    [
        "def is_busday(dates, weekmask=None, holidays=None, busdaycal=None, out=None):",
        "def is_busday(dates, weekmask=None, holidays=None, busdaycal=None,"
    ],
    [
        "Calculates which of the given dates are valid days, and which are not.",
        "Calculates which of the given dates are valid days, and which"
    ],
    [
        "The array of dates to process.",
        "The array of dates"
    ],
    [
        "weekmask : str or array_like of bool, optional",
        "weekmask : str or array_like of bool,"
    ],
    [
        "A seven-element array indicating which of Monday through Sunday are",
        "A seven-element array indicating which of Monday through"
    ],
    [
        "valid days. May be specified as a length-seven list or array, like",
        "valid days. May be specified as a length-seven list or array,"
    ],
    [
        "weekdays, optionally separated by white space. Valid abbreviations",
        "weekdays, optionally separated by white space."
    ],
    [
        "are: Mon Tue Wed Thu Fri Sat Sun",
        "are: Mon Tue Wed Thu Fri"
    ],
    [
        "An array of dates to consider as invalid dates.  They may be",
        "An array of dates to consider as invalid dates."
    ],
    [
        "specified in any order, and NaT (not-a-time) dates are ignored.",
        "specified in any order, and NaT"
    ],
    [
        "This list is saved in a normalized form that is suited for",
        "This list is saved in a normalized form that is suited"
    ],
    [
        "A `busdaycalendar` object which specifies the valid days. If this",
        "A `busdaycalendar` object which specifies"
    ],
    [
        "parameter is provided, neither weekmask nor holidays may be",
        "parameter is provided, neither weekmask"
    ],
    [
        "out : array of bool, optional",
        "out : array"
    ],
    [
        "If provided, this array is filled with the result.",
        "If provided, this array is filled"
    ],
    [
        "An array with the same shape as ``dates``, containing True for",
        "An array with the same shape as"
    ],
    [
        "each valid day, and False for each invalid day.",
        "each valid day, and False for each"
    ],
    [
        "busdaycalendar : An object that specifies a custom set of valid days.",
        "busdaycalendar : An object that specifies a custom"
    ],
    [
        "busday_offset : Applies an offset counted in valid days.",
        "busday_offset : Applies an offset"
    ],
    [
        "busday_count : Counts how many valid days are in a half-open date range.",
        "busday_count : Counts how many valid days"
    ],
    [
        "def busday_offset(dates, offsets, roll=None, weekmask=None, holidays=None,",
        "def busday_offset(dates, offsets, roll=None, weekmask=None,"
    ],
    [
        "First adjusts the date to fall on a valid day according to",
        "First adjusts the date to fall"
    ],
    [
        "the ``roll`` rule, then applies offsets to the given dates",
        "the ``roll`` rule, then applies offsets to the given"
    ],
    [
        "The array of dates to process.",
        "The array of"
    ],
    [
        "The array of offsets, which is broadcast with ``dates``.",
        "The array of offsets, which"
    ],
    [
        "roll : {'raise', 'nat', 'forward', 'following', 'backward', 'preceding', \\",
        "roll : {'raise', 'nat', 'forward',"
    ],
    [
        "How to treat dates that do not fall on a valid day. The default",
        "How to treat dates that do not fall on a"
    ],
    [
        "* 'raise' means to raise an exception for an invalid day.",
        "* 'raise' means to raise an exception"
    ],
    [
        "* 'nat' means to return a NaT (not-a-time) for an invalid day.",
        "* 'nat' means to return a"
    ],
    [
        "* 'forward' and 'following' mean to take the first valid day",
        "* 'forward' and 'following' mean to take the first valid"
    ],
    [
        "* 'backward' and 'preceding' mean to take the first valid day",
        "* 'backward' and 'preceding' mean to take the first valid"
    ],
    [
        "* 'modifiedfollowing' means to take the first valid day",
        "* 'modifiedfollowing' means to take"
    ],
    [
        "later in time unless it is across a Month boundary, in which",
        "later in time unless it is"
    ],
    [
        "case to take the first valid day earlier in time.",
        "case to take the first"
    ],
    [
        "* 'modifiedpreceding' means to take the first valid day",
        "* 'modifiedpreceding' means to take the"
    ],
    [
        "earlier in time unless it is across a Month boundary, in which",
        "earlier in time unless it is across a Month boundary, in"
    ],
    [
        "case to take the first valid day later in time.",
        "case to take the first"
    ],
    [
        "weekmask : str or array_like of bool, optional",
        "weekmask : str or"
    ],
    [
        "A seven-element array indicating which of Monday through Sunday are",
        "A seven-element array indicating which of Monday through Sunday"
    ],
    [
        "valid days. May be specified as a length-seven list or array, like",
        "valid days. May be specified as"
    ],
    [
        "weekdays, optionally separated by white space. Valid abbreviations",
        "weekdays, optionally separated by"
    ],
    [
        "are: Mon Tue Wed Thu Fri Sat Sun",
        "are: Mon Tue Wed Thu Fri"
    ],
    [
        "An array of dates to consider as invalid dates.  They may be",
        "An array of dates to consider as invalid dates. They"
    ],
    [
        "specified in any order, and NaT (not-a-time) dates are ignored.",
        "specified in any order, and"
    ],
    [
        "This list is saved in a normalized form that is suited for",
        "This list is saved in a normalized form"
    ],
    [
        "A `busdaycalendar` object which specifies the valid days. If this",
        "A `busdaycalendar` object which specifies"
    ],
    [
        "parameter is provided, neither weekmask nor holidays may be",
        "parameter is provided, neither weekmask nor holidays may"
    ],
    [
        "If provided, this array is filled with the result.",
        "If provided, this array is filled with"
    ],
    [
        "An array with a shape from broadcasting ``dates`` and ``offsets``",
        "An array with a shape from broadcasting ``dates`` and"
    ],
    [
        "together, containing the dates with offsets applied.",
        "together, containing the dates with offsets"
    ],
    [
        "busdaycalendar : An object that specifies a custom set of valid days.",
        "busdaycalendar : An object that specifies a custom set"
    ],
    [
        "is_busday : Returns a boolean array indicating valid days.",
        "is_busday : Returns a boolean array indicating valid"
    ],
    [
        "busday_count : Counts how many valid days are in a half-open date range.",
        "busday_count : Counts how many valid days are in"
    ],
    [
        "return (dates, offsets, weekmask, holidays, out)",
        "return (dates, offsets, weekmask, holidays,"
    ],
    [
        "Counts the number of valid days between `begindates` and",
        "Counts the number of valid days between"
    ],
    [
        "`enddates`, not including the day of `enddates`.",
        "`enddates`, not including the day"
    ],
    [
        "If ``enddates`` specifies a date value that is earlier than the",
        "If ``enddates`` specifies a date value that is"
    ],
    [
        "corresponding ``begindates`` date value, the count will be negative.",
        "corresponding ``begindates`` date value, the count will be"
    ],
    [
        "The array of the first dates for counting.",
        "The array of the first"
    ],
    [
        "The array of the end dates for counting, which are excluded",
        "The array of the end dates for counting, which"
    ],
    [
        "weekmask : str or array_like of bool, optional",
        "weekmask : str or array_like"
    ],
    [
        "A seven-element array indicating which of Monday through Sunday are",
        "A seven-element array indicating which of"
    ],
    [
        "valid days. May be specified as a length-seven list or array, like",
        "valid days. May be specified as a length-seven list or"
    ],
    [
        "weekdays, optionally separated by white space. Valid abbreviations",
        "weekdays, optionally separated by"
    ],
    [
        "are: Mon Tue Wed Thu Fri Sat Sun",
        "are: Mon Tue Wed"
    ],
    [
        "An array of dates to consider as invalid dates.  They may be",
        "An array of dates to consider"
    ],
    [
        "specified in any order, and NaT (not-a-time) dates are ignored.",
        "specified in any order, and NaT"
    ],
    [
        "This list is saved in a normalized form that is suited for",
        "This list is saved in a"
    ],
    [
        "A `busdaycalendar` object which specifies the valid days. If this",
        "A `busdaycalendar` object which specifies the"
    ],
    [
        "parameter is provided, neither weekmask nor holidays may be",
        "parameter is provided, neither weekmask nor holidays"
    ],
    [
        "out : array of int, optional",
        "out : array of int,"
    ],
    [
        "If provided, this array is filled with the result.",
        "If provided, this array is filled with the"
    ],
    [
        "An array with a shape from broadcasting ``begindates`` and ``enddates``",
        "An array with a shape from broadcasting ``begindates`` and"
    ],
    [
        "together, containing the number of valid days between",
        "together, containing the number"
    ],
    [
        "busdaycalendar : An object that specifies a custom set of valid days.",
        "busdaycalendar : An object that specifies a"
    ],
    [
        "is_busday : Returns a boolean array indicating valid days.",
        "is_busday : Returns a boolean array indicating valid"
    ],
    [
        "busday_offset : Applies an offset counted in valid days.",
        "busday_offset : Applies an offset counted in valid"
    ],
    [
        "return (begindates, enddates, weekmask, holidays, out)",
        "return (begindates, enddates, weekmask, holidays,"
    ],
    [
        "Convert an array of datetimes into an array of strings.",
        "Convert an array of datetimes"
    ],
    [
        "The array of UTC timestamps to format.",
        "The array of UTC"
    ],
    [
        "timezone : {'naive', 'UTC', 'local'} or tzinfo",
        "timezone : {'naive', 'UTC', 'local'} or"
    ],
    [
        "Timezone information to use when displaying the datetime. If 'UTC',",
        "Timezone information to use when displaying"
    ],
    [
        "end with a Z to indicate UTC time. If 'local', convert to the local",
        "end with a Z to indicate UTC time. If 'local', convert to"
    ],
    [
        "object, then do as with 'local', but use the specified timezone.",
        "object, then do as with 'local', but"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}",
        "casting : {'no', 'equiv', 'safe',"
    ],
    [
        "Casting to allow when changing between datetime units.",
        "Casting to allow when changing between"
    ],
    [
        "An array of strings the same shape as `arr`.",
        "An array of strings the same"
    ],
    [
        "Setting the timezone to UTC shows the same information, but with a Z suffix",
        "Setting the timezone to UTC shows the same"
    ],
    [
        "Note that we picked datetimes that cross a DST boundary. Passing in a",
        "Note that we picked datetimes that cross a DST boundary. Passing in"
    ],
    [
        "``pytz`` timezone object will print the appropriate offset",
        "``pytz`` timezone object will print the appropriate"
    ],
    [
        "Passing in a unit will change the precision",
        "Passing in a unit will"
    ],
    [
        "'casting' can be used to specify whether precision can be changed",
        "'casting' can be used to specify whether precision can be"
    ],
    [
        "TypeError: Cannot create a datetime string as units 'h' from a NumPy",
        "TypeError: Cannot create a datetime string as units 'h' from a"
    ],
    [
        "datetime with units 'm' according to the rule 'safe'",
        "datetime with units 'm' according"
    ],
    [
        "Functions in the ``as*array`` family that promote array-likes into arrays.",
        "Functions in the ``as*array`` family that promote"
    ],
    [
        "`require` fits this category despite its name not matching this pattern.",
        "`require` fits this category despite its name not matching this"
    ],
    [
        "'C': 'C', 'C_CONTIGUOUS': 'C', 'CONTIGUOUS': 'C',",
        "'C': 'C', 'C_CONTIGUOUS': 'C', 'CONTIGUOUS':"
    ],
    [
        "'F': 'F', 'F_CONTIGUOUS': 'F', 'FORTRAN': 'F',",
        "'F': 'F', 'F_CONTIGUOUS':"
    ],
    [
        "def require(a, dtype=None, requirements=None, *, like=None):",
        "def require(a, dtype=None, requirements=None, *,"
    ],
    [
        "Return an ndarray of the provided type that satisfies requirements.",
        "Return an ndarray of the provided type that"
    ],
    [
        "This function is useful to be sure that an array with the correct flags",
        "This function is useful to be sure that"
    ],
    [
        "is returned for passing to compiled code (perhaps through ctypes).",
        "is returned for passing to compiled code (perhaps through"
    ],
    [
        "The object to be converted to a type-and-requirement-satisfying array.",
        "The object to be converted to a"
    ],
    [
        "The required data-type. If None preserve the current dtype. If your",
        "The required data-type. If None preserve the current dtype."
    ],
    [
        "application requires the data to be in native byteorder, include",
        "application requires the data to be in native byteorder,"
    ],
    [
        "a byteorder specification as a part of the dtype specification.",
        "a byteorder specification as a"
    ],
    [
        "requirements : str or sequence of str",
        "requirements : str or sequence of"
    ],
    [
        "The requirements list can be any of the following",
        "The requirements list can be any"
    ],
    [
        "* 'F_CONTIGUOUS' ('F') - ensure a Fortran-contiguous array",
        "* 'F_CONTIGUOUS' ('F') - ensure"
    ],
    [
        "* 'C_CONTIGUOUS' ('C') - ensure a C-contiguous array",
        "* 'C_CONTIGUOUS' ('C') - ensure"
    ],
    [
        "* 'ALIGNED' ('A')      - ensure a data-type aligned array",
        "* 'ALIGNED' ('A') - ensure a data-type"
    ],
    [
        "* 'WRITEABLE' ('W')    - ensure a writable array",
        "* 'WRITEABLE' ('W') - ensure"
    ],
    [
        "* 'OWNDATA' ('O')      - ensure an array that owns its own data",
        "* 'OWNDATA' ('O') - ensure an array that owns"
    ],
    [
        "* 'ENSUREARRAY', ('E') - ensure a base array, instead of a subclass",
        "* 'ENSUREARRAY', ('E') - ensure a base array,"
    ],
    [
        "Array with specified requirements and type if given.",
        "Array with specified requirements and"
    ],
    [
        "asarray : Convert input to an ndarray.",
        "asarray : Convert input"
    ],
    [
        "asanyarray : Convert to an ndarray, but pass through ndarray subclasses.",
        "asanyarray : Convert to an ndarray, but pass through"
    ],
    [
        "ascontiguousarray : Convert input to a contiguous array.",
        "ascontiguousarray : Convert input"
    ],
    [
        "asfortranarray : Convert input to an ndarray with column-major",
        "asfortranarray : Convert input to an"
    ],
    [
        "ndarray.flags : Information about the memory layout of the array.",
        "ndarray.flags : Information about the memory layout"
    ],
    [
        "The returned array will be guaranteed to have the listed requirements",
        "The returned array will be guaranteed"
    ],
    [
        "by making a copy if needed.",
        "by making a copy if"
    ],
    [
        "requirements = {POSSIBLE_FLAGS[x.upper()] for x in requirements}",
        "requirements = {POSSIBLE_FLAGS[x.upper()] for"
    ],
    [
        "raise ValueError('Cannot specify both \"C\" and \"F\" order')",
        "raise ValueError('Cannot specify both \"C\" and"
    ],
    [
        "arr = array(a, dtype=dtype, order=order, copy=None, subok=subok)",
        "arr = array(a, dtype=dtype,"
    ],
    [
        "This module contains a set of functions for record arrays.",
        "This module contains a set of functions for"
    ],
    [
        "from . import numeric as sb",
        "from . import numeric as"
    ],
    [
        "from . import numerictypes as nt",
        "from . import numerictypes as"
    ],
    [
        "\"\"\"Find duplication in a list, return a list of duplicated elements\"\"\"",
        "\"\"\"Find duplication in a list, return a list of duplicated"
    ],
    [
        "Class to convert formats, names, titles description to a dtype.",
        "Class to convert formats, names, titles description"
    ],
    [
        "After constructing the format_parser object, the dtype attribute is",
        "After constructing the format_parser object, the dtype"
    ],
    [
        "formats : str or list of str",
        "formats : str or list"
    ],
    [
        "The format description, either specified as a string with",
        "The format description, either specified as a string"
    ],
    [
        "a list of format description strings  in the form",
        "a list of format description"
    ],
    [
        "names : str or list/tuple of str",
        "names : str or list/tuple"
    ],
    [
        "The field names, either specified as a comma-separated string in the",
        "The field names, either specified as"
    ],
    [
        "An empty list can be used, in that case default field names",
        "An empty list can be used, in that"
    ],
    [
        "Sequence of title strings. An empty list can be used to leave titles",
        "Sequence of title strings. An empty list can be used"
    ],
    [
        "If True, align the fields by padding as the C-compiler would.",
        "If True, align the fields by"
    ],
    [
        "If specified, all the fields will be changed to the",
        "If specified, all the fields will"
    ],
    [
        "provided byte-order.  Otherwise, the default byte-order is",
        "provided byte-order. Otherwise, the default byte-order"
    ],
    [
        "used. For all available string specifiers, see `dtype.newbyteorder`.",
        "used. For all available string specifiers,"
    ],
    [
        "`names` and/or `titles` can be empty lists. If `titles` is an empty list,",
        "`names` and/or `titles` can be empty lists. If `titles` is"
    ],
    [
        "titles will simply not appear. If `names` is empty, default field names",
        "titles will simply not appear. If `names` is empty,"
    ],
    [
        "def __init__(self, formats, names, titles, aligned=False, byteorder=None):",
        "def __init__(self, formats, names,"
    ],
    [
        "\"\"\" Parse the field formats \"\"\"",
        "\"\"\" Parse the field"
    ],
    [
        "\"\"\"convert input field names into a list and assign to the _names",
        "\"\"\"convert input field names into a list and assign to the"
    ],
    [
        "raise NameError(\"illegal input names %s\" % repr(names))",
        "raise NameError(\"illegal input names %s\" %"
    ],
    [
        "self._names = [n.strip() for n in names[:self._nfields]]",
        "self._names = [n.strip() for n in"
    ],
    [
        "self._names += ['f%d' % i for i in range(len(self._names),",
        "self._names += ['f%d' % i"
    ],
    [
        "raise ValueError(\"Duplicate field names: %s\" % _dup)",
        "raise ValueError(\"Duplicate field names: %s\" %"
    ],
    [
        "self._titles = [n.strip() for n in titles[:self._nfields]]",
        "self._titles = [n.strip() for"
    ],
    [
        "self._titles += [None] * (self._nfields - len(titles))",
        "self._titles += [None] *"
    ],
    [
        "\"\"\"A data-type scalar that allows field access as attribute lookup.",
        "\"\"\"A data-type scalar that allows field access"
    ],
    [
        "if attr in ('setfield', 'getfield', 'dtype'):",
        "if attr in"
    ],
    [
        "raise AttributeError(\"'record' object has no \"",
        "raise AttributeError(\"'record' object"
    ],
    [
        "if attr in ('setfield', 'getfield', 'dtype'):",
        "if attr in"
    ],
    [
        "raise AttributeError(\"Cannot set '%s' attribute\" % attr)",
        "raise AttributeError(\"Cannot set '%s' attribute\""
    ],
    [
        "raise AttributeError(\"'record' object has no \"",
        "raise AttributeError(\"'record' object has no"
    ],
    [
        "if isinstance(obj, nt.void) and obj.dtype.names is not None:",
        "if isinstance(obj, nt.void) and obj.dtype.names is not"
    ],
    [
        "maxlen = max(len(name) for name in names)",
        "maxlen = max(len(name) for name in"
    ],
    [
        "fmt = '%% %ds: %%s' % maxlen",
        "fmt = '%% %ds: %%s' %"
    ],
    [
        "rows = [fmt % (name, getattr(self, name)) for name in names]",
        "rows = [fmt % (name, getattr(self, name)) for"
    ],
    [
        "\"\"\"Construct an ndarray that allows field access using attributes.",
        "\"\"\"Construct an ndarray that allows field"
    ],
    [
        "Arrays may have a data-types containing fields, analogous",
        "Arrays may have a data-types"
    ],
    [
        "to columns in a spread sheet.  An example is ``[(x, int), (y, float)]``,",
        "to columns in a spread sheet. An"
    ],
    [
        "where each entry in the array is a pair of ``(int, float)``.  Normally,",
        "where each entry in the array is a pair of"
    ],
    [
        "these attributes are accessed using dictionary lookups such as ``arr['x']``",
        "these attributes are accessed using dictionary lookups"
    ],
    [
        "and ``arr['y']``.  Record arrays allow the fields to be accessed as members",
        "and ``arr['y']``. Record arrays allow the fields to"
    ],
    [
        "of the array, using ``arr.x`` and ``arr.y``.",
        "of the array, using ``arr.x``"
    ],
    [
        "The desired data-type.  By default, the data-type is determined",
        "The desired data-type. By default, the data-type is"
    ],
    [
        "from `formats`, `names`, `titles`, `aligned` and `byteorder`.",
        "from `formats`, `names`, `titles`,"
    ],
    [
        "formats : list of data-types, optional",
        "formats : list of"
    ],
    [
        "A list containing the data-types for the different columns, e.g.",
        "A list containing the data-types for the different"
    ],
    [
        "convention of using types directly, i.e. ``(int, float, int)``.",
        "convention of using types directly,"
    ],
    [
        "Note that `formats` must be a list, not a tuple.",
        "Note that `formats` must be"
    ],
    [
        "Given that `formats` is somewhat limited, we recommend specifying",
        "Given that `formats` is somewhat limited, we recommend"
    ],
    [
        "names : tuple of str, optional",
        "names : tuple of"
    ],
    [
        "The name of each column, e.g. ``('x', 'y', 'z')``.",
        "The name of each column, e.g."
    ],
    [
        "By default, a new array is created of the given shape and data-type.",
        "By default, a new array is created"
    ],
    [
        "If `buf` is specified and is an object exposing the buffer interface,",
        "If `buf` is specified and is an object exposing the buffer"
    ],
    [
        "the array will use the memory from the existing buffer.  In this case,",
        "the array will use the memory from the existing buffer."
    ],
    [
        "the `offset` and `strides` keywords are available.",
        "the `offset` and `strides` keywords are"
    ],
    [
        "titles : tuple of str, optional",
        "titles : tuple of"
    ],
    [
        "Aliases for column names.  For example, if `names` were",
        "Aliases for column names. For"
    ],
    [
        "``('x', 'y', 'z')`` and `titles` is",
        "``('x', 'y', 'z')`` and"
    ],
    [
        "``arr['x']`` is equivalent to both ``arr.x`` and ``arr.x_coordinate``.",
        "``arr['x']`` is equivalent to"
    ],
    [
        "byteorder : {'<', '>', '='}, optional",
        "byteorder : {'<', '>', '='},"
    ],
    [
        "Align the fields in memory as the C-compiler would.",
        "Align the fields in memory as the C-compiler"
    ],
    [
        "strides : tuple of ints, optional",
        "strides : tuple of"
    ],
    [
        "Buffer (`buf`) is interpreted according to these strides (strides",
        "Buffer (`buf`) is interpreted according to"
    ],
    [
        "define how many bytes each array element, row, column, etc.",
        "define how many bytes each array element, row, column,"
    ],
    [
        "Start reading buffer (`buf`) from this offset onwards.",
        "Start reading buffer (`buf`)"
    ],
    [
        "Row-major (C-style) or column-major (Fortran-style) order.",
        "Row-major (C-style) or column-major (Fortran-style)"
    ],
    [
        "Empty array of the given shape and type.",
        "Empty array of the given shape"
    ],
    [
        "numpy.rec.fromrecords : Construct a record array from data.",
        "numpy.rec.fromrecords : Construct a record"
    ],
    [
        "numpy.record : fundamental data-type for `recarray`.",
        "numpy.record : fundamental data-type for"
    ],
    [
        "numpy.rec.format_parser : determine data-type from formats, names, titles.",
        "numpy.rec.format_parser : determine data-type from formats, names,"
    ],
    [
        "This constructor can be compared to ``empty``: it creates a new record",
        "This constructor can be compared to ``empty``: it"
    ],
    [
        "array but does not fill it with data.  To create a record array from data,",
        "array but does not fill it with data. To create"
    ],
    [
        "use one of the following methods:",
        "use one of the following"
    ],
    [
        "Create an array with two fields, ``x`` and ``y``:",
        "Create an array with two fields, ``x`` and"
    ],
    [
        "View the array as a record array:",
        "View the array as"
    ],
    [
        "Create a new, empty record array:",
        "Create a new, empty record"
    ],
    [
        "if self.dtype.type is not record and self.dtype.names is not None:",
        "if self.dtype.type is not record and self.dtype.names"
    ],
    [
        "raise AttributeError(\"recarray has no attribute %s\" % attr) from e",
        "raise AttributeError(\"recarray has no attribute %s\" % attr) from"
    ],
    [
        "newattr = attr not in self.__dict__",
        "newattr = attr"
    ],
    [
        "fielddict = ndarray.__getattribute__(self, 'dtype').fields or {}",
        "fielddict = ndarray.__getattribute__(self,"
    ],
    [
        "fielddict = ndarray.__getattribute__(self, 'dtype').fields or {}",
        "fielddict = ndarray.__getattribute__(self, 'dtype').fields or"
    ],
    [
        "\"record array has no attribute %s\" % attr",
        "\"record array has no attribute %s\" %"
    ],
    [
        "lst = \"[], shape=%s\" % (repr(self.shape),)",
        "lst = \"[], shape=%s\" %"
    ],
    [
        "lf = '\\n' + ' ' * len(prefix)",
        "lf = '\\n' + ' ' *"
    ],
    [
        "return fmt % (lst, lf, repr_dtype)",
        "return fmt %"
    ],
    [
        "\"the shape and suppress this warning, pass `shape=None` instead.\",",
        "\"the shape and suppress this"
    ],
    [
        "\"\"\"Create a record array from a (flat) list of arrays",
        "\"\"\"Create a record array from a (flat)"
    ],
    [
        "List of array-like objects (such as lists, tuples,",
        "List of array-like objects (such as lists,"
    ],
    [
        "shape : int or tuple of ints, optional",
        "shape : int or tuple"
    ],
    [
        "Shape of the resulting array. If not provided, inferred from",
        "Shape of the resulting array. If"
    ],
    [
        "formats, names, titles, aligned, byteorder :",
        "formats, names, titles,"
    ],
    [
        "If `dtype` is ``None``, these arguments are passed to",
        "If `dtype` is ``None``, these arguments are"
    ],
    [
        "`numpy.rec.format_parser` to construct a dtype. See that function for",
        "`numpy.rec.format_parser` to construct a dtype."
    ],
    [
        "Record array consisting of given arrayList columns.",
        "Record array consisting of given"
    ],
    [
        "arrayList = [sb.asarray(x) for x in arrayList]",
        "arrayList = [sb.asarray(x) for x in"
    ],
    [
        "if formats is None and dtype is None:",
        "if formats is None and dtype is"
    ],
    [
        "formats = [obj.dtype for obj in arrayList]",
        "formats = [obj.dtype for obj in"
    ],
    [
        "descr = format_parser(formats, names, titles, aligned, byteorder).dtype",
        "descr = format_parser(formats, names, titles,"
    ],
    [
        "raise ValueError(\"mismatch between the number of fields \"",
        "raise ValueError(\"mismatch between the"
    ],
    [
        "raise ValueError(f'array-shape mismatch in array {k} (\"{name}\")')",
        "raise ValueError(f'array-shape mismatch in"
    ],
    [
        "def fromrecords(recList, dtype=None, shape=None, formats=None, names=None,",
        "def fromrecords(recList, dtype=None, shape=None, formats=None,"
    ],
    [
        "\"\"\"Create a recarray from a list of records in text form.",
        "\"\"\"Create a recarray from a list"
    ],
    [
        "data in the same field may be heterogeneous - they will be promoted",
        "data in the same field may be heterogeneous - they"
    ],
    [
        "shape : int or tuple of ints, optional",
        "shape : int or"
    ],
    [
        "formats, names, titles, aligned, byteorder :",
        "formats, names, titles,"
    ],
    [
        "If `dtype` is ``None``, these arguments are passed to",
        "If `dtype` is ``None``, these arguments are passed"
    ],
    [
        "`numpy.format_parser` to construct a dtype. See that function for",
        "`numpy.format_parser` to construct a dtype. See that function"
    ],
    [
        "If both `formats` and `dtype` are None, then this will auto-detect",
        "If both `formats` and `dtype` are None,"
    ],
    [
        "formats. Use list of tuples rather than list of lists for faster",
        "formats. Use list of tuples rather than list of"
    ],
    [
        "record array consisting of given recList rows.",
        "record array consisting of given recList"
    ],
    [
        "\"fromrecords expected a list of tuples, may have received a list \"",
        "\"fromrecords expected a list of tuples, may have received"
    ],
    [
        "\"of lists instead. In the future that will raise an error\",",
        "\"of lists instead. In the future that will raise an"
    ],
    [
        "if shape is not None and retval.shape != shape:",
        "if shape is not None and"
    ],
    [
        "r\"\"\"Create a record array from binary data",
        "r\"\"\"Create a record array from"
    ],
    [
        "Note that despite the name of this function it does not accept `str`",
        "Note that despite the name of this function"
    ],
    [
        "shape : int or tuple of ints, optional",
        "shape : int or tuple"
    ],
    [
        "Position in the buffer to start reading from.",
        "Position in the buffer to start"
    ],
    [
        "formats, names, titles, aligned, byteorder :",
        "formats, names, titles, aligned,"
    ],
    [
        "If `dtype` is ``None``, these arguments are passed to",
        "If `dtype` is ``None``, these arguments are passed"
    ],
    [
        "`numpy.format_parser` to construct a dtype. See that function for",
        "`numpy.format_parser` to construct a dtype. See that function"
    ],
    [
        "Record array view into the data in datastring. This will be readonly",
        "Record array view into the data in datastring. This will"
    ],
    [
        "TypeError: a bytes-like object is required, not 'str'",
        "TypeError: a bytes-like object is"
    ],
    [
        "if dtype is None and formats is None:",
        "if dtype is None and formats"
    ],
    [
        "raise TypeError(\"fromstring() needs a 'dtype' or 'formats' argument\")",
        "raise TypeError(\"fromstring() needs a 'dtype'"
    ],
    [
        "descr = format_parser(formats, names, titles, aligned, byteorder).dtype",
        "descr = format_parser(formats, names, titles, aligned,"
    ],
    [
        "shape = (len(datastring) - offset) // itemsize",
        "shape = (len(datastring) - offset) //"
    ],
    [
        "_array = recarray(shape, descr, buf=datastring, offset=offset)",
        "_array = recarray(shape,"
    ],
    [
        "\"\"\"Create an array from binary file data",
        "\"\"\"Create an array from binary"
    ],
    [
        "fd : str or file type",
        "fd : str or file"
    ],
    [
        "If file is a string or a path-like object then that file is opened,",
        "If file is a string or a path-like object then that file is"
    ],
    [
        "else it is assumed to be a file object. The file object must",
        "else it is assumed to be a file object. The file object"
    ],
    [
        "support random access (i.e. it must have tell and seek methods).",
        "support random access (i.e. it must have"
    ],
    [
        "shape : int or tuple of ints, optional",
        "shape : int or tuple of ints,"
    ],
    [
        "Position in the file to start reading from.",
        "Position in the file to start reading"
    ],
    [
        "formats, names, titles, aligned, byteorder :",
        "formats, names, titles, aligned,"
    ],
    [
        "If `dtype` is ``None``, these arguments are passed to",
        "If `dtype` is ``None``, these"
    ],
    [
        "`numpy.format_parser` to construct a dtype. See that function for",
        "`numpy.format_parser` to construct a dtype. See that"
    ],
    [
        "record array consisting of data enclosed in file.",
        "record array consisting of data enclosed in"
    ],
    [
        "if dtype is None and formats is None:",
        "if dtype is None and"
    ],
    [
        "raise TypeError(\"fromfile() needs a 'dtype' or 'formats' argument\")",
        "raise TypeError(\"fromfile() needs a"
    ],
    [
        "\"Not enough bytes left in file for specified \"",
        "\"Not enough bytes left in"
    ],
    [
        "raise OSError(\"Didn't read as many bytes as expected\")",
        "raise OSError(\"Didn't read as many bytes as"
    ],
    [
        "Construct a record array from a wide-variety of objects.",
        "Construct a record array from a wide-variety of"
    ],
    [
        "A general-purpose record array constructor that dispatches to the",
        "A general-purpose record array constructor"
    ],
    [
        "appropriate `recarray` creation function based on the inputs (see Notes).",
        "appropriate `recarray` creation function based on the inputs (see"
    ],
    [
        "Input object. See Notes for details on how various input types are",
        "Input object. See Notes for details on how various input"
    ],
    [
        "shape : int or tuple of ints, optional",
        "shape : int or"
    ],
    [
        "Position in the file or buffer to start reading from.",
        "Position in the file or"
    ],
    [
        "strides : tuple of ints, optional",
        "strides : tuple"
    ],
    [
        "Buffer (`buf`) is interpreted according to these strides (strides",
        "Buffer (`buf`) is interpreted according to these strides"
    ],
    [
        "define how many bytes each array element, row, column, etc.",
        "define how many bytes each array element,"
    ],
    [
        "formats, names, titles, aligned, byteorder :",
        "formats, names, titles, aligned, byteorder"
    ],
    [
        "If `dtype` is ``None``, these arguments are passed to",
        "If `dtype` is ``None``, these arguments are passed"
    ],
    [
        "`numpy.format_parser` to construct a dtype. See that function for",
        "`numpy.format_parser` to construct a dtype. See"
    ],
    [
        "Whether to copy the input object (True), or to use a reference instead.",
        "Whether to copy the input object (True), or to use"
    ],
    [
        "This option only applies when the input is an ndarray or recarray.",
        "This option only applies when the input is an ndarray or"
    ],
    [
        "Record array created from the specified object.",
        "Record array created from the"
    ],
    [
        "If `obj` is ``None``, then call the `~numpy.recarray` constructor. If",
        "If `obj` is ``None``, then call the `~numpy.recarray` constructor."
    ],
    [
        "`obj` is a string, then call the `fromstring` constructor. If `obj` is a",
        "`obj` is a string, then call the `fromstring` constructor. If `obj` is"
    ],
    [
        "list or a tuple, then if the first object is an `~numpy.ndarray`, call",
        "list or a tuple, then if the first object is an"
    ],
    [
        "`fromarrays`, otherwise call `fromrecords`. If `obj` is a",
        "`fromarrays`, otherwise call `fromrecords`. If"
    ],
    [
        "`~numpy.recarray`, then make a copy of the data in the recarray",
        "`~numpy.recarray`, then make a copy of the data"
    ],
    [
        "(if ``copy=True``) and use the new formats, names, and titles. If `obj`",
        "(if ``copy=True``) and use the new"
    ],
    [
        "is a file, then call `fromfile`. Finally, if obj is an `ndarray`, then",
        "is a file, then call `fromfile`. Finally, if"
    ],
    [
        "return ``obj.view(recarray)``, making a copy of the data if ``copy=True``.",
        "return ``obj.view(recarray)``, making a copy of the data if"
    ],
    [
        "if ((isinstance(obj, (type(None), str)) or hasattr(obj, 'readinto')) and",
        "if ((isinstance(obj, (type(None), str))"
    ],
    [
        "formats is None and dtype is None):",
        "formats is None and dtype is"
    ],
    [
        "raise ValueError(\"Must define formats (or dtype) if object is \"",
        "raise ValueError(\"Must define formats (or"
    ],
    [
        "\"None, string, or an open file\")",
        "\"None, string, or"
    ],
    [
        "raise ValueError(\"Must define a shape if obj is None\")",
        "raise ValueError(\"Must define a shape if obj is"
    ],
    [
        "return recarray(shape, dtype, buf=obj, offset=offset, strides=strides)",
        "return recarray(shape, dtype, buf=obj, offset=offset,"
    ],
    [
        "return fromstring(obj, dtype, shape=shape, offset=offset, **kwds)",
        "return fromstring(obj, dtype,"
    ],
    [
        "if dtype is not None and (obj.dtype != dtype):",
        "if dtype is not None and (obj.dtype !="
    ],
    [
        "if dtype is not None and (obj.dtype != dtype):",
        "if dtype is not None and (obj.dtype"
    ],
    [
        "if interface is None or not isinstance(interface, dict):",
        "if interface is None or"
    ],
    [
        "if dtype is not None and (obj.dtype != dtype):",
        "if dtype is not None and"
    ],
    [
        "This file is separate from ``_add_newdocs.py`` so that it can be mocked out by",
        "This file is separate from ``_add_newdocs.py`` so"
    ],
    [
        "our sphinx ``conf.py`` during doc builds, where we want to avoid showing",
        "our sphinx ``conf.py`` during doc builds, where we want to"
    ],
    [
        "from numpy._core import numerictypes as _numerictypes",
        "from numpy._core import numerictypes as"
    ],
    [
        "('intp', 'Signed integer large enough to fit pointer, compatible with C ``intptr_t``'),",
        "('intp', 'Signed integer large enough to fit pointer, compatible"
    ],
    [
        "('uintp', 'Unsigned integer large enough to fit pointer, compatible with C ``uintptr_t``'),",
        "('uintp', 'Unsigned integer large enough to fit"
    ],
    [
        "system, _, _, _, machine = os.uname()",
        "system, _, _, _,"
    ],
    [
        "_doc_alias_string = f\":Alias on this platform ({_system} {_machine}):\"",
        "_doc_alias_string = f\":Alias on this platform ({_system}"
    ],
    [
        "canonical_name_doc = \"\" if obj == o.__name__ else \\",
        "canonical_name_doc = \"\" if obj =="
    ],
    [
        "alias_doc += ''.join(f\"{_doc_alias_string} `numpy.{alias}`: {doc}.\\n    \"",
        "alias_doc += ''.join(f\"{_doc_alias_string}"
    ],
    [
        "for (alias_type, alias, doc) in possible_aliases if alias_type is o)",
        "for (alias_type, alias, doc) in possible_aliases if alias_type is"
    ],
    [
        "Boolean type (True or False), stored as a byte.",
        "Boolean type (True or False), stored as"
    ],
    [
        "The :class:`bool` type is not a subclass of the :class:`int_` type",
        "The :class:`bool` type is not a subclass of the"
    ],
    [
        "(the :class:`bool` is not even a number type). This is different",
        "(the :class:`bool` is not even a number"
    ],
    [
        "than Python's default implementation of :class:`bool` as a",
        "than Python's default implementation of :class:`bool` as"
    ],
    [
        "Signed integer type, compatible with C ``char``.",
        "Signed integer type, compatible"
    ],
    [
        "Signed integer type, compatible with C ``short``.",
        "Signed integer type, compatible with"
    ],
    [
        "Signed integer type, compatible with C ``int``.",
        "Signed integer type, compatible with C"
    ],
    [
        "Signed integer type, compatible with C ``long long``.",
        "Signed integer type, compatible with C ``long"
    ],
    [
        "Unsigned integer type, compatible with C ``unsigned char``.",
        "Unsigned integer type, compatible"
    ],
    [
        "Unsigned integer type, compatible with C ``unsigned short``.",
        "Unsigned integer type, compatible"
    ],
    [
        "Unsigned integer type, compatible with C ``unsigned int``.",
        "Unsigned integer type, compatible with C"
    ],
    [
        "Signed integer type, compatible with C ``unsigned long long``.",
        "Signed integer type, compatible with C ``unsigned long"
    ],
    [
        "Single-precision floating-point number type, compatible with C ``float``.",
        "Single-precision floating-point number type, compatible with"
    ],
    [
        "Double-precision floating-point number type, compatible with Python",
        "Double-precision floating-point number type,"
    ],
    [
        "Extended-precision floating-point number type, compatible with C",
        "Extended-precision floating-point number type, compatible with"
    ],
    [
        "Complex number type composed of two single-precision floating-point",
        "Complex number type composed of two single-precision"
    ],
    [
        "Complex number type composed of two double-precision floating-point",
        "Complex number type composed of two"
    ],
    [
        "Complex number type composed of two extended-precision floating-point",
        "Complex number type composed of two extended-precision"
    ],
    [
        "This type strips trailing null codepoints.",
        "This type strips trailing"
    ],
    [
        "Unlike the builtin :class:`str`, this supports the",
        "Unlike the builtin :class:`str`, this"
    ],
    [
        "When used in arrays, this type strips trailing null bytes.",
        "When used in arrays, this type strips trailing"
    ],
    [
        "Create a new structured or unstructured void scalar.",
        "Create a new structured or"
    ],
    [
        "length_or_data : int, array-like, bytes-like, object",
        "length_or_data : int,"
    ],
    [
        "One of multiple meanings (see notes).  The length or",
        "One of multiple meanings (see notes). The length"
    ],
    [
        "bytes data of an unstructured void.  Or alternatively,",
        "bytes data of an unstructured"
    ],
    [
        "the data to be stored in the new scalar when `dtype`",
        "the data to be stored in the new"
    ],
    [
        "This can be an array-like, in which case an array may",
        "This can be an array-like, in which case"
    ],
    [
        "If provided the dtype of the new scalar.  This dtype must",
        "If provided the dtype of the new scalar."
    ],
    [
        "be \"void\" dtype (i.e. a structured or unstructured void,",
        "be \"void\" dtype (i.e. a structured or"
    ],
    [
        "For historical reasons and because void scalars can represent both",
        "For historical reasons and because void scalars"
    ],
    [
        "arbitrary byte data and structured dtypes, the void constructor",
        "arbitrary byte data and structured dtypes, the void"
    ],
    [
        "array creation.  However, a void scalar rather than array is returned.",
        "array creation. However, a void scalar rather than array"
    ],
    [
        "Please see the examples which show all three different conventions.",
        "Please see the examples which show all three different"
    ],
    [
        "When parsing a string to create a datetime object, if the string contains",
        "When parsing a string to create a"
    ],
    [
        "a trailing timezone (A 'Z' or a timezone offset), the timezone will be",
        "a trailing timezone (A 'Z' or a timezone offset), the timezone"
    ],
    [
        "dropped and a User Warning is given.",
        "dropped and a User Warning"
    ],
    [
        "Return ``True`` if the number is finite with integral value.",
        "Return ``True`` if the number is"
    ],
    [
        "for float_name in ('half', 'single', 'double', 'longdouble'):",
        "for float_name in ('half', 'single', 'double',"
    ],
    [
        "Return a pair of integers, whose ratio is exactly equal to the original",
        "Return a pair of integers, whose ratio is exactly equal"
    ],
    [
        "floating point number, and with a positive denominator.",
        "floating point number, and with a positive"
    ],
    [
        "Raise `OverflowError` on infinities and a `ValueError` on NaNs.",
        "Raise `OverflowError` on infinities and"
    ],
    [
        "Return ``True`` if the floating point number is finite with integral",
        "Return ``True`` if the floating point number"
    ],
    [
        "Analogous to the builtin `int.bit_count` or ``popcount`` in C++.",
        "Analogous to the builtin `int.bit_count`"
    ],
    [
        "Contains the core of NumPy: ndarray, ufuncs, dtypes, etc.",
        "Contains the core of NumPy:"
    ],
    [
        "Please note that this module is private.  All functions and objects",
        "Please note that this module is private. All functions and"
    ],
    [
        "are available in the main ``numpy`` namespace - use that instead.",
        "are available in the main ``numpy``"
    ],
    [
        "from numpy.version import version as __version__",
        "from numpy.version import"
    ],
    [
        "IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!",
        "IMPORTANT: PLEASE READ THIS FOR ADVICE"
    ],
    [
        "Importing the numpy C-extensions failed. This error can happen for",
        "Importing the numpy C-extensions failed."
    ],
    [
        "many reasons, often due to issues with your setup or how NumPy was",
        "many reasons, often due to issues with your setup or how NumPy"
    ],
    [
        "We have compiled some common reasons and troubleshooting tips at:",
        "We have compiled some common reasons and troubleshooting tips"
    ],
    [
        "Please note and check the following:",
        "Please note and"
    ],
    [
        "* The Python version is: Python%d.%d from \"%s\"",
        "* The Python version"
    ],
    [
        "* The NumPy version is: \"%s\"",
        "* The NumPy version"
    ],
    [
        "and make sure that they are the versions you expect.",
        "and make sure that they are the"
    ],
    [
        "Please carefully study the documentation linked above for further help.",
        "Please carefully study the documentation"
    ],
    [
        "msg = (\"Something is wrong with the numpy installation. \"",
        "msg = (\"Something is wrong with"
    ],
    [
        "\"While importing we detected an older version of \"",
        "\"While importing we detected an older version"
    ],
    [
        "\"numpy in {}. One method of fixing this is to repeatedly uninstall \"",
        "\"numpy in {}. One method of fixing this is to repeatedly"
    ],
    [
        "\"numpy until none is found, then reinstall this version.\")",
        "\"numpy until none is found, then"
    ],
    [
        "from . import numerictypes as nt",
        "from . import numerictypes as"
    ],
    [
        "from .numeric import absolute as abs",
        "from .numeric import absolute as"
    ],
    [
        "\"pow\", \"permute_dims\", \"memmap\", \"sctypeDict\", \"record\", \"recarray\"",
        "\"pow\", \"permute_dims\", \"memmap\", \"sctypeDict\","
    ],
    [
        "if not DType._legacy or DType.__module__ == \"numpy.dtypes\":",
        "if not DType._legacy or"
    ],
    [
        "raise AttributeError(f\"Module {__name__!r} has no attribute {name!r}\")",
        "raise AttributeError(f\"Module {__name__!r} has no"
    ],
    [
        "Machine arithmetic - determine the parameters of the",
        "Machine arithmetic - determine the"
    ],
    [
        "Radix in which numbers are represented.",
        "Radix in which numbers are"
    ],
    [
        "Number of base-`ibeta` digits in the floating point mantissa M.",
        "Number of base-`ibeta` digits in"
    ],
    [
        "Exponent of the smallest (most negative) power of `ibeta` that,",
        "Exponent of the smallest (most negative) power"
    ],
    [
        "Floating-point number ``beta**machep`` (floating point precision)",
        "Floating-point number ``beta**machep``"
    ],
    [
        "Exponent of the smallest power of `ibeta` that, subtracted",
        "Exponent of the smallest power of `ibeta`"
    ],
    [
        "Number of bits in the exponent (including its sign and bias).",
        "Number of bits in the exponent (including its"
    ],
    [
        "Smallest (most negative) power of `ibeta` consistent with there",
        "Smallest (most negative) power of `ibeta` consistent with"
    ],
    [
        "being no leading zeros in the mantissa.",
        "being no leading zeros in the"
    ],
    [
        "Floating-point number ``beta**minexp`` (the smallest [in",
        "Floating-point number ``beta**minexp``"
    ],
    [
        "magnitude] positive floating point number with full precision).",
        "magnitude] positive floating point number"
    ],
    [
        "Smallest (positive) power of `ibeta` that causes overflow.",
        "Smallest (positive) power of `ibeta` that"
    ],
    [
        "in addition, and on how underflow is handled.",
        "in addition, and on how underflow is"
    ],
    [
        "Number of 'guard digits' used when truncating the product",
        "Number of 'guard digits' used"
    ],
    [
        "of two mantissas to fit the representation.",
        "of two mantissas to fit"
    ],
    [
        "An alias for `smallest_normal`, kept for backwards compatibility.",
        "An alias for `smallest_normal`, kept for"
    ],
    [
        "Function that converts an integer or integer array to a float",
        "Function that converts an integer or integer array to"
    ],
    [
        "or float array. Default is `float`.",
        "or float array. Default"
    ],
    [
        "Function that converts a float or float array to an integer or",
        "Function that converts a float or float array to an"
    ],
    [
        "Function that converts a float array to float. Default is `float`.",
        "Function that converts a float array to float. Default"
    ],
    [
        "Note that this does not seem to do anything useful in the current",
        "Note that this does not seem to do anything"
    ],
    [
        "Function that converts a single float to a string. Default is",
        "Function that converts a single float to a string. Default"
    ],
    [
        "Title that is printed in the string representation of `MachAr`.",
        "Title that is printed in the"
    ],
    [
        "finfo : Machine limits for floating point types.",
        "finfo : Machine limits for"
    ],
    [
        "iinfo : Machine limits for integer types.",
        "iinfo : Machine limits for integer"
    ],
    [
        "float_conv - convert integer to float (array)",
        "float_conv - convert integer to float"
    ],
    [
        "int_conv   - convert float (array) to integer",
        "int_conv - convert float (array)"
    ],
    [
        "float_to_float - convert float array to float",
        "float_to_float - convert float array to"
    ],
    [
        "float_to_str - convert array float to str",
        "float_to_str - convert array float"
    ],
    [
        "title        - description of used floating point numbers",
        "title - description of used floating"
    ],
    [
        "def _do_init(self, float_conv, int_conv, float_to_float, float_to_str, title):",
        "def _do_init(self, float_conv, int_conv, float_to_float,"
    ],
    [
        "msg = \"Did not converge after %d tries with %s\"",
        "msg = \"Did not converge"
    ],
    [
        "if any(temp - a != zero):",
        "if any(temp - a"
    ],
    [
        "if any(temp - one != zero):",
        "if any(temp -"
    ],
    [
        "raise RuntimeError(\"could not determine machine tolerance \"",
        "raise RuntimeError(\"could not determine"
    ],
    [
        "\"for 'negep', locals() -> %s\" % (locals()))",
        "\"for 'negep', locals() -> %s\" %"
    ],
    [
        "if any(temp - one != zero):",
        "if any(temp - one"
    ],
    [
        "if any(a + a == zero) or any(abs(z) >= y):",
        "if any(a + a == zero) or any(abs(z) >="
    ],
    [
        "if any((a + a) != zero) and any(abs(y) < xmin):",
        "if any((a + a) != zero)"
    ],
    [
        "if any(xmax * one != xmax):",
        "if any(xmax *"
    ],
    [
        "xmax = one - beta * epsneg",
        "xmax = one - beta"
    ],
    [
        "xmax = xmax / (xmin * beta * beta * beta)",
        "xmax = xmax / (xmin * beta"
    ],
    [
        "smallest_subnormal = abs(xmin / beta ** (it))",
        "smallest_subnormal = abs(xmin / beta"
    ],
    [
        "ten = two + two + two + two + two",
        "ten = two + two +"
    ],
    [
        "valid_filemodes = [\"r\", \"c\", \"r+\", \"w+\"]",
        "valid_filemodes = [\"r\","
    ],
    [
        "\"\"\"Create a memory-map to an array stored in a *binary* file on disk.",
        "\"\"\"Create a memory-map to an array stored in a *binary*"
    ],
    [
        "Memory-mapped files are used for accessing small segments of large files",
        "Memory-mapped files are used for accessing small segments of"
    ],
    [
        "on disk, without reading the entire file into memory.  NumPy's",
        "on disk, without reading the"
    ],
    [
        "memmap's are array-like objects.  This differs from Python's ``mmap``",
        "memmap's are array-like objects. This differs"
    ],
    [
        "This subclass of ndarray has some unpleasant interactions with",
        "This subclass of ndarray has some unpleasant"
    ],
    [
        "some operations, because it doesn't quite fit properly as a subclass.",
        "some operations, because it doesn't quite fit properly as"
    ],
    [
        "An alternative to using this subclass is to create the ``mmap``",
        "An alternative to using this subclass is to create the"
    ],
    [
        "object yourself, then create an ndarray with ndarray.__new__ directly,",
        "object yourself, then create an"
    ],
    [
        "passing the object created in its 'buffer=' parameter.",
        "passing the object created in its 'buffer='"
    ],
    [
        "This class may at some point be turned into a factory function",
        "This class may at some point be turned into a"
    ],
    [
        "which returns a view into an mmap buffer.",
        "which returns a view into an"
    ],
    [
        "Flush the memmap instance to write the changes to the file. Currently there",
        "Flush the memmap instance to write the"
    ],
    [
        "is no API to close the underlying ``mmap``. It is tricky to ensure the",
        "is no API to close the underlying ``mmap``. It is tricky"
    ],
    [
        "resource is actually closed, since it may be shared between different",
        "resource is actually closed, since it may be"
    ],
    [
        "filename : str, file-like object, or pathlib.Path instance",
        "filename : str, file-like object,"
    ],
    [
        "The file name or file object to be used as the array data buffer.",
        "The file name or file object to be used as"
    ],
    [
        "The data-type used to interpret the file contents.",
        "The data-type used to interpret the file"
    ],
    [
        "mode : {'r+', 'r', 'w+', 'c'}, optional",
        "mode : {'r+', 'r',"
    ],
    [
        "The file is opened in this mode:",
        "The file is opened"
    ],
    [
        "| 'r'  | Open existing file for reading only.                        |",
        "| 'r' | Open existing file"
    ],
    [
        "| 'r+' | Open existing file for reading and writing.                 |",
        "| 'r+' | Open existing file for reading"
    ],
    [
        "| 'w+' | Create or overwrite existing file for reading and writing.  |",
        "| 'w+' | Create or overwrite existing file for reading and writing."
    ],
    [
        "|      | If ``mode == 'w+'`` then `shape` must also be specified.    |",
        "| | If ``mode == 'w+'`` then `shape` must also"
    ],
    [
        "| 'c'  | Copy-on-write: assignments affect data in memory, but       |",
        "| 'c' | Copy-on-write: assignments affect"
    ],
    [
        "|      | changes are not saved to disk.  The file on disk is         |",
        "| | changes are not saved to disk. The"
    ],
    [
        "In the file, array data starts at this offset. Since `offset` is",
        "In the file, array data starts at this offset. Since `offset`"
    ],
    [
        "measured in bytes, it should normally be a multiple of the byte-size",
        "measured in bytes, it should normally be a multiple of the"
    ],
    [
        "of `dtype`. When ``mode != 'r'``, even positive offsets beyond end of",
        "of `dtype`. When ``mode != 'r'``, even positive offsets"
    ],
    [
        "file are valid; The file will be extended to accommodate the",
        "file are valid; The file will"
    ],
    [
        "additional data. By default, ``memmap`` will start at the beginning of",
        "additional data. By default, ``memmap`` will start at the beginning"
    ],
    [
        "the file, even if ``filename`` is a file pointer ``fp`` and",
        "the file, even if ``filename`` is a"
    ],
    [
        "shape : int or sequence of ints, optional",
        "shape : int or"
    ],
    [
        "The desired shape of the array. If ``mode == 'r'`` and the number",
        "The desired shape of the array. If ``mode == 'r'`` and"
    ],
    [
        "of remaining bytes after `offset` is not a multiple of the byte-size",
        "of remaining bytes after `offset` is not a"
    ],
    [
        "of `dtype`, you must specify `shape`. By default, the returned array",
        "of `dtype`, you must specify `shape`. By"
    ],
    [
        "The shape parameter can now be any integer sequence type, previously",
        "The shape parameter can now be"
    ],
    [
        "types were limited to tuple and int.",
        "types were limited to"
    ],
    [
        "Specify the order of the ndarray memory layout:",
        "Specify the order of the ndarray"
    ],
    [
        "Fortran-style.  This only has an effect if the shape is",
        "Fortran-style. This only has an effect if"
    ],
    [
        "filename : str or pathlib.Path instance",
        "filename : str or"
    ],
    [
        "Flush any changes in memory to file on disk.",
        "Flush any changes in memory to"
    ],
    [
        "When you delete a memmap object, flush is called first to write",
        "When you delete a memmap object, flush is called"
    ],
    [
        "lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.",
        "lib.format.open_memmap : Create or load"
    ],
    [
        "The memmap object can be used anywhere an ndarray is accepted.",
        "The memmap object can be used anywhere an ndarray"
    ],
    [
        "Given a memmap ``fp``, ``isinstance(fp, numpy.ndarray)`` returns",
        "Given a memmap ``fp``,"
    ],
    [
        "When a memmap causes a file to be created or extended beyond its",
        "When a memmap causes a file to be created or"
    ],
    [
        "current size in the filesystem, the contents of the new part are",
        "current size in the filesystem, the contents of"
    ],
    [
        "unspecified. On systems with POSIX filesystem semantics, the extended",
        "unspecified. On systems with POSIX filesystem"
    ],
    [
        "part will be filled with zero bytes.",
        "part will be filled with zero"
    ],
    [
        "This example uses a temporary file so that doctest doesn't write",
        "This example uses a temporary file"
    ],
    [
        "files to your directory. You would use a 'normal' filename.",
        "files to your directory. You would use a 'normal'"
    ],
    [
        "Create a memmap with dtype and shape that matches our data:",
        "Create a memmap with dtype and shape"
    ],
    [
        "Flushes memory changes to disk in order to read them back",
        "Flushes memory changes to disk in order"
    ],
    [
        "Load the memmap and verify data was stored:",
        "Load the memmap and"
    ],
    [
        "It's possible to assign to copy-on-write array, but values are only",
        "It's possible to assign to copy-on-write array, but values are"
    ],
    [
        "written into the memory copy of the array, and not written to disk:",
        "written into the memory copy of the array, and"
    ],
    [
        "\"mode must be one of {!r} (got {!r})\"",
        "\"mode must be one of"
    ],
    [
        "if mode == 'w+' and shape is None:",
        "if mode == 'w+'"
    ],
    [
        "raise ValueError(\"shape must be given if mode == 'w+'\")",
        "raise ValueError(\"shape must be given"
    ],
    [
        "('r' if mode == 'c' else mode) + 'b'",
        "('r' if mode == 'c' else mode)"
    ],
    [
        "raise ValueError(\"Size of available data is not a \"",
        "raise ValueError(\"Size of available data is not a"
    ],
    [
        "if type(shape) not in (tuple, list):",
        "if type(shape) not"
    ],
    [
        "bytes = int(offset + size * _dbytes)",
        "bytes = int(offset + size"
    ],
    [
        "start = offset - offset % mmap.ALLOCATIONGRANULARITY",
        "start = offset - offset %"
    ],
    [
        "mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)",
        "mm = mmap.mmap(fid.fileno(), bytes, access=acc,"
    ],
    [
        "self = ndarray.__new__(subtype, shape, dtype=descr, buffer=mm,",
        "self = ndarray.__new__(subtype, shape, dtype=descr,"
    ],
    [
        "elif hasattr(fid, \"name\") and isinstance(fid.name, str):",
        "elif hasattr(fid, \"name\") and isinstance(fid.name,"
    ],
    [
        "if hasattr(obj, '_mmap') and np.may_share_memory(self, obj):",
        "if hasattr(obj, '_mmap') and"
    ],
    [
        "Write any changes in the array to the file on disk.",
        "Write any changes in the array"
    ],
    [
        "if self.base is not None and hasattr(self.base, 'flush'):",
        "if self.base is not None"
    ],
    [
        "if self is arr or type(self) is not memmap:",
        "if self is arr or type(self)"
    ],
    [
        "if type(res) is memmap and res._mmap is None:",
        "if type(res) is memmap and"
    ],
    [
        "Reference object to allow the creation of arrays which are not",
        "Reference object to allow the creation of arrays which"
    ],
    [
        "NumPy arrays. If an array-like passed in as ``like`` supports",
        "NumPy arrays. If an array-like"
    ],
    [
        "the ``__array_function__`` protocol, the result will be defined",
        "the ``__array_function__`` protocol, the"
    ],
    [
        "by it. In this case, it ensures the creation of an array object",
        "by it. In this case, it ensures the creation of an"
    ],
    [
        "compatible with that passed in via this argument.\"\"\"",
        "compatible with that passed"
    ],
    [
        "Class to wrap functions with checks for __array_function__ overrides.",
        "Class to wrap functions with"
    ],
    [
        "All arguments are required, and can only be passed by position.",
        "All arguments are required, and can only be"
    ],
    [
        "The dispatcher function that returns a single sequence-like object",
        "The dispatcher function that returns"
    ],
    [
        "of all arguments relevant.  It must have the same signature (except",
        "of all arguments relevant. It must have"
    ],
    [
        "the default values) as the actual implementation.",
        "the default values) as the actual"
    ],
    [
        "If ``None``, this is a ``like=`` dispatcher and the",
        "If ``None``, this is a"
    ],
    [
        "``_ArrayFunctionDispatcher`` must be called with ``like`` as the",
        "``_ArrayFunctionDispatcher`` must be called"
    ],
    [
        "Function that implements the operation on NumPy arrays without",
        "Function that implements the operation on NumPy arrays"
    ],
    [
        "overrides.  Arguments passed calling the ``_ArrayFunctionDispatcher``",
        "overrides. Arguments passed"
    ],
    [
        "will be forwarded to this (and the ``dispatcher``) as if using",
        "will be forwarded to this (and the ``dispatcher``) as if"
    ],
    [
        "Collect arguments on which to call __array_function__.",
        "Collect arguments on which"
    ],
    [
        "Iterable of possibly array-like arguments to check for",
        "Iterable of possibly array-like"
    ],
    [
        "Sequence of arguments with __array_function__ methods, in the order in",
        "Sequence of arguments with __array_function__ methods, in the"
    ],
    [
        "ArgSpec = collections.namedtuple('ArgSpec', 'args varargs keywords defaults')",
        "ArgSpec = collections.namedtuple('ArgSpec', 'args"
    ],
    [
        "\"\"\"Verify that a dispatcher function has the right signature.\"\"\"",
        "\"\"\"Verify that a dispatcher function has the right"
    ],
    [
        "raise RuntimeError('implementation and dispatcher for %s have '",
        "raise RuntimeError('implementation and dispatcher"
    ],
    [
        "if dispatcher_spec.defaults != (None,) * len(dispatcher_spec.defaults):",
        "if dispatcher_spec.defaults != (None,)"
    ],
    [
        "raise RuntimeError('dispatcher functions can only use None for '",
        "raise RuntimeError('dispatcher functions can only use None"
    ],
    [
        "\"\"\"Decorator for adding dispatch with the __array_function__ protocol.",
        "\"\"\"Decorator for adding dispatch with"
    ],
    [
        "Function that when called like ``dispatcher(*args, **kwargs)`` with",
        "Function that when called"
    ],
    [
        "arguments from the NumPy function call returns an iterable of",
        "arguments from the NumPy function call returns an iterable"
    ],
    [
        "array-like arguments to check for ``__array_function__``.",
        "array-like arguments to check for"
    ],
    [
        "If `None`, the first argument is used as the single `like=` argument",
        "If `None`, the first argument is used as"
    ],
    [
        "and not passed on.  A function implementing `like=` must call its",
        "and not passed on. A function implementing `like=` must call"
    ],
    [
        "dispatcher with `like` as the first non-keyword argument.",
        "dispatcher with `like` as the"
    ],
    [
        "__module__ attribute to set on new function, e.g., ``module='numpy'``.",
        "__module__ attribute to set on new function, e.g.,"
    ],
    [
        "By default, module is copied from the decorated function.",
        "By default, module is copied"
    ],
    [
        "If True, verify the that the signature of the dispatcher and decorated",
        "If True, verify the that the signature of the"
    ],
    [
        "function signatures match exactly: all required and optional arguments",
        "function signatures match exactly: all required and"
    ],
    [
        "should appear in order with the same names, but the default values for",
        "should appear in order with the same names,"
    ],
    [
        "all optional arguments should be ``None``. Only disable verification",
        "all optional arguments should be ``None``."
    ],
    [
        "if the dispatcher's signature needs to deviate for some particular",
        "if the dispatcher's signature needs"
    ],
    [
        "reason, e.g., because the function has a signature like",
        "reason, e.g., because the function has a signature"
    ],
    [
        "If True, copy docs from the dispatcher function onto the dispatched",
        "If True, copy docs from the dispatcher"
    ],
    [
        "function, rather than from the implementation. This is useful for",
        "function, rather than from the implementation. This"
    ],
    [
        "functions defined in C, which otherwise don't have docstrings.",
        "functions defined in C, which otherwise don't have"
    ],
    [
        "Function suitable for decorating the implementation of a NumPy function.",
        "Function suitable for decorating the implementation"
    ],
    [
        "\"__array_function__ expects `like=` to be the last \"",
        "\"__array_function__ expects `like=` to"
    ],
    [
        "\"argument and a keyword-only argument. \"",
        "\"argument and a keyword-only argument."
    ],
    [
        "f\"{implementation} does not seem to comply.\")",
        "f\"{implementation} does not"
    ],
    [
        "\"\"\"Like array_function_dispatcher, but with function arguments flipped.\"\"\"",
        "\"\"\"Like array_function_dispatcher, but with function"
    ],
    [
        "from . import numerictypes as ntypes",
        "from . import numerictypes as"
    ],
    [
        "from .numeric import array, inf, nan",
        "from .numeric import array,"
    ],
    [
        "\"\"\" Object to simulate MachAr instance \"\"\"",
        "\"\"\" Object to simulate MachAr"
    ],
    [
        "def __init__(self, ftype, *, eps, epsneg, huge, tiny,",
        "def __init__(self, ftype, *, eps, epsneg, huge,"
    ],
    [
        "\"\"\"Return the value for the smallest subnormal.",
        "\"\"\"Return the value for the smallest"
    ],
    [
        "If the calculated value for the smallest subnormal is zero.",
        "If the calculated value for the smallest subnormal is"
    ],
    [
        "'The value of the smallest subnormal for {} type '",
        "'The value of the smallest subnormal"
    ],
    [
        "\"\"\"Return the string representation of the smallest subnormal.\"\"\"",
        "\"\"\"Return the string representation"
    ],
    [
        "_title_fmt = 'numpy {} precision floating point number'",
        "_title_fmt = 'numpy {} precision"
    ],
    [
        "\"\"\" Get MachAr instance or MachAr-like instance",
        "\"\"\" Get MachAr instance or MachAr-like"
    ],
    [
        "Get parameters for floating point type, by first trying signatures of",
        "Get parameters for floating point type, by"
    ],
    [
        "various known floating point types, then, if none match, attempting to",
        "various known floating point types, then,"
    ],
    [
        "ma_like : instance of :class:`MachAr` or :class:`MachArLike`",
        "ma_like : instance of :class:`MachAr`"
    ],
    [
        "Object giving floating point parameters for `ftype`.",
        "Object giving floating point"
    ],
    [
        "If the binary signature of the float type is not in the dictionary of",
        "If the binary signature of the float type is not"
    ],
    [
        "f'Signature {key} for {ftype} does not match any known type: '",
        "f'Signature {key} for {ftype} does not match"
    ],
    [
        "'falling back to type probe function.\\n'",
        "'falling back to type"
    ],
    [
        "'This warnings indicates broken support for the dtype!',",
        "'This warnings indicates broken support for the"
    ],
    [
        "\"\"\" Create MachAr instance with found information on float types",
        "\"\"\" Create MachAr instance with found"
    ],
    [
        "TODO: MachAr should be retired completely ideally.  We currently only",
        "TODO: MachAr should be retired completely ideally. We"
    ],
    [
        "ever use it system with broken longdouble (valgrind, WSL).",
        "ever use it system with broken"
    ],
    [
        "Machine limits for floating point types.",
        "Machine limits for"
    ],
    [
        "The number of bits occupied by the type.",
        "The number of bits occupied by"
    ],
    [
        "Returns the dtype for which `finfo` returns information. For complex",
        "Returns the dtype for which `finfo`"
    ],
    [
        "input, the returned dtype is the associated ``float*`` dtype for its",
        "input, the returned dtype is the associated ``float*`` dtype"
    ],
    [
        "The number of bits in the exponent portion of the floating point",
        "The number of bits in the exponent portion of the"
    ],
    [
        "max : floating point number of the appropriate type",
        "max : floating point number of the appropriate"
    ],
    [
        "min : floating point number of the appropriate type",
        "min : floating point number of"
    ],
    [
        "The smallest representable number, typically ``-max``.",
        "The smallest representable number,"
    ],
    [
        "The number of bits in the exponent including its sign and bias.",
        "The number of bits in the exponent including its sign"
    ],
    [
        "The number of bits in the mantissa.",
        "The number of bits"
    ],
    [
        "The approximate number of decimal digits to which this kind of",
        "The approximate number of decimal digits to which this"
    ],
    [
        "resolution : floating point number of the appropriate type",
        "resolution : floating point number of the appropriate"
    ],
    [
        "The approximate decimal resolution of this type, i.e.,",
        "The approximate decimal resolution of"
    ],
    [
        "An alias for `smallest_normal`, kept for backwards compatibility.",
        "An alias for `smallest_normal`, kept"
    ],
    [
        "dtype : float, dtype, or instance",
        "dtype : float, dtype, or"
    ],
    [
        "Kind of floating point or complex floating point",
        "Kind of floating point or"
    ],
    [
        "data-type about which to get information.",
        "data-type about which to get"
    ],
    [
        "iinfo : The equivalent for integer data types.",
        "iinfo : The equivalent for"
    ],
    [
        "spacing : The distance between a value and the nearest adjacent number",
        "spacing : The distance between a value and the nearest adjacent"
    ],
    [
        "For developers of NumPy: do not instantiate this at the module level.",
        "For developers of NumPy: do not instantiate this at the"
    ],
    [
        "The initial calculation of these parameters is expensive and negatively",
        "The initial calculation of these parameters is expensive"
    ],
    [
        "impacts import times.  These objects are cached, so calling ``finfo()``",
        "impacts import times. These objects are cached, so"
    ],
    [
        "repeatedly inside your functions is not a problem.",
        "repeatedly inside your functions is not"
    ],
    [
        "Note that ``smallest_normal`` is not actually the smallest positive",
        "Note that ``smallest_normal`` is not actually the smallest"
    ],
    [
        "This function can also be used for complex data types as well. If used,",
        "This function can also be used for complex data types as well."
    ],
    [
        "the output will be the same as the corresponding real float type",
        "the output will be the same"
    ],
    [
        "(e.g. numpy.finfo(numpy.csingle) is the same as numpy.finfo(numpy.single)).",
        "(e.g. numpy.finfo(numpy.csingle) is the same as"
    ],
    [
        "However, the output is true for the real and imaginary components.",
        "However, the output is true for the real and imaginary"
    ],
    [
        "\"finfo() dtype cannot be None. This behavior will \"",
        "\"finfo() dtype cannot be None. This behavior"
    ],
    [
        "raise ValueError(\"data type %r not inexact\" % (dtype))",
        "raise ValueError(\"data type %r not inexact\""
    ],
    [
        "for word in ['resolution', 'epsneg', 'smallest_subnormal']:",
        "for word in ['resolution', 'epsneg',"
    ],
    [
        "\"\"\"Return the value for the smallest normal.",
        "\"\"\"Return the value for the smallest"
    ],
    [
        "If the calculated value for the smallest normal is requested for",
        "If the calculated value for the"
    ],
    [
        "'The value of smallest normal is undefined for double double',",
        "'The value of smallest normal is"
    ],
    [
        "\"\"\"Return the value for tiny, alias of smallest_normal.",
        "\"\"\"Return the value for tiny, alias of"
    ],
    [
        "Value for the smallest normal, alias of smallest_normal.",
        "Value for the smallest"
    ],
    [
        "If the calculated value for the smallest normal is requested for",
        "If the calculated value for the smallest normal"
    ],
    [
        "The number of bits occupied by the type.",
        "The number of bits occupied by the"
    ],
    [
        "Returns the dtype for which `iinfo` returns information.",
        "Returns the dtype for which `iinfo`"
    ],
    [
        "The smallest integer expressible by the type.",
        "The smallest integer expressible"
    ],
    [
        "The largest integer expressible by the type.",
        "The largest integer expressible by the"
    ],
    [
        "int_type : integer type, dtype, or instance",
        "int_type : integer type,"
    ],
    [
        "The kind of integer data type to get information about.",
        "The kind of integer data type"
    ],
    [
        "finfo : The equivalent for floating point data types.",
        "finfo : The equivalent for floating"
    ],
    [
        "self.key = \"%s%d\" % (self.kind, self.bits)",
        "self.key = \"%s%d\" %"
    ],
    [
        "raise ValueError(\"Invalid integer data type %r.\" % (self.kind,))",
        "raise ValueError(\"Invalid integer data type %r.\""
    ],
    [
        "return fmt % {'dtype': self.dtype, 'min': self.min, 'max': self.max}",
        "return fmt % {'dtype': self.dtype, 'min': self.min, 'max':"
    ],
    [
        "return \"%s(min=%s, max=%s, dtype=%s)\" % (self.__class__.__name__,",
        "return \"%s(min=%s, max=%s, dtype=%s)\""
    ],
    [
        "\"ctypes bitfields have no dtype equivalent\")",
        "\"ctypes bitfields have no"
    ],
    [
        "Return the dtype type with endianness included if it's the case",
        "Return the dtype type with endianness included if it's"
    ],
    [
        "if getattr(t, '__ctype_be__', None) is t:",
        "if getattr(t, '__ctype_be__', None) is"
    ],
    [
        "elif getattr(t, '__ctype_le__', None) is t:",
        "elif getattr(t, '__ctype_le__',"
    ],
    [
        "Construct a dtype object from a ctypes type",
        "Construct a dtype object from"
    ],
    [
        "raise TypeError(\"ctypes pointers have no dtype equivalent\")",
        "raise TypeError(\"ctypes pointers have no dtype"
    ],
    [
        "This module contains a set of functions for vectorized string",
        "This module contains a set of functions"
    ],
    [
        "The `chararray` class exists for backwards compatibility with",
        "The `chararray` class exists for backwards compatibility"
    ],
    [
        "Numarray, it is not recommended for new development. Starting from numpy",
        "Numarray, it is not recommended for new development."
    ],
    [
        "`dtype` `object_`, `bytes_` or `str_`, and use the free functions",
        "`dtype` `object_`, `bytes_` or `str_`, and"
    ],
    [
        "in the `numpy.char` module for fast vectorized string operations.",
        "in the `numpy.char` module for fast vectorized"
    ],
    [
        "Some methods will only be available if the corresponding string method is",
        "Some methods will only be available if the corresponding"
    ],
    [
        "available in your version of Python.",
        "available in your version"
    ],
    [
        "The preferred alias for `defchararray` is `numpy.char`.",
        "The preferred alias for `defchararray` is"
    ],
    [
        "from .numerictypes import bytes_, str_, character",
        "from .numerictypes import"
    ],
    [
        "from .numeric import ndarray, array as narray, asarray as asnarray",
        "from .numeric import ndarray, array as narray,"
    ],
    [
        "'greater', 'less', 'str_len', 'add', 'multiply', 'mod', 'capitalize',",
        "'greater', 'less', 'str_len', 'add', 'multiply', 'mod',"
    ],
    [
        "'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs',",
        "'center', 'count', 'decode', 'encode',"
    ],
    [
        "'find', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace',",
        "'find', 'index', 'isalnum', 'isalpha',"
    ],
    [
        "'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'partition',",
        "'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip',"
    ],
    [
        "'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit',",
        "'replace', 'rfind', 'rindex', 'rjust', 'rpartition',"
    ],
    [
        "'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase',",
        "'rstrip', 'split', 'splitlines', 'startswith', 'strip',"
    ],
    [
        "'title', 'translate', 'upper', 'zfill', 'isnumeric', 'isdecimal',",
        "'title', 'translate', 'upper', 'zfill', 'isnumeric',"
    ],
    [
        "Unlike `numpy.equal`, this comparison is performed by first",
        "Unlike `numpy.equal`, this comparison is performed by"
    ],
    [
        "stripping whitespace characters from the end of the string.  This",
        "stripping whitespace characters from the end of"
    ],
    [
        "behavior is provided for backward-compatibility with numarray.",
        "behavior is provided for"
    ],
    [
        "Input arrays of the same shape.",
        "Input arrays of"
    ],
    [
        "Unlike `numpy.not_equal`, this comparison is performed by first",
        "Unlike `numpy.not_equal`, this comparison is"
    ],
    [
        "stripping whitespace characters from the end of the string.  This",
        "stripping whitespace characters from the end"
    ],
    [
        "behavior is provided for backward-compatibility with numarray.",
        "behavior is provided for backward-compatibility with"
    ],
    [
        "Input arrays of the same shape.",
        "Input arrays of the"
    ],
    [
        "Unlike `numpy.greater_equal`, this comparison is performed by",
        "Unlike `numpy.greater_equal`, this comparison is performed"
    ],
    [
        "first stripping whitespace characters from the end of the string.",
        "first stripping whitespace characters from the end"
    ],
    [
        "This behavior is provided for backward-compatibility with",
        "This behavior is provided for backward-compatibility"
    ],
    [
        "Input arrays of the same shape.",
        "Input arrays of"
    ],
    [
        "Unlike `numpy.less_equal`, this comparison is performed by first",
        "Unlike `numpy.less_equal`, this comparison is"
    ],
    [
        "stripping whitespace characters from the end of the string.  This",
        "stripping whitespace characters from the end of"
    ],
    [
        "behavior is provided for backward-compatibility with numarray.",
        "behavior is provided for backward-compatibility with"
    ],
    [
        "Input arrays of the same shape.",
        "Input arrays of the same"
    ],
    [
        "Unlike `numpy.greater`, this comparison is performed by first",
        "Unlike `numpy.greater`, this comparison is performed by"
    ],
    [
        "stripping whitespace characters from the end of the string.  This",
        "stripping whitespace characters from the end"
    ],
    [
        "behavior is provided for backward-compatibility with numarray.",
        "behavior is provided for backward-compatibility with"
    ],
    [
        "Input arrays of the same shape.",
        "Input arrays of"
    ],
    [
        "Unlike `numpy.greater`, this comparison is performed by first",
        "Unlike `numpy.greater`, this comparison is performed by"
    ],
    [
        "stripping whitespace characters from the end of the string.  This",
        "stripping whitespace characters from the end of"
    ],
    [
        "behavior is provided for backward-compatibility with numarray.",
        "behavior is provided for"
    ],
    [
        "Input arrays of the same shape.",
        "Input arrays of the same"
    ],
    [
        "Return (a * i), that is string multiple concatenation,",
        "Return (a * i), that is"
    ],
    [
        "a : array_like, with `np.bytes_` or `np.str_` dtype",
        "a : array_like, with `np.bytes_` or `np.str_`"
    ],
    [
        "i : array_like, with any integer dtype",
        "i : array_like, with any integer"
    ],
    [
        "Output array of str or unicode, depending on input types",
        "Output array of str or unicode,"
    ],
    [
        "This is a thin wrapper around np.strings.multiply that raises",
        "This is a thin wrapper around np.strings.multiply that"
    ],
    [
        "`ValueError` when ``i`` is not an integer. It only",
        "`ValueError` when ``i`` is not an integer. It"
    ],
    [
        ">>> a = np.array([\"a\", \"b\", \"c\"])",
        ">>> a ="
    ],
    [
        "raise ValueError(\"Can only multiply by integers\")",
        "raise ValueError(\"Can only multiply by"
    ],
    [
        "Partition each element in `a` around `sep`.",
        "Partition each element in"
    ],
    [
        "For each element in `a`, split the element as the first",
        "For each element in `a`, split the element as"
    ],
    [
        "before the separator, the separator itself, and the part after",
        "before the separator, the separator itself,"
    ],
    [
        "containing the string itself, followed by two empty strings.",
        "containing the string itself, followed"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or"
    ],
    [
        "Separator to split each string element in `a`.",
        "Separator to split each"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "depending on input types. The output array will have an extra",
        "depending on input types. The output array"
    ],
    [
        ">>> x = np.array([\"Numpy is nice!\"])",
        ">>> x = np.array([\"Numpy"
    ],
    [
        "Partition (split) each element around the right-most separator.",
        "Partition (split) each element around"
    ],
    [
        "For each element in `a`, split the element as the last",
        "For each element in `a`, split the"
    ],
    [
        "before the separator, the separator itself, and the part after",
        "before the separator, the separator itself, and the part"
    ],
    [
        "containing the string itself, followed by two empty strings.",
        "containing the string itself, followed by two"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``,"
    ],
    [
        "Right-most separator to split each element in array.",
        "Right-most separator to split each element"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or"
    ],
    [
        "depending on input types. The output array will have an extra",
        "depending on input types. The output array"
    ],
    [
        ">>> a = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> a = np.array(['aAaAaA',"
    ],
    [
        "Provides a convenient view on arrays of string and unicode values.",
        "Provides a convenient view on arrays of string"
    ],
    [
        "The `chararray` class exists for backwards compatibility with",
        "The `chararray` class exists for"
    ],
    [
        "Numarray, it is not recommended for new development. Starting from numpy",
        "Numarray, it is not recommended for new"
    ],
    [
        "`dtype` `~numpy.object_`, `~numpy.bytes_` or `~numpy.str_`, and use",
        "`dtype` `~numpy.object_`, `~numpy.bytes_` or `~numpy.str_`, and"
    ],
    [
        "the free functions in the `numpy.char` module for fast vectorized",
        "the free functions in the `numpy.char` module for fast"
    ],
    [
        "Versus a NumPy array of dtype `~numpy.bytes_` or `~numpy.str_`, this",
        "Versus a NumPy array of dtype"
    ],
    [
        "(e.g. `.endswith`) and infix operators (e.g. ``\"+\", \"*\", \"%\"``)",
        "(e.g. `.endswith`) and infix operators"
    ],
    [
        "chararrays should be created using `numpy.char.array` or",
        "chararrays should be created using"
    ],
    [
        "`numpy.char.asarray`, rather than this constructor directly.",
        "`numpy.char.asarray`, rather than this"
    ],
    [
        "This constructor creates the array, using `buffer` (with `offset`",
        "This constructor creates the array, using `buffer`"
    ],
    [
        "and `strides`) if it is not ``None``. If `buffer` is ``None``, then",
        "and `strides`) if it is not"
    ],
    [
        "constructs a new array with `strides` in \"C order\", unless both",
        "constructs a new array with `strides` in \"C"
    ],
    [
        "Are the array elements of type unicode (True) or string (False).",
        "Are the array elements of type"
    ],
    [
        "buffer : object exposing the buffer interface or str, optional",
        "buffer : object exposing the buffer interface or"
    ],
    [
        "Memory address of the start of the array data.  Default is None,",
        "Memory address of the start of the array data. Default"
    ],
    [
        "in which case a new array is created.",
        "in which case a"
    ],
    [
        "Fixed stride displacement from the beginning of an axis?",
        "Fixed stride displacement from the beginning"
    ],
    [
        "strides : array_like of ints, optional",
        "strides : array_like of"
    ],
    [
        "Strides for the array (see `~numpy.ndarray.strides` for",
        "Strides for the array (see"
    ],
    [
        "The order in which the array data is stored in memory: 'C' ->",
        "The order in which the array data is"
    ],
    [
        "\"row major\" order (the default), 'F' -> \"column major\"",
        "\"row major\" order (the default),"
    ],
    [
        "self = ndarray.__new__(subtype, shape, (dtype, itemsize),",
        "self = ndarray.__new__(subtype, shape, (dtype,"
    ],
    [
        "self = ndarray.__new__(subtype, shape, (dtype, itemsize),",
        "self = ndarray.__new__(subtype, shape, (dtype,"
    ],
    [
        "raise ValueError(\"Can only create a chararray from string data.\")",
        "raise ValueError(\"Can only create a chararray"
    ],
    [
        "Return (self + other), that is string concatenation,",
        "Return (self + other), that is string"
    ],
    [
        "element-wise for a pair of array_likes of str or unicode.",
        "element-wise for a pair of"
    ],
    [
        "Return (other + self), that is string concatenation,",
        "Return (other + self), that"
    ],
    [
        "element-wise for a pair of array_likes of `bytes_` or `str_`.",
        "element-wise for a pair of array_likes of `bytes_`"
    ],
    [
        "Return (self * i), that is string multiple concatenation,",
        "Return (self * i), that is"
    ],
    [
        "Return (self * i), that is string multiple concatenation,",
        "Return (self * i), that is string multiple"
    ],
    [
        "(interpolation), element-wise for a pair of array_likes of `bytes_`",
        "(interpolation), element-wise for a pair of"
    ],
    [
        "Return the indices that sort the array lexicographically.",
        "Return the indices that"
    ],
    [
        "For full documentation see `numpy.argsort`, for which this method is",
        "For full documentation see `numpy.argsort`,"
    ],
    [
        "in fact merely a \"thin wrapper.\"",
        "in fact merely"
    ],
    [
        "Return a copy of `self` with only the first character of each element",
        "Return a copy of `self` with only the first character"
    ],
    [
        "Return a copy of `self` with its elements centered in a",
        "Return a copy of `self` with its"
    ],
    [
        "Returns an array with the number of non-overlapping occurrences of",
        "Returns an array with the number of non-overlapping occurrences"
    ],
    [
        "substring `sub` in the range [`start`, `end`].",
        "substring `sub` in the range"
    ],
    [
        "Returns a boolean array which is `True` where the string element",
        "Returns a boolean array which is `True` where the string"
    ],
    [
        "in `self` ends with `suffix`, otherwise `False`.",
        "in `self` ends with `suffix`,"
    ],
    [
        "Return a copy of each string element where all tab characters are",
        "Return a copy of each string element where all"
    ],
    [
        "replaced by one or more spaces.",
        "replaced by one or more"
    ],
    [
        "For each element, return the lowest index in the string where",
        "For each element, return the lowest index in"
    ],
    [
        "Like `find`, but raises :exc:`ValueError` when the substring is not",
        "Like `find`, but raises :exc:`ValueError`"
    ],
    [
        "Returns true for each element if all characters in the string",
        "Returns true for each element if all characters in the"
    ],
    [
        "are alphanumeric and there is at least one character, false",
        "are alphanumeric and there is"
    ],
    [
        "Returns true for each element if all characters in the string",
        "Returns true for each element if all characters in the"
    ],
    [
        "are alphabetic and there is at least one character, false",
        "are alphabetic and there is at least one"
    ],
    [
        "Returns true for each element if all characters in the string are",
        "Returns true for each element if"
    ],
    [
        "digits and there is at least one character, false otherwise.",
        "digits and there is at least one character, false"
    ],
    [
        "Returns true for each element if all cased characters in the",
        "Returns true for each element if all"
    ],
    [
        "string are lowercase and there is at least one cased character,",
        "string are lowercase and there is at least one"
    ],
    [
        "Returns true for each element if there are only whitespace",
        "Returns true for each element if there are"
    ],
    [
        "characters in the string and there is at least one character,",
        "characters in the string and there is at"
    ],
    [
        "Returns true for each element if the element is a titlecased",
        "Returns true for each element if the element is"
    ],
    [
        "string and there is at least one character, false otherwise.",
        "string and there is at"
    ],
    [
        "Returns true for each element if all cased characters in the",
        "Returns true for each element if all"
    ],
    [
        "string are uppercase and there is at least one character, false",
        "string are uppercase and there is at least one"
    ],
    [
        "Return a string which is the concatenation of the strings in the",
        "Return a string which is the concatenation"
    ],
    [
        "Return an array with the elements of `self` left-justified in a",
        "Return an array with the elements of `self` left-justified"
    ],
    [
        "Return an array with the elements of `self` converted to",
        "Return an array with the elements of `self`"
    ],
    [
        "For each element in `self`, return a copy with the leading characters",
        "For each element in `self`, return"
    ],
    [
        "Partition each element in `self` around `sep`.",
        "Partition each element in"
    ],
    [
        "For each element in `self`, return a copy of the string with all",
        "For each element in `self`, return a copy"
    ],
    [
        "occurrences of substring `old` replaced by `new`.",
        "occurrences of substring `old` replaced"
    ],
    [
        "For each element in `self`, return the highest index in the string",
        "For each element in `self`, return the highest index in"
    ],
    [
        "where substring `sub` is found, such that `sub` is contained",
        "where substring `sub` is found,"
    ],
    [
        "Like `rfind`, but raises :exc:`ValueError` when the substring `sub` is",
        "Like `rfind`, but raises :exc:`ValueError` when the"
    ],
    [
        "Return an array with the elements of `self`",
        "Return an array with"
    ],
    [
        "right-justified in a string of length `width`.",
        "right-justified in a string"
    ],
    [
        "Partition each element in `self` around `sep`.",
        "Partition each element in `self`"
    ],
    [
        "For each element in `self`, return a list of the words in",
        "For each element in `self`, return a list of the"
    ],
    [
        "the string, using `sep` as the delimiter string.",
        "the string, using `sep` as the"
    ],
    [
        "For each element in `self`, return a copy with the trailing",
        "For each element in `self`, return a"
    ],
    [
        "For each element in `self`, return a list of the words in the",
        "For each element in `self`, return a list of the words"
    ],
    [
        "string, using `sep` as the delimiter string.",
        "string, using `sep` as the"
    ],
    [
        "For each element in `self`, return a list of the lines in the",
        "For each element in `self`, return a list"
    ],
    [
        "Returns a boolean array which is `True` where the string element",
        "Returns a boolean array which is `True` where the"
    ],
    [
        "in `self` starts with `prefix`, otherwise `False`.",
        "in `self` starts with"
    ],
    [
        "For each element in `self`, return a copy with the leading and",
        "For each element in `self`, return a copy with"
    ],
    [
        "For each element in `self`, return a copy of the string with",
        "For each element in `self`, return a"
    ],
    [
        "uppercase characters converted to lowercase and vice versa.",
        "uppercase characters converted to lowercase and vice"
    ],
    [
        "For each element in `self`, return a titlecased version of the",
        "For each element in `self`, return a titlecased version"
    ],
    [
        "string: words start with uppercase characters, all remaining cased",
        "string: words start with uppercase characters, all"
    ],
    [
        "For each element in `self`, return a copy of the string where",
        "For each element in `self`, return"
    ],
    [
        "all characters occurring in the optional argument",
        "all characters occurring in the"
    ],
    [
        "`deletechars` are removed, and the remaining characters have",
        "`deletechars` are removed, and the remaining characters"
    ],
    [
        "been mapped through the given translation table.",
        "been mapped through the given"
    ],
    [
        "Return an array with the elements of `self` converted to",
        "Return an array with the elements of `self` converted"
    ],
    [
        "Return the numeric string left-filled with zeros in a string of",
        "Return the numeric string left-filled with"
    ],
    [
        "For each element in `self`, return True if there are only",
        "For each element in `self`, return True if"
    ],
    [
        "For each element in `self`, return True if there are only",
        "For each element in `self`, return True if"
    ],
    [
        "def array(obj, itemsize=None, copy=True, unicode=None, order=None):",
        "def array(obj, itemsize=None, copy=True,"
    ],
    [
        "This class is provided for numarray backward-compatibility.",
        "This class is provided for numarray"
    ],
    [
        "New code (not concerned with numarray compatibility) should use",
        "New code (not concerned with numarray compatibility) should"
    ],
    [
        "arrays of type `bytes_` or `str_` and use the free functions",
        "arrays of type `bytes_` or `str_`"
    ],
    [
        "in :mod:`numpy.char` for fast vectorized string operations instead.",
        "in :mod:`numpy.char` for fast vectorized"
    ],
    [
        "Versus a NumPy array of dtype `bytes_` or `str_`, this",
        "Versus a NumPy array of dtype `bytes_`"
    ],
    [
        "and infix operators (e.g. ``+, *, %``)",
        "and infix operators (e.g. ``+,"
    ],
    [
        "obj : array of str or unicode-like",
        "obj : array of str"
    ],
    [
        "`itemsize` is the number of characters per scalar in the",
        "`itemsize` is the number of characters per scalar"
    ],
    [
        "resulting array.  If `itemsize` is None, and `obj` is an",
        "resulting array. If `itemsize` is None, and"
    ],
    [
        "object array or a Python list, the `itemsize` will be",
        "object array or a Python list, the"
    ],
    [
        "automatically determined.  If `itemsize` is provided and `obj`",
        "automatically determined. If `itemsize` is"
    ],
    [
        "is of type str or unicode, then the `obj` string will be",
        "is of type str or unicode, then the"
    ],
    [
        "If true (default), then the object is copied.  Otherwise, a copy",
        "If true (default), then the object is copied. Otherwise, a"
    ],
    [
        "will only be made if ``__array__`` returns a copy, if obj is a",
        "will only be made if ``__array__`` returns a copy, if obj is"
    ],
    [
        "nested sequence, or if a copy is needed to satisfy any of the other",
        "nested sequence, or if a copy is needed to satisfy"
    ],
    [
        "When true, the resulting `~numpy.char.chararray` can contain Unicode",
        "When true, the resulting `~numpy.char.chararray` can"
    ],
    [
        "None and `obj` is one of the following:",
        "None and `obj` is one"
    ],
    [
        "- an ndarray of type :class:`str_` or :class:`bytes_`",
        "- an ndarray of type"
    ],
    [
        "- a Python :class:`str` or :class:`bytes` object,",
        "- a Python :class:`str` or"
    ],
    [
        "then the unicode setting of the output array will be",
        "then the unicode setting of the output array will"
    ],
    [
        "order : {'C', 'F', 'A'}, optional",
        "order : {'C', 'F', 'A'},"
    ],
    [
        "Specify the order of the array.  If order is 'C' (default), then the",
        "Specify the order of the array. If"
    ],
    [
        "array will be in C-contiguous order (last-index varies the",
        "array will be in C-contiguous order (last-index varies"
    ],
    [
        "fastest).  If order is 'F', then the returned array",
        "fastest). If order is 'F', then the"
    ],
    [
        "will be in Fortran-contiguous order (first-index varies the",
        "will be in Fortran-contiguous order (first-index"
    ],
    [
        "fastest).  If order is 'A', then the returned array may",
        "fastest). If order is 'A', then the returned"
    ],
    [
        "be in any order (either C-, Fortran-contiguous, or even",
        "be in any order (either C-,"
    ],
    [
        ">>> char_array = np.char.array(['hello', 'world', 'numpy','array'])",
        ">>> char_array ="
    ],
    [
        "if isinstance(obj, ndarray) and issubclass(obj.dtype.type, character):",
        "if isinstance(obj, ndarray) and issubclass(obj.dtype.type,"
    ],
    [
        "(not unicode and isinstance(obj, str_)) or",
        "(not unicode and isinstance(obj,"
    ],
    [
        "if isinstance(obj, ndarray) and issubclass(obj.dtype.type, object):",
        "if isinstance(obj, ndarray) and issubclass(obj.dtype.type,"
    ],
    [
        "val = narray(obj, dtype=dtype, order=order, subok=True)",
        "val = narray(obj, dtype=dtype, order=order,"
    ],
    [
        "val = narray(obj, dtype=(dtype, itemsize), order=order, subok=True)",
        "val = narray(obj, dtype=(dtype,"
    ],
    [
        "Convert the input to a `~numpy.char.chararray`, copying the data only if",
        "Convert the input to a `~numpy.char.chararray`, copying"
    ],
    [
        "Versus a NumPy array of dtype `bytes_` or `str_`, this",
        "Versus a NumPy array of dtype"
    ],
    [
        "and infix operators (e.g. ``+``, ``*``, ``%``)",
        "and infix operators (e.g. ``+``,"
    ],
    [
        "obj : array of str or unicode-like",
        "obj : array of str"
    ],
    [
        "`itemsize` is the number of characters per scalar in the",
        "`itemsize` is the number of characters per scalar in"
    ],
    [
        "resulting array.  If `itemsize` is None, and `obj` is an",
        "resulting array. If `itemsize` is"
    ],
    [
        "object array or a Python list, the `itemsize` will be",
        "object array or a Python list, the `itemsize`"
    ],
    [
        "automatically determined.  If `itemsize` is provided and `obj`",
        "automatically determined. If `itemsize`"
    ],
    [
        "is of type str or unicode, then the `obj` string will be",
        "is of type str or unicode, then the `obj` string"
    ],
    [
        "When true, the resulting `~numpy.char.chararray` can contain Unicode",
        "When true, the resulting `~numpy.char.chararray`"
    ],
    [
        "None and `obj` is one of the following:",
        "None and `obj` is one of"
    ],
    [
        "- an ndarray of type `str_` or `unicode_`",
        "- an ndarray of"
    ],
    [
        "- a Python str or unicode object,",
        "- a Python str or unicode"
    ],
    [
        "then the unicode setting of the output array will be",
        "then the unicode setting of the output"
    ],
    [
        "Specify the order of the array.  If order is 'C' (default), then the",
        "Specify the order of the array. If"
    ],
    [
        "array will be in C-contiguous order (last-index varies the",
        "array will be in C-contiguous order"
    ],
    [
        "fastest).  If order is 'F', then the returned array",
        "fastest). If order is 'F', then"
    ],
    [
        "will be in Fortran-contiguous order (first-index varies the",
        "will be in Fortran-contiguous order"
    ],
    [
        "from . import numeric as _nx",
        "from . import numeric"
    ],
    [
        "from .multiarray import array, asanyarray, normalize_axis_index",
        "from .multiarray import array,"
    ],
    [
        "from . import fromnumeric as _from_nx",
        "from . import fromnumeric as"
    ],
    [
        "Convert inputs to arrays with at least one dimension.",
        "Convert inputs to arrays with at least"
    ],
    [
        "Copies are made only if necessary.",
        "Copies are made only if"
    ],
    [
        "View inputs as arrays with at least two dimensions.",
        "View inputs as arrays with at"
    ],
    [
        "One or more array-like sequences.  Non-array inputs are converted",
        "One or more array-like sequences. Non-array inputs are"
    ],
    [
        "to arrays.  Arrays that already have two or more dimensions are",
        "to arrays. Arrays that already have two or more dimensions"
    ],
    [
        "Copies are avoided where possible, and views with two or more",
        "Copies are avoided where possible, and views with two"
    ],
    [
        "View inputs as arrays with at least three dimensions.",
        "View inputs as arrays with"
    ],
    [
        "One or more array-like sequences.  Non-array inputs are converted to",
        "One or more array-like sequences. Non-array inputs are converted"
    ],
    [
        "arrays.  Arrays that already have three or more dimensions are",
        "arrays. Arrays that already have three"
    ],
    [
        "avoided where possible, and views with three or more dimensions are",
        "avoided where possible, and views with three or"
    ],
    [
        "raise TypeError('arrays to stack must be passed as a \"sequence\" type '",
        "raise TypeError('arrays to stack must be passed as a \"sequence\""
    ],
    [
        "Stack arrays in sequence vertically (row wise).",
        "Stack arrays in sequence"
    ],
    [
        "instance, for pixel-data with a height (first axis), width (second axis),",
        "instance, for pixel-data with a height (first axis), width"
    ],
    [
        "and r/g/b channels (third axis). The functions `concatenate`, `stack` and",
        "and r/g/b channels (third axis). The"
    ],
    [
        "`block` provide more general stacking and concatenation operations.",
        "`block` provide more general"
    ],
    [
        "The arrays must have the same shape along all but the first axis.",
        "The arrays must have the same shape along"
    ],
    [
        "array_like input, it will be treated as a sequence of arrays; i.e.,",
        "array_like input, it will be treated as a sequence"
    ],
    [
        "each element along the zeroth axis is treated as a separate array.",
        "each element along the zeroth axis is treated"
    ],
    [
        "If provided, the destination array will have this dtype. Cannot be",
        "If provided, the destination array will have this dtype. Cannot"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe', 'same_kind',"
    ],
    [
        "Controls what kind of data casting may occur. Defaults to 'same_kind'.",
        "Controls what kind of data casting"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of arrays along an existing"
    ],
    [
        "stack : Join a sequence of arrays along a new axis.",
        "stack : Join a sequence of arrays along"
    ],
    [
        "block : Assemble an nd-array from nested lists of blocks.",
        "block : Assemble an nd-array from nested lists of"
    ],
    [
        "hstack : Stack arrays in sequence horizontally (column wise).",
        "hstack : Stack arrays in sequence"
    ],
    [
        "dstack : Stack arrays in sequence depth wise (along third axis).",
        "dstack : Stack arrays in sequence depth wise (along third"
    ],
    [
        "vsplit : Split an array into multiple sub-arrays vertically (row-wise).",
        "vsplit : Split an array into multiple sub-arrays vertically"
    ],
    [
        "unstack : Split an array into a tuple of sub-arrays along an axis.",
        "unstack : Split an array into a tuple of"
    ],
    [
        "Stack arrays in sequence horizontally (column wise).",
        "Stack arrays in sequence horizontally (column"
    ],
    [
        "arrays where it concatenates along the first axis. Rebuilds arrays divided",
        "arrays where it concatenates along the first axis. Rebuilds arrays"
    ],
    [
        "instance, for pixel-data with a height (first axis), width (second axis),",
        "instance, for pixel-data with a height (first axis),"
    ],
    [
        "and r/g/b channels (third axis). The functions `concatenate`, `stack` and",
        "and r/g/b channels (third axis). The functions `concatenate`,"
    ],
    [
        "`block` provide more general stacking and concatenation operations.",
        "`block` provide more general"
    ],
    [
        "The arrays must have the same shape along all but the second axis,",
        "The arrays must have the same shape along all but"
    ],
    [
        "array_like input, it will be treated as a sequence of arrays; i.e.,",
        "array_like input, it will be treated as a"
    ],
    [
        "each element along the zeroth axis is treated as a separate array.",
        "each element along the zeroth axis"
    ],
    [
        "If provided, the destination array will have this dtype. Cannot be",
        "If provided, the destination array will have"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe', 'same_kind',"
    ],
    [
        "Controls what kind of data casting may occur. Defaults to 'same_kind'.",
        "Controls what kind of data casting may occur. Defaults"
    ],
    [
        "The array formed by stacking the given arrays.",
        "The array formed by stacking"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of arrays along"
    ],
    [
        "stack : Join a sequence of arrays along a new axis.",
        "stack : Join a sequence of arrays along a new"
    ],
    [
        "block : Assemble an nd-array from nested lists of blocks.",
        "block : Assemble an nd-array from"
    ],
    [
        "vstack : Stack arrays in sequence vertically (row wise).",
        "vstack : Stack arrays in sequence vertically"
    ],
    [
        "dstack : Stack arrays in sequence depth wise (along third axis).",
        "dstack : Stack arrays in sequence depth"
    ],
    [
        "hsplit : Split an array into multiple sub-arrays",
        "hsplit : Split an array into"
    ],
    [
        "unstack : Split an array into a tuple of sub-arrays along an axis.",
        "unstack : Split an array into a tuple of sub-arrays along"
    ],
    [
        "Join a sequence of arrays along a new axis.",
        "Join a sequence of arrays along"
    ],
    [
        "The ``axis`` parameter specifies the index of the new axis in the",
        "The ``axis`` parameter specifies the index of the"
    ],
    [
        "Each array must have the same shape. In the case of a single ndarray",
        "Each array must have the same shape. In the case"
    ],
    [
        "array_like input, it will be treated as a sequence of arrays; i.e.,",
        "array_like input, it will be treated as"
    ],
    [
        "each element along the zeroth axis is treated as a separate array.",
        "each element along the zeroth axis is treated as a"
    ],
    [
        "The axis in the result array along which the input arrays are stacked.",
        "The axis in the result array along which the"
    ],
    [
        "If provided, the destination to place the result. The shape must be",
        "If provided, the destination to place"
    ],
    [
        "correct, matching that of what stack would have returned if no",
        "correct, matching that of what stack would have returned if"
    ],
    [
        "If provided, the destination array will have this dtype. Cannot be",
        "If provided, the destination array will have this dtype."
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv',"
    ],
    [
        "Controls what kind of data casting may occur. Defaults to 'same_kind'.",
        "Controls what kind of data casting"
    ],
    [
        "The stacked array has one more dimension than the input arrays.",
        "The stacked array has one more dimension than the"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of"
    ],
    [
        "block : Assemble an nd-array from nested lists of blocks.",
        "block : Assemble an nd-array"
    ],
    [
        "split : Split array into a list of multiple sub-arrays of equal size.",
        "split : Split array into a list of multiple sub-arrays of equal"
    ],
    [
        "unstack : Split an array into a tuple of sub-arrays along an axis.",
        "unstack : Split an array into a tuple of"
    ],
    [
        "arrays = [asanyarray(arr) for arr in arrays]",
        "arrays = [asanyarray(arr) for"
    ],
    [
        "raise ValueError('need at least one array to stack')",
        "raise ValueError('need at least one array"
    ],
    [
        "shapes = {arr.shape for arr in arrays}",
        "shapes = {arr.shape for"
    ],
    [
        "raise ValueError('all input arrays must have the same shape')",
        "raise ValueError('all input arrays must have the"
    ],
    [
        "sl = (slice(None),) * axis + (_nx.newaxis,)",
        "sl = (slice(None),) *"
    ],
    [
        "expanded_arrays = [arr[sl] for arr in arrays]",
        "expanded_arrays = [arr[sl] for arr in"
    ],
    [
        "Split an array into a sequence of arrays along the given axis.",
        "Split an array into a sequence of"
    ],
    [
        "The ``axis`` parameter specifies the dimension along which the array will",
        "The ``axis`` parameter specifies the dimension along which the"
    ],
    [
        "The result is a tuple of arrays split along ``axis``.",
        "The result is a tuple of arrays split"
    ],
    [
        "stack : Join a sequence of arrays along a new axis.",
        "stack : Join a sequence of arrays along a new"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of arrays"
    ],
    [
        "block : Assemble an nd-array from nested lists of blocks.",
        "block : Assemble an nd-array from"
    ],
    [
        "split : Split array into a list of multiple sub-arrays of equal size.",
        "split : Split array into a list of"
    ],
    [
        "``unstack`` serves as the reverse operation of :py:func:`stack`, i.e.,",
        "``unstack`` serves as the reverse operation of :py:func:`stack`,"
    ],
    [
        "iterating on an array iterates along the first axis.",
        "iterating on an array iterates"
    ],
    [
        "idx_str = ''.join('[{}]'.format(i) for i in index if i is not None)",
        "idx_str = ''.join('[{}]'.format(i) for i in"
    ],
    [
        "Recursive function checking that the depths of nested lists in `arrays`",
        "Recursive function checking that the depths of nested lists"
    ],
    [
        "all match. Mismatch raises a ValueError as described in the block",
        "all match. Mismatch raises a ValueError as described"
    ],
    [
        "The entire index (rather than just the depth) needs to be calculated",
        "The entire index (rather than just the"
    ],
    [
        "for each innermost list, in case an error needs to be raised, so that",
        "for each innermost list, in case an"
    ],
    [
        "the index of the offending list can be printed as part of the error.",
        "the index of the offending list can be printed as part of"
    ],
    [
        "arrays : nested list of arrays",
        "arrays : nested list of"
    ],
    [
        "The full index of `arrays` within the nested lists passed to",
        "The full index of `arrays` within the nested lists passed"
    ],
    [
        "`_block_check_depths_match` at the top of the recursion.",
        "`_block_check_depths_match` at the top of the"
    ],
    [
        "The full index of an element from the bottom of the nesting in",
        "The full index of an element from the bottom of the nesting"
    ],
    [
        "`arrays`. If any element at the bottom is an empty list, this will",
        "`arrays`. If any element at the bottom is an"
    ],
    [
        "refer to it, and the last index along the empty axis will be None.",
        "refer to it, and the last index along the empty"
    ],
    [
        "The maximum of the ndims of the arrays nested in `arrays`.",
        "The maximum of the ndims of the"
    ],
    [
        "The number of elements in the final array. This is used the motivate",
        "The number of elements in the final array. This is used the"
    ],
    [
        "the choice of algorithm used using benchmarking wisdom.",
        "the choice of algorithm used using benchmarking"
    ],
    [
        "'Only lists can be used to arrange blocks, and np.block does '",
        "'Only lists can be used to arrange"
    ],
    [
        "'not allow implicit conversion from tuple to ndarray.'.format(",
        "'not allow implicit conversion from tuple"
    ],
    [
        "idxs_ndims = (_block_check_depths_match(arr, parent_index + [i])",
        "idxs_ndims = (_block_check_depths_match(arr, parent_index +"
    ],
    [
        "for index, ndim, size in idxs_ndims:",
        "for index, ndim,"
    ],
    [
        "\"List depths are mismatched. First element was at depth \"",
        "\"List depths are mismatched. First element was"
    ],
    [
        "\"{}, but there is an element at depth {} ({})\".format(",
        "\"{}, but there is an element at"
    ],
    [
        "\"\"\"Given array shapes, return the resulting shape and slices prefixes.",
        "\"\"\"Given array shapes, return the resulting"
    ],
    [
        "shape, _ = _concatenate_shapes([arr.shape for shape in arrs], axis)",
        "shape, _ = _concatenate_shapes([arr.shape for"
    ],
    [
        "slice_prefixes: tuple of (slice(start, end), )",
        "slice_prefixes: tuple of"
    ],
    [
        "For a list of arrays being concatenated, this returns the slice",
        "For a list of arrays being"
    ],
    [
        "in the larger array at axis that needs to be sliced into.",
        "in the larger array at axis that needs to be sliced"
    ],
    [
        "ret = concatenate([a, b, c], axis)",
        "ret = concatenate([a, b,"
    ],
    [
        "_, (sl_a, sl_b, sl_c) = concatenate_slices([a, b, c], axis)",
        "_, (sl_a, sl_b, sl_c) = concatenate_slices([a, b, c],"
    ],
    [
        "ret[(slice(None),) * axis + sl_a] == a",
        "ret[(slice(None),) * axis + sl_a] =="
    ],
    [
        "ret[(slice(None),) * axis + sl_b] == b",
        "ret[(slice(None),) * axis + sl_b]"
    ],
    [
        "ret[(slice(None),) * axis + sl_c] == c",
        "ret[(slice(None),) * axis +"
    ],
    [
        "These are called slice prefixes since they are used in the recursive",
        "These are called slice prefixes since they are used in the"
    ],
    [
        "blocking algorithm to compute the left-most slices during the",
        "blocking algorithm to compute the left-most slices"
    ],
    [
        "recursion. Therefore, they must be prepended to rest of the slice",
        "recursion. Therefore, they must be prepended to rest of the"
    ],
    [
        "that was computed deeper in the recursion.",
        "that was computed deeper in the"
    ],
    [
        "These are returned as tuples to ensure that they can quickly be added",
        "These are returned as tuples to ensure that they"
    ],
    [
        "to existing slice tuple without creating a new tuple every time.",
        "to existing slice tuple without creating"
    ],
    [
        "shape_at_axis = [shape[axis] for shape in shapes]",
        "shape_at_axis = [shape[axis] for shape"
    ],
    [
        "'Mismatched array shapes in block along axis {}.'.format(axis))",
        "'Mismatched array shapes in block"
    ],
    [
        "Returns the shape of the final array, along with a list",
        "Returns the shape of the final array, along with"
    ],
    [
        "of slices and a list of arrays that can be used for assignment inside the",
        "of slices and a list of arrays that can be used for assignment inside"
    ],
    [
        "arrays : nested list of arrays",
        "arrays : nested list of"
    ],
    [
        "The number of dimensions in thefinal array.",
        "The number of dimensions in"
    ],
    [
        "The shape that the final array will take on.",
        "The shape that the final array"
    ],
    [
        "slices: list of tuple of slices",
        "slices: list of tuple"
    ],
    [
        "The slices into the full array required for assignment. These are",
        "The slices into the full array"
    ],
    [
        "required to be prepended with ``(Ellipsis, )`` to obtain to correct",
        "required to be prepended with ``(Ellipsis, )`` to"
    ],
    [
        "The data to assign to each slice of the full array",
        "The data to assign to each slice"
    ],
    [
        "axis = result_ndim - max_depth + depth",
        "axis = result_ndim - max_depth +"
    ],
    [
        "for slice_prefix, inner_slices in zip(slice_prefixes, slices)",
        "for slice_prefix, inner_slices in"
    ],
    [
        "Internal implementation of block based on repeated concatenation.",
        "Internal implementation of block based"
    ],
    [
        "`arrays` is the argument passed to",
        "`arrays` is the argument"
    ],
    [
        "block. `max_depth` is the depth of nested lists within `arrays` and",
        "block. `max_depth` is the depth of"
    ],
    [
        "`result_ndim` is the greatest of the dimensions of the arrays in",
        "`result_ndim` is the greatest of the dimensions of"
    ],
    [
        "`arrays` and the depth of the lists in `arrays` (see block docstring",
        "`arrays` and the depth of the lists in `arrays`"
    ],
    [
        "Assemble an nd-array from nested lists of blocks.",
        "Assemble an nd-array from"
    ],
    [
        "Blocks in the innermost lists are concatenated (see `concatenate`) along",
        "Blocks in the innermost lists are concatenated (see `concatenate`)"
    ],
    [
        "Blocks can be of any dimension, but will not be broadcasted using",
        "Blocks can be of any dimension, but will not"
    ],
    [
        "to make ``block.ndim`` the same for all blocks. This is primarily useful",
        "to make ``block.ndim`` the same for all blocks. This is primarily"
    ],
    [
        "When the nested list is two levels deep, this allows block matrices to be",
        "When the nested list is two levels deep, this allows block"
    ],
    [
        "arrays : nested list of array_like or scalars (but not tuples)",
        "arrays : nested list of array_like or"
    ],
    [
        "is returned unmodified (and not copied).",
        "is returned unmodified (and not"
    ],
    [
        "Elements shapes must match along the appropriate axes (without",
        "Elements shapes must match along the appropriate axes"
    ],
    [
        "necessary to make the dimensions match.",
        "necessary to make the"
    ],
    [
        "The array assembled from the given blocks.",
        "The array assembled from the"
    ],
    [
        "The dimensionality of the output is equal to the greatest of:",
        "The dimensionality of the output is equal"
    ],
    [
        "* the dimensionality of all the inputs",
        "* the dimensionality of all the"
    ],
    [
        "* the depth to which the input list is nested",
        "* the depth to which the"
    ],
    [
        "* If list depths are mismatched - for instance, ``[[a, b], c]`` is",
        "* If list depths are mismatched - for instance,"
    ],
    [
        "illegal, and should be spelt ``[[a, b], [c]]``",
        "illegal, and should be spelt ``[[a, b],"
    ],
    [
        "* If lists are empty - for instance, ``[[a, b], []]``",
        "* If lists are empty - for instance,"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of arrays along an"
    ],
    [
        "stack : Join a sequence of arrays along a new axis.",
        "stack : Join a sequence of arrays along"
    ],
    [
        "vstack : Stack arrays in sequence vertically (row wise).",
        "vstack : Stack arrays in sequence"
    ],
    [
        "hstack : Stack arrays in sequence horizontally (column wise).",
        "hstack : Stack arrays in sequence horizontally"
    ],
    [
        "dstack : Stack arrays in sequence depth wise (along third axis).",
        "dstack : Stack arrays in sequence depth wise (along third"
    ],
    [
        "vsplit : Split an array into multiple sub-arrays vertically (row-wise).",
        "vsplit : Split an array into multiple sub-arrays vertically"
    ],
    [
        "unstack : Split an array into a tuple of sub-arrays along an axis.",
        "unstack : Split an array into a tuple of"
    ],
    [
        "When called with only scalars, ``np.block`` is equivalent to an ndarray",
        "When called with only scalars, ``np.block`` is equivalent to"
    ],
    [
        "This function does not enforce that the blocks lie on a fixed grid.",
        "This function does not enforce that the"
    ],
    [
        "``np.block([[a, b], [c, d]])`` is not restricted to arrays of the form::",
        "``np.block([[a, b], [c, d]])`` is not"
    ],
    [
        "But is also allowed to produce, for some ``a, b, c, d``::",
        "But is also allowed to produce,"
    ],
    [
        "Since concatenation happens along the last axis first, `block` is *not*",
        "Since concatenation happens along the last"
    ],
    [
        "capable of producing the following directly::",
        "capable of producing the following"
    ],
    [
        "Matlab's \"square bracket stacking\", ``[A, B, ...; p, q, ...]``, is",
        "Matlab's \"square bracket stacking\", ``[A, B, ...; p, q, ...]``,"
    ],
    [
        "equivalent to ``np.block([[A, B, ...], [p, q, ...]])``.",
        "equivalent to ``np.block([[A, B,"
    ],
    [
        "The most common use of this function is to build a block matrix:",
        "The most common use of this function is to build a block"
    ],
    [
        "arrays, list_ndim, result_ndim, final_size = _block_setup(arrays)",
        "arrays, list_ndim, result_ndim,"
    ],
    [
        "'List at {} cannot be empty'.format(",
        "'List at {}"
    ],
    [
        "dtype = _nx.result_type(*[arr.dtype for arr in arrays])",
        "dtype = _nx.result_type(*[arr.dtype for arr"
    ],
    [
        "F_order = all(arr.flags['F_CONTIGUOUS'] for arr in arrays)",
        "F_order = all(arr.flags['F_CONTIGUOUS'] for arr"
    ],
    [
        "C_order = all(arr.flags['C_CONTIGUOUS'] for arr in arrays)",
        "C_order = all(arr.flags['C_CONTIGUOUS'] for arr"
    ],
    [
        "order = 'F' if F_order and not C_order else 'C'",
        "order = 'F' if F_order and not C_order"
    ],
    [
        "for the_slice, arr in zip(slices, arrays):",
        "for the_slice, arr"
    ],
    [
        "from . import numerictypes as nt",
        "from . import numerictypes as"
    ],
    [
        "ALLOW_THREADS, BUFSIZE, CLIP, MAXDIMS, MAY_SHARE_BOUNDS, MAY_SHARE_EXACT,",
        "ALLOW_THREADS, BUFSIZE, CLIP, MAXDIMS,"
    ],
    [
        "RAISE, WRAP, arange, array, asarray, asanyarray, ascontiguousarray,",
        "RAISE, WRAP, arange, array, asarray, asanyarray,"
    ],
    [
        "asfortranarray, broadcast, can_cast, concatenate, copyto, dot, dtype,",
        "asfortranarray, broadcast, can_cast, concatenate,"
    ],
    [
        "empty, empty_like, flatiter, frombuffer, from_dlpack, fromfile, fromiter,",
        "empty, empty_like, flatiter, frombuffer, from_dlpack,"
    ],
    [
        "fromstring, inner, lexsort, matmul, may_share_memory, min_scalar_type,",
        "fromstring, inner, lexsort, matmul,"
    ],
    [
        "ndarray, nditer, nested_iters, promote_types, putmask, result_type,",
        "ndarray, nditer, nested_iters, promote_types, putmask,"
    ],
    [
        "shares_memory, vdot, where, zeros, normalize_axis_index, vecdot",
        "shares_memory, vdot, where, zeros, normalize_axis_index,"
    ],
    [
        "from .umath import (multiply, invert, sin, PINF, NAN)",
        "from .umath import (multiply, invert, sin, PINF,"
    ],
    [
        "'newaxis', 'ndarray', 'flatiter', 'nditer', 'nested_iters', 'ufunc',",
        "'newaxis', 'ndarray', 'flatiter', 'nditer',"
    ],
    [
        "'asfortranarray', 'zeros', 'count_nonzero', 'empty', 'broadcast', 'dtype',",
        "'asfortranarray', 'zeros', 'count_nonzero',"
    ],
    [
        "'correlate', 'convolve', 'inner', 'dot', 'outer', 'vdot', 'roll',",
        "'correlate', 'convolve', 'inner', 'dot', 'outer',"
    ],
    [
        "'flatnonzero', 'inf', 'nan', 'False_', 'True_', 'bitwise_not',",
        "'flatnonzero', 'inf', 'nan',"
    ],
    [
        "a, dtype=None, order=None, subok=None, shape=None, *, device=None",
        "a, dtype=None, order=None, subok=None, shape=None,"
    ],
    [
        "a, dtype=None, order='K', subok=True, shape=None, *, device=None",
        "a, dtype=None, order='K', subok=True,"
    ],
    [
        "Return an array of zeros with the same shape and type as a given array.",
        "Return an array of zeros with the same shape and type as"
    ],
    [
        "The shape and data-type of `a` define these same attributes of",
        "The shape and data-type of `a`"
    ],
    [
        "Overrides the data type of the result.",
        "Overrides the data type"
    ],
    [
        "order : {'C', 'F', 'A', or 'K'}, optional",
        "order : {'C', 'F', 'A',"
    ],
    [
        "Overrides the memory layout of the result. 'C' means C-order,",
        "Overrides the memory layout of the"
    ],
    [
        "'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,",
        "'F' means F-order, 'A' means 'F' if"
    ],
    [
        "'C' otherwise. 'K' means match the layout of `a` as closely",
        "'C' otherwise. 'K' means match the layout of `a`"
    ],
    [
        "If True, then the newly created array will use the sub-class",
        "If True, then the newly created array will use"
    ],
    [
        "type of `a`, otherwise it will be a base-class array. Defaults",
        "type of `a`, otherwise it will be a"
    ],
    [
        "shape : int or sequence of ints, optional.",
        "shape : int or sequence of ints,"
    ],
    [
        "Overrides the shape of the result. If order='K' and the number of",
        "Overrides the shape of the result."
    ],
    [
        "dimensions is unchanged, will try to keep order, otherwise,",
        "dimensions is unchanged, will try to keep order,"
    ],
    [
        "The device on which to place the created array. Default: None.",
        "The device on which to place the created"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be"
    ],
    [
        "Array of zeros with the same shape and type as `a`.",
        "Array of zeros with the same shape"
    ],
    [
        "empty_like : Return an empty array with shape and type of input.",
        "empty_like : Return an empty array with"
    ],
    [
        "ones_like : Return an array of ones with shape and type of input.",
        "ones_like : Return an array of ones with shape and type of"
    ],
    [
        "full_like : Return a new array with shape of input filled with value.",
        "full_like : Return a new array with shape"
    ],
    [
        "zeros : Return a new array setting values to zero.",
        "zeros : Return a new array setting values to"
    ],
    [
        "a, dtype=dtype, order=order, subok=subok, shape=shape, device=device",
        "a, dtype=dtype, order=order, subok=subok,"
    ],
    [
        "def ones(shape, dtype=None, order='C', *, device=None, like=None):",
        "def ones(shape, dtype=None, order='C', *,"
    ],
    [
        "Return a new array of given shape and type, filled with ones.",
        "Return a new array of given shape and type, filled"
    ],
    [
        "shape : int or sequence of ints",
        "shape : int or sequence of"
    ],
    [
        "order : {'C', 'F'}, optional, default: C",
        "order : {'C', 'F'}, optional, default:"
    ],
    [
        "Whether to store multi-dimensional data in row-major",
        "Whether to store multi-dimensional data in"
    ],
    [
        "(C-style) or column-major (Fortran-style) order in",
        "(C-style) or column-major"
    ],
    [
        "The device on which to place the created array. Default: None.",
        "The device on which to place the created array. Default:"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be ``\"cpu\"`` if"
    ],
    [
        "Array of ones with the given shape, dtype, and order.",
        "Array of ones with the given shape, dtype, and"
    ],
    [
        "ones_like : Return an array of ones with shape and type of input.",
        "ones_like : Return an array of ones with shape and type"
    ],
    [
        "empty : Return a new uninitialized array.",
        "empty : Return a new uninitialized"
    ],
    [
        "zeros : Return a new array setting values to zero.",
        "zeros : Return a new array"
    ],
    [
        "full : Return a new array of given shape filled with value.",
        "full : Return a new array of given shape filled"
    ],
    [
        "a = empty(shape, dtype, order, device=device)",
        "a = empty(shape,"
    ],
    [
        "a, dtype=None, order=None, subok=None, shape=None, *, device=None",
        "a, dtype=None, order=None, subok=None, shape=None, *,"
    ],
    [
        "a, dtype=None, order='K', subok=True, shape=None, *, device=None",
        "a, dtype=None, order='K', subok=True, shape=None,"
    ],
    [
        "Return an array of ones with the same shape and type as a given array.",
        "Return an array of ones with the same shape and type"
    ],
    [
        "The shape and data-type of `a` define these same attributes of",
        "The shape and data-type of `a` define"
    ],
    [
        "Overrides the data type of the result.",
        "Overrides the data type of the"
    ],
    [
        "order : {'C', 'F', 'A', or 'K'}, optional",
        "order : {'C', 'F', 'A', or 'K'},"
    ],
    [
        "Overrides the memory layout of the result. 'C' means C-order,",
        "Overrides the memory layout of the"
    ],
    [
        "'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,",
        "'F' means F-order, 'A' means 'F'"
    ],
    [
        "'C' otherwise. 'K' means match the layout of `a` as closely",
        "'C' otherwise. 'K' means match the"
    ],
    [
        "If True, then the newly created array will use the sub-class",
        "If True, then the newly created array"
    ],
    [
        "type of `a`, otherwise it will be a base-class array. Defaults",
        "type of `a`, otherwise it will be a"
    ],
    [
        "shape : int or sequence of ints, optional.",
        "shape : int or sequence of ints,"
    ],
    [
        "Overrides the shape of the result. If order='K' and the number of",
        "Overrides the shape of the result. If order='K' and the number"
    ],
    [
        "dimensions is unchanged, will try to keep order, otherwise,",
        "dimensions is unchanged, will try to keep"
    ],
    [
        "The device on which to place the created array. Default: None.",
        "The device on which to place the created array."
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be"
    ],
    [
        "Array of ones with the same shape and type as `a`.",
        "Array of ones with the same"
    ],
    [
        "empty_like : Return an empty array with shape and type of input.",
        "empty_like : Return an empty array with shape"
    ],
    [
        "zeros_like : Return an array of zeros with shape and type of input.",
        "zeros_like : Return an array of zeros"
    ],
    [
        "full_like : Return a new array with shape of input filled with value.",
        "full_like : Return a new array with"
    ],
    [
        "ones : Return a new array setting values to one.",
        "ones : Return a new array setting"
    ],
    [
        "a, dtype=dtype, order=order, subok=subok, shape=shape, device=device",
        "a, dtype=dtype, order=order,"
    ],
    [
        "shape, fill_value, dtype=None, order=None, *, device=None, like=None",
        "shape, fill_value, dtype=None, order=None, *, device=None,"
    ],
    [
        "def full(shape, fill_value, dtype=None, order='C', *, device=None, like=None):",
        "def full(shape, fill_value, dtype=None,"
    ],
    [
        "Return a new array of given shape and type, filled with `fill_value`.",
        "Return a new array of given shape and type,"
    ],
    [
        "shape : int or sequence of ints",
        "shape : int or sequence of"
    ],
    [
        "The desired data-type for the array  The default, None, means",
        "The desired data-type for the"
    ],
    [
        "Whether to store multidimensional data in C- or Fortran-contiguous",
        "Whether to store multidimensional data in C- or"
    ],
    [
        "(row- or column-wise) order in memory.",
        "(row- or column-wise) order in"
    ],
    [
        "The device on which to place the created array. Default: None.",
        "The device on which to place the"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must"
    ],
    [
        "Array of `fill_value` with the given shape, dtype, and order.",
        "Array of `fill_value` with the given shape, dtype,"
    ],
    [
        "full_like : Return a new array with shape of input filled with value.",
        "full_like : Return a new array with"
    ],
    [
        "empty : Return a new uninitialized array.",
        "empty : Return a"
    ],
    [
        "ones : Return a new array setting values to one.",
        "ones : Return a new array setting"
    ],
    [
        "zeros : Return a new array setting values to zero.",
        "zeros : Return a new array setting values to"
    ],
    [
        "like, shape, fill_value, dtype=dtype, order=order, device=device",
        "like, shape, fill_value, dtype=dtype,"
    ],
    [
        "a = empty(shape, dtype, order, device=device)",
        "a = empty(shape,"
    ],
    [
        "a, fill_value, dtype=None, order=None, subok=None, shape=None,",
        "a, fill_value, dtype=None, order=None,"
    ],
    [
        "a, fill_value, dtype=None, order='K', subok=True, shape=None,",
        "a, fill_value, dtype=None, order='K',"
    ],
    [
        "Return a full array with the same shape and type as a given array.",
        "Return a full array with the same shape and type as a"
    ],
    [
        "The shape and data-type of `a` define these same attributes of",
        "The shape and data-type of `a` define these same"
    ],
    [
        "Overrides the data type of the result.",
        "Overrides the data type of the"
    ],
    [
        "order : {'C', 'F', 'A', or 'K'}, optional",
        "order : {'C', 'F', 'A', or"
    ],
    [
        "Overrides the memory layout of the result. 'C' means C-order,",
        "Overrides the memory layout of the result. 'C'"
    ],
    [
        "'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,",
        "'F' means F-order, 'A' means 'F' if"
    ],
    [
        "'C' otherwise. 'K' means match the layout of `a` as closely",
        "'C' otherwise. 'K' means match the layout of `a`"
    ],
    [
        "If True, then the newly created array will use the sub-class",
        "If True, then the newly created"
    ],
    [
        "type of `a`, otherwise it will be a base-class array. Defaults",
        "type of `a`, otherwise it will be a base-class"
    ],
    [
        "shape : int or sequence of ints, optional.",
        "shape : int or"
    ],
    [
        "Overrides the shape of the result. If order='K' and the number of",
        "Overrides the shape of the result. If order='K' and"
    ],
    [
        "dimensions is unchanged, will try to keep order, otherwise,",
        "dimensions is unchanged, will try to keep order,"
    ],
    [
        "The device on which to place the created array. Default: None.",
        "The device on which to place"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be ``\"cpu\"``"
    ],
    [
        "Array of `fill_value` with the same shape and type as `a`.",
        "Array of `fill_value` with the same"
    ],
    [
        "empty_like : Return an empty array with shape and type of input.",
        "empty_like : Return an empty array"
    ],
    [
        "ones_like : Return an array of ones with shape and type of input.",
        "ones_like : Return an array of ones with shape and"
    ],
    [
        "zeros_like : Return an array of zeros with shape and type of input.",
        "zeros_like : Return an array of zeros with shape"
    ],
    [
        "full : Return a new array of given shape filled with value.",
        "full : Return a new array of given shape filled with"
    ],
    [
        "array([nan, nan, nan, nan, nan, nan])",
        "array([nan, nan, nan,"
    ],
    [
        "a, dtype=dtype, order=order, subok=subok, shape=shape, device=device",
        "a, dtype=dtype, order=order, subok=subok,"
    ],
    [
        "Counts the number of non-zero values in the array ``a``.",
        "Counts the number of non-zero values in the"
    ],
    [
        "\"truthfulness\". For example, any number is considered",
        "\"truthfulness\". For example, any number"
    ],
    [
        "truthful if it is nonzero, whereas any string is considered",
        "truthful if it is nonzero, whereas any"
    ],
    [
        "truthful if it is not the empty string. Thus, this function",
        "truthful if it is not the"
    ],
    [
        "(recursively) counts how many elements in ``a`` (and in",
        "(recursively) counts how many elements in ``a``"
    ],
    [
        "sub-arrays thereof) have their ``__nonzero__()`` or ``__bool__()``",
        "sub-arrays thereof) have their"
    ],
    [
        "The array for which to count non-zeros.",
        "The array for which to"
    ],
    [
        "axis : int or tuple, optional",
        "axis : int or tuple,"
    ],
    [
        "Axis or tuple of axes along which to count non-zeros.",
        "Axis or tuple of axes along which"
    ],
    [
        "Default is None, meaning that non-zeros will be counted",
        "Default is None, meaning that non-zeros"
    ],
    [
        "along a flattened version of ``a``.",
        "along a flattened version"
    ],
    [
        "If this is set to True, the axes that are counted are left",
        "If this is set to True, the"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size"
    ],
    [
        "the result will broadcast correctly against the input array.",
        "the result will broadcast correctly against the input"
    ],
    [
        "count : int or array of int",
        "count : int or"
    ],
    [
        "Number of non-zero values in the array along a given axis.",
        "Number of non-zero values in the array"
    ],
    [
        "Otherwise, the total number of non-zero values in the array",
        "Otherwise, the total number of non-zero values in the"
    ],
    [
        "nonzero : Return the coordinates of all the non-zero values.",
        "nonzero : Return the coordinates of"
    ],
    [
        "if axis is None and not keepdims:",
        "if axis is None"
    ],
    [
        "Check if the array is Fortran contiguous but *not* C contiguous.",
        "Check if the array is Fortran contiguous"
    ],
    [
        "This function is obsolete. If you only want to check if an array is Fortran",
        "This function is obsolete. If you only want to"
    ],
    [
        "Returns True if the array is Fortran contiguous but *not* C contiguous.",
        "Returns True if the array is"
    ],
    [
        "np.array allows to specify whether the array is written in C-contiguous",
        "np.array allows to specify whether the array is"
    ],
    [
        "order (last index varies the fastest), or FORTRAN-contiguous order in",
        "order (last index varies the fastest), or FORTRAN-contiguous order"
    ],
    [
        "memory (first index varies the fastest).",
        "memory (first index varies"
    ],
    [
        "The transpose of a C-ordered array is a FORTRAN-ordered array.",
        "The transpose of a C-ordered array"
    ],
    [
        "C-ordered arrays evaluate as False even if they are also FORTRAN-ordered.",
        "C-ordered arrays evaluate as False even if they"
    ],
    [
        "Find the indices of array elements that are non-zero, grouped by element.",
        "Find the indices of array elements that are non-zero, grouped"
    ],
    [
        "Indices of elements that are non-zero. Indices are grouped by element.",
        "Indices of elements that are non-zero. Indices are grouped by"
    ],
    [
        "This array will have shape ``(N, a.ndim)`` where ``N`` is the number of",
        "This array will have shape ``(N, a.ndim)`` where ``N`` is the number"
    ],
    [
        "``np.argwhere(a)`` is almost the same as ``np.transpose(np.nonzero(a))``,",
        "``np.argwhere(a)`` is almost the same as"
    ],
    [
        "The output of ``argwhere`` is not suitable for indexing arrays.",
        "The output of ``argwhere`` is not suitable for"
    ],
    [
        "For this purpose use ``nonzero(a)`` instead.",
        "For this purpose"
    ],
    [
        "Return indices that are non-zero in the flattened version of a.",
        "Return indices that are non-zero in"
    ],
    [
        "Output array, containing the indices of the elements of ``a.ravel()``",
        "Output array, containing the indices of the elements"
    ],
    [
        "nonzero : Return the indices of the non-zero elements of the input array.",
        "nonzero : Return the indices of the non-zero"
    ],
    [
        "Use the indices of the non-zero elements as an index array to extract",
        "Use the indices of the non-zero elements"
    ],
    [
        "This function computes the correlation as generally defined in signal",
        "This function computes the correlation as generally defined in"
    ],
    [
        ".. math:: c_k = \\sum_n a_{n+k} \\cdot \\overline{v}_n",
        ".. math:: c_k = \\sum_n a_{n+k}"
    ],
    [
        "with a and v sequences being zero-padded where necessary and",
        "with a and v sequences being"
    ],
    [
        "mode : {'valid', 'same', 'full'}, optional",
        "mode : {'valid', 'same',"
    ],
    [
        "Refer to the `convolve` docstring.  Note that the default",
        "Refer to the `convolve` docstring."
    ],
    [
        "is 'valid', unlike `convolve`, which uses 'full'.",
        "is 'valid', unlike `convolve`, which"
    ],
    [
        "Discrete cross-correlation of `a` and `v`.",
        "Discrete cross-correlation of `a`"
    ],
    [
        "convolve : Discrete, linear convolution of two one-dimensional sequences.",
        "convolve : Discrete, linear convolution"
    ],
    [
        "scipy.signal.correlate : uses FFT which has superior performance",
        "scipy.signal.correlate : uses FFT"
    ],
    [
        "The definition of correlation above is not unique and sometimes",
        "The definition of correlation above is not unique"
    ],
    [
        ".. math:: c'_k = \\sum_n a_{n} \\cdot \\overline{v_{n+k}}",
        ".. math:: c'_k = \\sum_n a_{n}"
    ],
    [
        "which is related to :math:`c_k` by :math:`c'_k = c_{-k}`.",
        "which is related to :math:`c_k` by :math:`c'_k"
    ],
    [
        "because it does not use the FFT to compute the convolution; in that case,",
        "because it does not use the FFT to"
    ],
    [
        "Note that you get the time reversed, complex conjugated result",
        "Note that you get the time reversed, complex"
    ],
    [
        "(:math:`\\overline{c_{-k}}`) when the two input sequences a and v change",
        "(:math:`\\overline{c_{-k}}`) when the two input sequences a"
    ],
    [
        "Returns the discrete, linear convolution of two one-dimensional sequences.",
        "Returns the discrete, linear convolution of two one-dimensional"
    ],
    [
        "The convolution operator is often seen in signal processing, where it",
        "The convolution operator is often seen in"
    ],
    [
        "probability theory, the sum of two independent random variables is",
        "probability theory, the sum of two"
    ],
    [
        "distributed according to the convolution of their individual",
        "distributed according to the convolution of their"
    ],
    [
        "If `v` is longer than `a`, the arrays are swapped before computation.",
        "If `v` is longer than `a`, the"
    ],
    [
        "mode : {'full', 'valid', 'same'}, optional",
        "mode : {'full', 'valid',"
    ],
    [
        "By default, mode is 'full'.  This returns the convolution",
        "By default, mode is 'full'. This returns"
    ],
    [
        "the end-points of the convolution, the signals do not overlap",
        "the end-points of the convolution, the signals"
    ],
    [
        "completely, and boundary effects may be seen.",
        "completely, and boundary effects may"
    ],
    [
        "Mode 'same' returns output of length ``max(M, N)``.  Boundary",
        "Mode 'same' returns output of length ``max(M, N)``."
    ],
    [
        "Mode 'valid' returns output of length",
        "Mode 'valid' returns"
    ],
    [
        "for points where the signals overlap completely.  Values outside",
        "for points where the signals overlap completely. Values"
    ],
    [
        "the signal boundary have no effect.",
        "the signal boundary have"
    ],
    [
        "Discrete, linear convolution of `a` and `v`.",
        "Discrete, linear convolution of `a` and"
    ],
    [
        "scipy.signal.fftconvolve : Convolve two arrays using the Fast Fourier",
        "scipy.signal.fftconvolve : Convolve two arrays"
    ],
    [
        "scipy.linalg.toeplitz : Used to construct the convolution operator.",
        "scipy.linalg.toeplitz : Used to construct the convolution"
    ],
    [
        "polymul : Polynomial multiplication. Same output as convolve, but also",
        "polymul : Polynomial multiplication. Same output as"
    ],
    [
        "The discrete convolution operation is defined as",
        "The discrete convolution operation is"
    ],
    [
        ".. math:: (a * v)_n = \\\\sum_{m = -\\\\infty}^{\\\\infty} a_m v_{n - m}",
        ".. math:: (a * v)_n = \\\\sum_{m = -\\\\infty}^{\\\\infty} a_m v_{n"
    ],
    [
        "It can be shown that a convolution :math:`x(t) * y(t)` in time/space",
        "It can be shown that a convolution :math:`x(t) * y(t)` in"
    ],
    [
        "is equivalent to the multiplication :math:`X(f) Y(f)` in the Fourier",
        "is equivalent to the multiplication"
    ],
    [
        "domain, after appropriate padding (padding is necessary to prevent",
        "domain, after appropriate padding (padding is necessary"
    ],
    [
        "circular convolution).  Since multiplication is more efficient (faster)",
        "circular convolution). Since multiplication is more efficient"
    ],
    [
        "than convolution, the function `scipy.signal.fftconvolve` exploits the",
        "than convolution, the function `scipy.signal.fftconvolve`"
    ],
    [
        "FFT to calculate the convolution of large data-sets.",
        "FFT to calculate the convolution of large"
    ],
    [
        "Note how the convolution operator flips the second array",
        "Note how the convolution operator flips the"
    ],
    [
        "before \"sliding\" the two across one another:",
        "before \"sliding\" the two across one"
    ],
    [
        "Only return the middle values of the convolution.",
        "Only return the middle values of the"
    ],
    [
        "Contains boundary effects, where zeros are taken",
        "Contains boundary effects, where zeros"
    ],
    [
        "The two arrays are of the same length, so there",
        "The two arrays are of the"
    ],
    [
        "is only one position where they completely overlap:",
        "is only one position where"
    ],
    [
        "Compute the outer product of two vectors.",
        "Compute the outer product of two"
    ],
    [
        "Given two vectors `a` and `b` of length ``M`` and ``N``, respectively,",
        "Given two vectors `a` and `b`"
    ],
    [
        "First input vector.  Input is flattened if",
        "First input vector. Input is"
    ],
    [
        "Second input vector.  Input is flattened if",
        "Second input vector. Input is"
    ],
    [
        "out : (M, N) ndarray, optional",
        "out : (M, N)"
    ],
    [
        "A location where the result is stored",
        "A location where the result is"
    ],
    [
        "``out[i, j] = a[i] * b[j]``",
        "``out[i, j] ="
    ],
    [
        "einsum : ``einsum('i,j->ij', a.ravel(), b.ravel())`` is the equivalent.",
        "einsum : ``einsum('i,j->ij', a.ravel(),"
    ],
    [
        "linalg.outer : An Array API compatible variation of ``np.outer``,",
        "linalg.outer : An Array API"
    ],
    [
        "tensordot : ``np.tensordot(a.ravel(), b.ravel(), axes=((), ()))``",
        "tensordot : ``np.tensordot(a.ravel(),"
    ],
    [
        "Make a (*very* coarse) grid for computing a Mandelbrot set:",
        "Make a (*very* coarse) grid"
    ],
    [
        ">>> grid = rl + im",
        ">>> grid = rl +"
    ],
    [
        "An example using a \"vector\" of letters:",
        "An example using a"
    ],
    [
        ">>> x = np.array(['a', 'b', 'c'], dtype=object)",
        ">>> x = np.array(['a', 'b',"
    ],
    [
        "return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis, :], out)",
        "return multiply(a.ravel()[:, newaxis],"
    ],
    [
        "Compute tensor dot product along specified axes.",
        "Compute tensor dot product"
    ],
    [
        "Given two tensors, `a` and `b`, and an array_like object containing",
        "Given two tensors, `a` and `b`,"
    ],
    [
        "two array_like objects, ``(a_axes, b_axes)``, sum the products of",
        "two array_like objects, ``(a_axes, b_axes)``, sum the products"
    ],
    [
        "`a`'s and `b`'s elements (components) over the axes specified by",
        "`a`'s and `b`'s elements (components) over the axes"
    ],
    [
        "``a_axes`` and ``b_axes``. The third argument can be a single non-negative",
        "``a_axes`` and ``b_axes``. The third argument can be"
    ],
    [
        "integer_like scalar, ``N``; if it is such, then the last ``N`` dimensions",
        "integer_like scalar, ``N``; if it is such,"
    ],
    [
        "of `a` and the first ``N`` dimensions of `b` are summed over.",
        "of `a` and the first ``N`` dimensions of"
    ],
    [
        "If an int N, sum over the last N axes of `a` and the first N axes",
        "If an int N, sum over the last N axes of `a` and the"
    ],
    [
        "of `b` in order. The sizes of the corresponding axes must match.",
        "of `b` in order. The sizes"
    ],
    [
        "Or, a list of axes to be summed over, first sequence applying to `a`,",
        "Or, a list of axes to be summed over, first"
    ],
    [
        "second to `b`. Both elements array_like must be of the same length.",
        "second to `b`. Both elements array_like must"
    ],
    [
        "The tensor dot product of the input.",
        "The tensor dot product of the"
    ],
    [
        "When `axes` is integer_like, the sequence of axes for evaluation",
        "When `axes` is integer_like, the"
    ],
    [
        "the element of `a` and `b` are defined as the `axes`.",
        "the element of `a` and `b` are"
    ],
    [
        "When there is more than one axis to sum over - and they are not the last",
        "When there is more than one axis to sum over - and they are not the"
    ],
    [
        "(first) axes of `a` (`b`) - the argument `axes` should consist of",
        "(first) axes of `a` (`b`) - the argument `axes`"
    ],
    [
        "two sequences of the same length, with the first axis to sum over given",
        "two sequences of the same length, with"
    ],
    [
        "first in both sequences, the second axis second, and so forth.",
        "first in both sequences, the second"
    ],
    [
        "The calculation can be referred to ``numpy.einsum``.",
        "The calculation can be referred"
    ],
    [
        "The shape of the result consists of the non-contracted axes of the",
        "The shape of the result consists of the non-contracted axes of"
    ],
    [
        "first tensor, followed by the non-contracted axes of the second.",
        "first tensor, followed by the"
    ],
    [
        "A slower but equivalent way of computing the same...",
        "A slower but equivalent way of computing"
    ],
    [
        "...         d[i,j] += a[k,n,i] * b[n,k,j]",
        "... d[i,j] += a[k,n,i] *"
    ],
    [
        "An extended example taking advantage of the overloading of + and \\\\*:",
        "An extended example taking advantage of"
    ],
    [
        ">>> A = np.array(('a', 'b', 'c', 'd'), dtype=object)",
        ">>> A = np.array(('a', 'b', 'c',"
    ],
    [
        "notin = [k for k in range(nda) if k not in axes_a]",
        "notin = [k for k in range(nda) if k"
    ],
    [
        "olda = [as_[axis] for axis in notin]",
        "olda = [as_[axis] for axis in"
    ],
    [
        "notin = [k for k in range(ndb) if k not in axes_b]",
        "notin = [k for k in range(ndb) if k"
    ],
    [
        "oldb = [bs[axis] for axis in notin]",
        "oldb = [bs[axis] for"
    ],
    [
        "Roll array elements along a given axis.",
        "Roll array elements along a given"
    ],
    [
        "Elements that roll beyond the last position are re-introduced at",
        "Elements that roll beyond the last position"
    ],
    [
        "shift : int or tuple of ints",
        "shift : int or"
    ],
    [
        "The number of places by which elements are shifted.  If a tuple,",
        "The number of places by which elements are shifted."
    ],
    [
        "then `axis` must be a tuple of the same size, and each of the",
        "then `axis` must be a tuple of the same size, and each of"
    ],
    [
        "given axes is shifted by the corresponding number.  If an int",
        "given axes is shifted by the corresponding number. If"
    ],
    [
        "while `axis` is a tuple of ints, then the same value is used for",
        "while `axis` is a tuple of ints, then"
    ],
    [
        "axis : int or tuple of ints, optional",
        "axis : int or tuple of ints,"
    ],
    [
        "Axis or axes along which elements are shifted.  By default, the",
        "Axis or axes along which elements are shifted. By"
    ],
    [
        "array is flattened before shifting, after which the original",
        "array is flattened before shifting, after which"
    ],
    [
        "Output array, with the same shape as `a`.",
        "Output array, with the same shape"
    ],
    [
        "rollaxis : Roll the specified axis backwards, until it lies in a",
        "rollaxis : Roll the specified axis backwards, until it lies in"
    ],
    [
        "Supports rolling over multiple dimensions simultaneously.",
        "Supports rolling over"
    ],
    [
        "rolls = [((slice(None), slice(None)),)] * a.ndim",
        "rolls = [((slice(None), slice(None)),)] *"
    ],
    [
        "rolls[ax] = ((slice(None, -offset), slice(offset, None)),",
        "rolls[ax] = ((slice(None, -offset), slice(offset,"
    ],
    [
        "Roll the specified axis backwards, until it lies in a given position.",
        "Roll the specified axis backwards, until"
    ],
    [
        "This function continues to be supported for backward compatibility, but you",
        "This function continues to be supported for backward compatibility, but"
    ],
    [
        "should prefer `moveaxis`. The `moveaxis` function was added in NumPy",
        "should prefer `moveaxis`. The `moveaxis` function"
    ],
    [
        "The axis to be rolled. The positions of the other axes do not",
        "The axis to be rolled. The positions of"
    ],
    [
        "When ``start <= axis``, the axis is rolled back until it lies in",
        "When ``start <= axis``, the axis is rolled back until it"
    ],
    [
        "this position. When ``start > axis``, the axis is rolled until it",
        "this position. When ``start > axis``, the axis is rolled"
    ],
    [
        "roll. The following table describes how negative values of ``start``",
        "roll. The following table describes how negative"
    ],
    [
        "|     ``start``     | Normalized ``start`` |",
        "| ``start`` | Normalized ``start``"
    ],
    [
        "NumPy versions a view of `a` is returned only if the order of the",
        "NumPy versions a view of `a` is returned only"
    ],
    [
        "axes is changed, otherwise the input array is returned.",
        "axes is changed, otherwise the"
    ],
    [
        "moveaxis : Move array axes to new positions.",
        "moveaxis : Move array"
    ],
    [
        "roll : Roll the elements of an array by a number of positions along a",
        "roll : Roll the elements of an array by a number"
    ],
    [
        "msg = \"'%s' arg requires %d <= %s < %d, but %d was passed in\"",
        "msg = \"'%s' arg requires %d <= %s"
    ],
    [
        "Normalizes an axis argument into a tuple of non-negative integer axes.",
        "Normalizes an axis argument into a"
    ],
    [
        "as well as performing the handling of negative indices covered by",
        "as well as performing the handling of negative indices covered"
    ],
    [
        "By default, this forbids axes from being specified multiple times.",
        "By default, this forbids axes from"
    ],
    [
        "axis : int, iterable of int",
        "axis : int,"
    ],
    [
        "The un-normalized index or indices of the axis.",
        "The un-normalized index or indices of"
    ],
    [
        "The number of dimensions of the array that `axis` should be normalized",
        "The number of dimensions of the array that `axis` should"
    ],
    [
        "A prefix to put before the error message, typically the name of the",
        "A prefix to put before the error message, typically the"
    ],
    [
        "If False, the default, disallow an axis from being specified twice.",
        "If False, the default, disallow an axis from being"
    ],
    [
        "If any axis provided is out of range",
        "If any axis provided is"
    ],
    [
        "normalize_axis_index : normalizing a single scalar axis",
        "normalize_axis_index : normalizing a"
    ],
    [
        "if type(axis) not in (tuple, list):",
        "if type(axis) not in"
    ],
    [
        "axis = tuple(normalize_axis_index(ax, ndim, argname) for ax in axis)",
        "axis = tuple(normalize_axis_index(ax, ndim, argname) for"
    ],
    [
        "if not allow_duplicate and len(set(axis)) != len(axis):",
        "if not allow_duplicate and len(set(axis))"
    ],
    [
        "raise ValueError('repeated axis in `{}` argument'.format(argname))",
        "raise ValueError('repeated axis in `{}`"
    ],
    [
        "Move axes of an array to new positions.",
        "Move axes of an array to"
    ],
    [
        "Other axes remain in their original order.",
        "Other axes remain in"
    ],
    [
        "The array whose axes should be reordered.",
        "The array whose axes should be"
    ],
    [
        "source : int or sequence of int",
        "source : int or sequence of"
    ],
    [
        "Original positions of the axes to move. These must be unique.",
        "Original positions of the axes to"
    ],
    [
        "destination : int or sequence of int",
        "destination : int or sequence of"
    ],
    [
        "Destination positions for each of the original axes. These must also be",
        "Destination positions for each of the original axes. These"
    ],
    [
        "Array with moved axes. This array is a view of the input array.",
        "Array with moved axes. This array is a view of the"
    ],
    [
        "transpose : Permute the dimensions of an array.",
        "transpose : Permute the dimensions of"
    ],
    [
        "swapaxes : Interchange two axes of an array.",
        "swapaxes : Interchange two axes"
    ],
    [
        "These all achieve the same result:",
        "These all achieve the"
    ],
    [
        "raise ValueError('`source` and `destination` arguments must have '",
        "raise ValueError('`source` and `destination` arguments must"
    ],
    [
        "order = [n for n in range(a.ndim) if n not in source]",
        "order = [n for n in range(a.ndim) if n"
    ],
    [
        "for dest, src in sorted(zip(destination, source)):",
        "for dest, src"
    ],
    [
        "def _cross_dispatcher(a, b, axisa=None, axisb=None, axisc=None, axis=None):",
        "def _cross_dispatcher(a, b, axisa=None, axisb=None,"
    ],
    [
        "Return the cross product of two (arrays of) vectors.",
        "Return the cross product of two"
    ],
    [
        "to both `a` and `b`.  If `a` and `b` are arrays of vectors, the vectors",
        "to both `a` and `b`. If `a` and `b` are arrays of vectors,"
    ],
    [
        "are defined by the last axis of `a` and `b` by default, and these axes",
        "are defined by the last axis of `a` and `b` by"
    ],
    [
        "cross product calculated accordingly.  In cases where both input vectors",
        "cross product calculated accordingly. In"
    ],
    [
        "Axis of `a` that defines the vector(s).  By default, the last axis.",
        "Axis of `a` that defines the"
    ],
    [
        "Axis of `b` that defines the vector(s).  By default, the last axis.",
        "Axis of `b` that defines the vector(s)."
    ],
    [
        "Axis of `c` containing the cross product vector(s).  Ignored if",
        "Axis of `c` containing the cross product vector(s)."
    ],
    [
        "If defined, the axis of `a`, `b` and `c` that defines the vector(s)",
        "If defined, the axis of `a`, `b` and `c` that"
    ],
    [
        "and cross product(s).  Overrides `axisa`, `axisb` and `axisc`.",
        "and cross product(s). Overrides `axisa`, `axisb` and"
    ],
    [
        "When the dimension of the vector(s) in `a` and/or `b` does not",
        "When the dimension of the vector(s) in `a` and/or `b`"
    ],
    [
        "linalg.cross : An Array API compatible variation of ``np.cross``,",
        "linalg.cross : An Array API compatible variation of"
    ],
    [
        "Supports full broadcasting of the inputs.",
        "Supports full broadcasting"
    ],
    [
        "Multiple vector cross-products. Note that the direction of the cross",
        "Multiple vector cross-products. Note that the direction"
    ],
    [
        "product vector is defined by the *right-hand rule*.",
        "product vector is defined by the *right-hand"
    ],
    [
        "The orientation of `c` can be changed using the `axisc` keyword.",
        "The orientation of `c` can be changed using the `axisc`"
    ],
    [
        "Change the vector definition of `x` and `y` using `axisa` and `axisb`.",
        "Change the vector definition of `x`"
    ],
    [
        "raise ValueError(\"At least one array has zero dimension\")",
        "raise ValueError(\"At least one array"
    ],
    [
        "msg = (\"incompatible dimensions for cross product\\n\"",
        "msg = (\"incompatible dimensions for cross"
    ],
    [
        "Return an array representing the indices of a grid.",
        "Return an array representing the indices of a"
    ],
    [
        "varying only along the corresponding axis.",
        "varying only along"
    ],
    [
        "Return a sparse representation of the grid instead of a dense",
        "Return a sparse representation of the"
    ],
    [
        "grid : one ndarray or tuple of ndarrays",
        "grid : one ndarray"
    ],
    [
        "Returns one array of grid indices,",
        "Returns one array of grid"
    ],
    [
        "Returns a tuple of arrays, with",
        "Returns a tuple of arrays,"
    ],
    [
        "The output shape in the dense case is obtained by prepending the number",
        "The output shape in the dense case is obtained by prepending"
    ],
    [
        "of dimensions in front of the tuple of dimensions, i.e. if `dimensions`",
        "of dimensions in front of the tuple"
    ],
    [
        "The subarrays ``grid[k]`` contains the N-D array of indices along the",
        "The subarrays ``grid[k]`` contains the N-D array of indices"
    ],
    [
        "The indices can be used as an index into an array.",
        "The indices can be used as an index"
    ],
    [
        "Note that it would be more straightforward in the above example to",
        "Note that it would be more straightforward in the above example"
    ],
    [
        "If sparse is set to true, the grid will be returned in a sparse",
        "If sparse is set to true, the grid"
    ],
    [
        "res = empty((N,) + dimensions, dtype=dtype)",
        "res = empty((N,) +"
    ],
    [
        "def fromfunction(function, shape, *, dtype=float, like=None, **kwargs):",
        "def fromfunction(function, shape, *, dtype=float, like=None,"
    ],
    [
        "Construct an array by executing a function over each coordinate.",
        "Construct an array by executing a function"
    ],
    [
        "The resulting array therefore has a value ``fn(x, y, z)`` at",
        "The resulting array therefore has a value"
    ],
    [
        "The function is called with N parameters, where N is the rank of",
        "The function is called with N parameters, where N"
    ],
    [
        "`shape`.  Each parameter represents the coordinates of the array",
        "`shape`. Each parameter represents the coordinates"
    ],
    [
        "varying along a specific axis.  For example, if `shape`",
        "varying along a specific axis. For"
    ],
    [
        "shape : (N,) tuple of ints",
        "shape : (N,) tuple of"
    ],
    [
        "Shape of the output array, which also determines the shape of",
        "Shape of the output array, which also determines the"
    ],
    [
        "the coordinate arrays passed to `function`.",
        "the coordinate arrays passed"
    ],
    [
        "Data-type of the coordinate arrays passed to `function`.",
        "Data-type of the coordinate arrays passed"
    ],
    [
        "The result of the call to `function` is passed back directly.",
        "The result of the call to `function` is passed"
    ],
    [
        "Therefore the shape of `fromfunction` is completely determined by",
        "Therefore the shape of `fromfunction` is completely determined"
    ],
    [
        "`function`.  If `function` returns a scalar value, the shape of",
        "`function`. If `function` returns a"
    ],
    [
        "`fromfunction` would not match the `shape` parameter.",
        "`fromfunction` would not match"
    ],
    [
        "Keywords other than `dtype` and `like` are passed to `function`.",
        "Keywords other than `dtype` and `like` are"
    ],
    [
        "Returns True if the type of `element` is a scalar type.",
        "Returns True if the type of"
    ],
    [
        "Input argument, can be of any type and shape.",
        "Input argument, can be of any"
    ],
    [
        "True if `element` is a scalar type, False if it is not.",
        "True if `element` is a scalar type, False if"
    ],
    [
        "ndim : Get the number of dimensions of an array",
        "ndim : Get the number of dimensions of"
    ],
    [
        "If you need a stricter way to identify a *numerical* scalar, use",
        "If you need a stricter way to identify"
    ],
    [
        "``isinstance(x, numbers.Number)``, as that returns ``False`` for most",
        "``isinstance(x, numbers.Number)``, as that returns ``False``"
    ],
    [
        "functions in the style of the ``dx`` arguments to `gradient` and",
        "functions in the style of the ``dx`` arguments"
    ],
    [
        "the ``bins`` argument to `histogram`. Some key differences:",
        "the ``bins`` argument to `histogram`."
    ],
    [
        "| (including builtins)               |               |                   |",
        "| (including builtins) |"
    ],
    [
        "| builtin string and buffer objects  | ``True``      | ``True``          |",
        "| builtin string and buffer objects |"
    ],
    [
        "| other builtin objects, like        | ``False``     | ``True``          |",
        "| other builtin objects, like | ``False``"
    ],
    [
        "| `pathlib.Path`, `Exception`,       |               |                   |",
        "| `pathlib.Path`, `Exception`, |"
    ],
    [
        "| the result of `re.compile`         |               |                   |",
        "| the result of `re.compile` |"
    ],
    [
        "| third-party objects like           | ``False``     | ``True``          |",
        "| third-party objects like | ``False``"
    ],
    [
        "| zero-dimensional numpy arrays      | ``False``     | ``True``          |",
        "| zero-dimensional numpy arrays | ``False``"
    ],
    [
        "| other numpy arrays                 | ``False``     | ``False``         |",
        "| other numpy arrays | ``False`` | ``False``"
    ],
    [
        "| `list`, `tuple`, and other         | ``False``     | ``False``         |",
        "| `list`, `tuple`, and other"
    ],
    [
        "| sequence objects                   |               |                   |",
        "| sequence objects"
    ],
    [
        "Return the binary representation of the input number as a string.",
        "Return the binary representation of the input"
    ],
    [
        "For negative numbers, if width is not given, a minus sign is added to the",
        "For negative numbers, if width is not given, a minus sign is added to"
    ],
    [
        "front. If width is given, the two's complement of the number is",
        "front. If width is given, the two's complement"
    ],
    [
        "returned, with respect to that width.",
        "returned, with respect to that"
    ],
    [
        "In a two's-complement system negative numbers are represented by the two's",
        "In a two's-complement system negative numbers are represented by the"
    ],
    [
        "complement of the absolute value. This is the most common method of",
        "complement of the absolute value. This is the most common"
    ],
    [
        "system can represent every integer in the range",
        "system can represent every integer in"
    ],
    [
        "Only an integer decimal number can be used.",
        "Only an integer decimal number"
    ],
    [
        "The length of the returned string if `num` is positive, or the length",
        "The length of the returned string if `num` is positive, or the"
    ],
    [
        "of the two's complement if `num` is negative, provided that `width` is",
        "of the two's complement if `num` is negative, provided that `width`"
    ],
    [
        "at least a sufficient number of bits for `num` to be represented in",
        "at least a sufficient number of bits for `num` to be"
    ],
    [
        "the designated form. If the `width` value is insufficient, an error is",
        "the designated form. If the `width` value is"
    ],
    [
        "Binary representation of `num` or two's complement of `num`.",
        "Binary representation of `num` or two's complement of"
    ],
    [
        "base_repr: Return a string representation of a number in the given base",
        "base_repr: Return a string representation of a number in the given"
    ],
    [
        "bin: Python's built-in binary representation generator of an integer.",
        "bin: Python's built-in binary representation generator"
    ],
    [
        "The two's complement is returned when the input number is negative and",
        "The two's complement is returned when the input"
    ],
    [
        "if width is not None and width < binwidth:",
        "if width is not None"
    ],
    [
        "f\"Insufficient bit {width=} provided for {binwidth=}\"",
        "f\"Insufficient bit {width=} provided"
    ],
    [
        "outwidth = (binwidth if width is None",
        "outwidth = (binwidth if width is"
    ],
    [
        "Return a string representation of a number in the given base system.",
        "Return a string representation of a number in the given base"
    ],
    [
        "The value to convert. Positive and negative values are handled.",
        "The value to convert. Positive and negative values"
    ],
    [
        "String representation of `number` in `base` system.",
        "String representation of `number` in"
    ],
    [
        "The identity array is a square array with ones on",
        "The identity array is a"
    ],
    [
        "Number of rows (and columns) in `n` x `n` output.",
        "Number of rows (and columns) in `n`"
    ],
    [
        "Data-type of the output.  Defaults to ``float``.",
        "Data-type of the output. Defaults"
    ],
    [
        "`n` x `n` array with its main diagonal set to one,",
        "`n` x `n` array with its main diagonal set"
    ],
    [
        "def _allclose_dispatcher(a, b, rtol=None, atol=None, equal_nan=None):",
        "def _allclose_dispatcher(a, b, rtol=None,"
    ],
    [
        "Returns True if two arrays are element-wise equal within a tolerance.",
        "Returns True if two arrays are element-wise equal within a"
    ],
    [
        "The tolerance values are positive, typically very small numbers.  The",
        "The tolerance values are positive, typically very small numbers."
    ],
    [
        "relative difference (`rtol` * abs(`b`)) and the absolute difference",
        "relative difference (`rtol` * abs(`b`)) and the absolute"
    ],
    [
        "`atol` are added together to compare against the absolute difference",
        "`atol` are added together to compare against the absolute"
    ],
    [
        ".. warning:: The default `atol` is not appropriate for comparing numbers",
        ".. warning:: The default `atol` is"
    ],
    [
        "with magnitudes much smaller than one (see Notes).",
        "with magnitudes much smaller than one (see"
    ],
    [
        "NaNs are treated as equal if they are in the same place and if",
        "NaNs are treated as equal if they are in the same place"
    ],
    [
        "``equal_nan=True``.  Infs are treated as equal if they are in the same",
        "``equal_nan=True``. Infs are treated as equal if they are in"
    ],
    [
        "place and of the same sign in both arrays.",
        "place and of the same sign in"
    ],
    [
        "The relative tolerance parameter (see Notes).",
        "The relative tolerance parameter (see"
    ],
    [
        "The absolute tolerance parameter (see Notes).",
        "The absolute tolerance parameter"
    ],
    [
        "Whether to compare NaN's as equal.  If True, NaN's in `a` will be",
        "Whether to compare NaN's as equal. If"
    ],
    [
        "considered equal to NaN's in `b` in the output array.",
        "considered equal to NaN's in `b` in"
    ],
    [
        "Returns True if the two arrays are equal within the given",
        "Returns True if the two arrays are equal"
    ],
    [
        "If the following equation is element-wise True, then allclose returns",
        "If the following equation is element-wise True, then allclose"
    ],
    [
        "absolute(a - b) <= (atol + rtol * absolute(b))",
        "absolute(a - b) <= (atol + rtol *"
    ],
    [
        "The above equation is not symmetric in `a` and `b`, so that",
        "The above equation is not symmetric in"
    ],
    [
        "``allclose(a, b)`` might be different from ``allclose(b, a)`` in",
        "``allclose(a, b)`` might be different"
    ],
    [
        "The default value of `atol` is not appropriate when the reference value",
        "The default value of `atol` is not appropriate when"
    ],
    [
        "`b` has magnitude smaller than one. For example, it is unlikely that",
        "`b` has magnitude smaller than one. For"
    ],
    [
        "to select `atol` for the use case at hand, especially for defining the",
        "to select `atol` for the use case at hand, especially for"
    ],
    [
        "threshold below which a non-zero value in `a` will be considered \"close\"",
        "threshold below which a non-zero value in `a`"
    ],
    [
        "to a very small or zero value in `b`.",
        "to a very small or zero value in"
    ],
    [
        "The comparison of `a` and `b` uses standard broadcasting, which",
        "The comparison of `a` and"
    ],
    [
        "means that `a` and `b` need not have the same shape in order for",
        "means that `a` and `b` need not"
    ],
    [
        "``allclose(a, b)`` to evaluate to True.  The same is true for",
        "``allclose(a, b)`` to evaluate to True. The"
    ],
    [
        "`allclose` is not defined for non-numeric data types.",
        "`allclose` is not defined for non-numeric"
    ],
    [
        "`bool` is considered a numeric data-type for this purpose.",
        "`bool` is considered a numeric data-type for"
    ],
    [
        "res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))",
        "res = all(isclose(a, b,"
    ],
    [
        "def _isclose_dispatcher(a, b, rtol=None, atol=None, equal_nan=None):",
        "def _isclose_dispatcher(a, b, rtol=None,"
    ],
    [
        "Returns a boolean array where two arrays are element-wise equal within a",
        "Returns a boolean array where two arrays are element-wise equal within"
    ],
    [
        "The tolerance values are positive, typically very small numbers.  The",
        "The tolerance values are positive,"
    ],
    [
        "relative difference (`rtol` * abs(`b`)) and the absolute difference",
        "relative difference (`rtol` * abs(`b`)) and"
    ],
    [
        "`atol` are added together to compare against the absolute difference",
        "`atol` are added together to compare"
    ],
    [
        ".. warning:: The default `atol` is not appropriate for comparing numbers",
        ".. warning:: The default `atol` is not"
    ],
    [
        "with magnitudes much smaller than one (see Notes).",
        "with magnitudes much smaller than"
    ],
    [
        "The relative tolerance parameter (see Notes).",
        "The relative tolerance"
    ],
    [
        "The absolute tolerance parameter (see Notes).",
        "The absolute tolerance"
    ],
    [
        "Whether to compare NaN's as equal.  If True, NaN's in `a` will be",
        "Whether to compare NaN's as equal. If True, NaN's in"
    ],
    [
        "considered equal to NaN's in `b` in the output array.",
        "considered equal to NaN's in"
    ],
    [
        "Returns a boolean array of where `a` and `b` are equal within the",
        "Returns a boolean array of where `a` and `b` are equal"
    ],
    [
        "given tolerance. If both `a` and `b` are scalars, returns a single",
        "given tolerance. If both `a` and"
    ],
    [
        "For finite values, isclose uses the following equation to test whether",
        "For finite values, isclose uses the following"
    ],
    [
        "two floating point values are equivalent.::",
        "two floating point values"
    ],
    [
        "absolute(a - b) <= (atol + rtol * absolute(b))",
        "absolute(a - b) <= (atol + rtol *"
    ],
    [
        "Unlike the built-in `math.isclose`, the above equation is not symmetric",
        "Unlike the built-in `math.isclose`, the above equation is not"
    ],
    [
        "in `a` and `b` -- it assumes `b` is the reference value -- so that",
        "in `a` and `b` -- it assumes `b` is the reference value"
    ],
    [
        "`isclose(a, b)` might be different from `isclose(b, a)`.",
        "`isclose(a, b)` might be"
    ],
    [
        "The default value of `atol` is not appropriate when the reference value",
        "The default value of `atol` is not"
    ],
    [
        "`b` has magnitude smaller than one. For example, it is unlikely that",
        "`b` has magnitude smaller than one. For example, it is unlikely"
    ],
    [
        "to select `atol` for the use case at hand, especially for defining the",
        "to select `atol` for the use case at"
    ],
    [
        "threshold below which a non-zero value in `a` will be considered \"close\"",
        "threshold below which a non-zero value in `a` will"
    ],
    [
        "to a very small or zero value in `b`.",
        "to a very small or zero value in"
    ],
    [
        "`isclose` is not defined for non-numeric data types.",
        "`isclose` is not defined for non-numeric data"
    ],
    [
        ":class:`bool` is considered a numeric data-type for this purpose.",
        ":class:`bool` is considered a numeric"
    ],
    [
        "x, y, atol, rtol = (",
        "x, y, atol, rtol ="
    ],
    [
        "a if isinstance(a, (int, float, complex)) else asanyarray(a)",
        "a if isinstance(a, (int, float, complex)) else"
    ],
    [
        "for a in (a, b, atol, rtol))",
        "for a in (a,"
    ],
    [
        "if (dtype := getattr(y, \"dtype\", None)) is not None and dtype.kind != \"m\":",
        "if (dtype := getattr(y, \"dtype\", None)) is not None and"
    ],
    [
        "result = (less_equal(abs(x - y), atol + rtol * abs(y))",
        "result = (less_equal(abs(x - y), atol"
    ],
    [
        "True if two arrays have the same shape and elements, False otherwise.",
        "True if two arrays have the"
    ],
    [
        "complex, values will be considered equal if either the real or the",
        "complex, values will be considered equal if either the"
    ],
    [
        "imaginary component of a given value is ``nan``.",
        "imaginary component of a given"
    ],
    [
        "Returns True if the arrays are equal.",
        "Returns True if the arrays are"
    ],
    [
        "allclose: Returns True if two arrays are element-wise equal within a",
        "allclose: Returns True if two arrays are"
    ],
    [
        "array_equiv: Returns True if input arrays are shape consistent and all",
        "array_equiv: Returns True if input arrays"
    ],
    [
        "When ``equal_nan`` is True, complex values with nan components are",
        "When ``equal_nan`` is True, complex"
    ],
    [
        "considered equal if either the real *or* the imaginary components are nan.",
        "considered equal if either the real *or* the imaginary components"
    ],
    [
        "Returns True if input arrays are shape consistent and all elements equal.",
        "Returns True if input arrays are shape consistent and all"
    ],
    [
        "Shape consistent means they are either the same shape, or one input array",
        "Shape consistent means they are either the same shape, or one input"
    ],
    [
        "can be broadcasted to create the same shape as the other one.",
        "can be broadcasted to create the same shape"
    ],
    [
        "def _astype_dispatcher(x, dtype, /, *, copy=None, device=None):",
        "def _astype_dispatcher(x, dtype, /, *, copy=None,"
    ],
    [
        "def astype(x, dtype, /, *, copy=True, device=None):",
        "def astype(x, dtype, /, *, copy=True,"
    ],
    [
        "Copies an array to a specified data type.",
        "Copies an array to a"
    ],
    [
        "This function is an Array API compatible alternative to",
        "This function is an Array"
    ],
    [
        "Input NumPy array to cast. ``array_likes`` are explicitly not",
        "Input NumPy array to cast."
    ],
    [
        "Specifies whether to copy an array when the specified dtype matches",
        "Specifies whether to copy an array"
    ],
    [
        "the data type of the input array ``x``. If ``True``, a newly allocated",
        "the data type of the input array"
    ],
    [
        "array must always be returned. If ``False`` and the specified dtype",
        "array must always be returned. If ``False`` and"
    ],
    [
        "matches the data type of the input array, the input array must be",
        "matches the data type of the input array, the input"
    ],
    [
        "returned; otherwise, a newly allocated array must be returned.",
        "returned; otherwise, a newly allocated"
    ],
    [
        "The device on which to place the returned array. Default: None.",
        "The device on which to place the"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so"
    ],
    [
        "An array having the specified data type.",
        "An array having the specified data"
    ],
    [
        ">>> arr_noncpy = np.astype(arr, arr.dtype, copy=False)",
        ">>> arr_noncpy = np.astype(arr,"
    ],
    [
        "if not (isinstance(x, np.ndarray) or isscalar(x)):",
        "if not (isinstance(x, np.ndarray)"
    ],
    [
        "\"Input should be a NumPy array or scalar. \"",
        "\"Input should be a NumPy array"
    ],
    [
        "if device is not None and device != \"cpu\":",
        "if device is not None and device !="
    ],
    [
        "'Device not understood. Only \"cpu\" is allowed, but received:'",
        "'Device not understood. Only \"cpu\" is allowed,"
    ],
    [
        "from . import numeric as _nx",
        "from . import"
    ],
    [
        "from .numeric import result_type, nan, asanyarray, ndim",
        "from .numeric import result_type, nan,"
    ],
    [
        "def _linspace_dispatcher(start, stop, num=None, endpoint=None, retstep=None,",
        "def _linspace_dispatcher(start, stop, num=None, endpoint=None,"
    ],
    [
        "Return evenly spaced numbers over a specified interval.",
        "Return evenly spaced numbers"
    ],
    [
        "Returns `num` evenly spaced samples, calculated over the",
        "Returns `num` evenly spaced samples,"
    ],
    [
        "The endpoint of the interval can optionally be excluded.",
        "The endpoint of the interval"
    ],
    [
        "integer ``dtype`` is specified. The old behavior can",
        "integer ``dtype`` is specified. The old"
    ],
    [
        "still be obtained with ``np.linspace(start, stop, num).astype(int)``",
        "still be obtained with ``np.linspace(start, stop,"
    ],
    [
        "The starting value of the sequence.",
        "The starting value of"
    ],
    [
        "The end value of the sequence, unless `endpoint` is set to False.",
        "The end value of the sequence, unless `endpoint`"
    ],
    [
        "evenly spaced samples, so that `stop` is excluded.  Note that the step",
        "evenly spaced samples, so that `stop` is"
    ],
    [
        "size changes when `endpoint` is False.",
        "size changes when `endpoint` is"
    ],
    [
        "If True, `stop` is the last sample. Otherwise, it is not included.",
        "If True, `stop` is the last sample. Otherwise, it is"
    ],
    [
        "If True, return (`samples`, `step`), where `step` is the spacing",
        "If True, return (`samples`, `step`), where `step` is the"
    ],
    [
        "The type of the output array.  If `dtype` is not given, the data type",
        "The type of the output array. If `dtype`"
    ],
    [
        "is inferred from `start` and `stop`. The inferred dtype will never be",
        "is inferred from `start` and `stop`."
    ],
    [
        "an integer; `float` is chosen even if the arguments would produce an",
        "an integer; `float` is chosen even if the arguments would"
    ],
    [
        "The axis in the result to store the samples.  Relevant only if start",
        "The axis in the result to store the samples. Relevant"
    ],
    [
        "The device on which to place the created array. Default: None.",
        "The device on which to place the created array."
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so"
    ],
    [
        "There are `num` equally spaced samples in the closed interval",
        "There are `num` equally spaced samples in the closed"
    ],
    [
        "``[start, stop]`` or the half-open interval ``[start, stop)``",
        "``[start, stop]`` or the half-open interval ``[start,"
    ],
    [
        "(depending on whether `endpoint` is True or False).",
        "(depending on whether `endpoint`"
    ],
    [
        "Only returned if `retstep` is True",
        "Only returned if `retstep`"
    ],
    [
        "arange : Similar to `linspace`, but uses a step size (instead of the",
        "arange : Similar to `linspace`, but uses a step"
    ],
    [
        "geomspace : Similar to `linspace`, but with numbers spaced evenly on a log",
        "geomspace : Similar to `linspace`, but with numbers spaced evenly on"
    ],
    [
        "logspace : Similar to `geomspace`, but with the end points specified as",
        "logspace : Similar to `geomspace`, but"
    ],
    [
        "\"Number of samples, %s, must be non-negative.\" % num",
        "\"Number of samples, %s, must be non-negative.\" %"
    ],
    [
        "def _logspace_dispatcher(start, stop, num=None, endpoint=None, base=None,",
        "def _logspace_dispatcher(start, stop, num=None, endpoint=None,"
    ],
    [
        "Return numbers spaced evenly on a log scale.",
        "Return numbers spaced evenly on a log"
    ],
    [
        "In linear space, the sequence starts at ``base ** start``",
        "In linear space, the sequence starts at"
    ],
    [
        "(`base` to the power of `start`) and ends with ``base ** stop``",
        "(`base` to the power of `start`) and"
    ],
    [
        "``base ** start`` is the starting value of the sequence.",
        "``base ** start`` is the starting value"
    ],
    [
        "``base ** stop`` is the final value of the sequence, unless `endpoint`",
        "``base ** stop`` is the final value of"
    ],
    [
        "interval in log-space, of which all but the last (a sequence of",
        "interval in log-space, of which all but"
    ],
    [
        "If true, `stop` is the last sample. Otherwise, it is not included.",
        "If true, `stop` is the last sample. Otherwise, it is not"
    ],
    [
        "The base of the log space. The step size between the elements in",
        "The base of the log space. The step size between the elements"
    ],
    [
        "``ln(samples) / ln(base)`` (or ``log_base(samples)``) is uniform.",
        "``ln(samples) / ln(base)`` (or ``log_base(samples)``)"
    ],
    [
        "The type of the output array.  If `dtype` is not given, the data type",
        "The type of the output array. If `dtype` is not given, the"
    ],
    [
        "is inferred from `start` and `stop`. The inferred type will never be",
        "is inferred from `start` and `stop`. The"
    ],
    [
        "an integer; `float` is chosen even if the arguments would produce an",
        "an integer; `float` is chosen even if the arguments would produce"
    ],
    [
        "The axis in the result to store the samples.  Relevant only if start,",
        "The axis in the result to store the samples. Relevant only if"
    ],
    [
        "`num` samples, equally spaced on a log scale.",
        "`num` samples, equally spaced"
    ],
    [
        "arange : Similar to linspace, with the step size specified instead of the",
        "arange : Similar to linspace, with the step"
    ],
    [
        "number of samples. Note that, when used with a float endpoint, the",
        "number of samples. Note that, when used with a float"
    ],
    [
        "endpoint may or may not be included.",
        "endpoint may or may not be"
    ],
    [
        "linspace : Similar to logspace, but with the samples uniformly distributed",
        "linspace : Similar to logspace, but with the samples"
    ],
    [
        "in linear space, instead of log space.",
        "in linear space, instead of"
    ],
    [
        "geomspace : Similar to logspace, but with endpoints specified directly.",
        "geomspace : Similar to logspace,"
    ],
    [
        "If base is a scalar, logspace is equivalent to the code",
        "If base is a scalar, logspace is equivalent"
    ],
    [
        ">>> y = np.linspace(start, stop, num=num, endpoint=endpoint)",
        ">>> y = np.linspace(start, stop, num=num,"
    ],
    [
        "if not isinstance(base, (float, int)) and np.ndim(base):",
        "if not isinstance(base, (float,"
    ],
    [
        "for a in (start, stop, base)",
        "for a in"
    ],
    [
        "y = linspace(start, stop, num=num, endpoint=endpoint, axis=axis)",
        "y = linspace(start, stop, num=num, endpoint=endpoint,"
    ],
    [
        "def _geomspace_dispatcher(start, stop, num=None, endpoint=None, dtype=None,",
        "def _geomspace_dispatcher(start, stop,"
    ],
    [
        "Return numbers spaced evenly on a log scale (a geometric progression).",
        "Return numbers spaced evenly on a log"
    ],
    [
        "This is similar to `logspace`, but with endpoints specified directly.",
        "This is similar to `logspace`, but"
    ],
    [
        "Each output sample is a constant multiple of the previous.",
        "Each output sample is a constant multiple of"
    ],
    [
        "The starting value of the sequence.",
        "The starting value of the"
    ],
    [
        "The final value of the sequence, unless `endpoint` is False.",
        "The final value of the sequence, unless"
    ],
    [
        "interval in log-space, of which all but the last (a sequence of",
        "interval in log-space, of which all but the last (a"
    ],
    [
        "If true, `stop` is the last sample. Otherwise, it is not included.",
        "If true, `stop` is the last sample. Otherwise,"
    ],
    [
        "The type of the output array.  If `dtype` is not given, the data type",
        "The type of the output array. If `dtype`"
    ],
    [
        "is inferred from `start` and `stop`. The inferred dtype will never be",
        "is inferred from `start` and `stop`. The inferred"
    ],
    [
        "an integer; `float` is chosen even if the arguments would produce an",
        "an integer; `float` is chosen even"
    ],
    [
        "The axis in the result to store the samples.  Relevant only if start",
        "The axis in the result to store the"
    ],
    [
        "`num` samples, equally spaced on a log scale.",
        "`num` samples, equally spaced"
    ],
    [
        "logspace : Similar to geomspace, but with endpoints specified using log",
        "logspace : Similar to geomspace, but"
    ],
    [
        "linspace : Similar to geomspace, but with arithmetic instead of geometric",
        "linspace : Similar to geomspace, but with arithmetic instead of"
    ],
    [
        "arange : Similar to linspace, with the step size specified instead of the",
        "arange : Similar to linspace, with the step"
    ],
    [
        "If the inputs or dtype are complex, the output will follow a logarithmic",
        "If the inputs or dtype are complex, the output will follow a"
    ],
    [
        "spiral in the complex plane.  (There are an infinite number of spirals",
        "spiral in the complex plane. (There"
    ],
    [
        "passing through two points; the output will follow the shortest such path.)",
        "passing through two points; the output will follow the"
    ],
    [
        "Note that the above may not produce exact integers:",
        "Note that the above may not produce exact"
    ],
    [
        "Negative, decreasing, and complex inputs are allowed:",
        "Negative, decreasing, and complex"
    ],
    [
        "raise ValueError('Geometric sequence cannot include zero')",
        "raise ValueError('Geometric sequence cannot include"
    ],
    [
        "dt = result_type(start, stop, float(num), _nx.zeros((), dtype))",
        "dt = result_type(start, stop,"
    ],
    [
        "Returns true if the only way to set the docstring of `obj` from python is",
        "Returns true if the only way to set the docstring of `obj` from"
    ],
    [
        "This function errs on the side of being overly conservative.",
        "This function errs on the side of"
    ],
    [
        "if isinstance(obj, type) and obj.__flags__ & Py_TPFLAGS_HEAPTYPE:",
        "if isinstance(obj, type) and obj.__flags__ &"
    ],
    [
        "\"add_newdoc was used on a pure-python object {}. \"",
        "\"add_newdoc was used on a pure-python"
    ],
    [
        "\"Prefer to attach it directly to the source.\"",
        "\"Prefer to attach it directly to the"
    ],
    [
        "Add documentation to an existing object, typically one defined in C",
        "Add documentation to an existing object, typically one defined"
    ],
    [
        "The purpose is to allow easier editing of the docstrings without requiring",
        "The purpose is to allow easier editing"
    ],
    [
        "a re-compile. This exists primarily for internal use within numpy itself.",
        "a re-compile. This exists primarily for internal"
    ],
    [
        "The absolute name of the module to import from",
        "The absolute name of the"
    ],
    [
        "The name of the object to add documentation to, typically a class or",
        "The name of the object to add documentation to,"
    ],
    [
        "doc : {str, Tuple[str, str], List[Tuple[str, str]]}",
        "doc : {str, Tuple[str, str],"
    ],
    [
        "If a string, the documentation to apply to `obj`",
        "If a string, the documentation to apply to"
    ],
    [
        "If a tuple, then the first element is interpreted as an attribute",
        "If a tuple, then the first element is interpreted as an"
    ],
    [
        "of `obj` and the second as the docstring to apply -",
        "of `obj` and the second as the docstring"
    ],
    [
        "If a list, then each element of the list should be a tuple of length",
        "If a list, then each element of the list"
    ],
    [
        "If True, the default, emit `UserWarning` if this is used to attach",
        "If True, the default, emit `UserWarning` if this is"
    ],
    [
        "This routine never raises an error if the docstring can't be written, but",
        "This routine never raises an error if the docstring can't"
    ],
    [
        "will raise an error if the object being documented does not exist.",
        "will raise an error if the object"
    ],
    [
        "This routine cannot modify read-only docstrings, as appear",
        "This routine cannot modify read-only docstrings,"
    ],
    [
        "in new-style classes or built-in functions. Because this",
        "in new-style classes or built-in functions."
    ],
    [
        "routine never raises an error the caller must check manually",
        "routine never raises an error the caller must"
    ],
    [
        "Since this function grabs the ``char *`` from a c-level str object and puts",
        "Since this function grabs the ``char *`` from a c-level str object"
    ],
    [
        "it into the ``tp_doc`` slot of the type of `obj`, it violates a number of",
        "it into the ``tp_doc`` slot of the type of `obj`,"
    ],
    [
        "- modifying a `PyTypeObject` after calling `PyType_Ready`",
        "- modifying a `PyTypeObject`"
    ],
    [
        "- calling `Py_INCREF` on the str and losing the reference, so the str",
        "- calling `Py_INCREF` on the str and losing the reference, so the"
    ],
    [
        "If possible it should be avoided.",
        "If possible it"
    ],
    [
        "new = getattr(__import__(place, globals(), {}, [obj]), obj)",
        "new = getattr(__import__(place, globals(), {}, [obj]),"
    ],
    [
        "Computes the number of FLOPS in the contraction.",
        "Computes the number of FLOPS"
    ],
    [
        "The indices involved in the contraction",
        "The indices involved"
    ],
    [
        "Does this contraction require an inner product?",
        "Does this contraction require an"
    ],
    [
        "The number of terms in a contraction",
        "The number of terms in a"
    ],
    [
        "The size of each of the indices in idx_contraction",
        "The size of each of"
    ],
    [
        "The total number of FLOPS required for the contraction.",
        "The total number of FLOPS required for the"
    ],
    [
        "Computes the product of the elements in indices based on the dictionary",
        "Computes the product of the elements"
    ],
    [
        "Indices to base the product on.",
        "Indices to base"
    ],
    [
        "Finds the contraction for a given set of input and output sets.",
        "Finds the contraction for a given set of"
    ],
    [
        "Integer positions of terms used in the contraction.",
        "Integer positions of terms used in"
    ],
    [
        "List of sets that represent the lhs side of the einsum subscript",
        "List of sets that represent the lhs side of the"
    ],
    [
        "Set that represents the rhs side of the overall einsum subscript",
        "Set that represents the rhs side of the overall einsum"
    ],
    [
        "The indices of the resulting contraction",
        "The indices of"
    ],
    [
        "List of sets that have not been contracted, the new set is appended to",
        "List of sets that have not been contracted, the new set"
    ],
    [
        "Indices removed from the entire contraction",
        "Indices removed from the"
    ],
    [
        "The indices used in the current contraction",
        "The indices used in the current"
    ],
    [
        "({'a', 'c'}, [{'a', 'c'}], {'b'}, {'a', 'b', 'c'})",
        "({'a', 'c'}, [{'a', 'c'}], {'b'},"
    ],
    [
        ">>> isets = [set('abd'), set('ac'), set('bdc')]",
        ">>> isets ="
    ],
    [
        "({'a', 'c'}, [{'a', 'c'}, {'a', 'c'}], {'b', 'd'}, {'a', 'b', 'c', 'd'})",
        "({'a', 'c'}, [{'a', 'c'}, {'a', 'c'}], {'b', 'd'}, {'a',"
    ],
    [
        "Computes all possible pair contractions, sieves the results based",
        "Computes all possible pair contractions, sieves the results"
    ],
    [
        "on ``memory_limit`` and returns the lowest cost path. This algorithm",
        "on ``memory_limit`` and returns the lowest cost path. This"
    ],
    [
        "scales factorial with respect to the elements in the list ``input_sets``.",
        "scales factorial with respect to the elements"
    ],
    [
        "List of sets that represent the lhs side of the einsum subscript",
        "List of sets that represent the lhs"
    ],
    [
        "Set that represents the rhs side of the overall einsum subscript",
        "Set that represents the rhs side of the overall"
    ],
    [
        "The maximum number of elements in a temporary array",
        "The maximum number of elements"
    ],
    [
        "The optimal contraction order within the memory limit constraint.",
        "The optimal contraction order within the memory"
    ],
    [
        ">>> isets = [set('abd'), set('ac'), set('bdc')]",
        ">>> isets = [set('abd'),"
    ],
    [
        "new_result, new_input_sets, idx_removed, idx_contract = cont",
        "new_result, new_input_sets, idx_removed, idx_contract"
    ],
    [
        "\"\"\"Compute the cost (removed size + flops) and resultant indices for",
        "\"\"\"Compute the cost (removed size + flops) and resultant"
    ],
    [
        "performing the contraction specified by ``positions``.",
        "performing the contraction specified"
    ],
    [
        "The locations of the proposed tensors to contract.",
        "The locations of the proposed tensors"
    ],
    [
        "The indices found on each tensors.",
        "The indices found"
    ],
    [
        "The output indices of the expression.",
        "The output indices of the"
    ],
    [
        "Mapping of each index to its size.",
        "Mapping of each index"
    ],
    [
        "The total allowed size for an intermediary tensor.",
        "The total allowed size"
    ],
    [
        "The cost of the unoptimized expression.",
        "The cost of the"
    ],
    [
        "A tuple containing the size of any indices removed, and the flop cost.",
        "A tuple containing the size of any indices removed, and the flop"
    ],
    [
        "The locations of the proposed tensors to contract.",
        "The locations of the proposed"
    ],
    [
        "The resulting new list of indices if this proposed contraction",
        "The resulting new list of"
    ],
    [
        "idx_result, new_input_sets, idx_removed, idx_contract = contract",
        "idx_result, new_input_sets, idx_removed, idx_contract ="
    ],
    [
        "_compute_size_by_dict(input_sets[p], idx_dict) for p in positions",
        "_compute_size_by_dict(input_sets[p], idx_dict) for p in"
    ],
    [
        "cost = _flop_count(idx_contract, idx_removed, len(positions), idx_dict)",
        "cost = _flop_count(idx_contract, idx_removed,"
    ],
    [
        "if (path_cost + cost) > naive_cost:",
        "if (path_cost + cost) >"
    ],
    [
        "\"\"\"Update the positions and provisional input_sets of ``results``",
        "\"\"\"Update the positions and"
    ],
    [
        "based on performing the contraction result ``best``. Remove any",
        "based on performing the contraction"
    ],
    [
        "List of contraction results produced by",
        "List of contraction results"
    ],
    [
        "The best contraction of ``results`` i.e. the one that",
        "The best contraction of ``results`` i.e. the one"
    ],
    [
        "The list of modified results, updated with outcome of",
        "The list of modified results,"
    ],
    [
        "for cost, (x, y), con_sets in results:",
        "for cost, (x, y),"
    ],
    [
        "if x in best_con or y in best_con:",
        "if x in best_con or y"
    ],
    [
        "del con_sets[by - int(by > x) - int(by > y)]",
        "del con_sets[by - int(by >"
    ],
    [
        "del con_sets[bx - int(bx > x) - int(bx > y)]",
        "del con_sets[bx - int(bx > x)"
    ],
    [
        "mod_con = x - int(x > bx) - int(x > by), y - int(y > bx) - int(y > by)",
        "mod_con = x - int(x > bx) - int(x > by), y -"
    ],
    [
        "Finds the path by contracting the best pair until the input list is",
        "Finds the path by contracting the best pair until the input"
    ],
    [
        "exhausted. The best pair is found by minimizing the tuple",
        "exhausted. The best pair is"
    ],
    [
        "``(-prod(indices_removed), cost)``.  What this amounts to is prioritizing",
        "``(-prod(indices_removed), cost)``. What this amounts"
    ],
    [
        "matrix multiplication or inner product operations, then Hadamard like",
        "matrix multiplication or inner product operations, then"
    ],
    [
        "operations, and finally outer operations. Outer products are limited by",
        "operations, and finally outer operations. Outer products"
    ],
    [
        "``memory_limit``. This algorithm scales cubically with respect to the",
        "``memory_limit``. This algorithm scales cubically with"
    ],
    [
        "number of elements in the list ``input_sets``.",
        "number of elements in"
    ],
    [
        "List of sets that represent the lhs side of the einsum subscript",
        "List of sets that represent the"
    ],
    [
        "Set that represents the rhs side of the overall einsum subscript",
        "Set that represents the rhs side"
    ],
    [
        "The maximum number of elements in a temporary array",
        "The maximum number of elements in"
    ],
    [
        "The greedy contraction order within the memory limit constraint.",
        "The greedy contraction order within the memory"
    ],
    [
        ">>> isets = [set('abd'), set('ac'), set('bdc')]",
        ">>> isets = [set('abd'),"
    ],
    [
        "idx_result, new_input_sets, idx_removed, idx_contract = contract",
        "idx_result, new_input_sets, idx_removed, idx_contract ="
    ],
    [
        "comb_iter = ((i, new_tensor_pos) for i in range(new_tensor_pos))",
        "comb_iter = ((i, new_tensor_pos)"
    ],
    [
        "Checks if we can use BLAS (np.tensordot) call and its beneficial to do so.",
        "Checks if we can use BLAS (np.tensordot) call and its"
    ],
    [
        "Indices that are removed in the summation",
        "Indices that are removed in the"
    ],
    [
        "Returns true if BLAS should and can be used, else False",
        "Returns true if BLAS should and"
    ],
    [
        "we default back to einsum as the memory movement to copy is more",
        "we default back to einsum as the memory movement"
    ],
    [
        "for c in set(input_left + input_right):",
        "for c in"
    ],
    [
        "if not keep_left or not keep_right:",
        "if not keep_left or not"
    ],
    [
        "A reproduction of einsum c side einsum parsing in python.",
        "A reproduction of einsum c side einsum parsing"
    ],
    [
        "The operands to use in the numpy contraction",
        "The operands to use in the numpy"
    ],
    [
        "The operand list is simplified to reduce printing:",
        "The operand list is simplified to"
    ],
    [
        "raise ValueError(\"Character %s is not a valid symbol.\" % s)",
        "raise ValueError(\"Character %s is not a valid symbol.\""
    ],
    [
        "operands = [asanyarray(v) for v in operand_list]",
        "operands = [asanyarray(v) for"
    ],
    [
        "\"For this input type lists must contain \"",
        "\"For this input type lists must contain"
    ],
    [
        "\"For this input type lists must contain \"",
        "\"For this input type"
    ],
    [
        "if (\"-\" in subscripts) or (\">\" in subscripts):",
        "if (\"-\" in subscripts) or (\">\" in"
    ],
    [
        "raise ValueError(\"Subscripts can only contain one '->'.\")",
        "raise ValueError(\"Subscripts can only contain"
    ],
    [
        "used = subscripts.replace(\".\", \"\").replace(\",\", \"\").replace(\"->\", \"\")",
        "used = subscripts.replace(\".\", \"\").replace(\",\","
    ],
    [
        "raise ValueError(\"Ellipses lengths do not match.\")",
        "raise ValueError(\"Ellipses lengths"
    ],
    [
        "subscripts += \"->\" + output_sub.replace(\"...\", out_ellipse)",
        "subscripts += \"->\""
    ],
    [
        "raise ValueError(\"Character %s is not a valid symbol.\" % s)",
        "raise ValueError(\"Character %s is not a"
    ],
    [
        "subscripts += \"->\" + out_ellipse + normal_inds",
        "subscripts += \"->\" +"
    ],
    [
        "raise ValueError(\"Character %s is not a valid symbol.\" % s)",
        "raise ValueError(\"Character %s is not a valid symbol.\""
    ],
    [
        "raise ValueError(\"Output character %s appeared more than once in \"",
        "raise ValueError(\"Output character %s appeared more than"
    ],
    [
        "raise ValueError(\"Output character %s did not appear in the input\"",
        "raise ValueError(\"Output character %s did not appear in the"
    ],
    [
        "raise ValueError(\"Number of einsum subscripts must be equal to the \"",
        "raise ValueError(\"Number of einsum subscripts must be equal to"
    ],
    [
        "Evaluates the lowest cost contraction order for an einsum expression by",
        "Evaluates the lowest cost contraction order"
    ],
    [
        "considering the creation of intermediate arrays.",
        "considering the creation of intermediate"
    ],
    [
        "These are the arrays for the operation.",
        "These are the arrays for the"
    ],
    [
        "optimize : {bool, list, tuple, 'greedy', 'optimal'}",
        "optimize : {bool, list, tuple, 'greedy',"
    ],
    [
        "Choose the type of path. If a tuple is provided, the second argument is",
        "Choose the type of path. If a tuple"
    ],
    [
        "assumed to be the maximum intermediate size created. If only a single",
        "assumed to be the maximum intermediate size"
    ],
    [
        "argument is provided the largest input or output array size is used",
        "argument is provided the largest input or output array size"
    ],
    [
        "* if a list is given that starts with ``einsum_path``, uses this as the",
        "* if a list is given that starts"
    ],
    [
        "* if False no optimization is taken",
        "* if False no"
    ],
    [
        "* if True defaults to the 'greedy' algorithm",
        "* if True defaults to the"
    ],
    [
        "* 'optimal' An algorithm that combinatorially explores all possible",
        "* 'optimal' An algorithm that combinatorially"
    ],
    [
        "ways of contracting the listed tensors and chooses the least costly",
        "ways of contracting the listed tensors and chooses the least"
    ],
    [
        "path. Scales exponentially with the number of terms in the",
        "path. Scales exponentially with the"
    ],
    [
        "* 'greedy' An algorithm that chooses the best pair contraction",
        "* 'greedy' An algorithm that"
    ],
    [
        "at each step. Effectively, this algorithm searches the largest inner,",
        "at each step. Effectively, this algorithm searches the"
    ],
    [
        "Hadamard, and then outer products at each step. Scales cubically with",
        "Hadamard, and then outer products at"
    ],
    [
        "the number of terms in the contraction. Equivalent to the 'optimal'",
        "the number of terms in the contraction. Equivalent"
    ],
    [
        "A list representation of the einsum path.",
        "A list representation of the"
    ],
    [
        "A printable representation of the einsum path.",
        "A printable representation of the einsum"
    ],
    [
        "The resulting path indicates which terms of the input contraction should be",
        "The resulting path indicates which terms of the"
    ],
    [
        "contracted first, the result of this contraction is then appended to the",
        "contracted first, the result of this contraction is"
    ],
    [
        "end of the contraction list. This list can then be iterated over until all",
        "end of the contraction list. This list can then be iterated"
    ],
    [
        "We can begin with a chain dot example. In this case, it is optimal to",
        "We can begin with a chain dot example. In this case, it is optimal"
    ],
    [
        "contract the ``b`` and ``c`` tensors first as represented by the first",
        "contract the ``b`` and ``c`` tensors first as represented"
    ],
    [
        ">>> path_info = np.einsum_path('ij,jk,kl->il', a, b, c, optimize='greedy')",
        ">>> path_info = np.einsum_path('ij,jk,kl->il',"
    ],
    [
        "A more complex index transformation example.",
        "A more complex index transformation"
    ],
    [
        ">>> path_info = np.einsum_path('ea,fb,abcd,gc,hd->efgh', C, C, I, C, C,",
        ">>> path_info = np.einsum_path('ea,fb,abcd,gc,hd->efgh', C, C, I,"
    ],
    [
        "if (path_type is False) or isinstance(path_type, str):",
        "if (path_type is False) or"
    ],
    [
        "raise TypeError(\"Did not understand the path: %s\" % str(path_type))",
        "raise TypeError(\"Did not understand the path:"
    ],
    [
        "input_sets = [set(x) for x in input_list]",
        "input_sets = [set(x) for x in"
    ],
    [
        "broadcast_indices = [[] for x in range(len(input_list))]",
        "broadcast_indices = [[] for"
    ],
    [
        "raise ValueError(\"Einstein sum subscript %s does not contain the \"",
        "raise ValueError(\"Einstein sum subscript %s"
    ],
    [
        "\"correct number of indices for operand %d.\"",
        "\"correct number of indices"
    ],
    [
        "raise ValueError(\"Size of label '%s' for operand %d (%d) \"",
        "raise ValueError(\"Size of label '%s'"
    ],
    [
        "\"does not match previous terms (%d).\"",
        "\"does not match"
    ],
    [
        "broadcast_indices = [set(x) for x in broadcast_indices]",
        "broadcast_indices = [set(x) for"
    ],
    [
        "for term in input_list + [output_subscript]]",
        "for term in"
    ],
    [
        "raise KeyError(\"Path name %s not found\", path_type)",
        "raise KeyError(\"Path name %s not"
    ],
    [
        "cost_list, scale_list, size_list, contraction_list = [], [], [], []",
        "cost_list, scale_list, size_list, contraction_list = [], [],"
    ],
    [
        "out_inds, input_sets, idx_removed, idx_contract = contract",
        "out_inds, input_sets, idx_removed,"
    ],
    [
        "sort_result = [(dimension_dict[ind], ind) for ind in out_inds]",
        "sort_result = [(dimension_dict[ind], ind)"
    ],
    [
        "einsum_str = \",\".join(tmp_inputs) + \"->\" + idx_result",
        "einsum_str = \",\".join(tmp_inputs) + \"->\""
    ],
    [
        "\"Invalid einsum_path is specified: {} more operands has to be \"",
        "\"Invalid einsum_path is specified: {} more operands has to"
    ],
    [
        "overall_contraction = input_subscripts + \"->\" + output_subscript",
        "overall_contraction = input_subscripts + \"->\""
    ],
    [
        "path_print = \"  Complete contraction:  %s\\n\" % overall_contraction",
        "path_print = \" Complete"
    ],
    [
        "path_print += \"         Naive scaling:  %d\\n\" % len(indices)",
        "path_print += \" Naive scaling:"
    ],
    [
        "path_print += \"     Optimized scaling:  %d\\n\" % max(scale_list)",
        "path_print += \" Optimized scaling: %d\\n\""
    ],
    [
        "inds, idx_rm, einsum_str, remaining, blas = contraction",
        "inds, idx_rm, einsum_str, remaining,"
    ],
    [
        "remaining_str = \",\".join(remaining) + \"->\" + output_subscript",
        "remaining_str = \",\".join(remaining) + \"->\""
    ],
    [
        "Evaluates the Einstein summation convention on the operands.",
        "Evaluates the Einstein summation convention on"
    ],
    [
        "Using the Einstein summation convention, many common multi-dimensional,",
        "Using the Einstein summation convention, many"
    ],
    [
        "linear algebraic array operations can be represented in a simple fashion.",
        "linear algebraic array operations can be"
    ],
    [
        "In *implicit* mode `einsum` computes these values.",
        "In *implicit* mode `einsum` computes"
    ],
    [
        "In *explicit* mode, `einsum` provides further flexibility to compute",
        "In *explicit* mode, `einsum` provides further"
    ],
    [
        "other array operations that might not be considered classical Einstein",
        "other array operations that might not"
    ],
    [
        "summation operations, by disabling, or forcing summation over specified",
        "summation operations, by disabling, or forcing summation"
    ],
    [
        "See the notes and examples for clarification.",
        "See the notes and examples"
    ],
    [
        "Specifies the subscripts for summation as comma separated list of",
        "Specifies the subscripts for summation"
    ],
    [
        "subscript labels. An implicit (classical Einstein summation)",
        "subscript labels. An implicit"
    ],
    [
        "calculation is performed unless the explicit indicator '->' is",
        "calculation is performed unless the"
    ],
    [
        "included as well as subscript labels of the precise output form.",
        "included as well as subscript labels of the"
    ],
    [
        "These are the arrays for the operation.",
        "These are the arrays"
    ],
    [
        "If provided, the calculation is done into this array.",
        "If provided, the calculation is done into"
    ],
    [
        "If provided, forces the calculation to use the data type specified.",
        "If provided, forces the calculation to"
    ],
    [
        "Note that you may have to also give a more liberal `casting`",
        "Note that you may have to also give a"
    ],
    [
        "parameter to allow the conversions. Default is None.",
        "parameter to allow the conversions. Default is"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A',"
    ],
    [
        "Controls the memory layout of the output. 'C' means it should",
        "Controls the memory layout of the output. 'C' means it"
    ],
    [
        "be C contiguous. 'F' means it should be Fortran contiguous,",
        "be C contiguous. 'F' means it should be"
    ],
    [
        "'A' means it should be 'F' if the inputs are all 'F', 'C' otherwise.",
        "'A' means it should be 'F' if the inputs"
    ],
    [
        "'K' means it should be as close to the layout as the inputs as",
        "'K' means it should be as close to the"
    ],
    [
        "is possible, including arbitrarily permuted axes.",
        "is possible, including arbitrarily"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv',"
    ],
    [
        "Controls what kind of data casting may occur.  Setting this to",
        "Controls what kind of data casting may occur. Setting"
    ],
    [
        "'unsafe' is not recommended, as it can adversely affect accumulations.",
        "'unsafe' is not recommended, as it"
    ],
    [
        "* 'no' means the data types should not be cast at all.",
        "* 'no' means the data types should"
    ],
    [
        "* 'equiv' means only byte-order changes are allowed.",
        "* 'equiv' means only"
    ],
    [
        "* 'safe' means only casts which can preserve values are allowed.",
        "* 'safe' means only casts which"
    ],
    [
        "* 'same_kind' means only safe casts or casts within a kind,",
        "* 'same_kind' means only safe casts"
    ],
    [
        "* 'unsafe' means any data conversions may be done.",
        "* 'unsafe' means any data"
    ],
    [
        "optimize : {False, True, 'greedy', 'optimal'}, optional",
        "optimize : {False, True,"
    ],
    [
        "Controls if intermediate optimization should occur. No optimization",
        "Controls if intermediate optimization"
    ],
    [
        "will occur if False and True will default to the 'greedy' algorithm.",
        "will occur if False and True will default to"
    ],
    [
        "Also accepts an explicit contraction list from the ``np.einsum_path``",
        "Also accepts an explicit contraction list from"
    ],
    [
        "function. See ``np.einsum_path`` for more details. Defaults to False.",
        "function. See ``np.einsum_path`` for more"
    ],
    [
        "The calculation based on the Einstein summation convention.",
        "The calculation based on the Einstein"
    ],
    [
        "einsum_path, dot, inner, outer, tensordot, linalg.multi_dot",
        "einsum_path, dot, inner, outer, tensordot,"
    ],
    [
        "Similar verbose interface is provided by the",
        "Similar verbose interface is provided by"
    ],
    [
        "optimizes contraction order for einsum-like expressions",
        "optimizes contraction order for einsum-like"
    ],
    [
        "The Einstein summation convention can be used to compute",
        "The Einstein summation convention can be used to"
    ],
    [
        "many multi-dimensional, linear algebraic array operations. `einsum`",
        "many multi-dimensional, linear algebraic"
    ],
    [
        "provides a succinct way of representing these.",
        "provides a succinct way of"
    ],
    [
        "A non-exhaustive list of these operations,",
        "A non-exhaustive list"
    ],
    [
        "which can be computed by `einsum`, is shown below along with examples:",
        "which can be computed by `einsum`, is shown below"
    ],
    [
        "* Trace of an array, :py:func:`numpy.trace`.",
        "* Trace of an array,"
    ],
    [
        "* Matrix multiplication and dot product, :py:func:`numpy.matmul`",
        "* Matrix multiplication and dot product,"
    ],
    [
        "* Vector inner and outer products, :py:func:`numpy.inner`",
        "* Vector inner and"
    ],
    [
        "* Broadcasting, element-wise and scalar multiplication,",
        "* Broadcasting, element-wise and scalar"
    ],
    [
        "* Chained array operations, in efficient calculation order,",
        "* Chained array operations, in"
    ],
    [
        "The subscripts string is a comma-separated list of subscript labels,",
        "The subscripts string is a"
    ],
    [
        "where each label refers to a dimension of the corresponding operand.",
        "where each label refers to a dimension of the"
    ],
    [
        "Whenever a label is repeated it is summed, so ``np.einsum('i,i', a, b)``",
        "Whenever a label is repeated it"
    ],
    [
        "is equivalent to :py:func:`np.inner(a,b) <numpy.inner>`. If a label",
        "is equivalent to :py:func:`np.inner(a,b) <numpy.inner>`. If"
    ],
    [
        "appears only once, it is not summed, so ``np.einsum('i', a)``",
        "appears only once, it is not summed, so ``np.einsum('i',"
    ],
    [
        "produces a view of ``a`` with no changes. A further example",
        "produces a view of ``a`` with no changes. A further"
    ],
    [
        "``np.einsum('ij,jk', a, b)`` describes traditional matrix multiplication",
        "``np.einsum('ij,jk', a, b)`` describes traditional"
    ],
    [
        "and is equivalent to :py:func:`np.matmul(a,b) <numpy.matmul>`.",
        "and is equivalent to"
    ],
    [
        "Repeated subscript labels in one operand take the diagonal.",
        "Repeated subscript labels in one operand take"
    ],
    [
        "For example, ``np.einsum('ii', a)`` is equivalent to",
        "For example, ``np.einsum('ii', a)`` is equivalent"
    ],
    [
        "In *implicit mode*, the chosen subscripts are important",
        "In *implicit mode*, the chosen subscripts are"
    ],
    [
        "since the axes of the output are reordered alphabetically.  This",
        "since the axes of the output are reordered"
    ],
    [
        "``np.einsum('ji', a)`` takes its transpose. Additionally,",
        "``np.einsum('ji', a)`` takes its transpose."
    ],
    [
        "``np.einsum('ij,jk', a, b)`` returns a matrix multiplication, while,",
        "``np.einsum('ij,jk', a, b)`` returns a"
    ],
    [
        "``np.einsum('ij,jh', a, b)`` returns the transpose of the",
        "``np.einsum('ij,jh', a, b)`` returns the transpose"
    ],
    [
        "multiplication since subscript 'h' precedes subscript 'i'.",
        "multiplication since subscript 'h'"
    ],
    [
        "In *explicit mode* the output can be directly controlled by",
        "In *explicit mode* the output can"
    ],
    [
        "specifying output subscript labels.  This requires the",
        "specifying output subscript labels. This requires"
    ],
    [
        "identifier '->' as well as the list of output subscript labels.",
        "identifier '->' as well as the"
    ],
    [
        "This feature increases the flexibility of the function since",
        "This feature increases the flexibility of the function"
    ],
    [
        "summing can be disabled or forced when required. The call",
        "summing can be disabled or forced when required. The"
    ],
    [
        "``np.einsum('i->', a)`` is like :py:func:`np.sum(a) <numpy.sum>`",
        "``np.einsum('i->', a)`` is like"
    ],
    [
        "The difference is that `einsum` does not allow broadcasting by default.",
        "The difference is that `einsum` does not allow broadcasting"
    ],
    [
        "Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies the",
        "Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies"
    ],
    [
        "order of the output subscript labels and therefore returns matrix",
        "order of the output subscript labels and therefore"
    ],
    [
        "multiplication, unlike the example above in implicit mode.",
        "multiplication, unlike the example above"
    ],
    [
        "To enable and control broadcasting, use an ellipsis.  Default",
        "To enable and control broadcasting, use"
    ],
    [
        "NumPy-style broadcasting is done by adding an ellipsis",
        "NumPy-style broadcasting is done"
    ],
    [
        "to the left of each term, like ``np.einsum('...ii->...i', a)``.",
        "to the left of each"
    ],
    [
        "To take the trace along the first and last axes,",
        "To take the trace along the first and"
    ],
    [
        "you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix",
        "you can do ``np.einsum('i...i', a)``, or to"
    ],
    [
        "product with the left-most indices instead of rightmost, one can do",
        "product with the left-most indices instead of rightmost, one can"
    ],
    [
        "When there is only one operand, no axes are summed, and no output",
        "When there is only one operand, no axes"
    ],
    [
        "parameter is provided, a view into the operand is returned instead",
        "parameter is provided, a view into"
    ],
    [
        "of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``",
        "of a new array. Thus, taking the diagonal"
    ],
    [
        "`einsum` also provides an alternative way to provide the subscripts and",
        "`einsum` also provides an alternative way to"
    ],
    [
        "If the output shape is not provided in this format `einsum` will be",
        "If the output shape is not provided"
    ],
    [
        "calculated in implicit mode, otherwise it will be performed explicitly.",
        "calculated in implicit mode, otherwise it"
    ],
    [
        "The examples below have corresponding `einsum` calls with the two",
        "The examples below have corresponding `einsum`"
    ],
    [
        "Views returned from einsum are now writeable whenever the input array",
        "Views returned from einsum are now"
    ],
    [
        "is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will now",
        "is writeable. For example, ``np.einsum('ijk...->kji...',"
    ],
    [
        "and ``np.einsum('ii->i', a)`` will return a writeable view of the diagonal",
        "and ``np.einsum('ii->i', a)`` will return a writeable view of the"
    ],
    [
        "Added the ``optimize`` argument which will optimize the contraction order",
        "Added the ``optimize`` argument which will"
    ],
    [
        "of an einsum expression. For a contraction with three or more operands",
        "of an einsum expression. For a contraction with three or"
    ],
    [
        "this can greatly increase the computational efficiency at the cost of",
        "this can greatly increase the computational efficiency at the"
    ],
    [
        "a larger memory footprint during computation.",
        "a larger memory"
    ],
    [
        "Typically a 'greedy' algorithm is applied which empirical tests have shown",
        "Typically a 'greedy' algorithm is applied which empirical tests have"
    ],
    [
        "returns the optimal path in the majority of cases. In some cases 'optimal'",
        "returns the optimal path in the majority of"
    ],
    [
        "will return the superlative path through a more expensive, exhaustive",
        "will return the superlative path through a more"
    ],
    [
        "search. For iterative calculations it may be advisable to calculate",
        "search. For iterative calculations it may be"
    ],
    [
        "the optimal path once and reuse that path by supplying it as an argument.",
        "the optimal path once and reuse that path by supplying it as an"
    ],
    [
        "Extract the diagonal (requires explicit form):",
        "Extract the diagonal"
    ],
    [
        "Sum over an axis (requires explicit form):",
        "Sum over an axis (requires"
    ],
    [
        "For higher dimensional arrays summing a single axis can be done",
        "For higher dimensional arrays summing a single axis"
    ],
    [
        "Compute a matrix transpose, or reorder any number of axes:",
        "Compute a matrix transpose, or"
    ],
    [
        "Chained array operations. For more complicated contractions, speed ups",
        "Chained array operations. For more complicated contractions, speed"
    ],
    [
        "might be achieved by repeatedly computing a 'greedy' path or pre-computing",
        "might be achieved by repeatedly computing a 'greedy'"
    ],
    [
        "the 'optimal' path and repeatedly applying it, using an `einsum_path`",
        "the 'optimal' path and repeatedly applying it, using an"
    ],
    [
        "specified_out = out is not None",
        "specified_out = out is"
    ],
    [
        "unknown_kwargs = [k for (k, v) in kwargs.items() if",
        "unknown_kwargs = [k for (k,"
    ],
    [
        "raise TypeError(\"Did not understand the following kwargs: %s\"",
        "raise TypeError(\"Did not understand"
    ],
    [
        "if all(arr.flags.f_contiguous for arr in operands):",
        "if all(arr.flags.f_contiguous for arr"
    ],
    [
        "inds, idx_rm, einsum_str, remaining, blas = contraction",
        "inds, idx_rm, einsum_str, remaining,"
    ],
    [
        "tmp_operands = [operands.pop(x) for x in inds]",
        "tmp_operands = [operands.pop(x) for"
    ],
    [
        "if (tensor_result != results_index) or handle_out:",
        "if (tensor_result != results_index)"
    ],
    [
        "tensor_result + '->' + results_index, new_view, **kwargs",
        "tensor_result + '->' +"
    ],
    [
        "Functions for changing global ufunc configuration",
        "Functions for changing global ufunc"
    ],
    [
        "This provides helpers which wrap `_get_extobj_dict` and `_make_extobj`, and",
        "This provides helpers which wrap `_get_extobj_dict` and `_make_extobj`,"
    ],
    [
        "from .umath import _make_extobj, _get_extobj_dict, _extobj_contextvar",
        "from .umath import _make_extobj, _get_extobj_dict,"
    ],
    [
        "\"seterr\", \"geterr\", \"setbufsize\", \"getbufsize\", \"seterrcall\", \"geterrcall\",",
        "\"seterr\", \"geterr\", \"setbufsize\","
    ],
    [
        "def seterr(all=None, divide=None, over=None, under=None, invalid=None):",
        "def seterr(all=None, divide=None,"
    ],
    [
        "Set how floating-point errors are handled.",
        "Set how floating-point errors are"
    ],
    [
        "handled like floating point, and are affected by these settings.",
        "handled like floating point, and are affected by these"
    ],
    [
        "all : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional",
        "all : {'ignore', 'warn', 'raise',"
    ],
    [
        "Set treatment for all types of floating-point errors at once:",
        "Set treatment for all types of"
    ],
    [
        "- ignore: Take no action when the exception occurs.",
        "- ignore: Take no action"
    ],
    [
        "- warn: Print a :exc:`RuntimeWarning` (via the Python `warnings`",
        "- warn: Print a :exc:`RuntimeWarning` (via the"
    ],
    [
        "- call: Call a function specified using the `seterrcall` function.",
        "- call: Call a function specified using the"
    ],
    [
        "- print: Print a warning directly to ``stdout``.",
        "- print: Print a warning directly to"
    ],
    [
        "- log: Record error in a Log object specified by `seterrcall`.",
        "- log: Record error in a Log object specified by"
    ],
    [
        "The default is not to change the current behavior.",
        "The default is not to"
    ],
    [
        "divide : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional",
        "divide : {'ignore', 'warn', 'raise', 'call', 'print',"
    ],
    [
        "over : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional",
        "over : {'ignore', 'warn', 'raise', 'call', 'print', 'log'},"
    ],
    [
        "under : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional",
        "under : {'ignore', 'warn', 'raise',"
    ],
    [
        "invalid : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional",
        "invalid : {'ignore', 'warn', 'raise', 'call', 'print',"
    ],
    [
        "seterrcall : Set a callback function for the 'call' mode.",
        "seterrcall : Set a callback function for"
    ],
    [
        "- Division by zero: infinite result obtained from finite numbers.",
        "- Division by zero: infinite"
    ],
    [
        "- Overflow: result too large to be expressed.",
        "- Overflow: result too large to"
    ],
    [
        "- Underflow: result so close to zero that some precision",
        "- Underflow: result so close to zero"
    ],
    [
        "- Invalid operation: result is not an expressible number, typically",
        "- Invalid operation: result is"
    ],
    [
        "indicates that a NaN was produced.",
        "indicates that a NaN was"
    ],
    [
        "{'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}",
        "{'divide': 'ignore', 'over': 'ignore', 'under': 'ignore',"
    ],
    [
        "FloatingPointError: overflow encountered in scalar multiply",
        "FloatingPointError: overflow encountered in scalar"
    ],
    [
        "{'divide': 'print', 'over': 'print', 'under': 'print', 'invalid': 'print'}",
        "{'divide': 'print', 'over': 'print', 'under':"
    ],
    [
        "{'divide': 'print', 'over': 'print', 'under': 'print', 'invalid': 'print'}",
        "{'divide': 'print', 'over': 'print', 'under': 'print', 'invalid':"
    ],
    [
        "Get the current way of handling floating-point errors.",
        "Get the current way of"
    ],
    [
        "A dictionary with keys \"divide\", \"over\", \"under\", and \"invalid\",",
        "A dictionary with keys \"divide\", \"over\", \"under\", and"
    ],
    [
        "whose values are from the strings \"ignore\", \"print\", \"log\", \"warn\",",
        "whose values are from the strings \"ignore\", \"print\", \"log\","
    ],
    [
        "\"raise\", and \"call\". The keys represent possible floating-point",
        "\"raise\", and \"call\". The keys represent possible"
    ],
    [
        "exceptions, and the values define how these exceptions are handled.",
        "exceptions, and the values define how these exceptions are"
    ],
    [
        "For complete documentation of the types of floating-point exceptions and",
        "For complete documentation of the"
    ],
    [
        "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}",
        "{'divide': 'warn', 'over': 'warn', 'under': 'ignore',"
    ],
    [
        "RuntimeWarning: invalid value encountered in divide",
        "RuntimeWarning: invalid value encountered"
    ],
    [
        "{'divide': 'warn', 'over': 'warn', 'under': 'warn', 'invalid': 'raise'}",
        "{'divide': 'warn', 'over': 'warn',"
    ],
    [
        "FloatingPointError: invalid value encountered in divide",
        "FloatingPointError: invalid value encountered"
    ],
    [
        "Set the size of the buffer used in ufuncs.",
        "Set the size of the buffer used in"
    ],
    [
        "The scope of setting the buffer is tied to the `numpy.errstate`",
        "The scope of setting the buffer is tied to the"
    ],
    [
        "context.  Exiting a ``with errstate():`` will also restore the bufsize.",
        "context. Exiting a ``with errstate():`` will also restore the"
    ],
    [
        "Previous size of ufunc buffer in bytes.",
        "Previous size of ufunc buffer"
    ],
    [
        "When exiting a `numpy.errstate` context manager the bufsize is restored:",
        "When exiting a `numpy.errstate` context manager the"
    ],
    [
        "Return the size of the buffer used in ufuncs.",
        "Return the size of the buffer"
    ],
    [
        "Size of ufunc buffer in bytes.",
        "Size of ufunc"
    ],
    [
        "Set the floating-point error callback function or log object.",
        "Set the floating-point error callback function"
    ],
    [
        "There are two ways to capture floating-point error messages.  The first",
        "There are two ways to capture floating-point error messages."
    ],
    [
        "is to set the error-handler to 'call', using `seterr`.  Then, set",
        "is to set the error-handler to 'call', using"
    ],
    [
        "the function to call using this function.",
        "the function to call using"
    ],
    [
        "The second is to set the error-handler to 'log', using `seterr`.",
        "The second is to set the error-handler"
    ],
    [
        "Floating-point errors then trigger a call to the 'write' method of",
        "Floating-point errors then trigger a call to the"
    ],
    [
        "func : callable f(err, flag) or object with write method",
        "func : callable f(err, flag) or object with"
    ],
    [
        "Function to call upon floating-point errors ('call'-mode) or",
        "Function to call upon"
    ],
    [
        "object whose 'write' method is used to log such message ('log'-mode).",
        "object whose 'write' method is used to log such"
    ],
    [
        "The call function takes two arguments. The first is a string describing",
        "The call function takes two arguments. The first is"
    ],
    [
        "the type of error (such as \"divide by zero\", \"overflow\", \"underflow\",",
        "the type of error (such as \"divide by"
    ],
    [
        "or \"invalid value\"), and the second is the status flag.  The flag is a",
        "or \"invalid value\"), and the second is the status flag. The flag"
    ],
    [
        "byte, whose four least-significant bits indicate the type of error, one",
        "byte, whose four least-significant bits indicate the type of"
    ],
    [
        "If an object is provided, its write method should take one argument,",
        "If an object is provided, its write method should take one"
    ],
    [
        "h : callable, log instance or None",
        "h : callable, log"
    ],
    [
        "...     print(\"Floating point error (%s), with flag %s\" % (type, flag))",
        "... print(\"Floating point error (%s), with flag"
    ],
    [
        "{'divide': 'call', 'over': 'call', 'under': 'call', 'invalid': 'call'}",
        "{'divide': 'call', 'over': 'call', 'under':"
    ],
    [
        "LOG: Warning: divide by zero encountered in divide",
        "LOG: Warning: divide by zero"
    ],
    [
        "{'divide': 'log', 'over': 'log', 'under': 'log', 'invalid': 'log'}",
        "{'divide': 'log', 'over': 'log', 'under': 'log',"
    ],
    [
        "Return the current callback function used on floating-point errors.",
        "Return the current callback function"
    ],
    [
        "When the error handling for a floating-point error (one of \"divide\",",
        "When the error handling for a floating-point error"
    ],
    [
        "\"over\", \"under\", or \"invalid\") is set to 'call' or 'log', the function",
        "\"over\", \"under\", or \"invalid\") is set to 'call' or"
    ],
    [
        "that is called or the log instance that is written to is returned by",
        "that is called or the log instance that is written"
    ],
    [
        "`geterrcall`. This function or log instance has been set with",
        "`geterrcall`. This function or log instance has been"
    ],
    [
        "errobj : callable, log instance or None",
        "errobj : callable, log"
    ],
    [
        "The current error handler. If no handler was set through `seterrcall`,",
        "The current error handler. If no"
    ],
    [
        "For complete documentation of the types of floating-point exceptions and",
        "For complete documentation of the types of"
    ],
    [
        "...     print(\"Floating point error (%s), with flag %s\" % (type, flag))",
        "... print(\"Floating point error (%s), with"
    ],
    [
        "Context manager for floating-point error handling.",
        "Context manager for"
    ],
    [
        "Using an instance of `errstate` as a context manager allows statements in",
        "Using an instance of `errstate` as a"
    ],
    [
        "that context to execute with a known error handling behavior. Upon entering",
        "that context to execute with a known error handling behavior. Upon"
    ],
    [
        "the context the error handling is set with `seterr` and `seterrcall`, and",
        "the context the error handling is"
    ],
    [
        "upon exiting it is reset to what it was before.",
        "upon exiting it is reset to what"
    ],
    [
        "`errstate` is also usable as a function decorator, saving",
        "`errstate` is also usable as a"
    ],
    [
        "a level of indentation if an entire function is wrapped.",
        "a level of indentation if an entire function"
    ],
    [
        "`errstate` is now fully thread and asyncio safe, but may not be",
        "`errstate` is now fully thread and"
    ],
    [
        "It is not safe to decorate async functions using ``errstate``.",
        "It is not safe to decorate async functions using"
    ],
    [
        "kwargs : {divide, over, under, invalid}",
        "kwargs : {divide,"
    ],
    [
        "Keyword arguments. The valid keywords are the possible floating-point",
        "Keyword arguments. The valid keywords are the"
    ],
    [
        "exceptions. Each keyword should have a string value that defines the",
        "exceptions. Each keyword should have a string"
    ],
    [
        "treatment for the particular error. Possible values are",
        "treatment for the particular error. Possible values"
    ],
    [
        "{'ignore', 'warn', 'raise', 'call', 'print', 'log'}.",
        "{'ignore', 'warn', 'raise',"
    ],
    [
        "For complete documentation of the types of floating-point exceptions and",
        "For complete documentation of the types"
    ],
    [
        "FloatingPointError: invalid value encountered in sqrt",
        "FloatingPointError: invalid value encountered"
    ],
    [
        "Outside the context the error handling behavior has not changed:",
        "Outside the context the error handling"
    ],
    [
        "{'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}",
        "{'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid':"
    ],
    [
        "\"_call\", \"_all\", \"_divide\", \"_over\", \"_under\", \"_invalid\", \"_token\")",
        "\"_call\", \"_all\", \"_divide\", \"_over\","
    ],
    [
        "Various richly-typed exceptions, that also help us deal with string formatting",
        "Various richly-typed exceptions, that also help us deal with string"
    ],
    [
        "By putting the formatting in `__str__`, we also avoid paying the cost for",
        "By putting the formatting in `__str__`, we also avoid paying the cost"
    ],
    [
        "A decorator that makes an exception class look like its base.",
        "A decorator that makes an exception class look like"
    ],
    [
        "We use this to hide subclasses that are implementation details - the user",
        "We use this to hide subclasses that are"
    ],
    [
        "should catch the base type, which is what the traceback will show them.",
        "should catch the base type, which is"
    ],
    [
        "Classes decorated with this decorator are subject to removal without a",
        "Classes decorated with this decorator are subject to removal without"
    ],
    [
        "\"\"\" Base class for all ufunc exceptions \"\"\"",
        "\"\"\" Base class for"
    ],
    [
        "\"\"\" Thrown when a ufunc loop cannot be found \"\"\"",
        "\"\"\" Thrown when a ufunc loop"
    ],
    [
        "\"ufunc {!r} did not contain a loop with signature matching types \"",
        "\"ufunc {!r} did not contain a loop with signature"
    ],
    [
        "\"\"\" Thrown when a binary resolution fails \"\"\"",
        "\"\"\" Thrown when a binary"
    ],
    [
        "\"ufunc {!r} cannot use operands with types {!r} and {!r}\"",
        "\"ufunc {!r} cannot use operands with types {!r} and"
    ],
    [
        "def __init__(self, ufunc, casting, from_, to):",
        "def __init__(self, ufunc, casting,"
    ],
    [
        "\"\"\" Thrown when a ufunc input cannot be casted \"\"\"",
        "\"\"\" Thrown when a ufunc input cannot be"
    ],
    [
        "def __init__(self, ufunc, casting, from_, to, i):",
        "def __init__(self, ufunc, casting, from_,"
    ],
    [
        "\"Cannot cast ufunc {!r} input {}from {!r} to {!r} with casting \"",
        "\"Cannot cast ufunc {!r} input {}from {!r} to {!r} with casting"
    ],
    [
        "\"\"\" Thrown when a ufunc output cannot be casted \"\"\"",
        "\"\"\" Thrown when a ufunc output cannot be casted"
    ],
    [
        "def __init__(self, ufunc, casting, from_, to, i):",
        "def __init__(self, ufunc, casting,"
    ],
    [
        "\"Cannot cast ufunc {!r} output {}from {!r} to {!r} with casting \"",
        "\"Cannot cast ufunc {!r} output {}from {!r}"
    ],
    [
        "\"\"\" Thrown when an array cannot be allocated\"\"\"",
        "\"\"\" Thrown when an array cannot"
    ],
    [
        "\"\"\" Convert a number of bytes into a binary size string \"\"\"",
        "\"\"\" Convert a number of bytes into"
    ],
    [
        "units = ['bytes', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB']",
        "units = ['bytes', 'KiB', 'MiB',"
    ],
    [
        "\"Unable to allocate {} for an array with shape {} and data type {}\"",
        "\"Unable to allocate {} for an array with shape {} and data"
    ],
    [
        "numerictypes: Define the numeric type objects",
        "numerictypes: Define the numeric"
    ],
    [
        "This module is designed so \"from numerictypes import \\\\*\" is safe.",
        "This module is designed so \"from numerictypes import \\\\*\" is"
    ],
    [
        "Dictionary with all registered number types (including aliases):",
        "Dictionary with all registered number types"
    ],
    [
        "Type objects (not all will be available, depends on platform):",
        "Type objects (not all will be available, depends"
    ],
    [
        "see variable sctypes for which ones you have",
        "see variable sctypes for which ones you"
    ],
    [
        "As part of the type-hierarchy:    xx -- is bit-width",
        "As part of the type-hierarchy: xx --"
    ],
    [
        "|   |   +-> signedinteger     (intxx)      (kind=i)",
        "| | +-> signedinteger (intxx)"
    ],
    [
        "|   |   \\\\-> unsignedinteger  (uintxx)     (kind=u)",
        "| | \\\\-> unsignedinteger (uintxx)"
    ],
    [
        "\\\\-> object_ (not used much)               (kind=O)",
        "\\\\-> object_ (not used much)"
    ],
    [
        "from . import multiarray as ma",
        "from . import multiarray"
    ],
    [
        "Return the scalar type of highest precision of the same kind as the input.",
        "Return the scalar type of highest precision of the same kind as the"
    ],
    [
        "t : dtype or dtype specifier",
        "t : dtype"
    ],
    [
        "The input data type. This can be a `dtype` object or an object that",
        "The input data type. This can be a"
    ],
    [
        "The highest precision data type of the same kind (`dtype.kind`) as `t`.",
        "The highest precision data type of the same kind (`dtype.kind`) as"
    ],
    [
        "Determines whether the given object represents a scalar data-type.",
        "Determines whether the given object represents a"
    ],
    [
        "If `rep` is an instance of a scalar dtype, True is returned. If not,",
        "If `rep` is an instance of a scalar"
    ],
    [
        "Boolean result of check whether `rep` is a scalar dtype.",
        "Boolean result of check whether"
    ],
    [
        "Strings are also a scalar type:",
        "Strings are also a scalar"
    ],
    [
        "if res and res != object_:",
        "if res and res !="
    ],
    [
        "Return the scalar dtype or NumPy equivalent of Python type of an object.",
        "Return the scalar dtype or NumPy equivalent of"
    ],
    [
        "The object of which the type is returned.",
        "The object of which the"
    ],
    [
        "If given, this is returned for objects whose types can not be",
        "If given, this is returned for objects whose"
    ],
    [
        "determined. If not given, None is returned for those objects.",
        "determined. If not given, None is"
    ],
    [
        "dtype : dtype or Python type",
        "dtype : dtype or Python"
    ],
    [
        "if isinstance(rep, type) and issubclass(rep, generic):",
        "if isinstance(rep, type)"
    ],
    [
        "Determine if a class is a subclass of a second class.",
        "Determine if a class is a subclass of a"
    ],
    [
        "`issubclass_` is equivalent to the Python built-in ``issubclass``,",
        "`issubclass_` is equivalent to"
    ],
    [
        "except that it returns False instead of raising a TypeError if one",
        "except that it returns False instead of raising"
    ],
    [
        "of the arguments is not a class.",
        "of the arguments is not"
    ],
    [
        "subclass of any of the tuple elements.",
        "subclass of any of the tuple"
    ],
    [
        "Determine if the first argument is a subclass of the second argument.",
        "Determine if the first argument is a"
    ],
    [
        "if isinstance(dtype, ndarray) or dtype not in allTypes.values():",
        "if isinstance(dtype, ndarray) or dtype"
    ],
    [
        "Determine if a provided dtype is of a specified data type ``kind``.",
        "Determine if a provided dtype is of"
    ],
    [
        "This function only supports built-in NumPy's data types.",
        "This function only supports built-in NumPy's"
    ],
    [
        "Third-party dtypes are not yet supported.",
        "Third-party dtypes are not"
    ],
    [
        "kind : dtype or str or tuple of dtypes/strs.",
        "kind : dtype or str or tuple"
    ],
    [
        "dtype or dtype kind. Allowed dtype kinds are:",
        "dtype or dtype kind. Allowed"
    ],
    [
        "* ``'signed integer'`` : signed integer data types",
        "* ``'signed integer'`` : signed integer data"
    ],
    [
        "* ``'unsigned integer'`` : unsigned integer data types",
        "* ``'unsigned integer'`` : unsigned integer"
    ],
    [
        "* ``'integral'`` : integer data types",
        "* ``'integral'`` : integer"
    ],
    [
        "* ``'real floating'`` : real-valued floating-point data types",
        "* ``'real floating'`` : real-valued floating-point data"
    ],
    [
        "* ``'complex floating'`` : complex floating-point data types",
        "* ``'complex floating'`` : complex floating-point"
    ],
    [
        "* ``'numeric'`` : numeric data types",
        "* ``'numeric'`` : numeric data"
    ],
    [
        "\"dtype argument must be a NumPy dtype, \"",
        "\"dtype argument must be a NumPy"
    ],
    [
        "input_kinds = kind if isinstance(kind, tuple) else (kind,)",
        "input_kinds = kind if"
    ],
    [
        "\"kind argument is a string, but\"",
        "\"kind argument is a"
    ],
    [
        "f\" {kind!r} is not a known kind name.\"",
        "f\" {kind!r} is not"
    ],
    [
        "\"kind argument must be comprised of \"",
        "\"kind argument must be comprised of"
    ],
    [
        "\"NumPy dtypes or strings only, \"",
        "\"NumPy dtypes or"
    ],
    [
        "Returns True if first argument is a typecode lower/equal in type hierarchy.",
        "Returns True if first argument is a typecode lower/equal in"
    ],
    [
        "This is like the builtin :func:`issubclass`, but for `dtype`\\ s.",
        "This is like the builtin :func:`issubclass`,"
    ],
    [
        "`dtype` or object coercible to one",
        "`dtype` or object"
    ],
    [
        ":ref:`arrays.scalars` : Overview of the numpy type hierarchy.",
        ":ref:`arrays.scalars` : Overview of the"
    ],
    [
        "`issubdtype` can be used to check the type of arrays:",
        "`issubdtype` can be used to check"
    ],
    [
        "Similar types of different sizes are not subdtypes of each other:",
        "Similar types of different sizes are not subdtypes of each"
    ],
    [
        "but both are subtypes of `floating`:",
        "but both are subtypes"
    ],
    [
        "For convenience, dtype-like objects are allowed too:",
        "For convenience, dtype-like objects"
    ],
    [
        "Return the string representation of a scalar dtype.",
        "Return the string representation of"
    ],
    [
        "sctype : scalar dtype or object",
        "sctype : scalar dtype"
    ],
    [
        "If a scalar dtype, the corresponding string character is",
        "If a scalar dtype, the corresponding string"
    ],
    [
        "and then return the corresponding string character.",
        "and then return the corresponding string"
    ],
    [
        "The string character corresponding to the scalar type.",
        "The string character corresponding to the scalar"
    ],
    [
        "If `sctype` is an object for which the type can not be inferred.",
        "If `sctype` is an object for which the type can"
    ],
    [
        "ScalarType = [int, float, complex, bool, bytes, str, memoryview]",
        "ScalarType = [int, float, complex, bool,"
    ],
    [
        "Due to compatibility, numpy has a very large number of different naming",
        "Due to compatibility, numpy has a very"
    ],
    [
        "conventions for the scalar types (those subclassing from `numpy.generic`).",
        "conventions for the scalar types (those subclassing"
    ],
    [
        "This file produces a convoluted set of dictionaries mapping names to types,",
        "This file produces a convoluted set of"
    ],
    [
        "A dictionary of names to types that will be exposed as attributes through",
        "A dictionary of names to types that will be exposed"
    ],
    [
        "Similar to `allTypes`, but maps a broader set of aliases to their types.",
        "Similar to `allTypes`, but maps a broader set of"
    ],
    [
        "A dictionary keyed by a \"type group\" string, providing a list of types",
        "A dictionary keyed by a \"type group\" string, providing a list"
    ],
    [
        "if k.startswith(\"NPY_\") and v not in c_names_dict:",
        "if k.startswith(\"NPY_\") and v not in"
    ],
    [
        "for is_complex, full_name in [(False, \"longdouble\"), (True, \"clongdouble\")]:",
        "for is_complex, full_name in [(False, \"longdouble\"),"
    ],
    [
        "base_name: str = \"complex\" if is_complex else \"float\"",
        "base_name: str = \"complex\" if"
    ],
    [
        "sctypes = {\"int\": set(), \"uint\": set(), \"float\": set(),",
        "sctypes = {\"int\": set(), \"uint\": set(),"
    ],
    [
        "\"\"\"Simple script to compute the api hash of the current API.",
        "\"\"\"Simple script to compute the api hash of the"
    ],
    [
        "The API has is defined by numpy_api_order and ufunc_api_order.",
        "The API has is defined by numpy_api_order"
    ],
    [
        "Stores and defines the low-level format_options context variable.",
        "Stores and defines the low-level format_options"
    ],
    [
        "This is defined in its own file outside of the arrayprint module",
        "This is defined in its own file outside of the"
    ],
    [
        "so we can import it from C while initializing the multiarray",
        "so we can import it from C"
    ],
    [
        "C module during import without introducing circular dependencies.",
        "C module during import"
    ],
    [
        "This module contains a set of functions for vectorized string",
        "This module contains a set of"
    ],
    [
        "equal, not_equal, less, less_equal, greater, greater_equal,",
        "equal, not_equal, less,"
    ],
    [
        "isalnum, isalpha, isdecimal, isdigit, islower, isnumeric, isspace,",
        "isalnum, isalpha, isdecimal, isdigit, islower, isnumeric,"
    ],
    [
        "\"equal\", \"not_equal\", \"less\", \"less_equal\", \"greater\", \"greater_equal\",",
        "\"equal\", \"not_equal\", \"less\", \"less_equal\", \"greater\","
    ],
    [
        "\"add\", \"multiply\", \"isalpha\", \"isdigit\", \"isspace\", \"isalnum\", \"islower\",",
        "\"add\", \"multiply\", \"isalpha\", \"isdigit\", \"isspace\", \"isalnum\","
    ],
    [
        "\"isupper\", \"istitle\", \"isdecimal\", \"isnumeric\", \"str_len\", \"find\",",
        "\"isupper\", \"istitle\", \"isdecimal\", \"isnumeric\","
    ],
    [
        "\"rfind\", \"index\", \"rindex\", \"count\", \"startswith\", \"endswith\", \"lstrip\",",
        "\"rfind\", \"index\", \"rindex\", \"count\", \"startswith\","
    ],
    [
        "\"rstrip\", \"strip\", \"replace\", \"expandtabs\", \"center\", \"ljust\", \"rjust\",",
        "\"rstrip\", \"strip\", \"replace\", \"expandtabs\", \"center\", \"ljust\","
    ],
    [
        "Helper function that returns the number of characters per field in",
        "Helper function that returns the number of characters per field"
    ],
    [
        "a string or unicode array.  This is to abstract out the fact that",
        "a string or unicode array. This is to abstract out"
    ],
    [
        "Helper function to cast a result back into an array",
        "Helper function to cast a result back into an"
    ],
    [
        "with the appropriate dtype if an object array must be used",
        "with the appropriate dtype if an object array"
    ],
    [
        "Helper function for delegating arguments to Python string",
        "Helper function for delegating"
    ],
    [
        "Many of the Python string operations that have optional arguments",
        "Many of the Python string operations"
    ],
    [
        "do not use 'None' to indicate a default value.  In these cases,",
        "do not use 'None' to indicate a default value."
    ],
    [
        "we need to remove all None arguments, and those following them.",
        "we need to remove all None"
    ],
    [
        "Return (a * i), that is string multiple concatenation,",
        "Return (a * i), that is string multiple"
    ],
    [
        "a : array_like, with ``StringDType``, ``bytes_`` or ``str_`` dtype",
        "a : array_like, with ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "i : array_like, with any integer dtype",
        "i : array_like, with any"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or"
    ],
    [
        ">>> a = np.array([\"a\", \"b\", \"c\"])",
        ">>> a = np.array([\"a\","
    ],
    [
        "raise TypeError(f\"unsupported type {i.dtype} for operand 'i'\")",
        "raise TypeError(f\"unsupported type {i.dtype} for"
    ],
    [
        "raise MemoryError(\"repeated string is too long\")",
        "raise MemoryError(\"repeated string is"
    ],
    [
        "(interpolation), element-wise for a pair of array_likes of str",
        "(interpolation), element-wise for a pair of"
    ],
    [
        "a : array_like, with `np.bytes_` or `np.str_` dtype",
        "a : array_like, with `np.bytes_`"
    ],
    [
        "These values will be element-wise interpolated into the string.",
        "These values will be element-wise interpolated into the"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        ">>> a = np.array([\"NumPy is a %s library\"])",
        ">>> a = np.array([\"NumPy is"
    ],
    [
        ">>> a = np.array([b'%d bytes', b'%d bits'])",
        ">>> a = np.array([b'%d bytes',"
    ],
    [
        "For each element, return the lowest index in the string where",
        "For each element, return the lowest index in"
    ],
    [
        "substring ``sub`` is found, such that ``sub`` is contained in the",
        "substring ``sub`` is found, such that ``sub`` is contained in"
    ],
    [
        "a : array_like, with ``StringDType``, ``bytes_`` or ``str_`` dtype",
        "a : array_like, with ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "sub : array_like, with `np.bytes_` or `np.str_` dtype",
        "sub : array_like, with `np.bytes_`"
    ],
    [
        "start, end : array_like, with any integer dtype",
        "start, end : array_like, with"
    ],
    [
        "The range to look in, interpreted as in slice notation.",
        "The range to look in, interpreted as"
    ],
    [
        ">>> a = np.array([\"NumPy is a Python library\"])",
        ">>> a = np.array([\"NumPy"
    ],
    [
        "end = end if end is not None else MAX",
        "end = end if end is not None else"
    ],
    [
        "For each element, return the highest index in the string where",
        "For each element, return the highest index"
    ],
    [
        "substring ``sub`` is found, such that ``sub`` is contained in the",
        "substring ``sub`` is found, such that"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``,"
    ],
    [
        "sub : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "sub : array-like, with ``StringDType``, ``bytes_``, or"
    ],
    [
        "start, end : array_like, with any integer dtype",
        "start, end : array_like, with any integer"
    ],
    [
        "The range to look in, interpreted as in slice notation.",
        "The range to look in, interpreted"
    ],
    [
        ">>> b = np.array([\"Computer Science\", \"Science\"])",
        ">>> b = np.array([\"Computer"
    ],
    [
        "end = end if end is not None else MAX",
        "end = end if end is not None else"
    ],
    [
        "Like `find`, but raises :exc:`ValueError` when the substring is not found.",
        "Like `find`, but raises :exc:`ValueError` when the substring"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "sub : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "sub : array-like, with ``StringDType``, ``bytes_``, or"
    ],
    [
        "start, end : array_like, with any integer dtype, optional",
        "start, end : array_like, with any integer dtype,"
    ],
    [
        "end = end if end is not None else MAX",
        "end = end if end is not None else"
    ],
    [
        "Like `rfind`, but raises :exc:`ValueError` when the substring `sub` is",
        "Like `rfind`, but raises :exc:`ValueError`"
    ],
    [
        "a : array-like, with `np.bytes_` or `np.str_` dtype",
        "a : array-like, with `np.bytes_` or"
    ],
    [
        "sub : array-like, with `np.bytes_` or `np.str_` dtype",
        "sub : array-like, with `np.bytes_` or"
    ],
    [
        "start, end : array-like, with any integer dtype, optional",
        "start, end : array-like, with any integer dtype,"
    ],
    [
        "end = end if end is not None else MAX",
        "end = end if end is not None else"
    ],
    [
        "Returns an array with the number of non-overlapping occurrences of",
        "Returns an array with the number of non-overlapping occurrences"
    ],
    [
        "substring ``sub`` in the range [``start``, ``end``).",
        "substring ``sub`` in the"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``,"
    ],
    [
        "sub : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "sub : array-like, with ``StringDType``,"
    ],
    [
        "start, end : array_like, with any integer dtype",
        "start, end : array_like, with"
    ],
    [
        "The range to look in, interpreted as in slice notation.",
        "The range to look in,"
    ],
    [
        ">>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> c = np.array(['aAaAaA',"
    ],
    [
        "end = end if end is not None else MAX",
        "end = end if end"
    ],
    [
        "Returns a boolean array which is `True` where the string element",
        "Returns a boolean array which is `True` where the string"
    ],
    [
        "in ``a`` starts with ``prefix``, otherwise `False`.",
        "in ``a`` starts with"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "prefix : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "prefix : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "start, end : array_like, with any integer dtype",
        "start, end : array_like, with any integer"
    ],
    [
        "With ``start``, test beginning at that position. With ``end``,",
        "With ``start``, test beginning at that position."
    ],
    [
        "end = end if end is not None else MAX",
        "end = end if end is"
    ],
    [
        "Returns a boolean array which is `True` where the string element",
        "Returns a boolean array which is `True` where the string"
    ],
    [
        "in ``a`` ends with ``suffix``, otherwise `False`.",
        "in ``a`` ends with"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "suffix : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "suffix : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "start, end : array_like, with any integer dtype",
        "start, end : array_like, with any integer"
    ],
    [
        "With ``start``, test beginning at that position. With ``end``,",
        "With ``start``, test beginning at that"
    ],
    [
        "end = end if end is not None else MAX",
        "end = end if end is"
    ],
    [
        "The set of available codecs comes from the Python standard library,",
        "The set of available codecs comes from the"
    ],
    [
        "and may be extended at runtime.  For more information, see the",
        "and may be extended at runtime. For more information,"
    ],
    [
        "a : array_like, with ``bytes_`` dtype",
        "a : array_like, with"
    ],
    [
        "Specifies how to handle encoding errors",
        "Specifies how to"
    ],
    [
        "The type of the result will depend on the encoding specified.",
        "The type of the result will depend on the encoding"
    ],
    [
        "The set of available codecs comes from the Python standard library,",
        "The set of available codecs comes from the Python standard"
    ],
    [
        "and may be extended at runtime. For more information, see the",
        "and may be extended at runtime. For more information, see"
    ],
    [
        "a : array_like, with ``StringDType`` or ``str_`` dtype",
        "a : array_like, with ``StringDType``"
    ],
    [
        "Specifies how to handle encoding errors",
        "Specifies how to handle encoding"
    ],
    [
        "The type of the result will depend on the encoding specified.",
        "The type of the result will"
    ],
    [
        ">>> a = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> a = np.array(['aAaAaA', '"
    ],
    [
        "Return a copy of each string element where all tab characters are",
        "Return a copy of each string element"
    ],
    [
        "replaced by one or more spaces.",
        "replaced by one"
    ],
    [
        "Return a copy of each string element where all tab characters are",
        "Return a copy of each string"
    ],
    [
        "replaced by one or more spaces, depending on the current column",
        "replaced by one or more spaces, depending on the current"
    ],
    [
        "and the given `tabsize`. The column number is reset to zero after",
        "and the given `tabsize`. The column number is reset to"
    ],
    [
        "each newline occurring in the string. This doesn't understand other",
        "each newline occurring in the string. This"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "Replace tabs with `tabsize` number of spaces.  If not given defaults",
        "Replace tabs with `tabsize` number of spaces. If"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or"
    ],
    [
        "Return a copy of `a` with its elements centered in a string of",
        "Return a copy of `a` with its elements centered in a"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "width : array_like, with any integer dtype",
        "width : array_like, with"
    ],
    [
        "The length of the resulting strings, unless ``width < str_len(a)``.",
        "The length of the resulting strings, unless"
    ],
    [
        "fillchar : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "fillchar : array-like, with ``StringDType``, ``bytes_``, or"
    ],
    [
        "Optional padding character to use (default is space).",
        "Optional padding character to use"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "While it is possible for ``a`` and ``fillchar`` to have different dtypes,",
        "While it is possible for ``a`` and ``fillchar`` to have"
    ],
    [
        "passing a non-ASCII character in ``fillchar`` when ``a`` is of dtype \"S\"",
        "passing a non-ASCII character in ``fillchar`` when ``a`` is"
    ],
    [
        "is not allowed, and a ``ValueError`` is raised.",
        "is not allowed, and a ``ValueError``"
    ],
    [
        "raise TypeError(f\"unsupported type {width.dtype} for operand 'width'\")",
        "raise TypeError(f\"unsupported type {width.dtype} for operand"
    ],
    [
        "\"The fill character must be exactly one character long\")",
        "\"The fill character must be exactly one character"
    ],
    [
        "Return an array with the elements of `a` left-justified in a",
        "Return an array with the elements of `a` left-justified in"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "width : array_like, with any integer dtype",
        "width : array_like, with"
    ],
    [
        "The length of the resulting strings, unless ``width < str_len(a)``.",
        "The length of the resulting strings, unless ``width"
    ],
    [
        "fillchar : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "fillchar : array-like, with ``StringDType``,"
    ],
    [
        "Optional character to use for padding (default is space).",
        "Optional character to use for padding (default"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_``"
    ],
    [
        "While it is possible for ``a`` and ``fillchar`` to have different dtypes,",
        "While it is possible for ``a`` and ``fillchar``"
    ],
    [
        "passing a non-ASCII character in ``fillchar`` when ``a`` is of dtype \"S\"",
        "passing a non-ASCII character in ``fillchar`` when ``a`` is of dtype"
    ],
    [
        "is not allowed, and a ``ValueError`` is raised.",
        "is not allowed, and a ``ValueError`` is"
    ],
    [
        ">>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> c = np.array(['aAaAaA', ' aA"
    ],
    [
        "raise TypeError(f\"unsupported type {width.dtype} for operand 'width'\")",
        "raise TypeError(f\"unsupported type {width.dtype}"
    ],
    [
        "\"The fill character must be exactly one character long\")",
        "\"The fill character must be exactly one"
    ],
    [
        "Return an array with the elements of `a` right-justified in a",
        "Return an array with the elements of"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "width : array_like, with any integer dtype",
        "width : array_like, with any"
    ],
    [
        "The length of the resulting strings, unless ``width < str_len(a)``.",
        "The length of the resulting strings, unless"
    ],
    [
        "fillchar : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "fillchar : array-like, with ``StringDType``, ``bytes_``, or"
    ],
    [
        "Optional padding character to use (default is space).",
        "Optional padding character to use (default"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_``"
    ],
    [
        "While it is possible for ``a`` and ``fillchar`` to have different dtypes,",
        "While it is possible for ``a``"
    ],
    [
        "passing a non-ASCII character in ``fillchar`` when ``a`` is of dtype \"S\"",
        "passing a non-ASCII character in ``fillchar`` when"
    ],
    [
        "is not allowed, and a ``ValueError`` is raised.",
        "is not allowed, and a ``ValueError``"
    ],
    [
        ">>> a = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> a = np.array(['aAaAaA', '"
    ],
    [
        "raise TypeError(f\"unsupported type {width.dtype} for operand 'width'\")",
        "raise TypeError(f\"unsupported type {width.dtype}"
    ],
    [
        "\"The fill character must be exactly one character long\")",
        "\"The fill character must be exactly one"
    ],
    [
        "Return the numeric string left-filled with zeros. A leading",
        "Return the numeric string left-filled with"
    ],
    [
        "sign prefix (``+``/``-``) is handled by inserting the padding",
        "sign prefix (``+``/``-``) is handled by"
    ],
    [
        "after the sign character rather than before.",
        "after the sign character rather"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "width : array_like, with any integer dtype",
        "width : array_like, with any integer"
    ],
    [
        "Width of string to left-fill elements in `a`.",
        "Width of string to left-fill elements in"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or"
    ],
    [
        "raise TypeError(f\"unsupported type {width.dtype} for operand 'width'\")",
        "raise TypeError(f\"unsupported type {width.dtype}"
    ],
    [
        "For each element in `a`, return a copy with the leading characters",
        "For each element in `a`, return a copy with the"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "chars : scalar with the same dtype as ``a``, optional",
        "chars : scalar with the"
    ],
    [
        "The ``chars`` argument is a string specifying the set of",
        "The ``chars`` argument is a"
    ],
    [
        "characters to be removed. If ``None``, the ``chars``",
        "characters to be removed. If ``None``, the"
    ],
    [
        "argument defaults to removing whitespace. The ``chars`` argument",
        "argument defaults to removing whitespace."
    ],
    [
        "is not a prefix or suffix; rather, all combinations of its",
        "is not a prefix or suffix; rather,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        ">>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> c = np.array(['aAaAaA', ' aA ',"
    ],
    [
        ">>> (np.strings.lstrip(c, ' ') == np.strings.lstrip(c, '')).all()",
        ">>> (np.strings.lstrip(c, ' ')"
    ],
    [
        ">>> (np.strings.lstrip(c, ' ') == np.strings.lstrip(c)).all()",
        ">>> (np.strings.lstrip(c, ' ') =="
    ],
    [
        "For each element in `a`, return a copy with the trailing characters",
        "For each element in `a`, return"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "chars : scalar with the same dtype as ``a``, optional",
        "chars : scalar with the"
    ],
    [
        "The ``chars`` argument is a string specifying the set of",
        "The ``chars`` argument is a string specifying"
    ],
    [
        "characters to be removed. If ``None``, the ``chars``",
        "characters to be removed. If"
    ],
    [
        "argument defaults to removing whitespace. The ``chars`` argument",
        "argument defaults to removing whitespace. The ``chars``"
    ],
    [
        "is not a prefix or suffix; rather, all combinations of its",
        "is not a prefix or suffix; rather,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or"
    ],
    [
        "For each element in `a`, return a copy with the leading and",
        "For each element in `a`, return a copy with the"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "chars : scalar with the same dtype as ``a``, optional",
        "chars : scalar with the"
    ],
    [
        "The ``chars`` argument is a string specifying the set of",
        "The ``chars`` argument is a string specifying"
    ],
    [
        "characters to be removed. If ``None``, the ``chars``",
        "characters to be removed. If ``None``,"
    ],
    [
        "argument defaults to removing whitespace. The ``chars`` argument",
        "argument defaults to removing"
    ],
    [
        "is not a prefix or suffix; rather, all combinations of its",
        "is not a prefix or suffix; rather,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_``"
    ],
    [
        ">>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> c = np.array(['aAaAaA', ' aA ',"
    ],
    [
        "Return an array with the elements converted to uppercase.",
        "Return an array with the elements converted"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``,"
    ],
    [
        "Return an array with the elements converted to lowercase.",
        "Return an array with the"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "Return element-wise a copy of the string with",
        "Return element-wise a copy of the"
    ],
    [
        "uppercase characters converted to lowercase and vice versa.",
        "uppercase characters converted to"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "Return a copy of ``a`` with only the first character of each element",
        "Return a copy of ``a`` with only the first character of each"
    ],
    [
        "For byte strings, this method is locale-dependent.",
        "For byte strings, this method is"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "Input array of strings to capitalize.",
        "Input array of strings to"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``,"
    ],
    [
        "Return element-wise title cased version of string or unicode.",
        "Return element-wise title cased version of string or"
    ],
    [
        "Title case words start with uppercase characters, all remaining cased",
        "Title case words start with uppercase"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``,"
    ],
    [
        "For each element in ``a``, return a copy of the string with",
        "For each element in ``a``, return"
    ],
    [
        "occurrences of substring ``old`` replaced by ``new``.",
        "occurrences of substring ``old``"
    ],
    [
        "a : array_like, with ``bytes_`` or ``str_`` dtype",
        "a : array_like, with ``bytes_`` or"
    ],
    [
        "old, new : array_like, with ``bytes_`` or ``str_`` dtype",
        "old, new : array_like, with ``bytes_``"
    ],
    [
        "count : array_like, with ``int_`` dtype",
        "count : array_like,"
    ],
    [
        "If the optional argument ``count`` is given, only the first",
        "If the optional argument ``count``"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``,"
    ],
    [
        ">>> a = np.array([\"That is a mango\", \"Monkeys eat mangos\"])",
        ">>> a = np.array([\"That is"
    ],
    [
        ">>> a = np.array([\"The dish is fresh\", \"This is it\"])",
        ">>> a = np.array([\"The dish is fresh\","
    ],
    [
        "raise TypeError(f\"unsupported type {count.dtype} for operand 'count'\")",
        "raise TypeError(f\"unsupported type {count.dtype}"
    ],
    [
        "if np.result_type(arr, old, new).char == \"T\":",
        "if np.result_type(arr, old, new).char =="
    ],
    [
        "old = old.astype(old_dtype if old_dtype else a_dt, copy=False)",
        "old = old.astype(old_dtype if old_dtype else a_dt,"
    ],
    [
        "new = new.astype(new_dtype if new_dtype else a_dt, copy=False)",
        "new = new.astype(new_dtype if new_dtype else a_dt,"
    ],
    [
        "buffersizes = str_len(arr) + counts * (str_len(new) - str_len(old))",
        "buffersizes = str_len(arr) + counts * (str_len(new) -"
    ],
    [
        "return _replace(arr, old, new, counts, out=out)",
        "return _replace(arr, old, new,"
    ],
    [
        "Return a string which is the concatenation of the strings in the",
        "Return a string which is the concatenation"
    ],
    [
        "sep : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "sep : array-like, with ``StringDType``, ``bytes_``, or"
    ],
    [
        "seq : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "seq : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "For each element in `a`, return a list of the words in the",
        "For each element in `a`, return a list"
    ],
    [
        "string, using `sep` as the delimiter string.",
        "string, using `sep` as the delimiter"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "sep : str or unicode, optional",
        "sep : str or unicode,"
    ],
    [
        "If `sep` is not specified or None, any whitespace string is a",
        "If `sep` is not specified or None, any"
    ],
    [
        "If `maxsplit` is given, at most `maxsplit` splits are done.",
        "If `maxsplit` is given, at most"
    ],
    [
        ">>> x = np.array(\"Numpy is nice!\")",
        ">>> x = np.array(\"Numpy is"
    ],
    [
        "a, np.object_, 'split', [sep] + _clean_args(maxsplit))",
        "a, np.object_, 'split', [sep]"
    ],
    [
        "For each element in `a`, return a list of the words in the",
        "For each element in `a`, return a list of the words"
    ],
    [
        "string, using `sep` as the delimiter string.",
        "string, using `sep` as"
    ],
    [
        "Except for splitting from the right, `rsplit`",
        "Except for splitting from"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or"
    ],
    [
        "sep : str or unicode, optional",
        "sep : str or unicode,"
    ],
    [
        "If `sep` is not specified or None, any whitespace string",
        "If `sep` is not specified or None,"
    ],
    [
        "If `maxsplit` is given, at most `maxsplit` splits are done,",
        "If `maxsplit` is given, at most `maxsplit` splits"
    ],
    [
        "a, np.object_, 'rsplit', [sep] + _clean_args(maxsplit))",
        "a, np.object_, 'rsplit',"
    ],
    [
        "For each element in `a`, return a list of the lines in the",
        "For each element in `a`, return a list of"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "Line breaks are not included in the resulting list unless",
        "Line breaks are not included"
    ],
    [
        "Partition each element in ``a`` around ``sep``.",
        "Partition each element in ``a`` around"
    ],
    [
        "For each element in ``a``, split the element at the first",
        "For each element in ``a``, split the element at"
    ],
    [
        "before the separator, the separator itself, and the part after",
        "before the separator, the separator itself, and the part"
    ],
    [
        "the separator. If the separator is not found, the first item of",
        "the separator. If the separator is not found, the first item"
    ],
    [
        "the tuple will contain the whole string, and the second and third",
        "the tuple will contain the whole"
    ],
    [
        "ones will be the empty string.",
        "ones will be the"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "sep : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "sep : array-like, with ``StringDType``, ``bytes_``, or"
    ],
    [
        "Separator to split each string element in ``a``.",
        "Separator to split each string"
    ],
    [
        "- array with ``StringDType``, ``bytes_`` or ``str_`` dtype with the",
        "- array with ``StringDType``, ``bytes_`` or"
    ],
    [
        "- array with ``StringDType``, ``bytes_`` or ``str_`` dtype with the",
        "- array with ``StringDType``, ``bytes_`` or ``str_`` dtype"
    ],
    [
        "- array with ``StringDType``, ``bytes_`` or ``str_`` dtype with the",
        "- array with ``StringDType``, ``bytes_`` or ``str_`` dtype with"
    ],
    [
        ">>> x = np.array([\"Numpy is nice!\"])",
        ">>> x = np.array([\"Numpy"
    ],
    [
        "out_dtype = \",\".join([f\"{a.dtype.char}{n}\" for n in (",
        "out_dtype = \",\".join([f\"{a.dtype.char}{n}\" for"
    ],
    [
        "Partition (split) each element around the right-most separator.",
        "Partition (split) each element around"
    ],
    [
        "For each element in ``a``, split the element at the last",
        "For each element in ``a``, split the element at the"
    ],
    [
        "before the separator, the separator itself, and the part after",
        "before the separator, the separator itself, and the part"
    ],
    [
        "the separator. If the separator is not found, the third item of",
        "the separator. If the separator is not found,"
    ],
    [
        "the tuple will contain the whole string, and the first and second",
        "the tuple will contain the whole"
    ],
    [
        "ones will be the empty string.",
        "ones will be the empty"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``,"
    ],
    [
        "sep : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "sep : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "Separator to split each string element in ``a``.",
        "Separator to split each string"
    ],
    [
        "- array with ``StringDType``, ``bytes_`` or ``str_`` dtype with the",
        "- array with ``StringDType``, ``bytes_`` or"
    ],
    [
        "- array with ``StringDType``, ``bytes_`` or ``str_`` dtype with the",
        "- array with ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "- array with ``StringDType``, ``bytes_`` or ``str_`` dtype with the",
        "- array with ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        ">>> a = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> a = np.array(['aAaAaA', ' aA"
    ],
    [
        "out_dtype = \",\".join([f\"{a.dtype.char}{n}\" for n in (",
        "out_dtype = \",\".join([f\"{a.dtype.char}{n}\" for n"
    ],
    [
        "For each element in `a`, return a copy of the string where all",
        "For each element in `a`, return a copy of the string"
    ],
    [
        "characters occurring in the optional argument `deletechars` are",
        "characters occurring in the"
    ],
    [
        "removed, and the remaining characters have been mapped through the",
        "removed, and the remaining characters have been mapped through"
    ],
    [
        "a : array-like, with `np.bytes_` or `np.str_` dtype",
        "a : array-like, with `np.bytes_` or `np.str_`"
    ],
    [
        "Output array of str or unicode, depending on input type",
        "Output array of str or"
    ],
    [
        "def slice(a, start=None, stop=None, step=None, /):",
        "def slice(a, start=None, stop=None, step=None,"
    ],
    [
        "Slice the strings in `a` by slices specified by `start`, `stop`, `step`.",
        "Slice the strings in `a` by"
    ],
    [
        "Like in the regular Python `slice` object, if only `start` is",
        "Like in the regular Python `slice` object, if only"
    ],
    [
        "specified then it is interpreted as the `stop`.",
        "specified then it is interpreted as the"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``,"
    ],
    [
        "start : None, an integer or an array of integers",
        "start : None, an integer or"
    ],
    [
        "The start of the slice, broadcasted to `a`'s shape",
        "The start of the slice, broadcasted"
    ],
    [
        "stop : None, an integer or an array of integers",
        "stop : None, an integer"
    ],
    [
        "The end of the slice, broadcasted to `a`'s shape",
        "The end of the slice, broadcasted"
    ],
    [
        "step : None, an integer or an array of integers",
        "step : None, an integer or an array of"
    ],
    [
        "The step for the slice, broadcasted to `a`'s shape",
        "The step for the slice, broadcasted to"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or"
    ],
    [
        "One can specify different start/stop/step for different array entries:",
        "One can specify different start/stop/step for"
    ],
    [
        "Negative slices have the same meaning as in regular Python:",
        "Negative slices have the same meaning as"
    ],
    [
        ">>> b = np.array(['hello world', 'Î³ÎµÎ¹Î± ÏƒÎ¿Ï… ÎºÏŒÏƒÎ¼Îµ', 'ä½ å¥½ä¸–ç•Œ', 'ðŸ‘‹ ðŸŒ'],",
        ">>> b = np.array(['hello world', 'Î³ÎµÎ¹Î± ÏƒÎ¿Ï… ÎºÏŒÏƒÎ¼Îµ',"
    ],
    [
        "array(['hello wor', 'Î³ÎµÎ¹Î± ÏƒÎ¿Ï… ÎºÏŒÏƒ', 'ä½ å¥½', 'ðŸ‘‹'], dtype=StringDType())",
        "array(['hello wor', 'Î³ÎµÎ¹Î± ÏƒÎ¿Ï… ÎºÏŒÏƒ', 'ä½ å¥½', 'ðŸ‘‹'],"
    ],
    [
        "array(['lo worl', ' ÏƒÎ¿Ï… ÎºÏŒÏƒ', 'ä¸–', 'ðŸ‘‹ ðŸŒ'], dtype=StringDType())",
        "array(['lo worl', ' ÏƒÎ¿Ï… ÎºÏŒÏƒ',"
    ],
    [
        "array(['dlrow olleh', 'ÎµÎ¼ÏƒÏŒÎº Ï…Î¿Ïƒ Î±Î¹ÎµÎ³', 'ç•Œä¸–å¥½ä½ ', 'ðŸŒ ðŸ‘‹'],",
        "array(['dlrow olleh', 'ÎµÎ¼ÏƒÏŒÎº Ï…Î¿Ïƒ Î±Î¹ÎµÎ³',"
    ],
    [
        "raise TypeError(f\"unsupported type {step.dtype} for operand 'step'\")",
        "raise TypeError(f\"unsupported type {step.dtype} for"
    ],
    [
        "raise ValueError(\"slice step cannot be zero\")",
        "raise ValueError(\"slice step cannot be"
    ],
    [
        "from . import numerictypes as _nt",
        "from . import numerictypes"
    ],
    [
        "from .umath import absolute, isinf, isfinite, isnat",
        "from .umath import absolute, isinf,"
    ],
    [
        "from .numeric import concatenate, asarray, errstate",
        "from .numeric import concatenate, asarray,"
    ],
    [
        "Make a dictionary out of the non-None arguments, plus conversion of",
        "Make a dictionary out of the non-None arguments,"
    ],
    [
        "options = {k: v for k, v in list(locals().items()) if v is not None}",
        "options = {k: v for k, v in list(locals().items()) if v is"
    ],
    [
        "modes = ['fixed', 'unique', 'maxprec', 'maxprec_equal']",
        "modes = ['fixed', 'unique', 'maxprec',"
    ],
    [
        "if floatmode not in modes + [None]:",
        "if floatmode not in modes"
    ],
    [
        "raise ValueError(\"floatmode option must be one of \" +",
        "raise ValueError(\"floatmode option must be"
    ],
    [
        "\", \".join('\"{}\"'.format(m) for m in modes))",
        "\", \".join('\"{}\"'.format(m) for"
    ],
    [
        "if sign not in [None, '-', '+', ' ']:",
        "if sign not in [None,"
    ],
    [
        "raise ValueError(\"sign option must be one of ' ', '+', or '-'\")",
        "raise ValueError(\"sign option must be one of '"
    ],
    [
        "raise ValueError(\"threshold must be non-NAN, try \"",
        "raise ValueError(\"threshold must be non-NAN, try"
    ],
    [
        "raise TypeError('precision must be an integer') from e",
        "raise TypeError('precision must be an integer')"
    ],
    [
        "These options determine the way floating point numbers, arrays and",
        "These options determine the way floating point"
    ],
    [
        "precision : int or None, optional",
        "precision : int"
    ],
    [
        "May be None if `floatmode` is not `fixed`, to print as many digits as",
        "May be None if `floatmode` is not `fixed`, to"
    ],
    [
        "necessary to uniquely specify the value.",
        "necessary to uniquely"
    ],
    [
        "Total number of array elements which trigger summarization",
        "Total number of array"
    ],
    [
        "To always use the full repr without summarization, pass `sys.maxsize`.",
        "To always use the full repr without"
    ],
    [
        "Number of array items in summary at beginning and end of",
        "Number of array items in summary at beginning"
    ],
    [
        "The number of characters per line for the purpose of inserting",
        "The number of characters per line for the"
    ],
    [
        "If True, always print floating point numbers using fixed point",
        "If True, always print floating point numbers using fixed"
    ],
    [
        "notation, in which case numbers equal to zero in the current precision",
        "notation, in which case numbers equal to"
    ],
    [
        "will print as zero.  If False, then scientific notation is used when",
        "will print as zero. If False, then scientific notation is used"
    ],
    [
        "String representation of floating point not-a-number (default nan).",
        "String representation of floating point not-a-number (default"
    ],
    [
        "String representation of floating point infinity (default inf).",
        "String representation of floating point infinity"
    ],
    [
        "sign : string, either '-', '+', or ' ', optional",
        "sign : string, either '-', '+', or ' ',"
    ],
    [
        "Controls printing of the sign of floating-point types. If '+', always",
        "Controls printing of the sign of floating-point"
    ],
    [
        "print the sign of positive values. If ' ', always prints a space",
        "print the sign of positive values. If"
    ],
    [
        "(whitespace character) in the sign position of positive values.  If",
        "(whitespace character) in the sign"
    ],
    [
        "'-', omit the sign character of positive values. (default '-')",
        "'-', omit the sign character of positive values. (default"
    ],
    [
        "The sign parameter can now be an integer type, previously",
        "The sign parameter can now be"
    ],
    [
        "formatter : dict of callables, optional",
        "formatter : dict"
    ],
    [
        "If not None, the keys should indicate the type(s) that the respective",
        "If not None, the keys should indicate the type(s) that"
    ],
    [
        "formatting function applies to.  Callables should return a string.",
        "formatting function applies to. Callables"
    ],
    [
        "Types that are not specified (by their corresponding keys) are handled",
        "Types that are not specified (by their"
    ],
    [
        "by the default formatters.  Individual types for which a formatter",
        "by the default formatters. Individual"
    ],
    [
        "- 'numpystr' : types `numpy.bytes_` and `numpy.str_`",
        "- 'numpystr' : types `numpy.bytes_` and"
    ],
    [
        "Other keys that can be used to set a group of types at once are:",
        "Other keys that can be used to set a group"
    ],
    [
        "- 'all' : sets all types",
        "- 'all' : sets"
    ],
    [
        "- 'float_kind' : sets 'float' and 'longfloat'",
        "- 'float_kind' : sets 'float' and"
    ],
    [
        "- 'complex_kind' : sets 'complexfloat' and 'longcomplexfloat'",
        "- 'complex_kind' : sets 'complexfloat' and"
    ],
    [
        "Controls the interpretation of the `precision` option for",
        "Controls the interpretation of the `precision`"
    ],
    [
        "floating-point types. Can take the following values",
        "floating-point types. Can take"
    ],
    [
        "* 'fixed': Always print exactly `precision` fractional digits,",
        "* 'fixed': Always print exactly `precision`"
    ],
    [
        "even if this would print more or fewer digits than",
        "even if this would print more or fewer digits"
    ],
    [
        "necessary to specify the value uniquely.",
        "necessary to specify the"
    ],
    [
        "* 'unique': Print the minimum number of fractional digits necessary",
        "* 'unique': Print the minimum"
    ],
    [
        "to represent each value uniquely. Different elements may",
        "to represent each value uniquely."
    ],
    [
        "have a different number of digits. The value of the",
        "have a different number of digits. The value"
    ],
    [
        "* 'maxprec': Print at most `precision` fractional digits, but if",
        "* 'maxprec': Print at most `precision`"
    ],
    [
        "an element can be uniquely represented with fewer digits",
        "an element can be uniquely represented"
    ],
    [
        "only print it with that many.",
        "only print it with"
    ],
    [
        "* 'maxprec_equal': Print at most `precision` fractional digits,",
        "* 'maxprec_equal': Print at"
    ],
    [
        "but if every element in the array can be uniquely",
        "but if every element in"
    ],
    [
        "represented with an equal number of fewer digits, use that",
        "represented with an equal number"
    ],
    [
        "legacy : string or `False`, optional",
        "legacy : string or"
    ],
    [
        "by not inserting spaces after commas that separate fields and after",
        "by not inserting spaces after commas that"
    ],
    [
        "that numeric scalars are printed without their type information, e.g.",
        "that numeric scalars are printed without their type"
    ],
    [
        "summarized (i.e., multiple elements replaced with ``...``).",
        "summarized (i.e., multiple elements replaced with"
    ],
    [
        "If set to `False`, disables legacy mode.",
        "If set to `False`, disables legacy"
    ],
    [
        "Unrecognized strings will be ignored with a warning for forward",
        "Unrecognized strings will be ignored with"
    ],
    [
        "If set a passed function will be used for generating arrays' repr.",
        "If set a passed function will be"
    ],
    [
        "`formatter` is always reset with a call to `set_printoptions`.",
        "`formatter` is always reset with a"
    ],
    [
        "Use `printoptions` as a context manager to set the values temporarily.",
        "Use `printoptions` as a context manager to set the values"
    ],
    [
        "Floating point precision can be set:",
        "Floating point precision can"
    ],
    [
        "A custom formatter can be used to display array elements as desired:",
        "A custom formatter can be used to display array elements as"
    ],
    [
        "To put back the default options, you can use:",
        "To put back the default options,"
    ],
    [
        "Also to temporarily override options, use `printoptions`",
        "Also to temporarily override options,"
    ],
    [
        "new_opt = _make_options_dict(precision, threshold, edgeitems, linewidth,",
        "new_opt = _make_options_dict(precision, threshold,"
    ],
    [
        "Dictionary of current print options with keys",
        "Dictionary of current print"
    ],
    [
        "- formatter : dict of callables",
        "- formatter : dict"
    ],
    [
        "- legacy : str or False",
        "- legacy : str"
    ],
    [
        "For a full description of these options, see `set_printoptions`.",
        "For a full description of these"
    ],
    [
        "\"\"\"Return the legacy print mode as an int.\"\"\"",
        "\"\"\"Return the legacy print mode"
    ],
    [
        "\"\"\"Context manager for setting print options.",
        "\"\"\"Context manager for"
    ],
    [
        "Set print options for the scope of the `with` block, and restore the old",
        "Set print options for the scope of the `with` block, and"
    ],
    [
        "options at the end. See `set_printoptions` for the full description of",
        "options at the end. See `set_printoptions` for"
    ],
    [
        "The `as`-clause of the `with`-statement gives the current print options:",
        "The `as`-clause of the `with`-statement gives the current"
    ],
    [
        "Keep only the N-D corners (leading and trailing edges) of an array.",
        "Keep only the N-D corners (leading and trailing"
    ],
    [
        "Should be passed a base-class ndarray, since it makes no guarantees about",
        "Should be passed a base-class ndarray,"
    ],
    [
        "return _leading_trailing(a, edgeitems, index + np.index_exp[:])",
        "return _leading_trailing(a, edgeitems, index +"
    ],
    [
        "\"\"\" Object arrays containing lists should be printed unambiguously \"\"\"",
        "\"\"\" Object arrays containing lists should be printed"
    ],
    [
        "def _get_formatdict(data, *, precision, floatmode, suppress, sign, legacy,",
        "def _get_formatdict(data, *, precision, floatmode, suppress, sign,"
    ],
    [
        "data, precision, floatmode, suppress, sign, legacy=legacy),",
        "data, precision, floatmode, suppress,"
    ],
    [
        "data, precision, floatmode, suppress, sign, legacy=legacy),",
        "data, precision, floatmode,"
    ],
    [
        "data, precision, floatmode, suppress, sign, legacy=legacy),",
        "data, precision, floatmode,"
    ],
    [
        "data, precision, floatmode, suppress, sign, legacy=legacy),",
        "data, precision, floatmode, suppress,"
    ],
    [
        "fkeys = [k for k in formatter.keys() if formatter[k] is not None]",
        "fkeys = [k for k in formatter.keys() if formatter[k] is"
    ],
    [
        "find the right formatting function for the dtype_",
        "find the right formatting function for"
    ],
    [
        "Decorates a function such that if it calls itself with the same first",
        "Decorates a function such that if it calls itself with the"
    ],
    [
        "argument, it returns `fillvalue` instead of recursing.",
        "argument, it returns `fillvalue` instead"
    ],
    [
        "next_line_prefix += \" \" * len(prefix)",
        "next_line_prefix += \" \" *"
    ],
    [
        "Return a string representation of an array.",
        "Return a string representation"
    ],
    [
        "Inserts newlines if text is longer than `max_line_width`.",
        "Inserts newlines if text is"
    ],
    [
        "precision : int or None, optional",
        "precision : int or"
    ],
    [
        "Represent numbers \"very close\" to zero as zero; default is False.",
        "Represent numbers \"very close\" to zero as zero;"
    ],
    [
        "The length of the prefix and suffix strings are used to respectively",
        "The length of the prefix and suffix strings are"
    ],
    [
        "align and wrap the output. An array is typically printed as::",
        "align and wrap the output. An array is"
    ],
    [
        "The output is left-padded by the length of the prefix string, and",
        "The output is left-padded by the length"
    ],
    [
        "wrapping is forced at the column ``max_line_width - len(suffix)``.",
        "wrapping is forced at the column ``max_line_width"
    ],
    [
        "It should be noted that the content of prefix and suffix strings are",
        "It should be noted that the content of"
    ],
    [
        "Has no effect, do not use.",
        "Has no effect, do not"
    ],
    [
        "formatter : dict of callables, optional",
        "formatter : dict"
    ],
    [
        "If not None, the keys should indicate the type(s) that the respective",
        "If not None, the keys should indicate"
    ],
    [
        "formatting function applies to.  Callables should return a string.",
        "formatting function applies to. Callables should return"
    ],
    [
        "Types that are not specified (by their corresponding keys) are handled",
        "Types that are not specified (by their corresponding keys)"
    ],
    [
        "by the default formatters.  Individual types for which a formatter",
        "by the default formatters. Individual"
    ],
    [
        "- 'numpystr' : types `numpy.bytes_` and `numpy.str_`",
        "- 'numpystr' : types `numpy.bytes_` and"
    ],
    [
        "Other keys that can be used to set a group of types at once are:",
        "Other keys that can be used to set a group of types at"
    ],
    [
        "- 'all' : sets all types",
        "- 'all' : sets all"
    ],
    [
        "- 'float_kind' : sets 'float' and 'longfloat'",
        "- 'float_kind' : sets 'float' and"
    ],
    [
        "- 'complex_kind' : sets 'complexfloat' and 'longcomplexfloat'",
        "- 'complex_kind' : sets 'complexfloat'"
    ],
    [
        "Total number of array elements which trigger summarization",
        "Total number of array elements"
    ],
    [
        "Number of array items in summary at beginning and end of",
        "Number of array items in summary at beginning and"
    ],
    [
        "sign : string, either '-', '+', or ' ', optional",
        "sign : string, either '-', '+', or '"
    ],
    [
        "Controls printing of the sign of floating-point types. If '+', always",
        "Controls printing of the sign of floating-point types. If"
    ],
    [
        "print the sign of positive values. If ' ', always prints a space",
        "print the sign of positive values. If ' ', always prints a"
    ],
    [
        "(whitespace character) in the sign position of positive values.  If",
        "(whitespace character) in the sign position of positive"
    ],
    [
        "'-', omit the sign character of positive values.",
        "'-', omit the sign character of positive"
    ],
    [
        "The sign parameter can now be an integer type, previously",
        "The sign parameter can now be an integer type,"
    ],
    [
        "Controls the interpretation of the `precision` option for",
        "Controls the interpretation of the `precision` option"
    ],
    [
        "- 'fixed': Always print exactly `precision` fractional digits,",
        "- 'fixed': Always print"
    ],
    [
        "even if this would print more or fewer digits than",
        "even if this would print more"
    ],
    [
        "necessary to specify the value uniquely.",
        "necessary to specify the"
    ],
    [
        "- 'unique': Print the minimum number of fractional digits necessary",
        "- 'unique': Print the minimum number of"
    ],
    [
        "to represent each value uniquely. Different elements may",
        "to represent each value uniquely. Different"
    ],
    [
        "have a different number of digits.  The value of the",
        "have a different number of digits. The value of"
    ],
    [
        "- 'maxprec': Print at most `precision` fractional digits, but if",
        "- 'maxprec': Print at most `precision` fractional digits, but"
    ],
    [
        "an element can be uniquely represented with fewer digits",
        "an element can be uniquely"
    ],
    [
        "only print it with that many.",
        "only print it with"
    ],
    [
        "- 'maxprec_equal': Print at most `precision` fractional digits,",
        "- 'maxprec_equal': Print at most `precision` fractional"
    ],
    [
        "but if every element in the array can be uniquely",
        "but if every element in the array"
    ],
    [
        "represented with an equal number of fewer digits, use that",
        "represented with an equal number of"
    ],
    [
        "legacy : string or `False`, optional",
        "legacy : string or `False`,"
    ],
    [
        "`False`, disables legacy mode. Unrecognized strings will be ignored",
        "`False`, disables legacy mode. Unrecognized strings will"
    ],
    [
        "with a warning for forward compatibility.",
        "with a warning for forward"
    ],
    [
        "if a callable in `formatter` does not return a string.",
        "if a callable in `formatter` does"
    ],
    [
        "If a formatter is specified for a certain type, the `precision` keyword is",
        "If a formatter is specified for a certain type, the"
    ],
    [
        "This is a very flexible function; `array_repr` and `array_str` are using",
        "This is a very flexible function; `array_repr` and"
    ],
    [
        "if a.shape == () and a.dtype.names is None:",
        "if a.shape == () and"
    ],
    [
        "warnings.warn(\"'style' argument is deprecated and no longer functional\"",
        "warnings.warn(\"'style' argument is deprecated and no"
    ],
    [
        "def _extendLine(s, line, word, line_width, next_line_prefix, legacy):",
        "def _extendLine(s, line, word,"
    ],
    [
        "needs_wrap = len(line) + len(word) > line_width",
        "needs_wrap = len(line) +"
    ],
    [
        "def _extendLine_pretty(s, line, word, line_width, next_line_prefix, legacy):",
        "def _extendLine_pretty(s, line, word, line_width, next_line_prefix,"
    ],
    [
        "Extends line with nicely formatted (possibly multi-line) string ``word``.",
        "Extends line with nicely formatted (possibly"
    ],
    [
        "return _extendLine(s, line, word, line_width, next_line_prefix, legacy)",
        "return _extendLine(s, line, word,"
    ],
    [
        "max_word_length = max(len(word) for word in words)",
        "max_word_length = max(len(word) for word"
    ],
    [
        "if (len(line) + max_word_length > line_width and",
        "if (len(line) + max_word_length >"
    ],
    [
        "indent = len(line) * ' '",
        "indent = len(line) *"
    ],
    [
        "line += suffix_length * ' '",
        "line += suffix_length"
    ],
    [
        "\"\"\"formatArray is designed for two modes of operation:",
        "\"\"\"formatArray is designed for two"
    ],
    [
        "By using this local function, we don't need to recurse with all the",
        "By using this local function, we don't need to recurse"
    ],
    [
        "arguments. Since this function is not created recursively, the cost is",
        "arguments. Since this function is not created recursively, the"
    ],
    [
        "next_hanging_indent = hanging_indent + ' '",
        "next_hanging_indent = hanging_indent + '"
    ],
    [
        "word = recurser(index + (i,), next_hanging_indent, next_width)",
        "word = recurser(index + (i,),"
    ],
    [
        "s, line, word, elem_width, hanging_indent, legacy)",
        "s, line, word,"
    ],
    [
        "s, line, summary_insert, elem_width, hanging_indent, legacy",
        "s, line, summary_insert, elem_width, hanging_indent,"
    ],
    [
        "word = recurser(index + (-i,), next_hanging_indent, next_width)",
        "word = recurser(index + (-i,),"
    ],
    [
        "s, line, word, elem_width, hanging_indent, legacy)",
        "s, line, word, elem_width,"
    ],
    [
        "s, line, word, elem_width, hanging_indent, legacy)",
        "s, line, word, elem_width,"
    ],
    [
        "s += hanging_indent + nested + line_sep",
        "s += hanging_indent + nested"
    ],
    [
        "s += hanging_indent + summary_insert + \", \\n\"",
        "s += hanging_indent + summary_insert"
    ],
    [
        "s += hanging_indent + summary_insert + line_sep",
        "s += hanging_indent +"
    ],
    [
        "nested = recurser(index + (-i,), next_hanging_indent,",
        "nested = recurser(index +"
    ],
    [
        "s += hanging_indent + nested + line_sep",
        "s += hanging_indent + nested +"
    ],
    [
        "s = '[' + s[len(hanging_indent):] + ']'",
        "s = '[' + s[len(hanging_indent):]"
    ],
    [
        "\"\"\" Formatter for subtypes of np.floating \"\"\"",
        "\"\"\" Formatter for subtypes of np.floating"
    ],
    [
        "def __init__(self, data, precision, floatmode, suppress_small, sign=False,",
        "def __init__(self, data, precision, floatmode, suppress_small,"
    ],
    [
        "sign = '+' if sign else '-'",
        "sign = '+' if sign else"
    ],
    [
        "if data.shape != () and sign == '-':",
        "if data.shape != () and"
    ],
    [
        "frac_strs, _, exp_strs = zip(*(s.partition('e') for s in strs))",
        "frac_strs, _, exp_strs = zip(*(s.partition('e') for s in"
    ],
    [
        "int_part, frac_part = zip(*(s.split('.') for s in frac_strs))",
        "int_part, frac_part = zip(*(s.split('.') for s"
    ],
    [
        "self.precision = max(len(s) for s in frac_part)",
        "self.precision = max(len(s) for s in"
    ],
    [
        "self.pad_left = max(len(s) for s in int_part)",
        "self.pad_left = max(len(s) for s in"
    ],
    [
        "int_part, frac_part = zip(*(s.split('.') for s in strs))",
        "int_part, frac_part = zip(*(s.split('.') for s"
    ],
    [
        "self.pad_left = max(len(s) for s in int_part)",
        "self.pad_left = max(len(s) for s in"
    ],
    [
        "self.pad_right = max(len(s) for s in frac_part)",
        "self.pad_right = max(len(s) for s in"
    ],
    [
        "if self.sign == ' ' and not any(np.signbit(finite_vals)):",
        "if self.sign == ' ' and not"
    ],
    [
        "sign = '+' if self.sign == '+' else ''",
        "sign = '+' if self.sign == '+' else"
    ],
    [
        "Format a floating-point scalar as a decimal string in scientific notation.",
        "Format a floating-point scalar as a decimal string"
    ],
    [
        "Provides control over rounding, trimming and padding. Uses and assumes",
        "Provides control over rounding, trimming and padding. Uses and"
    ],
    [
        "x : python float or numpy floating scalar",
        "x : python float or"
    ],
    [
        "precision : non-negative integer or None, optional",
        "precision : non-negative integer"
    ],
    [
        "Maximum number of digits to print. May be None if `unique` is",
        "Maximum number of digits to print. May be None"
    ],
    [
        "`True`, but must be an integer if unique is `False`.",
        "`True`, but must be an integer"
    ],
    [
        "If `True`, use a digit-generation strategy which gives the shortest",
        "If `True`, use a digit-generation"
    ],
    [
        "representation which uniquely identifies the floating-point number from",
        "representation which uniquely identifies"
    ],
    [
        "other values of the same type, by judicious rounding. If `precision`",
        "other values of the same type,"
    ],
    [
        "is given fewer digits than necessary can be printed. If `min_digits`",
        "is given fewer digits than necessary can be printed. If"
    ],
    [
        "is given more can be printed, in which cases the last digit is rounded",
        "is given more can be printed, in which cases the last digit"
    ],
    [
        "If `False`, digits are generated as if printing an infinite-precision",
        "If `False`, digits are generated as if"
    ],
    [
        "value and stopping after `precision` digits, rounding the remaining",
        "value and stopping after `precision` digits, rounding"
    ],
    [
        "Controls post-processing trimming of trailing digits, as follows:",
        "Controls post-processing trimming of"
    ],
    [
        "* 'k' : keep trailing zeros, keep decimal point (no trimming)",
        "* 'k' : keep trailing zeros, keep decimal point (no"
    ],
    [
        "* '.' : trim all trailing zeros, leave decimal point",
        "* '.' : trim all trailing zeros, leave"
    ],
    [
        "* '-' : trim trailing zeros and any trailing decimal point",
        "* '-' : trim trailing zeros and any"
    ],
    [
        "Whether to show the sign for positive values.",
        "Whether to show the sign for"
    ],
    [
        "Pad the left side of the string with whitespace until at least that",
        "Pad the left side of the string with"
    ],
    [
        "many characters are to the left of the decimal point.",
        "many characters are to the left of"
    ],
    [
        "Pad the exponent with zeros until it contains at least this",
        "Pad the exponent with zeros until it contains at least"
    ],
    [
        "min_digits : non-negative integer or None, optional",
        "min_digits : non-negative integer or None,"
    ],
    [
        "Minimum number of digits to print. This only has an effect for",
        "Minimum number of digits to print. This only has an"
    ],
    [
        "`unique=True`. In that case more digits than necessary to uniquely",
        "`unique=True`. In that case more digits"
    ],
    [
        "identify the value may be printed and rounded unbiased.",
        "identify the value may be printed"
    ],
    [
        "The string representation of the floating point value",
        "The string representation of"
    ],
    [
        "raise ValueError(\"min_digits must be less than or equal to precision\")",
        "raise ValueError(\"min_digits must be less"
    ],
    [
        "Format a floating-point scalar as a decimal string in positional notation.",
        "Format a floating-point scalar as a decimal string in"
    ],
    [
        "Provides control over rounding, trimming and padding. Uses and assumes",
        "Provides control over rounding, trimming and padding. Uses and"
    ],
    [
        "x : python float or numpy floating scalar",
        "x : python float or numpy floating"
    ],
    [
        "precision : non-negative integer or None, optional",
        "precision : non-negative integer or"
    ],
    [
        "Maximum number of digits to print. May be None if `unique` is",
        "Maximum number of digits to print. May be None"
    ],
    [
        "`True`, but must be an integer if unique is `False`.",
        "`True`, but must be an integer if unique is"
    ],
    [
        "If `True`, use a digit-generation strategy which gives the shortest",
        "If `True`, use a digit-generation strategy which gives the"
    ],
    [
        "representation which uniquely identifies the floating-point number from",
        "representation which uniquely identifies the floating-point number"
    ],
    [
        "other values of the same type, by judicious rounding. If `precision`",
        "other values of the same type, by"
    ],
    [
        "is given fewer digits than necessary can be printed, or if `min_digits`",
        "is given fewer digits than necessary"
    ],
    [
        "is given more can be printed, in which cases the last digit is rounded",
        "is given more can be printed, in which cases"
    ],
    [
        "If `False`, digits are generated as if printing an infinite-precision",
        "If `False`, digits are generated as if printing an"
    ],
    [
        "value and stopping after `precision` digits, rounding the remaining",
        "value and stopping after `precision` digits, rounding"
    ],
    [
        "If `True`, the cutoffs of `precision` and `min_digits` refer to the",
        "If `True`, the cutoffs of `precision` and `min_digits` refer"
    ],
    [
        "total number of digits after the decimal point, including leading",
        "total number of digits after the decimal point, including"
    ],
    [
        "If `False`, `precision` and `min_digits` refer to the total number of",
        "If `False`, `precision` and `min_digits` refer to the"
    ],
    [
        "significant digits, before or after the decimal point, ignoring leading",
        "significant digits, before or after the"
    ],
    [
        "Controls post-processing trimming of trailing digits, as follows:",
        "Controls post-processing trimming of"
    ],
    [
        "* 'k' : keep trailing zeros, keep decimal point (no trimming)",
        "* 'k' : keep trailing zeros, keep"
    ],
    [
        "* '.' : trim all trailing zeros, leave decimal point",
        "* '.' : trim all trailing zeros, leave decimal"
    ],
    [
        "* '-' : trim trailing zeros and any trailing decimal point",
        "* '-' : trim trailing zeros and any trailing"
    ],
    [
        "Whether to show the sign for positive values.",
        "Whether to show the sign"
    ],
    [
        "Pad the left side of the string with whitespace until at least that",
        "Pad the left side of the string"
    ],
    [
        "many characters are to the left of the decimal point.",
        "many characters are to the left of"
    ],
    [
        "Pad the right side of the string with whitespace until at least that",
        "Pad the right side of the string"
    ],
    [
        "many characters are to the right of the decimal point.",
        "many characters are to the right of the decimal"
    ],
    [
        "min_digits : non-negative integer or None, optional",
        "min_digits : non-negative integer"
    ],
    [
        "Minimum number of digits to print. Only has an effect if `unique=True`",
        "Minimum number of digits to print. Only"
    ],
    [
        "in which case additional digits past those necessary to uniquely",
        "in which case additional digits past"
    ],
    [
        "identify the value may be printed, rounding the last additional digit.",
        "identify the value may be printed, rounding the"
    ],
    [
        "The string representation of the floating point value",
        "The string representation of the"
    ],
    [
        "raise ValueError(\"min_digits must be less than or equal to precision\")",
        "raise ValueError(\"min_digits must be less than or"
    ],
    [
        "self.truestr = ' True' if data.shape != () else 'True'",
        "self.truestr = ' True' if data.shape !="
    ],
    [
        "return self.truestr if x else \"False\"",
        "return self.truestr if x"
    ],
    [
        "\"\"\" Formatter for subtypes of np.complexfloating \"\"\"",
        "\"\"\" Formatter for subtypes of np.complexfloating"
    ],
    [
        "def __init__(self, x, precision, floatmode, suppress_small,",
        "def __init__(self, x, precision, floatmode,"
    ],
    [
        "sign = '+' if sign else '-'",
        "sign = '+' if sign"
    ],
    [
        "i = i[:sp] + 'j' + i[sp:]",
        "i = i[:sp] +"
    ],
    [
        "def __init__(self, x, unit=None, timezone=None, casting='same_kind',",
        "def __init__(self, x, unit=None,"
    ],
    [
        "self.summary_insert = \"...\" if a.size > self.threshold else \"\"",
        "self.summary_insert = \"...\" if a.size"
    ],
    [
        "+ [self.format_array(a_) for a_ in a[-self.edge_items:]]",
        "+ [self.format_array(a_) for"
    ],
    [
        "formatted = [self.format_array(a_) for a_ in a]",
        "formatted = [self.format_array(a_) for a_ in"
    ],
    [
        "return \"[\" + \", \".join(formatted) + \"]\"",
        "return \"[\" + \", \".join(formatted) +"
    ],
    [
        "This does not work on structured alias types like",
        "This does not work on structured alias"
    ],
    [
        "and the implementation relies upon np.void.__getitem__.",
        "and the implementation"
    ],
    [
        "This is a second way to initialize StructuredVoidFormat,",
        "This is a second"
    ],
    [
        "using the raw data as input. Added to avoid changing",
        "using the raw data as input. Added"
    ],
    [
        "for field, format_function in zip(x, self.format_functions)",
        "for field, format_function in"
    ],
    [
        "Implements the repr for structured-void scalars. It is called from the",
        "Implements the repr for structured-void scalars. It is"
    ],
    [
        "scalartypes.c.src code, and is placed here because it uses the elementwise",
        "scalartypes.c.src code, and is placed here because"
    ],
    [
        "cls_fqn = cls.__module__.replace(\"numpy\", \"np\") + \".\" + cls.__name__",
        "cls_fqn = cls.__module__.replace(\"numpy\", \"np\") +"
    ],
    [
        "Determine if the given dtype is implied by the representation",
        "Determine if the given dtype is implied by the"
    ],
    [
        "True if the dtype is implied by the representation of its values.",
        "True if the dtype is implied by the"
    ],
    [
        "Convert a dtype to a short form which evaluates to the same dtype.",
        "Convert a dtype to a short form which evaluates"
    ],
    [
        "The intent is roughly that the following holds",
        "The intent is roughly that the following"
    ],
    [
        "arr.shape == () and not arr.dtype.names):",
        "arr.shape == ()"
    ],
    [
        "return prefix + lst + \")\"",
        "return prefix +"
    ],
    [
        "arr_str = prefix + lst + \",\"",
        "arr_str = prefix + lst"
    ],
    [
        "extra_str = \", \".join(extras) + \")\"",
        "extra_str = \", \".join(extras) +"
    ],
    [
        "spacer = '\\n' + ' ' * len(prefix)",
        "spacer = '\\n' + '"
    ],
    [
        "spacer = '\\n' + ' ' * len(prefix)",
        "spacer = '\\n' + ' '"
    ],
    [
        "return arr_str + spacer + extra_str",
        "return arr_str + spacer +"
    ],
    [
        "Return the string representation of an array.",
        "Return the string representation of"
    ],
    [
        "Inserts newlines if text is longer than `max_line_width`.",
        "Inserts newlines if text is longer"
    ],
    [
        "Represent numbers \"very close\" to zero as zero; default is False.",
        "Represent numbers \"very close\" to zero as zero;"
    ],
    [
        "The string representation of an array.",
        "The string representation"
    ],
    [
        "a.shape == () and not a.dtype.names):",
        "a.shape == ()"
    ],
    [
        "Return a string representation of the data in an array.",
        "Return a string representation of"
    ],
    [
        "The data in the array is returned as a single string.  This function is",
        "The data in the array is returned as a single string. This function"
    ],
    [
        "similar to `array_repr`, the difference being that `array_repr` also",
        "similar to `array_repr`, the difference"
    ],
    [
        "returns information on the kind of array and its data type.",
        "returns information on the kind of array and"
    ],
    [
        "Inserts newlines if text is longer than `max_line_width`.",
        "Inserts newlines if text is longer"
    ],
    [
        "Represent numbers \"very close\" to zero as zero; default is False.",
        "Represent numbers \"very close\" to zero as zero; default"
    ],
    [
        "byteorder = {'little': '<', 'big': '>'}[sys.byteorder]",
        "byteorder = {'little':"
    ],
    [
        "\"Normalize a description adding the platform byteorder.\"",
        "\"Normalize a description adding"
    ],
    [
        "raise ValueError(\"Expected a str or list and got %s\" %",
        "raise ValueError(\"Expected a str or list and"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays zero-valued\"\"\"",
        "\"\"\"Check the creation of heterogeneous arrays"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays zero-valued (plain)\"\"\"",
        "\"\"\"Check the creation of heterogeneous arrays zero-valued"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays zero-valued (nested)\"\"\"",
        "\"\"\"Check the creation of"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays with values\"\"\"",
        "\"\"\"Check the creation of heterogeneous arrays"
    ],
    [
        "\"\"\"Check creation from list of tuples\"\"\"",
        "\"\"\"Check creation from"
    ],
    [
        "\"\"\"Check creation from list of list of tuples\"\"\"",
        "\"\"\"Check creation from list of list"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays (plain, single row)\"\"\"",
        "\"\"\"Check the creation of heterogeneous arrays (plain, single"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays (plain, multiple rows)\"\"\"",
        "\"\"\"Check the creation of heterogeneous arrays"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays (nested, single row)\"\"\"",
        "\"\"\"Check the creation of heterogeneous"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays (nested, multiple rows)\"\"\"",
        "\"\"\"Check the creation of heterogeneous arrays (nested, multiple"
    ],
    [
        "\"\"\"Check the reading of values in heterogeneous arrays (plain)\"\"\"",
        "\"\"\"Check the reading of values in"
    ],
    [
        "\"\"\"Check the creation of heterogeneous arrays (plain, single row)\"\"\"",
        "\"\"\"Check the creation of heterogeneous arrays (plain, single"
    ],
    [
        "\"\"\"Check the values of heterogeneous arrays (plain, multiple rows)\"\"\"",
        "\"\"\"Check the values of heterogeneous arrays (plain,"
    ],
    [
        "\"\"\"Check the reading of values in heterogeneous arrays (nested)\"\"\"",
        "\"\"\"Check the reading of values"
    ],
    [
        "\"\"\"Check reading the top fields of a nested array\"\"\"",
        "\"\"\"Check reading the top fields of a"
    ],
    [
        "\"\"\"Check the values of heterogeneous arrays (nested, single row)\"\"\"",
        "\"\"\"Check the values of heterogeneous arrays (nested,"
    ],
    [
        "\"\"\"Check the values of heterogeneous arrays (nested, multiple rows)\"\"\"",
        "\"\"\"Check the values of heterogeneous"
    ],
    [
        "wrappers = [np.dtype, lambda x: x]",
        "wrappers = [np.dtype,"
    ],
    [
        "Check correctness of `np.isdtype`. The test considers different argument",
        "Check correctness of `np.isdtype`. The test considers"
    ],
    [
        "with concrete dtypes and dtype groups.",
        "with concrete dtypes"
    ],
    [
        "sctypes[\"int\"] + sctypes[\"uint\"] + sctypes[\"float\"] +",
        "sctypes[\"int\"] + sctypes[\"uint\"] +"
    ],
    [
        "None, \"signed integer\", \"unsigned integer\", \"integral\",",
        "None, \"signed integer\", \"unsigned"
    ],
    [
        "with assert_raises_regex(TypeError, r\".*must be a NumPy dtype.*\"):",
        "with assert_raises_regex(TypeError, r\".*must be a NumPy"
    ],
    [
        "with assert_raises_regex(ValueError, r\".*not a known kind name.*\"):",
        "with assert_raises_regex(ValueError, r\".*not a known kind"
    ],
    [
        "'t', [np.byte, np.short, np.intc, np.long, np.longlong]",
        "'t', [np.byte, np.short,"
    ],
    [
        "'t', [np.ubyte, np.ushort, np.uintc, np.ulong, np.ulonglong]",
        "'t', [np.ubyte, np.ushort, np.uintc,"
    ],
    [
        "reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "reason=\"PyPy cannot modify tp_doc"
    ],
    [
        "names = [t.__name__ for t in self.numeric_types]",
        "names = [t.__name__ for t in"
    ],
    [
        "\"\"\" Test that names correspond to where the type is under ``np.`` \"\"\"",
        "\"\"\" Test that names correspond to where the type"
    ],
    [
        "\"\"\" Test the dtype constructor maps names back to the type \"\"\"",
        "\"\"\" Test the dtype constructor maps names back to the"
    ],
    [
        "Test the scalar constructors, which also do type-coercion",
        "Test the scalar constructors, which also"
    ],
    [
        "from numpy.testing import assert_equal, assert_raises, IS_MUSL",
        "from numpy.testing import assert_equal,"
    ],
    [
        "reason=\"long double is same as double\"),",
        "reason=\"long double is same"
    ],
    [
        "for frac, exp in zip(frac_vals, exp_vals):",
        "for frac, exp in zip(frac_vals,"
    ],
    [
        "pytest.skip(\"longdouble too small on this platform\")",
        "pytest.skip(\"longdouble too small"
    ],
    [
        "assert_equal(nf / df, f, \"{}/{}\".format(n, d))",
        "assert_equal(nf / df, f,"
    ],
    [
        "def test_special(self, code: str, str_value: str) -> None:",
        "def test_special(self, code: str,"
    ],
    [
        "def test_true(self, code: str) -> None:",
        "def test_true(self, code:"
    ],
    [
        "def test_false(self, code: str) -> None:",
        "def test_false(self, code:"
    ],
    [
        "def test_abc(self, cls: Type[np.number]) -> None:",
        "def test_abc(self, cls: Type[np.number])"
    ],
    [
        "def test_abc_complexfloating_subscript_tuple(self, arg_len: int) -> None:",
        "def test_abc_complexfloating_subscript_tuple(self, arg_len: int)"
    ],
    [
        "def test_abc_non_numeric(self, cls: Type[np.generic]) -> None:",
        "def test_abc_non_numeric(self, cls: Type[np.generic])"
    ],
    [
        "def test_concrete(self, code: str) -> None:",
        "def test_concrete(self, code: str) ->"
    ],
    [
        "def test_subscript_tuple(self, arg_len: int) -> None:",
        "def test_subscript_tuple(self, arg_len:"
    ],
    [
        "msg = f\"Smoke test for {itype}({a}).bit_count()\"",
        "msg = f\"Smoke test for"
    ],
    [
        "Test scalar.device attribute and scalar.to_device() method.",
        "Test scalar.device attribute and"
    ],
    [
        "from hypothesis.extra import numpy as hynp",
        "from hypothesis.extra import numpy as"
    ],
    [
        "types = [np.bool, np.byte, np.ubyte, np.short, np.ushort, np.intc, np.uintc,",
        "types = [np.bool, np.byte, np.ubyte, np.short,"
    ],
    [
        "objecty_things = [object(), None, np.array(None, dtype=object)]",
        "objecty_things = [object(),"
    ],
    [
        "\"error with types (%d/'%c' + %d/'%c')\" %",
        "\"error with types (%d/'%c' +"
    ],
    [
        "comp_ops = {operator.ge, operator.gt, operator.le, operator.lt}",
        "comp_ops = {operator.ge, operator.gt,"
    ],
    [
        "pytest.xfail(\"complex comp ufuncs use sort-order, scalars do not.\")",
        "pytest.xfail(\"complex comp ufuncs use"
    ],
    [
        "This is a thorough test attempting to cover important promotion paths",
        "This is a thorough test attempting to cover"
    ],
    [
        "and ensuring that arrays and scalars stay as aligned as possible.",
        "and ensuring that arrays and scalars stay as aligned as"
    ],
    [
        "However, if it creates troubles, it should maybe just be removed.",
        "However, if it creates troubles, it should maybe just be"
    ],
    [
        "assert (i / f).dtype == expected",
        "assert (i / f).dtype"
    ],
    [
        "assert (f / i).dtype == expected",
        "assert (f /"
    ],
    [
        "msg = \"error with %r: got %r\" % (t, b)",
        "msg = \"error with %r: got %r\""
    ],
    [
        "msg = (\"error with %r and %r:\"",
        "msg = (\"error with %r"
    ],
    [
        "return (x // y, x % y)",
        "return (x // y, x %"
    ],
    [
        "assert_equal(div * b + rem, a, err_msg=msg)",
        "assert_equal(div * b + rem, a,"
    ],
    [
        "tgt = [divmod(*t) for t in arg]",
        "tgt = [divmod(*t) for"
    ],
    [
        "msg = 'op: %s, dtype: %s' % (op.__name__, dt)",
        "msg = 'op: %s, dtype: %s' % (op.__name__,"
    ],
    [
        "div, rem = zip(*[op(a_, b_) for a_, b_ in zip(fa, fb)])",
        "div, rem = zip(*[op(a_, b_) for a_,"
    ],
    [
        "assert_equal(div * b + rem, a, err_msg=msg)",
        "assert_equal(div * b +"
    ],
    [
        "assert_(rem <= b, 'dt: %s' % dt)",
        "assert_(rem <= b, 'dt: %s' %"
    ],
    [
        "assert_(rem >= -b, 'dt: %s' % dt)",
        "assert_(rem >= -b, 'dt: %s'"
    ],
    [
        "sup.filter(RuntimeWarning, \"invalid value encountered in remainder\")",
        "sup.filter(RuntimeWarning, \"invalid value encountered"
    ],
    [
        "sup.filter(RuntimeWarning, \"divide by zero encountered in remainder\")",
        "sup.filter(RuntimeWarning, \"divide by zero encountered"
    ],
    [
        "sup.filter(RuntimeWarning, \"divide by zero encountered in floor_divide\")",
        "sup.filter(RuntimeWarning, \"divide by zero encountered"
    ],
    [
        "sup.filter(RuntimeWarning, \"divide by zero encountered in divmod\")",
        "sup.filter(RuntimeWarning, \"divide by zero encountered"
    ],
    [
        "sup.filter(RuntimeWarning, \"invalid value encountered in divmod\")",
        "sup.filter(RuntimeWarning, \"invalid value encountered in"
    ],
    [
        "match=r\"Cannot cast ufunc 'floor_divide' output from\"):",
        "match=r\"Cannot cast ufunc 'floor_divide'"
    ],
    [
        "assert_equal([int(_m) for _m in a], li)",
        "assert_equal([int(_m) for _m in a],"
    ],
    [
        "for code in [np.int_, np.uint, np.longlong, np.ulonglong]:",
        "for code in [np.int_, np.uint, np.longlong,"
    ],
    [
        "reason=\"long double is same as double\")",
        "reason=\"long double is"
    ],
    [
        "for which in ['small denorm', 'small norm']:",
        "for which in ['small denorm',"
    ],
    [
        "assert_equal(seq * i, seq * int(i))",
        "assert_equal(seq * i, seq"
    ],
    [
        "assert_equal(i * seq, int(i) * seq)",
        "assert_equal(i * seq,"
    ],
    [
        "sys.platform == \"cygwin\" and dtype == np.clongdouble and",
        "sys.platform == \"cygwin\" and dtype == np.clongdouble"
    ],
    [
        "sys.platform == \"cygwin\" and dtype == np.clongdouble and",
        "sys.platform == \"cygwin\" and"
    ],
    [
        "\"\"\"Shifts where the shift amount is the width of the type or wider \"\"\"",
        "\"\"\"Shifts where the shift amount is the width"
    ],
    [
        "if sctype == np.clongdouble and op in [operator.mod, operator.floordiv]:",
        "if sctype == np.clongdouble and op in"
    ],
    [
        "lambda min, max: max + max,",
        "lambda min, max:"
    ],
    [
        "lambda min, max: min - max,",
        "lambda min, max: min"
    ],
    [
        "lambda min, max: max * max], ids=[\"+\", \"-\", \"*\"])",
        "lambda min, max: max * max], ids=[\"+\", \"-\","
    ],
    [
        "lambda val, zero: val // zero,",
        "lambda val, zero: val //"
    ],
    [
        "lambda val, zero: val % zero, ], ids=[\"//\", \"%\"])",
        "lambda val, zero: val %"
    ],
    [
        "def test_subclass_deferral(sctype, __op__, __rop__, op, cmp):",
        "def test_subclass_deferral(sctype, __op__, __rop__,"
    ],
    [
        "This test covers scalar subclass deferral.  Note that this is exceedingly",
        "This test covers scalar subclass deferral."
    ],
    [
        "complicated, especially since it tends to fall back to the array paths and",
        "complicated, especially since it tends to fall back to the array paths"
    ],
    [
        "these additionally add the \"array priority\" mechanism.",
        "these additionally add the \"array priority\""
    ],
    [
        "scalars work).  Due to its complexity and the fact that subclassing NumPy",
        "scalars work). Due to its complexity and the fact that subclassing"
    ],
    [
        "scalars is probably a bad idea to begin with.  There is probably room",
        "scalars is probably a bad idea to begin with. There"
    ],
    [
        "myf_op = type(\"myf_op\", (sctype,), {__op__: op_func, __rop__: rop_func})",
        "myf_op = type(\"myf_op\", (sctype,), {__op__:"
    ],
    [
        "assert type(res) == sctype or type(res) == np.bool",
        "assert type(res) == sctype or"
    ],
    [
        "def test_pyscalar_subclasses(subtype, __op__, __rop__, op, cmp):",
        "def test_pyscalar_subclasses(subtype, __op__,"
    ],
    [
        "{__op__: op_func, __rop__: rop_func, \"__array_ufunc__\": None})",
        "{__op__: op_func, __rop__:"
    ],
    [
        "if op in {operator.mod, operator.floordiv} and subtype == complex:",
        "if op in {operator.mod, operator.floordiv}"
    ],
    [
        "myt = type(\"myt\", (subtype,), {__rop__: rop_func})",
        "myt = type(\"myt\", (subtype,),"
    ],
    [
        "[op for op in binary_operators_for_scalars if op is not operator.pow])",
        "[op for op in binary_operators_for_scalars if"
    ],
    [
        "op = lambda x, y: _op(y, x)",
        "op = lambda x, y:"
    ],
    [
        "ta = np.array(a if np.issubdtype(t, np.number) else a_str, dtype=t)",
        "ta = np.array(a if np.issubdtype(t, np.number) else a_str,"
    ],
    [
        "for mode in ('raise', 'clip', 'wrap'):",
        "for mode in ('raise',"
    ],
    [
        "Tests for array coercion, mainly through testing `np.array` results directly.",
        "Tests for array coercion, mainly"
    ],
    [
        "Note that other such tests exist, e.g., in `test_api.py` and many corner-cases",
        "Note that other such tests exist,"
    ],
    [
        "Generator for functions converting an array into various array-likes.",
        "Generator for functions converting an"
    ],
    [
        "If full is True (default) it includes array-likes not capable of handling",
        "If full is True (default) it includes array-likes not capable"
    ],
    [
        "\"\"\"Returns True if the dtype is a parametric legacy dtype (itemsize",
        "\"\"\"Returns True if the dtype is"
    ],
    [
        "assert np.array([arr, arr], dtype=\"S\").dtype == expected",
        "assert np.array([arr, arr], dtype=\"S\").dtype =="
    ],
    [
        "pytest.xfail(\"Rational to object cast is undefined currently.\")",
        "pytest.xfail(\"Rational to object cast"
    ],
    [
        "should behave the same.  The only exceptions are parametric dtypes",
        "should behave the same. The only exceptions are"
    ],
    [
        "(mainly datetime/timedelta without unit) and void without fields.",
        "(mainly datetime/timedelta without unit) and void without"
    ],
    [
        "if scalar.dtype.fields is not None and dtype.fields is None:",
        "if scalar.dtype.fields is not None"
    ],
    [
        "\"\"\"NumPy arrays are read/write which means that anything but invariant",
        "\"\"\"NumPy arrays are read/write which means that"
    ],
    [
        "behaviour is on thin ice.  However, we currently are happy to discover",
        "behaviour is on thin ice. However, we currently are"
    ],
    [
        "subclasses of Python float, int, complex the same as the base classes.",
        "subclasses of Python float, int, complex the same"
    ],
    [
        "Signed integers are currently different in that they do not cast other",
        "Signed integers are currently different in that they do not cast"
    ],
    [
        "NumPy scalar, but instead use scalar.__int__(). The hardcoded",
        "NumPy scalar, but instead"
    ],
    [
        "exception to this rule is `np.array(scalar, dtype=integer)`.",
        "exception to this rule is `np.array(scalar,"
    ],
    [
        "with pytest.raises(ValueError, match=\".*would exceed the maximum\"):",
        "with pytest.raises(ValueError, match=\".*would exceed"
    ],
    [
        "arr = np.array([l, l, l], dtype=object)",
        "arr = np.array([l, l,"
    ],
    [
        "arr = np.array([l, [None], l], dtype=object)",
        "arr = np.array([l, [None], l],"
    ],
    [
        "with pytest.raises(ValueError, match=\".*would exceed the maximum\"):",
        "with pytest.raises(ValueError, match=\".*would exceed"
    ],
    [
        "raise TypeError(\"e.g. quantities raise on this\")",
        "raise TypeError(\"e.g. quantities raise"
    ],
    [
        "\"\"\"Test the error paths, including for memory leaks\"\"\"",
        "\"\"\"Test the error paths, including for"
    ],
    [
        "\"\"\"Confirm the intended behavior for *dtype* kwarg.",
        "\"\"\"Confirm the intended behavior for *dtype*"
    ],
    [
        "The result of ``asarray()`` should have the dtype provided through the",
        "The result of ``asarray()`` should have the dtype provided through"
    ],
    [
        "keyword argument, when used. This forces unique array handles to be",
        "keyword argument, when used. This forces unique array"
    ],
    [
        "produced for unique np.dtype objects, but (for equivalent dtypes), the",
        "produced for unique np.dtype objects, but (for equivalent"
    ],
    [
        "underlying data (the base object) is shared with the original array",
        "underlying data (the base object) is shared with"
    ],
    [
        "integer_dtypes = [np.dtype(code) for code in integer_type_codes]",
        "integer_dtypes = [np.dtype(code) for"
    ],
    [
        "assert isinstance(typeA, np.dtype) and isinstance(typeB, np.dtype)",
        "assert isinstance(typeA, np.dtype) and"
    ],
    [
        "assert np.asarray(long_int_array, dtype='q') is not long_int_array",
        "assert np.asarray(long_int_array, dtype='q') is not"
    ],
    [
        "assert array_a is not np.asarray(array_a, dtype=typeB)",
        "assert array_a is"
    ],
    [
        "from numpy.testing import IS_WASM, IS_PYPY, NOGIL_BUILD, IS_EDITABLE",
        "from numpy.testing import IS_WASM,"
    ],
    [
        "from Cython.Compiler.Version import version as cython_version",
        "from Cython.Compiler.Version import version as"
    ],
    [
        "pytestmark = pytest.mark.skipif(cython is None, reason=\"requires cython\")",
        "pytestmark = pytest.mark.skipif(cython is"
    ],
    [
        "\"Editable install doesn't support tests with a compile step\",",
        "\"Editable install doesn't support tests with"
    ],
    [
        "\"Py_LIMITED_API is incompatible with Py_DEBUG, Py_TRACE_REFS, \"",
        "\"Py_LIMITED_API is incompatible with Py_DEBUG, Py_TRACE_REFS,"
    ],
    [
        "reason=\"Py_GIL_DISABLED builds do not currently support the limited API\",",
        "reason=\"Py_GIL_DISABLED builds do not currently"
    ],
    [
        "@pytest.mark.skipif(IS_PYPY, reason=\"no support for limited API in PyPy\")",
        "@pytest.mark.skipif(IS_PYPY, reason=\"no support for limited API in"
    ],
    [
        "\"\"\"Test building a third-party C extension with the limited API",
        "\"\"\"Test building a third-party C extension with"
    ],
    [
        "and building a cython extension with the limited API",
        "and building a cython extension with the limited"
    ],
    [
        "Generate value+dtype pairs that generate floating point errors during",
        "Generate value+dtype pairs that generate floating"
    ],
    [
        "casts.  The invalid casts to integers will generate \"invalid\" value",
        "casts. The invalid casts to integers will generate \"invalid\""
    ],
    [
        "warnings, the float casts all generate \"overflow\".",
        "warnings, the float casts all generate"
    ],
    [
        "(The Python int/float paths don't need to get tested in all the same",
        "(The Python int/float paths don't need to get tested"
    ],
    [
        "situations, but it does not hurt.)",
        "situations, but it"
    ],
    [
        "There are many dedicated paths in NumPy which cast and should check for",
        "There are many dedicated paths in NumPy which cast and"
    ],
    [
        "floating point errors which occurred during those casts.",
        "floating point errors which occurred during"
    ],
    [
        "arr[[True, False, True]] = np.array([value, value])",
        "arr[[True, False, True]] = np.array([value,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception support\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception"
    ],
    [
        "match = \"invalid\" if dtype.kind in 'iu' else \"overflow\"",
        "match = \"invalid\" if dtype.kind in"
    ],
    [
        "Test machar. Given recent changes to hardcode type data, we might want to get",
        "Test machar. Given recent changes to hardcode type data, we"
    ],
    [
        "rid of both MachAr and this test at some point.",
        "rid of both MachAr and"
    ],
    [
        "msg = \"Caught %s exception, should not have been raised.\" % e",
        "msg = \"Caught %s exception, should"
    ],
    [
        "is_cmp = name.strip(\"_\") in [\"eq\", \"ne\", \"le\", \"lt\", \"ge\", \"gt\"]",
        "is_cmp = name.strip(\"_\") in [\"eq\","
    ],
    [
        "or isinstance(other, (str, bytes, numbers.Number, np.bool))",
        "or isinstance(other, (str,"
    ],
    [
        "or isinstance(other, np.ndarray) and not other.shape",
        "or isinstance(other, np.ndarray) and not"
    ],
    [
        "if name in [\"__sub__\", \"__rsub__\", \"__add__\", \"__radd__\"]:",
        "if name in [\"__sub__\","
    ],
    [
        "raise TypeError(\"boolean value of NA is ambiguous\")",
        "raise TypeError(\"boolean value of NA"
    ],
    [
        "elif other is True or other is pd_NA:",
        "elif other is True or other"
    ],
    [
        "elif other is False or other is pd_NA:",
        "elif other is False or other"
    ],
    [
        "if other is False or other is True or other is pd_NA:",
        "if other is False or other is True"
    ],
    [
        "_HANDLED_TYPES = (np.ndarray, numbers.Number, str, np.bool)",
        "_HANDLED_TYPES = (np.ndarray,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc,"
    ],
    [
        "raise ValueError(f\"ufunc method '{method}' not supported for NA\")",
        "raise ValueError(f\"ufunc method '{method}' not supported for"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_array_equal",
        "from numpy.testing import assert_,"
    ],
    [
        "charmax = max(ord(c) for c in arr)",
        "charmax = max(ord(c) for c in"
    ],
    [
        "\"\"\"Check the creation of zero-valued arrays\"\"\"",
        "\"\"\"Check the creation of"
    ],
    [
        "ua = np.zeros((), dtype='U%s' % self.ulen)",
        "ua = np.zeros((), dtype='U%s'"
    ],
    [
        "\"\"\"Check the creation of unicode arrays with values\"\"\"",
        "\"\"\"Check the creation of unicode arrays"
    ],
    [
        "ua = np.array(self.ucs_value * self.ulen, dtype='U%s' % self.ulen)",
        "ua = np.array(self.ucs_value *"
    ],
    [
        "\"\"\"Check the assignment of unicode arrays with values\"\"\"",
        "\"\"\"Check the assignment of"
    ],
    [
        "ua = np.zeros((), dtype='U%s' % self.ulen)",
        "ua = np.zeros((), dtype='U%s' %"
    ],
    [
        "\"\"\"Check the byteorder of unicode arrays in round-trip conversions\"\"\"",
        "\"\"\"Check the byteorder of unicode arrays in"
    ],
    [
        "ua = np.array(self.ucs_value * self.ulen, dtype='U%s' % self.ulen)",
        "ua = np.array(self.ucs_value *"
    ],
    [
        "Testing the utilities of the CPU dispatcher",
        "Testing the utilities of the"
    ],
    [
        "if feature not in __cpu_dispatch__ or not __cpu_features__[feature]:",
        "if feature not in __cpu_dispatch__ or not"
    ],
    [
        "from hypothesis.extra import numpy as hynp",
        "from hypothesis.extra import numpy"
    ],
    [
        "fmt = {'all': lambda x: x.to_string()}",
        "fmt = {'all': lambda x:"
    ],
    [
        "assert_equal(str(dc), \"[zero one two many many]\")",
        "assert_equal(str(dc), \"[zero one"
    ],
    [
        "assert_equal(repr(arr_no_fields), 'array([(), (), (), ()], dtype=[])')",
        "assert_equal(repr(arr_no_fields), 'array([(), (),"
    ],
    [
        "cvals = [complex(rp, ip) for rp in rvals for ip in rvals]",
        "cvals = [complex(rp, ip) for rp in rvals for"
    ],
    [
        "actual = [str(np.array([c], dt)) for c in cvals for dt in dtypes]",
        "actual = [str(np.array([c], dt)) for c in cvals for dt"
    ],
    [
        "for res, val in zip(actual, wanted):",
        "for res, val in zip(actual,"
    ],
    [
        "\"\"\"Test custom format function for each element in array.\"\"\"",
        "\"\"\"Test custom format function for each"
    ],
    [
        "( 'NaT',) ( 'NaT',) ( 'NaT',)]\"\"\")",
        "( 'NaT',) ( 'NaT',)"
    ],
    [
        "a = np.array([[None, MultiLine()], [MultiLine(), None]])",
        "a = np.array([[None, MultiLine()], [MultiLine(),"
    ],
    [
        "a = np.array([[None, MultiLineLong()], [MultiLineLong(), None]])",
        "a = np.array([[None,"
    ],
    [
        "\"\"\"Test getting and setting global print options.\"\"\"",
        "\"\"\"Test getting and setting"
    ],
    [
        "even though their dtypes have different endianness.",
        "even though their dtypes have different"
    ],
    [
        "assert ('dtype' in native_repr) ^ (native_dtype in _typelessdata),\\",
        "assert ('dtype' in native_repr)"
    ],
    [
        "(\"an array's repr should show dtype if and only if the type \"",
        "(\"an array's repr should show dtype if and only if"
    ],
    [
        "'of the array is NOT one of the standard types '",
        "'of the array is NOT one of the"
    ],
    [
        "assert_equal({k: saved_opts[k] for k in opts}, opts)",
        "assert_equal({k: saved_opts[k] for k in opts},"
    ],
    [
        "pytest.skip(allow_module_level=True, reason=\"no threading support in wasm\")",
        "pytest.skip(allow_module_level=True, reason=\"no threading"
    ],
    [
        "pytest.skip(\"Couldn't spawn enough threads to run the test\")",
        "pytest.skip(\"Couldn't spawn enough threads to"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import"
    ],
    [
        "'shape': (), 'format': code, 'readonly': True}",
        "'shape': (), 'format': code, 'readonly':"
    ],
    [
        "with pytest.raises(BufferError, match=\"scalar buffer is readonly\"):",
        "with pytest.raises(BufferError, match=\"scalar buffer is"
    ],
    [
        "with pytest.raises(BufferError, match=\"scalar buffer is readonly\"):",
        "with pytest.raises(BufferError, match=\"scalar buffer"
    ],
    [
        "return {'strides': m.strides, 'shape': m.shape, 'itemsize': m.itemsize,",
        "return {'strides': m.strides, 'shape': m.shape, 'itemsize':"
    ],
    [
        "'ndim': m.ndim, 'format': m.format, 'readonly': m.readonly}",
        "'ndim': m.ndim, 'format':"
    ],
    [
        "with pytest.raises(BufferError, match=\"scalar buffer is readonly\"):",
        "with pytest.raises(BufferError, match=\"scalar buffer"
    ],
    [
        "assert_equal(code_points, [ord(c) for c in s])",
        "assert_equal(code_points, [ord(c) for"
    ],
    [
        "with pytest.raises(BufferError, match=\"scalar buffer is readonly\"):",
        "with pytest.raises(BufferError, match=\"scalar buffer"
    ],
    [
        "with pytest.raises(BufferError, match=\"scalar buffer is readonly\"):",
        "with pytest.raises(BufferError, match=\"scalar"
    ],
    [
        "'''Tests to exercise indexerrors not covered by other tests.'''",
        "'''Tests to exercise indexerrors not covered by"
    ],
    [
        "\"too many indices for array: \"",
        "\"too many indices for array:"
    ],
    [
        "from numpy.testing import assert_, assert_equal, IS_MUSL",
        "from numpy.testing import"
    ],
    [
        "_REF = {np.inf: 'inf', -np.inf: '-inf', np.nan: 'nan'}",
        "_REF = {np.inf: 'inf',"
    ],
    [
        "This is only for the str function, and only for simple types.",
        "This is only for the str function, and only"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for type %s'"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for type %s'"
    ],
    [
        "\"\"\" Check formatting of nan & inf.",
        "\"\"\" Check formatting of"
    ],
    [
        "This is only for the str function, and only for simple types.",
        "This is only for the str function, and"
    ],
    [
        "for x in [np.inf, -np.inf, np.nan]:",
        "for x in [np.inf,"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for"
    ],
    [
        "This is only for the str function, and only for simple types.",
        "This is only for the str function, and"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for type"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for type %s'"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for type"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for type %s' %"
    ],
    [
        "err_msg='Failed str formatting for type %s' % tp)",
        "err_msg='Failed str formatting for type %s' %"
    ],
    [
        "\"\"\"Check inf/nan formatting of complex types.\"\"\"",
        "\"\"\"Check inf/nan formatting"
    ],
    [
        "err_msg='print failed for type%s' % tp)",
        "err_msg='print failed for"
    ],
    [
        "\"\"\"Check formatting when using print \"\"\"",
        "\"\"\"Check formatting when using print"
    ],
    [
        "for x in [np.inf, -np.inf, np.nan]:",
        "for x in [np.inf,"
    ],
    [
        "\"\"\"Check formatting when using print \"\"\"",
        "\"\"\"Check formatting when using"
    ],
    [
        "\"\"\"Test the str.format method with NumPy scalar types\"\"\"",
        "\"\"\"Test the str.format method with NumPy"
    ],
    [
        "for (fmat, val, valtype) in tests:",
        "for (fmat, val, valtype)"
    ],
    [
        "\"failed with val %s, type %s\" % (val, valtype))",
        "\"failed with val %s, type"
    ],
    [
        "\"format raised exception (fmt='%s', val=%s, type=%s, exc='%s')\" %",
        "\"format raised exception (fmt='%s', val=%s,"
    ],
    [
        "from numpy.testing import assert_, assert_equal, IS_WASM",
        "from numpy.testing import assert_, assert_equal,"
    ],
    [
        "\"Did not raise floating point %s error\" % strmatch)",
        "\"Did not raise floating point %s error\" %"
    ],
    [
        "\"Did not raise floating point %s error\" % strmatch)",
        "\"Did not raise floating point %s error\" %"
    ],
    [
        "if shift == \"down\" and offset != \"up\":",
        "if shift == \"down\" and offset !="
    ],
    [
        "elif shift == \"up\" and offset != \"down\":",
        "elif shift == \"up\" and offset !="
    ],
    [
        "\"\"\"Confirms a small number of known half values\"\"\"",
        "\"\"\"Confirms a small number of known"
    ],
    [
        "\"\"\"Checks that rounding when converting to half is correct\"\"\"",
        "\"\"\"Checks that rounding when converting to half is"
    ],
    [
        "\"\"\"Make sure comparisons are working right\"\"\"",
        "\"\"\"Make sure comparisons are"
    ],
    [
        "assert_equal(np.equal(a, b), [False, False, False, True, False])",
        "assert_equal(np.equal(a, b), [False, False, False, True,"
    ],
    [
        "assert_equal(np.not_equal(a, b), [True, True, True, False, True])",
        "assert_equal(np.not_equal(a, b), [True, True, True,"
    ],
    [
        "assert_equal(np.less(a, b), [False, True, False, False, True])",
        "assert_equal(np.less(a, b), [False, True, False, False,"
    ],
    [
        "assert_equal(np.less_equal(a, b), [False, True, False, True, True])",
        "assert_equal(np.less_equal(a, b), [False, True,"
    ],
    [
        "assert_equal(np.greater(a, b), [True, False, True, False, False])",
        "assert_equal(np.greater(a, b), [True, False,"
    ],
    [
        "assert_equal(np.greater_equal(a, b), [True, False, True, True, False])",
        "assert_equal(np.greater_equal(a, b), [True, False, True, True,"
    ],
    [
        "assert_equal(np.logical_and(a, b), [False, True, True, True, True])",
        "assert_equal(np.logical_and(a, b), [False, True, True, True,"
    ],
    [
        "assert_equal(np.logical_or(a, b), [True, True, True, True, True])",
        "assert_equal(np.logical_or(a, b), [True, True,"
    ],
    [
        "assert_equal(np.logical_xor(a, b), [True, False, False, False, False])",
        "assert_equal(np.logical_xor(a, b), [True, False,"
    ],
    [
        "assert_equal(np.logical_not(a), [True, False, False, False, False])",
        "assert_equal(np.logical_not(a), [True, False, False, False,"
    ],
    [
        "assert_equal(np.isnan(c), [False, False, False, True, False])",
        "assert_equal(np.isnan(c), [False, False,"
    ],
    [
        "assert_equal(np.isinf(c), [False, False, True, False, False])",
        "assert_equal(np.isinf(c), [False, False,"
    ],
    [
        "assert_equal(np.isfinite(c), [True, True, False, False, True])",
        "assert_equal(np.isfinite(c), [True, True, False, False,"
    ],
    [
        "assert_equal(np.signbit(b), [True, False, False, False, False])",
        "assert_equal(np.signbit(b), [True, False,"
    ],
    [
        "\"\"\"Test that half gets coerced properly with the other types\"\"\"",
        "\"\"\"Test that half gets coerced properly"
    ],
    [
        "reason=\"fp exceptions don't work in wasm.\")",
        "reason=\"fp exceptions don't"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b: a /"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b: a /"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b:"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b: a /"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b: a"
    ],
    [
        "assert_raises_fpe('overflow', lambda a, b: a + b,",
        "assert_raises_fpe('overflow', lambda a, b: a"
    ],
    [
        "assert_raises_fpe('overflow', lambda a, b: a - b,",
        "assert_raises_fpe('overflow', lambda a, b:"
    ],
    [
        "\"\"\"Test that half is compatible with __array_interface__\"\"\"",
        "\"\"\"Test that half is"
    ],
    [
        "This file tests the generic aspects of ArrayMethod.  At the time of writing",
        "This file tests the generic aspects of ArrayMethod. At the"
    ],
    [
        "this is private API, but when added, public API may be added here.",
        "this is private API, but when added, public API may be added"
    ],
    [
        "from numpy._core._multiarray_umath import _get_castingimpl as get_castingimpl",
        "from numpy._core._multiarray_umath import"
    ],
    [
        "def test_class_getitem(self, cls: type[np.ndarray]) -> None:",
        "def test_class_getitem(self, cls: type[np.ndarray]) ->"
    ],
    [
        "def test_subscript_tup(self, cls: type[np.ndarray], arg_len: int) -> None:",
        "def test_subscript_tup(self, cls: type[np.ndarray], arg_len: int)"
    ],
    [
        "\"\"\"Returns slices of length nelems, from start onwards, in direction sign.\"\"\"",
        "\"\"\"Returns slices of length nelems, from start onwards, in direction"
    ],
    [
        "stop = start + nelems * step * sign",
        "stop = start + nelems * step *"
    ],
    [
        "\"\"\"Returns (src, dst) pairs of indices.\"\"\"",
        "\"\"\"Returns (src, dst)"
    ],
    [
        "\"\"\"Check assignment arr[dstidx] = arr[srcidx] works.\"\"\"",
        "\"\"\"Check assignment arr[dstidx] ="
    ],
    [
        "'assigning arr[%s] = arr[%s]' % (dstidx, srcidx))",
        "'assigning arr[%s] = arr[%s]' %"
    ],
    [
        "assert_(X_simplified is None, (A, U, b, X_simplified))",
        "assert_(X_simplified is None, (A, U,"
    ],
    [
        "assert_(not any(sum(w) == b for w in itertools.product(*ranges)))",
        "assert_(not any(sum(w) == b for w"
    ],
    [
        "assert_(X_simplified is not None, (A, U, b, X_simplified))",
        "assert_(X_simplified is not None, (A, U, b,"
    ],
    [
        "assert_(sum(a * x for a, x in zip(A, X)) == b)",
        "assert_(sum(a * x for a, x in"
    ],
    [
        "err_msg = \"    \" + \"\\n    \".join([",
        "err_msg = \" \""
    ],
    [
        "easy_answer = np.may_share_memory(a, b, max_work=get_max_work(a, b))",
        "easy_answer = np.may_share_memory(a, b, max_work=get_max_work(a,"
    ],
    [
        "exists = (X is not None)",
        "exists = (X"
    ],
    [
        "ranges = tuple(range(n) for n in a.shape)",
        "ranges = tuple(range(n) for n"
    ],
    [
        "offset = sum(s * w for s, w in zip(a.strides, v))",
        "offset = sum(s * w for s, w in zip(a.strides,"
    ],
    [
        "if manual_expected is not None and expected != manual_expected:",
        "if manual_expected is not None and expected"
    ],
    [
        "\"\"\"Construct an array viewing the first byte of each element of `x`\"\"\"",
        "\"\"\"Construct an array viewing the first"
    ],
    [
        "Check that operation(*args, out=out) produces results",
        "Check that operation(*args, out=out) produces"
    ],
    [
        "equivalent to out[...] = operation(*args, out=out.copy())",
        "equivalent to out[...] ="
    ],
    [
        "Test ufunc call memory overlap handling",
        "Test ufunc call memory overlap"
    ],
    [
        "outsize, scalarize = get_out_axis_size(a, b, axis)",
        "outsize, scalarize = get_out_axis_size(a, b,"
    ],
    [
        "dtypes = [np.dtype(x) for x in dtypes]",
        "dtypes = [np.dtype(x) for x"
    ],
    [
        "for xi, yi in itertools.product(indices, indices):",
        "for xi, yi in itertools.product(indices,"
    ],
    [
        "for x, y, z in itertools.product(indices, indices, indices):",
        "for x, y, z"
    ],
    [
        "desired = [a[:, :, newaxis], b[:, :, newaxis]]",
        "desired = [a[:, :, newaxis],"
    ],
    [
        "with pytest.raises(TypeError, match=\"arrays to stack must be\"):",
        "with pytest.raises(TypeError, match=\"arrays to stack must"
    ],
    [
        "with pytest.raises(TypeError, match=\"arrays to stack must be\"):",
        "with pytest.raises(TypeError, match=\"arrays to stack"
    ],
    [
        "with pytest.raises(TypeError, match=\"arrays to stack must be\"):",
        "with pytest.raises(TypeError, match=\"arrays to"
    ],
    [
        "r\"all the input arrays must have same number of dimensions, but \"",
        "r\"all the input arrays must have same number of"
    ],
    [
        "\"all the input array dimensions except for the concatenation axis \"",
        "\"all the input array dimensions except for the"
    ],
    [
        "\"must match exactly, but along dimension {}, the array at \"",
        "\"must match exactly, but along dimension {},"
    ],
    [
        "r = np.concatenate((a, b, c), axis=None, dtype=\"U\")",
        "r = np.concatenate((a, b, c),"
    ],
    [
        "rout = np.concatenate((a, b), axis=None, out=out)",
        "rout = np.concatenate((a, b),"
    ],
    [
        "@pytest.mark.skipif(IS_PYPY, reason=\"PYPY handles sq_concat, nb_add differently than cpython\")",
        "@pytest.mark.skipif(IS_PYPY, reason=\"PYPY handles sq_concat, nb_add differently"
    ],
    [
        "res = np.concatenate(arrs, axis=axis, dtype=string_dt, casting=\"unsafe\")",
        "res = np.concatenate(arrs, axis=axis, dtype=string_dt,"
    ],
    [
        "for axis, expected_shape in zip(axes, expected_shapes):",
        "for axis, expected_shape in"
    ],
    [
        "for axis, expected_shape in zip(axes, expected_shapes):",
        "for axis, expected_shape in"
    ],
    [
        "assert_raises_regex(ValueError, 'need at least one array', stack, [])",
        "assert_raises_regex(ValueError, 'need at least one array', stack,"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same shape',",
        "assert_raises_regex(ValueError, 'must have the"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same shape',",
        "assert_raises_regex(ValueError, 'must have the"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same shape',",
        "assert_raises_regex(ValueError, 'must have"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same shape',",
        "assert_raises_regex(ValueError, 'must have the"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same shape',",
        "assert_raises_regex(ValueError, 'must have"
    ],
    [
        "with pytest.raises(TypeError, match=\"arrays to stack must be\"):",
        "with pytest.raises(TypeError, match=\"arrays to"
    ],
    [
        "arrays, list_ndim, result_ndim, _ = _block_setup(arrays)",
        "arrays, list_ndim, result_ndim, _ ="
    ],
    [
        "arrays, list_ndim, result_ndim, _ = _block_setup(arrays)",
        "arrays, list_ndim, result_ndim, _"
    ],
    [
        "raise ValueError('Unknown blocking request. There is a typo in the tests.')",
        "raise ValueError('Unknown blocking request. There is a typo in"
    ],
    [
        "result = block([[a, b], [a, b]])",
        "result = block([[a, b],"
    ],
    [
        "assert_equal(list(_block_dispatcher([[a], [b, [c]]])), [a, b, c])",
        "assert_equal(list(_block_dispatcher([[a], [b, [c]]])),"
    ],
    [
        "from numpy.testing import extbuild, IS_WASM, IS_EDITABLE",
        "from numpy.testing import"
    ],
    [
        "\"\"\" Some codes to generate data and manage temporary buffers use when",
        "\"\"\" Some codes to generate data"
    ],
    [
        "sharing with numpy via the array interface protocol.",
        "sharing with numpy via"
    ],
    [
        "pytest.skip(\"Can't build module for editable install\")",
        "pytest.skip(\"Can't build module"
    ],
    [
        "/* get the array interface structure */",
        "/* get the array interface structure"
    ],
    [
        "/* get the buffer by which data was shared */",
        "/* get the buffer by which"
    ],
    [
        "/* for the purposes of the regression test set the elements",
        "/* for the purposes of the"
    ],
    [
        "/* free the shared buffer */",
        "/* free the"
    ],
    [
        "/* free the array interface structure */",
        "/* free the array interface"
    ],
    [
        "fprintf(stderr, \"delete_array_struct\\\\ncap = %ld inter = %ld\"",
        "fprintf(stderr, \"delete_array_struct\\\\ncap = %ld inter ="
    ],
    [
        "\" ptr = %ld\\\\n\", (long)cap, (long)inter, (long)ptr);",
        "\" ptr = %ld\\\\n\", (long)cap,"
    ],
    [
        "if (!PyArg_ParseTuple(args, \"Ld\", &n_elem, &value)) {",
        "if (!PyArg_ParseTuple(args, \"Ld\", &n_elem,"
    ],
    [
        "/* allocate and initialize the data to share with numpy */",
        "/* allocate and initialize the data to"
    ],
    [
        "\"Failed to malloc %lld bytes\", n_bytes);",
        "\"Failed to malloc %lld bytes\","
    ],
    [
        "/* calculate the shape and stride */",
        "/* calculate the shape"
    ],
    [
        "npy_intp *stride = ss + nd;",
        "npy_intp *stride = ss"
    ],
    [
        "/* construct the array interface */",
        "/* construct the array"
    ],
    [
        "inter->flags = NPY_ARRAY_WRITEABLE | NPY_ARRAY_NOTSWAPPED |",
        "inter->flags = NPY_ARRAY_WRITEABLE |"
    ],
    [
        "/* package into a capsule */",
        "/* package into a capsule"
    ],
    [
        "PyObject *cap = PyCapsule_New(inter, NULL, delete_array_struct);",
        "PyObject *cap = PyCapsule_New(inter,"
    ],
    [
        "/* save the pointer to the data */",
        "/* save the pointer to"
    ],
    [
        "fprintf(stderr, \"new_array_struct\\\\ncap = %ld inter = %ld\"",
        "fprintf(stderr, \"new_array_struct\\\\ncap = %ld"
    ],
    [
        "\" ptr = %ld\\\\n\", (long)cap, (long)inter, (long)data);",
        "\" ptr = %ld\\\\n\", (long)cap,"
    ],
    [
        "This class is for testing the timing of the PyCapsule destructor",
        "This class is for testing the timing of the PyCapsule"
    ],
    [
        "invoked when numpy release its reference to the shared data as part of",
        "invoked when numpy release its reference to the shared data as part"
    ],
    [
        "the numpy array interface protocol. If the PyCapsule destructor is",
        "the numpy array interface protocol. If the PyCapsule destructor"
    ],
    [
        "called early the shared data is freed and invalid memory accesses will",
        "called early the shared data is freed and invalid memory"
    ],
    [
        "stderr.write(' ---- create an object to share data ---- \\n')",
        "stderr.write(' ---- create an object"
    ],
    [
        "stderr.write(' ---- share data via the array interface protocol ---- \\n')",
        "stderr.write(' ---- share data via the"
    ],
    [
        "stderr.write(' ---- destroy the object that shared data ---- \\n')",
        "stderr.write(' ---- destroy the object that shared data"
    ],
    [
        "stderr.write(' ---- read shared data ---- \\n')",
        "stderr.write(' ---- read shared"
    ],
    [
        "stderr.write(' ---- modify shared data ---- \\n')",
        "stderr.write(' ---- modify shared"
    ],
    [
        "stderr.write(' ---- read modified shared data ---- \\n')",
        "stderr.write(' ---- read modified"
    ],
    [
        "stderr.write(' ---- free shared data ---- \\n')",
        "stderr.write(' ---- free shared data ----"
    ],
    [
        "Tests related to deprecation warnings. Also a convenient place",
        "Tests related to deprecation warnings. Also a"
    ],
    [
        "to document how deprecations should eventually be turned into errors.",
        "to document how deprecations should eventually be turned into"
    ],
    [
        "\"\"\"Test if DeprecationWarnings are given and raised.",
        "\"\"\"Test if DeprecationWarnings are given"
    ],
    [
        "This first checks if the function when called gives `num`",
        "This first checks if the function"
    ],
    [
        "DeprecationWarnings, after that it tries to raise these",
        "DeprecationWarnings, after that it tries"
    ],
    [
        "DeprecationWarnings and compares them with `exceptions`.",
        "DeprecationWarnings and compares"
    ],
    [
        "The exceptions can be different for cases where this code path",
        "The exceptions can be different for cases"
    ],
    [
        "is simply not anticipated and the exception is replaced.",
        "is simply not anticipated and"
    ],
    [
        "Whether warnings of the wrong type should be ignored (note that",
        "Whether warnings of the wrong type should be ignored"
    ],
    [
        "If the function would normally fail, setting this will check for",
        "If the function would normally fail, setting this"
    ],
    [
        "exceptions : Exception or tuple of Exceptions",
        "exceptions : Exception or tuple of"
    ],
    [
        "Exception to expect when turning the warnings into an error.",
        "Exception to expect when turning the warnings"
    ],
    [
        "The default checks for DeprecationWarnings. If exceptions is",
        "The default checks for DeprecationWarnings. If exceptions"
    ],
    [
        "empty the function is expected to run successfully.",
        "empty the function is"
    ],
    [
        "except (Exception if function_fails else ()):",
        "except (Exception if function_fails"
    ],
    [
        "\"expected %s but got: %s\" %",
        "\"expected %s but"
    ],
    [
        "if num is not None and num_found != num:",
        "if num is not None and num_found !="
    ],
    [
        "msg = \"%i warnings found but %i expected.\" % (len(self.log), num)",
        "msg = \"%i warnings found but %i"
    ],
    [
        "lst = [str(w) for w in self.log]",
        "lst = [str(w) for"
    ],
    [
        "\"No error raised during function call\")",
        "\"No error raised during function"
    ],
    [
        "\"\"\"Test that warnings are not raised.",
        "\"\"\"Test that warnings"
    ],
    [
        "This is just a shorthand for:",
        "This is just"
    ],
    [
        "message = \"concatenate with `axis=None` will use same-kind casting\"",
        "message = \"concatenate with `axis=None` will use"
    ],
    [
        "def test_deprecated(self, name: str) -> None:",
        "def test_deprecated(self, name: str) ->"
    ],
    [
        "def test_not_deprecated(self, name: str) -> None:",
        "def test_not_deprecated(self, name:"
    ],
    [
        "message = r\".*stop allowing conversion of out-of-bound.*\"",
        "message = r\".*stop allowing conversion of"
    ],
    [
        "for creation_func in [scalar, assign, create]:",
        "for creation_func in [scalar, assign,"
    ],
    [
        "msg = f\".*\\n`np.{name}` was a deprecated alias for the builtin\"",
        "msg = f\".*\\n`np.{name}` was a deprecated alias"
    ],
    [
        "kwargs = {'delimiter': \",\", 'missing_values': \"N/A\", 'names': True}",
        "kwargs = {'delimiter': \",\", 'missing_values':"
    ],
    [
        "message = \"Passing in a parenthesized single number\"",
        "message = \"Passing in a parenthesized single"
    ],
    [
        "message = \"The 'fix_imports' flag is deprecated and has no effect.\"",
        "message = \"The 'fix_imports' flag is"
    ],
    [
        "from numpy.testing import assert_, assert_raises, IS_WASM",
        "from numpy.testing import"
    ],
    [
        "arm_softfloat = False if hosttype is None else hosttype.endswith('gnueabi')",
        "arm_softfloat = False if hosttype is None"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "is adopted in the main test suite.  A few may be moved elsewhere.",
        "is adopted in the main test suite. A few may be moved"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"wasm doesn't have support for fp errors\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"wasm doesn't have support for fp"
    ],
    [
        "pytest.skip(\"`huge_int -> string -> longdouble` failed\")",
        "pytest.skip(\"`huge_int -> string -> longdouble`"
    ],
    [
        "dtype = [('a', float), ('b', float)]",
        "dtype = [('a',"
    ],
    [
        "recordarr_r = eval(\"np.\" + repr(recordarr), {'np': np})",
        "recordarr_r = eval(\"np.\" +"
    ],
    [
        "recarr_r = eval(\"np.\" + repr(recarr), {'np': np})",
        "recarr_r = eval(\"np.\" + repr(recarr),"
    ],
    [
        "recordview_r = eval(\"np.\" + repr(recordview), {'np': np, 'numpy': np})",
        "recordview_r = eval(\"np.\" + repr(recordview), {'np': np,"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', object)])",
        "ndtype = np.dtype([('a', int),"
    ],
    [
        "dt = np.dtype([('obj', 'O'), ('int', 'i')])",
        "dt = np.dtype([('obj', 'O'),"
    ],
    [
        "\"\"\" Test that nested structured types are treated as records too \"\"\"",
        "\"\"\" Test that nested structured types are"
    ],
    [
        "\"\"\" test that trailing padding is preserved \"\"\"",
        "\"\"\" test that trailing padding"
    ],
    [
        "from numpy.testing import extbuild, assert_warns, IS_WASM, IS_EDITABLE",
        "from numpy.testing import extbuild, assert_warns, IS_WASM,"
    ],
    [
        "actual allocation, and fill the prefix with some text. Then check at each",
        "actual allocation, and fill the prefix with"
    ],
    [
        "memory manipulation that the prefix exists, to make sure all alloc/realloc/",
        "memory manipulation that the prefix exists, to make sure"
    ],
    [
        "free/calloc go via the functions here.",
        "free/calloc go via the functions"
    ],
    [
        "pytest.skip(\"Can't build module for editable install\")",
        "pytest.skip(\"Can't build module for"
    ],
    [
        "if (args != NULL && PyCapsule_CheckExact(args)) {",
        "if (args != NULL"
    ],
    [
        "if (arr == NULL) return NULL;",
        "if (arr == NULL)"
    ],
    [
        "PyObject *obj = PyCapsule_New(buf, \"buf capsule\",",
        "PyObject *obj = PyCapsule_New(buf,"
    ],
    [
        "* This struct allows the dynamic configuration of the allocator funcs",
        "* This struct allows the dynamic configuration of the allocator"
    ],
    [
        "* of the `secret_data_allocator`. It is provided here for",
        "* of the `secret_data_allocator`. It is provided"
    ],
    [
        "* demonstration purposes, as a valid `ctx` use-case scenario.",
        "* demonstration purposes, as a valid `ctx` use-case"
    ],
    [
        "shift_zero(void *ctx, size_t sz, size_t cnt) {",
        "shift_zero(void *ctx, size_t sz, size_t"
    ],
    [
        "shift_free(void *ctx, void * p, npy_uintp sz) {",
        "shift_free(void *ctx, void *"
    ],
    [
        "/* Make C runtime crash by calling free on the wrong address */",
        "/* Make C runtime crash by calling"
    ],
    [
        "\"(ptr, %ld) but allocated %ld\\\\n\", sz, i);",
        "\"(ptr, %ld) but allocated"
    ],
    [
        "/* This happens in some places, only print */",
        "/* This happens in some places,"
    ],
    [
        "shift_realloc(void *ctx, void * p, npy_uintp sz) {",
        "shift_realloc(void *ctx, void * p, npy_uintp"
    ],
    [
        "/* As an example, we use the standard {m|c|re}alloc/free funcs. */",
        "/* As an example, we use"
    ],
    [
        "reason=(\"bad interaction between getenv and \"",
        "reason=(\"bad interaction between getenv and"
    ],
    [
        "from numpy._core._simd import targets, clear_floatstatus, get_floatstatus",
        "from numpy._core._simd import"
    ],
    [
        "To call NPV intrinsics without the attribute 'npyv' and",
        "To call NPV intrinsics without"
    ],
    [
        "auto suffixing intrinsics according to class attribute 'sfx'",
        "auto suffixing intrinsics according to class"
    ],
    [
        "return getattr(self.npyv, attr + \"_\" + self.sfx)",
        "return getattr(self.npyv, attr + \"_\""
    ],
    [
        "Create list of consecutive numbers according to number of vector's lanes.",
        "Create list of consecutive numbers according to number of"
    ],
    [
        "rng = range(start, start + count)",
        "rng = range(start,"
    ],
    [
        "return [min(max(v, min_int), max_int) for v in seq]",
        "return [min(max(v, min_int), max_int) for v in"
    ],
    [
        "To test all boolean vector types at once",
        "To test all boolean vector types"
    ],
    [
        "load = getattr(self.npyv, \"load_u\" + len_str)",
        "load = getattr(self.npyv, \"load_u\" +"
    ],
    [
        "data_and = [a & b for a, b in zip(data_a, data_b)]",
        "data_and = [a & b for a, b"
    ],
    [
        "data_or = [a | b for a, b in zip(data_a, data_b)]",
        "data_or = [a | b for a, b in zip(data_a,"
    ],
    [
        "data_xor = [a ^ b for a, b in zip(data_a, data_b)]",
        "data_xor = [a ^ b for a, b in"
    ],
    [
        "vpack = pack_simd(vrdata, vrdata, vdata, vdata)",
        "vpack = pack_simd(vrdata,"
    ],
    [
        "vpack = pack_simd(vrdata, vrdata, vrdata, vrdata,",
        "vpack = pack_simd(vrdata, vrdata,"
    ],
    [
        "assert not not simd == desired",
        "assert not not"
    ],
    [
        "To test all integer vector types at once",
        "To test all integer vector"
    ],
    [
        "data_shl_a = self.load([a << count for a in data_a])",
        "data_shl_a = self.load([a << count"
    ],
    [
        "data_shr_a = self.load([a >> count for a in data_a])",
        "data_shr_a = self.load([a >> count"
    ],
    [
        "data_shl_a = self.load([a << count for a in data_a])",
        "data_shl_a = self.load([a << count for a"
    ],
    [
        "data_shr_a = self.load([a >> count for a in data_a])",
        "data_shr_a = self.load([a >> count for a"
    ],
    [
        "data_adds = self._int_clip([a + b for a, b in zip(data_a, data_b)])",
        "data_adds = self._int_clip([a + b for"
    ],
    [
        "data_subs = self._int_clip([a - b for a, b in zip(data_a, data_b)])",
        "data_subs = self._int_clip([a - b for a, b in"
    ],
    [
        "data_max = [max(a, b) for a, b in zip(data_a, data_b)]",
        "data_max = [max(a, b) for a, b in zip(data_a,"
    ],
    [
        "data_min = [min(a, b) for a, b in zip(data_a, data_b)]",
        "data_min = [min(a, b) for a, b"
    ],
    [
        "Round to nearest even integer, assume CPU control register is set to rounding.",
        "Round to nearest even integer, assume CPU control"
    ],
    [
        "data_round = [_round(x) for x in vdata_a]",
        "data_round = [_round(x) for x in"
    ],
    [
        "Round to nearest even integer, assume CPU control register is set to rounding.",
        "Round to nearest even integer, assume CPU"
    ],
    [
        "data_round = [round(x) for x in list(vdata_a) + list(vdata_b)]",
        "data_round = [round(x) for x"
    ],
    [
        "To test all float vector types at once",
        "To test all float vector types"
    ],
    [
        "data_fma = self.load([a * b + c for a, b, c in zip(vdata_a, vdata_b, vdata_c)])",
        "data_fma = self.load([a * b + c for a, b,"
    ],
    [
        "pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()",
        "pinf, ninf, nan = self._pinfinity(), self._ninfinity(),"
    ],
    [
        "pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()",
        "pinf, ninf, nan ="
    ],
    [
        "pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()",
        "pinf, ninf, nan = self._pinfinity(),"
    ],
    [
        "square_cases = ((nan, nan), (pinf, pinf), (ninf, pinf))",
        "square_cases = ((nan, nan), (pinf, pinf), (ninf,"
    ],
    [
        "data_square = [x * x for x in data]",
        "data_square = [x * x for x"
    ],
    [
        "(\"trunc\", math.trunc), (\"floor\", math.floor), (\"rint\", round)])",
        "(\"trunc\", math.trunc), (\"floor\","
    ],
    [
        "pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()",
        "pinf, ninf, nan ="
    ],
    [
        "round_cases = ((nan, nan), (pinf, pinf), (ninf, ninf))",
        "round_cases = ((nan, nan), (pinf, pinf),"
    ],
    [
        "data = self.load([(x + a) * w for a in range(self.nlanes)])",
        "data = self.load([(x + a) * w for"
    ],
    [
        "data_round = [func(x) for x in data]",
        "data_round = [func(x) for"
    ],
    [
        "data_round = [func(n) for n in x]",
        "data_round = [func(n) for n"
    ],
    [
        "\"max\", \"maxp\", \"maxn\", \"min\", \"minp\", \"minn\"",
        "\"max\", \"maxp\", \"maxn\", \"min\","
    ],
    [
        "pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()",
        "pinf, ninf, nan ="
    ],
    [
        "reduce_intrin = getattr(self, \"reduce_\" + intrin)",
        "reduce_intrin = getattr(self, \"reduce_\""
    ],
    [
        "test_nan = lambda a, b: (",
        "test_nan = lambda"
    ],
    [
        "b if math.isnan(a) else a if math.isnan(b) else b",
        "b if math.isnan(a) else a if math.isnan(b)"
    ],
    [
        "test_nan = lambda a, b: (",
        "test_nan = lambda a, b:"
    ],
    [
        "nan if math.isnan(a) or math.isnan(b) else b",
        "nan if math.isnan(a) or math.isnan(b)"
    ],
    [
        "pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()",
        "pinf, ninf, nan ="
    ],
    [
        "for d in [float(\"nan\"), float(\"inf\"), -float(\"inf\")]:",
        "for d in [float(\"nan\"), float(\"inf\"),"
    ],
    [
        "pinf, ninf, nan = self._pinfinity(), self._ninfinity(), self._nan()",
        "pinf, ninf, nan = self._pinfinity(),"
    ],
    [
        "return [lane == mask_true for lane in vector]",
        "return [lane == mask_true for lane"
    ],
    [
        "data_cmp = [py_comp(a, b) for a, b in zip(data_a, data_b)]",
        "data_cmp = [py_comp(a, b) for a, b in"
    ],
    [
        "assert not not simd == desired",
        "assert not not"
    ],
    [
        "To test all vector types at once",
        "To test all vector types"
    ],
    [
        "def test_memory_partial_load(self, intrin, elsizes, scale, fill):",
        "def test_memory_partial_load(self, intrin,"
    ],
    [
        "data_till = data[:n] + fill * ((self.nlanes - n) // scale)",
        "data_till = data[:n] + fill * ((self.nlanes - n)"
    ],
    [
        "data_till[:n * scale] = data[:n * scale]",
        "data_till[:n * scale] = data[:n *"
    ],
    [
        "data = self._data(stride, -stride * self.nlanes)",
        "data = self._data(stride, -stride *"
    ],
    [
        "def test_memory_noncont_partial_load(self, intrin, elsizes, scale, fill):",
        "def test_memory_noncont_partial_load(self, intrin, elsizes,"
    ],
    [
        "data = self._data(stride, -stride * self.nlanes)",
        "data = self._data(stride, -stride"
    ],
    [
        "data_stride[:nscale] + fill * (llanes // scale)",
        "data_stride[:nscale] + fill *"
    ],
    [
        "loadn_till = npyv_loadn_till(data, stride, n, *fill)",
        "loadn_till = npyv_loadn_till(data, stride,"
    ],
    [
        "i = (s // stride) * scale",
        "i = (s // stride)"
    ],
    [
        "data_storen[s:s + scale] = data[i:i + scale]",
        "data_storen[s:s + scale] = data[i:i"
    ],
    [
        "i = (s // stride) * scale",
        "i = (s // stride)"
    ],
    [
        "data_storen[s - scale:s or None] = data[i:i + scale]",
        "data_storen[s - scale:s or None] = data[i:i"
    ],
    [
        "i = (s // stride) * scale",
        "i = (s // stride) *"
    ],
    [
        "data_till[s:s + scale] = tdata[i:i + scale]",
        "data_till[s:s + scale] = tdata[i:i"
    ],
    [
        "i = (s // stride) * scale",
        "i = (s // stride) *"
    ],
    [
        "data_till[s - scale:s or None] = tdata[i:i + scale]",
        "data_till[s - scale:s or None]"
    ],
    [
        "assert broadcasti == [i] * self.nlanes",
        "assert broadcasti == [i]"
    ],
    [
        "vec_name = getattr(self, \"reinterpret_\" + sfx)(vdata_a).__name__",
        "vec_name = getattr(self,"
    ],
    [
        "assert vec_name == \"npyv_\" + sfx",
        "assert vec_name == \"npyv_\""
    ],
    [
        "select_a = self.select(self.cmpeq(self.zero(), self.zero()), vdata_a, vdata_b)",
        "select_a = self.select(self.cmpeq(self.zero(),"
    ],
    [
        "select_b = self.select(self.cmpneq(self.zero(), self.zero()), vdata_a, vdata_b)",
        "select_b = self.select(self.cmpneq(self.zero(), self.zero()), vdata_a,"
    ],
    [
        "assert combinel == data_a_lo + data_b_lo",
        "assert combinel == data_a_lo"
    ],
    [
        "assert combineh == data_a_hi + data_b_hi",
        "assert combineh == data_a_hi +"
    ],
    [
        "assert combine == (data_a_lo + data_b_lo, data_a_hi + data_b_hi)",
        "assert combine == (data_a_lo + data_b_lo,"
    ],
    [
        "v for p in zip(data_a_lo, data_b_lo) for v in p",
        "v for p in zip(data_a_lo, data_b_lo) for"
    ],
    [
        "v for p in zip(data_a_hi, data_b_hi) for v in p",
        "v for p in zip(data_a_hi, data_b_hi) for"
    ],
    [
        "assert vzip == list(data_zipl) + list(data_ziph)",
        "assert vzip == list(data_zipl)"
    ],
    [
        "indices = [(i >> shf) & permd for shf in shfl]",
        "indices = [(i >> shf) & permd"
    ],
    [
        "return [lane == mask_true for lane in vector]",
        "return [lane == mask_true for lane"
    ],
    [
        "data_cmp = [func(a, b) for a, b in zip(data_a, data_b)]",
        "data_cmp = [func(a, b) for a,"
    ],
    [
        "cast, cast_data = lambda a: a, self.load",
        "cast, cast_data = lambda a:"
    ],
    [
        "data_xor = cast_data([a ^ b for a, b in zip(data_cast_a, data_cast_b)])",
        "data_xor = cast_data([a ^ b for a, b in zip(data_cast_a,"
    ],
    [
        "data_or = cast_data([a | b for a, b in zip(data_cast_a, data_cast_b)])",
        "data_or = cast_data([a | b for a,"
    ],
    [
        "data_and = cast_data([a & b for a, b in zip(data_cast_a, data_cast_b)])",
        "data_and = cast_data([a & b for a, b in"
    ],
    [
        "data_not = cast_data([~a for a in data_cast_a])",
        "data_not = cast_data([~a for a in"
    ],
    [
        "data_andc = [a & ~b for a, b in zip(data_cast_a, data_cast_b)]",
        "data_andc = [a & ~b for"
    ],
    [
        "assert not not simd == desired",
        "assert not not"
    ],
    [
        "to_boolean = getattr(self.npyv, \"cvt_%s_%s\" % (bsfx, self.sfx))",
        "to_boolean = getattr(self.npyv, \"cvt_%s_%s\""
    ],
    [
        "from_boolean = getattr(self.npyv, \"cvt_%s_%s\" % (self.sfx, bsfx))",
        "from_boolean = getattr(self.npyv, \"cvt_%s_%s\" % (self.sfx,"
    ],
    [
        "data_sub = self.load([a - b for a, b in zip(data_a, data_b)])",
        "data_sub = self.load([a - b for a, b"
    ],
    [
        "data_mul = self.load([a * b for a, b in zip(data_a, data_b)])",
        "data_mul = self.load([a * b for"
    ],
    [
        "data_div = self.load([a / b for a, b in zip(data_a, data_b)])",
        "data_div = self.load([a / b for"
    ],
    [
        "and wrap around overflow similar to what C does.",
        "and wrap around overflow similar to what C"
    ],
    [
        "data += [-x for x in data]",
        "data += [-x for"
    ],
    [
        "for dividend, divisor in itertools.product(data, data):",
        "for dividend, divisor"
    ],
    [
        "data_divc = [trunc_div(a, divisor) for a in dividend]",
        "data_divc = [trunc_div(a, divisor) for a in"
    ],
    [
        "Conditional addition and subtraction for all supported data types.",
        "Conditional addition and subtraction for all"
    ],
    [
        "ifsub = self.ifsub(true_mask, vdata_b, vdata_a, vdata_b)",
        "ifsub = self.ifsub(true_mask, vdata_b,"
    ],
    [
        "ifsub = self.ifsub(false_mask, vdata_a, vdata_b, vdata_b)",
        "ifsub = self.ifsub(false_mask, vdata_a,"
    ],
    [
        "ifadd = self.ifadd(true_mask, vdata_b, vdata_a, vdata_b)",
        "ifadd = self.ifadd(true_mask,"
    ],
    [
        "ifadd = self.ifadd(false_mask, vdata_a, vdata_b, vdata_b)",
        "ifadd = self.ifadd(false_mask, vdata_a,"
    ],
    [
        "ifdiv = self.ifdiv(true_mask, vdata_b, vdata_a, vdata_b)",
        "ifdiv = self.ifdiv(true_mask, vdata_b,"
    ],
    [
        "ifdiv = self.ifdiv(false_mask, vdata_a, vdata_b, vdata_b)",
        "ifdiv = self.ifdiv(false_mask,"
    ],
    [
        "simd_width = npyv.simd if npyv else ''",
        "simd_width = npyv.simd if"
    ],
    [
        "skip = f\"target '{pretty_name}' isn't supported by current machine\"",
        "skip = f\"target '{pretty_name}' isn't"
    ],
    [
        "skip = f\"target '{pretty_name}' isn't supported by NPYV\"",
        "skip = f\"target '{pretty_name}' isn't"
    ],
    [
        "attr = {\"npyv\": targets[target_name], \"sfx\": sfx, \"target_name\": target_name}",
        "attr = {\"npyv\": targets[target_name], \"sfx\": sfx, \"target_name\":"
    ],
    [
        "\"\"\" Test printing of scalar types.",
        "\"\"\" Test printing of scalar"
    ],
    [
        "b = np.array([[ True, False, True],",
        "b = np.array([["
    ],
    [
        "ind = np.array([False, True, True], dtype=bool)",
        "ind = np.array([False, True, True],"
    ],
    [
        "These tests use code to mimic the C-Code indexing for selection.",
        "These tests use code to mimic the C-Code indexing"
    ],
    [
        "* This still lacks tests for complex item setting.",
        "* This still lacks tests"
    ],
    [
        "* If you change behavior of indexing, you might want to modify",
        "* If you change behavior of indexing, you might want to"
    ],
    [
        "these tests to try more combinations.",
        "these tests to try"
    ],
    [
        "* Only tuple indices are supported by the mimicking code.",
        "* Only tuple indices are supported"
    ],
    [
        "(and tested as of writing this)",
        "(and tested as of writing"
    ],
    [
        "* Error types should match most of the time as long as there",
        "* Error types should match most of the time as long as"
    ],
    [
        "is only one error. For multiple errors, what gets raised",
        "is only one error. For multiple errors,"
    ],
    [
        "will usually not be the same one. They are *not* tested.",
        "will usually not be the same one. They"
    ],
    [
        "indefinitely and it can be dropped if maintenance becomes a burden.",
        "indefinitely and it can be dropped if maintenance becomes a"
    ],
    [
        "indices : tuple of index objects",
        "indices : tuple of index"
    ],
    [
        "An array equivalent to the indexing operation (but always a copy).",
        "An array equivalent to the indexing operation (but always a"
    ],
    [
        "Whether the indexing operation requires a copy. If this is `True`,",
        "Whether the indexing operation requires a"
    ],
    [
        "`np.may_share_memory(arr, arr[indices])` should be `True` (with",
        "`np.may_share_memory(arr, arr[indices])` should be `True`"
    ],
    [
        "While the function may mostly match the errors of normal indexing this",
        "While the function may mostly match the errors of normal indexing"
    ],
    [
        "if isinstance(indx, np.ndarray) and indx.dtype == bool:",
        "if isinstance(indx, np.ndarray) and indx.dtype =="
    ],
    [
        "elif indx.dtype.kind != 'b' and indx.dtype.kind != 'i':",
        "elif indx.dtype.kind != 'b'"
    ],
    [
        "raise IndexError('arrays used as indices must be of '",
        "raise IndexError('arrays used as indices must"
    ],
    [
        "if isinstance(indx, np.ndarray) and indx.dtype == bool:",
        "if isinstance(indx, np.ndarray) and"
    ],
    [
        "if indx.shape != arr.shape[ax:ax + indx.ndim]:",
        "if indx.shape !="
    ],
    [
        "if indx >= arr.shape[ax] or indx < -arr.shape[ax]:",
        "if indx >= arr.shape[ax]"
    ],
    [
        "if indx >= arr.shape[ax] or indx < - arr.shape[ax]:",
        "if indx >= arr.shape[ax] or indx"
    ],
    [
        "if np.any(_indx >= _size) or np.any(_indx < -_size):",
        "if np.any(_indx >= _size) or"
    ],
    [
        "\"\"\"Check a multi index item getting and simple setting.",
        "\"\"\"Check a multi index item getting and"
    ],
    [
        "Array to be indexed, must be a reshaped arange.",
        "Array to be indexed, must be"
    ],
    [
        "index : tuple of indexing objects",
        "index : tuple"
    ],
    [
        "\"\"\"Check a single index item getting and simple setting.",
        "\"\"\"Check a single index item"
    ],
    [
        "Array to be indexed, must be an arange.",
        "Array to be indexed,"
    ],
    [
        "Index being tested. Must be a single index and not a tuple",
        "Index being tested. Must be a single index and not a"
    ],
    [
        "of indexing objects (see also `_check_multi_index`).",
        "of indexing objects (see also"
    ],
    [
        "def _compare_index_result(self, arr, index, mimic_get, no_copy):",
        "def _compare_index_result(self, arr, index,"
    ],
    [
        "\"\"\"Compare mimicked result to indexing result.",
        "\"\"\"Compare mimicked result to indexing"
    ],
    [
        "return isinstance(idx, str) and idx == \"skip\"",
        "return isinstance(idx, str) and idx"
    ],
    [
        "index = tuple(i for i in index if not isskip(i))",
        "index = tuple(i for i in index"
    ],
    [
        "These test that ``TypeError`` is raised when you try to use",
        "These test that ``TypeError`` is raised"
    ],
    [
        "\"\"\"Tests that array_likes only valid if can safely cast to integer.",
        "\"\"\"Tests that array_likes only valid if can safely cast"
    ],
    [
        "For instance, lists give IndexError when they cannot be safely cast to",
        "For instance, lists give IndexError when they cannot"
    ],
    [
        "\"\"\"An index can only have a single ellipsis.",
        "\"\"\"An index can only have"
    ],
    [
        "from numpy._core import _umath_tests as ncu_tests, sctypes",
        "from numpy._core import _umath_tests"
    ],
    [
        "UFUNCS = [obj for obj in np._core.umath.__dict__.values()",
        "UFUNCS = [obj for obj in"
    ],
    [
        "uf for uf in UFUNCS_UNARY if 'f->f' in uf.types",
        "uf for uf in UFUNCS_UNARY"
    ],
    [
        "Helper to create \"interesting\" operands to cover common code paths:",
        "Helper to create \"interesting\" operands to cover common code"
    ],
    [
        "* only first \"values\" is an array (e.g. scalar division fast-paths)",
        "* only first \"values\" is an array (e.g."
    ],
    [
        "* Longer array (SIMD) placing the value of interest at different positions",
        "* Longer array (SIMD) placing the value of interest"
    ],
    [
        "* Oddly strided arrays which may not be SIMD compatible",
        "* Oddly strided arrays which may"
    ],
    [
        "It does not attempt to cover unaligned access or mixed dtypes.",
        "It does not attempt to cover"
    ],
    [
        "These are normally handled by the casting/buffering machinery.",
        "These are normally handled by"
    ],
    [
        "This is not a fixture (currently), since I believe a fixture normally",
        "This is not a fixture (currently), since I believe a fixture"
    ],
    [
        "\"\"\" True if we are running on a Power PC platform.\"\"\"",
        "\"\"\" True if we are running on a Power"
    ],
    [
        "return platform.processor() == 'powerpc' or \\",
        "return platform.processor() == 'powerpc' or"
    ],
    [
        "comp_b_list = [int(py_comp(x, y)) for x, y in zip(a_lst, b_lst)]",
        "comp_b_list = [int(py_comp(x, y)) for x, y in"
    ],
    [
        "py_comp = lambda x, y: py_comp_func(y, x)",
        "py_comp = lambda x,"
    ],
    [
        "np_comp = lambda x, y: np_comp_func(y, x)",
        "np_comp = lambda x, y:"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "c_div = lambda n, d: (",
        "c_div = lambda"
    ],
    [
        "div_lst = [c_div(x, y) for x, y in zip(a_lst, b_lst)]",
        "div_lst = [c_div(x, y) for x, y in"
    ],
    [
        "msg = \"Integer arrays floor division check (//)\"",
        "msg = \"Integer arrays floor"
    ],
    [
        "msg_eq = \"Integer arrays floor division check (//=)\"",
        "msg_eq = \"Integer arrays floor"
    ],
    [
        "div_lst = [c_div(i, divisor) for i in a_lst]",
        "div_lst = [c_div(i, divisor)"
    ],
    [
        "match=\"divide by zero encountered in floor_divide\"):",
        "match=\"divide by zero encountered"
    ],
    [
        "if fo.min and fo.min in a:",
        "if fo.min and fo.min"
    ],
    [
        "match=\"divide by zero encountered in floor_divide\"):",
        "match=\"divide by zero encountered"
    ],
    [
        "match=\"divide by zero encountered in floor_divide\"):",
        "match=\"divide by zero encountered"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "c_div = lambda n, d: (",
        "c_div = lambda"
    ],
    [
        "msg = \"Reduce floor integer division check\"",
        "msg = \"Reduce floor integer"
    ],
    [
        "match=\"divide by zero encountered in reduce\"):",
        "match=\"divide by zero encountered"
    ],
    [
        "if divisor and (isinstance(quotient, int) or not np.isnat(quotient)):",
        "if divisor and (isinstance(quotient, int)"
    ],
    [
        "msg = \"Timedelta floor division check\"",
        "msg = \"Timedelta floor"
    ],
    [
        "assert dividend // divisor == quotient, msg",
        "assert dividend // divisor"
    ],
    [
        "msg = \"Timedelta arrays floor division check\"",
        "msg = \"Timedelta arrays floor"
    ],
    [
        "assert all(dividend_array // divisor == quotient_array), msg",
        "assert all(dividend_array // divisor == quotient_array),"
    ],
    [
        "pytest.skip(\"fp errors don't work in wasm\")",
        "pytest.skip(\"fp errors don't work"
    ],
    [
        "msg = \"Complex division implementation check\"",
        "msg = \"Complex division"
    ],
    [
        "msg = \"Complex division overflow/underflow check\"",
        "msg = \"Complex division overflow/underflow"
    ],
    [
        "y = complex(np.inf, np.nan) / x",
        "y = complex(np.inf, np.nan)"
    ],
    [
        "y = complex(np.nan, np.inf) / x",
        "y = complex(np.nan, np.inf) /"
    ],
    [
        "y = complex(np.inf, np.inf) / x",
        "y = complex(np.inf,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "sup.filter(RuntimeWarning, \"invalid value encountered in floor_divide\")",
        "sup.filter(RuntimeWarning, \"invalid value encountered in"
    ],
    [
        "assert np.isnan(div), \"div: %s\" % div",
        "assert np.isnan(div), \"div: %s\" %"
    ],
    [
        "assert np.isnan(div), \"div: %s\" % div",
        "assert np.isnan(div), \"div: %s\""
    ],
    [
        "assert np.isnan(div), \"div: %s\" % div",
        "assert np.isnan(div), \"div: %s\""
    ],
    [
        "assert_equal(div * b + rem, a, err_msg=msg)",
        "assert_equal(div * b +"
    ],
    [
        "tgt = [divmod(*t) for t in arg]",
        "tgt = [divmod(*t) for t"
    ],
    [
        "msg = 'op: %s, dtype: %s' % (op.__name__, dt)",
        "msg = 'op: %s, dtype: %s' % (op.__name__,"
    ],
    [
        "assert_equal(div * b + rem, a, err_msg=msg)",
        "assert_equal(div * b + rem, a,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "reason=\"MacOS seems to not give the correct 'invalid' warning for \"",
        "reason=\"MacOS seems to not give the correct 'invalid'"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "reason=\"MacOS seems to not give the correct 'invalid' warning for \"",
        "reason=\"MacOS seems to not give the correct 'invalid'"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "sup.filter(RuntimeWarning, \"invalid value encountered in divmod\")",
        "sup.filter(RuntimeWarning, \"invalid value encountered in"
    ],
    [
        "sup.filter(RuntimeWarning, \"divide by zero encountered in divmod\")",
        "sup.filter(RuntimeWarning, \"divide by zero encountered"
    ],
    [
        "assert np.isinf(div), 'dt: %s, div: %s' % (dt, rem)",
        "assert np.isinf(div), 'dt: %s, div:"
    ],
    [
        "assert np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem)",
        "assert np.isnan(rem), 'dt: %s, rem: %s' % (dt,"
    ],
    [
        "assert np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem)",
        "assert np.isnan(rem), 'dt: %s, rem: %s' %"
    ],
    [
        "assert_(np.isnan(div)), 'dt: %s, rem: %s' % (dt, rem)",
        "assert_(np.isnan(div)), 'dt: %s, rem: %s' % (dt,"
    ],
    [
        "assert np.isnan(div), 'dt: %s, rem: %s' % (dt, rem)",
        "assert np.isnan(div), 'dt: %s, rem: %s' % (dt,"
    ],
    [
        "assert np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem)",
        "assert np.isnan(rem), 'dt: %s, rem: %s' %"
    ],
    [
        "assert np.isinf(div), 'dt: %s, rem: %s' % (dt, rem)",
        "assert np.isinf(div), 'dt: %s, rem: %s'"
    ],
    [
        "assert np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem)",
        "assert np.isnan(rem), 'dt: %s, rem: %s'"
    ],
    [
        "assert np.isnan(rem), \"dt: %s, rem: %s\" % (dt, rem)",
        "assert np.isnan(rem), \"dt: %s, rem: %s\""
    ],
    [
        "assert np.isnan(div), \"dt: %s, rem: %s\" % (dt, rem)",
        "assert np.isnan(div), \"dt: %s, rem: %s\""
    ],
    [
        "assert np.isnan(rem), \"dt: %s, rem: %s\" % (dt, rem)",
        "assert np.isnan(rem), \"dt: %s, rem: %s\""
    ],
    [
        "assert np.isnan(div), \"dt: %s, rem: %s\" % (dt, rem)",
        "assert np.isnan(div), \"dt: %s, rem: %s\""
    ],
    [
        "assert np.isnan(rem), \"dt: %s, rem: %s\" % (dt, rem)",
        "assert np.isnan(rem), \"dt: %s, rem: %s\""
    ],
    [
        "assert np.isnan(div), \"dt: %s, rem: %s\" % (dt, rem)",
        "assert np.isnan(div), \"dt: %s, rem: %s\""
    ],
    [
        "assert_(rem <= b, 'dt: %s' % dt)",
        "assert_(rem <= b, 'dt: %s'"
    ],
    [
        "assert_(rem >= -b, 'dt: %s' % dt)",
        "assert_(rem >= -b, 'dt:"
    ],
    [
        "sup.filter(RuntimeWarning, \"invalid value encountered in remainder\")",
        "sup.filter(RuntimeWarning, \"invalid value encountered"
    ],
    [
        "sup.filter(RuntimeWarning, \"invalid value encountered in fmod\")",
        "sup.filter(RuntimeWarning, \"invalid value encountered in"
    ],
    [
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem))",
        "assert_(np.isnan(rem), 'dt: %s, rem: %s'"
    ],
    [
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, fmod))",
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s' %"
    ],
    [
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem))",
        "assert_(np.isnan(rem), 'dt: %s, rem: %s'"
    ],
    [
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem))",
        "assert_(np.isnan(rem), 'dt: %s, rem: %s'"
    ],
    [
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, fmod))",
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s'"
    ],
    [
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem))",
        "assert_(np.isnan(rem), 'dt: %s, rem: %s'"
    ],
    [
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, fmod))",
        "assert_(np.isnan(fmod), 'dt: %s, fmod:"
    ],
    [
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem))",
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' %"
    ],
    [
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, fmod))",
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt,"
    ],
    [
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem))",
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' % (dt,"
    ],
    [
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, rem))",
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s'"
    ],
    [
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' % (dt, rem))",
        "assert_(np.isnan(rem), 'dt: %s, rem: %s' %"
    ],
    [
        "assert_(np.isnan(fmod), 'dt: %s, fmod: %s' % (dt, rem))",
        "assert_(np.isnan(fmod), 'dt: %s, fmod:"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "exp = [ncu.sqrt(i) for i in inp]",
        "exp = [ncu.sqrt(i) for"
    ],
    [
        "exp = [ncu.sqrt(i) for i in inp]",
        "exp = [ncu.sqrt(i) for"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "b = np.array([np.inf, -np.inf, np.inf, -np.inf,",
        "b = np.array([np.inf, -np.inf,"
    ],
    [
        "for dtin, dtout in zip(arg_type, res_type):",
        "for dtin, dtout in zip(arg_type,"
    ],
    [
        "msg = \"dtin: %s, dtout: %s\" % (dtin, dtout)",
        "msg = \"dtin: %s, dtout:"
    ],
    [
        "assert_equal(v, float(i), err_msg='at exponent %d' % i)",
        "assert_equal(v, float(i), err_msg='at exponent %d' %"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "for dt in ['f', 'd', 'g']:",
        "for dt in"
    ],
    [
        "for dt in ['f', 'd', 'g']:",
        "for dt in ['f', 'd',"
    ],
    [
        "for dt in ['f', 'd', 'g']:",
        "for dt in"
    ],
    [
        "for dt in ['f', 'd', 'g']:",
        "for dt in ['f', 'd',"
    ],
    [
        "for dt in ['f', 'd', 'g']:",
        "for dt in ['f',"
    ],
    [
        "y = [np.nan, -np.nan, np.inf, -np.inf]",
        "y = [np.nan, -np.nan, np.inf,"
    ],
    [
        "for dt in ['e', 'f', 'd', 'g']:",
        "for dt in ['e', 'f',"
    ],
    [
        "reason=\"Older glibc versions may not raise appropriate FP exceptions\"",
        "reason=\"Older glibc versions may not raise"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "x = [np.nan, np.nan, np.inf, np.nan, -np.inf, np.nan]",
        "x = [np.nan, np.nan, np.inf, np.nan, -np.inf,"
    ],
    [
        "for dt in ['e', 'f', 'd', 'g']:",
        "for dt in ['e',"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e', 'f',"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e', 'f',"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "x = [np.nan, np.nan, np.nan, np.nan]",
        "x = [np.nan, np.nan,"
    ],
    [
        "y = [np.nan, -np.nan, np.inf, -np.inf]",
        "y = [np.nan, -np.nan, np.inf,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "reason=\"underflow is triggered for scalar 'sin'\"",
        "reason=\"underflow is triggered"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "for dt in ['e', 'f', 'd', 'g']:",
        "for dt in ['e',"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "x = [np.nan,  np.nan, np.inf, np.inf]",
        "x = [np.nan, np.nan, np.inf,"
    ],
    [
        "y = [np.nan, -np.nan, np.inf, -np.inf]",
        "y = [np.nan, -np.nan, np.inf,"
    ],
    [
        "for dt in ['e', 'f', 'd', 'g']:",
        "for dt in ['e',"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "for dt in ['e', 'f', 'd', 'g']:",
        "for dt in ['e', 'f', 'd',"
    ],
    [
        "for dt in ['e', 'f', 'd', 'g']:",
        "for dt in ['e', 'f', 'd',"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e', 'f',"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "in_ = [np.nan, -np.nan, np.inf, -np.inf]",
        "in_ = [np.nan, -np.nan,"
    ],
    [
        "out = [np.nan, np.nan, np.nan, np.nan]",
        "out = [np.nan, np.nan, np.nan,"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e',"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e',"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e',"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "in_ = [np.nan, -np.nan, np.inf, -np.inf]",
        "in_ = [np.nan, -np.nan,"
    ],
    [
        "out = [np.nan, np.nan, np.inf, -np.inf]",
        "out = [np.nan, np.nan,"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "in_ = [np.nan, -np.nan, np.inf, -np.inf]",
        "in_ = [np.nan, -np.nan,"
    ],
    [
        "out = [np.nan, np.nan, np.inf, np.inf]",
        "out = [np.nan, np.nan, np.inf,"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in"
    ],
    [
        "in_ = [np.nan, -np.nan, np.inf, -np.inf]",
        "in_ = [np.nan, -np.nan, np.inf,"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e',"
    ],
    [
        "in_ = [np.nan, -np.nan, np.inf, -np.inf]",
        "in_ = [np.nan, -np.nan,"
    ],
    [
        "out = [np.nan, np.nan, np.inf, -np.inf]",
        "out = [np.nan, np.nan, np.inf,"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e', 'f',"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e', 'f',"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "out = [np.nan, np.nan, np.nan, np.nan, np.inf, -np.inf, np.nan]",
        "out = [np.nan, np.nan, np.nan,"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e',"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in"
    ],
    [
        "reason=\"Older glibc versions may not raise appropriate FP exceptions\"",
        "reason=\"Older glibc versions may not"
    ],
    [
        "in_ = [np.nan, -np.nan, np.inf, -np.inf]",
        "in_ = [np.nan, -np.nan, np.inf,"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e', 'f',"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "in_ = [np.nan, -np.nan, np.inf, -np.inf]",
        "in_ = [np.nan, -np.nan,"
    ],
    [
        "for dt in ['e', 'f', 'd']:",
        "for dt in ['e', 'f',"
    ],
    [
        "np.cos, np.sin, np.tan, np.arccos, np.arcsin, np.spacing, np.arctanh",
        "np.cos, np.sin, np.tan, np.arccos, np.arcsin,"
    ],
    [
        "def test_unary_spurious_fpexception(self, ufunc, dtype, data, escape):",
        "def test_unary_spurious_fpexception(self, ufunc, dtype, data,"
    ],
    [
        "if escape and ufunc in escape:",
        "if escape and"
    ],
    [
        "if ufunc in (np.spacing, np.ceil) and dtype == 'e':",
        "if ufunc in (np.spacing, np.ceil) and"
    ],
    [
        "nan = np.array([True, True, False, False, False, False,",
        "nan = np.array([True, True, False,"
    ],
    [
        "inf = np.array([False, False, True, True, False, False,",
        "inf = np.array([False, False, True, True, False,"
    ],
    [
        "sign = np.array([False, True, False, True, True, False,",
        "sign = np.array([False, True, False,"
    ],
    [
        "finite = np.array([False, False, False, False, True, True,",
        "finite = np.array([False, False, False, False,"
    ],
    [
        "reason=\"np.frexp gives different answers for NAN/INF on windows and linux\")",
        "reason=\"np.frexp gives different answers for NAN/INF on"
    ],
    [
        "mant, exp = np.frexp(arr[::stride], out=(out_mant[::stride], out_exp[::stride]))",
        "mant, exp = np.frexp(arr[::stride],"
    ],
    [
        "for dt in ['f', 'd', 'g']:",
        "for dt in ['f',"
    ],
    [
        "for dt in ['f', 'd', 'g']:",
        "for dt in ['f', 'd',"
    ],
    [
        "\"hypot(%s, %s) is %s, not nan\" % (x, y, ncu.hypot(x, y)))",
        "\"hypot(%s, %s) is %s, not nan\" % (x, y, ncu.hypot(x,"
    ],
    [
        "\"hypot(%s, %s) is %s, not inf\" % (x, y, ncu.hypot(x, y)))",
        "\"hypot(%s, %s) is %s, not inf\" % (x, y,"
    ],
    [
        "out = np.array([nan, nan, nan], dtype=complex)",
        "out = np.array([nan, nan, nan],"
    ],
    [
        "out = np.array([nan, nan, nan], dtype=complex)",
        "out = np.array([nan,"
    ],
    [
        "out = [False, True, True, True]",
        "out = [False, True, True,"
    ],
    [
        "out = [False, False, False, True]",
        "out = [False,"
    ],
    [
        "out = [False, True, True, False]",
        "out = [False,"
    ],
    [
        "out = [False, True, True, True]",
        "out = [False, True, True,"
    ],
    [
        "out = [False, False, False, True]",
        "out = [False,"
    ],
    [
        "out = [False, True, True, False]",
        "out = [False, True,"
    ],
    [
        "arrs = [none, some, every, empty]",
        "arrs = [none, some, every,"
    ],
    [
        "np.dtype(c) for c in '?' + np.typecodes[\"AllInteger\"] + 'O']",
        "np.dtype(c) for c in '?' +"
    ],
    [
        "msg = \"dt = '%s'\" % dt.char",
        "msg = \"dt ="
    ],
    [
        "msg = \"dt = '%s'\" % dt.char",
        "msg = \"dt = '%s'\""
    ],
    [
        "msg = \"dt: '%s', f: '%s'\" % (dt, f)",
        "msg = \"dt: '%s', f: '%s'\""
    ],
    [
        "msg = \"dt: '%s', f: '%s'\" % (dt, f)",
        "msg = \"dt: '%s', f: '%s'\""
    ],
    [
        "msg = \"dt: '%s'\" % (f,)",
        "msg = \"dt: '%s'\""
    ],
    [
        "msg = \"dt: '%s'\" % (f,)",
        "msg = \"dt: '%s'\" %"
    ],
    [
        "input_dtype, np.signedinteger) or input_dtype == np.object_:",
        "input_dtype, np.signedinteger) or input_dtype"
    ],
    [
        "msg = f\"array bitwise_count for {input_dtype}\"",
        "msg = f\"array bitwise_count for"
    ],
    [
        "for out, inp, msg in _gen_alignment_data(dtype=dt, type='unary',",
        "for out, inp, msg in _gen_alignment_data(dtype=dt,"
    ],
    [
        "emsg = lambda: '%r\\n%s' % (inp, msg)",
        "emsg = lambda: '%r\\n%s'"
    ],
    [
        "for r in np.diagflat(np.array([np.nan] * n, dtype=dt)):",
        "for r in np.diagflat(np.array([np.nan] *"
    ],
    [
        "for out, inp, msg in _gen_alignment_data(dtype=dt, type='unary',",
        "for out, inp, msg"
    ],
    [
        "tgt = [ncu.absolute(i) for i in inp]",
        "tgt = [ncu.absolute(i) for i"
    ],
    [
        "for v in [np.nan, -np.inf, np.inf]:",
        "for v in [np.nan, -np.inf,"
    ],
    [
        "d[i] = -v if v == -np.inf else v",
        "d[i] = -v if v == -np.inf"
    ],
    [
        "valid_dtypes = [int, float, complex, object]",
        "valid_dtypes = [int,"
    ],
    [
        "\"Bad arguments passed in ufunc call\",",
        "\"Bad arguments passed in"
    ],
    [
        "def __array_ufunc__(self, func, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, func,"
    ],
    [
        "return self, func, method, inputs, kwargs",
        "return self, func,"
    ],
    [
        "return a * b * c",
        "return a * b"
    ],
    [
        "return a * b * c * d",
        "return a * b * c"
    ],
    [
        "def __array_ufunc__(self, func, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, func, method, *inputs,"
    ],
    [
        "def __array_ufunc__(self, func, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, func,"
    ],
    [
        "def __array_ufunc__(self, func, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, func, method,"
    ],
    [
        "def __array_ufunc__(self, func, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, func, method,"
    ],
    [
        "def __array_ufunc__(self, func, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, func, method,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method,"
    ],
    [
        "return self, ufunc, method, inputs, kwargs",
        "return self, ufunc, method,"
    ],
    [
        "assert_raises(TypeError, np.multiply, a, a, a, a)",
        "assert_raises(TypeError, np.multiply, a, a,"
    ],
    [
        "assert_raises(TypeError, np.multiply, a, a, sig='a', signature='a')",
        "assert_raises(TypeError, np.multiply, a, a,"
    ],
    [
        "res = np.multiply.reduce(a, None, out=(None,), dtype=None)",
        "res = np.multiply.reduce(a,"
    ],
    [
        "res = np.multiply.accumulate(a, None, out=(None,), dtype=None)",
        "res = np.multiply.accumulate(a, None, out=(None,),"
    ],
    [
        "assert_raises(TypeError, np.multiply.outer, a, a, a, a)",
        "assert_raises(TypeError, np.multiply.outer, a, a, a,"
    ],
    [
        "assert_raises(TypeError, np.multiply.outer, a, a, sig='a', signature='a')",
        "assert_raises(TypeError, np.multiply.outer, a, a,"
    ],
    [
        "assert_raises(TypeError, np.multiply.at, a, a, a, a)",
        "assert_raises(TypeError, np.multiply.at, a, a, a,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method, *inputs,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc,"
    ],
    [
        "assert_raises(TypeError, np.multiply, a, b, 'one', out='two')",
        "assert_raises(TypeError, np.multiply, a, b,"
    ],
    [
        "assert_raises(TypeError, np.multiply, a, b, 'one', 'two')",
        "assert_raises(TypeError, np.multiply, a, b, 'one',"
    ],
    [
        "assert_raises(ValueError, np.multiply, a, b, out=('one', 'two'))",
        "assert_raises(ValueError, np.multiply, a,"
    ],
    [
        "assert_raises(TypeError, np.modf, a, 'one', out=('two', 'three'))",
        "assert_raises(TypeError, np.modf, a, 'one', out=('two',"
    ],
    [
        "assert_raises(TypeError, np.modf, a, 'one', 'two', 'three')",
        "assert_raises(TypeError, np.modf, a,"
    ],
    [
        "assert_raises(ValueError, np.modf, a, out=('one', 'two', 'three'))",
        "assert_raises(ValueError, np.modf, a, out=('one',"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method, *inputs,"
    ],
    [
        "r = super().__array_ufunc__(ufunc, method, *inputs, **kwargs)",
        "r = super().__array_ufunc__(ufunc,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method, *inputs,"
    ],
    [
        "r = super().__array_ufunc__(ufunc, method, *inputs, **kwargs)",
        "r = super().__array_ufunc__(ufunc, method,"
    ],
    [
        "msg = (\"operand type(s) all returned NotImplemented from \"",
        "msg = (\"operand type(s) all"
    ],
    [
        "msg = (\"operand type(s) all returned NotImplemented from \"",
        "msg = (\"operand type(s) all returned"
    ],
    [
        "\"__array_ufunc__(<ufunc 'add'>, '__call__', <*>, <object *>, \"",
        "\"__array_ufunc__(<ufunc 'add'>, '__call__', <*>, <object"
    ],
    [
        "msg = \"operand 'OptOut' does not support ufuncs\"",
        "msg = \"operand 'OptOut'"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method,"
    ],
    [
        "return self, ufunc, method, inputs, kwargs",
        "return self, ufunc, method,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, out=None, **kwargs):",
        "def __array_ufunc__(self, ufunc, method, *inputs, out=None,"
    ],
    [
        "if output is None else output)",
        "if output is None else"
    ],
    [
        "for result, output in zip(results, outputs))",
        "for result, output in zip(results,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method,"
    ],
    [
        "if any(isinstance(input_, A) for input_ in inputs):",
        "if any(isinstance(input_, A) for input_"
    ],
    [
        "assert_(a.__array_ufunc__(np.add, '__call__', a, b) is NotImplemented)",
        "assert_(a.__array_ufunc__(np.add, '__call__', a,"
    ],
    [
        "assert_(b.__array_ufunc__(np.add, '__call__', a, b) is NotImplemented)",
        "assert_(b.__array_ufunc__(np.add, '__call__', a,"
    ],
    [
        "assert_(a.__array_ufunc__(np.add, '__call__', a, b) is NotImplemented)",
        "assert_(a.__array_ufunc__(np.add, '__call__', a, b)"
    ],
    [
        "assert_(b.__array_ufunc__(np.add, '__call__', a, b) == \"A!\")",
        "assert_(b.__array_ufunc__(np.add, '__call__', a,"
    ],
    [
        "res = a.__array_ufunc__(np.add, \"__call__\", a, a)",
        "res = a.__array_ufunc__(np.add, \"__call__\","
    ],
    [
        "{} if IS_PYPY else {\"__module__\": \"numpy\", \"__qualname__\": \"add\"}",
        "{} if IS_PYPY else"
    ],
    [
        "\"\"\" test direct implementation of these magic methods \"\"\"",
        "\"\"\" test direct implementation of"
    ],
    [
        "\"\"\" test implementations via __float__ \"\"\"",
        "\"\"\" test implementations via __float__"
    ],
    [
        "funcs = [np.arcsin,  np.arccos,  np.arctan, np.arcsinh, np.arccosh,",
        "funcs = [np.arcsin, np.arccos,"
    ],
    [
        "assert_almost_equal(fz.real, fr, err_msg='real part %s' % f)",
        "assert_almost_equal(fz.real, fr, err_msg='real part"
    ],
    [
        "name_map = {'arcsin': 'asin', 'arccos': 'acos', 'arctan': 'atan',",
        "name_map = {'arcsin': 'asin', 'arccos': 'acos',"
    ],
    [
        "'arcsinh': 'asinh', 'arccosh': 'acosh', 'arctanh': 'atanh'}",
        "'arcsinh': 'asinh', 'arccosh': 'acosh', 'arctanh':"
    ],
    [
        "\"%s %s: %s; cmath: %s\" % (fname, p, a, b)",
        "\"%s %s: %s; cmath: %s\" % (fname, p,"
    ],
    [
        "reason=\"Older glibc versions are imprecise (maybe passes with SIMD?)\"",
        "reason=\"Older glibc versions are imprecise (maybe passes"
    ],
    [
        "\"\"\"Check loss of precision in complex arc* functions\"\"\"",
        "\"\"\"Check loss of precision"
    ],
    [
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)], d.max(),",
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)],"
    ],
    [
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)], d.max(),",
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)],"
    ],
    [
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)], d.max(),",
        "assert_(np.all(d < rtol),"
    ],
    [
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)], d.max(),",
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)],"
    ],
    [
        "pytest.skip(\"Trig functions of np.clongdouble values known \"",
        "pytest.skip(\"Trig functions of np.clongdouble"
    ],
    [
        "for func in (np.arcsinh, np.arcsinh, np.arcsin, np.arctanh, np.arctan):",
        "for func in (np.arcsinh, np.arcsinh, np.arcsin,"
    ],
    [
        "Check for a branch cut in a function.",
        "Check for a branch cut"
    ],
    [
        "Change of sign of the real or imaginary part expected",
        "Change of sign of the real or"
    ],
    [
        "Whether to check if the branch cut respects signed zero (if applicable)",
        "Whether to check if the branch cut respects signed zero"
    ],
    [
        "Dtype to check (should be complex)",
        "Dtype to check (should be"
    ],
    [
        "assert_(np.nextafter(one, two) - one == eps)",
        "assert_(np.nextafter(one, two) - one"
    ],
    [
        "reason=\"long double is same as double\")",
        "reason=\"long double is"
    ],
    [
        "reason=\"long double is same as double\")",
        "reason=\"long double is"
    ],
    [
        "\"\"\"Check np.nan is a positive nan.\"\"\"",
        "\"\"\"Check np.nan is a"
    ],
    [
        "\"\"\"Test bug in reduceat when structured arrays are not copied.\"\"\"",
        "\"\"\"Test bug in reduceat when"
    ],
    [
        "\"\"\"Reduceat should work with empty arrays\"\"\"",
        "\"\"\"Reduceat should work with"
    ],
    [
        "for x in nans + fins:",
        "for x in"
    ],
    [
        "for y in nans + fins:",
        "for y in nans +"
    ],
    [
        "assert_equal(x < y, False, err_msg=\"%r < %r\" % (x, y))",
        "assert_equal(x < y, False, err_msg=\"%r"
    ],
    [
        "assert_equal(x > y, False, err_msg=\"%r > %r\" % (x, y))",
        "assert_equal(x > y, False, err_msg=\"%r"
    ],
    [
        "assert_equal(x <= y, False, err_msg=\"%r <= %r\" % (x, y))",
        "assert_equal(x <= y, False, err_msg=\"%r"
    ],
    [
        "assert_equal(x >= y, False, err_msg=\"%r >= %r\" % (x, y))",
        "assert_equal(x >= y, False, err_msg=\"%r"
    ],
    [
        "assert_equal(x == y, False, err_msg=\"%r == %r\" % (x, y))",
        "assert_equal(x == y, False, err_msg=\"%r =="
    ],
    [
        "@pytest.mark.skipif(IS_PYPY, reason=\"PyPy does not modify tp_doc\")",
        "@pytest.mark.skipif(IS_PYPY, reason=\"PyPy does"
    ],
    [
        "from numpy.random import rand, randint, randn",
        "from numpy.random import rand,"
    ],
    [
        "from hypothesis import given, strategies as st",
        "from hypothesis import given, strategies"
    ],
    [
        "from hypothesis.extra import numpy as hynp",
        "from hypothesis.extra import numpy"
    ],
    [
        "match=\"You cannot specify 'newshape' and 'shape' \"",
        "match=\"You cannot specify 'newshape' and"
    ],
    [
        "assert not np.shares_memory(np.reshape(arr, shape, copy=True), arr)",
        "assert not np.shares_memory(np.reshape(arr,"
    ],
    [
        "err_msg = \"Unable to avoid creating a copy while reshaping.\"",
        "err_msg = \"Unable to avoid creating a"
    ],
    [
        "std_b = np.std(B, axis=axis, keepdims=True, mean=mean_b)",
        "std_b = np.std(B, axis=axis, keepdims=True,"
    ],
    [
        "var_b = np.var(B, axis=axis, keepdims=True, mean=mean_b)",
        "var_b = np.var(B,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception support\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp"
    ],
    [
        "def assert_raises_fpe(self, fpeerr, flop, x, y):",
        "def assert_raises_fpe(self, fpeerr, flop, x,"
    ],
    [
        "\"Type %s did not raise fpe error '%s'.\" % (ftype, fpeerr))",
        "\"Type %s did not raise fpe error '%s'.\" % (ftype,"
    ],
    [
        "\"Type %s raised wrong fpe error '%s'.\" % (ftype, exc))",
        "\"Type %s raised wrong fpe error '%s'.\" % (ftype,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception support\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm"
    ],
    [
        "if 'bsd' in sys.platform and typecode in 'gG':",
        "if 'bsd' in sys.platform and"
    ],
    [
        "pytest.skip(reason=\"Fallback impl for (c)longdouble may not raise \"",
        "pytest.skip(reason=\"Fallback impl for (c)longdouble"
    ],
    [
        "\"FPE errors as expected on BSD OSes, \"",
        "\"FPE errors as expected on BSD"
    ],
    [
        "lambda a, b: a / b, ft_tiny, ft_max)",
        "lambda a, b: a / b, ft_tiny,"
    ],
    [
        "lambda a, b: a * b, ft_tiny, ft_tiny)",
        "lambda a, b: a"
    ],
    [
        "lambda a, b: a + b, ft_max, ft_max * ft_eps)",
        "lambda a, b: a + b, ft_max, ft_max"
    ],
    [
        "lambda a, b: a - b, -ft_max, ft_max * ft_eps)",
        "lambda a, b: a - b, -ft_max,"
    ],
    [
        "invalid, lambda a, b: a / b, ftype(np.inf), ftype(np.inf)",
        "invalid, lambda a, b: a / b,"
    ],
    [
        "invalid, lambda a, b: a - b, ftype(np.inf), ftype(np.inf)",
        "invalid, lambda a, b: a"
    ],
    [
        "invalid, lambda a, b: a + b, ftype(np.inf), ftype(-np.inf)",
        "invalid, lambda a, b: a"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception support\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm"
    ],
    [
        "invalid_types = \"BHILQP\" + \"FDG\" + \"mM\" + \"f\" + \"V\"",
        "invalid_types = \"BHILQP\" + \"FDG\" +"
    ],
    [
        "promote_types = lambda a, b: np.promote_types(b, a)",
        "promote_types = lambda a, b: np.promote_types(b,"
    ],
    [
        "\"\"\"Metadata handling in promotion does not appear formalized",
        "\"\"\"Metadata handling in promotion does not"
    ],
    [
        "right now in NumPy. This test should thus be considered to",
        "right now in NumPy. This test should thus"
    ],
    [
        "document behaviour, rather than test the correct definition of it.",
        "document behaviour, rather than test the correct definition of"
    ],
    [
        "This test is very ugly, it was useful for rewriting part of the",
        "This test is very ugly, it was useful for rewriting"
    ],
    [
        "promotion, but probably should eventually be replaced/deleted",
        "promotion, but probably should eventually be"
    ],
    [
        "(i.e. when metadata handling in promotion is better defined).",
        "(i.e. when metadata handling in promotion is"
    ],
    [
        "if res.char not in \"USV\" or res.names is not None or res.shape != ():",
        "if res.char not in \"USV\" or res.names is not None or res.shape !="
    ],
    [
        "raise NIterError('error at index %s' % eindex)",
        "raise NIterError('error at index"
    ],
    [
        "msg = \"Mismatch for dtype: %s\"",
        "msg = \"Mismatch for dtype:"
    ],
    [
        "msg = \"Mismatch for axis: %s\"",
        "msg = \"Mismatch for axis:"
    ],
    [
        "Test that a ValueError is raised instead of a SystemError",
        "Test that a ValueError is raised instead of a"
    ],
    [
        "If the __bool__ function is called after the error state is set,",
        "If the __bool__ function is called after the error state"
    ],
    [
        "Python (cpython) will raise a SystemError.",
        "Python (cpython) will raise a"
    ],
    [
        "we pre-create arrays as we sometime want to pass the same instance",
        "we pre-create arrays as we sometime want to pass the"
    ],
    [
        "and sometime not. Passing the same instances may not mean the array are",
        "and sometime not. Passing the same instances may not mean the"
    ],
    [
        "def test_array_equal_equal_nan(self, bx, by, equal_nan, expected):",
        "def test_array_equal_equal_nan(self, bx, by, equal_nan,"
    ],
    [
        "This test array_equal for a few combinations:",
        "This test array_equal for a"
    ],
    [
        "- are the two inputs the same object or not (same object may not",
        "- are the two inputs the same object or"
    ],
    [
        "- Whether we should consider or not, NaNs, being equal.",
        "- Whether we should consider or not,"
    ],
    [
        "def fastclip(self, a, m, M, out=None, **kwargs):",
        "def fastclip(self, a, m, M,"
    ],
    [
        "def clip(self, a, m, M, out=None):",
        "def clip(self, a, m, M,"
    ],
    [
        "ac = self.fastclip(a, m * np.zeros(a.shape), M)",
        "ac = self.fastclip(a, m"
    ],
    [
        "act = self.clip(a, m * np.zeros(a.shape), M)",
        "act = self.clip(a, m *"
    ],
    [
        "act = self.clip(a, m, M, out=b)",
        "act = self.clip(a, m,"
    ],
    [
        "ac = self.fastclip(a, m, M, out=b)",
        "ac = self.fastclip(a,"
    ],
    [
        "act = self.clip(a, m, M, out=b)",
        "act = self.clip(a, m,"
    ],
    [
        "ac = self.fastclip(a, m, M, out=b)",
        "ac = self.fastclip(a,"
    ],
    [
        "def test_clip_problem_cases(self, arr, amin, amax, exp):",
        "def test_clip_problem_cases(self, arr,"
    ],
    [
        "This aims for maximum generality: it could in principle generate *any*",
        "This aims for maximum generality: it could"
    ],
    [
        "valid inputs to np.clip, and in practice generates much more varied",
        "valid inputs to np.clip, and in"
    ],
    [
        "inputs than human testers come up with.",
        "inputs than human testers come"
    ],
    [
        "Because many of the inputs have tricky dependencies - compatible dtypes",
        "Because many of the inputs have"
    ],
    [
        "and mutually-broadcastable shapes - we use `st.data()` strategy draw",
        "and mutually-broadcastable shapes - we use `st.data()` strategy"
    ],
    [
        "values *inside* the test function, from strategies we construct based",
        "values *inside* the test function,"
    ],
    [
        "on previous values.  An alternative would be to define a custom strategy",
        "on previous values. An alternative would be to define"
    ],
    [
        "with `@st.composite`, but until we have duplicated code inline is fine.",
        "with `@st.composite`, but until we have duplicated"
    ],
    [
        "That accounts for most of the function; the actual test is just three",
        "That accounts for most of the function;"
    ],
    [
        "lines to calculate and compare actual vs expected results!",
        "lines to calculate and compare actual"
    ],
    [
        "expected = np.minimum(amax, np.maximum(arr, amin, dtype=t), dtype=t)",
        "expected = np.minimum(amax, np.maximum(arr, amin, dtype=t),"
    ],
    [
        "msg = (\"Passing `min` or `max` keyword argument when `a_min` and \"",
        "msg = (\"Passing `min` or `max` keyword argument when `a_min`"
    ],
    [
        "assert_(np.allclose(x, y), \"%s and %s not close\" % (x, y))",
        "assert_(np.allclose(x, y), \"%s and %s not close\" %"
    ],
    [
        "assert_(not np.allclose(x, y), \"%s and %s shouldn't be close\" % (x, y))",
        "assert_(not np.allclose(x, y), \"%s and %s shouldn't be"
    ],
    [
        "(arr, arr + arr * rtol),",
        "(arr, arr +"
    ],
    [
        "(aran, aran + aran * rtol),",
        "(aran, aran + aran"
    ],
    [
        "(arr, arr + arr * rtol),",
        "(arr, arr +"
    ],
    [
        "(arr, arr + arr * rtol + atol),",
        "(arr, arr + arr *"
    ],
    [
        "(aran, aran + aran * rtol),",
        "(aran, aran + aran *"
    ],
    [
        "for (x, y), result in zip(tests, results):",
        "for (x, y), result in"
    ],
    [
        "expected = np.array([True, False, True, False, False, False])",
        "expected = np.array([True, False, True,"
    ],
    [
        "message = \"operands could not be broadcast together...\"",
        "message = \"operands could"
    ],
    [
        "assert_(np.all(np.isclose(x, y)), \"%s and %s not close\" % (x, y))",
        "assert_(np.all(np.isclose(x, y)), \"%s and %s not close\" %"
    ],
    [
        "msg = \"%s and %s shouldn't be close\"",
        "msg = \"%s and %s shouldn't"
    ],
    [
        "assert_(not np.any(np.isclose(x, y)), msg % (x, y))",
        "assert_(not np.any(np.isclose(x, y)), msg"
    ],
    [
        "msg = \"isclose.all() and allclose aren't same for %s and %s\"",
        "msg = \"isclose.all() and allclose aren't same"
    ],
    [
        "assert_array_equal(np.isclose(x, y).all(), np.allclose(x, y), msg % (x, y))",
        "assert_array_equal(np.isclose(x, y).all(), np.allclose(x, y), msg % (x,"
    ],
    [
        "assert np.allclose(x, y, atol=atol, rtol=rtol, equal_nan=True)",
        "assert np.allclose(x, y, atol=atol,"
    ],
    [
        "tests = (self.all_close_tests + self.none_close_tests +",
        "tests = (self.all_close_tests"
    ],
    [
        "x = np.ma.masked_where([True, True, False], [np.nan, np.inf, np.nan])",
        "x = np.ma.masked_where([True, True, False], [np.nan, np.inf,"
    ],
    [
        "x = np.ma.masked_where([True, True, False], [np.nan, np.nan, np.nan])",
        "x = np.ma.masked_where([True, True,"
    ],
    [
        "x = np.ma.masked_where([True, True, False], [np.nan, np.nan, np.nan])",
        "x = np.ma.masked_where([True, True, False],"
    ],
    [
        "err_msg = \"ddof and correction can't be provided simultaneously.\"",
        "err_msg = \"ddof and correction can't be"
    ],
    [
        "dtypes = {np.dtype(tp) for tp in itertools.chain(*sctypes.values())}",
        "dtypes = {np.dtype(tp) for tp"
    ],
    [
        "self.dtypes = sorted(dtypes - variable_sized |",
        "self.dtypes = sorted(dtypes"
    ],
    [
        "self.dtypes += [type(dt) for dt in sorted(dtypes, key=keyfunc)]",
        "self.dtypes += [type(dt) for dt in sorted(dtypes,"
    ],
    [
        "self.orders = {'C': 'c_contiguous', 'F': 'f_contiguous'}",
        "self.orders = {'C': 'c_contiguous',"
    ],
    [
        "for size, ndims, order, dtype in itertools.product(*par):",
        "for size, ndims, order, dtype"
    ],
    [
        "is_void = dtype is np.dtypes.VoidDType or (",
        "is_void = dtype is"
    ],
    [
        "'''Test ones_like, zeros_like, empty_like and full_like'''",
        "'''Test ones_like, zeros_like, empty_like and"
    ],
    [
        "dz = like_function(d, order='C', dtype=dtype, **fill_kwarg)",
        "dz = like_function(d, order='C',"
    ],
    [
        "dz = like_function(d, order='F', dtype=dtype, **fill_kwarg)",
        "dz = like_function(d, order='F', dtype=dtype,"
    ],
    [
        "dz = like_function(d, order='A', dtype=dtype, **fill_kwarg)",
        "dz = like_function(d, order='A',"
    ],
    [
        "sz = like_function(d, dtype=dtype, shape=s, order=o,",
        "sz = like_function(d, dtype=dtype, shape=s,"
    ],
    [
        "if o == 'C' or (o == 'A' and d.flags.c_contiguous):",
        "if o == 'C' or (o =="
    ],
    [
        "elif o == 'F' or (o == 'A' and d.flags.f_contiguous):",
        "elif o == 'F' or (o"
    ],
    [
        "kwargs = {'fill_value': ''} if likefunc == np.full_like else {}",
        "kwargs = {'fill_value': ''} if"
    ],
    [
        "assert_(res.shape == self.tgtshape[(i, j)], str((i, j)))",
        "assert_(res.shape == self.tgtshape[(i,"
    ],
    [
        "for source, destination, expected in [",
        "for source, destination, expected in"
    ],
    [
        "for source, destination, expected in [",
        "for source, destination, expected in"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same number',",
        "assert_raises_regex(ValueError, 'must have"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same number',",
        "assert_raises_regex(ValueError, 'must have the same"
    ],
    [
        "assert \"At least one array has zero dimension\" in str(exc.value)",
        "assert \"At least one array has zero dimension\" in"
    ],
    [
        "for arr in np.indices(dims, dtype=dtype, sparse=True):",
        "for arr in np.indices(dims, dtype=dtype,"
    ],
    [
        "for idtype, fdtype, flag in itertools.product(id, fd, self.flag_names):",
        "for idtype, fdtype, flag"
    ],
    [
        "assert_raises(ValueError, np.require, a, None, ['C', 'F'])",
        "assert_raises(ValueError, np.require, a,"
    ],
    [
        "for a, ia in zip(arrs, mit.iters):",
        "for a, ia in"
    ],
    [
        "return np.ndarray.sum(self, axis, dtype, out, keepdims=True)",
        "return np.ndarray.sum(self, axis,"
    ],
    [
        "with pytest.raises(TypeError, match=\"Input should be a NumPy array\"):",
        "with pytest.raises(TypeError, match=\"Input should be a"
    ],
    [
        "logspace, linspace, geomspace, dtype, array, arange, isnan,",
        "logspace, linspace, geomspace, dtype,"
    ],
    [
        "[logspace(start, stop, num=num, base=_base) for _base in base],",
        "[logspace(start, stop, num=num, base=_base) for _base in"
    ],
    [
        "for _stop, _base in zip(stop, base)],",
        "for _stop, _base in"
    ],
    [
        "A generic object that supports the __array_interface__ and hence",
        "A generic object that supports"
    ],
    [
        "can in principle be converted to a numeric scalar, but is not",
        "can in principle be converted to"
    ],
    [
        "otherwise recognized as numeric, but also happens to support",
        "otherwise recognized as numeric, but"
    ],
    [
        "Data should be an object that implements the buffer interface,",
        "Data should be an object"
    ],
    [
        "@pytest.mark.xfail(IS_PYPY, reason=\"PyPy does not modify tp_doc\")",
        "@pytest.mark.xfail(IS_PYPY, reason=\"PyPy does not modify"
    ],
    [
        "tgt = \"Current flat index into the array.\"",
        "tgt = \"Current flat index into the"
    ],
    [
        "from pytz import timezone as tz",
        "from pytz import"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones available for"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones"
    ],
    [
        "for unit in ['Y', 'M', 'W', 'D',",
        "for unit in ['Y', 'M',"
    ],
    [
        "for larger_unit, smaller_unit in zip(larger_units, smaller_units):",
        "for larger_unit, smaller_unit in zip(larger_units,"
    ],
    [
        "\"s\", \"ms\", \"us\", \"ns\", \"ps\", \"fs\", \"as\"])",
        "\"s\", \"ms\", \"us\", \"ns\", \"ps\","
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones available for"
    ],
    [
        "(\"Y\"), (\"M\"), (\"W\"), (\"D\"), (\"h\"), (\"m\"),",
        "(\"Y\"), (\"M\"), (\"W\"), (\"D\"), (\"h\"),"
    ],
    [
        "\"Verify that datetime dtype __setstate__ can handle bad arguments\"",
        "\"Verify that datetime dtype __setstate__ can handle bad"
    ],
    [
        "\"Error roundtripping unit %s\" % unit)",
        "\"Error roundtripping unit"
    ],
    [
        "\"Error roundtripping unit %s\" % unit)",
        "\"Error roundtripping unit %s\" %"
    ],
    [
        "for tda, tdb, tdzero, tdone, tdmone in \\",
        "for tda, tdb, tdzero, tdone, tdmone"
    ],
    [
        "for dta, dtb, dtc, dtnat, tda, tdb, tdc in \\",
        "for dta, dtb, dtc, dtnat, tda, tdb, tdc in"
    ],
    [
        "for dta, dtb, dtc, dtd, dte, dtnat, tda, tdb, tdc in \\",
        "for dta, dtb, dtc, dtd, dte, dtnat, tda, tdb, tdc in"
    ],
    [
        "for dta, tda, tdb, tdc in \\",
        "for dta, tda, tdb, tdc in"
    ],
    [
        "sup.filter(RuntimeWarning, \"invalid value encountered in multiply\")",
        "sup.filter(RuntimeWarning, \"invalid value encountered in"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"does not work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"does not work"
    ],
    [
        "for dta, tda, tdb, tdc, tdd in \\",
        "for dta, tda, tdb,"
    ],
    [
        "for op in [np.equal, np.less, np.less_equal,",
        "for op in [np.equal, np.less,"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones available"
    ],
    [
        "for unit in ['ms', 'us', 'ns']:",
        "for unit in ['ms',"
    ],
    [
        "err_msg='Datetime conversion error for unit %s' % unit)",
        "err_msg='Datetime conversion error for unit"
    ],
    [
        "@pytest.mark.skipif(not _has_pytz, reason=\"The pytz module is not available.\")",
        "@pytest.mark.skipif(not _has_pytz, reason=\"The pytz module is"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "\"'remainder' cannot use operands with types\"):",
        "\"'remainder' cannot use operands"
    ],
    [
        "msg = r\"the resolved dtypes are not compatible\"",
        "msg = r\"the resolved dtypes are"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones available for \""
    ],
    [
        "for unit in ['Y', 'M', 'W', 'D',",
        "for unit in ['Y', 'M',"
    ],
    [
        "@pytest.mark.parametrize('unit', ['Y', 'M', 'W', 'D', 'h', 'm', 's', 'ms',",
        "@pytest.mark.parametrize('unit', ['Y', 'M', 'W', 'D',"
    ],
    [
        "'''check isfinite, isinf, isnan for all units of <M, >M, <m, >m dtypes",
        "'''check isfinite, isinf, isnan for all units of <M, >M, <m, >m"
    ],
    [
        "arr = np.array(arr_val,  dtype= dstr % unit)",
        "arr = np.array(arr_val, dtype= dstr %"
    ],
    [
        "\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \"ps\", \"fs\", \"as\",",
        "\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \"ps\","
    ],
    [
        "assert earliest < epoch < latest",
        "assert earliest < epoch <"
    ],
    [
        "\"s\", \"ms\", \"us\", \"ns\", \"ps\", \"fs\", \"as\",",
        "\"s\", \"ms\", \"us\", \"ns\", \"ps\","
    ],
    [
        "Limits should roundtrip when converted to strings.",
        "Limits should roundtrip when converted"
    ],
    [
        "This tests the conversion to and from npy_datetimestruct.",
        "This tests the conversion"
    ],
    [
        "@pytest.mark.parametrize('unit', ('Y', 'M', 'W', 'D', 'h', 'm', 's', 'ms', 'us'))",
        "@pytest.mark.parametrize('unit', ('Y', 'M', 'W', 'D',"
    ],
    [
        "@pytest.mark.parametrize('unit', ('h', 'm', 's', 'ms', 'us'))",
        "@pytest.mark.parametrize('unit', ('h', 'm', 's',"
    ],
    [
        "@pytest.mark.parametrize('unit', ('Y', 'M', 'W', 'D', 'h', 'm', 's', 'ms', 'us'))",
        "@pytest.mark.parametrize('unit', ('Y', 'M', 'W', 'D', 'h', 'm',"
    ],
    [
        "@pytest.mark.parametrize('unit', ('m', 's', 'ms', 'us', 'ns', 'ps', 'fs'))",
        "@pytest.mark.parametrize('unit', ('m', 's', 'ms',"
    ],
    [
        "@pytest.mark.parametrize('unit', ('W', 'D', 'h', 'm', 's', 'ms', 'us'))",
        "@pytest.mark.parametrize('unit', ('W', 'D', 'h', 'm', 's',"
    ],
    [
        "@pytest.mark.parametrize('unit', ('W', 'D', 'h', 'm', 's', 'ms', 'us'))",
        "@pytest.mark.parametrize('unit', ('W', 'D', 'h',"
    ],
    [
        "@pytest.mark.parametrize('unit', ('W', 'D', 'h', 'm', 's', 'ms', 'us'))",
        "@pytest.mark.parametrize('unit', ('W', 'D', 'h',"
    ],
    [
        "@pytest.mark.parametrize('unit', ('ms', 'us', 'ns', 'ps', 'fs', 'as'))",
        "@pytest.mark.parametrize('unit', ('ms', 'us', 'ns', 'ps',"
    ],
    [
        "@pytest.mark.parametrize('unit', ('W', 'D', 'h', 'm', 's', 'ms', 'us'))",
        "@pytest.mark.parametrize('unit', ('W', 'D', 'h', 'm',"
    ],
    [
        "Tests of the ._exceptions module. Primarily for exercising the __str__ methods.",
        "Tests of the ._exceptions module. Primarily for exercising"
    ],
    [
        "\"\"\" Test that _ArrayMemoryError can be pickled \"\"\"",
        "\"\"\" Test that _ArrayMemoryError"
    ],
    [
        "\"\"\" Test that _UFuncNoLoopError can be pickled \"\"\"",
        "\"\"\" Test that _UFuncNoLoopError"
    ],
    [
        "\"\"\"Test that `AxisError` can be pickled.\"\"\"",
        "\"\"\"Test that `AxisError`"
    ],
    [
        "for name in (\"axis\", \"ndim\", \"args\"):",
        "for name in"
    ],
    [
        "Iterate over Cartesian product of *args, and if an exception is raised,",
        "Iterate over Cartesian product of *args, and"
    ],
    [
        "add information of the current iterate.",
        "add information of the current"
    ],
    [
        "for xop, a, b in it:",
        "for xop, a,"
    ],
    [
        "if c != d or d != dr or b * d + dr != a:",
        "if c != d or d != dr or b * d + dr !="
    ],
    [
        "assert_equal(b * d + dr, a)",
        "assert_equal(b * d +"
    ],
    [
        "from numpy.testing import assert_array_equal, IS_WASM, IS_EDITABLE",
        "from numpy.testing import assert_array_equal, IS_WASM,"
    ],
    [
        "from Cython.Compiler.Version import version as cython_version",
        "from Cython.Compiler.Version import"
    ],
    [
        "pytestmark = pytest.mark.skipif(cython is None, reason=\"requires cython\")",
        "pytestmark = pytest.mark.skipif(cython is"
    ],
    [
        "\"Editable install doesn't support tests with a compile step\",",
        "\"Editable install doesn't support tests with a compile"
    ],
    [
        "for x, y in zip(bcast.iters, checks.get_multiiter_iters(bcast))",
        "for x, y in"
    ],
    [
        "assert checks.get_npyiter_size(it) == it.itersize == np.prod(arr.shape)",
        "assert checks.get_npyiter_size(it) == it.itersize =="
    ],
    [
        "assert checks.npyiter_has_index(it) == it.has_index == False",
        "assert checks.npyiter_has_index(it) =="
    ],
    [
        "assert checks.npyiter_has_index(it) == it.has_index == True",
        "assert checks.npyiter_has_index(it) == it.has_index =="
    ],
    [
        "assert checks.get_npyiter_size(it) == it.itersize == np.prod(arr.shape)",
        "assert checks.get_npyiter_size(it) == it.itersize"
    ],
    [
        "assert checks.npyiter_has_multi_index(it) == it.has_multi_index == True",
        "assert checks.npyiter_has_multi_index(it) == it.has_multi_index =="
    ],
    [
        "x is y for x, y in zip(checks.get_npyiter_operands(it), it.operands)",
        "x is y for x, y in zip(checks.get_npyiter_operands(it),"
    ],
    [
        "for x, y in zip(checks.get_npyiter_itviews(it), it.itviews)",
        "for x, y in"
    ],
    [
        "\"\"\"Check that the cython API can write to a vstring array.\"\"\"",
        "\"\"\"Check that the cython API can write to a vstring"
    ],
    [
        "arr = np.array(['a', 'b', 'c'], dtype='T')",
        "arr = np.array(['a', 'b', 'c'],"
    ],
    [
        "\"\"\"Check that the cython API can load strings from a vstring array.\"\"\"",
        "\"\"\"Check that the cython API can load strings from a"
    ],
    [
        "arr = np.array(['abcd', 'b', 'c'], dtype='T')",
        "arr = np.array(['abcd',"
    ],
    [
        "\"\"\"Check that the cython API can acquire/release multiple vstring allocators.\"\"\"",
        "\"\"\"Check that the cython API can"
    ],
    [
        "\"\"\"Check that allocators for non-StringDType arrays is NULL.\"\"\"",
        "\"\"\"Check that allocators for non-StringDType arrays"
    ],
    [
        "xfail_complex_tests = (not sys.platform.startswith('linux') or functions_seem_flaky)",
        "xfail_complex_tests = (not sys.platform.startswith('linux')"
    ],
    [
        "msgform = \"cexp(inf, inf) is (%f, %f), expected (+-inf, nan)\"",
        "msgform = \"cexp(inf, inf) is (%f, %f),"
    ],
    [
        "if not np.isinf(z.real) or not np.isnan(z.imag):",
        "if not np.isinf(z.real) or not"
    ],
    [
        "msgform = \"cexp(-inf, nan) is (%f, %f), expected (+-inf, nan)\"",
        "msgform = \"cexp(-inf, nan) is"
    ],
    [
        "if not np.isinf(z.real) or not np.isnan(z.imag):",
        "if not np.isinf(z.real) or"
    ],
    [
        "msgform = \"csqrt(-inf, nan) is (%f, %f), expected (nan, +-inf)\"",
        "msgform = \"csqrt(-inf, nan) is (%f,"
    ],
    [
        "n_r = [x[i] ** y[i] for i in lx]",
        "n_r = [x[i] ** y[i] for i in"
    ],
    [
        "assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' % i)",
        "assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' %"
    ],
    [
        "assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' % i)",
        "assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' %"
    ],
    [
        "assert len(xa) == len(x) == len(y)",
        "assert len(xa) =="
    ],
    [
        "for xi, yi in zip(x, y):",
        "for xi, yi in"
    ],
    [
        "reason=\"Complex arithmetic with signed zero fails on most platforms\")",
        "reason=\"Complex arithmetic with signed zero fails on most"
    ],
    [
        "\"\"\"Provide class for testing in French locale",
        "\"\"\"Provide class for testing in French"
    ],
    [
        "\"\"\"See if platform has a decimal point as comma locale.",
        "\"\"\"See if platform has a"
    ],
    [
        "Find a locale that uses a comma instead of a period as the",
        "Find a locale that uses a comma"
    ],
    [
        "Locale when the function was called.",
        "Locale when the function"
    ],
    [
        "First French locale found, None if none found.",
        "First French locale found, None if"
    ],
    [
        "\"\"\"Sets LC_NUMERIC to a locale with comma as decimal point.",
        "\"\"\"Sets LC_NUMERIC to a locale with comma as decimal"
    ],
    [
        "Classes derived from this class have setup and teardown methods that run",
        "Classes derived from this class have setup"
    ],
    [
        "tests with locale.LC_NUMERIC set to a locale where commas (',') are used as",
        "tests with locale.LC_NUMERIC set to a locale where"
    ],
    [
        "the decimal point instead of periods ('.'). On exit the locale is restored",
        "the decimal point instead of periods ('.')."
    ],
    [
        "to the initial locale. It also serves as context manager with the same",
        "to the initial locale. It also serves as context manager with the"
    ],
    [
        "effect. If no such locale is available, the test is skipped.",
        "effect. If no such locale is available, the"
    ],
    [
        "match=\"error raised inside the core-loop: non-finite factor!\"):",
        "match=\"error raised inside the"
    ],
    [
        "match=\"the resolved dtypes are not compatible\"):",
        "match=\"the resolved dtypes"
    ],
    [
        "\"\"\"The addition method is special for the scaled float, because it",
        "\"\"\"The addition method is special for the scaled float, because"
    ],
    [
        "includes the \"cast\" between different factors, thus cast-safety",
        "includes the \"cast\" between different factors,"
    ],
    [
        "with NamedTemporaryFile(\"wb\", delete=False, suffix=\".npz\") as f:",
        "with NamedTemporaryFile(\"wb\", delete=False, suffix=\".npz\")"
    ],
    [
        "], ids=[\"int_list\", \"ellipsis\", \"slice\", \"bool_array\", \"int_array\"])",
        "], ids=[\"int_list\", \"ellipsis\", \"slice\","
    ],
    [
        "_vec_string([['abc', 'def']], np.int_, 'find', (['a', 'd', 'j'],))",
        "_vec_string([['abc', 'def']], np.int_, 'find', (['a', 'd',"
    ],
    [
        "[[True, True, False], [True, True, True]])",
        "[[True, True, False],"
    ],
    [
        "[[False, False, True], [False, False, False]])",
        "[[False, False, True],"
    ],
    [
        "[[False, False, True], [True, False, True]])",
        "[[False, False, True], [True, False,"
    ],
    [
        "[[True, True, True], [False, True, False]])",
        "[[True, True, True], [False, True,"
    ],
    [
        "[[False, False, False], [True, False, True]])",
        "[[False, False, False],"
    ],
    [
        "[[True, True, False], [False, True, False]])",
        "[[True, True, False],"
    ],
    [
        "self.A = np.array([[' abc ', ''],",
        "self.A = np.array([[' abc ',"
    ],
    [
        "assert_array_equal(self.A.isalnum(), [[False, False], [True, True], [False, True]])",
        "assert_array_equal(self.A.isalnum(), [[False, False], [True, True],"
    ],
    [
        "assert_array_equal(self.A.isalpha(), [[False, False], [False, True], [False, True]])",
        "assert_array_equal(self.A.isalpha(), [[False, False], [False, True], [False,"
    ],
    [
        "assert_array_equal(self.A.isdigit(), [[False, False], [True, False], [False, False]])",
        "assert_array_equal(self.A.isdigit(), [[False, False], [True, False],"
    ],
    [
        "assert_array_equal(self.A.islower(), [[True, False], [False, False], [False, False]])",
        "assert_array_equal(self.A.islower(), [[True, False], [False, False],"
    ],
    [
        "assert_array_equal(self.A.isspace(), [[False, False], [False, False], [False, False]])",
        "assert_array_equal(self.A.isspace(), [[False, False], [False, False],"
    ],
    [
        "assert_array_equal(self.A.istitle(), [[False, False], [False, False], [False, False]])",
        "assert_array_equal(self.A.istitle(), [[False, False], [False, False],"
    ],
    [
        "assert_array_equal(self.A.isupper(), [[False, False], [False, False], [False, True]])",
        "assert_array_equal(self.A.isupper(), [[False, False], [False, False],"
    ],
    [
        "self.A = np.array([[' abc ', ''],",
        "self.A = np.array([[' abc"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b'"
    ],
    [
        "tgt = [[b'   FOO    ', b'        FOO         '],",
        "tgt = [[b' FOO ',"
    ],
    [
        "[b'      FOO      ', b'  FOO   ']]",
        "[b' FOO ', b'"
    ],
    [
        "tgt = np.array([[' ,a,b,c, ', ''],",
        "tgt = np.array([[' ,a,b,c,"
    ],
    [
        "[False, True], [False, False], [False, False]])",
        "[False, True], [False, False],"
    ],
    [
        "tgt = [[b'FOO       ', b'FOO                 '],",
        "tgt = [[b'FOO ',"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b' abc"
    ],
    [
        "tgt = [[(b' abc ', b'', b''), (b'', b'', b'')],",
        "tgt = [[(b' abc ', b'', b''), (b'', b'',"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b'"
    ],
    [
        "[[False, True], [False, False], [False, False]])",
        "[[False, True], [False, False], [False,"
    ],
    [
        "tgt = [[b'       FOO', b'                 FOO'],",
        "tgt = [[b' FOO',"
    ],
    [
        "tgt = [[(b'', b'', b' abc '), (b'', b'', b'')],",
        "tgt = [[(b'', b'', b'"
    ],
    [
        "tgt = [[[b' abc '], [b'']],",
        "tgt = [[[b'"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b' abc"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b' abc ',"
    ],
    [
        "tgt = [[b' ABC ', b''],",
        "tgt = [[b'"
    ],
    [
        "tgt = [[b' Abc ', b''],",
        "tgt = [[b'"
    ],
    [
        "tgt = [[b' ABC ', b''],",
        "tgt = [[b'"
    ],
    [
        "[False, False], [True, False], [False, False]])",
        "[False, False], [True, False],"
    ],
    [
        "[False, False], [True, False], [False, False]])",
        "[False, False], [True, False],"
    ],
    [
        "F = np.array([['%d', '%f'], ['%s', '%r']]).view(np.char.chararray)",
        "F = np.array([['%d', '%f'],"
    ],
    [
        "TypeError, \"unsupported operand type.* and 'chararray'\"):",
        "TypeError, \"unsupported operand type.* and"
    ],
    [
        "arr = np.array([['abc ', 'def '], ['geh ', 'ijk ']],",
        "arr = np.array([['abc ', 'def '], ['geh ',"
    ],
    [
        "A = np.array([[' abc ', ''],",
        "A = np.array([[' abc ',"
    ],
    [
        "s = \"\\tone level of indentation\\n\\t\\ttwo levels of indentation\"",
        "s = \"\\tone level of indentation\\n\\t\\ttwo levels of"
    ],
    [
        "\"  one level of indentation\\n    two levels of indentation\"",
        "\" one level of indentation\\n"
    ],
    [
        "from numpy._core.multiarray import CLIP, WRAP, RAISE",
        "from numpy._core.multiarray import"
    ],
    [
        "\"\"\"Takes valid non-deprecated inputs for converters,",
        "\"\"\"Takes valid non-deprecated inputs"
    ],
    [
        "runs converters on inputs, checks correctness of outputs,",
        "runs converters on inputs, checks correctness"
    ],
    [
        "self._check_value_error(\"there's no way this is supported\")",
        "self._check_value_error(\"there's no way this is"
    ],
    [
        "\"\"\" Test printing of scalar types.",
        "\"\"\" Test printing of"
    ],
    [
        "for wants, val in zip(wanted, svals):",
        "for wants, val in zip(wanted,"
    ],
    [
        "for want, styp in zip(wants, styps):",
        "for want, styp"
    ],
    [
        "preckwd = lambda prec: {'unique': False, 'precision': prec}",
        "preckwd = lambda prec: {'unique': False, 'precision':"
    ],
    [
        "The tests exercise the casting machinery in a more low-level manner.",
        "The tests exercise the casting machinery in a more"
    ],
    [
        "The reason is mostly to test a new implementation of the casting machinery.",
        "The reason is mostly to test a"
    ],
    [
        "Unlike most tests in NumPy, these are closer to unit-tests rather",
        "Unlike most tests in NumPy, these"
    ],
    [
        "from numpy._core._multiarray_umath import _get_castingimpl as get_castingimpl",
        "from numpy._core._multiarray_umath import _get_castingimpl"
    ],
    [
        "simple_dtypes = [type(np.dtype(c)) for c in simple_dtypes]",
        "simple_dtypes = [type(np.dtype(c)) for c in"
    ],
    [
        "\"\"\"Returns the string length when casting the basic dtypes to strings.",
        "\"\"\"Returns the string length when casting the basic"
    ],
    [
        "raise AssertionError(f\"did not find expected length for {dtype}\")",
        "raise AssertionError(f\"did not find expected"
    ],
    [
        "raise AssertionError(f\"did not find expected length for {dtype}\")",
        "raise AssertionError(f\"did not find expected"
    ],
    [
        "X ? b h i l q B H I L Q e f d g F D G S U V O M m",
        "X ? b h i l q B H I L Q e"
    ],
    [
        "convert_cast = {\".\": Casting.unsafe, \"~\": Casting.same_kind,",
        "convert_cast = {\".\":"
    ],
    [
        "These test cases exercise some behaviour changes",
        "These test cases exercise"
    ],
    [
        "values = [bool(v) for v in values]",
        "values = [bool(v) for v"
    ],
    [
        "values = [bool(v) for v in values]",
        "values = [bool(v) for"
    ],
    [
        "casting, (from_res, to_res), view_off = (",
        "casting, (from_res, to_res), view_off ="
    ],
    [
        "This test checks numeric direct casts for dtypes supported also by the",
        "This test checks numeric direct casts for"
    ],
    [
        "struct module (plus complex).  It tries to be test a wide range of",
        "struct module (plus complex). It tries to be test a wide range"
    ],
    [
        "inputs, but skips over possibly undefined behaviour (e.g. int rollover).",
        "inputs, but skips over possibly"
    ],
    [
        "Longdouble and CLongdouble are tested, but only using double precision.",
        "Longdouble and CLongdouble are tested, but only using double"
    ],
    [
        "If this test creates issues, it should possibly just be simplified",
        "If this test creates issues, it should possibly just be"
    ],
    [
        "or even removed (checking whether unaligned/non-contiguous casts give",
        "or even removed (checking whether unaligned/non-contiguous"
    ],
    [
        "the same results is useful, though).",
        "the same results is useful,"
    ],
    [
        "casting, (from_res, to_res), view_off = cast._resolve_descriptors(",
        "casting, (from_res, to_res), view_off ="
    ],
    [
        "if from_res is not from_dt or to_res is not to_dt:",
        "if from_res is not from_dt"
    ],
    [
        "casting, (from_res, to_res), view_off = cast._resolve_descriptors(",
        "casting, (from_res, to_res), view_off"
    ],
    [
        "casting, (from_res, to_res), view_off = cast._resolve_descriptors(",
        "casting, (from_res, to_res),"
    ],
    [
        "assert to_res is to_dt or to_dt is None",
        "assert to_res is to_dt or"
    ],
    [
        "expected_out = (values * nom // denom).view(to_res)",
        "expected_out = (values *"
    ],
    [
        "length = dtype.itemsize // fact + change_length",
        "length = dtype.itemsize // fact +"
    ],
    [
        "safety, (res_other_dt, res_dt), view_off = cast._resolve_descriptors(",
        "safety, (res_other_dt, res_dt), view_off ="
    ],
    [
        "assert res_dt.itemsize == expected_length * fact",
        "assert res_dt.itemsize == expected_length *"
    ],
    [
        "safety, (_, res_dt), view_off = cast._resolve_descriptors(",
        "safety, (_, res_dt), view_off"
    ],
    [
        "safety, _, view_off = cast._resolve_descriptors((string_dt, other_dt))",
        "safety, _, view_off ="
    ],
    [
        "safety, (_, res_dt), view_off = cast._resolve_descriptors(",
        "safety, (_, res_dt), view_off ="
    ],
    [
        "Tests casts from and to string by checking the roundtripping property.",
        "Tests casts from and to string by"
    ],
    [
        "The test also covers some string to string casts (but not all).",
        "The test also covers some string to string casts"
    ],
    [
        "If this test creates issues, it should possibly just be simplified",
        "If this test creates issues, it should possibly"
    ],
    [
        "or even removed (checking whether unaligned/non-contiguous casts give",
        "or even removed (checking"
    ],
    [
        "the same results is useful, though).",
        "the same results is useful,"
    ],
    [
        "_, (res_other_dt, string_dt), _ = cast._resolve_descriptors(",
        "_, (res_other_dt, string_dt), _ ="
    ],
    [
        "safety, (res_other_dt, res_dt), view_off = cast._resolve_descriptors(",
        "safety, (res_other_dt, res_dt), view_off ="
    ],
    [
        "assert res_dt.itemsize == expected_length * fact",
        "assert res_dt.itemsize == expected_length *"
    ],
    [
        "safety, (_, res_dt), view_off = cast._resolve_descriptors(",
        "safety, (_, res_dt), view_off ="
    ],
    [
        "element = \"this is a Ã¼nicode stringâ€½\"",
        "element = \"this is a Ã¼nicode"
    ],
    [
        "match=\"casting from object to the parametric DType\"):",
        "match=\"casting from object to the parametric"
    ],
    [
        "safety, (_, res_dt), view_off = cast._resolve_descriptors(",
        "safety, (_, res_dt), view_off"
    ],
    [
        "safety, (_, res_dt), view_off = cast._resolve_descriptors(",
        "safety, (_, res_dt), view_off ="
    ],
    [
        "safety, (_, res_dt), view_off = cast._resolve_descriptors(",
        "safety, (_, res_dt), view_off ="
    ],
    [
        "safety, _, view_off = cast._resolve_descriptors((from_dt, to_dt))",
        "safety, _, view_off"
    ],
    [
        "_, _, view_off = cast._resolve_descriptors((from_dt, to_dt))",
        "_, _, view_off"
    ],
    [
        "f\"{t.__name__} is not instance of Real\")",
        "f\"{t.__name__} is not"
    ],
    [
        "f\"{t.__name__} is not subclass of Real\")",
        "f\"{t.__name__} is not"
    ],
    [
        "f\"{t.__name__} is not instance of Complex\")",
        "f\"{t.__name__} is not instance"
    ],
    [
        "f\"{t.__name__} is not subclass of Complex\")",
        "f\"{t.__name__} is not subclass of"
    ],
    [
        "f\"{t.__name__} is not instance of Integral\")",
        "f\"{t.__name__} is not instance"
    ],
    [
        "f\"{t.__name__} is not subclass of Integral\")",
        "f\"{t.__name__} is not subclass of"
    ],
    [
        "f\"{t.__name__} is not instance of Integral\")",
        "f\"{t.__name__} is not instance of"
    ],
    [
        "f\"{t.__name__} is not subclass of Integral\")",
        "f\"{t.__name__} is not subclass of"
    ],
    [
        "UNARY_UFUNCS = [obj for obj in np._core.umath.__dict__.values()",
        "UNARY_UFUNCS = [obj for obj in"
    ],
    [
        "UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if \"O->O\" in uf.types]",
        "UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if \"O->O\" in"
    ],
    [
        "The loops to be tested are:",
        "The loops to be tested"
    ],
    [
        "It is difficult to assure that each of these loops is entered from the",
        "It is difficult to assure that each"
    ],
    [
        "Python level as the special cased loops are a moving target and the",
        "Python level as the special cased loops"
    ],
    [
        "corresponding types are architecture dependent. We probably need to",
        "corresponding types are architecture dependent. We"
    ],
    [
        "define C level testing ufuncs to get at them. For the time being, I've",
        "define C level testing ufuncs to get at them. For"
    ],
    [
        "just looked at the signatures registered in the build directory to find",
        "just looked at the signatures registered in the"
    ],
    [
        "\"\"\"Compare the result of the object loop with non-object one\"\"\"",
        "\"\"\"Compare the result of the object"
    ],
    [
        "@pytest.mark.skipif(IS_PYPY, reason=\"'is' check does not work on PyPy\")",
        "@pytest.mark.skipif(IS_PYPY, reason=\"'is' check does not work on"
    ],
    [
        "\"\"\"Try to check presence and results of all ufuncs.",
        "\"\"\"Try to check presence and results of"
    ],
    [
        "The list of ufuncs comes from generate_umath.py and is as follows:",
        "The list of ufuncs comes from generate_umath.py and is as"
    ],
    [
        "Types other than those listed will be accepted, but they are cast to",
        "Types other than those listed will be accepted, but"
    ],
    [
        "the smallest compatible type for which the function is defined. The",
        "the smallest compatible type for which the"
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags, sizes ="
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags,"
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags,"
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags, sizes"
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags, sizes"
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags, sizes"
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags,"
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags, sizes ="
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags,"
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags, sizes ="
    ],
    [
        "enabled, num_dims, ixs, flags, sizes = umt.test_signature(",
        "enabled, num_dims, ixs, flags, sizes"
    ],
    [
        "lambda dt: {\"signature\": (dt, None, None)}])",
        "lambda dt: {\"signature\": (dt, None,"
    ],
    [
        "param(lambda x: {\"signature\": (x, None, None)}, id=\"signature\")])",
        "param(lambda x: {\"signature\": (x, None, None)},"
    ],
    [
        "msg = \"The `dtype` and `signature` arguments to ufuncs\"",
        "msg = \"The `dtype` and `signature`"
    ],
    [
        "match=\"the signature object to ufunc must be a string or\"):",
        "match=\"the signature object to ufunc must be"
    ],
    [
        "\"\"\"Basic test for the safest casts, because ufuncs inner loops can",
        "\"\"\"Basic test for the safest casts,"
    ],
    [
        "indicate a cast-safety as well (which is normally always \"no\").",
        "indicate a cast-safety as well (which is normally always"
    ],
    [
        "for x, y in itertools.product([aa, -aa], [bb, -bb]):",
        "for x, y in"
    ],
    [
        "if not np.isfinite(res) and tcout == 'e':",
        "if not np.isfinite(res) and"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "expected = np.einsum('...i,ij,...j', vec.conj(), mat, vec)",
        "expected = np.einsum('...i,ij,...j', vec.conj(),"
    ],
    [
        "with pytest.raises(TypeError, match=r\"\\*: 'float' and 'NoneType'\"):",
        "with pytest.raises(TypeError, match=r\"\\*: 'float'"
    ],
    [
        "msg = \"extend & broadcast loop dimensions\"",
        "msg = \"extend & broadcast"
    ],
    [
        "msg = \"type cast on one argument\"",
        "msg = \"type cast on"
    ],
    [
        "msg = \"incontiguous memory layout of array\"",
        "msg = \"incontiguous memory"
    ],
    [
        "msg = \"output argument with type cast\"",
        "msg = \"output argument"
    ],
    [
        "msg = \"output argument with incontiguous layout\"",
        "msg = \"output argument with"
    ],
    [
        "assert_raises(TypeError, mm, a, b, axes=[None, None, None])",
        "assert_raises(TypeError, mm, a, b, axes=[None,"
    ],
    [
        "d = np.vecdot(a, b, keepdims=True, out=out)",
        "d = np.vecdot(a, b,"
    ],
    [
        "\"\"\"Test generalized ufunc with zero-sized operands\"\"\"",
        "\"\"\"Test generalized ufunc"
    ],
    [
        "np.array([x or None for x in a], dtype=object))",
        "np.array([x or None for x in"
    ],
    [
        "np.array([x or True for x in a], dtype=object))",
        "np.array([x or True for x"
    ],
    [
        "np.array([x or \"blah\" for x in a], dtype=object))",
        "np.array([x or \"blah\" for x in"
    ],
    [
        "np.array([x and None for x in a], dtype=object))",
        "np.array([x and None for x in a],"
    ],
    [
        "np.array([x and True for x in a], dtype=object))",
        "np.array([x and True for x in a],"
    ],
    [
        "np.array([x and \"blah\" for x in a], dtype=object))",
        "np.array([x and \"blah\" for x in"
    ],
    [
        "np.array([not x for x in a], dtype=object))",
        "np.array([not x for x"
    ],
    [
        "a = np.array(['a', 'b', 'c'], dtype=object)",
        "a = np.array(['a',"
    ],
    [
        "a = np.array([True, False, True], dtype=object)",
        "a = np.array([True, False, True],"
    ],
    [
        "for a in [[], np.array([], dtype=object)]:",
        "for a in"
    ],
    [
        "The type of the result should always depend on the selected loop, not",
        "The type of the result should always"
    ],
    [
        "necessarily the output (only relevant for object arrays).",
        "necessarily the output (only relevant"
    ],
    [
        "res = np.maximum.reduce(a, axis=axis, where=where, initial=initial)",
        "res = np.maximum.reduce(a,"
    ],
    [
        "def __array_wrap__(cls, array, context=None, return_scalar = False):",
        "def __array_wrap__(cls, array, context=None,"
    ],
    [
        "indexed_ufuncs = [np.add, np.subtract, np.multiply, np.floor_divide,",
        "indexed_ufuncs = [np.add,"
    ],
    [
        "if ufunc is np.divide and typecode in np.typecodes['AllInteger']:",
        "if ufunc is np.divide and typecode in"
    ],
    [
        "for i, v in zip(indx, vals):",
        "for i, v"
    ],
    [
        "for i, v in zip(indxs, vals):",
        "for i, v"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc,"
    ],
    [
        "target = np.array([True, False, False, False], dtype=bool)",
        "target = np.array([True, False, False,"
    ],
    [
        "[(None, None, object), (object, None, None),",
        "[(None, None, object), (object,"
    ],
    [
        "a = np.array([True, None, False], dtype=object)",
        "a = np.array([True, None, False],"
    ],
    [
        "[(bool, None, object), (object, None, bool),",
        "[(bool, None, object), (object, None,"
    ],
    [
        "assert exc.match('loop of ufunc does not support')",
        "assert exc.match('loop of ufunc does"
    ],
    [
        "@pytest.mark.parametrize('ufunc', [getattr(np, x) for x in dir(np)",
        "@pytest.mark.parametrize('ufunc', [getattr(np, x) for x"
    ],
    [
        "Check all ufuncs that the correct type is returned. Avoid",
        "Check all ufuncs that the correct type"
    ],
    [
        "object and boolean types since many operations are not defined for",
        "object and boolean types since many"
    ],
    [
        "Choose the shape so even dot and matmul will succeed",
        "Choose the shape so even dot and matmul will"
    ],
    [
        "if 'O' in typ or '?' in typ:",
        "if 'O' in typ"
    ],
    [
        "for r, t in zip(res, outs):",
        "for r, t"
    ],
    [
        "@pytest.mark.parametrize('ufunc', [getattr(np, x) for x in dir(np)",
        "@pytest.mark.parametrize('ufunc', [getattr(np, x) for x"
    ],
    [
        "Check that contiguous and non-contiguous calls to ufuncs",
        "Check that contiguous and non-contiguous calls to"
    ],
    [
        "dtype = np.dtype([(\"_\", off_dt), (\"t\", orig_dt)], align=False)",
        "dtype = np.dtype([(\"_\", off_dt),"
    ],
    [
        "for a in args_c + args_n + args_o:",
        "for a in args_c +"
    ],
    [
        "for c_ar, n_ar, o_ar in zip(res_c, res_n, res_o):",
        "for c_ar, n_ar, o_ar in"
    ],
    [
        "arr = np.array([value] * bad_offset +",
        "arr = np.array([value] * bad_offset"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "arr = np.array([value] * bad_offset +",
        "arr = np.array([value] *"
    ],
    [
        "arr = np.array([value] * offset +",
        "arr = np.array([value] *"
    ],
    [
        "assert out[()] < value * offset",
        "assert out[()] < value *"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "arr = np.array([neg_zero] * i, dtype=dtype)",
        "arr = np.array([neg_zero] *"
    ],
    [
        "[(\"S\", \"U\"), (\"U\", \"S\"), (\"S\", \"d\"), (\"S\", \"V\"), (\"U\", \"l\")])",
        "[(\"S\", \"U\"), (\"U\", \"S\"), (\"S\", \"d\"), (\"S\", \"V\"),"
    ],
    [
        "[(\">\", \">\"), (\"<\", \"<\"), (\">\", \"<\"), (\"<\", \">\")])",
        "[(\">\", \">\"), (\"<\", \"<\"), (\">\", \"<\"), (\"<\","
    ],
    [
        "result = np._core.umath.find(arr, \"a\", start, end)",
        "result = np._core.umath.find(arr, \"a\", start,"
    ],
    [
        "assert res == (default_int_, default_int_, default_int_)",
        "assert res =="
    ],
    [
        "ct.c_int, ct.c_void_p, data_t, dim_t, strides_t, ct.c_void_p)",
        "ct.c_int, ct.c_void_p, data_t, dim_t, strides_t,"
    ],
    [
        "from hypothesis.extra import numpy as hynp",
        "from hypothesis.extra import"
    ],
    [
        "\"two equivalent types do not hash to the same value !\")",
        "\"two equivalent types do not hash to the"
    ],
    [
        "\"two different types hash to the same value !\")",
        "\"two different types hash to"
    ],
    [
        "\"\"\"Only test hash runs at all.\"\"\"",
        "\"\"\"Only test hash runs"
    ],
    [
        "\"\"\"Test whether equivalent record dtypes hash the same.\"\"\"",
        "\"\"\"Test whether equivalent record dtypes hash"
    ],
    [
        "d = {\"names\": names, \"formats\": formats, \"titles\": titles, \"offsets\": offsets}",
        "d = {\"names\": names, \"formats\":"
    ],
    [
        "refcounts = {k: sys.getrefcount(i) for k, i in d.items()}",
        "refcounts = {k: sys.getrefcount(i) for k, i"
    ],
    [
        "refcounts_new = {k: sys.getrefcount(i) for k, i in d.items()}",
        "refcounts_new = {k: sys.getrefcount(i) for k, i"
    ],
    [
        "with pytest.raises(ValueError, match=\"must replace all names at once\"):",
        "with pytest.raises(ValueError, match=\"must replace all names at"
    ],
    [
        "\"\"\"Test if an appropriate exception is raised when passing bad values to",
        "\"\"\"Test if an appropriate exception is raised when passing bad values"
    ],
    [
        "\"\"\"Test whether equivalent subarray dtypes hash the same.\"\"\"",
        "\"\"\"Test whether equivalent subarray dtypes hash the"
    ],
    [
        "\"\"\"Test whether different subarray dtypes hash differently.\"\"\"",
        "\"\"\"Test whether different subarray"
    ],
    [
        "\"\"\"Test some data types that are equal\"\"\"",
        "\"\"\"Test some data types"
    ],
    [
        "\"\"\"Test some simple cases that shouldn't be equal\"\"\"",
        "\"\"\"Test some simple cases that"
    ],
    [
        "\"\"\"Test some more complicated cases that shouldn't be equal\"\"\"",
        "\"\"\"Test some more complicated cases"
    ],
    [
        "Iterates over a few complex dtypes and object pattern which",
        "Iterates over a few complex dtypes and"
    ],
    [
        "fill the array with a given object (defaults to a singleton).",
        "fill the array with a given object"
    ],
    [
        "Structured tuple for use with `np.array`.",
        "Structured tuple for use"
    ],
    [
        "Number of objects stored in the dtype.",
        "Number of objects stored"
    ],
    [
        "A singleton object. The returned pattern is constructed so that",
        "A singleton object. The returned"
    ],
    [
        "all objects inside the datatype are set to the singleton.",
        "all objects inside the datatype"
    ],
    [
        "\"\"\"These tests cover various uses of complicated structured types which",
        "\"\"\"These tests cover various uses of complicated structured types"
    ],
    [
        "include objects and thus require reference counting.",
        "include objects and thus require reference"
    ],
    [
        "def test_structured_object_create_delete(self, dt, pat, count, singleton,",
        "def test_structured_object_create_delete(self, dt,"
    ],
    [
        "\"\"\"Structured object reference counting in creation and deletion\"\"\"",
        "\"\"\"Structured object reference counting in creation"
    ],
    [
        "def test_structured_object_item_setting(self, dt, pat, count, singleton):",
        "def test_structured_object_item_setting(self, dt,"
    ],
    [
        "\"\"\"Structured object reference counting for simple item setting\"\"\"",
        "\"\"\"Structured object reference counting"
    ],
    [
        "\"\"\"Structured object reference counting for advanced indexing.\"\"\"",
        "\"\"\"Structured object reference counting"
    ],
    [
        "def test_structured_object_take_and_repeat(self, dt, pat, count, singleton):",
        "def test_structured_object_take_and_repeat(self, dt, pat, count,"
    ],
    [
        "\"\"\"Structured object reference counting for specialized functions.",
        "\"\"\"Structured object reference counting for specialized"
    ],
    [
        "The older functions such as take and repeat use different code paths",
        "The older functions such as take and repeat use different"
    ],
    [
        "then item setting (when writing this).",
        "then item setting (when writing"
    ],
    [
        "\"\"\"Tests subarray fields which contain sparse dtypes so that",
        "\"\"\"Tests subarray fields which contain sparse dtypes"
    ],
    [
        "not all memory is used by the dtype work. Such dtype's should",
        "not all memory is used by the dtype work. Such dtype's"
    ],
    [
        "dtype = np.dtype([('a', {'names': ['aa', 'ab'], 'formats': ['f', 'f'],",
        "dtype = np.dtype([('a', {'names': ['aa', 'ab'], 'formats':"
    ],
    [
        "sparse_dtype = np.dtype([('a', {'names': ['ab'], 'formats': ['f'],",
        "sparse_dtype = np.dtype([('a', {'names':"
    ],
    [
        "'titles': ['Red pixel', 'Green pixel', 'Blue pixel']})",
        "'titles': ['Red pixel', 'Green pixel', 'Blue"
    ],
    [
        "dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],",
        "dt = np.dtype({'names': ['rgba',"
    ],
    [
        "\" 'titles': ['Color', 'Red pixel', \"",
        "\" 'titles': ['Color', 'Red"
    ],
    [
        "\" 'titles': ['Red pixel', 'Blue pixel'],\"",
        "\" 'titles': ['Red pixel',"
    ],
    [
        "'titles': ['Red pixel', 'Green pixel', 'Blue pixel']},",
        "'titles': ['Red pixel', 'Green pixel',"
    ],
    [
        "dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],",
        "dt = np.dtype({'names': ['rgba',"
    ],
    [
        "\" 'titles': ['Color', 'Red pixel', \"",
        "\" 'titles': ['Color',"
    ],
    [
        "\"'titles': ['Red pixel', 'Blue pixel'], \"",
        "\"'titles': ['Red pixel', 'Blue"
    ],
    [
        "attr = [\"subdtype\", \"descr\", \"str\", \"name\", \"base\", \"shape\",",
        "attr = [\"subdtype\", \"descr\", \"str\","
    ],
    [
        "Check most properties relevant to \"canonical\" versions of a dtype,",
        "Check most properties relevant to \"canonical\" versions of"
    ],
    [
        "which is mainly native byte order for datatypes supporting this.",
        "which is mainly native byte order for datatypes"
    ],
    [
        "The main work is checking structured dtypes with fields, where we",
        "The main work is checking structured dtypes with fields, where"
    ],
    [
        "reproduce most the actual logic used in the C-code.",
        "reproduce most the actual logic used in the"
    ],
    [
        "return - (-offset // alignment) * alignment",
        "return - (-offset //"
    ],
    [
        "assert (canonical.flags & expected) == expected",
        "assert (canonical.flags &"
    ],
    [
        "@pytest.mark.parametrize('unit', ['', 'Y', 'M', 'W', 'D', 'h', 'm', 's',",
        "@pytest.mark.parametrize('unit', ['', 'Y', 'M', 'W',"
    ],
    [
        "'ms', 'us', 'ns', 'ps', 'fs', 'as'])",
        "'ms', 'us', 'ns',"
    ],
    [
        "dt = np.dtype('%s[%s]' % (base, unit) if unit else base)",
        "dt = np.dtype('%s[%s]' % (base, unit) if"
    ],
    [
        "[type(np.dtype(t)) for t in np.typecodes['All']] +",
        "[type(np.dtype(t)) for t in"
    ],
    [
        "[np.dtype(t) for t in np.typecodes['All']] +",
        "[np.dtype(t) for t in np.typecodes['All']]"
    ],
    [
        "\"\"\"Test cases related to more complex DType promotions.  Further promotion",
        "\"\"\"Test cases related to more"
    ],
    [
        "match=r\".* no common DType exists for the given inputs\"):",
        "match=r\".* no common DType exists for"
    ],
    [
        "match=r\".* no common DType exists for the given inputs\"):",
        "match=r\".* no common DType exists for the"
    ],
    [
        "if dt_name == \"uint\" or dt_name == \"int\":",
        "if dt_name == \"uint\""
    ],
    [
        "\"names\": ['a', 'b', 'c', 'd', 'e', 'f', 'g'],",
        "\"names\": ['a', 'b', 'c',"
    ],
    [
        "Check that np.dtype('x,y') matches [np.dtype('x'), np.dtype('y')]",
        "Check that np.dtype('x,y')"
    ],
    [
        "def test_dtype_subclass(self, code: str) -> None:",
        "def test_dtype_subclass(self, code: str) ->"
    ],
    [
        "def test_subscript_tuple(self, arg_len: int) -> None:",
        "def test_subscript_tuple(self, arg_len: int)"
    ],
    [
        "with pytest.raises(TypeError, match=\"Cannot convert np.dtype into a\"):",
        "with pytest.raises(TypeError, match=\"Cannot convert"
    ],
    [
        "from ctypes import c_longlong, c_double, c_float, c_int, cast, pointer, POINTER",
        "from ctypes import c_longlong, c_double, c_float,"
    ],
    [
        "UNARY_UFUNCS = [obj for obj in np._core.umath.__dict__.values() if",
        "UNARY_UFUNCS = [obj for"
    ],
    [
        "UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if \"O->O\" in uf.types]",
        "UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if \"O->O\""
    ],
    [
        "files = list(filter(lambda f: f.endswith('.csv'), files))",
        "files = list(filter(lambda"
    ],
    [
        "This testing unit only for checking the sanity of common functionality,",
        "This testing unit only for checking the sanity"
    ],
    [
        "therefore all we need is just to take one submodule that represents any",
        "therefore all we need is just to take one submodule that"
    ],
    [
        "of enabled SIMD extensions to run the test on it and the second submodule",
        "of enabled SIMD extensions to run the test"
    ],
    [
        "required to run only one check related to the possibility of mixing",
        "required to run only one check"
    ],
    [
        "the data types among each submodule.",
        "the data types"
    ],
    [
        "npyvs = [npyv_mod for npyv_mod in targets.values() if npyv_mod and npyv_mod.simd]",
        "npyvs = [npyv_mod for npyv_mod in"
    ],
    [
        "@pytest.mark.skipif(not npyv, reason=\"could not find any SIMD extension with NPYV support\")",
        "@pytest.mark.skipif(not npyv, reason=\"could not find any SIMD extension"
    ],
    [
        "nlanes = getattr(npyv, \"nlanes_\" + sfx)",
        "nlanes = getattr(npyv, \"nlanes_\""
    ],
    [
        "assert vector.__name__ == \"npyv_\" + sfx",
        "assert vector.__name__ == \"npyv_\""
    ],
    [
        "vcb = lambda intrin: getattr(npyv, f\"{intrin}_{sfx}\")",
        "vcb = lambda intrin:"
    ],
    [
        "\"could not find a second SIMD extension with NPYV support\"",
        "\"could not find a second SIMD"
    ],
    [
        "nlanes = getattr(npyv, \"nlanes_\" + sfx)",
        "nlanes = getattr(npyv,"
    ],
    [
        "assert lanes == [maxu] * nlanes",
        "assert lanes =="
    ],
    [
        "assert lanes == [maxu] * nlanes",
        "assert lanes =="
    ],
    [
        "nlanes = getattr(npyv, \"nlanes_\" + sfx)",
        "nlanes = getattr(npyv, \"nlanes_\""
    ],
    [
        "\"\"\" Test functions for limits module.",
        "\"\"\" Test functions for limits"
    ],
    [
        "from numpy import half, single, double, longdouble",
        "from numpy import half, single, double,"
    ],
    [
        "from numpy.testing import assert_equal, assert_, assert_raises",
        "from numpy.testing import assert_equal, assert_,"
    ],
    [
        "for attr in ('bits', 'eps', 'epsneg', 'iexp', 'machep',",
        "for attr in ('bits',"
    ],
    [
        "'max', 'maxexp', 'min', 'minexp', 'negep', 'nexp',",
        "'max', 'maxexp', 'min',"
    ],
    [
        "for attr in ('bits', 'min', 'max'):",
        "for attr in ('bits',"
    ],
    [
        "\"\"\"Test that the subnormal is zero warning is not being raised.\"\"\"",
        "\"\"\"Test that the subnormal is zero"
    ],
    [
        "for ftype in np._core.sctypes['float'] + np._core.sctypes['complex']:",
        "for ftype in np._core.sctypes['float'] +"
    ],
    [
        "from numpy.testing._private.utils import get_stringdtype_dtype as get_dtype",
        "from numpy.testing._private.utils import"
    ],
    [
        "params=[\"unset\", None, pd_NA, np.nan, float(\"nan\"), \"__nan__\"],",
        "params=[\"unset\", None, pd_NA, np.nan, float(\"nan\"),"
    ],
    [
        "ids=[\"unset\", \"None\", \"pandas.NA\", \"np.nan\", \"float('nan')\", \"string nan\"],",
        "ids=[\"unset\", \"None\", \"pandas.NA\", \"np.nan\","
    ],
    [
        "assert not hasattr(dt, \"na_object\") and dt.coerce is True",
        "assert not hasattr(dt, \"na_object\") and dt.coerce is"
    ],
    [
        "assert dt.na_object is None and dt.coerce is True",
        "assert dt.na_object is None and dt.coerce is"
    ],
    [
        "assert not hasattr(dt, \"na_object\") and dt.coerce is False",
        "assert not hasattr(dt, \"na_object\") and dt.coerce is"
    ],
    [
        "assert dt.na_object is None and dt.coerce is False",
        "assert dt.na_object is None and"
    ],
    [
        "if not hasattr(dtype, \"na_object\") and dtype.coerce:",
        "if not hasattr(dtype, \"na_object\") and"
    ],
    [
        "pytest.skip(\"does not have an na object\")",
        "pytest.skip(\"does not have an na"
    ],
    [
        "assert str(arr) == \"[\" + \" \".join([repr(s) for s in string_list]) + \"]\"",
        "assert str(arr) == \"[\" + \" \".join([repr(s) for"
    ],
    [
        "strings = [s_medium, s_empty, s_short, s_medium, s_long]",
        "strings = [s_medium, s_empty,"
    ],
    [
        "for s in [a[i], s_medium + s_short, s_short, s_empty, s_long]:",
        "for s in [a[i], s_medium"
    ],
    [
        "arr = np.array([\"a\", \"b\", \"c\"], dtype=StringDType())",
        "arr = np.array([\"a\", \"b\","
    ],
    [
        "assert str(arr) == \"[\" + \" \".join([\"'\" + str(d) + \"'\" for d in data]) + \"]\"",
        "assert str(arr) == \"[\" + \" \".join([\"'\" + str(d) + \"'\" for d in data]) +"
    ],
    [
        "str_vals = [str(d) for d in data]",
        "str_vals = [str(d) for d in"
    ],
    [
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\", \"â˜ƒâ‚¬ðŸ˜Š AÂ¢\", \"ðŸ˜Šâ˜ƒAÂ¢ â‚¬\"],",
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\", \"â˜ƒâ‚¬ðŸ˜Š AÂ¢\","
    ],
    [
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\", \"â˜ƒâ‚¬ðŸ˜Š AÂ¢\", \"ðŸ˜Šâ˜ƒAÂ¢ â‚¬\"],",
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\","
    ],
    [
        "\"\"\"Test that inserting a scalar works.\"\"\"",
        "\"\"\"Test that inserting a"
    ],
    [
        "sarr = np.array(string_list + [dtype.na_object], dtype=dtype)",
        "sarr = np.array(string_list + [dtype.na_object],"
    ],
    [
        "is_nan = isinstance(dtype.na_object, float) and np.isnan(dtype.na_object)",
        "is_nan = isinstance(dtype.na_object, float)"
    ],
    [
        "[\"left\", \"right\", \"leftovers\", \"righty\", \"up\", \"down\"],",
        "[\"left\", \"right\", \"leftovers\", \"righty\","
    ],
    [
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\", \"â˜ƒâ‚¬ðŸ˜Š AÂ¢\", \"ðŸ˜Šâ˜ƒAÂ¢ â‚¬\"],",
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\", \"â˜ƒâ‚¬ðŸ˜Š"
    ],
    [
        "\"\"\"Test that sorting matches python's internal sorting.\"\"\"",
        "\"\"\"Test that sorting matches python's"
    ],
    [
        "if na_object is None and None in strings:",
        "if na_object is None"
    ],
    [
        "match=\"Cannot compare null that is not a nan-like value\",",
        "match=\"Cannot compare null that is"
    ],
    [
        "elif na_object is pd_NA or na_object != '':",
        "elif na_object is pd_NA or"
    ],
    [
        "if na_object is None and None in strings:",
        "if na_object is None and None"
    ],
    [
        "match=\"Cannot compare null that is not a nan-like value\",",
        "match=\"Cannot compare null that is not a"
    ],
    [
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\", \"â˜ƒâ‚¬ðŸ˜Š AÂ¢\", \"ðŸ˜Šâ˜ƒAÂ¢ â‚¬\"],",
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\", \"â˜ƒâ‚¬ðŸ˜Š AÂ¢\","
    ],
    [
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \"\", \" \", \"ï€ \"],",
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \"\", \" \", \"ï€"
    ],
    [
        "if na_object is not pd_NA and na_object == 'unset':",
        "if na_object is not pd_NA and na_object =="
    ],
    [
        "strings_with_na = np.array(strings + [na_object], dtype=dtype)",
        "strings_with_na = np.array(strings + [na_object],"
    ],
    [
        "res = np.where([True, False, True, False, True, False], a, b)",
        "res = np.where([True, False, True, False, True, False],"
    ],
    [
        "for b in [rop, np.array(rop, dtype=\"T\")]:",
        "for b in [rop,"
    ],
    [
        "sarr_cat = np.array(string_list + string_list, dtype=\"T\")",
        "sarr_cat = np.array(string_list + string_list,"
    ],
    [
        "with pytest.raises(ValueError, match=\"Unable to avoid copy\"):",
        "with pytest.raises(ValueError, match=\"Unable"
    ],
    [
        "[\"left\", \"right\", \"leftovers\", \"righty\", \"up\", \"down\"],",
        "[\"left\", \"right\", \"leftovers\", \"righty\","
    ],
    [
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\", \"â˜ƒâ‚¬ðŸ˜Š AÂ¢\", \"ðŸ˜Šâ˜ƒAÂ¢ â‚¬\"],",
        "[\"AÂ¢â˜ƒâ‚¬ ðŸ˜Š\", \" Aâ˜ƒâ‚¬Â¢ðŸ˜Š\","
    ],
    [
        "\"\"\"Test that argmax/argmin matches what python calculates.\"\"\"",
        "\"\"\"Test that argmax/argmin matches"
    ],
    [
        "[[\"hello\", \"world\"], [True, True], True, True],",
        "[[\"hello\", \"world\"], [True, True], True,"
    ],
    [
        "[[\"\", \"\"], [False, False], False, False],",
        "[[\"\", \"\"], [False,"
    ],
    [
        "[[\"hello\", \"\"], [True, False], True, False],",
        "[[\"hello\", \"\"], [True,"
    ],
    [
        "[[\"\", \"world\"], [False, True], True, False],",
        "[[\"\", \"world\"], [False,"
    ],
    [
        "eres = [np.inf, fi.max, -np.inf, fi.min]",
        "eres = [np.inf,"
    ],
    [
        "\"\"\"Test that the min/max ufuncs match Python builtin min/max behavior.\"\"\"",
        "\"\"\"Test that the min/max ufuncs match"
    ],
    [
        "ufunc = getattr(np, ufunc_name + \"imum\")",
        "ufunc = getattr(np, ufunc_name +"
    ],
    [
        "arr = np.array(['y', 'y', 'z'], dtype=\"T\")",
        "arr = np.array(['y',"
    ],
    [
        "[\"ðŸšœ\", \"ðŸ™ƒ\", \"ðŸ˜¾\", \"ðŸ˜¹\", \"ðŸš \", \"ðŸšŒ\"],",
        "[\"ðŸšœ\", \"ðŸ™ƒ\", \"ðŸ˜¾\", \"ðŸ˜¹\", \"ðŸš \","
    ],
    [
        "[\"ðŸ¥¦\", \"Â¨\", \"â¨¯\", \"âˆ° \", \"â¨Œ \", \"âŽ¶ \"],",
        "[\"ðŸ¥¦\", \"Â¨\", \"â¨¯\", \"âˆ° \", \"â¨Œ"
    ],
    [
        "is_nan = isinstance(dtype.na_object, float) and np.isnan(dtype.na_object)",
        "is_nan = isinstance(dtype.na_object,"
    ],
    [
        "if is_nan or bool_errors or is_str:",
        "if is_nan or bool_errors"
    ],
    [
        "values = [\"a\", \"this is a long string\", \"c\"]",
        "values = [\"a\", \"this is"
    ],
    [
        "lresult = np.array([\"hello\" + s for s in string_list], dtype=StringDType())",
        "lresult = np.array([\"hello\" + s for s"
    ],
    [
        "rresult = np.array([s + \"hello\" for s in string_list], dtype=StringDType())",
        "rresult = np.array([s + \"hello\" for s"
    ],
    [
        "for op in [\"hello\", np.str_(\"hello\"), np.array([\"hello\"])]:",
        "for op in [\"hello\", np.str_(\"hello\"),"
    ],
    [
        "np.add(arr, \"add\", signature=(\"U\", \"U\", None), casting=\"unsafe\")",
        "np.add(arr, \"add\", signature=(\"U\", \"U\","
    ],
    [
        "with pytest.raises(TypeError, match=\".*did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\".*did not contain"
    ],
    [
        "with pytest.raises(TypeError, match=\".*did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\".*did not contain a"
    ],
    [
        "with pytest.raises(TypeError, match=\".*did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\".*did not"
    ],
    [
        "with pytest.raises(TypeError, match=\"the resolved dtypes are not\"):",
        "with pytest.raises(TypeError, match=\"the resolved dtypes are"
    ],
    [
        "assert res == val * np.prod(repeats)",
        "assert res == val"
    ],
    [
        "def test_ufunc_multiply(dtype, string_list, other, other_dtype, use_out):",
        "def test_ufunc_multiply(dtype, string_list, other, other_dtype,"
    ],
    [
        "\"\"\"Test the two-argument ufuncs match python builtin behavior.\"\"\"",
        "\"\"\"Test the two-argument ufuncs match python"
    ],
    [
        "result = [s * o for s, o in zip(string_list, other)]",
        "result = [s * o for s, o in"
    ],
    [
        "result = [s * other for s in string_list]",
        "result = [s * other"
    ],
    [
        "arr = np.array(string_list + [dtype.na_object], dtype=dtype)",
        "arr = np.array(string_list +"
    ],
    [
        "if is_nan or bool_errors or is_str:",
        "if is_nan or bool_errors or"
    ],
    [
        "for res in [arr * other, other * arr]:",
        "for res in [arr * other, other *"
    ],
    [
        "for dtypes in [(\"T\", \"U\"), (\"U\", \"T\")]:",
        "for dtypes in [(\"T\", \"U\"),"
    ],
    [
        "for dtypes in [(\"T\", \"U\"), (\"U\", \"T\")]:",
        "for dtypes in [(\"T\", \"U\"),"
    ],
    [
        "arg = [\"Hello, planet!\", \"planet, Hello!\"]",
        "arg = [\"Hello,"
    ],
    [
        "answer = [\"Hello, world!\", \"world, Hello!\"]",
        "answer = [\"Hello, world!\", \"world,"
    ],
    [
        "if dtypes == (\"U\", \"U\", \"U\"):",
        "if dtypes == (\"U\","
    ],
    [
        "for dtypes in [(\"T\", \"U\"), (\"U\", \"T\")]:",
        "for dtypes in [(\"T\", \"U\"), (\"U\","
    ],
    [
        "is_str = isinstance(getattr(dtype, \"na_object\", None), str)",
        "is_str = isinstance(getattr(dtype,"
    ],
    [
        "for na_object in [np._NoValue, None, np.nan, 'nat', '']:",
        "for na_object in [np._NoValue, None, np.nan,"
    ],
    [
        "arr = np.array([''] + all_nats, dtype=dtype)",
        "arr = np.array([''] +"
    ],
    [
        "with pytest.raises(ValueError, match=\"string coercion is disabled\"):",
        "with pytest.raises(ValueError, match=\"string coercion is"
    ],
    [
        "if function_name == \"str_len\" and not is_str:",
        "if function_name == \"str_len\" and not"
    ],
    [
        "if is_nan and function_name in NAN_PRESERVING_FUNCTIONS:",
        "if is_nan and function_name"
    ],
    [
        "reason=\"unicode output width is buggy\", strict=True",
        "reason=\"unicode output width"
    ],
    [
        "np.array(arg, dtype=array.dtype) if isinstance(arg, str) else",
        "np.array(arg, dtype=array.dtype) if isinstance(arg,"
    ],
    [
        "ures = call_func(func, args, unicode_array, sanitize=False)",
        "ures = call_func(func,"
    ],
    [
        "if not isinstance(sres, tuple) and sres.dtype == StringDType():",
        "if not isinstance(sres, tuple) and"
    ],
    [
        "if function_name not in SUPPORTS_NULLS or not hasattr(dtype, \"na_object\"):",
        "if function_name not in SUPPORTS_NULLS or"
    ],
    [
        "should_error = not (is_nan or is_str)",
        "should_error = not (is_nan or"
    ],
    [
        "(function_name in NULLS_ALWAYS_ERROR and not is_str)",
        "(function_name in NULLS_ALWAYS_ERROR"
    ],
    [
        "or (function_name in PASSES_THROUGH_NAN_NULLS and should_error)",
        "or (function_name in PASSES_THROUGH_NAN_NULLS and"
    ],
    [
        "or (function_name in NULLS_ARE_FALSEY and should_error)",
        "or (function_name in NULLS_ARE_FALSEY and"
    ],
    [
        "indx = function(a, \"ðŸ\", start, stop)",
        "indx = function(a,"
    ],
    [
        "result = np.strings.replace(a, \"ðŸ¦œ-\", \"ðŸ¦œâ€ \", count)",
        "result = np.strings.replace(a,"
    ],
    [
        "for op_dtype in [None, StringDType(), StringDType(coerce=False),",
        "for op_dtype in [None, StringDType(),"
    ],
    [
        "for op_dtype in [None, StringDType(), StringDType(coerce=True),",
        "for op_dtype in [None, StringDType(),"
    ],
    [
        "\"\"\"Accumulation is odd for StringDType but tests dtypes with references.",
        "\"\"\"Accumulation is odd for StringDType but tests dtypes"
    ],
    [
        "\"\"\"Check that strings are stored in the arena when possible.",
        "\"\"\"Check that strings are stored"
    ],
    [
        "This tests implementation details, so should be adjusted if",
        "This tests implementation details, so should be adjusted"
    ],
    [
        "] if sys.byteorder == 'little' else [",
        "] if sys.byteorder == 'little' else"
    ],
    [
        "return self.get_flags(a) == self.INITIALIZED | self.OUTSIDE_ARENA",
        "return self.get_flags(a) =="
    ],
    [
        "return self.get_flags(a) & self.MISSING == self.MISSING",
        "return self.get_flags(a) & self.MISSING"
    ],
    [
        "return (self.get_flags(a) & (self.INITIALIZED | self.OUTSIDE_ARENA)",
        "return (self.get_flags(a) & (self.INITIALIZED |"
    ],
    [
        "in_arena = np.array([True, False, True, True])",
        "in_arena = np.array([True,"
    ],
    [
        "from numpy.testing import assert_array_equal, assert_raises, IS_PYPY",
        "from numpy.testing import assert_array_equal,"
    ],
    [
        "with pytest.raises(TypeError, match=\"did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\"did not contain"
    ],
    [
        "with pytest.raises(TypeError, match=\"did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\"did not"
    ],
    [
        "def test_string_comparisons(op, ufunc, sym, dtypes, aligned):",
        "def test_string_comparisons(op, ufunc, sym, dtypes,"
    ],
    [
        "arr = np.array([np.nan, np.inf, -np.inf, fi.max, fi.min], dtype=float_dt)",
        "arr = np.array([np.nan, np.inf, -np.inf, fi.max,"
    ],
    [
        "expected = [\"nan\", \"inf\", \"-inf\", str(fi.max), str(fi.min)]",
        "expected = [\"nan\", \"inf\", \"-inf\","
    ],
    [
        "pytest.skip(\"python failed to create huge string\")",
        "pytest.skip(\"python failed to create"
    ],
    [
        "raise AssertionError(\"Ops should raise before any large allocation.\")",
        "raise AssertionError(\"Ops should raise"
    ],
    [
        "a = np.array([\"A\" * very_large], dtype=str_dt)",
        "a = np.array([\"A\" * very_large],"
    ],
    [
        "raise AssertionError(\"Ops should raise before any large allocation.\")",
        "raise AssertionError(\"Ops should raise before any"
    ],
    [
        "([\"abc\", \"def\"], [\"hello\", \"world\"], [\"abchello\", \"defworld\"]),",
        "([\"abc\", \"def\"], [\"hello\", \"world\"],"
    ],
    [
        "def test_find(self, a, sub, start, end, out, dt):",
        "def test_find(self, a, sub,"
    ],
    [
        "if \"ðŸ˜Š\" in a and dt == \"S\":",
        "if \"ðŸ˜Š\" in a and"
    ],
    [
        "pytest.skip(\"Bytes dtype does not support non-ascii input\")",
        "pytest.skip(\"Bytes dtype does not support non-ascii"
    ],
    [
        "def test_rfind(self, a, sub, start, end, out, dt):",
        "def test_rfind(self, a, sub, start, end,"
    ],
    [
        "if \"ðŸ˜Š\" in a and dt == \"S\":",
        "if \"ðŸ˜Š\" in a and dt =="
    ],
    [
        "pytest.skip(\"Bytes dtype does not support non-ascii input\")",
        "pytest.skip(\"Bytes dtype does not support non-ascii"
    ],
    [
        "def test_count(self, a, sub, start, end, out, dt):",
        "def test_count(self, a, sub, start, end, out,"
    ],
    [
        "if \"ðŸ˜Š\" in a and dt == \"S\":",
        "if \"ðŸ˜Š\" in a and dt =="
    ],
    [
        "pytest.skip(\"Bytes dtype does not support non-ascii input\")",
        "pytest.skip(\"Bytes dtype does not support non-ascii"
    ],
    [
        "def test_startswith(self, a, prefix, start, end, out, dt):",
        "def test_startswith(self, a, prefix, start, end,"
    ],
    [
        "def test_endswith(self, a, suffix, start, end, out, dt):",
        "def test_endswith(self, a, suffix,"
    ],
    [
        "(\"   hello   \", None, \"hello   \"),",
        "(\" hello \", None, \"hello"
    ],
    [
        "(\" \\t\\n\\r\\f\\vabc \\t\\n\\r\\f\\v\", None, \"abc \\t\\n\\r\\f\\v\"),",
        "(\" \\t\\n\\r\\f\\vabc \\t\\n\\r\\f\\v\", None,"
    ],
    [
        "([\"   hello   \", \"hello\"], None, [\"hello   \", \"hello\"]),",
        "([\" hello \", \"hello\"], None, [\"hello"
    ],
    [
        "([\"ba\", \"ac\", \"baa\", \"bba\"], \"b\", [\"a\", \"ac\", \"aa\", \"a\"]),",
        "([\"ba\", \"ac\", \"baa\", \"bba\"], \"b\", [\"a\", \"ac\", \"aa\","
    ],
    [
        "def test_lstrip(self, a, chars, out, dt):",
        "def test_lstrip(self, a, chars,"
    ],
    [
        "(\"   hello   \", None, \"   hello\"),",
        "(\" hello \", None, \""
    ],
    [
        "(\" \\t\\n\\r\\f\\vabc \\t\\n\\r\\f\\v\", None, \" \\t\\n\\r\\f\\vabc\"),",
        "(\" \\t\\n\\r\\f\\vabc \\t\\n\\r\\f\\v\", None,"
    ],
    [
        "([\"   hello   \", \"hello\"], None, [\"   hello\", \"hello\"]),",
        "([\" hello \", \"hello\"], None, [\" hello\","
    ],
    [
        "([\"ab\", \"ac\", \"aab\", \"abb\"], \"b\", [\"a\", \"ac\", \"aa\", \"a\"]),",
        "([\"ab\", \"ac\", \"aab\", \"abb\"], \"b\", [\"a\", \"ac\", \"aa\","
    ],
    [
        "def test_rstrip(self, a, chars, out, dt):",
        "def test_rstrip(self, a, chars,"
    ],
    [
        "([\"   hello   \", \"hello\"], None, [\"hello\", \"hello\"]),",
        "([\" hello \", \"hello\"],"
    ],
    [
        "([\"bab\", \"ac\", \"baab\", \"bbabb\"], \"b\", [\"a\", \"ac\", \"aa\", \"a\"]),",
        "([\"bab\", \"ac\", \"baab\", \"bbabb\"], \"b\", [\"a\", \"ac\","
    ],
    [
        "def test_strip(self, a, chars, out, dt):",
        "def test_strip(self, a, chars,"
    ],
    [
        "def test_replace(self, buf, old, new, count, res, dt):",
        "def test_replace(self, buf, old, new, count, res,"
    ],
    [
        "if \"ðŸ˜Š\" in buf and dt == \"S\":",
        "if \"ðŸ˜Š\" in buf"
    ],
    [
        "pytest.skip(\"Bytes dtype does not support non-ascii input\")",
        "pytest.skip(\"Bytes dtype does not support non-ascii"
    ],
    [
        "def test_index(self, buf, sub, start, end, res, dt):",
        "def test_index(self, buf, sub, start, end, res,"
    ],
    [
        "def test_index_raises(self, buf, sub, start, end, dt):",
        "def test_index_raises(self, buf, sub, start, end,"
    ],
    [
        "def test_rindex(self, buf, sub, start, end, res, dt):",
        "def test_rindex(self, buf, sub, start, end, res,"
    ],
    [
        "def test_rindex_raises(self, buf, sub, start, end, dt):",
        "def test_rindex_raises(self, buf, sub,"
    ],
    [
        "def test_expandtabs(self, buf, tabsize, res, dt):",
        "def test_expandtabs(self, buf, tabsize,"
    ],
    [
        "with pytest.raises(OverflowError, match=\"new string is too long\"):",
        "with pytest.raises(OverflowError, match=\"new string is too"
    ],
    [
        "FILL_ERROR = \"The fill character must be exactly one character long\"",
        "FILL_ERROR = \"The fill character must"
    ],
    [
        "def test_center(self, buf, width, fillchar, res, dt):",
        "def test_center(self, buf, width,"
    ],
    [
        "def test_ljust(self, buf, width, fillchar, res, dt):",
        "def test_ljust(self, buf, width, fillchar,"
    ],
    [
        "def test_rjust(self, buf, width, fillchar, res, dt):",
        "def test_rjust(self, buf, width,"
    ],
    [
        "def test_zfill(self, buf, width, res, dt):",
        "def test_zfill(self, buf, width,"
    ],
    [
        "(\"this is the partition method\", \"ti\", \"this is the par\",",
        "(\"this is the partition method\","
    ],
    [
        "(\"this is the partition method\", \"ti\", \"this is the parti\",",
        "(\"this is the partition method\","
    ],
    [
        "bcast_args = tuple(np.broadcast_to(arg, buf.shape) for arg in args)",
        "bcast_args = tuple(np.broadcast_to(arg, buf.shape) for"
    ],
    [
        "for s, arg in zip(buf, zip(*bcast_args))],",
        "for s, arg"
    ],
    [
        "with pytest.raises(TypeError, match=\"did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\"did not"
    ],
    [
        "np.strings.slice(np.array(['foo', 'bar'], dtype=dt), np.array(['foo', 'bar'], dtype=dt))",
        "np.strings.slice(np.array(['foo', 'bar'], dtype=dt),"
    ],
    [
        "def test_replace_unicode(self, buf, old, new, count, res, dt):",
        "def test_replace_unicode(self, buf, old, new,"
    ],
    [
        "def test_index_unicode(self, buf, sub, start, end, res, dt):",
        "def test_index_unicode(self, buf, sub, start, end,"
    ],
    [
        "def test_center(self, buf, width, fillchar, res, dt):",
        "def test_center(self, buf, width,"
    ],
    [
        "def test_ljust(self, buf, width, fillchar, res, dt):",
        "def test_ljust(self, buf, width,"
    ],
    [
        "def test_rjust(self, buf, width, fillchar, res, dt):",
        "def test_rjust(self, buf, width,"
    ],
    [
        "def test_strip_functions_unicode(self, source, strip, method, dt):",
        "def test_strip_functions_unicode(self, source, strip,"
    ],
    [
        "buf = np.array([\"ÐŸÑ€Ð¸Ð²ÐµÌÑ‚ à¤¨à¤®à¤¸à¥à¤¤à¥‡ ×©Ö¸××œ×•Ö¹×\", \"ðŸ˜€ðŸ˜ƒðŸ˜„ðŸ˜ðŸ˜†ðŸ˜…ðŸ¤£ðŸ˜‚ðŸ™‚ðŸ™ƒ\"],",
        "buf = np.array([\"ÐŸÑ€Ð¸Ð²ÐµÌÑ‚ à¤¨à¤®à¤¸à¥à¤¤à¥‡ ×©Ö¸××œ×•Ö¹×\","
    ],
    [
        "bcast_args = tuple(np.broadcast_to(arg, buf.shape) for arg in args)",
        "bcast_args = tuple(np.broadcast_to(arg, buf.shape) for arg in"
    ],
    [
        "for s, arg in zip(buf, zip(*bcast_args))],",
        "for s, arg"
    ],
    [
        "with pytest.raises(ValueError, match=\"'ascii' codec can't encode\"):",
        "with pytest.raises(ValueError, match=\"'ascii' codec can't"
    ],
    [
        "with pytest.raises(ValueError, match=\"'ascii' codec can't encode\"):",
        "with pytest.raises(ValueError, match=\"'ascii'"
    ],
    [
        "with pytest.raises(ValueError, match=\"'ascii' codec can't encode\"):",
        "with pytest.raises(ValueError, match=\"'ascii' codec"
    ],
    [
        "\"Output indices do not map to the correct dimensions. Expected: \"",
        "\"Output indices do not map to"
    ],
    [
        "assert_raises(CustomException, np.einsum, \"ij, j\", a, b)",
        "assert_raises(CustomException, np.einsum, \"ij, j\", a,"
    ],
    [
        "assert_raises(CustomException, np.einsum, \"ij, jh\", a, a)",
        "assert_raises(CustomException, np.einsum, \"ij, jh\", a,"
    ],
    [
        "a = np.arange(n * n, dtype=dtype).reshape(n, n)",
        "a = np.arange(n * n, dtype=dtype).reshape(n,"
    ],
    [
        "assert_equal(np.einsum(\"...i, ...i\", a, b, optimize=do_opt), np.inner(a, b))",
        "assert_equal(np.einsum(\"...i, ...i\", a, b, optimize=do_opt),"
    ],
    [
        "assert_equal(np.einsum(\"ijk, jil -> kl\", a, b),",
        "assert_equal(np.einsum(\"ijk, jil ->"
    ],
    [
        "c = np.array([True, True, False, True, True, False, True, True])",
        "c = np.array([True, True, False, True, True,"
    ],
    [
        "assert_equal(np.einsum(\"i,i\", a, a, optimize=do_opt), np.dot(a, a))",
        "assert_equal(np.einsum(\"i,i\", a, a, optimize=do_opt),"
    ],
    [
        "b = np.einsum(\"i->\", a, dtype=dtype, casting='unsafe')",
        "b = np.einsum(\"i->\", a,"
    ],
    [
        "ref = np.einsum('ijk,j->ijk', A, B, optimize=False)",
        "ref = np.einsum('ijk,j->ijk', A, B,"
    ],
    [
        "ref = np.einsum('ik,kj->ij', A, B, optimize=False)",
        "ref = np.einsum('ik,kj->ij', A, B,"
    ],
    [
        "ref = np.einsum('ijkl,k->ijl', a, v, optimize=False)",
        "ref = np.einsum('ijkl,k->ijl', a, v,"
    ],
    [
        "ref = np.einsum('...lmn,...lmno->...o', A, B, optimize=False)",
        "ref = np.einsum('...lmn,...lmno->...o', A, B,"
    ],
    [
        "es = np.einsum('cl, cpx->lpx',  A,  B)",
        "es = np.einsum('cl, cpx->lpx', A,"
    ],
    [
        "es = np.einsum('cl, cpxy->lpxy',  A, B)",
        "es = np.einsum('cl, cpxy->lpxy',"
    ],
    [
        "assert np.einsum('i,i->', arr, arr) == (arr * arr).sum()",
        "assert np.einsum('i,i->', arr, arr) =="
    ],
    [
        "assert res == np.einsum('i->', scalar * arr)",
        "assert res == np.einsum('i->', scalar"
    ],
    [
        "assert res == np.einsum('i->', scalar * arr)",
        "assert res == np.einsum('i->', scalar *"
    ],
    [
        "res = np.einsum('i,i,i->', arr, arr, arr)",
        "res = np.einsum('i,i,i->', arr, arr,"
    ],
    [
        "assert_array_equal(res, (arr * arr * arr).sum())",
        "assert_array_equal(res, (arr * arr"
    ],
    [
        "res = np.einsum('i,i,i,i->', arr, arr, arr, arr)",
        "res = np.einsum('i,i,i,i->', arr, arr, arr,"
    ],
    [
        "assert_array_equal(res, (arr * arr * arr * arr).sum())",
        "assert_array_equal(res, (arr * arr * arr *"
    ],
    [
        "res = np.einsum('...ij,...jk->...ik', a, a, out=out)",
        "res = np.einsum('...ij,...jk->...ik', a, a,"
    ],
    [
        "res = np.einsum('...ij,...jk->...ik', a, a, out=a)",
        "res = np.einsum('...ij,...jk->...ik', a,"
    ],
    [
        "dims = [global_size_dict[x] for x in term]",
        "dims = [global_size_dict[x] for x"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='a', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a, b,"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='f', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='f',"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='c', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a,"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='k', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='k',"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a,"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, c, order='a', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a, c, order='a',"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', d, c, order='a', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', d, c,"
    ],
    [
        "dims = [size_dict[x] for x in term]",
        "dims = [size_dict[x] for"
    ],
    [
        "c = np.einsum('ij,jk->ik', a, b, out=b)",
        "c = np.einsum('ij,jk->ik',"
    ],
    [
        "never (or almost never?) used the `GROWINNER` mechanism to increase the",
        "never (or almost never?) used the `GROWINNER`"
    ],
    [
        "inner loop size when no buffers are needed.",
        "inner loop size when"
    ],
    [
        "Calling the inner-loop more often actually improves accuracy slightly",
        "Calling the inner-loop more often actually"
    ],
    [
        "(same effect as pairwise summation but much less).",
        "(same effect as pairwise summation but much"
    ],
    [
        "Without adding pairwise summation to the inner-loop it seems best to just",
        "Without adding pairwise summation to the inner-loop"
    ],
    [
        "the simplest `einsum(\"i,i->i\", x, x)` case.",
        "the simplest `einsum(\"i,i->i\","
    ],
    [
        "(It is not clear that we should guarantee precision to this extend.)",
        "(It is not clear that we should"
    ],
    [
        "res = np.einsum(\"i->\", np.broadcast_to(np.array(value), num)) / num",
        "res = np.einsum(\"i->\", np.broadcast_to(np.array(value),"
    ],
    [
        "o = type(\"o\", (object,), {\"__array__\": custom__array__})()",
        "o = type(\"o\", (object,),"
    ],
    [
        "[True, True, True, True, True, True, False, False],",
        "[True, True, True, True, True, True, False,"
    ],
    [
        "l = [True] * pad + [True, True, True, True]",
        "l = [True] * pad + [True,"
    ],
    [
        "def check_copy_result(x, y, ccontig, fcontig, strides=False):",
        "def check_copy_result(x, y,"
    ],
    [
        "\"\"\"Confirm that extracting a value doesn't convert to python float\"\"\"",
        "\"\"\"Confirm that extracting a value"
    ],
    [
        "reason=\"repr precision not enough to show eps\")",
        "reason=\"repr precision not enough to"
    ],
    [
        "assert_equal(np.longdouble(str(o)), o, \"str was %s\" % str(o))",
        "assert_equal(np.longdouble(str(o)), o, \"str was %s\" %"
    ],
    [
        "Test that string representations of long-double roundtrip both",
        "Test that string representations of long-double roundtrip"
    ],
    [
        "out = ''.join([str(t) + '\\n' for t in tgt])",
        "out = ''.join([str(t) + '\\n'"
    ],
    [
        "res = np.fromfile(path, dtype=np.longdouble, sep=\" \")",
        "res = np.fromfile(path, dtype=np.longdouble,"
    ],
    [
        "a = np.fromstring(repr(f), dtype=float, sep=\" \")",
        "a = np.fromstring(repr(f),"
    ],
    [
        "a = np.fromstring(s, dtype=np.longdouble, sep=\" \")",
        "a = np.fromstring(s, dtype=np.longdouble,"
    ],
    [
        "assert_equal(_get_implementing_args([a, b, c]), [b, c, a])",
        "assert_equal(_get_implementing_args([a, b, c]), [b,"
    ],
    [
        "assert_equal(_get_implementing_args([a, c, b]), [c, b, a])",
        "assert_equal(_get_implementing_args([a, c, b]),"
    ],
    [
        "relevant_args = [t() for t in types]",
        "relevant_args = [t() for"
    ],
    [
        "with pytest.raises(TypeError, match=\"args must be a tuple\"):",
        "with pytest.raises(TypeError, match=\"args must be"
    ],
    [
        "with pytest.raises(TypeError, match=\"kwargs must be a dict\"):",
        "with pytest.raises(TypeError, match=\"kwargs must be"
    ],
    [
        "with pytest.raises(TypeError, match=\"args must be a tuple\"):",
        "with pytest.raises(TypeError, match=\"args must"
    ],
    [
        "with pytest.raises(TypeError, match=\"kwargs must be a dict\"):",
        "with pytest.raises(TypeError, match=\"kwargs must be"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func,"
    ],
    [
        "return (self, func, types, args, kwargs)",
        "return (self, func, types,"
    ],
    [
        "(obj, func, types, args, kwargs) = dispatched_one_arg(original)",
        "(obj, func, types, args,"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func, types,"
    ],
    [
        "def __array_function__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_function__(self, ufunc,"
    ],
    [
        "\"\"\"Create a duck array type and implements functions.\"\"\"",
        "\"\"\"Create a duck array"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func,"
    ],
    [
        "if not all(issubclass(t, MyArray) for t in types):",
        "if not all(issubclass(t, MyArray) for t in"
    ],
    [
        "TypeError, \"no implementation found for 'my.func'\"):",
        "TypeError, \"no implementation"
    ],
    [
        "pytest.skip(\"Python version is not using __qualname__ for \"",
        "pytest.skip(\"Python version is not using __qualname__ for"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func, types, args,"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func,"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func, types, args,"
    ],
    [
        "result = super().__array_function__(func, types, args, kwargs)",
        "result = super().__array_function__(func, types, args,"
    ],
    [
        "if enable_value_error and 'value_error' in kwargs:",
        "if enable_value_error and 'value_error' in"
    ],
    [
        "getattr(np, func_name) for func_name, *_ in self.__class__._array_tests",
        "getattr(np, func_name) for func_name, *_ in"
    ],
    [
        "def test_array_like(self, function, args, kwargs, numpy_ref):",
        "def test_array_like(self, function, args,"
    ],
    [
        "like_args = tuple(a() if callable(a) else a for a in args)",
        "like_args = tuple(a() if callable(a) else a for a in"
    ],
    [
        "np_args = tuple(a() if callable(a) else a for a in args)",
        "np_args = tuple(a() if callable(a) else"
    ],
    [
        "def test_no_array_function_like(self, function, args, kwargs, ref):",
        "def test_no_array_function_like(self, function,"
    ],
    [
        "like_args = tuple(a() if callable(a) else a for a in args)",
        "like_args = tuple(a() if callable(a) else a for a"
    ],
    [
        "'The `like` argument must be an array-like that implements'):",
        "'The `like` argument must be"
    ],
    [
        "like_args = tuple(a() if callable(a) else a for a in args)",
        "like_args = tuple(a() if callable(a) else a for a in"
    ],
    [
        "np_args = tuple(a() if callable(a) else a for a in args)",
        "np_args = tuple(a() if callable(a) else a for a"
    ],
    [
        "like_args = tuple(a() if callable(a) else a for a in args)",
        "like_args = tuple(a() if callable(a) else a"
    ],
    [
        "like_args_exp = tuple(a() if callable(a) else a for a in args)",
        "like_args_exp = tuple(a() if callable(a) else a for a in"
    ],
    [
        "Test the scalar constructors, which also do type-coercion",
        "Test the scalar constructors,"
    ],
    [
        "\"\"\" Strings containing an unrepresentable float overflow \"\"\"",
        "\"\"\" Strings containing an unrepresentable"
    ],
    [
        "int_types = [np.byte, np.short, np.intc, np.long, np.longlong]",
        "int_types = [np.byte, np.short, np.intc, np.long,"
    ],
    [
        "uint_types = [np.ubyte, np.ushort, np.uintc, np.ulong, np.ulonglong]",
        "uint_types = [np.ubyte, np.ushort, np.uintc, np.ulong,"
    ],
    [
        "float_types = [np.half, np.single, np.double, np.longdouble]",
        "float_types = [np.half, np.single,"
    ],
    [
        "pytest.xfail(\"creating a clongdouble from real and \"",
        "pytest.xfail(\"creating a clongdouble from real and"
    ],
    [
        "Allocate a new ndarray with aligned memory.",
        "Allocate a new ndarray with aligned"
    ],
    [
        "The ndarray is guaranteed *not* aligned to twice the requested alignment.",
        "The ndarray is guaranteed *not* aligned to twice the"
    ],
    [
        "raise ValueError(\"object array alignment not supported\")",
        "raise ValueError(\"object array alignment not"
    ],
    [
        "size = functools.reduce(operator.mul, shape) * dtype.itemsize",
        "size = functools.reduce(operator.mul,"
    ],
    [
        "data = np.ndarray(shape, dtype, buf, order=order)",
        "data = np.ndarray(shape,"
    ],
    [
        "r.strides = strides = strides * x.itemsize",
        "r.strides = strides = strides"
    ],
    [
        "r = np.array([[d, d], [d, d]])",
        "r = np.array([[d, d],"
    ],
    [
        "r = np.array([[True, True, False], [False, False, True]])",
        "r = np.array([[True, True, False], [False, False,"
    ],
    [
        "r = np.array([[True, False], [True, False], [False, True]])",
        "r = np.array([[True, False], [True, False], [False,"
    ],
    [
        "match=\"strings are not allowed for 'copy' keyword. \"",
        "match=\"strings are not allowed for"
    ],
    [
        "assert_raises(IndexError, lambda x: x[np.array([], int)], a)",
        "assert_raises(IndexError, lambda x: x[np.array([],"
    ],
    [
        "assert_raises(IndexError, lambda x: x[np.array([], int)], b)",
        "assert_raises(IndexError, lambda x: x[np.array([], int)],"
    ],
    [
        "assert_raises(IndexError, lambda x: x[np.array([], int)], a)",
        "assert_raises(IndexError, lambda x: x[np.array([],"
    ],
    [
        "msg = 'String conversion for %s' % type",
        "msg = 'String conversion"
    ],
    [
        "Class Fail breaks the sequence protocol for new style classes, i.e.,",
        "Class Fail breaks the sequence protocol"
    ],
    [
        "those derived from object. Class Map is a mapping type indicated by",
        "those derived from object. Class Map is"
    ],
    [
        "raising a ValueError. At some point we may raise a warning instead",
        "raising a ValueError. At some point we may"
    ],
    [
        "of an error in the Fail case.",
        "of an error in the"
    ],
    [
        "expected = expected * (arr.nbytes // len(expected))",
        "expected = expected * (arr.nbytes //"
    ],
    [
        "assert_equal(a == b, [[True, True, False], [False, False, True]])",
        "assert_equal(a == b, [[True, True, False], [False,"
    ],
    [
        "assert_equal(b == a, [[True, True, False], [False, False, True]])",
        "assert_equal(b == a, [[True, True, False],"
    ],
    [
        "assert_equal(a == b, [[True, True, False], [False, False, True]])",
        "assert_equal(a == b, [[True, True, False], [False,"
    ],
    [
        "assert_equal(b == a, [[True, True, False], [False, False, True]])",
        "assert_equal(b == a, [[True, True, False], [False,"
    ],
    [
        "assert_equal(a == b, [[True, False, False], [False, False, True]])",
        "assert_equal(a == b, [[True, False, False], [False, False,"
    ],
    [
        "assert_equal(b == a, [[True, False, False], [False, False, True]])",
        "assert_equal(b == a, [[True, False, False],"
    ],
    [
        "assert_equal(a == b, [[True, False, False], [False, False, True]])",
        "assert_equal(a == b, [[True, False, False],"
    ],
    [
        "assert_equal(b == a, [[True, False, False], [False, False, True]])",
        "assert_equal(b == a, [[True, False,"
    ],
    [
        "operator.eq, lambda x, y: operator.eq(y, x),",
        "operator.eq, lambda x, y: operator.eq(y,"
    ],
    [
        "operator.ne, lambda x, y: operator.ne(y, x)])",
        "operator.ne, lambda x, y: operator.ne(y,"
    ],
    [
        "for casting in ['no', 'safe', 'equiv', 'same_kind']:",
        "for casting in ['no', 'safe',"
    ],
    [
        "a = np.array([], dtype=[('a', 'f'), ('b', 'f'), ('c', 'O')])",
        "a = np.array([], dtype=[('a', 'f'),"
    ],
    [
        "x['S'] = ['a', 'b', 'c', 'd']",
        "x['S'] = ['a',"
    ],
    [
        "assert_array_equal(eval(repr(xx), {\"np\": np, \"array\": np.array}), xx)",
        "assert_array_equal(eval(repr(xx), {\"np\": np, \"array\": np.array}),"
    ],
    [
        "for dt in [bytes, np.void, str]:",
        "for dt in [bytes, np.void,"
    ],
    [
        "for dt in [bytes, np.void, str]:",
        "for dt in [bytes,"
    ],
    [
        "for dt in [bytes, np.void, str]:",
        "for dt in [bytes, np.void,"
    ],
    [
        "for dt in [bytes, np.void, str]:",
        "for dt in [bytes,"
    ],
    [
        "\"\"\"Checking if an empty array pickled and un-pickled will not cause a",
        "\"\"\"Checking if an empty array pickled and un-pickled"
    ],
    [
        "msg = \"Test real sort order with nans\"",
        "msg = \"Test real sort order with"
    ],
    [
        "msg = \"Test complex sort order with nans\"",
        "msg = \"Test complex sort order"
    ],
    [
        "\"kind` and `stable` parameters can't be provided at the same time\"",
        "\"kind` and `stable` parameters can't be provided at the same"
    ],
    [
        "msg = \"scalar sort, kind=%s\" % kind",
        "msg = \"scalar sort, kind=%s\""
    ],
    [
        "msg = \"scalar sort, kind=%s\" % (kind)",
        "msg = \"scalar sort, kind=%s\""
    ],
    [
        "for kind in ['q', 'h', 'm']:",
        "for kind in ['q', 'h',"
    ],
    [
        "for kind in ['q', 'h', 'm']:",
        "for kind in"
    ],
    [
        "for kind in ['q', 'h', 'm']:",
        "for kind in ['q',"
    ],
    [
        "assert_equal(d, c, \"test sort with default axis\")",
        "assert_equal(d, c, \"test sort"
    ],
    [
        "msg = 'test empty array sort with axis=None'",
        "msg = 'test empty array sort with"
    ],
    [
        "__eq__ = __ne__ = __lt__ = __gt__ = __ge__ = __le__ = raises_anything",
        "__eq__ = __ne__ = __lt__ = __gt__ = __ge__ = __le__"
    ],
    [
        "msg = \"scalar argsort, kind=%s, dtype=%s\" % (kind, dtype)",
        "msg = \"scalar argsort, kind=%s, dtype=%s\" %"
    ],
    [
        "msg = \"complex argsort, kind=%s\" % kind",
        "msg = \"complex argsort, kind=%s\" %"
    ],
    [
        "msg = \"complex argsort, kind=%s\" % kind",
        "msg = \"complex argsort, kind=%s\""
    ],
    [
        "msg = \"string argsort, kind=%s\" % kind",
        "msg = \"string argsort, kind=%s\""
    ],
    [
        "msg = \"unicode argsort, kind=%s\" % kind",
        "msg = \"unicode argsort, kind=%s\" %"
    ],
    [
        "msg = \"object argsort, kind=%s\" % kind",
        "msg = \"object argsort,"
    ],
    [
        "dt = np.dtype([('f', float), ('i', int)])",
        "dt = np.dtype([('f',"
    ],
    [
        "msg = \"structured array argsort, kind=%s\" % kind",
        "msg = \"structured array"
    ],
    [
        "for kind in ['q', 'h', 'm']:",
        "for kind in"
    ],
    [
        "for kind in ['q', 'h', 'm']:",
        "for kind in"
    ],
    [
        "msg = 'test empty array argsort with axis=None'",
        "msg = 'test empty array argsort with"
    ],
    [
        "\"kind` and `stable` parameters can't be provided at the same time\"",
        "\"kind` and `stable` parameters can't be provided"
    ],
    [
        "msg = \"Test real (%s) searchsorted with nans, side='l'\" % a.dtype",
        "msg = \"Test real (%s) searchsorted"
    ],
    [
        "msg = \"Test real (%s) searchsorted with nans, side='r'\" % a.dtype",
        "msg = \"Test real (%s) searchsorted with nans, side='r'\""
    ],
    [
        "msg = \"Test complex searchsorted with nans, side='l'\"",
        "msg = \"Test complex"
    ],
    [
        "msg = \"Test complex searchsorted with nans, side='r'\"",
        "msg = \"Test complex searchsorted with nans,"
    ],
    [
        "msg = \"Test searchsorted with little endian, side='l'\"",
        "msg = \"Test searchsorted with little"
    ],
    [
        "msg = \"Test searchsorted with big endian, side='l'\"",
        "msg = \"Test searchsorted with big endian,"
    ],
    [
        "assert_equal([a.searchsorted(v, 'left') for v in a], ind)",
        "assert_equal([a.searchsorted(v, 'left') for v in a],"
    ],
    [
        "assert_equal([a.searchsorted(a[i], 'left') for i in ind], ind)",
        "assert_equal([a.searchsorted(a[i], 'left') for i in ind],"
    ],
    [
        "msg = 'test empty array partition with axis=None'",
        "msg = 'test empty array partition with"
    ],
    [
        "msg = 'test empty array argpartition with axis=None'",
        "msg = 'test empty"
    ],
    [
        "msg=\"%d: %r <= %r\" % (i, p[:, i], p[:, :i].T))",
        "msg=\"%d: %r <= %r\" % (i, p[:,"
    ],
    [
        "msg=\"%d: %r <= %r\" % (i, p[i, :], p[:i, :]))",
        "msg=\"%d: %r <= %r\" %"
    ],
    [
        "msg=\"kth %d, %r not greater equal %r\" % (k, d[k:], d[k]))",
        "msg=\"kth %d, %r not greater equal %r\" % (k, d[k:],"
    ],
    [
        "d = np.array(['Galahad', 'Arthur', 'zebra', 'Lancelot'])",
        "d = np.array(['Galahad',"
    ],
    [
        "err_msg=\"data: %r\\n kth: %r\" % (d, kth))",
        "err_msg=\"data: %r\\n kth: %r\" %"
    ],
    [
        "dtypes = [np.dtype(code) for code in np.typecodes['All']",
        "dtypes = [np.dtype(code) for code in"
    ],
    [
        "for dt in icodes + fcodes + 'O':",
        "for dt in icodes"
    ],
    [
        "tgt = np.array([False, True, False, True, False, True], dtype=dt)",
        "tgt = np.array([False, True, False, True,"
    ],
    [
        "match=\"cannot replace elements of an empty array\"):",
        "match=\"cannot replace elements of an empty"
    ],
    [
        "match=\"cannot replace elements of an empty array\"):",
        "match=\"cannot replace elements of an"
    ],
    [
        "for order in ('C', 'F', 'A', 'K'):",
        "for order in ('C', 'F',"
    ],
    [
        "for k, src in enumerate((a, b)):",
        "for k, src in"
    ],
    [
        "assert_equal(ac, [k.conjugate() for k in a])",
        "assert_equal(ac, [k.conjugate() for k"
    ],
    [
        "'f', 'd', 'g', 'F', 'D', 'G',",
        "'f', 'd', 'g', 'F',"
    ],
    [
        "'f', 'd', 'g', 'F', 'D', 'G',",
        "'f', 'd', 'g',"
    ],
    [
        "c = (a * a) / b",
        "c = (a * a)"
    ],
    [
        "def array_ufunc_impl(self, ufunc, method, *args, **kwargs):",
        "def array_ufunc_impl(self, ufunc, method,"
    ],
    [
        "return (\"__array_ufunc__\", ufunc, method, args, kwargs)",
        "return (\"__array_ufunc__\", ufunc,"
    ],
    [
        "for op, (ufunc, has_inplace, dtype) in ops.items():",
        "for op, (ufunc, has_inplace, dtype)"
    ],
    [
        "err_msg = ('op: %s, ufunc: %s, has_inplace: %s, dtype: %s'",
        "err_msg = ('op: %s, ufunc: %s, has_inplace: %s,"
    ],
    [
        "op_fn = getattr(operator, op + \"_\", None)",
        "op_fn = getattr(operator, op"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kw):",
        "def __array_ufunc__(self, ufunc,"
    ],
    [
        "assert SomeClass() + scalar == \"result\"",
        "assert SomeClass() + scalar =="
    ],
    [
        "assert scalar + SomeClass() == \"result\"",
        "assert scalar + SomeClass() =="
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kw):",
        "def __array_ufunc__(self, ufunc, method,"
    ],
    [
        "assert_('sig' not in kw and 'signature' not in kw)",
        "assert_('sig' not in kw and 'signature'"
    ],
    [
        "assert_('sig' not in kw and 'signature' in kw)",
        "assert_('sig' not in kw and"
    ],
    [
        "assert_('sig' not in kw and 'signature' in kw)",
        "assert_('sig' not in kw and"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kw):",
        "def __array_ufunc__(self, ufunc,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kw):",
        "def __array_ufunc__(self, ufunc, method,"
    ],
    [
        "raise AssertionError('__mul__ should not be called')",
        "raise AssertionError('__mul__ should not"
    ],
    [
        "raise AssertionError('__div__ should not be called')",
        "raise AssertionError('__div__ should not"
    ],
    [
        "return np.array([x ** exp for x in arr])",
        "return np.array([x ** exp for"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method, *inputs,"
    ],
    [
        "assert_equal(((f + f) + d).dtype, d.dtype)",
        "assert_equal(((f + f) +"
    ],
    [
        "assert_equal(((d + d) + l).dtype, l.dtype)",
        "assert_equal(((d + d)"
    ],
    [
        "match=\"expected a sequence of integers or a single integer, \"):",
        "match=\"expected a sequence of integers or a"
    ],
    [
        "match=\"expected a sequence of integers or a single integer, \"",
        "match=\"expected a sequence of integers or a single"
    ],
    [
        "match=\"'float' object cannot be interpreted as an integer\"):",
        "match=\"'float' object cannot be interpreted as an"
    ],
    [
        "reason=('this tests the error messages when trying to'",
        "reason=('this tests the error messages"
    ],
    [
        "dtype=[('a', object), ('b', int), ('c', float)])",
        "dtype=[('a', object), ('b', int),"
    ],
    [
        "dtype=[('a', str), ('b', int), ('c', float)])",
        "dtype=[('a', str), ('b', int), ('c',"
    ],
    [
        "refs = [weakref.ref(a) for a in DATA]",
        "refs = [weakref.ref(a) for a"
    ],
    [
        "for axis in list(range(-len(size), len(size))) + [None]]",
        "for axis in list(range(-len(size), len(size)))"
    ],
    [
        "arg_method = getattr(a, 'arg' + method)",
        "arg_method = getattr(a, 'arg' +"
    ],
    [
        "def test_unicode(self, np_array, method, idx, val):",
        "def test_unicode(self, np_array,"
    ],
    [
        "assert res is out or not inplace",
        "assert res is out"
    ],
    [
        "assert res is out or not inplace",
        "assert res is out or not"
    ],
    [
        "assert res is out or not inplace",
        "assert res is out or"
    ],
    [
        "def tst_basic(self, x, T, mask, val):",
        "def tst_basic(self, x, T,"
    ],
    [
        "x = np.array([True, False, True, False])",
        "x = np.array([True,"
    ],
    [
        "x = np.array([True, False, True, False])",
        "x = np.array([True,"
    ],
    [
        "for u, v in (a, b), (b, a):",
        "for u, v in (a, b),"
    ],
    [
        "u, v = np.array(u, dtype='object'), np.array(v, dtype='object')",
        "u, v = np.array(u, dtype='object'), np.array(v,"
    ],
    [
        "surnames = np.array(['Hertz',    'Galilei', 'Hertz'], dtype=dtype)",
        "surnames = np.array(['Hertz', 'Galilei', 'Hertz'],"
    ],
    [
        "first_names = np.array(['Heinrich', 'Galileo', 'Gustav'], dtype=dtype)",
        "first_names = np.array(['Heinrich', 'Galileo', 'Gustav'],"
    ],
    [
        "\"\"\"Test tofile, fromfile, tobytes, and fromstring\"\"\"",
        "\"\"\"Test tofile, fromfile,"
    ],
    [
        "v = np.array([True, False, True, False], dtype=np.bool)",
        "v = np.array([True, False, True,"
    ],
    [
        "raise OSError('Can not tell or seek')",
        "raise OSError('Can not tell or"
    ],
    [
        "err_msg = \"%d %s\" % (size, mode)",
        "err_msg = \"%d %s\""
    ],
    [
        "assert_raises_regex(ValueError, \"Cannot read into object array\",",
        "assert_raises_regex(ValueError, \"Cannot read into"
    ],
    [
        "assert_raises_regex(ValueError, \"Cannot read into object array\",",
        "assert_raises_regex(ValueError, \"Cannot read"
    ],
    [
        "\"'offset' argument only permitted for binary files\",",
        "\"'offset' argument only permitted for binary"
    ],
    [
        "for dup, exc in ((dup_str, TypeError), (dup_bigint, OSError)):",
        "for dup, exc in ((dup_str, TypeError),"
    ],
    [
        "def _check_from(self, s, value, filename, **kw):",
        "def _check_from(self, s,"
    ],
    [
        "Including this fixture in a test will automatically",
        "Including this fixture in a test"
    ],
    [
        "execute it with both types of decimal separator.",
        "execute it with both types of decimal"
    ],
    [
        "is equivalent to the following two tests::",
        "is equivalent to the following two"
    ],
    [
        "b\"nan +nan -nan NaN nan(foo) +NaN(BAR) -NAN(q_u_u_x_)\",",
        "b\"nan +nan -nan NaN nan(foo)"
    ],
    [
        "[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],",
        "[np.nan, np.nan, np.nan, np.nan, np.nan,"
    ],
    [
        "b\"inf +inf -inf infinity -Infinity iNfInItY -inF\",",
        "b\"inf +inf -inf infinity"
    ],
    [
        "[np.inf, np.inf, -np.inf, np.inf, -np.inf, np.inf, -np.inf],",
        "[np.inf, np.inf, -np.inf, np.inf, -np.inf, np.inf,"
    ],
    [
        "v = np.array([True, False, True, False], dtype=np.bool)",
        "v = np.array([True, False, True,"
    ],
    [
        "y = np.array([float(p) for p in s.split(',')])",
        "y = np.array([float(p) for p"
    ],
    [
        "reason=\"PyPy's memoryview currently does not track exports. See: \"",
        "reason=\"PyPy's memoryview currently does not track exports. See:"
    ],
    [
        "dt = np.dtype([('f', float), ('i', int)])",
        "dt = np.dtype([('f', float),"
    ],
    [
        "np.array([(), (), (), (), ()], dtype={'names': [], 'formats': [],",
        "np.array([(), (), (), (), ()], dtype={'names': [],"
    ],
    [
        "self.omat = np.array([Decimal(str(r)) for r in self.rmat.flat])",
        "self.omat = np.array([Decimal(str(r)) for r in"
    ],
    [
        "for mat in [self.rmat, self.cmat, self.omat]:",
        "for mat in [self.rmat, self.cmat,"
    ],
    [
        "res = _mean(mat, axis=axis) * mat.shape[axis]",
        "res = _mean(mat,"
    ],
    [
        "res = _mean(mat, axis=axis) * np.prod(mat.shape)",
        "res = _mean(mat, axis=axis) *"
    ],
    [
        "wh_full = np.array([[False, True, False, True],",
        "wh_full = np.array([[False,"
    ],
    [
        "for _ax, _wh, _res in _cases:",
        "for _ax, _wh,"
    ],
    [
        "_wh_partial = np.array([False, True, True, False])",
        "_wh_partial = np.array([False,"
    ],
    [
        "for mat in [self.rmat, self.cmat, self.omat]:",
        "for mat in"
    ],
    [
        "msqr = _mean(mat * mat.conj(), axis=axis)",
        "msqr = _mean(mat *"
    ],
    [
        "tgt = msqr - mean * mean.conjugate()",
        "tgt = msqr - mean"
    ],
    [
        "msqr = _mean(mat * mat.conj(), axis=axis)",
        "msqr = _mean(mat *"
    ],
    [
        "tgt = msqr - mean * mean.conjugate()",
        "tgt = msqr -"
    ],
    [
        "msqr = _mean(mat * mat.conj(), axis=axis)",
        "msqr = _mean(mat"
    ],
    [
        "tgt = msqr - mean * mean.conjugate()",
        "tgt = msqr - mean *"
    ],
    [
        "wh_full = np.array([[False, True, False, True, True],",
        "wh_full = np.array([[False, True, False, True,"
    ],
    [
        "for _ax, _wh, _res in _cases:",
        "for _ax, _wh, _res in"
    ],
    [
        "_wh_partial = np.array([False, True, True, False])",
        "_wh_partial = np.array([False,"
    ],
    [
        "for mat in [self.rmat, self.cmat, self.omat]:",
        "for mat in"
    ],
    [
        "whf = np.array([[False, True, False, True, True],",
        "whf = np.array([[False, True, False,"
    ],
    [
        "for _ax, _wh, _res in _cases:",
        "for _ax, _wh, _res"
    ],
    [
        "_wh_partial = np.array([False, True, True, False])",
        "_wh_partial = np.array([False, True, True,"
    ],
    [
        "for dt in dt_numeric + 'O':",
        "for dt in dt_numeric"
    ],
    [
        "for dt in dt_complex + 'O':",
        "for dt in"
    ],
    [
        "zeros_test = np.dot(U_cont, x) - np.dot(U_non_cont, x)",
        "zeros_test = np.dot(U_cont, x)"
    ],
    [
        "tmp = tmp[offset:offset + N * d.nbytes].view(dtype=dtype)",
        "tmp = tmp[offset:offset + N *"
    ],
    [
        "aligned = aligned_array(arr.shape, align, dtype, order)",
        "aligned = aligned_array(arr.shape, align,"
    ],
    [
        "for align, m, n, a_order in testdata:",
        "for align, m, n,"
    ],
    [
        "raise TypeError(\"just this tiny mint leaf\")",
        "raise TypeError(\"just this tiny"
    ],
    [
        "\"\"\"Common tests for '@' operator and numpy.matmul.",
        "\"\"\"Common tests for '@' operator and"
    ],
    [
        "for arg in [(m, v), (v, m), (m, m)]:",
        "for arg in [(m, v), (v, m),"
    ],
    [
        "msg = \"Cannot cast ufunc .* output\"",
        "msg = \"Cannot cast ufunc"
    ],
    [
        "assert_raises_regex(TypeError, msg, self.matmul, a, b, out=out)",
        "assert_raises_regex(TypeError, msg, self.matmul, a,"
    ],
    [
        "from fractions import Fraction as F",
        "from fractions import"
    ],
    [
        "def test_shapes(self, a_shape: tuple[int, ...], b_shape: tuple[int, ...]):",
        "def test_shapes(self, a_shape: tuple[int, ...],"
    ],
    [
        "for dt in np.typecodes['AllInteger'] + np.typecodes['AllFloat'] + '?':",
        "for dt in np.typecodes['AllInteger'] + np.typecodes['AllFloat']"
    ],
    [
        "for dt in np.typecodes['AllInteger'] + np.typecodes['AllFloat'] + '?':",
        "for dt in np.typecodes['AllInteger'] +"
    ],
    [
        "for dt in np.typecodes['AllInteger'] + np.typecodes['AllFloat'] + '?':",
        "for dt in np.typecodes['AllInteger']"
    ],
    [
        "assert_([i.dtype == dt for i in l])",
        "assert_([i.dtype == dt for"
    ],
    [
        "err_msg=\"spec %r != dtype %r\" % (spec, wanted))",
        "err_msg=\"spec %r != dtype %r\" % (spec,"
    ],
    [
        "[('a', 'b'), ('b', 'i'), ('c', 'b'), ('d', 'b'),",
        "[('a', 'b'), ('b', 'i'), ('c', 'b'),"
    ],
    [
        "sz = sum(np.dtype(b).itemsize for a, b in dt)",
        "sz = sum(np.dtype(b).itemsize for a, b"
    ],
    [
        "[('a', 'b'), ('b', 'i'), ('sub', np.dtype('b,i')), ('c', 'i')],",
        "[('a', 'b'), ('b', 'i'), ('sub',"
    ],
    [
        "[('a', 'b'), ('b', 'i'), ('c', 'b'), ('d', 'b'),",
        "[('a', 'b'), ('b', 'i'), ('c', 'b'),"
    ],
    [
        "for c_integer in {ctypes.c_int, ctypes.c_long, ctypes.c_longlong}:",
        "for c_integer in {ctypes.c_int, ctypes.c_long,"
    ],
    [
        "the new buffer-info field. This checks that an error is raised",
        "the new buffer-info field. This checks that an error"
    ],
    [
        "if this happens (for buffer export), an error is written on delete.",
        "if this happens (for buffer export), an error"
    ],
    [
        "This is a sanity check to help users transition to safe code, it",
        "This is a sanity check to help users transition"
    ],
    [
        "may be deleted at any point.",
        "may be deleted"
    ],
    [
        "match=f\".*{name} appears to be C subclassed\"):",
        "match=f\".*{name} appears to be"
    ],
    [
        "msg = \"NumPy currently does not support.*suboffsets\"",
        "msg = \"NumPy currently"
    ],
    [
        "assert res is not arr and res.flags.owndata",
        "assert res is not"
    ],
    [
        "assert res is arr or res.base is arr",
        "assert res is arr or res.base"
    ],
    [
        "assert res is arr or res.base is arr",
        "assert res is arr"
    ],
    [
        "assert res is not arr and res.flags.owndata",
        "assert res is not arr and"
    ],
    [
        "for copy, val in [(True, None), (np._CopyMode.ALWAYS, None),",
        "for copy, val in [(True,"
    ],
    [
        "for copy in self.if_needed_vals + self.false_vals:",
        "for copy in"
    ],
    [
        "assert res is not arr and res.flags.owndata",
        "assert res is not arr and"
    ],
    [
        "for copy in self.if_needed_vals + self.false_vals:",
        "for copy in self.if_needed_vals +"
    ],
    [
        "assert res is arr or res.base.obj is arr",
        "assert res is arr or res.base.obj is"
    ],
    [
        "attr = ['shape', 'strides', 'data', 'dtype', 'real', 'imag', 'flat']",
        "attr = ['shape', 'strides', 'data', 'dtype', 'real', 'imag',"
    ],
    [
        "attr = [\"ndim\", \"flags\", \"itemsize\", \"size\", \"nbytes\", \"base\",",
        "attr = [\"ndim\", \"flags\", \"itemsize\", \"size\","
    ],
    [
        "attr = ['writebackifcopy', 'updateifcopy', 'aligned', 'writeable']",
        "attr = ['writebackifcopy',"
    ],
    [
        "attr = [\"contiguous\", \"c_contiguous\", \"f_contiguous\", \"fortran\",",
        "attr = [\"contiguous\","
    ],
    [
        "\"owndata\", \"fnc\", \"forc\", \"behaved\", \"carray\", \"farray\",",
        "\"owndata\", \"fnc\", \"forc\","
    ],
    [
        "with pytest.raises(ValueError, match=\".*one element is ambiguous\"):",
        "with pytest.raises(ValueError, match=\".*one"
    ],
    [
        "with pytest.raises(ValueError, match=\".*empty array is ambiguous\"):",
        "with pytest.raises(ValueError, match=\".*empty"
    ],
    [
        "with pytest.raises(ValueError, match=\".*empty array is ambiguous\"):",
        "with pytest.raises(ValueError, match=\".*empty array is"
    ],
    [
        "int_funcs = (int, lambda x: x.__int__())",
        "int_funcs = (int, lambda x:"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception support\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm"
    ],
    [
        "r = np.where(np.array(c)[:, np.newaxis], a, b)",
        "r = np.where(np.array(c)[:, np.newaxis],"
    ],
    [
        "c = np.array([False, True, False, False, False, False, True, False,",
        "c = np.array([False, True, False, False, False,"
    ],
    [
        "c = np.array([False, True, False, False, False, False, True, False,",
        "c = np.array([False, True, False, False, False, False, True,"
    ],
    [
        "op.pow, op.add, op.sub, op.mul, op.floordiv, op.truediv, op.mod,",
        "op.pow, op.add, op.sub, op.mul, op.floordiv,"
    ],
    [
        "op.and_, op.or_, op.xor, op.lshift, op.rshift, op.mod, op.gt,",
        "op.and_, op.or_, op.xor, op.lshift, op.rshift,"
    ],
    [
        "\"\"\" Tests that GETITEM, SETITEM, and PyArray_Scalar roundtrip \"\"\"",
        "\"\"\" Tests that GETITEM, SETITEM, and PyArray_Scalar roundtrip"
    ],
    [
        "assert_(arr_ref() is not None, \"ctypes pointer did not hold onto a reference\")",
        "assert_(arr_ref() is not None, \"ctypes pointer did"
    ],
    [
        "assert_(arr_ref() is None, \"unknowable whether ctypes pointer holds a reference\")",
        "assert_(arr_ref() is None, \"unknowable whether ctypes pointer holds"
    ],
    [
        "assert_(arr_ref() is not None, \"ctypes pointer did not hold onto a reference\")",
        "assert_(arr_ref() is not None, \"ctypes pointer did not hold onto a"
    ],
    [
        "assert_(arr_ref() is None, \"unknowable whether ctypes pointer holds a reference\")",
        "assert_(arr_ref() is None, \"unknowable whether ctypes pointer holds"
    ],
    [
        "reason=\"increments self in dealloc; ignore since deprecated path.\")",
        "reason=\"increments self in dealloc;"
    ],
    [
        "match=rf\"arange\\(\\) not supported for inputs .* {DType_name}\"):",
        "match=rf\"arange\\(\\) not supported for inputs .*"
    ],
    [
        "match=rf\"arange\\(\\) not supported for inputs .* {DType_name}\"):",
        "match=rf\"arange\\(\\) not supported for"
    ],
    [
        "for scalar_type in [type, dict, list, tuple]:",
        "for scalar_type in [type, dict,"
    ],
    [
        "assert_(obj_ref() is not None, \"object should not already be dead\")",
        "assert_(obj_ref() is not None, \"object should not already"
    ],
    [
        "assert_(obj_ref() is not None, \"obj_arr should not hold the last reference\")",
        "assert_(obj_ref() is not None, \"obj_arr should not hold"
    ],
    [
        "assert_(obj_ref() is None, \"no references should remain\")",
        "assert_(obj_ref() is None, \"no"
    ],
    [
        "def test_npymath_complex(fun, npfun, x, y, test_dtype):",
        "def test_npymath_complex(fun, npfun, x, y,"
    ],
    [
        "for x, t in itertools.product(vals, types):",
        "for x, t"
    ],
    [
        "def check(self, shape, dtype, order, align):",
        "def check(self, shape, dtype,"
    ],
    [
        "err_msg = repr((shape, dtype, order, align))",
        "err_msg = repr((shape, dtype,"
    ],
    [
        "x = _aligned_zeros(shape, dtype, order, align=align)",
        "x = _aligned_zeros(shape, dtype,"
    ],
    [
        "for order in [\"C\", \"F\", None]:",
        "for order in [\"C\", \"F\","
    ],
    [
        "Verify that making a view of a non-contiguous array works as expected.",
        "Verify that making a view of"
    ],
    [
        "match='the last axis must be contiguous'):",
        "match='the last axis must"
    ],
    [
        "match='the last axis must be contiguous'):",
        "match='the last axis"
    ],
    [
        "match='When changing to a smaller dtype'):",
        "match='When changing to a smaller"
    ],
    [
        "match='When changing to a larger dtype'):",
        "match='When changing to a larger"
    ],
    [
        "match='the last axis must be contiguous'):",
        "match='the last axis"
    ],
    [
        "infarr = np.inf * np.ones(N, dtype=dtype)",
        "infarr = np.inf"
    ],
    [
        "neginfarr = -np.inf * np.ones(N, dtype=dtype)",
        "neginfarr = -np.inf"
    ],
    [
        "infarr = np.inf * np.ones(N, dtype=dtype)",
        "infarr = np.inf *"
    ],
    [
        "@pytest.mark.parametrize(\"dtype\", ['h', 'H', 'i', 'I', 'l', 'L'])",
        "@pytest.mark.parametrize(\"dtype\", ['h', 'H', 'i',"
    ],
    [
        "arr = rnd.randint(low=minv, high=maxv, size=N, dtype=dtype)",
        "arr = rnd.randint(low=minv,"
    ],
    [
        "arr = rnd.randint(low=minv, high=maxv, size=N, dtype=dtype)",
        "arr = rnd.randint(low=minv,"
    ],
    [
        "arr = rnd.randint(low=minv, high=maxv, size=N, dtype=dtype)",
        "arr = rnd.randint(low=minv,"
    ],
    [
        "arr = rnd.randint(low=minv, high=maxv, size=N, dtype=dtype)",
        "arr = rnd.randint(low=minv, high=maxv,"
    ],
    [
        "If a 'width' parameter is passed into ``binary_repr`` that is insufficient",
        "If a 'width' parameter is passed into ``binary_repr``"
    ],
    [
        "form, the function used to silently ignore the parameter and return a",
        "form, the function used to silently ignore the"
    ],
    [
        "representation using the minimal number of bits needed for the form in",
        "representation using the minimal number of bits"
    ],
    [
        "question. Such behavior is now considered unsafe from a user perspective",
        "question. Such behavior is now considered unsafe from"
    ],
    [
        "Test arr.device attribute and arr.to_device() method.",
        "Test arr.device attribute"
    ],
    [
        "r\"Device not understood. Only \\\"cpu\\\" is allowed, \"",
        "r\"Device not understood. Only \\\"cpu\\\""
    ],
    [
        "r\"attribute 'device' of '(numpy.|)ndarray' objects is \"",
        "r\"attribute 'device' of '(numpy.|)ndarray' objects is"
    ],
    [
        "r\"The stream argument in to_device\\(\\) is not supported\"",
        "r\"The stream argument in to_device\\(\\) is not"
    ],
    [
        "memmap, sum, average, prod, ndarray, isscalar, add, subtract, multiply)",
        "memmap, sum, average, prod, ndarray, isscalar,"
    ],
    [
        "from numpy import arange, allclose, asarray",
        "from numpy import arange,"
    ],
    [
        "sup.filter(FutureWarning, \"np.average currently does not preserve\")",
        "sup.filter(FutureWarning, \"np.average currently"
    ],
    [
        "for unary_op in [sum, average, prod]:",
        "for unary_op in"
    ],
    [
        "for binary_op in [add, subtract, multiply]:",
        "for binary_op in [add,"
    ],
    [
        "fp = memmap(self.tmpfp, shape=size, mode='w+', offset=offset)",
        "fp = memmap(self.tmpfp, shape=size, mode='w+',"
    ],
    [
        "fp = memmap(self.tmpfp, shape=size, mode='w+', offset=offset)",
        "fp = memmap(self.tmpfp,"
    ],
    [
        "from numpy import array, arange, nditer, all",
        "from numpy import array,"
    ],
    [
        "i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a, None], [],"
    ],
    [
        "i = nditer([a.T, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a.T, None], [], [['readonly'], ['writeonly',"
    ],
    [
        "i = nditer([a.T, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a.T, None], [], [['readonly'], ['writeonly',"
    ],
    [
        "raise AssertionError('Should have raised a broadcast error')",
        "raise AssertionError('Should have raised a broadcast"
    ],
    [
        "raise AssertionError('Should have raised a broadcast error')",
        "raise AssertionError('Should have raised a broadcast"
    ],
    [
        "('Message \"%s\" doesn\\'t contain remapped operand shape'",
        "('Message \"%s\" doesn\\'t contain remapped operand"
    ],
    [
        "raise AssertionError('Should have raised a broadcast error')",
        "raise AssertionError('Should have raised a broadcast"
    ],
    [
        "assert_raises(ValueError, nditer, [a], ['bad flag'], [['readonly']])",
        "assert_raises(ValueError, nditer, [a], ['bad"
    ],
    [
        "assert_raises(ValueError, nditer, [a], [], [['readonly', 'bad flag']])",
        "assert_raises(ValueError, nditer, [a], [],"
    ],
    [
        "assert_raises(ValueError, nditer, [a], [], [['readonly']], order='G')",
        "assert_raises(ValueError, nditer, [a],"
    ],
    [
        "assert_raises(ValueError, nditer, [a], [], [['readonly']], casting='noon')",
        "assert_raises(ValueError, nditer, [a], [], [['readonly']],"
    ],
    [
        "assert_raises(ValueError, nditer, a, [], [['readonly', 'writeonly']])",
        "assert_raises(ValueError, nditer, a, [],"
    ],
    [
        "assert_raises(ValueError, nditer, a, [], [['readonly', 'readwrite']])",
        "assert_raises(ValueError, nditer, a, [], [['readonly',"
    ],
    [
        "assert_raises(ValueError, nditer, a, [], [['writeonly', 'readwrite']])",
        "assert_raises(ValueError, nditer, a, [], [['writeonly',"
    ],
    [
        "i = nditer([a, b, c], [], ['readwrite'])",
        "i = nditer([a, b,"
    ],
    [
        "it = np.nditer(a, [], [['readwrite', 'updateifcopy']],",
        "it = np.nditer(a,"
    ],
    [
        "it = np.nditer(a, [], [['readwrite', 'updateifcopy']],",
        "it = np.nditer(a,"
    ],
    [
        "i = nditer(au, [], [['readwrite', 'updateifcopy']],",
        "i = nditer(au, [],"
    ],
    [
        "with nditer(au, [], [['readwrite', 'updateifcopy', 'nbo']],",
        "with nditer(au, [],"
    ],
    [
        "with nditer(a, [], [['readwrite', 'updateifcopy', 'aligned']]) as i:",
        "with nditer(a, [], [['readwrite', 'updateifcopy',"
    ],
    [
        "i = nditer(a, [], [['readonly', 'copy']],",
        "i = nditer(a,"
    ],
    [
        "i = nditer(a, [], [['readonly', 'copy']],",
        "i = nditer(a, [],"
    ],
    [
        "vals = [x_[()] for x_ in i]",
        "vals = [x_[()] for"
    ],
    [
        "vals = [x_[()] for x_ in i]",
        "vals = [x_[()] for x_ in"
    ],
    [
        "i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],",
        "i = nditer(a, ['refs_ok', 'buffered'],"
    ],
    [
        "i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],",
        "i = nditer(a, ['refs_ok',"
    ],
    [
        "i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],",
        "i = nditer(a,"
    ],
    [
        "i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],",
        "i = nditer(a,"
    ],
    [
        "for flag in ['readonly', 'writeonly', 'readwrite']:",
        "for flag in ['readonly', 'writeonly',"
    ],
    [
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['readwrite']]) as i:",
        "with nditer([a, b], ['copy_if_overlap'],"
    ],
    [
        "i = nditer([a, b], ['copy_if_overlap'], [['readonly', 'overlap_assume_elementwise'],",
        "i = nditer([a, b], ['copy_if_overlap'],"
    ],
    [
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['readwrite']]) as i:",
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'],"
    ],
    [
        "i = nditer([a, b], ['copy_if_overlap'], [['readonly'], ['writeonly']])",
        "i = nditer([a, b],"
    ],
    [
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['writeonly']]) as i:",
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'],"
    ],
    [
        "i = nditer([a, b, c], ['copy_if_overlap'],",
        "i = nditer([a, b,"
    ],
    [
        "i = nditer([a, b, c], ['copy_if_overlap'],",
        "i = nditer([a,"
    ],
    [
        "i = nditer([a, b, c], ['copy_if_overlap'],",
        "i = nditer([a, b,"
    ],
    [
        "assert_(all([x == y for (x, y) in i]))",
        "assert_(all([x == y for (x, y)"
    ],
    [
        "assert_(all([x == y for (x, y) in i]))",
        "assert_(all([x == y for (x, y) in"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for x"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for x"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for x in"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for x in"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i],"
    ],
    [
        "assert_equal([x[()] for x in j], a.ravel(order='F'))",
        "assert_equal([x[()] for x in"
    ],
    [
        "assert_equal([x[()] for x in j], a.ravel(order='F'))",
        "assert_equal([x[()] for x in j],"
    ],
    [
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],",
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\","
    ],
    [
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],",
        "it = np.nditer((arr,), [\"buffered\","
    ],
    [
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],",
        "it = np.nditer((arr,),"
    ],
    [
        "i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a, None], [], [['readonly'], ['writeonly',"
    ],
    [
        "i = nditer([a, None], ['buffered', 'delay_bufalloc'],",
        "i = nditer([a,"
    ],
    [
        "i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a, None],"
    ],
    [
        "i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a, None],"
    ],
    [
        "i = nditer([None, a], [], [['writeonly', 'allocate'], ['readonly']],",
        "i = nditer([None, a], [], [['writeonly',"
    ],
    [
        "i = nditer([a, a, None], [],",
        "i = nditer([a, a,"
    ],
    [
        "i = nditer([a, b, None], [],",
        "i = nditer([a,"
    ],
    [
        "i = nditer([a, b, None], [],",
        "i = nditer([a, b, None],"
    ],
    [
        "i = nditer(a, flags, order='F', buffersize=buffersize)",
        "i = nditer(a, flags,"
    ],
    [
        "i = nditer(a, ['ranged'], ['readonly'], order='F',",
        "i = nditer(a, ['ranged'], ['readonly'],"
    ],
    [
        "assert_equal([x[()] for x in i], a_fort)",
        "assert_equal([x[()] for x in"
    ],
    [
        "i = nditer(a, ['ranged', 'buffered'], ['readonly'], order='F',",
        "i = nditer(a, ['ranged', 'buffered'],"
    ],
    [
        "assert_equal([x[()] for x in i], a_fort)",
        "assert_equal([x[()] for x in i],"
    ],
    [
        "i = nditer(a, ['ranged', 'buffered', 'external_loop'],",
        "i = nditer(a, ['ranged',"
    ],
    [
        "i = nditer([a, b], ['buffered', 'delay_bufalloc', 'multi_index', 'reduce_ok'],",
        "i = nditer([a, b], ['buffered',"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered', 'refs_ok'],"
    ],
    [
        "vals = [np.array(x) for x in i]",
        "vals = [np.array(x) for"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered', 'refs_ok'],"
    ],
    [
        "vals = [x.copy() for x in i]",
        "vals = [x.copy() for"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a,"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered', 'refs_ok'],"
    ],
    [
        "for intent in [\"readwrite\", \"readonly\", \"writeonly\"]:",
        "for intent in [\"readwrite\", \"readonly\","
    ],
    [
        "nditer((simple_arr, a), ['buffered', 'refs_ok'], [intent, intent],",
        "nditer((simple_arr, a), ['buffered',"
    ],
    [
        "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"PyPy seems to not hit this.\")",
        "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"PyPy seems to not"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered',"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readwrite'],",
        "i = nditer(a,"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readwrite'],",
        "i = nditer(a, ['buffered',"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered',"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered',"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a,"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a,"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered', 'refs_ok'],"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a,"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered', 'refs_ok'],"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered', 'refs_ok'],"
    ],
    [
        "a = np.array(['abc', 'a', 'abcd'], dtype=np.bytes_)",
        "a = np.array(['abc', 'a', 'abcd'],"
    ],
    [
        "a = np.array(['abc', 'a', 'abcd'], dtype=np.str_)",
        "a = np.array(['abc', 'a',"
    ],
    [
        "i = nditer(a, ['buffered', 'growinner', 'external_loop'],",
        "i = nditer(a,"
    ],
    [
        "with pytest.raises(TypeError, match=\"Iterator operand required buffering\"):",
        "with pytest.raises(TypeError, match=\"Iterator"
    ],
    [
        "Tests the strides with the contig flag for both broadcast and non-broadcast",
        "Tests the strides with the contig"
    ],
    [
        "NOTE: The semantics of the cast flag are not clearly defined when",
        "NOTE: The semantics of the cast"
    ],
    [
        "it comes to reduction.  It is unclear that there are any users.",
        "it comes to reduction. It is unclear"
    ],
    [
        "for f, b, r in iterator:",
        "for f, b, r"
    ],
    [
        "@pytest.mark.xfail(reason=\"The contig flag was always buggy.\")",
        "@pytest.mark.xfail(reason=\"The contig flag"
    ],
    [
        "flags = ['buffered', 'delay_bufalloc', 'multi_index', 'reduce_ok', 'refs_ok']",
        "flags = ['buffered', 'delay_bufalloc', 'multi_index', 'reduce_ok',"
    ],
    [
        "strides = (xs * a.itemsize, ys * a.itemsize, a.itemsize)",
        "strides = (xs * a.itemsize, ys"
    ],
    [
        "for arr, op_axes, skip in get_params():",
        "for arr, op_axes, skip"
    ],
    [
        "flags = ['buffered', 'reduce_ok', 'refs_ok', 'multi_index']",
        "flags = ['buffered',"
    ],
    [
        "assert_raises(ValueError, nditer, [a, b, c], [],",
        "assert_raises(ValueError, nditer, [a, b,"
    ],
    [
        "assert_raises(ValueError, nditer, [a, b, c], [],",
        "assert_raises(ValueError, nditer, [a,"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _ in"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _ in"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _ in"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _ in"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _ in"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _ in"
    ],
    [
        "vals = [list(j) for _ in i]",
        "vals = [list(j) for _ in"
    ],
    [
        "i = nditer([a, None], ['reduce_ok', 'external_loop'],",
        "i = nditer([a,"
    ],
    [
        "i = nditer([a, b], ['reduce_ok', 'buffered'],",
        "i = nditer([a, b], ['reduce_ok',"
    ],
    [
        "i = nditer([a, b], ['reduce_ok', 'external_loop', 'buffered'],",
        "i = nditer([a, b], ['reduce_ok',"
    ],
    [
        "it = np.nditer([a, b], flags=['reduce_ok', 'external_loop', 'buffered'],",
        "it = np.nditer([a, b],"
    ],
    [
        "m = np.array([[True, True, False], [False, True, False]])",
        "m = np.array([[True, True,"
    ],
    [
        "assert_raises(ValueError, nditer, [a, b, m], ['reduce_ok'],",
        "assert_raises(ValueError, nditer, [a, b, m],"
    ],
    [
        "msk[...] = [True, True, False] * reps",
        "msk[...] = [True, True, False]"
    ],
    [
        "it = np.nditer([arr, mask], ['buffered', \"refs_ok\"],",
        "it = np.nditer([arr, mask],"
    ],
    [
        "assert sys.getrefcount(singleton) - count == np.count_nonzero(mask)",
        "assert sys.getrefcount(singleton) - count =="
    ],
    [
        "attr = [\"value\", \"shape\", \"operands\", \"itviews\", \"has_delayed_bufalloc\",",
        "attr = [\"value\", \"shape\", \"operands\", \"itviews\","
    ],
    [
        "attr = [\"multi_index\", \"index\", \"iterrange\", \"iterindex\"]",
        "attr = [\"multi_index\", \"index\", \"iterrange\","
    ],
    [
        "for a, b, c in it:",
        "for a, b,"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a,"
    ],
    [
        "it = nditer(au, [], [['readwrite', 'updateifcopy']],",
        "it = nditer(au, [],"
    ],
    [
        "it = nditer(au, [], [['readwrite', 'updateifcopy']],",
        "it = nditer(au, [], [['readwrite',"
    ],
    [
        "raise ValueError('exit context manager on exception')",
        "raise ValueError('exit context"
    ],
    [
        "it = nditer(au, [], [['readwrite', 'updateifcopy']],",
        "it = nditer(au, [],"
    ],
    [
        "''' using a context amanger and using nditer.close are equivalent",
        "''' using a context amanger and using nditer.close are"
    ],
    [
        "it = np.nditer([x, y, out], [],",
        "it = np.nditer([x, y, out],"
    ],
    [
        "for (a, b, c) in it:",
        "for (a, b,"
    ],
    [
        "it = np.nditer([x, y, out], [],",
        "it = np.nditer([x, y,"
    ],
    [
        "for (a, b, c) in it:",
        "for (a, b,"
    ],
    [
        "it = np.nditer(au, [], [['readwrite', 'updateifcopy']],",
        "it = np.nditer(au, [],"
    ],
    [
        "Checks for reference counting leaks during cleanup.  Using explicit",
        "Checks for reference counting leaks during"
    ],
    [
        "reference counts lead to occasional false positives (at least in parallel",
        "reference counts lead to occasional false positives (at"
    ],
    [
        "test setups).  This test now should still test leaks correctly when",
        "test setups). This test now should still test leaks correctly"
    ],
    [
        "run e.g. with pytest-valgrind or pytest-leaks",
        "run e.g. with pytest-valgrind or"
    ],
    [
        "assert all(v == i for v in vals)",
        "assert all(v == i for v in"
    ],
    [
        "assert all(v == i for v in vals)",
        "assert all(v == i for v"
    ],
    [
        "with pytest.raises(ValueError, match=\"Too many operands to nditer\"):",
        "with pytest.raises(ValueError, match=\"Too many operands"
    ],
    [
        "with pytest.raises(ValueError, match=\"Too many operands to nditer\"):",
        "with pytest.raises(ValueError, match=\"Too many operands"
    ],
    [
        "Matches the expected output of a debug print with the actual output.",
        "Matches the expected output of a debug"
    ],
    [
        "Note that the iterator dump should not be considered stable API,",
        "Note that the iterator dump should not be"
    ],
    [
        "this test is mainly to ensure the print does not crash.",
        "this test is mainly to ensure the print does not"
    ],
    [
        "Currently uses a subprocess to avoid dealing with the C level `printf`s.",
        "Currently uses a subprocess to avoid"
    ],
    [
        "for res_line, expected_line in zip(res, expected):",
        "for res_line, expected_line in zip(res,"
    ],
    [
        "\"\"\" % (detected, cpuinfo, auxv), prefix='\\r')",
        "\"\"\" % (detected, cpuinfo,"
    ],
    [
        ") % (fname, actual, desired, error_report))",
        ") % (fname, actual,"
    ],
    [
        "test_features = [self.cpu_have(f) for f in features]",
        "test_features = [self.cpu_have(f) for"
    ],
    [
        "return any(f in self.features_flags for f in map_names)",
        "return any(f in self.features_flags"
    ],
    [
        "\"The subprocess module is not available on WASM platforms and\"",
        "\"The subprocess module is not available on"
    ],
    [
        "\" therefore this test class cannot be properly executed.\"",
        "\" therefore this test class cannot"
    ],
    [
        "SUBPROCESS_ARGS = {\"cwd\": cwd, \"capture_output\": True, \"text\": True, \"check\": True}",
        "SUBPROCESS_ARGS = {\"cwd\": cwd, \"capture_output\": True, \"text\": True,"
    ],
    [
        "feat for feat in __cpu_dispatch__ if not __cpu_features__[feat]",
        "feat for feat in __cpu_dispatch__"
    ],
    [
        "detected = [feat for feat in __cpu_dispatch__ if __cpu_features__[feat]]",
        "detected = [feat for feat in __cpu_dispatch__ if"
    ],
    [
        "f\"Expected error of type: {err_type}; see full \"",
        "f\"Expected error of type: {err_type}; see"
    ],
    [
        "\"\"\"Ensure that the environment is reset\"\"\"",
        "\"\"\"Ensure that the environment is"
    ],
    [
        "Ensure that when selecting `NPY_ENABLE_CPU_FEATURES`, only the",
        "Ensure that when selecting `NPY_ENABLE_CPU_FEATURES`,"
    ],
    [
        "\"No dispatchable features outside of baseline detected.\"",
        "\"No dispatchable features outside of baseline"
    ],
    [
        "Ensure that when both environment variables are set then an",
        "Ensure that when both environment variables"
    ],
    [
        "msg = \"Both NPY_DISABLE_CPU_FEATURES and NPY_ENABLE_CPU_FEATURES\"",
        "msg = \"Both NPY_DISABLE_CPU_FEATURES and"
    ],
    [
        "Test that an error is thrown if the environment variables are too long",
        "Test that an error is thrown if the environment"
    ],
    [
        "f\"Length of environment variable 'NPY_{action}_CPU_FEATURES' is \"",
        "f\"Length of environment variable 'NPY_{action}_CPU_FEATURES'"
    ],
    [
        "Test that a RuntimeError is thrown if an impossible feature-disabling",
        "Test that a RuntimeError is thrown if an impossible"
    ],
    [
        "request is made. This includes disabling a baseline feature.",
        "request is made. This includes"
    ],
    [
        "pytest.skip(\"There are no unavailable features to test with\")",
        "pytest.skip(\"There are no unavailable features"
    ],
    [
        "f\"You cannot disable CPU feature '{bad_feature}', since it is \"",
        "f\"You cannot disable CPU feature '{bad_feature}', since it"
    ],
    [
        "Test that a RuntimeError is thrown if an impossible feature-enabling",
        "Test that a RuntimeError is"
    ],
    [
        "request is made. This includes enabling a feature not supported by the",
        "request is made. This includes enabling a feature not"
    ],
    [
        "machine, or disabling a baseline optimization.",
        "machine, or disabling a baseline"
    ],
    [
        "pytest.skip(\"There are no unavailable features to test with\")",
        "pytest.skip(\"There are no unavailable"
    ],
    [
        "f\"You cannot enable CPU features \\\\({bad_feature}\\\\), since \"",
        "f\"You cannot enable CPU features"
    ],
    [
        "\"they are not supported by your machine.\"",
        "\"they are not supported by"
    ],
    [
        "f\"You cannot enable CPU features \\\\({bad_feature}\\\\), since they \"",
        "f\"You cannot enable CPU features"
    ],
    [
        "\"are not supported by your machine.\"",
        "\"are not supported by"
    ],
    [
        "f\"You cannot enable CPU features \\\\({bad_feature}\\\\), since \"",
        "f\"You cannot enable CPU features \\\\({bad_feature}\\\\),"
    ],
    [
        "\"they are not supported by your machine.\"",
        "\"they are not supported by your"
    ],
    [
        "@pytest.mark.skipif(not is_linux or not is_power, reason=\"Only for Linux and Power\")",
        "@pytest.mark.skipif(not is_linux or not is_power, reason=\"Only for"
    ],
    [
        "reason=\"Only for Linux and IBM Z\")",
        "reason=\"Only for Linux and IBM"
    ],
    [
        "@pytest.mark.skipif(not is_linux or not is_arm, reason=\"Only for Linux and ARM\")",
        "@pytest.mark.skipif(not is_linux or not is_arm, reason=\"Only for Linux"
    ],
    [
        "\"SVE\", \"NEON\", \"ASIMD\", \"FPHP\", \"ASIMDHP\", \"ASIMDDP\", \"ASIMDFHM\"",
        "\"SVE\", \"NEON\", \"ASIMD\", \"FPHP\", \"ASIMDHP\", \"ASIMDDP\","
    ],
    [
        "@pytest.mark.skipif(not is_linux or not is_loongarch, reason=\"Only for Linux and LoongArch\")",
        "@pytest.mark.skipif(not is_linux or not is_loongarch,"
    ],
    [
        "\"numeric\": (\"integral\", \"real floating\", \"complex floating\"),",
        "\"numeric\": (\"integral\", \"real floating\", \"complex"
    ],
    [
        "Tests for the private NumPy argument parsing functionality.",
        "Tests for the private NumPy argument parsing"
    ],
    [
        "They mainly exists to ensure good test coverage without having to try the",
        "They mainly exists to ensure good test coverage without"
    ],
    [
        "weirder cases on actual numpy functions but test them in one place.",
        "weirder cases on actual numpy functions but test them in one"
    ],
    [
        "The test function is defined in C to be equivalent to (errors may not always",
        "The test function is defined in C to be equivalent"
    ],
    [
        "match exactly, and could be adjusted):",
        "match exactly, and"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"wasm doesn't have support for threads\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"wasm doesn't have support for"
    ],
    [
        "match=\"got an unexpected keyword argument 'missing_arg'\"):",
        "match=\"got an unexpected"
    ],
    [
        "dt = np.dtype([('x', int), ('y', np.object_), ('z', 'O')])",
        "dt = np.dtype([('x', int),"
    ],
    [
        "dt = np.dtype([('x', int), ('y', np.object_)])",
        "dt = np.dtype([('x',"
    ],
    [
        "x = np.char.array((\"x\", \"x \", \"x  \"))",
        "x = np.char.array((\"x\", \"x \", \"x"
    ],
    [
        "if isinstance(result, np.ndarray) and result.dtype.names is not None:",
        "if isinstance(result, np.ndarray) and result.dtype.names is not"
    ],
    [
        "raise AssertionError(\"compress with an out which cannot be \"",
        "raise AssertionError(\"compress with an out which"
    ],
    [
        "\"safely casted should not return \"",
        "\"safely casted should"
    ],
    [
        "msg = 'unicode offset: %d chars' % i",
        "msg = 'unicode offset: %d chars' %"
    ],
    [
        "dt = np.dtype([('foo', float), ('bar', float)])",
        "dt = np.dtype([('foo', float),"
    ],
    [
        "for dtype in [np.dtype('<' + t) for t in np.typecodes['Complex']]:",
        "for dtype in [np.dtype('<' +"
    ],
    [
        "dtspec = [(('a', 'a'), 'i'), ('b', 'i')]",
        "dtspec = [(('a', 'a'), 'i'), ('b',"
    ],
    [
        "dtypes = [x for x in np._core.sctypeDict.values()",
        "dtypes = [x for x"
    ],
    [
        "for name in ('eps', 'epsneg', 'max', 'min', 'resolution', 'tiny'):",
        "for name in ('eps', 'epsneg', 'max', 'min',"
    ],
    [
        "for tp in [np.csingle, np.cdouble, np.clongdouble]:",
        "for tp in"
    ],
    [
        "for tp in [np.csingle, np.cdouble, np.clongdouble]:",
        "for tp in [np.csingle,"
    ],
    [
        "for tp in [np.csingle, np.cdouble, np.clongdouble]:",
        "for tp in"
    ],
    [
        "for tostr, dtype in [(asunicode, \"U\"), (asbytes, \"S\")]:",
        "for tostr, dtype in [(asunicode,"
    ],
    [
        "arr = np.array([[a, b], [a, b]], order='F')",
        "arr = np.array([[a, b], [a, b]],"
    ],
    [
        "for f in [op.lt, op.le, op.gt, op.ge]:",
        "for f in [op.lt, op.le, op.gt,"
    ],
    [
        "for axis in chain(range(-a.ndim, a.ndim), [None]):",
        "for axis in chain(range(-a.ndim,"
    ],
    [
        "([('a', 'O'), ('b', 'O')], [('c', 'O'), ('d', 'O')]))",
        "([('a', 'O'), ('b', 'O')], [('c', 'O'),"
    ],
    [
        "s = 'Some long field name'",
        "s = 'Some long"
    ],
    [
        "with pytest.raises(TypeError, match=r\"Unable to convert dtype.*\"):",
        "with pytest.raises(TypeError, match=r\"Unable"
    ],
    [
        "assert str(f) == \"<ufunc 'cassÃ© (vectorized)'>\"",
        "assert str(f) == \"<ufunc 'cassÃ©"
    ],
    [
        "f\"Unexpected types order of ufunc in {operation}\"",
        "f\"Unexpected types order of ufunc in"
    ],
    [
        "f\"for {order}. Possible fix: Use signed before unsigned\"",
        "f\"for {order}. Possible fix: Use signed"
    ],
    [
        "with pytest.raises(TypeError, match=\"not an acceptable base type\"):",
        "with pytest.raises(TypeError, match=\"not an acceptable"
    ],
    [
        "with pytest.raises(TypeError, match=\"not an acceptable base type\"):",
        "with pytest.raises(TypeError, match=\"not an acceptable"
    ],
    [
        "match=\"Only None and strings are allowed as the Array API version\"",
        "match=\"Only None and strings are allowed"
    ],
    [
        "expected[:] = [s.replace(b\"E\", b\"D\") for s in test_strings]",
        "expected[:] = [s.replace(b\"E\", b\"D\") for s in"
    ],
    [
        "Provide python-space access to the functions exposed in numpy/__init__.pxd",
        "Provide python-space access to the functions exposed"
    ],
    [
        "Build an example package using the limited Python C API.",
        "Build an example package using the limited Python C"
    ],
    [
        "/* By default do not export API in an .so (was never the case on windows) */",
        "/* By default do not export API in an .so (was never the case"
    ],
    [
        "if (numpy == NULL && PyErr_ExceptionMatches(PyExc_ModuleNotFoundError)) {",
        "if (numpy == NULL &&"
    ],
    [
        "PyErr_SetString(PyExc_RuntimeError, \"_UFUNC_API is not PyCapsule object\");",
        "PyErr_SetString(PyExc_RuntimeError, \"_UFUNC_API is"
    ],
    [
        "/* These pointers will be stored in the C-object for use in other",
        "/* These pointers will be stored in the C-object"
    ],
    [
        "h_file = os.path.join(output_dir, '__%s.h' % basename)",
        "h_file = os.path.join(output_dir,"
    ],
    [
        "c_file = os.path.join(output_dir, '__%s.c' % basename)",
        "c_file = os.path.join(output_dir, '__%s.c' %"
    ],
    [
        "ufunc_api_dict[name] = TypeApi(name, index, 'PyTypeObject', api_name)",
        "ufunc_api_dict[name] = TypeApi(name,"
    ],
    [
        "s = h_template % ('\\n'.join(module_list), '\\n'.join(extension_list))",
        "s = h_template %"
    ],
    [
        "/* By default do not export API in an .so (was never the case on windows) */",
        "/* By default do not export API in an .so (was never the"
    ],
    [
        "* The DType classes are inconvenient for the Python generation so exposed",
        "* The DType classes are inconvenient for the Python generation"
    ],
    [
        "* manually in the header below  (may be moved).",
        "* manually in the header below (may be"
    ],
    [
        "if (numpy == NULL && PyErr_ExceptionMatches(PyExc_ModuleNotFoundError)) {",
        "if (numpy == NULL"
    ],
    [
        "PyErr_SetString(PyExc_RuntimeError, \"_ARRAY_API is not PyCapsule object\");",
        "PyErr_SetString(PyExc_RuntimeError, \"_ARRAY_API is not"
    ],
    [
        "* On exceedingly few platforms these sizes may not match, in which case",
        "* On exceedingly few platforms these sizes"
    ],
    [
        "* We do not support older NumPy versions at all.",
        "* We do not support"
    ],
    [
        "\"Unfortunately, this is not supported on niche platforms where \"",
        "\"Unfortunately, this is not supported on"
    ],
    [
        "* backwards compatible (in the exposed feature subset!) for all practical",
        "* backwards compatible (in the exposed"
    ],
    [
        "\"Check the section C-API incompatibility at the \"",
        "\"Check the section C-API incompatibility at the"
    ],
    [
        "\"for indications on how to solve this problem.\",",
        "\"for indications on how"
    ],
    [
        "* Perform runtime check of endianness and check it matches the one set by",
        "* Perform runtime check of endianness and check it matches the"
    ],
    [
        "* the headers (npy_endian.h) as a safeguard",
        "* the headers (npy_endian.h)"
    ],
    [
        "\"FATAL: module compiled as unknown endian\");",
        "\"FATAL: module compiled as"
    ],
    [
        "\"FATAL: module compiled as big endian, but \"",
        "\"FATAL: module compiled as big endian,"
    ],
    [
        "\"FATAL: module compiled as little endian, but \"",
        "\"FATAL: module compiled as little"
    ],
    [
        "/* These pointers will be stored in the C-object for use in other",
        "/* These pointers will be stored in the C-object for use in"
    ],
    [
        "h_file = os.path.join(output_dir, '__%s.h' % basename)",
        "h_file = os.path.join(output_dir, '__%s.h' %"
    ],
    [
        "c_file = os.path.join(output_dir, '__%s.c' % basename)",
        "c_file = os.path.join(output_dir,"
    ],
    [
        "multiarray_api_dict[name] = GlobalVarApi(name, index, type, api_name)",
        "multiarray_api_dict[name] = GlobalVarApi(name,"
    ],
    [
        "\"Multiarray API size mismatch - \"",
        "\"Multiarray API size mismatch"
    ],
    [
        "\"index has extra keys {}, dict has extra keys {}\"",
        "\"index has extra keys {}, dict has extra keys"
    ],
    [
        ".format(keys_index - keys_dict, keys_dict - keys_index)",
        ".format(keys_index - keys_dict, keys_dict -"
    ],
    [
        "s = h_template % ('\\n'.join(module_list), '\\n'.join(extension_list))",
        "s = h_template %"
    ],
    [
        "help=\"An ignored input - may be useful to add a \"",
        "help=\"An ignored input - may be useful to"
    ],
    [
        "Return current C API checksum and the recorded checksum.",
        "Return current C API checksum and the"
    ],
    [
        "Return current C API checksum and the recorded checksum for the given",
        "Return current C API checksum and the recorded checksum for"
    ],
    [
        "version of the C API version.",
        "version of the"
    ],
    [
        "\"\"\"Emits a MismatchCAPIWarning if the C API version needs updating.\"\"\"",
        "\"\"\"Emits a MismatchCAPIWarning if the C API version needs"
    ],
    [
        "msg = (\"API mismatch detected, the C API version \"",
        "msg = (\"API mismatch detected,"
    ],
    [
        "\"numbers have to be updated. Current C api version is \"",
        "\"numbers have to be updated. Current C api"
    ],
    [
        "f\"{apiversion}, with checksum {curapi_hash}, but recorded \"",
        "f\"{apiversion}, with checksum {curapi_hash}, but recorded"
    ],
    [
        "f\"checksum in _core/codegen_dir/cversions.txt is {api_hash}. \"",
        "f\"checksum in _core/codegen_dir/cversions.txt is {api_hash}."
    ],
    [
        "\"If functions were added in the C API, you have to update \"",
        "\"If functions were added in the C API, you have to update"
    ],
    [
        "help=\"C API version to verify (as a hex string)\"",
        "help=\"C API version to verify (as a hex"
    ],
    [
        "Get API information encoded in C files.",
        "Get API information encoded in"
    ],
    [
        "See ``find_function`` for how functions should be formatted, and",
        "See ``find_function`` for how functions"
    ],
    [
        "``read_order`` for how the order of the functions should be",
        "``read_order`` for how the order of the"
    ],
    [
        "API_FILES = [os.path.join(THIS_DIR, '..', 'src', a) for a in API_FILES]",
        "API_FILES = [os.path.join(THIS_DIR, '..', 'src', a) for"
    ],
    [
        "\"\"\"Wrap a definition behind a version guard\"\"\"",
        "\"\"\"Wrap a definition behind"
    ],
    [
        "return ' '.join('NPY_STEALS_REF_TO_ARG(%d)' % x for x in self.arg)",
        "return ' '.join('NPY_STEALS_REF_TO_ARG(%d)' % x for x"
    ],
    [
        "def __init__(self, name, return_type, args, doc=''):",
        "def __init__(self, name, return_type,"
    ],
    [
        "return typename + ' ' + name",
        "return typename + ' '"
    ],
    [
        "argstr = ', '.join([self._format_arg(*a) for a in self.args])",
        "argstr = ', '.join([self._format_arg(*a) for"
    ],
    [
        "doccomment = '/* %s */\\n' % self.doc",
        "doccomment = '/* %s"
    ],
    [
        "return '%s%s %s(%s)' % (doccomment, self.return_type, self.name, argstr)",
        "return '%s%s %s(%s)' % (doccomment, self.return_type,"
    ],
    [
        "return '%s:%s:%s' % (self.filename, self.lineno, self.msg)",
        "return '%s:%s:%s' % (self.filename, self.lineno,"
    ],
    [
        "raise ValueError(\"no match '%s' for '%s' (%r)\" % (lbrac, rbrac, s))",
        "raise ValueError(\"no match '%s' for '%s'"
    ],
    [
        "Scan the file, looking for tagged functions.",
        "Scan the file, looking for tagged"
    ],
    [
        "Assuming ``tag=='API'``, a tagged function looks like::",
        "Assuming ``tag=='API'``, a tagged function looks"
    ],
    [
        "where the return type must be on a separate line, the function",
        "where the return type must be on a separate"
    ],
    [
        "name must start the line, and the opening ``{`` must start the line.",
        "name must start the line, and the opening ``{`` must start the"
    ],
    [
        "An optional documentation comment in ReST format may follow the tag,",
        "An optional documentation comment in ReST"
    ],
    [
        "msg = \"see chained exception for details\"",
        "msg = \"see chained exception"
    ],
    [
        "Only write changed data to avoid updating timestamps unnecessarily",
        "Only write changed data to avoid"
    ],
    [
        "def __init__(self, name, index, ptr_cast, api_name, internal_type=None):",
        "def __init__(self, name, index,"
    ],
    [
        "return \"        (void *) &%s\" % self.name",
        "return \" (void *) &%s\""
    ],
    [
        "def __init__(self, name, index, type, api_name):",
        "def __init__(self, name, index, type,"
    ],
    [
        "return \"        (%s *) &%s\" % (self.type, self.name)",
        "return \" (%s *) &%s\" %"
    ],
    [
        "\"\"\" % {'type': self.type, 'name': self.name}",
        "\"\"\" % {'type': self.type,"
    ],
    [
        "return \"        (void *) &%s\" % self.name",
        "return \" (void *) &%s\""
    ],
    [
        "def __init__(self, name, index, annotations, return_type, args, api_name):",
        "def __init__(self, name, index, annotations, return_type,"
    ],
    [
        "return \"        (void *) %s\" % self.name",
        "return \" (void *) %s\" %"
    ],
    [
        "annstr = [str(a) for a in self.annotations]",
        "annstr = [str(a) for a in"
    ],
    [
        "NPY_NO_EXPORT %s %s %s \\\\\\n       (%s);\"\"\" % (annstr, self.return_type,",
        "NPY_NO_EXPORT %s %s %s \\\\\\n"
    ],
    [
        "\"\"\"Check that an api dict is valid (does not use the same index twice)",
        "\"\"\"Check that an api dict is valid (does"
    ],
    [
        "and removed `__unused_indices__` from it (which is important only here)",
        "and removed `__unused_indices__` from it"
    ],
    [
        "revert_dict = {v: k for k, v in index_d.items()}",
        "revert_dict = {v: k for k,"
    ],
    [
        "fmt = \"Same index has been used twice in api definition: {}\"",
        "fmt = \"Same index has been used twice in"
    ],
    [
        "raise ValueError(\"API index used but marked unused: \"",
        "raise ValueError(\"API index used but marked unused:"
    ],
    [
        "msg = \"There are some holes in the API indexing: \" \\",
        "msg = \"There are some holes"
    ],
    [
        "\"(symmetric diff is %s)\" % diff",
        "\"(symmetric diff is"
    ],
    [
        "\"\"\"Parse source files to get functions tagged by the given tag.\"\"\"",
        "\"\"\"Parse source files to get functions tagged by the given"
    ],
    [
        "\"\"\"Given a list of api dicts defining the numpy C API, compute a checksum",
        "\"\"\"Given a list of api dicts defining the numpy C API,"
    ],
    [
        "of the list of items in the API (as a string).\"\"\"",
        "of the list of items in the API (as"
    ],
    [
        "Generate the code to build all the internal ufuncs. At the base is the defdict:",
        "Generate the code to build all the internal"
    ],
    [
        "a dictionary ofUfunc classes. This is fed to make_code to generate",
        "a dictionary ofUfunc classes. This is"
    ],
    [
        "\"\"\"Stores the suffix to append when generating functions names.",
        "\"\"\"Stores the suffix to append when generating"
    ],
    [
        "func_data : str or None or FullTypeDescr or FuncNameSuffix, optional",
        "func_data : str or None"
    ],
    [
        "The string representing the expression to insert into the data",
        "The string representing the expression to insert into"
    ],
    [
        "in_ : str or None, optional",
        "in_ : str or"
    ],
    [
        "out : str or None, optional",
        "out : str or"
    ],
    [
        "astype : dict or None, optional",
        "astype : dict"
    ],
    [
        "If astype['x'] is 'y', uses PyUFunc_x_x_As_y_y/PyUFunc_xx_x_As_yy_y",
        "If astype['x'] is"
    ],
    [
        "cfunc_alias : str or none, optional",
        "cfunc_alias : str or none,"
    ],
    [
        "Appended to inner loop C function name, e.g., FLOAT_{cfunc_alias}. See make_arrays.",
        "Appended to inner loop C function name, e.g., FLOAT_{cfunc_alias}. See"
    ],
    [
        "dispatch : str or None, optional",
        "dispatch : str or"
    ],
    [
        "Dispatch-able source name without its extension '.dispatch.c' that",
        "Dispatch-able source name without its extension '.dispatch.c'"
    ],
    [
        "contains the definition of ufunc, dispatched at runtime depending on the",
        "contains the definition of ufunc, dispatched at runtime depending on"
    ],
    [
        "specified targets of the dispatch-able source.",
        "specified targets of"
    ],
    [
        "def __init__(self, type, f=None, in_=None, out=None, astype=None, cfunc_alias=None,",
        "def __init__(self, type, f=None, in_=None,"
    ],
    [
        "Helper to check that the loop types are ordered. The legacy type resolver",
        "Helper to check that the loop types are ordered. The legacy type"
    ],
    [
        "(and potentially downstream) may pick use the first loop to which operands",
        "(and potentially downstream) may pick use the first loop to"
    ],
    [
        "dtype_order = bints + 'kK' + times + flts + cmplxP + \"O\"",
        "dtype_order = bints + 'kK' + times + flts + cmplxP"
    ],
    [
        "signatures = [t.in_ + t.out for t in tds]",
        "signatures = [t.in_ + t.out for"
    ],
    [
        "func_data = [_floatformat_map.get(t, '%s') % (f,) for t in types]",
        "func_data = [_floatformat_map.get(t, '%s') % (f,) for"
    ],
    [
        "def TD(types, f=None, astype=None, in_=None, out=None, cfunc_alias=None,",
        "def TD(types, f=None, astype=None,"
    ],
    [
        "Generate a TypeDescription instance for each item in types",
        "Generate a TypeDescription instance for each item in"
    ],
    [
        "raise ValueError(\"Number of types and f do not match\")",
        "raise ValueError(\"Number of types and f do"
    ],
    [
        "raise ValueError(\"Number of types and inputs do not match\")",
        "raise ValueError(\"Number of types and inputs"
    ],
    [
        "raise ValueError(\"Number of types and outputs do not match\")",
        "raise ValueError(\"Number of types and outputs do not"
    ],
    [
        "for t, fd, i, o in zip(types, func_data, in_, out):",
        "for t, fd, i, o in zip(types,"
    ],
    [
        "t, f=fd, in_=i, out=o, astype=astype, cfunc_alias=cfunc_alias,",
        "t, f=fd, in_=i, out=o, astype=astype,"
    ],
    [
        "nin : number of input arguments",
        "nin : number of input"
    ],
    [
        "nout : number of output arguments",
        "nout : number of"
    ],
    [
        "identity : identity element for a two-argument function (like Zero)",
        "identity : identity element for a"
    ],
    [
        "docstring : docstring for the ufunc",
        "docstring : docstring for the"
    ],
    [
        "typereso: type resolver function of type PyUFunc_TypeResolutionFunc",
        "typereso: type resolver function of type"
    ],
    [
        "signature: a generalized ufunc signature (like for matmul)",
        "signature: a generalized ufunc signature (like"
    ],
    [
        "indexed: add indexed loops (ufunc.at) for these type characters",
        "indexed: add indexed loops (ufunc.at) for these type"
    ],
    [
        "def __init__(self, nin, nout, identity, docstring, typereso,",
        "def __init__(self, nin, nout,"
    ],
    [
        "\"\"\" Apply English case rules to convert ASCII strings to all upper case.",
        "\"\"\" Apply English case rules to convert ASCII strings to"
    ],
    [
        "This is an internal utility function to replace calls to str.upper() such",
        "This is an internal utility function"
    ],
    [
        "that we can avoid changing behavior with changing locales. In particular,",
        "that we can avoid changing behavior with changing locales. In"
    ],
    [
        "Turkish has distinct dotted and dotless variants of the Latin letter \"I\" in",
        "Turkish has distinct dotted and dotless variants of the"
    ],
    [
        "both lowercase and uppercase. Thus, \"i\".upper() != \"I\" in a \"tr\" locale.",
        "both lowercase and uppercase. Thus, \"i\".upper() != \"I\""
    ],
    [
        "allP = bints + times + flts + cmplxP",
        "allP = bints + times + flts +"
    ],
    [
        "intfltcmplx = ints + flts + cmplx",
        "intfltcmplx = ints +"
    ],
    [
        "nocmplx = bints + times + flts",
        "nocmplx = bints +"
    ],
    [
        "TD(flts + cmplx, cfunc_alias='divide', dispatch=[('loops_arithm_fp', 'fd')]),",
        "TD(flts + cmplx, cfunc_alias='divide',"
    ],
    [
        "TD(ints + flts + cmplx, dispatch=[",
        "TD(ints + flts"
    ],
    [
        "TD(bints + flts + timedeltaonly, dispatch=[",
        "TD(bints + flts"
    ],
    [
        "TD(ints + flts + timedeltaonly, dispatch=[('loops_unary', ints + 'fdg')]),",
        "TD(ints + flts + timedeltaonly,"
    ],
    [
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints + 'fd')]),",
        "TD(inexact + times, out='?', dispatch=[('loops_comparison',"
    ],
    [
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints + 'fd')]),",
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints"
    ],
    [
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints + 'fd')]),",
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints +"
    ],
    [
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints + 'fd')]),",
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints"
    ],
    [
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints + 'fd')]),",
        "TD(inexact + times, out='?',"
    ],
    [
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints + 'fd')]),",
        "TD(inexact + times, out='?', dispatch=[('loops_comparison', bints"
    ],
    [
        "indentation = ' ' * spaces",
        "indentation = ' '"
    ],
    [
        "indented = indentation + st.replace('\\n', '\\n' + indentation)",
        "indented = indentation + st.replace('\\n', '\\n' +"
    ],
    [
        "indented = re.sub(r' +$', r'', indented)",
        "indented = re.sub(r'"
    ],
    [
        "cfunc_alias = t.cfunc_alias if t.cfunc_alias else name",
        "cfunc_alias = t.cfunc_alias if t.cfunc_alias else"
    ],
    [
        "astr = ('%s_functions[%d] = PyUFunc_%s%s;' %",
        "astr = ('%s_functions[%d]"
    ],
    [
        "astr = ('%s_data[%d] = (void *) %s;' %",
        "astr = ('%s_data[%d] = (void *) %s;'"
    ],
    [
        "astr = ('%s_data[%d] = (void *) %s;' %",
        "astr = ('%s_data[%d] = (void *)"
    ],
    [
        "(name, k, cfunc_fname, t.in_ + t.out)",
        "(name, k, cfunc_fname,"
    ],
    [
        "for x in t.in_ + t.out:",
        "for x in t.in_ +"
    ],
    [
        "if funclist or siglist or datalist:",
        "if funclist or"
    ],
    [
        "for (ufunc_name, func_idx, cfunc_name, inout) in funcs:",
        "for (ufunc_name, func_idx, cfunc_name,"
    ],
    [
        "if ({has_identity} && identity == NULL) {{",
        "if ({has_identity} && identity =="
    ],
    [
        "\"funcs\": f\"{name}_functions\" if not uf.empty else \"NULL\",",
        "\"funcs\": f\"{name}_functions\" if not"
    ],
    [
        "\"data\": f\"{name}_data\" if not uf.empty else \"NULL\",",
        "\"data\": f\"{name}_data\" if not uf.empty else"
    ],
    [
        "\"signatures\": f\"{name}_signatures\" if not uf.empty else \"NULL\",",
        "\"signatures\": f\"{name}_signatures\" if not uf.empty else"
    ],
    [
        "r\"((PyUFuncObject *)f)->type_resolver = &%s;\" % uf.typereso)",
        "r\"((PyUFuncObject *)f)->type_resolver ="
    ],
    [
        "\"cannot add indexed loop to ufunc \"",
        "\"cannot add indexed loop to ufunc"
    ],
    [
        "\"Not a PyArrayMethodObject in ufunc \"",
        "\"Not a PyArrayMethodObject in ufunc"
    ],
    [
        "/* info is borrowed, no need to decref*/",
        "/* info is borrowed, no need"
    ],
    [
        "/** Warning this file is autogenerated!!!",
        "/** Warning this file"
    ],
    [
        "Please make changes to the code generator program (%s)",
        "Please make changes to the code generator program"
    ],
    [
        "The syntax is designed to look like the function add_newdoc is being",
        "The syntax is designed to look like"
    ],
    [
        "called from numpy.lib, but in this file  add_newdoc puts the docstrings",
        "called from numpy.lib, but in this file add_newdoc puts the"
    ],
    [
        "in a dictionary. This dictionary is used in",
        "in a dictionary. This dictionary is used"
    ],
    [
        "ufuncs are created at compile time.",
        "ufuncs are created at compile"
    ],
    [
        "out : ndarray, None, or tuple of ndarray and None, optional",
        "out : ndarray, None, or tuple of ndarray and"
    ],
    [
        "A location into which the result is stored. If provided, it must have",
        "A location into which the result is stored."
    ],
    [
        "a shape that the inputs broadcast to. If not provided or None,",
        "a shape that the inputs broadcast to. If"
    ],
    [
        "a freshly-allocated array is returned. A tuple (possible only as a",
        "a freshly-allocated array is returned. A tuple"
    ],
    [
        "keyword argument) must have length equal to the number of outputs.",
        "keyword argument) must have length equal to the number of"
    ],
    [
        "This condition is broadcast over the input. At locations where the",
        "This condition is broadcast over the input. At locations"
    ],
    [
        "condition is True, the `out` array will be set to the ufunc result.",
        "condition is True, the `out` array will be set to the ufunc"
    ],
    [
        "Elsewhere, the `out` array will retain its original value.",
        "Elsewhere, the `out` array will retain its"
    ],
    [
        "Note that if an uninitialized `out` array is created via the default",
        "Note that if an uninitialized `out` array"
    ],
    [
        "``out=None``, locations within it where the condition is False will",
        "``out=None``, locations within it where"
    ],
    [
        "For other keyword-only arguments, see the",
        "For other keyword-only arguments, see"
    ],
    [
        "\"broadcastable to a common\\n    shape (which becomes \"",
        "\"broadcastable to a common\\n shape (which becomes"
    ],
    [
        "assert False, \"Could not detect number of inputs in {}\".format(name)",
        "assert False, \"Could not detect number of inputs in"
    ],
    [
        "doc = doc.replace('$' + k, v)",
        "doc = doc.replace('$' + k,"
    ],
    [
        "``np.abs`` is a shorthand for this function.",
        "``np.abs`` is a shorthand for"
    ],
    [
        "An ndarray containing the absolute value of",
        "An ndarray containing the absolute value"
    ],
    [
        "each element in `x`.  For complex input, ``a + ib``, the",
        "each element in `x`. For complex input, ``a"
    ],
    [
        "Plot the function over the complex plane:",
        "Plot the function over the"
    ],
    [
        "The `abs` function can be used as a shorthand for ``np.absolute`` on",
        "The `abs` function can be used as a shorthand"
    ],
    [
        "The ``+`` operator can be used as a shorthand for ``np.add`` on ndarrays.",
        "The ``+`` operator can be used as a shorthand for"
    ],
    [
        "The inverse of `cos` so that, if ``y = cos(x)``, then ``x = arccos(y)``.",
        "The inverse of `cos` so that, if ``y = cos(x)``, then ``x"
    ],
    [
        "The angle of the ray intersecting the unit circle at the given",
        "The angle of the ray intersecting the unit circle at the"
    ],
    [
        "`arccos` is a multivalued function: for each `x` there are infinitely",
        "`arccos` is a multivalued function: for"
    ],
    [
        "many numbers `z` such that ``cos(z) = x``. The convention is to return",
        "many numbers `z` such that ``cos(z) = x``. The convention is to"
    ],
    [
        "For real-valued input data types, `arccos` always returns real output.",
        "For real-valued input data types, `arccos` always"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity,",
        "For each value that cannot be expressed as a real number"
    ],
    [
        "it yields ``nan`` and sets the `invalid` floating point error flag.",
        "it yields ``nan`` and sets the `invalid` floating point"
    ],
    [
        "For complex-valued input, `arccos` is a complex analytic function that",
        "For complex-valued input, `arccos` is a complex analytic function"
    ],
    [
        "above on the former and from below on the latter.",
        "above on the former and from below"
    ],
    [
        "M. Abramowitz and I.A. Stegun, \"Handbook of Mathematical Functions\",",
        "M. Abramowitz and I.A. Stegun,"
    ],
    [
        "Array of the same shape as `x`.",
        "Array of the same shape as"
    ],
    [
        "`arccosh` is a multivalued function: for each `x` there are infinitely",
        "`arccosh` is a multivalued function: for each `x` there"
    ],
    [
        "many numbers `z` such that `cosh(z) = x`. The convention is to return the",
        "many numbers `z` such that `cosh(z) = x`. The convention is to return"
    ],
    [
        "`z` whose imaginary part lies in ``[-pi, pi]`` and the real part in",
        "`z` whose imaginary part lies in ``[-pi, pi]`` and the real part"
    ],
    [
        "For real-valued input data types, `arccosh` always returns real output.",
        "For real-valued input data types, `arccosh` always returns"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity, it",
        "For each value that cannot be expressed"
    ],
    [
        "yields ``nan`` and sets the `invalid` floating point error flag.",
        "yields ``nan`` and sets the `invalid` floating"
    ],
    [
        "For complex-valued input, `arccosh` is a complex analytical function that",
        "For complex-valued input, `arccosh` is a"
    ],
    [
        "The inverse sine of each element in `x`, in radians and in the",
        "The inverse sine of each element in `x`,"
    ],
    [
        "`arcsin` is a multivalued function: for each `x` there are infinitely",
        "`arcsin` is a multivalued function: for"
    ],
    [
        "many numbers `z` such that :math:`sin(z) = x`.  The convention is to",
        "many numbers `z` such that :math:`sin(z) = x`. The convention"
    ],
    [
        "For real-valued input data types, *arcsin* always returns real output.",
        "For real-valued input data types,"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity,",
        "For each value that cannot be expressed as a"
    ],
    [
        "it yields ``nan`` and sets the `invalid` floating point error flag.",
        "it yields ``nan`` and sets the `invalid` floating point"
    ],
    [
        "For complex-valued input, `arcsin` is a complex analytic function that",
        "For complex-valued input, `arcsin` is a complex"
    ],
    [
        "continuous from above on the former and from below on the latter.",
        "continuous from above on the former and from"
    ],
    [
        "Abramowitz, M. and Stegun, I. A., *Handbook of Mathematical Functions*,",
        "Abramowitz, M. and Stegun, I. A.,"
    ],
    [
        "Array of the same shape as `x`.",
        "Array of the same shape"
    ],
    [
        "`arcsinh` is a multivalued function: for each `x` there are infinitely",
        "`arcsinh` is a multivalued function: for each `x`"
    ],
    [
        "many numbers `z` such that `sinh(z) = x`. The convention is to return the",
        "many numbers `z` such that `sinh(z) = x`. The convention is"
    ],
    [
        "For real-valued input data types, `arcsinh` always returns real output.",
        "For real-valued input data types, `arcsinh` always returns real"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity, it",
        "For each value that cannot be expressed as a real"
    ],
    [
        "returns ``nan`` and sets the `invalid` floating point error flag.",
        "returns ``nan`` and sets the `invalid` floating point error"
    ],
    [
        "For complex-valued input, `arcsinh` is a complex analytical function that",
        "For complex-valued input, `arcsinh` is a complex analytical"
    ],
    [
        "the right on the former and from the left on the latter.",
        "the right on the former and from the"
    ],
    [
        "The inverse of tan, so that if ``y = tan(x)`` then ``x = arctan(y)``.",
        "The inverse of tan, so that if ``y ="
    ],
    [
        "Out has the same shape as `x`.  Its real part is in",
        "Out has the same shape as `x`. Its real part"
    ],
    [
        "angle : Argument of complex values.",
        "angle : Argument of"
    ],
    [
        "`arctan` is a multi-valued function: for each `x` there are infinitely",
        "`arctan` is a multi-valued function: for each `x`"
    ],
    [
        "many numbers `z` such that tan(`z`) = `x`.  The convention is to return",
        "many numbers `z` such that tan(`z`) = `x`. The"
    ],
    [
        "For real-valued input data types, `arctan` always returns real output.",
        "For real-valued input data types, `arctan` always"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity,",
        "For each value that cannot be expressed as a real number or"
    ],
    [
        "it yields ``nan`` and sets the `invalid` floating point error flag.",
        "it yields ``nan`` and sets the"
    ],
    [
        "For complex-valued input, `arctan` is a complex analytic function that",
        "For complex-valued input, `arctan` is a complex analytic"
    ],
    [
        "from the left on the former and from the right on the latter.",
        "from the left on the former and from the"
    ],
    [
        "Abramowitz, M. and Stegun, I. A., *Handbook of Mathematical Functions*,",
        "Abramowitz, M. and Stegun, I. A., *Handbook of Mathematical"
    ],
    [
        "the signed angle in radians between the ray ending at the origin and",
        "the signed angle in radians between the ray ending at"
    ],
    [
        "\"`y`-coordinate\" is the first function parameter, the \"`x`-coordinate\"",
        "\"`y`-coordinate\" is the first"
    ],
    [
        "is the second.)  By IEEE convention, this function is defined for",
        "is the second.) By IEEE convention, this function is"
    ],
    [
        "This function is not defined for complex-valued arguments; for the",
        "This function is not defined for"
    ],
    [
        "so-called argument of complex values, use `angle`.",
        "so-called argument of complex values, use"
    ],
    [
        "Array of angles in radians, in the range ``[-pi, pi]``.",
        "Array of angles in radians, in the range"
    ],
    [
        "C library.  The following special values are defined in the C",
        "C library. The following special values are defined in"
    ],
    [
        "Consider four points in different quadrants:",
        "Consider four points in"
    ],
    [
        "and at several other special points, obtaining values in",
        "and at several other special points, obtaining"
    ],
    [
        "DO NOT USE, ONLY FOR TESTING",
        "DO NOT USE, ONLY"
    ],
    [
        "Array of the same shape as `x`.",
        "Array of the same shape"
    ],
    [
        "`arctanh` is a multivalued function: for each `x` there are infinitely",
        "`arctanh` is a multivalued function: for"
    ],
    [
        "many numbers `z` such that ``tanh(z) = x``. The convention is to return",
        "many numbers `z` such that ``tanh(z) = x``. The"
    ],
    [
        "For real-valued input data types, `arctanh` always returns real output.",
        "For real-valued input data types, `arctanh` always returns"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity,",
        "For each value that cannot be expressed as a real number"
    ],
    [
        "it yields ``nan`` and sets the `invalid` floating point error flag.",
        "it yields ``nan`` and sets the `invalid` floating point"
    ],
    [
        "For complex-valued input, `arctanh` is a complex analytical function",
        "For complex-valued input, `arctanh` is"
    ],
    [
        "above on the former and from below on the latter.",
        "above on the former and from below on the"
    ],
    [
        "Compute the bit-wise AND of two arrays element-wise.",
        "Compute the bit-wise AND"
    ],
    [
        "Computes the bit-wise AND of the underlying binary representation of",
        "Computes the bit-wise AND of"
    ],
    [
        "the integers in the input arrays. This ufunc implements the C/Python",
        "the integers in the input arrays. This ufunc implements the"
    ],
    [
        "Only integer and boolean types are handled.",
        "Only integer and boolean types are"
    ],
    [
        "Return the binary representation of the input number as a string.",
        "Return the binary representation of the input number as"
    ],
    [
        "The ``&`` operator can be used as a shorthand for ``np.bitwise_and`` on",
        "The ``&`` operator can be used as"
    ],
    [
        "Compute the bit-wise OR of two arrays element-wise.",
        "Compute the bit-wise OR of two"
    ],
    [
        "Computes the bit-wise OR of the underlying binary representation of",
        "Computes the bit-wise OR of the underlying binary representation"
    ],
    [
        "the integers in the input arrays. This ufunc implements the C/Python",
        "the integers in the input arrays. This"
    ],
    [
        "Only integer and boolean types are handled.",
        "Only integer and boolean"
    ],
    [
        "Return the binary representation of the input number as a string.",
        "Return the binary representation of the input number"
    ],
    [
        "The ``|`` operator can be used as a shorthand for ``np.bitwise_or`` on",
        "The ``|`` operator can be used as a shorthand for ``np.bitwise_or``"
    ],
    [
        "Compute the bit-wise XOR of two arrays element-wise.",
        "Compute the bit-wise XOR"
    ],
    [
        "Computes the bit-wise XOR of the underlying binary representation of",
        "Computes the bit-wise XOR of the underlying binary"
    ],
    [
        "the integers in the input arrays. This ufunc implements the C/Python",
        "the integers in the input arrays. This ufunc"
    ],
    [
        "Only integer and boolean types are handled.",
        "Only integer and boolean types are"
    ],
    [
        "Return the binary representation of the input number as a string.",
        "Return the binary representation of the input number as"
    ],
    [
        "The ``^`` operator can be used as a shorthand for ``np.bitwise_xor`` on",
        "The ``^`` operator can be used as"
    ],
    [
        "Return the ceiling of the input, element-wise.",
        "Return the ceiling of"
    ],
    [
        "The ceil of the scalar `x` is the smallest integer `i`, such that",
        "The ceil of the scalar `x` is the smallest integer"
    ],
    [
        "``i >= x``.  It is often denoted as :math:`\\\\lceil x \\\\rceil`.",
        "``i >= x``. It is often denoted as"
    ],
    [
        "The ceiling of each element in `x`.",
        "The ceiling of each element in"
    ],
    [
        "Return the truncated value of the input, element-wise.",
        "Return the truncated value of the"
    ],
    [
        "The truncated value of the scalar `x` is the nearest integer `i` which",
        "The truncated value of the scalar `x` is the"
    ],
    [
        "is closer to zero than `x` is. In short, the fractional part of the",
        "is closer to zero than `x` is. In"
    ],
    [
        "The truncated value of each element in `x`.",
        "The truncated value of each element"
    ],
    [
        "The complex conjugate of a complex number is obtained by changing the",
        "The complex conjugate of a complex number is"
    ],
    [
        "The complex conjugate of `x`, with same dtype as `y`.",
        "The complex conjugate of `x`, with"
    ],
    [
        "`conj` is an alias for `conjugate`:",
        "`conj` is an"
    ],
    [
        "If `out` is provided, the function writes the result into it,",
        "If `out` is provided, the function writes the result"
    ],
    [
        "and returns a reference to `out`.  (See Examples)",
        "and returns a reference to `out`. (See"
    ],
    [
        "M. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions.",
        "M. Abramowitz and I. A. Stegun,"
    ],
    [
        "Output array of same shape as `x`.",
        "Output array of same"
    ],
    [
        "The hyperbolic cosine describes the shape of a hanging cable:",
        "The hyperbolic cosine describes the shape of"
    ],
    [
        "Convert angles from radians to degrees.",
        "Convert angles from"
    ],
    [
        "The corresponding degree values; if `out` was supplied this is a",
        "The corresponding degree values; if `out` was"
    ],
    [
        "Convert a radian array to degrees",
        "Convert a radian"
    ],
    [
        "Convert angles from radians to degrees.",
        "Convert angles from"
    ],
    [
        "unwrap : Remove large jumps in angle by wrapping.",
        "unwrap : Remove large jumps"
    ],
    [
        "seterr : Set whether to raise or warn on overflow, underflow and",
        "seterr : Set whether to raise or warn on"
    ],
    [
        "The ``/`` operator can be used as a shorthand for ``np.divide`` on",
        "The ``/`` operator can be used as a shorthand for"
    ],
    [
        "Typically of type bool, unless ``dtype=object`` is passed.",
        "Typically of type bool, unless ``dtype=object``"
    ],
    [
        "length one can evaluate as True:",
        "length one can evaluate as"
    ],
    [
        "The ``==`` operator can be used as a shorthand for ``np.equal`` on",
        "The ``==`` operator can be used as"
    ],
    [
        "Calculate the exponential of all elements in the input array.",
        "Calculate the exponential of all elements in"
    ],
    [
        "Output array, element-wise exponential of `x`.",
        "Output array, element-wise exponential"
    ],
    [
        "The irrational number ``e`` is also known as Euler's number.  It is",
        "The irrational number ``e`` is also"
    ],
    [
        "``ln`` (this means that, if :math:`x = \\\\ln y = \\\\log_e y`,",
        "``ln`` (this means that, if :math:`x ="
    ],
    [
        "then :math:`e^x = y`. For real input, ``exp(x)`` is always positive.",
        "then :math:`e^x = y`. For real input,"
    ],
    [
        "For complex arguments, ``x = a + ib``, we can write",
        "For complex arguments, ``x = a + ib``, we"
    ],
    [
        ":math:`e^x = e^a e^{ib}`.  The first term, :math:`e^a`, is already",
        ":math:`e^x = e^a e^{ib}`. The first term, :math:`e^a`,"
    ],
    [
        "known (it is the real argument, described above).  The second term,",
        "known (it is the real argument, described above)."
    ],
    [
        ":math:`e^{ib}`, is :math:`\\\\cos b + i \\\\sin b`, a function with",
        ":math:`e^{ib}`, is :math:`\\\\cos b + i \\\\sin b`, a"
    ],
    [
        "Plot the magnitude and phase of ``exp(x)`` in the complex plane:",
        "Plot the magnitude and phase of ``exp(x)``"
    ],
    [
        "This function returns the absolute values (positive magnitude) of the",
        "This function returns the absolute values (positive"
    ],
    [
        "data in `x`. Complex values are not handled, use `absolute` to find the",
        "data in `x`. Complex values are not handled, use"
    ],
    [
        "The array of numbers for which the absolute values are required. If",
        "The array of numbers for which the absolute"
    ],
    [
        "`x` is a scalar, the result `y` will also be a scalar.",
        "`x` is a scalar, the result `y` will also"
    ],
    [
        "The absolute values of `x`, the returned values are always floats.",
        "The absolute values of `x`, the returned"
    ],
    [
        "absolute : Absolute values including `complex` types.",
        "absolute : Absolute values including `complex`"
    ],
    [
        "Return the floor of the input, element-wise.",
        "Return the floor of the"
    ],
    [
        "The floor of the scalar `x` is the largest integer `i`, such that",
        "The floor of the scalar `x` is the largest integer `i`, such"
    ],
    [
        "`i <= x`.  It is often denoted as :math:`\\\\lfloor x \\\\rfloor`.",
        "`i <= x`. It is often denoted"
    ],
    [
        "The floor of each element in `x`.",
        "The floor of each"
    ],
    [
        "Some spreadsheet programs calculate the \"floor-towards-zero\", where",
        "Some spreadsheet programs calculate"
    ],
    [
        "function is called ``fix`` in NumPy.",
        "function is called ``fix`` in"
    ],
    [
        "Return the largest integer smaller or equal to the division of the inputs.",
        "Return the largest integer smaller or equal"
    ],
    [
        "It is equivalent to the Python ``//`` operator and pairs with the",
        "It is equivalent to the Python"
    ],
    [
        "Python ``%`` (`remainder`), function so that ``a = a % b + b * (a // b)``",
        "Python ``%`` (`remainder`), function so that ``a = a %"
    ],
    [
        "remainder : Remainder complementary to floor_divide.",
        "remainder : Remainder complementary"
    ],
    [
        "divmod : Simultaneous floor division and remainder.",
        "divmod : Simultaneous floor"
    ],
    [
        "floor : Round a number to the nearest integer toward minus infinity.",
        "floor : Round a number to the nearest integer toward minus"
    ],
    [
        "ceil : Round a number to the nearest integer toward infinity.",
        "ceil : Round a number to the nearest"
    ],
    [
        "The ``//`` operator can be used as a shorthand for ``np.floor_divide``",
        "The ``//`` operator can be used as a"
    ],
    [
        "Returns the element-wise remainder of division.",
        "Returns the element-wise remainder"
    ],
    [
        "This is the NumPy implementation of the C library function fmod, the",
        "This is the NumPy implementation of"
    ],
    [
        "the Matlab(TM) ``rem`` function and should not be confused with the",
        "the Matlab(TM) ``rem`` function and should not be confused"
    ],
    [
        "remainder : Equivalent to the Python ``%`` operator.",
        "remainder : Equivalent to the Python"
    ],
    [
        "The result of the modulo operation for negative dividend and divisors",
        "The result of the modulo operation for negative dividend and"
    ],
    [
        "is bound by conventions. For `fmod`, the sign of result is the sign of",
        "is bound by conventions. For `fmod`, the"
    ],
    [
        "the dividend, while for `remainder` the sign of the result is the sign",
        "the dividend, while for `remainder` the sign"
    ],
    [
        "of the divisor. The `fmod` function is equivalent to the Matlab(TM)",
        "of the divisor. The `fmod` function is equivalent to"
    ],
    [
        "Typically of type bool, unless ``dtype=object`` is passed.",
        "Typically of type bool,"
    ],
    [
        "The ``>`` operator can be used as a shorthand for ``np.greater`` on",
        "The ``>`` operator can be used as a"
    ],
    [
        "out : bool or ndarray of bool",
        "out : bool or ndarray"
    ],
    [
        "Typically of type bool, unless ``dtype=object`` is passed.",
        "Typically of type bool, unless"
    ],
    [
        "The ``>=`` operator can be used as a shorthand for ``np.greater_equal``",
        "The ``>=`` operator can be used as a shorthand for"
    ],
    [
        "Given the \"legs\" of a right triangle, return its hypotenuse.",
        "Given the \"legs\" of a right triangle, return its"
    ],
    [
        "it is broadcast for use with each element of the other argument.",
        "it is broadcast for use with each element of the"
    ],
    [
        "Example showing broadcast of scalar_like argument:",
        "Example showing broadcast of"
    ],
    [
        "Compute bit-wise inversion, or bit-wise NOT, element-wise.",
        "Compute bit-wise inversion, or"
    ],
    [
        "Computes the bit-wise NOT of the underlying binary representation of",
        "Computes the bit-wise NOT of the underlying binary representation"
    ],
    [
        "the integers in the input arrays. This ufunc implements the C/Python",
        "the integers in the input arrays. This ufunc implements the"
    ],
    [
        "For signed integer inputs, the bit-wise NOT of the absolute value is",
        "For signed integer inputs, the bit-wise NOT of"
    ],
    [
        "returned. In a two's-complement system, this operation effectively flips",
        "returned. In a two's-complement system, this operation"
    ],
    [
        "all the bits, resulting in a representation that corresponds to the",
        "all the bits, resulting in a representation that corresponds to"
    ],
    [
        "negative of the input plus one. This is the most common method of",
        "negative of the input plus one. This is the"
    ],
    [
        "Only integer and boolean types are handled.",
        "Only integer and boolean"
    ],
    [
        "Return the binary representation of the input number as a string.",
        "Return the binary representation of the input number"
    ],
    [
        "``numpy.bitwise_not`` is an alias for `invert`:",
        "``numpy.bitwise_not`` is an alias for"
    ],
    [
        "The result depends on the bit-width:",
        "The result depends"
    ],
    [
        "When using signed integer types, the result is the bit-wise NOT of",
        "When using signed integer types, the result is the"
    ],
    [
        "the unsigned type, interpreted as a signed integer:",
        "the unsigned type, interpreted as a signed"
    ],
    [
        "The ``~`` operator can be used as a shorthand for ``np.invert`` on",
        "The ``~`` operator can be used as"
    ],
    [
        "Test element-wise for finiteness (not infinity and not Not a Number).",
        "Test element-wise for finiteness (not infinity and not Not a"
    ],
    [
        "The result is returned as a boolean array.",
        "The result is returned as a"
    ],
    [
        "True where ``x`` is not positive infinity, negative infinity,",
        "True where ``x`` is not positive infinity, negative"
    ],
    [
        "Not a Number, positive infinity and negative infinity are considered",
        "Not a Number, positive infinity"
    ],
    [
        "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic",
        "NumPy uses the IEEE Standard for Binary Floating-Point for"
    ],
    [
        "Also that positive infinity is not equivalent to negative infinity. But",
        "Also that positive infinity is not equivalent to negative infinity."
    ],
    [
        "infinity is equivalent to positive infinity.  Errors result if the",
        "infinity is equivalent to positive infinity. Errors result"
    ],
    [
        "second argument is also supplied when `x` is a scalar input, or if",
        "second argument is also supplied when `x` is a scalar input, or"
    ],
    [
        "first and second arguments have different shapes.",
        "first and second arguments have different"
    ],
    [
        "Test element-wise for positive or negative infinity.",
        "Test element-wise for positive or"
    ],
    [
        "Returns a boolean array of the same shape as `x`, True where ``x ==",
        "Returns a boolean array of the same"
    ],
    [
        "y : bool (scalar) or boolean ndarray",
        "y : bool (scalar)"
    ],
    [
        "True where ``x`` is positive or negative infinity, false otherwise.",
        "True where ``x`` is positive"
    ],
    [
        "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic",
        "NumPy uses the IEEE Standard"
    ],
    [
        "Errors result if the second argument is supplied when the first",
        "Errors result if the second argument"
    ],
    [
        "argument is a scalar, or if the first and second arguments have",
        "argument is a scalar, or if the first and"
    ],
    [
        "Test element-wise for NaN and return result as a boolean array.",
        "Test element-wise for NaN and return"
    ],
    [
        "True where ``x`` is NaN, false otherwise.",
        "True where ``x`` is NaN, false"
    ],
    [
        "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic",
        "NumPy uses the IEEE Standard for"
    ],
    [
        "Test element-wise for NaT (not a time) and return result as a boolean array.",
        "Test element-wise for NaT (not a time) and return result as"
    ],
    [
        "Input array with datetime or timedelta data type.",
        "Input array with datetime or"
    ],
    [
        "True where ``x`` is NaT, false otherwise.",
        "True where ``x`` is NaT, false"
    ],
    [
        "Shift the bits of an integer to the left.",
        "Shift the bits of an integer to the"
    ],
    [
        "Since the internal representation of numbers is in binary format, this",
        "Since the internal representation of numbers"
    ],
    [
        "out : array of integer type",
        "out : array of"
    ],
    [
        "right_shift : Shift the bits of an integer to the right.",
        "right_shift : Shift the bits of an integer to the"
    ],
    [
        "binary_repr : Return the binary representation of the input number",
        "binary_repr : Return the binary representation of the input"
    ],
    [
        "Note that the dtype of the second argument may change the dtype of the",
        "Note that the dtype of the second argument may"
    ],
    [
        "result and can lead to unexpected results in some cases (see",
        "result and can lead to unexpected results in some cases"
    ],
    [
        "The ``<<`` operator can be used as a shorthand for ``np.left_shift`` on",
        "The ``<<`` operator can be used"
    ],
    [
        "Typically of type bool, unless ``dtype=object`` is passed.",
        "Typically of type bool, unless"
    ],
    [
        "The ``<`` operator can be used as a shorthand for ``np.less`` on ndarrays.",
        "The ``<`` operator can be used as a shorthand for ``np.less`` on"
    ],
    [
        "Typically of type bool, unless ``dtype=object`` is passed.",
        "Typically of type bool, unless"
    ],
    [
        "The ``<=`` operator can be used as a shorthand for ``np.less_equal`` on",
        "The ``<=`` operator can be used"
    ],
    [
        "The natural logarithm `log` is the inverse of the exponential function,",
        "The natural logarithm `log` is the"
    ],
    [
        "so that `log(exp(x)) = x`. The natural logarithm is logarithm in base",
        "so that `log(exp(x)) = x`. The natural"
    ],
    [
        "The natural logarithm of `x`, element-wise.",
        "The natural logarithm of"
    ],
    [
        "Logarithm is a multivalued function: for each `x` there is an infinite",
        "Logarithm is a multivalued function: for each `x`"
    ],
    [
        "number of `z` such that `exp(z) = x`. The convention is to return the",
        "number of `z` such that `exp(z) = x`. The convention is to"
    ],
    [
        "`z` whose imaginary part lies in `(-pi, pi]`.",
        "`z` whose imaginary part lies in"
    ],
    [
        "For real-valued input data types, `log` always returns real output. For",
        "For real-valued input data types, `log` always returns real"
    ],
    [
        "each value that cannot be expressed as a real number or infinity, it",
        "each value that cannot be expressed as a real number"
    ],
    [
        "yields ``nan`` and sets the `invalid` floating point error flag.",
        "yields ``nan`` and sets the `invalid`"
    ],
    [
        "For complex-valued input, `log` is a complex analytical function that",
        "For complex-valued input, `log` is"
    ],
    [
        "handles the floating-point negative zero as an infinitesimal negative",
        "handles the floating-point negative zero as an infinitesimal"
    ],
    [
        "In the cases where the input has a negative real part and a very small",
        "In the cases where the input has a negative real part and"
    ],
    [
        "that it evaluates to exactly `-pi`.",
        "that it evaluates to"
    ],
    [
        "Logarithm is a multivalued function: for each `x` there is an infinite",
        "Logarithm is a multivalued function: for each `x` there is"
    ],
    [
        "`z` whose imaginary part lies in `(-pi, pi]`.",
        "`z` whose imaginary part lies"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity,",
        "For each value that cannot be expressed as a real number or"
    ],
    [
        "it yields ``nan`` and sets the `invalid` floating point error flag.",
        "it yields ``nan`` and sets the `invalid` floating point"
    ],
    [
        "In the cases where the input has a negative real part and a very small",
        "In the cases where the input has a negative real part"
    ],
    [
        "that it evaluates to exactly `-pi`.",
        "that it evaluates"
    ],
    [
        "Logarithm is a multivalued function: for each `x` there is an infinite",
        "Logarithm is a multivalued function: for each `x` there is"
    ],
    [
        "whose imaginary part lies in `(-pi, pi]`.",
        "whose imaginary part lies in"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity,",
        "For each value that cannot be expressed as a real number"
    ],
    [
        "it yields ``nan`` and sets the `invalid` floating point error flag.",
        "it yields ``nan`` and sets the"
    ],
    [
        "handles the floating-point negative zero as an infinitesimal negative",
        "handles the floating-point negative zero as an infinitesimal"
    ],
    [
        "In the cases where the input has a negative real part and a very small",
        "In the cases where the input has a negative real part and a"
    ],
    [
        "that it evaluates to exactly `-pi`.",
        "that it evaluates to exactly"
    ],
    [
        "Logarithm of the sum of exponentiations of the inputs.",
        "Logarithm of the sum of exponentiations"
    ],
    [
        "statistics where the calculated probabilities of events may be so small",
        "statistics where the calculated probabilities of"
    ],
    [
        "as to exceed the range of normal floating point numbers.  In such cases",
        "as to exceed the range of normal floating point"
    ],
    [
        "the logarithm of the calculated probability is stored. This function",
        "the logarithm of the calculated probability is"
    ],
    [
        "allows adding probabilities stored in such a fashion.",
        "allows adding probabilities stored in"
    ],
    [
        "learning when the calculated probabilities of events may be so small as",
        "learning when the calculated probabilities of"
    ],
    [
        "to exceed the range of normal floating point numbers.  In such cases",
        "to exceed the range of normal floating point numbers."
    ],
    [
        "This function allows adding probabilities stored in such a fashion.",
        "This function allows adding probabilities stored in such a"
    ],
    [
        "logaddexp: Logarithm of the sum of exponentiations of the inputs.",
        "logaddexp: Logarithm of the sum"
    ],
    [
        "Return the natural logarithm of one plus the input array, element-wise.",
        "Return the natural logarithm of one plus the input array,"
    ],
    [
        "Logarithm is a multivalued function: for each `x` there is an infinite",
        "Logarithm is a multivalued function: for each `x` there is an"
    ],
    [
        "the `z` whose imaginary part lies in `[-pi, pi]`.",
        "the `z` whose imaginary part lies"
    ],
    [
        "For each value that cannot be expressed as a real number or infinity,",
        "For each value that cannot be expressed as"
    ],
    [
        "it yields ``nan`` and sets the `invalid` floating point error flag.",
        "it yields ``nan`` and sets the `invalid` floating"
    ],
    [
        "Boolean result of the logical AND operation applied to the elements",
        "Boolean result of the logical AND operation applied"
    ],
    [
        "The ``&`` operator can be used as a shorthand for ``np.logical_and`` on",
        "The ``&`` operator can be used as a"
    ],
    [
        "Compute the truth value of NOT x element-wise.",
        "Compute the truth value of"
    ],
    [
        "Logical NOT is applied to the elements of `x`.",
        "Logical NOT is applied to the elements of"
    ],
    [
        "y : bool or ndarray of bool",
        "y : bool or ndarray of"
    ],
    [
        "Boolean result with the same shape as `x` of the NOT operation",
        "Boolean result with the same shape as"
    ],
    [
        "Boolean result of the logical OR operation applied to the elements",
        "Boolean result of the logical OR operation applied to the"
    ],
    [
        "array([ True, False, False, False,  True])",
        "array([ True, False, False, False,"
    ],
    [
        "The ``|`` operator can be used as a shorthand for ``np.logical_or`` on",
        "The ``|`` operator can be used"
    ],
    [
        "y : bool or ndarray of bool",
        "y : bool or ndarray of"
    ],
    [
        "Boolean result of the logical XOR operation applied to the elements",
        "Boolean result of the logical XOR operation applied to the"
    ],
    [
        ">>> np.logical_xor([True, True, False, False], [True, False, True, False])",
        ">>> np.logical_xor([True, True, False, False], [True, False,"
    ],
    [
        "array([ True, False, False, False,  True])",
        "array([ True, False, False,"
    ],
    [
        "Simple example showing support of broadcasting",
        "Simple example showing support of"
    ],
    [
        "Compare two arrays and return a new array containing the element-wise",
        "Compare two arrays and return a"
    ],
    [
        "maxima. If one of the elements being compared is a NaN, then that",
        "maxima. If one of the elements being compared"
    ],
    [
        "element is returned. If both elements are NaNs then the first is",
        "element is returned. If both elements are NaNs then the first"
    ],
    [
        "returned. The latter distinction is important for complex NaNs, which",
        "returned. The latter distinction is"
    ],
    [
        "are defined as at least one of the real or imaginary parts being a NaN.",
        "are defined as at least one of the real or imaginary parts"
    ],
    [
        "The net effect is that NaNs are propagated.",
        "The net effect is that NaNs are"
    ],
    [
        "The arrays holding the elements to be compared.",
        "The arrays holding the elements to"
    ],
    [
        "Element-wise minimum of two arrays, propagates NaNs.",
        "Element-wise minimum of two arrays,"
    ],
    [
        "Element-wise maximum of two arrays, ignores NaNs.",
        "Element-wise maximum of two arrays, ignores"
    ],
    [
        "The maximum value of an array along a given axis, propagates NaNs.",
        "The maximum value of an array"
    ],
    [
        "The maximum value of an array along a given axis, ignores NaNs.",
        "The maximum value of an array along a given axis, ignores"
    ],
    [
        "Compare two arrays and return a new array containing the element-wise",
        "Compare two arrays and return a new array"
    ],
    [
        "minima. If one of the elements being compared is a NaN, then that",
        "minima. If one of the elements being compared is"
    ],
    [
        "element is returned. If both elements are NaNs then the first is",
        "element is returned. If both elements"
    ],
    [
        "returned. The latter distinction is important for complex NaNs, which",
        "returned. The latter distinction is important for"
    ],
    [
        "are defined as at least one of the real or imaginary parts being a NaN.",
        "are defined as at least one of the real or"
    ],
    [
        "The net effect is that NaNs are propagated.",
        "The net effect is that"
    ],
    [
        "The arrays holding the elements to be compared.",
        "The arrays holding the"
    ],
    [
        "Element-wise maximum of two arrays, propagates NaNs.",
        "Element-wise maximum of two arrays, propagates"
    ],
    [
        "Element-wise minimum of two arrays, ignores NaNs.",
        "Element-wise minimum of two arrays, ignores"
    ],
    [
        "The minimum value of an array along a given axis, propagates NaNs.",
        "The minimum value of an array along a given axis,"
    ],
    [
        "The minimum value of an array along a given axis, ignores NaNs.",
        "The minimum value of an array along a given"
    ],
    [
        "Compare two arrays and return a new array containing the element-wise",
        "Compare two arrays and return a new array containing the"
    ],
    [
        "maxima. If one of the elements being compared is a NaN, then the",
        "maxima. If one of the elements being compared is"
    ],
    [
        "non-nan element is returned. If both elements are NaNs then the first",
        "non-nan element is returned. If both"
    ],
    [
        "is returned.  The latter distinction is important for complex NaNs,",
        "is returned. The latter distinction is important for"
    ],
    [
        "which are defined as at least one of the real or imaginary parts being",
        "which are defined as at least one of the real or imaginary"
    ],
    [
        "a NaN. The net effect is that NaNs are ignored when possible.",
        "a NaN. The net effect is that NaNs are ignored"
    ],
    [
        "The arrays holding the elements to be compared.",
        "The arrays holding the elements to be"
    ],
    [
        "Element-wise minimum of two arrays, ignores NaNs.",
        "Element-wise minimum of two arrays, ignores"
    ],
    [
        "Element-wise maximum of two arrays, propagates NaNs.",
        "Element-wise maximum of two arrays, propagates"
    ],
    [
        "The maximum value of an array along a given axis, propagates NaNs.",
        "The maximum value of an array"
    ],
    [
        "The maximum value of an array along a given axis, ignores NaNs.",
        "The maximum value of an array along a"
    ],
    [
        "Compare two arrays and return a new array containing the element-wise",
        "Compare two arrays and return a new"
    ],
    [
        "minima. If one of the elements being compared is a NaN, then the",
        "minima. If one of the elements being compared is a NaN, then"
    ],
    [
        "non-nan element is returned. If both elements are NaNs then the first",
        "non-nan element is returned. If both"
    ],
    [
        "is returned.  The latter distinction is important for complex NaNs,",
        "is returned. The latter distinction is"
    ],
    [
        "which are defined as at least one of the real or imaginary parts being",
        "which are defined as at least one of the real or imaginary parts"
    ],
    [
        "a NaN. The net effect is that NaNs are ignored when possible.",
        "a NaN. The net effect is"
    ],
    [
        "The arrays holding the elements to be compared.",
        "The arrays holding the elements to be"
    ],
    [
        "Element-wise maximum of two arrays, ignores NaNs.",
        "Element-wise maximum of two"
    ],
    [
        "Element-wise minimum of two arrays, propagates NaNs.",
        "Element-wise minimum of two arrays, propagates"
    ],
    [
        "The minimum value of an array along a given axis, propagates NaNs.",
        "The minimum value of an array along a given axis, propagates"
    ],
    [
        "The minimum value of an array along a given axis, ignores NaNs.",
        "The minimum value of an array along a given"
    ],
    [
        "Clip (limit) the values in an array.",
        "Clip (limit) the values in an"
    ],
    [
        "Given an interval, values outside the interval are clipped to",
        "Given an interval, values outside the interval"
    ],
    [
        "Equivalent to but faster than ``np.minimum(np.maximum(a, a_min), a_max)``.",
        "Equivalent to but faster than ``np.minimum(np.maximum(a, a_min),"
    ],
    [
        "The results will be placed in this array. It may be the input",
        "The results will be placed in this array."
    ],
    [
        "array for in-place clipping.  `out` must be of the right shape",
        "array for in-place clipping. `out` must be of the right"
    ],
    [
        "to hold the output.  Its type is preserved.",
        "to hold the output."
    ],
    [
        "Wrapper that makes the ``a_min`` and ``a_max`` arguments optional,",
        "Wrapper that makes the ``a_min``"
    ],
    [
        "An array with the elements of `a`, but where values",
        "An array with the elements"
    ],
    [
        "< `a_min` are replaced with `a_min`, and those > `a_max`",
        "< `a_min` are replaced with `a_min`, and"
    ],
    [
        "A location into which the result is stored. If provided, it must have",
        "A location into which the result is"
    ],
    [
        "a shape that matches the signature `(n,k),(k,m)->(n,m)`. If not",
        "a shape that matches the signature `(n,k),(k,m)->(n,m)`. If"
    ],
    [
        "provided or None, a freshly-allocated array is returned.",
        "provided or None, a freshly-allocated array is"
    ],
    [
        "For other keyword-only arguments, see the",
        "For other keyword-only"
    ],
    [
        "The matrix product of the inputs.",
        "The matrix product of"
    ],
    [
        "If a scalar value is passed in.",
        "If a scalar value is passed"
    ],
    [
        "vecdot : Complex-conjugating dot product for stacks of vectors.",
        "vecdot : Complex-conjugating dot product"
    ],
    [
        "matvec : Matrix-vector product for stacks of matrices and vectors.",
        "matvec : Matrix-vector product for stacks of matrices"
    ],
    [
        "vecmat : Vector-matrix product for stacks of vectors and matrices.",
        "vecmat : Vector-matrix product for stacks of"
    ],
    [
        "tensordot : Sum products over arbitrary axes.",
        "tensordot : Sum products"
    ],
    [
        "dot : alternative matrix product with different broadcasting rules.",
        "dot : alternative matrix product with different"
    ],
    [
        "The behavior depends on the arguments in the following way.",
        "The behavior depends on the"
    ],
    [
        "matrices residing in the last two indexes and broadcast accordingly.",
        "matrices residing in the last"
    ],
    [
        "``matmul`` differs from ``dot`` in two important ways:",
        "``matmul`` differs from ``dot``"
    ],
    [
        "- Multiplication by scalars is not allowed, use ``*`` instead.",
        "- Multiplication by scalars is not allowed, use"
    ],
    [
        "- Stacks of matrices are broadcast together as if the matrices",
        "- Stacks of matrices are broadcast together as"
    ],
    [
        "were elements, respecting the signature ``(n,k),(k,m)->(n,m)``:",
        "were elements, respecting the"
    ],
    [
        "The matmul function implements the semantics of the ``@`` operator",
        "The matmul function implements the"
    ],
    [
        "It uses an optimized BLAS library when possible (see `numpy.linalg`).",
        "It uses an optimized BLAS"
    ],
    [
        "Broadcasting is conventional for stacks of arrays",
        "Broadcasting is conventional for"
    ],
    [
        "Vector, vector returns the scalar inner product, but neither argument",
        "Vector, vector returns the scalar inner"
    ],
    [
        "The ``@`` operator can be used as a shorthand for ``np.matmul`` on",
        "The ``@`` operator can be used as a"
    ],
    [
        "Vector dot product of two arrays.",
        "Vector dot product of two"
    ],
    [
        "where the sum is over the last dimension (unless `axis` is specified) and",
        "where the sum is over the last"
    ],
    [
        "where :math:`\\\\overline{a_i}` denotes the complex conjugate if :math:`a_i`",
        "where :math:`\\\\overline{a_i}` denotes the complex"
    ],
    [
        "is complex and the identity otherwise.",
        "is complex and the identity"
    ],
    [
        "A location into which the result is stored. If provided, it must have",
        "A location into which the result is"
    ],
    [
        "If not provided or None, a freshly-allocated array is used.",
        "If not provided or None,"
    ],
    [
        "For other keyword-only arguments, see the",
        "For other keyword-only arguments,"
    ],
    [
        "The vector dot product of the inputs.",
        "The vector dot product of"
    ],
    [
        "If a scalar value is passed in.",
        "If a scalar value is passed"
    ],
    [
        "vdot : same but flattens arguments first",
        "vdot : same but flattens arguments"
    ],
    [
        "Get the projected size along a given normal for an array of vectors.",
        "Get the projected size along a given normal for an"
    ],
    [
        "Matrix-vector dot product of two arrays.",
        "Matrix-vector dot product of two"
    ],
    [
        "(unless ``axes`` is specified).  (For a matrix-vector product with the",
        "(unless ``axes`` is specified). (For a matrix-vector product"
    ],
    [
        "A location into which the result is stored. If provided, it must have",
        "A location into which the result is stored. If provided, it must"
    ],
    [
        "removed. If not provided or None, a freshly-allocated array is used.",
        "removed. If not provided or None, a freshly-allocated"
    ],
    [
        "For other keyword-only arguments, see the",
        "For other keyword-only arguments,"
    ],
    [
        "The matrix-vector product of the inputs.",
        "The matrix-vector product of"
    ],
    [
        "If a scalar value is passed in.",
        "If a scalar value"
    ],
    [
        "Rotate a set of vectors from Y to X along Z.",
        "Rotate a set of vectors from Y"
    ],
    [
        "Vector-matrix dot product of two arrays.",
        "Vector-matrix dot product"
    ],
    [
        ":math:`\\\\overline{v_i}` denotes the complex conjugate if :math:`v`",
        ":math:`\\\\overline{v_i}` denotes the complex conjugate if"
    ],
    [
        "is complex and the identity otherwise. (For a non-conjugated vector-matrix",
        "is complex and the identity otherwise."
    ],
    [
        "A location into which the result is stored. If provided, it must have",
        "A location into which the result is stored."
    ],
    [
        "removed. If not provided or None, a freshly-allocated array is used.",
        "removed. If not provided or None, a freshly-allocated array"
    ],
    [
        "For other keyword-only arguments, see the",
        "For other keyword-only arguments, see"
    ],
    [
        "The vector-matrix product of the inputs.",
        "The vector-matrix product"
    ],
    [
        "If a scalar value is passed in.",
        "If a scalar value"
    ],
    [
        "Project a vector along X and Y.",
        "Project a vector along"
    ],
    [
        "Return the fractional and integral parts of an array, element-wise.",
        "Return the fractional and integral parts of"
    ],
    [
        "The fractional and integral parts are negative if the given number is",
        "The fractional and integral parts are"
    ],
    [
        "For integer input the return values are floats.",
        "For integer input the return values"
    ],
    [
        "switched, except it always has a positive remainder.",
        "switched, except it always has"
    ],
    [
        "The ``*`` operator can be used as a shorthand for ``np.multiply`` on",
        "The ``*`` operator can be used as a shorthand for ``np.multiply``"
    ],
    [
        "Returned array or scalar: `y = -x`.",
        "Returned array or scalar: `y ="
    ],
    [
        "The unary ``-`` operator can be used as a shorthand for ``np.negative`` on",
        "The unary ``-`` operator can be used as a"
    ],
    [
        "Returned array or scalar: `y = +x`.",
        "Returned array or scalar: `y ="
    ],
    [
        "Equivalent to `x.copy()`, but only defined for types that support",
        "Equivalent to `x.copy()`, but only defined"
    ],
    [
        "The unary ``+`` operator can be used as a shorthand for ``np.positive`` on",
        "The unary ``+`` operator can be used as a shorthand for ``np.positive``"
    ],
    [
        "Typically of type bool, unless ``dtype=object`` is passed.",
        "Typically of type bool,"
    ],
    [
        "The ``!=`` operator can be used as a shorthand for ``np.not_equal`` on",
        "The ``!=`` operator can be used"
    ],
    [
        "This function used to be the numpy.ones_like, but now a specific",
        "This function used to be the numpy.ones_like, but now"
    ],
    [
        "function for that has been written for consistency with the other",
        "function for that has been written for consistency with the"
    ],
    [
        "*_like functions. It is only used internally in a limited fashion now.",
        "*_like functions. It is only used internally in a"
    ],
    [
        "First array elements raised to powers from second array, element-wise.",
        "First array elements raised to"
    ],
    [
        "An integer type raised to a negative integer power will raise a",
        "An integer type raised to a negative integer power will raise"
    ],
    [
        "Negative values raised to a non-integral value will return ``nan``.",
        "Negative values raised to a non-integral"
    ],
    [
        "To get complex results, cast the input to complex, or specify the",
        "To get complex results, cast the input to complex, or"
    ],
    [
        "``dtype`` to be ``complex`` (see the example below).",
        "``dtype`` to be ``complex`` (see the example"
    ],
    [
        "float_power : power function that promotes integers to float",
        "float_power : power function that promotes"
    ],
    [
        "Cube each element in an array.",
        "Cube each element in an"
    ],
    [
        "Raise the bases to different exponents.",
        "Raise the bases to different"
    ],
    [
        "The ``**`` operator can be used as a shorthand for ``np.power`` on",
        "The ``**`` operator can be used as a shorthand"
    ],
    [
        "Negative values raised to a non-integral value will result in ``nan``",
        "Negative values raised to a non-integral"
    ],
    [
        "(and a warning will be generated).",
        "(and a warning"
    ],
    [
        "To get complex results, give the argument ``dtype=complex``.",
        "To get complex results,"
    ],
    [
        "First array elements raised to powers from second array, element-wise.",
        "First array elements raised to powers from second"
    ],
    [
        "inexact.  The intent is that the function will return a usable result for",
        "inexact. The intent is that the function will return"
    ],
    [
        "negative powers and seldom overflow for positive powers.",
        "negative powers and seldom overflow"
    ],
    [
        "Negative values raised to a non-integral value will return ``nan``.",
        "Negative values raised to a non-integral"
    ],
    [
        "To get complex results, cast the input to complex, or specify the",
        "To get complex results, cast the input to complex, or specify"
    ],
    [
        "``dtype`` to be ``complex`` (see the example below).",
        "``dtype`` to be ``complex``"
    ],
    [
        "power : power function that preserves type",
        "power : power function that preserves"
    ],
    [
        "Cube each element in a list.",
        "Cube each element in a"
    ],
    [
        "Raise the bases to different exponents.",
        "Raise the bases to"
    ],
    [
        "Negative values raised to a non-integral value will result in ``nan``",
        "Negative values raised to a non-integral value"
    ],
    [
        "(and a warning will be generated).",
        "(and a warning"
    ],
    [
        "To get complex results, give the argument ``dtype=complex``.",
        "To get complex results, give the argument"
    ],
    [
        "Convert angles from degrees to radians.",
        "Convert angles from degrees to"
    ],
    [
        "Convert a degree array to radians",
        "Convert a degree"
    ],
    [
        "Convert angles from degrees to radians.",
        "Convert angles from degrees to"
    ],
    [
        "unwrap : Remove large jumps in angle by wrapping.",
        "unwrap : Remove large jumps in angle by"
    ],
    [
        "Return the reciprocal of the argument, element-wise.",
        "Return the reciprocal of the"
    ],
    [
        "This function is not designed to work with integers.",
        "This function is not designed to work with"
    ],
    [
        "always zero because of the way Python handles integer division.  For",
        "always zero because of the way Python handles"
    ],
    [
        "integer zero the result is an overflow.",
        "integer zero the result is"
    ],
    [
        "Returns the element-wise remainder of division.",
        "Returns the element-wise remainder of"
    ],
    [
        "Computes the remainder complementary to the `floor_divide` function.  It is",
        "Computes the remainder complementary to"
    ],
    [
        "This should not be confused with:",
        "This should not be"
    ],
    [
        "computes the IEEE remainder, which are the complement to",
        "computes the IEEE remainder, which are the complement"
    ],
    [
        "* The MATLAB ``rem`` function and or the C ``%`` operator which is the",
        "* The MATLAB ``rem`` function and or the C ``%``"
    ],
    [
        "floor_divide : Equivalent of Python ``//`` operator.",
        "floor_divide : Equivalent of"
    ],
    [
        "divmod : Simultaneous floor division and remainder.",
        "divmod : Simultaneous floor"
    ],
    [
        "fmod : Equivalent of the MATLAB ``rem`` function.",
        "fmod : Equivalent of"
    ],
    [
        "``mod`` is an alias of ``remainder``.",
        "``mod`` is an"
    ],
    [
        "The ``%`` operator can be used as a shorthand for ``np.remainder`` on",
        "The ``%`` operator can be used as a shorthand for"
    ],
    [
        "Return element-wise quotient and remainder simultaneously.",
        "Return element-wise quotient and remainder"
    ],
    [
        "``np.divmod(x, y)`` is equivalent to ``(x // y, x % y)``, but faster",
        "``np.divmod(x, y)`` is equivalent to ``(x // y, x"
    ],
    [
        "because it avoids redundant work. It is used to implement the Python",
        "because it avoids redundant work. It is"
    ],
    [
        "built-in function ``divmod`` on NumPy arrays.",
        "built-in function ``divmod``"
    ],
    [
        "Element-wise quotient resulting from floor division.",
        "Element-wise quotient resulting from floor"
    ],
    [
        "floor_divide : Equivalent to Python's ``//`` operator.",
        "floor_divide : Equivalent to"
    ],
    [
        "remainder : Equivalent to Python's ``%`` operator.",
        "remainder : Equivalent to"
    ],
    [
        "The `divmod` function can be used as a shorthand for ``np.divmod`` on",
        "The `divmod` function can be used as a shorthand for ``np.divmod``"
    ],
    [
        "Shift the bits of an integer to the right.",
        "Shift the bits of an"
    ],
    [
        "representation of numbers is in binary format, this operation is",
        "representation of numbers is in binary format, this operation"
    ],
    [
        "left_shift : Shift the bits of an integer to the left.",
        "left_shift : Shift the bits of"
    ],
    [
        "binary_repr : Return the binary representation of the input number",
        "binary_repr : Return the binary"
    ],
    [
        "The ``>>`` operator can be used as a shorthand for ``np.right_shift`` on",
        "The ``>>`` operator can be used as a shorthand"
    ],
    [
        "Round elements of the array to the nearest integer.",
        "Round elements of the array to"
    ],
    [
        "Output array is same shape and type as `x`.",
        "Output array is same shape and type as"
    ],
    [
        "For values exactly halfway between rounded decimal values, NumPy",
        "For values exactly halfway between rounded decimal"
    ],
    [
        "Returns an element-wise indication of the sign of a number.",
        "Returns an element-wise indication of"
    ],
    [
        "For complex inputs, the `sign` function returns ``x / abs(x)``, the",
        "For complex inputs, the `sign` function returns ``x"
    ],
    [
        "Definition of complex sign changed to follow the Array API standard.",
        "Definition of complex sign changed to follow"
    ],
    [
        "There is more than one definition of sign in common use for complex",
        "There is more than one definition of sign"
    ],
    [
        "numbers.  The definition used here, :math:`x/|x|`, is the more common",
        "numbers. The definition used here, :math:`x/|x|`,"
    ],
    [
        "and useful one, but is different from the one used in numpy prior to",
        "and useful one, but is different from the one used in numpy"
    ],
    [
        "Returns element-wise True where signbit is set (less than zero).",
        "Returns element-wise True where signbit is set (less"
    ],
    [
        "Output array, or reference to `out` if that was supplied.",
        "Output array, or reference to"
    ],
    [
        "Values to change the sign of.",
        "Values to change"
    ],
    [
        "Values to find the next representable value of.",
        "Values to find the"
    ],
    [
        "Return the distance between x and the nearest adjacent number.",
        "Return the distance between x and the"
    ],
    [
        "Values to find the spacing of.",
        "Values to find the"
    ],
    [
        "The spacing of values of `x`.",
        "The spacing of values of"
    ],
    [
        "It can be considered as a generalization of EPS:",
        "It can be considered as"
    ],
    [
        "should not be any representable number between ``x + spacing(x)`` and",
        "should not be any representable number between ``x + spacing(x)``"
    ],
    [
        "Spacing of +- inf and NaN is NaN.",
        "Spacing of +- inf and NaN"
    ],
    [
        "The sine of each element of x.",
        "The sine of each element of"
    ],
    [
        "The sine is one of the fundamental functions of trigonometry (the",
        "The sine is one of the fundamental functions of"
    ],
    [
        "centered on the origin.  A ray comes in from the :math:`+x` axis, makes",
        "centered on the origin. A ray comes in from the"
    ],
    [
        "an angle at the origin (measured counter-clockwise from that axis), and",
        "an angle at the origin (measured counter-clockwise from"
    ],
    [
        "departs from the origin.  The :math:`y` coordinate of the outgoing",
        "departs from the origin. The :math:`y` coordinate of the"
    ],
    [
        "ray's intersection with the unit circle is the sine of that angle.  It",
        "ray's intersection with the unit circle is"
    ],
    [
        "function has zeroes where the angle is a multiple of :math:`\\\\pi`.",
        "function has zeroes where the angle is a multiple"
    ],
    [
        "The numerous properties of the sine and related functions are included",
        "The numerous properties of the sine"
    ],
    [
        "Print sines of an array of angles given in degrees:",
        "Print sines of an array of angles"
    ],
    [
        "If `out` is provided, the function writes the result into it,",
        "If `out` is provided, the function writes"
    ],
    [
        "and returns a reference to `out`.  (See Examples)",
        "and returns a reference to `out`. (See"
    ],
    [
        "M. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions.",
        "M. Abramowitz and I. A. Stegun,"
    ],
    [
        "Return the non-negative square-root of an array, element-wise.",
        "Return the non-negative square-root of an array,"
    ],
    [
        "The values whose square-roots are required.",
        "The values whose"
    ],
    [
        "An array of the same shape as `x`, containing the positive",
        "An array of the same shape"
    ],
    [
        "square-root of each element in `x`.  If any element in `x` is",
        "square-root of each element in `x`. If"
    ],
    [
        "complex, a complex array is returned (and the square-roots of",
        "complex, a complex array is returned"
    ],
    [
        "negative reals are calculated).  If all of the elements in `x`",
        "negative reals are calculated). If all of the elements in"
    ],
    [
        "are real, so is `y`, with negative elements returning ``nan``.",
        "are real, so is `y`,"
    ],
    [
        "If `out` was provided, `y` is a reference to it.",
        "If `out` was provided, `y`"
    ],
    [
        "A version which returns complex numbers when given negative reals.",
        "A version which returns complex numbers when given"
    ],
    [
        "*sqrt* has--consistent with common convention--as its branch cut the",
        "*sqrt* has--consistent with common convention--as its"
    ],
    [
        "A branch cut is a curve in the complex plane across which a given",
        "A branch cut is a curve in"
    ],
    [
        "complex function fails to be continuous.",
        "complex function fails"
    ],
    [
        "Return the cube-root of an array, element-wise.",
        "Return the cube-root of an array,"
    ],
    [
        "The values whose cube-roots are required.",
        "The values whose cube-roots"
    ],
    [
        "An array of the same shape as `x`, containing the",
        "An array of the same shape as"
    ],
    [
        "cube root of each element in `x`.",
        "cube root of each element"
    ],
    [
        "If `out` was provided, `y` is a reference to it.",
        "If `out` was provided, `y`"
    ],
    [
        "Return the element-wise square of the input.",
        "Return the element-wise square of the"
    ],
    [
        "Element-wise `x*x`, of the same shape and dtype as `x`.",
        "Element-wise `x*x`, of the same shape and dtype as"
    ],
    [
        "The arrays to be subtracted from each other.",
        "The arrays to be"
    ],
    [
        "The ``-`` operator can be used as a shorthand for ``np.subtract`` on",
        "The ``-`` operator can be used"
    ],
    [
        "If `out` is provided, the function writes the result into it,",
        "If `out` is provided, the function writes the"
    ],
    [
        "and returns a reference to `out`.  (See Examples)",
        "and returns a reference to `out`. (See"
    ],
    [
        "M. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions.",
        "M. Abramowitz and I. A. Stegun, Handbook of"
    ],
    [
        "If `out` is provided, the function writes the result into it,",
        "If `out` is provided, the function writes"
    ],
    [
        "and returns a reference to `out`.  (See Examples)",
        "and returns a reference to"
    ],
    [
        "Decompose the elements of x into mantissa and twos exponent.",
        "Decompose the elements of x into mantissa and"
    ],
    [
        "Array of numbers to be decomposed.",
        "Array of numbers to"
    ],
    [
        "Output array for the mantissa. Must have the same shape as `x`.",
        "Output array for the mantissa. Must have the same shape"
    ],
    [
        "Output array for the exponent. Must have the same shape as `x`.",
        "Output array for the exponent. Must have"
    ],
    [
        "Complex dtypes are not supported, they will raise a TypeError.",
        "Complex dtypes are not supported, they"
    ],
    [
        "Complex dtypes are not supported, they will raise a TypeError.",
        "Complex dtypes are not supported, they will"
    ],
    [
        "`ldexp` is useful as the inverse of `frexp`, if used by itself it is",
        "`ldexp` is useful as the inverse of `frexp`, if used"
    ],
    [
        "The greatest common divisor of the absolute value of the inputs",
        "The greatest common divisor of the absolute"
    ],
    [
        "lcm : The lowest common multiple",
        "lcm : The"
    ],
    [
        "The lowest common multiple of the absolute value of the inputs",
        "The lowest common multiple of the"
    ],
    [
        "gcd : The greatest common divisor",
        "gcd : The greatest common"
    ],
    [
        "Analogous to the builtin `int.bit_count` or ``popcount`` in C++.",
        "Analogous to the builtin `int.bit_count`"
    ],
    [
        "Returns the length of each element. For byte strings,",
        "Returns the length of each element."
    ],
    [
        "this is the number of bytes, while, for Unicode strings,",
        "this is the number of bytes, while,"
    ],
    [
        "it is the number of Unicode code points.",
        "it is the number"
    ],
    [
        "x : array_like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "x : array_like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        ">>> a = np.array(['Grace Hopper Conference', 'Open Source Day'])",
        ">>> a = np.array(['Grace Hopper Conference', 'Open Source"
    ],
    [
        "Returns true for each element if all characters in the data",
        "Returns true for each element if all characters in"
    ],
    [
        "interpreted as a string are alphabetic and there is at least",
        "interpreted as a string are alphabetic and"
    ],
    [
        "For byte strings (i.e. ``bytes``), alphabetic characters are",
        "For byte strings (i.e. ``bytes``), alphabetic"
    ],
    [
        "those byte values in the sequence",
        "those byte values in the"
    ],
    [
        "Unicode strings, alphabetic characters are those characters",
        "Unicode strings, alphabetic characters are those"
    ],
    [
        "defined in the Unicode character database as â€œLetterâ€.",
        "defined in the Unicode"
    ],
    [
        "x : array_like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "x : array_like, with ``StringDType``, ``bytes_``,"
    ],
    [
        "array([[ True,  True, False], [ True, False, False]])",
        "array([[ True, True, False], [ True,"
    ],
    [
        "Returns true for each element if all characters in the string are",
        "Returns true for each element if all"
    ],
    [
        "digits and there is at least one character, false otherwise.",
        "digits and there is at least one"
    ],
    [
        "For byte strings, digits are the byte values in the sequence",
        "For byte strings, digits are the byte values in the"
    ],
    [
        "characters and digits that need special handling, such as the",
        "characters and digits that need special"
    ],
    [
        "compatibility superscript digits. This also covers digits which",
        "compatibility superscript digits. This also covers digits"
    ],
    [
        "x : array_like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "x : array_like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "array([[False, False,  True], [False,  True,  True]])",
        "array([[False, False, True], [False,"
    ],
    [
        "Returns true for each element if there are only whitespace",
        "Returns true for each element if there are only"
    ],
    [
        "characters in the string and there is at least one character,",
        "characters in the string and there is at least"
    ],
    [
        "For byte strings, whitespace characters are the ones in the",
        "For byte strings, whitespace characters are"
    ],
    [
        "whitespace, if, in the Unicode character database, its general",
        "whitespace, if, in the Unicode"
    ],
    [
        "category is Zs (â€œSeparator, spaceâ€), or its bidirectional class",
        "category is Zs (â€œSeparator, spaceâ€), or its"
    ],
    [
        "is one of WS, B, or S.",
        "is one of WS, B, or"
    ],
    [
        "x : array_like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "x : array_like, with ``StringDType``,"
    ],
    [
        "Returns true for each element if all characters in the string are",
        "Returns true for each element if all characters"
    ],
    [
        "alphanumeric and there is at least one character, false otherwise.",
        "alphanumeric and there is at least one character,"
    ],
    [
        "x : array_like, with ``StringDType``, ``bytes_`` or ``str_`` dtype",
        "x : array_like, with ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "array([ True,  True,  True, False, False])",
        "array([ True, True,"
    ],
    [
        "Returns true for each element if all cased characters in the",
        "Returns true for each element if all cased characters"
    ],
    [
        "string are lowercase and there is at least one cased character,",
        "string are lowercase and there is at least"
    ],
    [
        "x : array_like, with ``StringDType``, ``bytes_`` or ``str_`` dtype",
        "x : array_like, with ``StringDType``,"
    ],
    [
        "Return true for each element if all cased characters in the",
        "Return true for each element if all"
    ],
    [
        "string are uppercase and there is at least one character, false",
        "string are uppercase and there is at least"
    ],
    [
        "x : array_like, with ``StringDType``, ``bytes_`` or ``str_`` dtype",
        "x : array_like, with ``StringDType``, ``bytes_``"
    ],
    [
        ">>> a = np.array([\"hello\", \"HELLO\", \"Hello\"])",
        ">>> a = np.array([\"hello\","
    ],
    [
        "Returns true for each element if the element is a titlecased",
        "Returns true for each element if the element is"
    ],
    [
        "string and there is at least one character, false otherwise.",
        "string and there is at"
    ],
    [
        "x : array_like, with ``StringDType``, ``bytes_`` or ``str_`` dtype",
        "x : array_like, with ``StringDType``,"
    ],
    [
        "For each element, return True if there are only decimal",
        "For each element, return True"
    ],
    [
        "Decimal characters include digit characters, and all characters",
        "Decimal characters include digit characters, and"
    ],
    [
        "that can be used to form decimal-radix numbers,",
        "that can be used to form"
    ],
    [
        "x : array_like, with ``StringDType`` or ``str_`` dtype",
        "x : array_like, with"
    ],
    [
        "For each element, return True if there are only numeric",
        "For each element, return True"
    ],
    [
        "Numeric characters include digit characters, and all characters",
        "Numeric characters include digit characters, and all"
    ],
    [
        "x : array_like, with ``StringDType`` or ``str_`` dtype",
        "x : array_like, with ``StringDType`` or"
    ],
    [
        "array([ True, False, False, False, False])",
        "array([ True, False,"
    ],
    [
        "For each element, return the lowest index in the string where",
        "For each element, return the lowest index in the string"
    ],
    [
        ">>> a = np.array([\"NumPy is a Python library\"])",
        ">>> a = np.array([\"NumPy is"
    ],
    [
        "For each element, return the highest index in the string where",
        "For each element, return the highest index"
    ],
    [
        "Returns an array with the number of non-overlapping occurrences of",
        "Returns an array with the number"
    ],
    [
        ">>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> c = np.array(['aAaAaA', ' aA"
    ],
    [
        "Like `find`, but raises :exc:`ValueError` when the substring is not found.",
        "Like `find`, but raises :exc:`ValueError` when the substring is not"
    ],
    [
        "The range to look in, interpreted as in slice notation.",
        "The range to look in, interpreted"
    ],
    [
        "Like `rfind`, but raises :exc:`ValueError` when the substring is not found.",
        "Like `rfind`, but raises :exc:`ValueError` when the"
    ],
    [
        "The range to look in, interpreted as in slice notation.",
        "The range to look in, interpreted as"
    ],
    [
        "UFunc implementation of ``replace``. This internal function",
        "UFunc implementation of ``replace``."
    ],
    [
        "is called by ``replace`` with ``out`` set, so that the",
        "is called by ``replace`` with ``out``"
    ],
    [
        "size of the resulting string buffer is known.",
        "size of the resulting"
    ],
    [
        "Returns a boolean array which is `True` where the string element",
        "Returns a boolean array which is `True`"
    ],
    [
        "Returns a boolean array which is `True` where the string element",
        "Returns a boolean array which is `True` where the string"
    ],
    [
        "The length of the resulting strings, unless ``width < str_len(a)``.",
        "The length of the resulting"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        "The length of the resulting strings, unless ``width < str_len(a)``.",
        "The length of the resulting strings,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        ">>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> c = np.array(['aAaAaA',"
    ],
    [
        "The length of the resulting strings, unless ``width < str_len(a)``.",
        "The length of the resulting strings,"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_`` or ``str_``"
    ],
    [
        ">>> a = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> a = np.array(['aAaAaA', ' aA"
    ],
    [
        "Return the numeric string left-filled with zeros. A leading",
        "Return the numeric string left-filled with zeros. A"
    ],
    [
        "sign prefix (``+``/``-``) is handled by inserting the padding",
        "sign prefix (``+``/``-``) is handled by inserting"
    ],
    [
        "after the sign character rather than before.",
        "after the sign character rather"
    ],
    [
        "Width of string to left-fill elements in `a`.",
        "Width of string to left-fill"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_``"
    ],
    [
        "containing the part before the separator, the separator itself,",
        "containing the part before the"
    ],
    [
        "and the part after the separator. If the separator is not found,",
        "and the part after the separator. If the separator is"
    ],
    [
        "the first item of the tuple will contain the whole string, and",
        "the first item of the tuple will contain"
    ],
    [
        "the second and third ones will be the empty string.",
        "the second and third ones will"
    ],
    [
        "- array with ``bytes_`` or ``str_`` dtype with the part before the",
        "- array with ``bytes_`` or ``str_`` dtype with the part"
    ],
    [
        "- array with ``bytes_`` or ``str_`` dtype with the separator",
        "- array with ``bytes_`` or ``str_`` dtype"
    ],
    [
        "- array with ``bytes_`` or ``str_`` dtype with the part after the",
        "- array with ``bytes_`` or ``str_`` dtype with the"
    ],
    [
        "The ufunc is used most easily via ``np.strings.partition``,",
        "The ufunc is used most easily"
    ],
    [
        "which calls it after calculating the indices::",
        "which calls it after"
    ],
    [
        ">>> x = np.array([\"Numpy is nice!\"])",
        ">>> x = np.array([\"Numpy"
    ],
    [
        "containing the part before the separator, the separator itself,",
        "containing the part before the separator,"
    ],
    [
        "and the part after the separator. If the separator is not found,",
        "and the part after the separator. If the separator is"
    ],
    [
        "the third item of the tuple will contain the whole string, and",
        "the third item of the tuple will contain the"
    ],
    [
        "the first and second ones will be the empty string.",
        "the first and second ones"
    ],
    [
        "- array with ``bytes_`` or ``str_`` dtype with the part before the",
        "- array with ``bytes_`` or ``str_`` dtype with the part before"
    ],
    [
        "- array with ``bytes_`` or ``str_`` dtype with the separator",
        "- array with ``bytes_`` or ``str_``"
    ],
    [
        "- array with ``bytes_`` or ``str_`` dtype with the part after the",
        "- array with ``bytes_`` or ``str_`` dtype"
    ],
    [
        "The ufunc is used most easily via ``np.strings.rpartition``,",
        "The ufunc is used most easily via"
    ],
    [
        "which calls it after calculating the indices::",
        "which calls it after"
    ],
    [
        ">>> a = np.array(['aAaAaA', '  aA  ', 'abBABba'])",
        ">>> a = np.array(['aAaAaA',"
    ],
    [
        "the separator, the separator itself, and the part after the",
        "the separator, the separator itself, and the part"
    ],
    [
        "separator. If the separator is not found, the first item of the",
        "separator. If the separator is not found, the first item"
    ],
    [
        "tuple will contain the whole string, and the second and third ones",
        "tuple will contain the whole string, and the second"
    ],
    [
        "- ``StringDType`` array with the part before the separator",
        "- ``StringDType`` array with the part before the"
    ],
    [
        "- ``StringDType`` array with the separator",
        "- ``StringDType`` array"
    ],
    [
        "- ``StringDType`` array with the part after the separator",
        "- ``StringDType`` array with the"
    ],
    [
        "The ufunc is used most easily via ``np.strings.partition``,",
        "The ufunc is used most easily via"
    ],
    [
        "which calls it under the hood::",
        "which calls it under"
    ],
    [
        ">>> x = np.array([\"Numpy is nice!\"], dtype=\"T\")",
        ">>> x = np.array([\"Numpy"
    ],
    [
        "containing the part before the separator, the separator itself,",
        "containing the part before the separator, the separator"
    ],
    [
        "and the part after the separator. If the separator is not found,",
        "and the part after the separator."
    ],
    [
        "the third item of the tuple will contain the whole string, and",
        "the third item of the tuple will contain the whole string,"
    ],
    [
        "the first and second ones will be the empty string.",
        "the first and second ones will be"
    ],
    [
        "- ``StringDType`` array with the part before the separator",
        "- ``StringDType`` array with the part"
    ],
    [
        "- ``StringDType`` array with the separator",
        "- ``StringDType`` array with the"
    ],
    [
        "- ``StringDType`` array with the part after the separator",
        "- ``StringDType`` array with the"
    ],
    [
        "The ufunc is used most easily via ``np.strings.rpartition``,",
        "The ufunc is used most"
    ],
    [
        "which calls it after calculating the indices::",
        "which calls it after calculating"
    ],
    [
        ">>> a = np.array(['aAaAaA', '  aA  ', 'abBABba'], dtype=\"T\")",
        ">>> a = np.array(['aAaAaA', ' aA"
    ],
    [
        "Slice the strings in `a` by slices specified by `start`, `stop`, `step`.",
        "Slice the strings in `a` by"
    ],
    [
        "Like in the regular Python `slice` object, if only `start` is",
        "Like in the regular Python `slice`"
    ],
    [
        "specified then it is interpreted as the `stop`.",
        "specified then it is interpreted"
    ],
    [
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype",
        "a : array-like, with ``StringDType``, ``bytes_``, or ``str_``"
    ],
    [
        "start : array-like, with integer dtype",
        "start : array-like, with"
    ],
    [
        "The start of the slice, broadcasted to `a`'s shape",
        "The start of the slice,"
    ],
    [
        "stop : array-like, with integer dtype",
        "stop : array-like,"
    ],
    [
        "The end of the slice, broadcasted to `a`'s shape",
        "The end of the slice, broadcasted to"
    ],
    [
        "step : array-like, with integer dtype",
        "step : array-like,"
    ],
    [
        "The step for the slice, broadcasted to `a`'s shape",
        "The step for the slice, broadcasted"
    ],
    [
        "Output array of ``StringDType``, ``bytes_`` or ``str_`` dtype,",
        "Output array of ``StringDType``, ``bytes_``"
    ],
    [
        "The ufunc is used most easily via ``np.strings.slice``,",
        "The ufunc is used most easily via"
    ],
    [
        "which calls it under the hood::",
        "which calls it under"
    ],
    [
        "\"\"\"Here we define the exported functions, types, etc... which need to be",
        "\"\"\"Here we define the exported functions,"
    ],
    [
        "exported through a global C pointer.",
        "exported through a global C"
    ],
    [
        "Each dictionary contains name -> index pair.",
        "Each dictionary contains name"
    ],
    [
        "Whenever you change one index, you break the ABI (and the ABI version number",
        "Whenever you change one index, you break the ABI"
    ],
    [
        "should be incremented). Whenever you add an item to one of the dict, the API",
        "should be incremented). Whenever you add an item to one of the"
    ],
    [
        "needs to be updated in both numpy/core/meson.build and by adding an appropriate",
        "needs to be updated in both numpy/core/meson.build and"
    ],
    [
        "entry to cversion.txt (generate the hash via \"python cversions.py\").",
        "entry to cversion.txt (generate the hash"
    ],
    [
        "When adding a function, make sure to use the next integer not used as an index",
        "When adding a function, make sure to use the next integer not used as an"
    ],
    [
        "(in case you use an existing index or jump, the build will stop and raise an",
        "(in case you use an existing index or jump, the build will stop"
    ],
    [
        "exception, so it should hopefully not get unnoticed).",
        "exception, so it should hopefully not get"
    ],
    [
        "_BoolCodes = Literal[\"bool\", \"bool_\", \"?\", \"|?\", \"=?\", \"<?\", \">?\"]",
        "_BoolCodes = Literal[\"bool\", \"bool_\", \"?\", \"|?\", \"=?\", \"<?\","
    ],
    [
        "_ByteCodes = Literal[\"byte\", \"b\", \"|b\", \"=b\", \"<b\", \">b\"]",
        "_ByteCodes = Literal[\"byte\", \"b\", \"|b\", \"=b\","
    ],
    [
        "_ShortCodes = Literal[\"short\", \"h\", \"|h\", \"=h\", \"<h\", \">h\"]",
        "_ShortCodes = Literal[\"short\", \"h\","
    ],
    [
        "_IntCCodes = Literal[\"intc\", \"i\", \"|i\", \"=i\", \"<i\", \">i\"]",
        "_IntCCodes = Literal[\"intc\", \"i\","
    ],
    [
        "_IntPCodes = Literal[\"intp\", \"int\", \"int_\", \"n\", \"|n\", \"=n\", \"<n\", \">n\"]",
        "_IntPCodes = Literal[\"intp\", \"int\", \"int_\", \"n\", \"|n\","
    ],
    [
        "_LongCodes = Literal[\"long\", \"l\", \"|l\", \"=l\", \"<l\", \">l\"]",
        "_LongCodes = Literal[\"long\", \"l\", \"|l\", \"=l\", \"<l\","
    ],
    [
        "_LongLongCodes = Literal[\"longlong\", \"q\", \"|q\", \"=q\", \"<q\", \">q\"]",
        "_LongLongCodes = Literal[\"longlong\", \"q\", \"|q\","
    ],
    [
        "_UByteCodes = Literal[\"ubyte\", \"B\", \"|B\", \"=B\", \"<B\", \">B\"]",
        "_UByteCodes = Literal[\"ubyte\", \"B\", \"|B\", \"=B\", \"<B\","
    ],
    [
        "_UShortCodes = Literal[\"ushort\", \"H\", \"|H\", \"=H\", \"<H\", \">H\"]",
        "_UShortCodes = Literal[\"ushort\", \"H\","
    ],
    [
        "_UIntCCodes = Literal[\"uintc\", \"I\", \"|I\", \"=I\", \"<I\", \">I\"]",
        "_UIntCCodes = Literal[\"uintc\", \"I\", \"|I\", \"=I\", \"<I\","
    ],
    [
        "_UIntPCodes = Literal[\"uintp\", \"uint\", \"N\", \"|N\", \"=N\", \"<N\", \">N\"]",
        "_UIntPCodes = Literal[\"uintp\", \"uint\", \"N\", \"|N\","
    ],
    [
        "_ULongCodes = Literal[\"ulong\", \"L\", \"|L\", \"=L\", \"<L\", \">L\"]",
        "_ULongCodes = Literal[\"ulong\", \"L\", \"|L\","
    ],
    [
        "_ULongLongCodes = Literal[\"ulonglong\", \"Q\", \"|Q\", \"=Q\", \"<Q\", \">Q\"]",
        "_ULongLongCodes = Literal[\"ulonglong\", \"Q\","
    ],
    [
        "_HalfCodes = Literal[\"half\", \"e\", \"|e\", \"=e\", \"<e\", \">e\"]",
        "_HalfCodes = Literal[\"half\", \"e\", \"|e\","
    ],
    [
        "_SingleCodes = Literal[\"single\", \"f\", \"|f\", \"=f\", \"<f\", \">f\"]",
        "_SingleCodes = Literal[\"single\", \"f\","
    ],
    [
        "_DoubleCodes = Literal[\"double\", \"float\", \"d\", \"|d\", \"=d\", \"<d\", \">d\"]",
        "_DoubleCodes = Literal[\"double\", \"float\", \"d\","
    ],
    [
        "_LongDoubleCodes = Literal[\"longdouble\", \"g\", \"|g\", \"=g\", \"<g\", \">g\"]",
        "_LongDoubleCodes = Literal[\"longdouble\", \"g\", \"|g\","
    ],
    [
        "_CSingleCodes = Literal[\"csingle\", \"F\", \"|F\", \"=F\", \"<F\", \">F\"]",
        "_CSingleCodes = Literal[\"csingle\", \"F\", \"|F\", \"=F\", \"<F\","
    ],
    [
        "_CDoubleCodes = Literal[\"cdouble\", \"complex\", \"D\", \"|D\", \"=D\", \"<D\", \">D\"]",
        "_CDoubleCodes = Literal[\"cdouble\", \"complex\", \"D\", \"|D\","
    ],
    [
        "_CLongDoubleCodes = Literal[\"clongdouble\", \"G\", \"|G\", \"=G\", \"<G\", \">G\"]",
        "_CLongDoubleCodes = Literal[\"clongdouble\", \"G\","
    ],
    [
        "_StrCodes = Literal[\"str\", \"str_\", \"unicode\", \"U\", \"|U\", \"=U\", \"<U\", \">U\"]",
        "_StrCodes = Literal[\"str\", \"str_\", \"unicode\", \"U\", \"|U\","
    ],
    [
        "_BytesCodes = Literal[\"bytes\", \"bytes_\", \"S\", \"|S\", \"=S\", \"<S\", \">S\"]",
        "_BytesCodes = Literal[\"bytes\", \"bytes_\", \"S\", \"|S\","
    ],
    [
        "_VoidCodes = Literal[\"void\", \"V\", \"|V\", \"=V\", \"<V\", \">V\"]",
        "_VoidCodes = Literal[\"void\", \"V\", \"|V\", \"=V\", \"<V\","
    ],
    [
        "_ObjectCodes = Literal[\"object\", \"object_\", \"O\", \"|O\", \"=O\", \"<O\", \">O\"]",
        "_ObjectCodes = Literal[\"object\", \"object_\", \"O\", \"|O\","
    ],
    [
        "_StringCodes = Literal[\"T\", \"|T\", \"=T\", \"<T\", \">T\"]",
        "_StringCodes = Literal[\"T\", \"|T\", \"=T\", \"<T\","
    ],
    [
        "\"\"\"A module with platform-specific extended precision",
        "\"\"\"A module with platform-specific"
    ],
    [
        "The subclasses are defined here (instead of ``__init__.pyi``) such",
        "The subclasses are defined here"
    ],
    [
        "that they can be imported conditionally via the numpy's mypy plugin.",
        "that they can be imported conditionally"
    ],
    [
        "\"\"\"A module with the precisions of platform-specific `~numpy.number`s.\"\"\"",
        "\"\"\"A module with the precisions of platform-specific"
    ],
    [
        "\"\"\"A module with the precisions of generic `~numpy.number` types.\"\"\"",
        "\"\"\"A module with the precisions"
    ],
    [
        "A type representing `numpy.number` precision during static type checking.",
        "A type representing `numpy.number` precision during"
    ],
    [
        "Used exclusively for the purpose static type checking, `NBitBase`",
        "Used exclusively for the purpose static type checking,"
    ],
    [
        "represents the base of a hierarchical set of subclasses.",
        "represents the base of a hierarchical set"
    ],
    [
        "Each subsequent subclass is herein used for representing a lower level",
        "Each subsequent subclass is herein used"
    ],
    [
        "Below is a typical usage example: `NBitBase` is herein used for annotating",
        "Below is a typical usage example: `NBitBase` is herein used for"
    ],
    [
        "a function that takes a float and integer of arbitrary precision",
        "a function that takes a float and integer of"
    ],
    [
        "as arguments and returns a new float of whichever precision is largest",
        "as arguments and returns a new float of whichever"
    ],
    [
        ">>> from typing import TypeVar, TYPE_CHECKING",
        ">>> from typing"
    ],
    [
        ">>> def add(a: np.floating[S], b: np.integer[T]) -> np.floating[S | T]:",
        ">>> def add(a: np.floating[S], b: np.integer[T]) ->"
    ],
    [
        "raise TypeError('cannot inherit from final class \"NBitBase\"')",
        "raise TypeError('cannot inherit from final class"
    ],
    [
        "from collections.abc import Collection, Callable, Sequence",
        "from collections.abc import Collection,"
    ],
    [
        "from typing import Any, Protocol, TypeAlias, TypeVar, runtime_checkable, TYPE_CHECKING",
        "from typing import Any, Protocol, TypeAlias, TypeVar,"
    ],
    [
        "def __array__(self) -> ndarray[Any, _DType_co]: ...",
        "def __array__(self) ->"
    ],
    [
        "from collections.abc import Buffer as _Buffer",
        "from collections.abc import Buffer as"
    ],
    [
        "def __buffer__(self, flags: int, /) -> memoryview: ...",
        "def __buffer__(self, flags: int, /) -> memoryview:"
    ],
    [
        "ArrayLike: TypeAlias = _Buffer | _DualArrayLike[",
        "ArrayLike: TypeAlias = _Buffer"
    ],
    [
        "bool | int | float | complex | str | bytes,",
        "bool | int | float | complex"
    ],
    [
        "bool | int | float | complex,",
        "bool | int | float |"
    ],
    [
        "bool | int | float | complex,",
        "bool | int |"
    ],
    [
        "from typing import Never as _UnknownType",
        "from typing import"
    ],
    [
        "from typing import NoReturn as _UnknownType",
        "from typing import NoReturn as"
    ],
    [
        "_CharLike_co: TypeAlias = str | bytes",
        "_CharLike_co: TypeAlias = str"
    ],
    [
        "_BoolLike_co: TypeAlias = bool | np.bool",
        "_BoolLike_co: TypeAlias = bool |"
    ],
    [
        "_UIntLike_co: TypeAlias = np.unsignedinteger[Any] | _BoolLike_co",
        "_UIntLike_co: TypeAlias = np.unsignedinteger[Any] |"
    ],
    [
        "_IntLike_co: TypeAlias = int | np.integer[Any] | _BoolLike_co",
        "_IntLike_co: TypeAlias = int | np.integer[Any] |"
    ],
    [
        "_FloatLike_co: TypeAlias = float | np.floating[Any] | _IntLike_co",
        "_FloatLike_co: TypeAlias = float | np.floating[Any]"
    ],
    [
        "_NumberLike_co: TypeAlias = int | float | complex | np.number[Any] | np.bool",
        "_NumberLike_co: TypeAlias = int | float | complex | np.number[Any]"
    ],
    [
        "_ScalarLike_co: TypeAlias = int | float | complex | str | bytes | np.generic",
        "_ScalarLike_co: TypeAlias = int | float | complex"
    ],
    [
        "_VoidLike_co: TypeAlias = tuple[Any, ...] | np.void",
        "_VoidLike_co: TypeAlias = tuple[Any, ...]"
    ],
    [
        "_ShapeLike: TypeAlias = SupportsIndex | Sequence[SupportsIndex]",
        "_ShapeLike: TypeAlias = SupportsIndex"
    ],
    [
        "\"\"\"A module for creating docstrings for sphinx ``data`` domains.\"\"\"",
        "\"\"\"A module for creating docstrings"
    ],
    [
        "def add_newdoc(name: str, value: str, doc: str) -> None:",
        "def add_newdoc(name: str, value: str, doc: str)"
    ],
    [
        "\"\"\"Append ``_docstrings_list`` with a docstring for `name`.",
        "\"\"\"Append ``_docstrings_list`` with a docstring"
    ],
    [
        "\"\"\"Convert all docstrings in ``_docstrings_list`` into a single",
        "\"\"\"Convert all docstrings in"
    ],
    [
        "for name, value, doc in _docstrings_list:",
        "for name, value, doc in"
    ],
    [
        "s_block = f\"\"\".. data:: {name}\\n    :value: {value}\\n    {s}\"\"\"",
        "s_block = f\"\"\".. data::"
    ],
    [
        "A `~typing.Union` representing objects that can be coerced",
        "A `~typing.Union` representing objects that can"
    ],
    [
        "Among others this includes the likes of:",
        "Among others this includes"
    ],
    [
        "* Objects implementing the `~class.__array__` protocol.",
        "* Objects implementing the"
    ],
    [
        "Any scalar or sequence that can be interpreted as an ndarray.",
        "Any scalar or sequence that can be"
    ],
    [
        ">>> def as_array(a: npt.ArrayLike) -> np.ndarray:",
        ">>> def as_array(a:"
    ],
    [
        "A `~typing.Union` representing objects that can be coerced",
        "A `~typing.Union` representing objects that can"
    ],
    [
        "Among others this includes the likes of:",
        "Among others this includes"
    ],
    [
        "* Character codes or the names of :class:`type` objects.",
        "* Character codes or the"
    ],
    [
        "* Objects with the ``.dtype`` attribute.",
        "* Objects with the"
    ],
    [
        ":ref:`Specifying and constructing data types <arrays.dtypes.constructing>`",
        ":ref:`Specifying and constructing data"
    ],
    [
        "A comprehensive overview of all objects that can be coerced",
        "A comprehensive overview of all objects"
    ],
    [
        ">>> def as_dtype(d: npt.DTypeLike) -> np.dtype:",
        ">>> def as_dtype(d:"
    ],
    [
        "type alias :term:`generic <generic type>` w.r.t. its",
        "type alias :term:`generic <generic type>`"
    ],
    [
        "Can be used during runtime for typing arrays with a given dtype",
        "Can be used during runtime for typing arrays with"
    ],
    [
        ">>> def func(a: npt.ArrayLike) -> npt.NDArray[Any]:",
        ">>> def func(a:"
    ],
    [
        "\"\"\"A module containing the `_NestedSequence` protocol.\"\"\"",
        "\"\"\"A module containing the"
    ],
    [
        "\"\"\"A protocol for representing nested sequences.",
        "\"\"\"A protocol for representing nested"
    ],
    [
        "`_NestedSequence` currently does not work in combination with typevars,",
        "`_NestedSequence` currently does not work"
    ],
    [
        "*e.g.* ``def func(a: _NestedSequnce[T]) -> T: ...``.",
        "*e.g.* ``def func(a: _NestedSequnce[T]) -> T:"
    ],
    [
        "ABCs for read-only and mutable :term:`sequences`.",
        "ABCs for read-only"
    ],
    [
        "def __getitem__(self, index: int, /) -> _T_co | _NestedSequence[_T_co]:",
        "def __getitem__(self, index: int, /) -> _T_co"
    ],
    [
        "def __contains__(self, x: object, /) -> bool:",
        "def __contains__(self, x: object,"
    ],
    [
        "def __iter__(self, /) -> Iterator[_T_co | _NestedSequence[_T_co]]:",
        "def __iter__(self, /) ->"
    ],
    [
        "def __reversed__(self, /) -> Iterator[_T_co | _NestedSequence[_T_co]]:",
        "def __reversed__(self, /) -> Iterator[_T_co |"
    ],
    [
        "def count(self, value: Any, /) -> int:",
        "def count(self, value: Any, /) ->"
    ],
    [
        "\"\"\"Return the number of occurrences of `value`.\"\"\"",
        "\"\"\"Return the number of occurrences of"
    ],
    [
        "def index(self, value: Any, /) -> int:",
        "def index(self, value: Any,"
    ],
    [
        "\"\"\"Return the first index of `value`.\"\"\"",
        "\"\"\"Return the first index of"
    ],
    [
        "Tests which scan for certain occurrences in the code, they may not find",
        "Tests which scan for certain occurrences in the code, they may"
    ],
    [
        "all of these occurrences but should catch almost all.",
        "all of these occurrences but should"
    ],
    [
        "\"warnings should have an appropriate stacklevel; found in \"",
        "\"warnings should have an appropriate stacklevel;"
    ],
    [
        "args = {kw.arg for kw in node.keywords}",
        "args = {kw.arg for"
    ],
    [
        "\"warnings should have an appropriate stacklevel; found in \"",
        "\"warnings should have an appropriate stacklevel; found in"
    ],
    [
        "if base / \"testing\" in path.parents:",
        "if base / \"testing\""
    ],
    [
        "if path == base / \"__init__.py\":",
        "if path == base /"
    ],
    [
        "if path == base / \"random\" / \"__init__.py\":",
        "if path == base /"
    ],
    [
        "if path == base / \"conftest.py\":",
        "if path == base"
    ],
    [
        "from numpy.ctypeslib import ndpointer, load_library, as_array",
        "from numpy.ctypeslib import ndpointer,"
    ],
    [
        "from numpy.testing import assert_, assert_array_equal, assert_raises, assert_equal",
        "from numpy.testing import assert_, assert_array_equal,"
    ],
    [
        "reason=\"ctypes not available in this python\")",
        "reason=\"ctypes not available"
    ],
    [
        "msg = (\"ctypes is not available on this python: skipping the test\"",
        "msg = (\"ctypes is not available on this python: skipping the"
    ],
    [
        "\" (import error was: %s)\" % str(e))",
        "\" (import error was:"
    ],
    [
        "dtdescr = {'names': dtnames, 'formats': dtformats}",
        "dtdescr = {'names':"
    ],
    [
        "reason=\"ctypes not available on this python installation\")",
        "reason=\"ctypes not available on this"
    ],
    [
        "\"\"\" Test that arguments are coerced from arrays \"\"\"",
        "\"\"\" Test that arguments are coerced from arrays"
    ],
    [
        "\"\"\" Test that return values are coerced to arrays \"\"\"",
        "\"\"\" Test that return values are coerced"
    ],
    [
        "\"\"\" Test that vague ndpointer return values do not promote to arrays \"\"\"",
        "\"\"\" Test that vague ndpointer return values do not"
    ],
    [
        "reason=\"ctypes not available on this python installation\")",
        "reason=\"ctypes not available on"
    ],
    [
        "from ctypes import c_int, cast, POINTER",
        "from ctypes import c_int, cast,"
    ],
    [
        "reason=\"ctypes not available on this python installation\")",
        "reason=\"ctypes not available on this python"
    ],
    [
        "\"\"\" Test conversion from dtypes to ctypes types \"\"\"",
        "\"\"\" Test conversion from dtypes to"
    ],
    [
        "from importlib.util import LazyLoader, find_spec, module_from_spec",
        "from importlib.util import LazyLoader, find_spec,"
    ],
    [
        "Check the numpy version is valid.",
        "Check the numpy version"
    ],
    [
        "in the version string, all else is treated as a release. The version string",
        "in the version string, all else is treated as a release. The version"
    ],
    [
        "itself is set from the output of ``git describe`` which relies on tags.",
        "itself is set from the output of ``git describe`` which relies on"
    ],
    [
        "Note that a release is determined by the version string, which in turn",
        "Note that a release is determined by the version string, which in"
    ],
    [
        "is controlled by the result of the ``git describe`` command.",
        "is controlled by the result of the"
    ],
    [
        "res = re.match(version_pattern + dev_suffix + '$', np.__version__)",
        "res = re.match(version_pattern + dev_suffix +"
    ],
    [
        "contents = {s for s in dir(np.version) if not s.startswith('_')}",
        "contents = {s for s in dir(np.version) if"
    ],
    [
        "\"\"\"At the time of writing this, it is *not* truly supported, but",
        "\"\"\"At the time of writing this, it is *not* truly"
    ],
    [
        "apparently enough users rely on it, for it to be an annoying change",
        "apparently enough users rely on it, for it to be an annoying"
    ],
    [
        "p = subprocess.run([sys.executable, '-c', code], capture_output=True)",
        "p = subprocess.run([sys.executable,"
    ],
    [
        "\"\"\"Returns a mapping of all objects with the wrong __module__ attribute.\"\"\"",
        "\"\"\"Returns a mapping of all objects with"
    ],
    [
        "if (hasattr(item, '__module__') and hasattr(item, '__name__')",
        "if (hasattr(item, '__module__') and"
    ],
    [
        "results[name] = item.__module__ + '.' + item.__name__",
        "results[name] = item.__module__ + '.'"
    ],
    [
        "\"\"\"Make sure we can actually use the modules we lazy load.",
        "\"\"\"Make sure we can actually use"
    ],
    [
        "While not exported as part of the public API, it was accessible.  With the",
        "While not exported as part of the public API, it was accessible. With"
    ],
    [
        "use of __getattr__ and __dir__, this isn't always true It can happen that",
        "use of __getattr__ and __dir__, this isn't"
    ],
    [
        "This is the only way I found that would force the failure to appear on the",
        "This is the only way I found that would force the failure to appear on"
    ],
    [
        "We also test for the presence of the lazily imported modules in dir",
        "We also test for the presence of the lazily imported modules in"
    ],
    [
        "exe = (sys.executable, '-c', \"import numpy; numpy.\" + name)",
        "exe = (sys.executable, '-c', \"import numpy;"
    ],
    [
        "\"\"\"Assert that output of dir has only one \"testing/tester\"",
        "\"\"\"Assert that output of dir has only"
    ],
    [
        "reason=\"ctypes not available in this python\")",
        "reason=\"ctypes not available in"
    ],
    [
        "assert f is None, (\"'test_not_exported' is mistakenly exported, \"",
        "assert f is None, (\"'test_not_exported' is mistakenly"
    ],
    [
        "PUBLIC_MODULES = ['numpy.' + s for s in [",
        "PUBLIC_MODULES = ['numpy.' + s for"
    ],
    [
        "'numpy.' + s for s in [",
        "'numpy.' + s for s"
    ],
    [
        "PRIVATE_BUT_PRESENT_MODULES = ['numpy.' + s for s in [",
        "PRIVATE_BUT_PRESENT_MODULES = ['numpy.' + s for s"
    ],
    [
        "'numpy.' + s for s in [",
        "'numpy.' + s for s in"
    ],
    [
        "\"\"\"Check if this needs to be considered.\"\"\"",
        "\"\"\"Check if this needs to be"
    ],
    [
        "'._' not in name and '.tests' not in name and '.setup' not in name",
        "'._' not in name and '.tests' not"
    ],
    [
        "Test that we don't add anything that looks like a new public module by",
        "Test that we don't add anything that looks like a new public"
    ],
    [
        "accident.  Check is based on filenames.",
        "accident. Check is"
    ],
    [
        "for _, modname, ispkg in pkgutil.walk_packages(path=np.__path__,",
        "for _, modname, ispkg in"
    ],
    [
        "if is_unexpected(modname) and modname not in SKIP_LIST:",
        "if is_unexpected(modname) and modname not"
    ],
    [
        "Method checking all objects. The pkgutil-based method in",
        "Method checking all objects. The pkgutil-based method"
    ],
    [
        "`test_all_modules_are_expected` does not catch imports into a namespace,",
        "`test_all_modules_are_expected` does not catch"
    ],
    [
        "only filenames.  So this test is more thorough, and checks this like:",
        "only filenames. So this test is more"
    ],
    [
        "To check if something in a module is (effectively) public, one can check if",
        "To check if something in a module is (effectively)"
    ],
    [
        "there's anything in that namespace that's a public function/object but is",
        "there's anything in that namespace that's a"
    ],
    [
        "not exposed in a higher-level namespace.  For example for a `numpy.lib`",
        "not exposed in a higher-level namespace. For example for a"
    ],
    [
        "fullobjname = mod_name + '.' + objname",
        "fullobjname = mod_name + '.' +"
    ],
    [
        "raise AssertionError(\"Found unexpected object(s) that look like \"",
        "raise AssertionError(\"Found unexpected object(s) that look like"
    ],
    [
        "Check that all submodules listed higher up in this file can be imported",
        "Check that all submodules listed higher up in this file"
    ],
    [
        "Note that if a PRIVATE_BUT_PRESENT_MODULES entry goes missing, it may",
        "Note that if a PRIVATE_BUT_PRESENT_MODULES entry goes missing,"
    ],
    [
        "simply need to be removed from the list (deprecation may or may not be",
        "simply need to be removed from the list (deprecation"
    ],
    [
        "raise AssertionError(\"Modules in the public API that cannot be \"",
        "raise AssertionError(\"Modules in the public API that"
    ],
    [
        "raise AssertionError(\"Modules in the public API that were not \"",
        "raise AssertionError(\"Modules in the public API that"
    ],
    [
        "raise AssertionError(\"Modules that are not really public but looked \"",
        "raise AssertionError(\"Modules that are not really public"
    ],
    [
        "\"public and can not be imported: \"",
        "\"public and can not be"
    ],
    [
        "\"NumPy possibly built with `USE_DEBUG=True ./tools/travis-test.sh`, \"",
        "\"NumPy possibly built with `USE_DEBUG=True"
    ],
    [
        "\"which does not expose the `array_api` entry point. \"",
        "\"which does not expose the `array_api`"
    ],
    [
        "Entry point for Array API implementation can be found with importlib and",
        "Entry point for Array API implementation"
    ],
    [
        "msg = \"No entry points for 'array_api' found\"",
        "msg = \"No entry"
    ],
    [
        "ep = next(ep for ep in xp_eps if ep.name == \"numpy\")",
        "ep = next(ep for ep in"
    ],
    [
        "msg = \"'numpy' not in array_api entry points\"",
        "msg = \"'numpy' not in array_api"
    ],
    [
        "f\"numpy entry point value '{ep.value}' \"",
        "f\"numpy entry point value '{ep.value}'"
    ],
    [
        "\"does not point to our Array API implementation\"",
        "\"does not point to our Array API"
    ],
    [
        "Checks if `dir(np)` and `np.__all__` are consistent and return",
        "Checks if `dir(np)` and `np.__all__`"
    ],
    [
        "the same content, excluding exceptions and private members.",
        "the same content, excluding"
    ],
    [
        "return {m for m in member_set if not m.startswith('_')}",
        "return {m for m in member_set if not"
    ],
    [
        "Check that all \"semi-public\" members of `numpy._core` are also accessible",
        "Check that all \"semi-public\" members of"
    ],
    [
        "and member.__spec__ and member.__spec__.origin is not None",
        "and member.__spec__ and member.__spec__.origin"
    ],
    [
        "Check that each public function is available from one location only.",
        "Check that each public function is available from"
    ],
    [
        "Test performs BFS search traversing NumPy's public API. It flags",
        "Test performs BFS search traversing NumPy's public API. It"
    ],
    [
        "any function-like object that is accessible from more that one place.",
        "any function-like object that is accessible from more"
    ],
    [
        "from typing import Any, Callable, Dict, List, Set, Tuple",
        "from typing import Any, Callable, Dict,"
    ],
    [
        "functions_original_paths: Dict[Callable[..., Any], str] = {}",
        "functions_original_paths: Dict[Callable[..., Any], str]"
    ],
    [
        "(member.__name__ == \"recarray\" and module.__name__ == \"numpy\") or",
        "(member.__name__ == \"recarray\" and module.__name__ =="
    ],
    [
        "(member.__name__ == \"record\" and module.__name__ == \"numpy.rec\")",
        "(member.__name__ == \"record\" and module.__name__ =="
    ],
    [
        "hasattr(actual_obj, \"__get__\") and hasattr(obj, \"__self__\") and",
        "hasattr(actual_obj, \"__get__\") and hasattr(obj,"
    ],
    [
        "Test that we can run executable scripts that have been installed with numpy.",
        "Test that we can run executable scripts that have been installed"
    ],
    [
        "from os.path import join as pathjoin, isfile, dirname",
        "from os.path import join as"
    ],
    [
        "from numpy.testing import IS_WASM, IS_INSTALLED, IS_EDITABLE, NUMPY_ROOT",
        "from numpy.testing import IS_WASM,"
    ],
    [
        "INCLUDE_DIR = NUMPY_ROOT / '_core' / 'include'",
        "INCLUDE_DIR = NUMPY_ROOT /"
    ],
    [
        "PKG_CONFIG_DIR = NUMPY_ROOT / '_core' / 'lib' / 'pkgconfig'",
        "PKG_CONFIG_DIR = NUMPY_ROOT / '_core' / 'lib' /"
    ],
    [
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"`numpy-config` not expected to be installed\")",
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"`numpy-config` not"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"wasm interpreter cannot start subprocess\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"wasm interpreter cannot start"
    ],
    [
        "p = subprocess.run(['numpy-config', arg], capture_output=True, text=True)",
        "p = subprocess.run(['numpy-config',"
    ],
    [
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"numpy must be installed to check its entrypoints\")",
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"numpy must be installed to"
    ],
    [
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"numpy.pc is only available when numpy is installed\")",
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"numpy.pc is only"
    ],
    [
        "@pytest.mark.skipif(IS_EDITABLE, reason=\"editable installs don't have a numpy.pc\")",
        "@pytest.mark.skipif(IS_EDITABLE, reason=\"editable installs don't"
    ],
    [
        "Check the numpy config is valid.",
        "Check the numpy"
    ],
    [
        "assert all(key in config for key in self.REQUIRED_CONFIG_KEYS), (",
        "assert all(key in config for"
    ],
    [
        "\" see index of `False` with `REQUIRED_CONFIG_KEYS`\"",
        "\" see index of `False` with"
    ],
    [
        "\" please add UT if applicable and increment this count\"",
        "\" please add UT if applicable and increment this"
    ],
    [
        "\"\"\"This hook should collect all binary files and any hidden modules that numpy",
        "\"\"\"This hook should collect all binary files and any hidden modules that"
    ],
    [
        "Our (some-what inadequate) docs for writing PyInstaller hooks are kept here:",
        "Our (some-what inadequate) docs for writing PyInstaller"
    ],
    [
        "\"\"\"Compile and run pyinstaller-smoke.py using PyInstaller.\"\"\"",
        "\"\"\"Compile and run pyinstaller-smoke.py"
    ],
    [
        "exe = tmp_path / \"dist\" / source.stem",
        "exe = tmp_path / \"dist\""
    ],
    [
        "exe = tmp_path / \"dist\" / source.stem / source.stem",
        "exe = tmp_path / \"dist\" / source.stem"
    ],
    [
        "assert p.stdout.strip() == b\"I made it!\"",
        "assert p.stdout.strip() == b\"I"
    ],
    [
        "\"WASM/Pyodide does not use or support Fortran\",",
        "\"WASM/Pyodide does not use or"
    ],
    [
        "\"Editable install doesn't support tests with a compile step\",",
        "\"Editable install doesn't support tests with a compile"
    ],
    [
        "\"\"\"A crude *bit of everything* smoke test to verify PyInstaller compatibility.",
        "\"\"\"A crude *bit of everything* smoke"
    ],
    [
        "PyInstaller typically goes wrong by forgetting to package modules, extension",
        "PyInstaller typically goes wrong by forgetting to package"
    ],
    [
        "modules or shared libraries. This script should aim to touch as many of those",
        "modules or shared libraries. This script should aim to touch as"
    ],
    [
        "as possible in an attempt to trip a ModuleNotFoundError or a DLL load failure",
        "as possible in an attempt to trip a ModuleNotFoundError"
    ],
    [
        "due to an uncollected resource. Missing resources are unlikely to lead to",
        "due to an uncollected resource. Missing resources are unlikely"
    ],
    [
        "arithmetic errors so there's generally no need to verify any calculation's",
        "arithmetic errors so there's generally no need"
    ],
    [
        "output - merely that it made it to the end OK. This script should not",
        "output - merely that it made it to the"
    ],
    [
        "explicitly import any of numpy's submodules as that gives PyInstaller undue",
        "explicitly import any of numpy's submodules"
    ],
    [
        "hints that those submodules exist and should be collected (accessing implicitly",
        "hints that those submodules exist and should be collected"
    ],
    [
        "addition a number of type aliases are available to users, most prominently",
        "addition a number of type aliases are available to"
    ],
    [
        "- `ArrayLike`: objects that can be converted to arrays",
        "- `ArrayLike`: objects that can"
    ],
    [
        "- `DTypeLike`: objects that can be converted to dtypes",
        "- `DTypeLike`: objects that can be"
    ],
    [
        "Differences from the runtime NumPy API",
        "Differences from the runtime NumPy"
    ],
    [
        "NumPy is very flexible. Trying to describe the full range of",
        "NumPy is very flexible. Trying to describe the full"
    ],
    [
        "possibilities statically would result in types that are not very",
        "possibilities statically would result in types that are not"
    ],
    [
        "helpful. For that reason, the typed NumPy API is often stricter than",
        "helpful. For that reason, the typed"
    ],
    [
        "the runtime NumPy API. This section describes some notable",
        "the runtime NumPy API. This section describes"
    ],
    [
        "The `ArrayLike` type tries to avoid creating object arrays. For",
        "The `ArrayLike` type tries to avoid creating object"
    ],
    [
        "array(<generator object <genexpr> at ...>, dtype=object)",
        "array(<generator object <genexpr>"
    ],
    [
        "array. Type checkers will complain about the above example when using",
        "array. Type checkers will complain about the"
    ],
    [
        "the NumPy types however. If you really intended to do the above, then",
        "the NumPy types however. If you really intended"
    ],
    [
        "or explicitly type the array like object as `~typing.Any`:",
        "or explicitly type the array"
    ],
    [
        "array(<generator object <genexpr> at ...>, dtype=object)",
        "array(<generator object <genexpr> at"
    ],
    [
        "It's possible to mutate the dtype of an array at runtime. For example,",
        "It's possible to mutate the dtype of an array at runtime. For"
    ],
    [
        "This sort of mutation is not allowed by the types. Users who want to",
        "This sort of mutation is not allowed by the types."
    ],
    [
        "write statically typed code should instead use the `numpy.ndarray.view`",
        "write statically typed code should instead use"
    ],
    [
        "method to create a view of the array with a different dtype.",
        "method to create a view of the array"
    ],
    [
        "The `DTypeLike` type tries to avoid creation of dtype objects using",
        "The `DTypeLike` type tries to avoid creation of dtype objects"
    ],
    [
        "Although this is valid NumPy code, the type checker will complain about it,",
        "Although this is valid NumPy code, the type checker will complain about"
    ],
    [
        "Please see : :ref:`Data type objects <arrays.dtypes>`",
        "Please see : :ref:`Data type"
    ],
    [
        "The precision of `numpy.number` subclasses is treated as a invariant generic",
        "The precision of `numpy.number` subclasses is treated as"
    ],
    [
        "parameter (see :class:`~NBitBase`), simplifying the annotating of processes",
        "parameter (see :class:`~NBitBase`), simplifying"
    ],
    [
        ">>> def func(a: \"np.floating[T]\", b: \"np.floating[T]\") -> \"np.floating[T]\":",
        ">>> def func(a: \"np.floating[T]\", b: \"np.floating[T]\") ->"
    ],
    [
        "runtime, they're not necessarily considered as sub-classes.",
        "runtime, they're not necessarily considered"
    ],
    [
        "`~numpy.signedinteger`, the former only inheriting from `~numpy.generic`",
        "`~numpy.signedinteger`, the former only inheriting from"
    ],
    [
        "corresponding `~numpy.generic` instance. Until the introduction of shape",
        "corresponding `~numpy.generic` instance. Until the introduction of"
    ],
    [
        "cast are currently annotated as exclusively returning an `~numpy.ndarray`.",
        "cast are currently annotated as exclusively returning"
    ],
    [
        "If it is known in advance that an operation *will* perform a",
        "If it is known in advance"
    ],
    [
        "The dtype of `numpy.recarray`, and the :ref:`routines.array-creation.rec`",
        "The dtype of `numpy.recarray`, and"
    ],
    [
        "functions in general, can be specified in one of two ways:",
        "functions in general, can be specified in one"
    ],
    [
        "* Directly via the ``dtype`` argument.",
        "* Directly via the ``dtype``"
    ],
    [
        "* With up to five helper arguments that operate via `numpy.rec.format_parser`:",
        "* With up to five helper arguments"
    ],
    [
        "``formats``, ``names``, ``titles``, ``aligned`` and ``byteorder``.",
        "``formats``, ``names``, ``titles``, ``aligned`` and"
    ],
    [
        "These two approaches are currently typed as being mutually exclusive,",
        "These two approaches are currently typed as being mutually"
    ],
    [
        "*i.e.* if ``dtype`` is specified than one may not specify ``formats``.",
        "*i.e.* if ``dtype`` is specified than one may"
    ],
    [
        "While this mutual exclusivity is not (strictly) enforced during runtime,",
        "While this mutual exclusivity is"
    ],
    [
        "combining both dtype specifiers can lead to unexpected or even downright",
        "combining both dtype specifiers can lead"
    ],
    [
        "__all__ = [\"ArrayLike\", \"DTypeLike\", \"NBitBase\", \"NDArray\"]",
        "__all__ = [\"ArrayLike\", \"DTypeLike\", \"NBitBase\","
    ],
    [
        "\"\"\"A mypy_ plugin for managing a number of platform-specific annotations.",
        "\"\"\"A mypy_ plugin for managing"
    ],
    [
        "Its functionality can be split into three distinct parts:",
        "Its functionality can be split into three distinct"
    ],
    [
        "* Assigning the (platform-dependent) precisions of certain `~numpy.number`",
        "* Assigning the (platform-dependent)"
    ],
    [
        "subclasses, including the likes of `~numpy.int_`, `~numpy.intp` and",
        "subclasses, including the likes of `~numpy.int_`,"
    ],
    [
        ":ref:`scalar types <arrays.scalars.built-in>` for a comprehensive overview",
        ":ref:`scalar types <arrays.scalars.built-in>` for"
    ],
    [
        "of the affected classes. Without the plugin the precision of all relevant",
        "of the affected classes. Without the plugin the precision"
    ],
    [
        "classes will be inferred as `~typing.Any`.",
        "classes will be"
    ],
    [
        "* Removing all extended-precision `~numpy.number` subclasses that are",
        "* Removing all extended-precision `~numpy.number` subclasses"
    ],
    [
        "unavailable for the platform in question. Most notably this includes the",
        "unavailable for the platform in question."
    ],
    [
        "extended-precision types will, as far as mypy is concerned, be available",
        "extended-precision types will, as far as mypy is"
    ],
    [
        "* Assigning the (platform-dependent) precision of `~numpy.ctypeslib.c_intp`.",
        "* Assigning the (platform-dependent) precision of"
    ],
    [
        "To enable the plugin, one must add it to their mypy `configuration file`_:",
        "To enable the plugin, one must add it to"
    ],
    [
        "from typing import TYPE_CHECKING, Final, TypeAlias, cast",
        "from typing import TYPE_CHECKING, Final, TypeAlias,"
    ],
    [
        "return [i for i in extended_names if hasattr(np, i)]",
        "return [i for i in extended_names if hasattr(np,"
    ],
    [
        "from mypy.nodes import MypyFile, ImportFrom, Statement",
        "from mypy.nodes import MypyFile, ImportFrom,"
    ],
    [
        "\"\"\"Replace a type-alias with a concrete ``NBitBase`` subclass.\"\"\"",
        "\"\"\"Replace a type-alias with a concrete"
    ],
    [
        "def _index(iterable: Iterable[Statement], id: str) -> int:",
        "def _index(iterable: Iterable[Statement], id: str) ->"
    ],
    [
        "\"\"\"Identify the first ``ImportFrom`` instance the specified `id`.\"\"\"",
        "\"\"\"Identify the first ``ImportFrom`` instance"
    ],
    [
        "if getattr(value, \"id\", None) == id:",
        "if getattr(value, \"id\", None) =="
    ],
    [
        "raise ValueError(\"Failed to identify a `ImportFrom` instance \"",
        "raise ValueError(\"Failed to identify a `ImportFrom` instance"
    ],
    [
        "\"\"\"Override the first `module`-based import with new `imports`.\"\"\"",
        "\"\"\"Override the first `module`-based import with new"
    ],
    [
        "for lst in [file.defs, cast(\"list[Statement]\", file.imports)]:",
        "for lst in [file.defs, cast(\"list[Statement]\","
    ],
    [
        "\"\"\"A mypy plugin for handling versus numpy-specific typing tasks.\"\"\"",
        "\"\"\"A mypy plugin for handling"
    ],
    [
        "def get_type_analyze_hook(self, fullname: str) -> _HookFunc | None:",
        "def get_type_analyze_hook(self, fullname: str) ->"
    ],
    [
        "\"\"\"Set the precision of platform-specific `numpy.number`",
        "\"\"\"Set the precision"
    ],
    [
        "For example: `numpy.int_`, `numpy.longlong` and `numpy.longdouble`.",
        "For example: `numpy.int_`, `numpy.longlong`"
    ],
    [
        "* Import the appropriate `ctypes` equivalent to `numpy.intp`.",
        "* Import the appropriate `ctypes` equivalent to"
    ],
    [
        "imports=[(v, v) for v in _EXTENDED_PRECISION_LIST],",
        "imports=[(v, v) for v"
    ],
    [
        "f\"`{plugin}` is deprecated, and will be removed in a future \"",
        "f\"`{plugin}` is deprecated, and will be removed in a future"
    ],
    [
        "f\"release. Please remove `plugins = {plugin}` in your mypy config.\"",
        "f\"release. Please remove `plugins ="
    ],
    [
        "FILES += [ROOT / \"distutils\" / \"__init__.pyi\"]",
        "FILES += [ROOT /"
    ],
    [
        "\"\"\"Test if all ``.pyi`` files are properly installed.\"\"\"",
        "\"\"\"Test if all ``.pyi`` files are properly"
    ],
    [
        "\"\"\"Split at the first occurrence of the ``:`` character.",
        "\"\"\"Split at the first occurrence of the"
    ],
    [
        "Windows drive-letters (*e.g.* ``C:``) are ignored herein.",
        "Windows drive-letters (*e.g.* ``C:``)"
    ],
    [
        "def _strip_filename(msg: str) -> tuple[int, str]:",
        "def _strip_filename(msg: str) ->"
    ],
    [
        "\"\"\"Strip the filename and line number from a mypy message.\"\"\"",
        "\"\"\"Strip the filename and line number"
    ],
    [
        "\"\"\"`re.sub` helper function for stripping module names.\"\"\"",
        "\"\"\"`re.sub` helper function for"
    ],
    [
        "\"\"\"Clears the cache and run mypy before running any of the typing tests.",
        "\"\"\"Clears the cache and run mypy before running any"
    ],
    [
        "The mypy results are cached in `OUTPUT_MYPY` for further use.",
        "The mypy results are cached in"
    ],
    [
        "The cache refresh can be skipped using",
        "The cache refresh can be skipped"
    ],
    [
        "for directory in (PASS_DIR, REVEAL_DIR, FAIL_DIR, MISC_DIR):",
        "for directory in (PASS_DIR,"
    ],
    [
        "filename: str | None = None",
        "filename: str | None"
    ],
    [
        "for root, _, files in os.walk(directory):",
        "for root, _, files in"
    ],
    [
        "or (\" E:\" not in line and lineno not in errors)",
        "or (\" E:\" not in line and lineno"
    ],
    [
        "f\"Unexpected mypy output at line {lineno}\\n\\n{errors[lineno]}\"",
        "f\"Unexpected mypy output at line"
    ],
    [
        "_REVEAL_MSG = \"\"\"Reveal mismatch at line {}",
        "_REVEAL_MSG = \"\"\"Reveal mismatch at line"
    ],
    [
        "\"\"\"Validate that mypy correctly infers the return-types of",
        "\"\"\"Validate that mypy correctly infers"
    ],
    [
        "\"\"\"Validate that the code in `path` properly during runtime.\"\"\"",
        "\"\"\"Validate that the code in `path` properly"
    ],
    [
        "path, expression, msg, 'Expression is of type \"Any\"', lineno",
        "path, expression, msg, 'Expression is"
    ],
    [
        "\"\"\"Test the runtime usage of `numpy.typing`.\"\"\"",
        "\"\"\"Test the runtime usage of"
    ],
    [
        "def test_get_args(name: type, tup: TypeTup) -> None:",
        "def test_get_args(name: type, tup:"
    ],
    [
        "def test_get_origin(name: type, tup: TypeTup) -> None:",
        "def test_get_origin(name: type, tup:"
    ],
    [
        "def test_get_type_hints(name: type, tup: TypeTup) -> None:",
        "def test_get_type_hints(name: type, tup: TypeTup)"
    ],
    [
        "func.__annotations__ = {\"a\": typ, \"return\": None}",
        "func.__annotations__ = {\"a\": typ,"
    ],
    [
        "ref = {\"a\": typ, \"return\": type(None)}",
        "ref = {\"a\": typ,"
    ],
    [
        "def test_get_type_hints_str(name: type, tup: TypeTup) -> None:",
        "def test_get_type_hints_str(name: type, tup: TypeTup)"
    ],
    [
        "\"\"\"Test `typing.get_type_hints` with string-representation of types.\"\"\"",
        "\"\"\"Test `typing.get_type_hints` with"
    ],
    [
        "func.__annotations__ = {\"a\": typ_str, \"return\": None}",
        "func.__annotations__ = {\"a\":"
    ],
    [
        "ref = {\"a\": typ, \"return\": type(None)}",
        "ref = {\"a\": typ,"
    ],
    [
        "\"\"\"Test that ``TYPES.keys()`` and ``numpy.typing.__all__`` are synced.\"\"\"",
        "\"\"\"Test that ``TYPES.keys()`` and ``numpy.typing.__all__``"
    ],
    [
        "PROTOCOLS: dict[str, tuple[type[Any], object]] = {",
        "PROTOCOLS: dict[str, tuple[type[Any], object]]"
    ],
    [
        "def test_isinstance(self, cls: type[Any], obj: object) -> None:",
        "def test_isinstance(self, cls: type[Any], obj: object) ->"
    ],
    [
        "def test_issubclass(self, cls: type[Any], obj: object) -> None:",
        "def test_issubclass(self, cls: type[Any], obj:"
    ],
    [
        "\"Protocols with non-method members don't support issubclass()\"",
        "\"Protocols with non-method members don't support"
    ],
    [
        "def __array__(self, dtype: np.typing.DTypeLike = None,",
        "def __array__(self, dtype: np.typing.DTypeLike"
    ],
    [
        "copy: bool | None = None) -> np.ndarray[Any, np.dtype[np.object_]]:",
        "copy: bool | None = None)"
    ],
    [
        "def __sub__(self, value: Any) -> Object:",
        "def __sub__(self, value: Any)"
    ],
    [
        "def __rsub__(self, value: Any) -> Object:",
        "def __rsub__(self, value: Any) ->"
    ],
    [
        "def __floordiv__(self, value: Any) -> Object:",
        "def __floordiv__(self, value: Any) ->"
    ],
    [
        "def __rfloordiv__(self, value: Any) -> Object:",
        "def __rfloordiv__(self, value: Any)"
    ],
    [
        "def __mul__(self, value: Any) -> Object:",
        "def __mul__(self, value:"
    ],
    [
        "def __rmul__(self, value: Any) -> Object:",
        "def __rmul__(self, value:"
    ],
    [
        "def __pow__(self, value: Any) -> Object:",
        "def __pow__(self, value: Any)"
    ],
    [
        "def __rpow__(self, value: Any) -> Object:",
        "def __rpow__(self, value: Any)"
    ],
    [
        "\"\"\"These tests are based on the doctests from `numpy/lib/recfunctions.py`.\"\"\"",
        "\"\"\"These tests are based on the doctests from"
    ],
    [
        "from numpy.lib import recfunctions as rfn",
        "from numpy.lib import recfunctions as"
    ],
    [
        "adtype = np.dtype([(\"a\", int), (\"b\", [(\"b_a\", int), (\"b_b\", int)])])",
        "adtype = np.dtype([(\"a\", int), (\"b\", [(\"b_a\", int), (\"b_b\","
    ],
    [
        "adtype = np.dtype([(\"a\", int), (\"b\", [(\"b_a\", int), (\"b_b\", int)])])",
        "adtype = np.dtype([(\"a\", int), (\"b\", [(\"b_a\", int), (\"b_b\","
    ],
    [
        "(\"B\", [(\"B_A\", int), (\"B_B\", [(\"B_B_A\", int), (\"B_B_B\", int)])]),",
        "(\"B\", [(\"B_A\", int), (\"B_B\", [(\"B_B_A\", int), (\"B_B_B\","
    ],
    [
        "KACF = frozenset({None, \"K\", \"A\", \"C\", \"F\"})",
        "KACF = frozenset({None, \"K\", \"A\","
    ],
    [
        "ACF = frozenset({None, \"A\", \"C\", \"F\"})",
        "ACF = frozenset({None, \"A\","
    ],
    [
        "order_list: list[tuple[frozenset[str | None], Callable[..., Any]]] = [",
        "order_list: list[tuple[frozenset[str | None], Callable[...,"
    ],
    [
        "def func(i: int, j: int, **kwargs: Any) -> SubClass:",
        "def func(i: int, j: int, **kwargs:"
    ],
    [
        "np.dtype({\"names\": [\"a\", \"b\"], \"formats\": [int, float]})",
        "np.dtype({\"names\": [\"a\", \"b\"], \"formats\":"
    ],
    [
        "np.dtype({\"names\": [\"a\"], \"formats\": [int], \"titles\": [object]})",
        "np.dtype({\"names\": [\"a\"], \"formats\": [int], \"titles\":"
    ],
    [
        "np.dtype({\"names\": [\"a\"], \"formats\": [int], \"titles\": [object()]})",
        "np.dtype({\"names\": [\"a\"], \"formats\":"
    ],
    [
        "Tests for miscellaneous (non-magic) ``np.ndarray``/``np.generic`` methods.",
        "Tests for miscellaneous (non-magic)"
    ],
    [
        "More extensive tests are performed for the methods'",
        "More extensive tests are performed for the"
    ],
    [
        "def write(self, a: str) -> None:",
        "def write(self, a: str) ->"
    ],
    [
        "def write(self, a: str) -> int:",
        "def write(self, a: str) ->"
    ],
    [
        "AR_LIKE_b = [[True, True], [True, True]]",
        "AR_LIKE_b = [[True,"
    ],
    [
        "Does not include tests which fall under ``array_constructors``.",
        "Does not include tests"
    ],
    [
        "from typing import Any, NamedTuple, cast",
        "from typing import"
    ],
    [
        "np.einsum(\"i,i->i\", AR_LIKE_U, AR_LIKE_U, dtype=int, casting=\"unsafe\", out=OUT_f)",
        "np.einsum(\"i,i->i\", AR_LIKE_U, AR_LIKE_U, dtype=int, casting=\"unsafe\","
    ],
    [
        "from numpy._typing import NDArray, ArrayLike, _SupportsArray",
        "from numpy._typing import NDArray,"
    ],
    [
        "self, dtype: None | np.dtype[Any] = None",
        "self, dtype: None |"
    ],
    [
        "\"\"\"Simple expression that should pass with mypy.\"\"\"",
        "\"\"\"Simple expression that should pass with"
    ],
    [
        "\"\"\"Based on the `if __name__ == \"__main__\"` test code in `lib/_user_array_impl.py`.\"\"\"",
        "\"\"\"Based on the `if __name__ =="
    ],
    [
        "def __ge__(self, value: object) -> bool:",
        "def __ge__(self, value: object) ->"
    ],
    [
        "def __array__(self, dtype: np.typing.DTypeLike | None = None,",
        "def __array__(self, dtype: np.typing.DTypeLike |"
    ],
    [
        "copy: bool | None = None) -> np.ndarray[Any, np.dtype[np.object_]]:",
        "copy: bool | None = None)"
    ],
    [
        "Only required declarations/macros/functions will be used.",
        "Only required declarations/macros/functions"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE"
    ],
    [
        "Write an error message to stderr.",
        "Write an error"
    ],
    [
        "typedefs['unsigned_char'] = 'typedef unsigned char unsigned_char;'",
        "typedefs['unsigned_char'] = 'typedef unsigned"
    ],
    [
        "typedefs['unsigned_short'] = 'typedef unsigned short unsigned_short;'",
        "typedefs['unsigned_short'] = 'typedef unsigned"
    ],
    [
        "typedefs['unsigned_long'] = 'typedef unsigned long unsigned_long;'",
        "typedefs['unsigned_long'] = 'typedef"
    ],
    [
        "typedefs['signed_char'] = 'typedef signed char signed_char;'",
        "typedefs['signed_char'] = 'typedef signed"
    ],
    [
        "'complex_long_double'] = 'typedef struct {long double r,i;} complex_long_double;'",
        "'complex_long_double'] = 'typedef struct {long"
    ],
    [
        "typedefs['complex_float'] = 'typedef struct {float r,i;} complex_float;'",
        "typedefs['complex_float'] = 'typedef struct {float"
    ],
    [
        "typedefs['complex_double'] = 'typedef struct {double r,i;} complex_double;'",
        "typedefs['complex_double'] = 'typedef struct {double"
    ],
    [
        "typedefs['string'] = \"\"\"typedef char * string;\"\"\"",
        "typedefs['string'] = \"\"\"typedef char *"
    ],
    [
        "/* See fortranobject.h for definitions. The macros here are provided for BC. */",
        "/* See fortranobject.h for definitions. The macros here are provided"
    ],
    [
        "if ((capi_tmp = PyTuple_GetItem((tuple),(index)))==NULL) goto capi_fail;\\\\",
        "if ((capi_tmp ="
    ],
    [
        "if ((p) == NULL) {                                              \\\\",
        "if ((p) =="
    ],
    [
        "STRINGPADN replaces null values with padding values from the right.",
        "STRINGPADN replaces null values with padding"
    ],
    [
        "`to` must have size of at least N bytes.",
        "`to` must have size of"
    ],
    [
        "preceding, nulls with the given padding.",
        "preceding, nulls with the"
    ],
    [
        "STRINGPADN(to, N, PADDING, NULLVALUE) is an inverse operation.",
        "STRINGPADN(to, N, PADDING, NULLVALUE) is"
    ],
    [
        "`to` and `from` buffers must have sizes of at least N bytes.",
        "`to` and `from` buffers must have sizes"
    ],
    [
        "sprintf(errstring, \\\"%s: \\\"show, \\\"(\\\"tcheck\\\") failed for \\\"name, slen(var), var);\\\\",
        "sprintf(errstring, \\\"%s: \\\"show, \\\"(\\\"tcheck\\\") failed for"
    ],
    [
        "sprintf(errstring, \\\"%s: \\\"show, \\\"(\\\"tcheck\\\") failed for \\\"name, var);\\\\",
        "sprintf(errstring, \\\"%s: \\\"show, \\\"(\\\"tcheck\\\")"
    ],
    [
        "static int calcarrindex(int *i,PyArrayObject *arr) {",
        "static int calcarrindex(int *i,PyArrayObject"
    ],
    [
        "static int calcarrindextr(int *i,PyArrayObject *arr) {",
        "static int calcarrindextr(int"
    ],
    [
        "static struct { int nd;npy_intp *d;int *i,*i_tr,tr; } forcombcache;",
        "static struct { int nd;npy_intp *d;int"
    ],
    [
        "static int initforcomb(npy_intp *dims,int nd,int tr) {",
        "static int initforcomb(npy_intp *dims,int"
    ],
    [
        "if ((i=forcombcache.i) == NULL) return NULL;",
        "if ((i=forcombcache.i) =="
    ],
    [
        "if ((i_tr=forcombcache.i_tr) == NULL) return NULL;",
        "if ((i_tr=forcombcache.i_tr) == NULL)"
    ],
    [
        "if (forcombcache.d == NULL) return NULL;",
        "if (forcombcache.d == NULL)"
    ],
    [
        "try_pyarr_from_string copies str[:len(obj)] to the data of an `ndarray`.",
        "try_pyarr_from_string copies str[:len(obj)] to the data of"
    ],
    [
        "If obj is an `ndarray`, it is assumed to be contiguous.",
        "If obj is an `ndarray`, it is"
    ],
    [
        "const string str, const int len) {",
        "const string str, const"
    ],
    [
        "if (!PyArray_Check(obj)) goto capi_fail; /* not an ndarray */",
        "if (!PyArray_Check(obj)) goto capi_fail; /* not"
    ],
    [
        "Create a new string buffer `str` of at most length `len` from a",
        "Create a new string buffer `str` of"
    ],
    [
        "The string buffer is padded with blanks: in Fortran, trailing blanks",
        "The string buffer is padded with"
    ],
    [
        "are insignificant contrary to C nulls.",
        "are insignificant contrary"
    ],
    [
        "string_from_pyobj(string *str, int *len, const string inistr, PyObject *obj,",
        "string_from_pyobj(string *str, int *len, const string inistr, PyObject"
    ],
    [
        "if (tmp == NULL) goto capi_fail;",
        "if (tmp =="
    ],
    [
        "/* TODO: change the type of `len` so that we can remove this */",
        "/* TODO: change the type of `len`"
    ],
    [
        "else if (*len < n) {",
        "else if (*len <"
    ],
    [
        "/* discard the last (len-n) bytes of input buf */",
        "/* discard the last (len-n) bytes of input buf"
    ],
    [
        "Pad fixed-width string with nulls. The caller will replace",
        "Pad fixed-width string with nulls. The caller will"
    ],
    [
        "nulls with blanks when the corresponding argument is not",
        "nulls with blanks when the corresponding"
    ],
    [
        "character_from_pyobj(character* v, PyObject *obj, const char *errmess) {",
        "character_from_pyobj(character* v, PyObject *obj,"
    ],
    [
        "/* empty bytes has trailing null, so dereferencing is always safe */",
        "/* empty bytes has trailing null, so dereferencing"
    ],
    [
        "/* TODO: This error (and most other) error handling needs cleaning. */",
        "/* TODO: This error (and most other) error handling needs cleaning."
    ],
    [
        "\" -- expected str|bytes|sequence-of-str-or-bytes, got \");",
        "\" -- expected str|bytes|sequence-of-str-or-bytes,"
    ],
    [
        "char_from_pyobj(char* v, PyObject *obj, const char *errmess) {",
        "char_from_pyobj(char* v, PyObject *obj,"
    ],
    [
        "signed_char_from_pyobj(signed_char* v, PyObject *obj, const char *errmess) {",
        "signed_char_from_pyobj(signed_char* v, PyObject *obj, const char"
    ],
    [
        "short_from_pyobj(short* v, PyObject *obj, const char *errmess) {",
        "short_from_pyobj(short* v, PyObject *obj,"
    ],
    [
        "int_from_pyobj(int* v, PyObject *obj, const char *errmess)",
        "int_from_pyobj(int* v, PyObject *obj, const"
    ],
    [
        "else if (PyBytes_Check(obj) || PyUnicode_Check(obj)) {",
        "else if (PyBytes_Check(obj) ||"
    ],
    [
        "long_from_pyobj(long* v, PyObject *obj, const char *errmess) {",
        "long_from_pyobj(long* v, PyObject *obj, const"
    ],
    [
        "else if (PyBytes_Check(obj) || PyUnicode_Check(obj)) {",
        "else if (PyBytes_Check(obj)"
    ],
    [
        "long_long_from_pyobj(long_long* v, PyObject *obj, const char *errmess)",
        "long_long_from_pyobj(long_long* v, PyObject *obj, const char"
    ],
    [
        "else if (PyBytes_Check(obj) || PyUnicode_Check(obj)) {",
        "else if (PyBytes_Check(obj) || PyUnicode_Check(obj))"
    ],
    [
        "long_double_from_pyobj(long_double* v, PyObject *obj, const char *errmess)",
        "long_double_from_pyobj(long_double* v, PyObject *obj,"
    ],
    [
        "else if (PyArray_Check(obj) && PyArray_TYPE(obj) == NPY_LONGDOUBLE) {",
        "else if (PyArray_Check(obj) && PyArray_TYPE(obj) == NPY_LONGDOUBLE)"
    ],
    [
        "double_from_pyobj(double* v, PyObject *obj, const char *errmess)",
        "double_from_pyobj(double* v, PyObject *obj, const"
    ],
    [
        "else if (PyBytes_Check(obj) || PyUnicode_Check(obj)) {",
        "else if (PyBytes_Check(obj) ||"
    ],
    [
        "float_from_pyobj(float* v, PyObject *obj, const char *errmess)",
        "float_from_pyobj(float* v, PyObject *obj, const"
    ],
    [
        "complex_long_double_from_pyobj(complex_long_double* v, PyObject *obj, const char *errmess)",
        "complex_long_double_from_pyobj(complex_long_double* v, PyObject *obj, const"
    ],
    [
        "else if (PyArray_Check(obj) && PyArray_TYPE(obj)==NPY_CLONGDOUBLE) {",
        "else if (PyArray_Check(obj) && PyArray_TYPE(obj)==NPY_CLONGDOUBLE)"
    ],
    [
        "complex_double_from_pyobj(complex_double* v, PyObject *obj, const char *errmess) {",
        "complex_double_from_pyobj(complex_double* v, PyObject *obj, const char"
    ],
    [
        "else { /* if (PyArray_IsScalar(obj, CDouble)) */",
        "else { /* if (PyArray_IsScalar(obj, CDouble))"
    ],
    [
        "arr = (PyArrayObject *)PyArray_Cast((PyArrayObject *)obj, NPY_CDOUBLE);",
        "arr = (PyArrayObject"
    ],
    [
        "/* Python does not provide PyNumber_Complex function :-( */",
        "/* Python does not provide"
    ],
    [
        "if (PySequence_Check(obj) && !(PyBytes_Check(obj) || PyUnicode_Check(obj))) {",
        "if (PySequence_Check(obj) && !(PyBytes_Check(obj)"
    ],
    [
        "static int try_pyarr_from_character(PyObject* obj, character* v) {",
        "static int try_pyarr_from_character(PyObject* obj,"
    ],
    [
        "\" -- expected bytes array-scalar|array, got \");",
        "\" -- expected bytes array-scalar|array,"
    ],
    [
        "'try_pyarr_from_char'] = 'static int try_pyarr_from_char(PyObject* obj,char* v) {\\n    TRYPYARRAYTEMPLATE(char,\\'c\\');\\n}\\n'",
        "'try_pyarr_from_char'] = 'static int try_pyarr_from_char(PyObject* obj,char* v)"
    ],
    [
        "'try_pyarr_from_unsigned_char'] = 'static int try_pyarr_from_unsigned_char(PyObject* obj,unsigned_char* v) {\\n    TRYPYARRAYTEMPLATE(unsigned_char,\\'b\\');\\n}\\n'",
        "'try_pyarr_from_unsigned_char'] = 'static int try_pyarr_from_unsigned_char(PyObject* obj,unsigned_char* v)"
    ],
    [
        "'try_pyarr_from_short'] = 'static int try_pyarr_from_short(PyObject* obj,short* v) {\\n    TRYPYARRAYTEMPLATE(short,\\'s\\');\\n}\\n'",
        "'try_pyarr_from_short'] = 'static int try_pyarr_from_short(PyObject*"
    ],
    [
        "'try_pyarr_from_int'] = 'static int try_pyarr_from_int(PyObject* obj,int* v) {\\n    TRYPYARRAYTEMPLATE(int,\\'i\\');\\n}\\n'",
        "'try_pyarr_from_int'] = 'static int try_pyarr_from_int(PyObject* obj,int* v)"
    ],
    [
        "'try_pyarr_from_long'] = 'static int try_pyarr_from_long(PyObject* obj,long* v) {\\n    TRYPYARRAYTEMPLATE(long,\\'l\\');\\n}\\n'",
        "'try_pyarr_from_long'] = 'static int try_pyarr_from_long(PyObject* obj,long*"
    ],
    [
        "'try_pyarr_from_long_long'] = 'static int try_pyarr_from_long_long(PyObject* obj,long_long* v) {\\n    TRYPYARRAYTEMPLATE(long_long,\\'L\\');\\n}\\n'",
        "'try_pyarr_from_long_long'] = 'static int try_pyarr_from_long_long(PyObject* obj,long_long*"
    ],
    [
        "'try_pyarr_from_float'] = 'static int try_pyarr_from_float(PyObject* obj,float* v) {\\n    TRYPYARRAYTEMPLATE(float,\\'f\\');\\n}\\n'",
        "'try_pyarr_from_float'] = 'static int try_pyarr_from_float(PyObject* obj,float* v)"
    ],
    [
        "'try_pyarr_from_double'] = 'static int try_pyarr_from_double(PyObject* obj,double* v) {\\n    TRYPYARRAYTEMPLATE(double,\\'d\\');\\n}\\n'",
        "'try_pyarr_from_double'] = 'static int try_pyarr_from_double(PyObject* obj,double* v) {\\n"
    ],
    [
        "'try_pyarr_from_complex_float'] = 'static int try_pyarr_from_complex_float(PyObject* obj,complex_float* v) {\\n    TRYCOMPLEXPYARRAYTEMPLATE(float,\\'F\\');\\n}\\n'",
        "'try_pyarr_from_complex_float'] = 'static int try_pyarr_from_complex_float(PyObject* obj,complex_float* v) {\\n"
    ],
    [
        "'try_pyarr_from_complex_double'] = 'static int try_pyarr_from_complex_double(PyObject* obj,complex_double* v) {\\n    TRYCOMPLEXPYARRAYTEMPLATE(double,\\'D\\');\\n}\\n'",
        "'try_pyarr_from_complex_double'] = 'static int try_pyarr_from_complex_double(PyObject* obj,complex_double* v) {\\n"
    ],
    [
        "create_cb_arglist(PyObject* fun, PyTupleObject* xa , const int maxnofargs,",
        "create_cb_arglist(PyObject* fun, PyTupleObject* xa , const int"
    ],
    [
        "const int nofoptargs, int *nofargs, PyTupleObject **args,",
        "const int nofoptargs, int"
    ],
    [
        "/* Get the total number of arguments */",
        "/* Get the total number of"
    ],
    [
        "tmp_fun = fun; /* built-in function */",
        "tmp_fun = fun; /* built-in function"
    ],
    [
        "/* In case the function has a co_argcount (like on PyPy) */",
        "/* In case the function has"
    ],
    [
        "fprintf(stderr,\\\"extra arguments tuple cannot be used with PyCapsule call-back\\\\n\\\");",
        "fprintf(stderr,\\\"extra arguments tuple cannot be"
    ],
    [
        "((fun == NULL) ? \\\"NULL\\\" : Py_TYPE(fun)->tp_name));",
        "((fun == NULL) ? \\\"NULL\\\" :"
    ],
    [
        "/* Get the number of optional arguments */",
        "/* Get the number"
    ],
    [
        "/* Get the number of extra arguments */",
        "/* Get the number of"
    ],
    [
        "/* Calculate the size of call-backs argument list */",
        "/* Calculate the size of call-backs"
    ],
    [
        "\\\"tot,opt,ext,siz,nofargs = %d(-%d), %zd, %zd, %zd, %zd, %d\\\\n\\\",",
        "\\\"tot,opt,ext,siz,nofargs = %d(-%d), %zd, %zd,"
    ],
    [
        "maxnofargs, nofoptargs, tot, opt, ext, siz, *nofargs);",
        "maxnofargs, nofoptargs, tot, opt, ext, siz,"
    ],
    [
        "\\\"create_cb_arglist: Failed to build argument list \\\"",
        "\\\"create_cb_arglist: Failed to build argument list"
    ],
    [
        "\\\"(siz) with enough arguments (tot-opt) required by \\\"",
        "\\\"(siz) with enough arguments (tot-opt)"
    ],
    [
        "errmess('append_needs: unknown need %s\\n' % (repr(need)))",
        "errmess('append_needs: unknown need %s\\n'"
    ],
    [
        "errmess('append_needs: expected list or string but got :%s\\n' %",
        "errmess('append_needs: expected list or string but got"
    ],
    [
        "'get_needs: no progress in sorting needs, probably circular dependence, skipping.\\n')",
        "'get_needs: no progress in sorting needs, probably circular"
    ],
    [
        "takes templated file .xxx.src and produces .xxx file where .xxx",
        "takes templated file .xxx.src and produces .xxx file"
    ],
    [
        "All function and subroutine blocks in a source file with names that",
        "All function and subroutine blocks in a source"
    ],
    [
        "contain '<..>' will be replicated according to the rules in '<..>'.",
        "contain '<..>' will be replicated according"
    ],
    [
        "The number of comma-separated words in '<..>' will determine the number of",
        "The number of comma-separated words in '<..>' will determine"
    ],
    [
        "'<..>' may have two different forms, named and short. For example,",
        "'<..>' may have two different forms, named and"
    ],
    [
        "<p=d,s,z,c> where anywhere inside a block '<p>' will be replaced with",
        "<p=d,s,z,c> where anywhere inside a block '<p>' will"
    ],
    [
        "'d', 's', 'z', and 'c' for each replicate of the block.",
        "'d', 's', 'z', and 'c' for"
    ],
    [
        "<_t>  is already defined: <_t=real,double precision,complex,double complex>",
        "<_t> is already defined: <_t=real,double precision,complex,double"
    ],
    [
        "<s,d,c,z>, a short form of the named, useful when no <p> appears inside",
        "<s,d,c,z>, a short form of the named,"
    ],
    [
        "In general, '<..>' contains a comma separated list of arbitrary",
        "In general, '<..>' contains a comma separated list of"
    ],
    [
        "expressions. If these expression must contain a comma|leftarrow|rightarrow,",
        "expressions. If these expression must"
    ],
    [
        "then prepend the comma|leftarrow|rightarrow with a backslash.",
        "then prepend the comma|leftarrow|rightarrow with"
    ],
    [
        "If an expression matches '\\\\<index>' then it will be replaced",
        "If an expression matches '\\\\<index>'"
    ],
    [
        "Note that all '<..>' forms in a block must have the same number of",
        "Note that all '<..>' forms in a block must"
    ],
    [
        "\"\"\" Return a list of tuples for each function or subroutine each",
        "\"\"\" Return a list of tuples for"
    ],
    [
        "tuple is the start and end of a subroutine or function to be",
        "tuple is the start and end of a subroutine or"
    ],
    [
        "l = [x.strip() for x in b]",
        "l = [x.strip() for x"
    ],
    [
        "\"\"\" Obtain a unique key given a dictionary.\"\"\"",
        "\"\"\" Obtain a unique"
    ],
    [
        "raise ValueError('No replicates found for <%s>' % (r))",
        "raise ValueError('No replicates found"
    ],
    [
        "if r not in names and not thelist.startswith('_'):",
        "if r not in names and"
    ],
    [
        "rule = [i.replace('@comma@', ',') for i in thelist.split(',')]",
        "rule = [i.replace('@comma@', ',') for i"
    ],
    [
        "print(\"Mismatch in number of replacements (base <{}={}>) \"",
        "print(\"Mismatch in number of replacements (base"
    ],
    [
        "\"for <{}={}>. Ignoring.\".format(base_rule, ','.join(rules[base_rule]), r, thelist))",
        "\"for <{}={}>. Ignoring.\".format(base_rule,"
    ],
    [
        "newstr += template_re.sub(namerepl, substr) + '\\n\\n'",
        "newstr += template_re.sub(namerepl, substr)"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is given"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE AT YOUR OWN"
    ],
    [
        "hasbody, hascommon, hasnote, isintent_hide, outmess, getuseblocks",
        "hasbody, hascommon, hasnote, isintent_hide,"
    ],
    [
        "vars_ = {v: block['vars'][v] for v in value}",
        "vars_ = {v: block['vars'][v]"
    ],
    [
        "ret = {'commonhooks': [], 'initcommonhooks': [],",
        "ret = {'commonhooks': [],"
    ],
    [
        "for (name, vnames, vars) in findcommonblocks(m):",
        "for (name, vnames, vars)"
    ],
    [
        "outmess('\\t\\tConstructing COMMON block support for \"%s\"...\\n\\t\\t  %s\\n\\t\\t  Hidden: %s\\n' % (",
        "outmess('\\t\\tConstructing COMMON block support for \"%s\"...\\n\\t\\t %s\\n\\t\\t"
    ],
    [
        "outmess('\\t\\tConstructing COMMON block support for \"%s\"...\\n\\t\\t  %s\\n' % (",
        "outmess('\\t\\tConstructing COMMON block support for \"%s\"...\\n\\t\\t %s\\n'"
    ],
    [
        "fadd('common /%s/ %s' % (name, ','.join(vnames)))",
        "fadd('common /%s/ %s'"
    ],
    [
        "% (n, dm['rank'], dms, at, elsize))",
        "% (n, dm['rank'], dms, at,"
    ],
    [
        "iadd('\\tif (tmp == NULL) return NULL;')",
        "iadd('\\tif (tmp == NULL)"
    ],
    [
        "'\"\\t/%s/ %s\\\\n\"' % (name, ','.join(map(lambda v, d: v + d, inames, idims))))",
        "'\"\\t/%s/ %s\\\\n\"' % (name, ','.join(map(lambda v, d: v"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED."
    ],
    [
        "The following Fortran statements/constructions are supported",
        "The following Fortran statements/constructions"
    ],
    [
        "Note: 'virtual' is mapped to 'dimension'.",
        "Note: 'virtual' is mapped to"
    ],
    [
        "Note: 'implicit integer (z) static (z)' is 'implicit static (z)' (this is minor bug).",
        "Note: 'implicit integer (z) static (z)' is 'implicit static (z)'"
    ],
    [
        "Note: code after 'contains' will be ignored until its scope ends.",
        "Note: code after 'contains' will be ignored until its scope"
    ],
    [
        "Note: 'common' statement is extended: dimensions are moved to variable definitions",
        "Note: 'common' statement is extended: dimensions are"
    ],
    [
        "Note: pythonmodule is introduced to represent Python module",
        "Note: pythonmodule is introduced to"
    ],
    [
        "`postlist` contains declaration information read from the list of files `files`.",
        "`postlist` contains declaration information read from the"
    ],
    [
        "*** it is a list of dictionaries containing `blocks':",
        "*** it is a list of"
    ],
    [
        "B['block'] = 'interface' | 'function' | 'subroutine' | 'module' |",
        "B['block'] = 'interface' | 'function'"
    ],
    [
        "'program' | 'block data' | 'type' | 'pythonmodule' |",
        "'program' | 'block data' | 'type' | 'pythonmodule'"
    ],
    [
        "B['body'] --- list containing `subblocks' with the same structure as `blocks'",
        "B['body'] --- list containing `subblocks' with the same"
    ],
    [
        "B['parent_block'] --- dictionary of a parent block:",
        "B['parent_block'] --- dictionary of"
    ],
    [
        "B['vars'] --- dictionary of variable definitions",
        "B['vars'] --- dictionary"
    ],
    [
        "B['sortvars'] --- dictionary of variable definitions sorted by dependence (independent first)",
        "B['sortvars'] --- dictionary of variable definitions sorted by dependence"
    ],
    [
        "B['name'] --- name of the block (not if B['block']=='interface')",
        "B['name'] --- name of the block (not if"
    ],
    [
        "B['prefix'] --- prefix string (only if B['block']=='function')",
        "B['prefix'] --- prefix string (only if"
    ],
    [
        "B['args'] --- list of argument names if B['block']== 'function' | 'subroutine'",
        "B['args'] --- list of argument names"
    ],
    [
        "B['result'] --- name of the return value (only if B['block']=='function')",
        "B['result'] --- name of the return value (only if"
    ],
    [
        "B['implicit'] --- dictionary {'a':<variable definition>,'b':...} | None",
        "B['implicit'] --- dictionary {'a':<variable definition>,'b':...}"
    ],
    [
        "B['externals'] --- list of variables being external",
        "B['externals'] --- list of"
    ],
    [
        "B['interfaced'] --- list of variables being external and defined",
        "B['interfaced'] --- list of variables being external"
    ],
    [
        "B['common'] --- dictionary of common blocks (list of objects)",
        "B['common'] --- dictionary of common blocks (list"
    ],
    [
        "B['commonvars'] --- list of variables used in common blocks (dimensions are moved to variable definitions)",
        "B['commonvars'] --- list of variables used in common"
    ],
    [
        "B['from'] --- string showing the 'parents' of the current block",
        "B['from'] --- string showing the"
    ],
    [
        "B['use'] --- dictionary of modules used in current block:",
        "B['use'] --- dictionary of modules used"
    ],
    [
        "B['note'] --- list of LaTeX comments on the block",
        "B['note'] --- list of LaTeX comments on the"
    ],
    [
        "B['varnames'] --- list of variable names given in the order of reading the",
        "B['varnames'] --- list of variable names given"
    ],
    [
        "Fortran code, useful for derived types.",
        "Fortran code, useful"
    ],
    [
        "B['saved_interface'] --- a string of scanned routine signature, defines explicit interface",
        "B['saved_interface'] --- a string of scanned routine signature, defines explicit"
    ],
    [
        "*** Variable definition is a dictionary",
        "*** Variable definition is a"
    ],
    [
        "D['typespec'] = 'byte' | 'character' | 'complex' | 'double complex' |",
        "D['typespec'] = 'byte' | 'character' | 'complex'"
    ],
    [
        "'double precision' | 'integer' | 'logical' | 'real' | 'type'",
        "'double precision' | 'integer' | 'logical' |"
    ],
    [
        "D['attrspec'] --- list of attributes (e.g. 'dimension(<arrayspec>)',",
        "D['attrspec'] --- list of"
    ],
    [
        "K = D['kindselector'] = {['*','kind']} (only if D['typespec'] =",
        "K = D['kindselector'] = {['*','kind']} (only"
    ],
    [
        "'complex' | 'integer' | 'logical' | 'real' )",
        "'complex' | 'integer' |"
    ],
    [
        "D['typename'] --- name of the type if D['typespec']=='type'",
        "D['typename'] --- name of the type if"
    ],
    [
        "D['dimension'] --- list of dimension bounds",
        "D['dimension'] --- list of dimension"
    ],
    [
        "D['intent'] --- list of intent specifications",
        "D['intent'] --- list"
    ],
    [
        "D['depend'] --- list of variable names on which current variable depends on",
        "D['depend'] --- list of variable names on which current variable depends"
    ],
    [
        "D['check'] --- list of C-expressions; if C-expr returns zero, exception is raised",
        "D['check'] --- list of C-expressions; if C-expr returns zero, exception is"
    ],
    [
        "D['note'] --- list of LaTeX comments on the variable",
        "D['note'] --- list of LaTeX comments"
    ],
    [
        "*** Meaning of kind/char selectors (few examples):",
        "*** Meaning of kind/char selectors"
    ],
    [
        "(see also fortran type declaration statement formats below)",
        "(see also fortran type"
    ],
    [
        "type declaration = <typespec> [[<attrspec>]::] <entitydecl>",
        "type declaration = <typespec> [[<attrspec>]::]"
    ],
    [
        "<attrspec> = comma separated list of attributes.",
        "<attrspec> = comma separated list of"
    ],
    [
        "Only the following attributes are used in",
        "Only the following attributes are"
    ],
    [
        "<intentspec> = in | out | inout",
        "<intentspec> = in | out |"
    ],
    [
        "<arrayspec> = comma separated list of dimension bounds.",
        "<arrayspec> = comma separated"
    ],
    [
        "<entitydecl> = <name> [[*<charlen>][(<arrayspec>)] | [(<arrayspec>)]*<charlen>]",
        "<entitydecl> = <name> [[*<charlen>][(<arrayspec>)] |"
    ],
    [
        "In addition, the following attributes are used: check,depend,note",
        "In addition, the following attributes are used:"
    ],
    [
        "The above may be solved by creating appropriate preprocessor program, for example.",
        "The above may be solved by"
    ],
    [
        "for n in ['int', 'double', 'float', 'char', 'short', 'long', 'void', 'case', 'while',",
        "for n in ['int', 'double', 'float',"
    ],
    [
        "'return', 'signed', 'unsigned', 'if', 'for', 'typedef', 'sizeof', 'union',",
        "'return', 'signed', 'unsigned', 'if',"
    ],
    [
        "'struct', 'static', 'register', 'new', 'break', 'do', 'goto', 'switch',",
        "'struct', 'static', 'register', 'new', 'break', 'do',"
    ],
    [
        "'continue', 'else', 'inline', 'extern', 'delete', 'const', 'auto',",
        "'continue', 'else', 'inline', 'extern',"
    ],
    [
        "'len', 'rank', 'shape', 'index', 'slen', 'size', '_i',",
        "'len', 'rank', 'shape', 'index', 'slen', 'size',"
    ],
    [
        "'string', 'complex_double', 'float_double', 'stdin', 'stderr', 'stdout',",
        "'string', 'complex_double', 'float_double',"
    ],
    [
        "\"\"\"Ensures that filename is opened with correct encoding parameter.",
        "\"\"\"Ensures that filename is opened with"
    ],
    [
        "This function uses charset_normalizer package, when available, for",
        "This function uses charset_normalizer package,"
    ],
    [
        "determining the encoding of the file to be opened. When charset_normalizer",
        "determining the encoding of the file to"
    ],
    [
        "is not available, the function detects only UTF encodings, otherwise, ASCII",
        "is not available, the function detects only UTF encodings, otherwise,"
    ],
    [
        "\"\"\"Check if file is in free format Fortran.\"\"\"",
        "\"\"\"Check if file is in"
    ],
    [
        "Read fortran codes from files and",
        "Read fortran codes from"
    ],
    [
        "global beginpattern, quiet, verbose, dolowercase, include_paths",
        "global beginpattern, quiet, verbose,"
    ],
    [
        "f' failed with\\n{msg}.\\nIt is likely that installing charset_normalizer'",
        "f' failed with\\n{msg}.\\nIt is likely that installing"
    ],
    [
        "if Path(currentfilename).suffix.lower() in COMMON_FIXED_EXTENSIONS and \\",
        "if Path(currentfilename).suffix.lower() in"
    ],
    [
        "raise Exception('readfortrancode: Found non-(space,digit) char '",
        "raise Exception('readfortrancode: Found non-(space,digit)"
    ],
    [
        "'in the first column.\\n\\tAre you sure that '",
        "'in the first column.\\n\\tAre you sure"
    ],
    [
        "'this code is in fix form?\\n\\tline=%s' % repr(l))",
        "'this code is in"
    ],
    [
        "if not cont and ext == '.pyf' and mline_mark.match(l):",
        "if not cont and ext =="
    ],
    [
        "'Unexpected end of file when reading multiline\\n')",
        "'Unexpected end of file when reading"
    ],
    [
        "cont = (r is not None)",
        "cont = (r is"
    ],
    [
        "\"Flag sourcecodeform must be either 'fix' or 'free': %s\" % repr(sourcecodeform))",
        "\"Flag sourcecodeform must be either 'fix' or 'free':"
    ],
    [
        "outmess('readfortrancode: could not find include file %s in %s. Ignoring.\\n' % (",
        "outmess('readfortrancode: could not find include file %s in %s."
    ],
    [
        "outmess('readfortrancode: could not find include file %s in %s. Ignoring.\\n' % (",
        "outmess('readfortrancode: could not find include file %s in %s. Ignoring.\\n' %"
    ],
    [
        "beginpattern, quiet, verbose, dolowercase = saveglobals",
        "beginpattern, quiet, verbose, dolowercase ="
    ],
    [
        "beforethisafter % ('', fortrantypes, fortrantypes, '.*'), re.I), 'type'",
        "beforethisafter % ('', fortrantypes, fortrantypes,"
    ],
    [
        "'', fortrantypes + '|static|automatic|undefined', fortrantypes + '|static|automatic|undefined', '.*'), re.I)",
        "'', fortrantypes + '|static|automatic|undefined', fortrantypes +"
    ],
    [
        "r'([a-z]+[\\w\\s(=*+-/)]*?|)', 'function', 'function', '.*'), re.I), 'begin'",
        "r'([a-z]+[\\w\\s(=*+-/)]*?|)', 'function', 'function', '.*'),"
    ],
    [
        "r'[a-z\\s]*?', 'subroutine', 'subroutine', '.*'), re.I), 'begin'",
        "r'[a-z\\s]*?', 'subroutine', 'subroutine',"
    ],
    [
        "beforethisafter % ('', groupends, groupends, '.*'), re.I), 'end'",
        "beforethisafter % ('', groupends, groupends, '.*'), re.I),"
    ],
    [
        "beforethisafter % (r'[\\w]*?', endifs, endifs, '.*'), re.I), 'endif'",
        "beforethisafter % (r'[\\w]*?', endifs, endifs, '.*'), re.I),"
    ],
    [
        "beforethisafter % ('', moduleprocedures, moduleprocedures, '.*'), re.I), \\",
        "beforethisafter % ('', moduleprocedures, moduleprocedures, '.*'),"
    ],
    [
        "beforethisafter % ('', 'implicit', 'implicit', '.*'), re.I), 'implicit'",
        "beforethisafter % ('', 'implicit',"
    ],
    [
        "'', 'dimension|virtual', 'dimension|virtual', '.*'), re.I), 'dimension'",
        "'', 'dimension|virtual', 'dimension|virtual', '.*'), re.I),"
    ],
    [
        "beforethisafter % ('', 'external', 'external', '.*'), re.I), 'external'",
        "beforethisafter % ('', 'external', 'external', '.*'),"
    ],
    [
        "beforethisafter % ('', 'optional', 'optional', '.*'), re.I), 'optional'",
        "beforethisafter % ('', 'optional', 'optional', '.*'),"
    ],
    [
        "beforethisafter % ('', 'required', 'required', '.*'), re.I), 'required'",
        "beforethisafter % ('', 'required', 'required', '.*'), re.I),"
    ],
    [
        "beforethisafter % ('', 'public', 'public', '.*'), re.I), 'public'",
        "beforethisafter % ('', 'public', 'public',"
    ],
    [
        "beforethisafter % ('', 'private', 'private', '.*'), re.I), 'private'",
        "beforethisafter % ('', 'private',"
    ],
    [
        "beforethisafter % ('', 'intrinsic', 'intrinsic', '.*'), re.I), 'intrinsic'",
        "beforethisafter % ('', 'intrinsic', 'intrinsic', '.*'),"
    ],
    [
        "'', 'intent|depend|note|check', 'intent|depend|note|check', r'\\s*\\(.*?\\).*'), re.I), 'intent'",
        "'', 'intent|depend|note|check', 'intent|depend|note|check', r'\\s*\\(.*?\\).*'),"
    ],
    [
        "beforethisafter % ('', 'parameter', 'parameter', r'\\s*\\(.*'), re.I), 'parameter'",
        "beforethisafter % ('', 'parameter', 'parameter', r'\\s*\\(.*'), re.I),"
    ],
    [
        "beforethisafter % ('', 'data', 'data', '.*'), re.I), 'data'",
        "beforethisafter % ('', 'data',"
    ],
    [
        "beforethisafter % ('', 'call', 'call', '.*'), re.I), 'call'",
        "beforethisafter % ('', 'call', 'call', '.*'),"
    ],
    [
        "beforethisafter % ('', 'entry', 'entry', '.*'), re.I), 'entry'",
        "beforethisafter % ('', 'entry', 'entry', '.*'), re.I),"
    ],
    [
        "beforethisafter % ('', 'callfun', 'callfun', '.*'), re.I), 'callfun'",
        "beforethisafter % ('', 'callfun', 'callfun', '.*'),"
    ],
    [
        "beforethisafter % ('', 'common', 'common', '.*'), re.I), 'common'",
        "beforethisafter % ('', 'common', 'common',"
    ],
    [
        "beforethisafter % ('', 'use', 'use', '.*'), re.I), 'use'",
        "beforethisafter % ('', 'use', 'use', '.*'), re.I),"
    ],
    [
        "beforethisafter % ('', 'contains', 'contains', ''), re.I), 'contains'",
        "beforethisafter % ('', 'contains', 'contains',"
    ],
    [
        "beforethisafter % ('', 'format', 'format', '.*'), re.I), 'format'",
        "beforethisafter % ('', 'format',"
    ],
    [
        "Splits the line into (line[:i], line[i:]),",
        "Splits the line"
    ],
    [
        "where i is the index of first occurrence of one of the characters",
        "where i is the index of first occurrence of one of"
    ],
    [
        "not within quotes, or len(line) if no such index exists",
        "not within quotes, or len(line) if"
    ],
    [
        "assert not (set('\"\\'') & set(characters)), \"cannot split by unquoted quotes\"",
        "assert not (set('\"\\'') & set(characters)),"
    ],
    [
        "global beginpattern, groupcounter, groupname, groupcache, grouplist",
        "global beginpattern, groupcounter, groupname, groupcache,"
    ],
    [
        "'crackline: Mismatch of blocks encountered. Trying to fix it by assuming \"end\" statement.\\n')",
        "'crackline: Mismatch of blocks encountered. Trying to fix it by"
    ],
    [
        "for pat in [dimensionpattern, externalpattern, intentpattern, optionalpattern,",
        "for pat in [dimensionpattern,"
    ],
    [
        "if 'interfaced' in groupcache[groupcounter] and name in groupcache[groupcounter]['interfaced']:",
        "if 'interfaced' in groupcache[groupcounter] and name"
    ],
    [
        "line = 'callfun %s(%s) result (%s)' % (",
        "line = 'callfun %s(%s) result"
    ],
    [
        "line = 'callfun %s(%s)' % (name, a)",
        "line = 'callfun %s(%s)' % (name,"
    ],
    [
        "'crackline: could not resolve function call for line=%s.\\n' % repr(line))",
        "'crackline: could not resolve function call for line=%s.\\n'"
    ],
    [
        "outmess('crackline:%d: No pattern for line\\n' % (groupcounter))",
        "outmess('crackline:%d: No pattern for line\\n'"
    ],
    [
        "raise Exception('crackline: groupcounter(=%s) is nonpositive. '",
        "raise Exception('crackline: groupcounter(=%s) is nonpositive."
    ],
    [
        "raise Exception('crackline: End group %s does not match with '",
        "raise Exception('crackline: End group %s does not"
    ],
    [
        "before, after = split_by_unquoted(line, comma + '()')",
        "before, after = split_by_unquoted(line, comma +"
    ],
    [
        "l += '@' + comma + '@'",
        "l += '@' + comma"
    ],
    [
        "assert not f, repr((f, line, l))",
        "assert not f,"
    ],
    [
        "if force or k not in decl:",
        "if force or k"
    ],
    [
        "if force or k not in decl:",
        "if force or k"
    ],
    [
        "elif k in ['intent', 'check', 'dimension', 'optional',",
        "elif k in ['intent', 'check',"
    ],
    [
        "errmess('appenddecl: \"%s\" not implemented.\\n' % k)",
        "errmess('appenddecl: \"%s\" not"
    ],
    [
        "raise Exception('appenddecl: Unknown variable definition key: ' +",
        "raise Exception('appenddecl: Unknown variable definition"
    ],
    [
        "attrs = [a.lower() for a in attrs.split(',')] if attrs else []",
        "attrs = [a.lower() for a in attrs.split(',')] if attrs else"
    ],
    [
        "Reads each line in the input file in sequence and updates global vars.",
        "Reads each line in the input file in"
    ],
    [
        "Effectively reads and collects information from the input file to the",
        "Effectively reads and collects information from the"
    ],
    [
        "global variable groupcache, a dictionary containing info about each part",
        "global variable groupcache, a dictionary"
    ],
    [
        "At the end of analyzeline, information is filtered into the correct dict",
        "At the end of analyzeline, information"
    ],
    [
        "keys, but parameter values and dimensions are not yet interpreted.",
        "keys, but parameter values and"
    ],
    [
        "global groupcounter, groupname, groupcache, grouplist, filepositiontext",
        "global groupcounter, groupname,"
    ],
    [
        "if expectbegin and case not in ['begin', 'call', 'callfun', 'type'] \\",
        "if expectbegin and case not in ['begin',"
    ],
    [
        "'analyzeline: no group yet. Creating program group with name \"%s\".\\n' % newname)",
        "'analyzeline: no group yet. Creating program group with"
    ],
    [
        "if case in ['begin', 'call', 'callfun']:",
        "if case in"
    ],
    [
        "name, args, result, bindcline = _resolvenameargspattern(m.group('after'))",
        "name, args, result,"
    ],
    [
        "if block not in ['interface', 'block data', 'abstract interface']:",
        "if block not in ['interface', 'block"
    ],
    [
        "outmess('analyzeline: No name/args pattern found for line.\\n')",
        "outmess('analyzeline: No name/args pattern found for"
    ],
    [
        "'analyzeline: argument list is malformed (missing argument).\\n')",
        "'analyzeline: argument list is malformed (missing"
    ],
    [
        "block = {'call': 'subroutine', 'callfun': 'function'}[case]",
        "block = {'call':"
    ],
    [
        "if block not in ['interface', 'abstract interface']:",
        "if block not in ['interface',"
    ],
    [
        "outmess('analyzeline: Creating module block %s\\n' %",
        "outmess('analyzeline: Creating module block"
    ],
    [
        "outmess('analyzeline: Creating additional interface block (groupcounter=%s).\\n' % (",
        "outmess('analyzeline: Creating additional interface block (groupcounter=%s).\\n' %"
    ],
    [
        "name = 'unknown_' + block.replace(' ', '_')",
        "name = 'unknown_' + block.replace(' ',"
    ],
    [
        "if result and result in groupcache[groupcounter]['vars']:",
        "if result and"
    ],
    [
        "name, args, result, _ = _resolvenameargspattern(m.group('after'))",
        "name, args, result,"
    ],
    [
        "last_name = updatevars(typespec, selector, attr, edecl)",
        "last_name = updatevars(typespec,"
    ],
    [
        "elif case in ['dimension', 'intent', 'optional', 'required', 'external', 'public', 'private', 'intrinsic']:",
        "elif case in ['dimension', 'intent', 'optional', 'required', 'external', 'public',"
    ],
    [
        "if ll[i:] == '::' and 'args' in groupcache[groupcounter]:",
        "if ll[i:] == '::'"
    ],
    [
        "outmess('All arguments will have attribute %s%s\\n' %",
        "outmess('All arguments will have attribute %s%s\\n'"
    ],
    [
        "outmess('analyzeline: cannot handle multiple attributes without type specification. Ignoring %r.\\n' % (",
        "outmess('analyzeline: cannot handle multiple attributes without type specification. Ignoring"
    ],
    [
        "for e in [x.strip() for x in markoutercomma(ll).split('@,@')]:",
        "for e in [x.strip() for"
    ],
    [
        "outmess('analyzeline: no name pattern found in %s statement for %s. Skipping.\\n' % (",
        "outmess('analyzeline: no name pattern found in %s statement"
    ],
    [
        "if case in ['public', 'private'] and \\",
        "if case in ['public', 'private'] and"
    ],
    [
        "(k == 'operator' or k == 'assignment'):",
        "(k == 'operator' or k =="
    ],
    [
        "'analyzeline: missing __user__ module (could be nothing)\\n')",
        "'analyzeline: missing __user__ module (could be"
    ],
    [
        "' to %s arguments\\n' % (k, groupcache[groupcounter]['name']))",
        "' to %s arguments\\n' % (k,"
    ],
    [
        "'analyzeline: intent(callback) %s is ignored\\n' % (k))",
        "'analyzeline: intent(callback) %s is"
    ],
    [
        "' in argument list\\n' % (k))",
        "' in argument"
    ],
    [
        "if case in ['optional', 'required', 'public', 'external', 'private', 'intrinsic']:",
        "if case in ['optional', 'required', 'public', 'external', 'private',"
    ],
    [
        "k, initexpr = [x.strip() for x in e.split('=')]",
        "k, initexpr = [x.strip()"
    ],
    [
        "'analyzeline: could not extract name,expr in parameter statement \"%s\" of \"%s\"\\n' % (e, ll))",
        "'analyzeline: could not extract name,expr in parameter"
    ],
    [
        "if '=' in edecl[k] and (not edecl[k]['='] == initexpr):",
        "if '=' in edecl[k] and (not edecl[k]['='] =="
    ],
    [
        "outmess('analyzeline: Overwriting the value of parameter \"%s\" (\"%s\") with \"%s\".\\n' % (",
        "outmess('analyzeline: Overwriting the value of parameter \"%s\""
    ],
    [
        "except (SyntaxError, NameError, TypeError) as msg:",
        "except (SyntaxError, NameError,"
    ],
    [
        "errmess('analyzeline: Failed to evaluate %r. Ignoring: %s\\n'",
        "errmess('analyzeline: Failed to evaluate %r. Ignoring:"
    ],
    [
        "'analyzeline: Overwriting earlier \"implicit none\" statement.\\n')",
        "'analyzeline: Overwriting earlier \"implicit none\""
    ],
    [
        "'analyzeline: could not extract info of implicit statement part \"%s\"\\n' % (e))",
        "'analyzeline: could not extract info of implicit statement part \"%s\"\\n'"
    ],
    [
        "'analyzeline: could not extract types pattern of implicit statement part \"%s\"\\n' % (e))",
        "'analyzeline: could not extract types pattern of implicit"
    ],
    [
        "begc, endc = [x.strip() for x in r.split('-')]",
        "begc, endc = [x.strip() for x"
    ],
    [
        "'analyzeline: expected \"<char>-<char>\" instead of \"%s\" in range list of implicit statement\\n' % r)",
        "'analyzeline: expected \"<char>-<char>\" instead of \"%s\" in"
    ],
    [
        "if c == '/' and fc:",
        "if c == '/'"
    ],
    [
        "outmess('analyzeline: implied-DO list \"%s\" is not supported. Skipping.\\n' % v)",
        "outmess('analyzeline: implied-DO list \"%s\" is not"
    ],
    [
        "new_val = \"(/{}/)\".format(\", \".join(matches)) if vdim else matches[idx]",
        "new_val = \"(/{}/)\".format(\", \".join(matches)) if vdim"
    ],
    [
        "if any(\"*\" in m for m in matches):",
        "if any(\"*\" in m"
    ],
    [
        "new_val = \"(/{}/)\".format(\", \".join(matches)) if vdim else matches[idx]",
        "new_val = \"(/{}/)\".format(\", \".join(matches)) if vdim"
    ],
    [
        "if current_val and (current_val != new_val):",
        "if current_val and (current_val !="
    ],
    [
        "outmess('analyzeline: changing init expression of \"%s\" (\"%s\") to \"%s\"\\n' % (v, current_val, new_val))",
        "outmess('analyzeline: changing init expression of \"%s\" (\"%s\") to \"%s\"\\n' % (v, current_val,"
    ],
    [
        "if 'list' in mm and mm['list'] is not None:",
        "if 'list' in mm and mm['list'] is not"
    ],
    [
        "if 'notonly' in mm and mm['notonly'] is None:",
        "if 'notonly' in mm and mm['notonly'] is"
    ],
    [
        "ll = [x.strip() for x in mm['list'].split(',')]",
        "ll = [x.strip() for"
    ],
    [
        "'analyzeline: Not local=>use pattern found in %s\\n' % repr(l))",
        "'analyzeline: Not local=>use pattern found in"
    ],
    [
        "outmess('analyzeline: Could not crack the use statement.\\n')",
        "outmess('analyzeline: Could not crack the"
    ],
    [
        "if m.group('this') == 'usercode' and 'usercode' in d:",
        "if m.group('this') == 'usercode' and 'usercode' in"
    ],
    [
        "outmess('analyzeline: No context for multiline block.\\n')",
        "outmess('analyzeline: No context for multiline"
    ],
    [
        "outmess('analyzeline: No code implemented for line.\\n')",
        "outmess('analyzeline: No code"
    ],
    [
        "if typespec in ['complex', 'integer', 'logical', 'real', 'character', 'type']:",
        "if typespec in ['complex', 'integer', 'logical',"
    ],
    [
        "if (expr[i] == ' ' and",
        "if (expr[i] == '"
    ],
    [
        "The function replace all spaces in the input variable line which are",
        "The function replace all spaces in the input variable line which"
    ],
    [
        "surrounded with quotation marks, with the triplet \"@_@\".",
        "surrounded with quotation marks,"
    ],
    [
        "For instance, for the input \"a 'b c'\" the function returns \"a 'b@_@c'\"",
        "For instance, for the input \"a 'b c'\" the function returns"
    ],
    [
        "if escaped == '\\\\' and c in ['\\\\', '\\'', '\"']:",
        "if escaped == '\\\\' and c in ['\\\\', '\\'',"
    ],
    [
        "if not inside and c in ['\\'', '\"']:",
        "if not inside and c in ['\\'',"
    ],
    [
        "elif c == ' ' and inside:",
        "elif c == ' '"
    ],
    [
        "Returns last_name, the variable name without special chars, parenthesis",
        "Returns last_name, the variable name without special"
    ],
    [
        "Alters groupcache to add the name, typespec, attrspec (and possibly value)",
        "Alters groupcache to add the name, typespec, attrspec"
    ],
    [
        "kindselect, charselect, typename = cracktypespec(typespec, selector)",
        "kindselect, charselect, typename = cracktypespec(typespec,"
    ],
    [
        "attrspec = [x.strip() for x in markoutercomma(attrspec).split('@,@')]",
        "attrspec = [x.strip() for x"
    ],
    [
        "el = [x.strip() for x in markoutercomma(entitydecl).split('@,@')]",
        "el = [x.strip() for x"
    ],
    [
        "'updatevars: no name pattern found for entity=%s. Skipping.\\n' % (repr(e)))",
        "'updatevars: no name pattern found for"
    ],
    [
        "not_has_typespec = 'typespec' not in edecl",
        "not_has_typespec = 'typespec' not in"
    ],
    [
        "elif typespec and (not typespec == edecl['typespec']):",
        "elif typespec and (not"
    ],
    [
        "outmess('updatevars: attempt to change the type of \"%s\" (\"%s\") to \"%s\". Ignoring.\\n' % (",
        "outmess('updatevars: attempt to change the type of \"%s\" (\"%s\")"
    ],
    [
        "if k in edecl['kindselector'] and (not kindselect[k] == edecl['kindselector'][k]):",
        "if k in edecl['kindselector'] and (not"
    ],
    [
        "outmess('updatevars: attempt to change the kindselector \"%s\" of \"%s\" (\"%s\") to \"%s\". Ignoring.\\n' % (",
        "outmess('updatevars: attempt to change the kindselector \"%s\" of \"%s\" (\"%s\") to \"%s\". Ignoring.\\n'"
    ],
    [
        "if 'charselector' not in edecl and charselect:",
        "if 'charselector' not in"
    ],
    [
        "errmess('updatevars:%s: attempt to change empty charselector to %r. Ignoring.\\n'",
        "errmess('updatevars:%s: attempt to change empty charselector to %r."
    ],
    [
        "if k in edecl['charselector'] and (not charselect[k] == edecl['charselector'][k]):",
        "if k in edecl['charselector'] and (not charselect[k]"
    ],
    [
        "outmess('updatevars: attempt to change the charselector \"%s\" of \"%s\" (\"%s\") to \"%s\". Ignoring.\\n' % (",
        "outmess('updatevars: attempt to change the charselector \"%s\" of"
    ],
    [
        "elif typename and (not edecl['typename'] == typename):",
        "elif typename and (not edecl['typename'] =="
    ],
    [
        "outmess('updatevars: attempt to change the typename of \"%s\" (\"%s\") to \"%s\". Ignoring.\\n' % (",
        "outmess('updatevars: attempt to change the typename of \"%s\" (\"%s\") to \"%s\"."
    ],
    [
        "if 'external' in (edecl.get('attrspec') or []) and e in groupcache[groupcounter]['args']:",
        "if 'external' in (edecl.get('attrspec') or []) and e in"
    ],
    [
        "for lk in ['len', 'array', 'init']:",
        "for lk in"
    ],
    [
        "if ('charselector' not in edecl) or (not edecl['charselector']):",
        "if ('charselector' not in edecl) or (not"
    ],
    [
        "errmess('updatevars: \"%s %s\" is mapped to \"%s %s(%s)\"\\n' % (",
        "errmess('updatevars: \"%s %s\" is mapped"
    ],
    [
        "if typespec in ['complex', 'integer', 'logical', 'real']:",
        "if typespec in ['complex', 'integer',"
    ],
    [
        "if ('kindselector' not in edecl) or (not edecl['kindselector']):",
        "if ('kindselector' not in edecl) or"
    ],
    [
        "if ('charselector' not in edecl) or (not edecl['charselector']):",
        "if ('charselector' not in"
    ],
    [
        "outmess('updatevars: attempt to change the init expression of \"%s\" (\"%s\") to \"%s\". Ignoring.\\n' % (",
        "outmess('updatevars: attempt to change the init expression of \"%s\""
    ],
    [
        "if 'attrspec' not in edecl or (not edecl['attrspec']):",
        "if 'attrspec' not in edecl or (not"
    ],
    [
        "errmess('updatevars:%s: attempt to change %r to %r. Ignoring.\\n'",
        "errmess('updatevars:%s: attempt to change"
    ],
    [
        "outmess('updatevars: could not crack entity declaration \"%s\". Ignoring.\\n' % (",
        "outmess('updatevars: could not crack entity"
    ],
    [
        "if typespec in ['complex', 'integer', 'logical', 'real']:",
        "if typespec in ['complex',"
    ],
    [
        "'cracktypespec: no kindselector pattern found for %s\\n' % (repr(selector)))",
        "'cracktypespec: no kindselector pattern found for"
    ],
    [
        "'cracktypespec: no charselector pattern found for %s\\n' % (repr(selector)))",
        "'cracktypespec: no charselector pattern found for %s\\n' %"
    ],
    [
        "outmess('cracktypespec: no typename found in %s\\n' %",
        "outmess('cracktypespec: no typename found in"
    ],
    [
        "outmess('cracktypespec: no selector used for %s\\n' %",
        "outmess('cracktypespec: no selector used for %s\\n'"
    ],
    [
        "if attr == 'static' and 'automatic' not in decl['attrspec']:",
        "if attr == 'static' and"
    ],
    [
        "elif attr == 'automatic' and 'static' not in decl['attrspec']:",
        "elif attr == 'automatic' and"
    ],
    [
        "if force or k not in decl['kindselector']:",
        "if force or k not in"
    ],
    [
        "if force or k not in decl['charselector']:",
        "if force or k"
    ],
    [
        "filepositiontext = 'In: %s:%s\\n' % (block['from'], block['name'])",
        "filepositiontext = 'In: %s:%s\\n'"
    ],
    [
        "outmess('get_useparameters: no module %s info used by %s\\n' %",
        "outmess('get_useparameters: no module %s info"
    ],
    [
        "errmess('get_useparameters: mapping for %s not impl.\\n' % (mapping))",
        "errmess('get_useparameters: mapping for %s not"
    ],
    [
        "' value from module %s\\n' % (repr(k), repr(usename)))",
        "' value from module %s\\n' % (repr(k),"
    ],
    [
        "if param_map is not None and 'vars' in block:",
        "if param_map is not None and 'vars' in"
    ],
    [
        "determine expression types if in argument list",
        "determine expression types if"
    ],
    [
        "g = postcrack(g, tab=tab + '\\t')",
        "g = postcrack(g, tab=tab +"
    ],
    [
        "if 'name' in g and '__user__' in g['name']:",
        "if 'name' in g and '__user__'"
    ],
    [
        "if not isinstance(block, dict) and 'block' not in block:",
        "if not isinstance(block, dict) and 'block' not"
    ],
    [
        "raise Exception('postcrack: Expected block dictionary instead of ' +",
        "raise Exception('postcrack: Expected block dictionary instead of"
    ],
    [
        "if 'name' in block and not block['name'] == 'unknown_interface':",
        "if 'name' in block and not block['name']"
    ],
    [
        "while '%s_%i' % (mname, i) in userisdefined:",
        "while '%s_%i' % (mname, i) in"
    ],
    [
        "mname = '%s_%i' % (mname, i)",
        "mname = '%s_%i'"
    ],
    [
        "interface = {'block': 'interface', 'body': [],",
        "interface = {'block': 'interface', 'body':"
    ],
    [
        "'vars': {}, 'name': name + '_user_interface'}",
        "'vars': {}, 'name': name +"
    ],
    [
        "if 'name' in bb and bb['name'] == e:",
        "if 'name' in bb"
    ],
    [
        "if e in mvars and not isexternal(mvars[e]):",
        "if e in mvars and"
    ],
    [
        "mblock = {'block': 'python module', 'body': [",
        "mblock = {'block': 'python module', 'body':"
    ],
    [
        "interface], 'vars': {}, 'name': mname, 'interfaced': block['externals']}",
        "interface], 'vars': {}, 'name': mname,"
    ],
    [
        "if 'depend' in vars[v] and vars[v]['depend']:",
        "if 'depend' in vars[v]"
    ],
    [
        "errmess('sortvarnames: failed to compute dependencies because'",
        "errmess('sortvarnames: failed to compute"
    ],
    [
        "' of cyclic dependencies between '",
        "' of cyclic dependencies between"
    ],
    [
        "'analyzecommon: failed to extract \"<name>[(<dims>)]\" from \"%s\" in common /%s/.\\n' % (e, k))",
        "'analyzecommon: failed to extract \"<name>[(<dims>)]\" from \"%s\" in common /%s/.\\n' %"
    ],
    [
        "if 'attrspec' not in value or 'public' not in value['attrspec']",
        "if 'attrspec' not in value or"
    ],
    [
        "if args is not None and b['name'] not in args:",
        "if args is not None and b['name'] not"
    ],
    [
        "if onlyfuncs and b['name'] not in onlyfuncs:",
        "if onlyfuncs and b['name']"
    ],
    [
        "b = postcrack(b, as_, tab=tab + '\\t')",
        "b = postcrack(b, as_, tab=tab"
    ],
    [
        "if b['block'] in ['interface', 'abstract interface'] and \\",
        "if b['block'] in ['interface', 'abstract interface']"
    ],
    [
        "if b['block'].replace(' ', '') == 'pythonmodule':",
        "if b['block'].replace(' ',"
    ],
    [
        "'buildimplicitrules: no implicit rules for routine %s.\\n' % repr(block['name']))",
        "'buildimplicitrules: no implicit rules for routine"
    ],
    [
        "if block['implicit'][k].get('typespec') not in ['static', 'automatic']:",
        "if block['implicit'][k].get('typespec') not in"
    ],
    [
        "\"\"\" Like `eval` but returns only integers and floats \"\"\"",
        "\"\"\" Like `eval` but returns only integers and"
    ],
    [
        "Obtain ``a`` and ``b`` when ``e == \"a*x+b\"``, where ``x`` is a symbol in",
        "Obtain ``a`` and ``b`` when ``e == \"a*x+b\"``, where ``x`` is a symbol"
    ],
    [
        "This can be tricked by sufficiently complex expressions",
        "This can be tricked by sufficiently"
    ],
    [
        "if re.search(r'\\w\\s*\\([^)]*\\b' + x + r'\\b', e):",
        "if re.search(r'\\w\\s*\\([^)]*\\b' + x + r'\\b',"
    ],
    [
        "a = myeval(ee, {}, {}) - b",
        "a = myeval(ee, {}, {})"
    ],
    [
        "if '=' in vars[name] and not isstring(vars[name]):",
        "if '=' in vars[name] and"
    ],
    [
        "if word not in words and word in vars and word != name:",
        "if word not in words and word in vars and word"
    ],
    [
        "for w in deps.get(word, []) \\",
        "for w in"
    ],
    [
        "outmess('_get_depend_dict: no dependence info for %s\\n' % (repr(name)))",
        "outmess('_get_depend_dict: no dependence info"
    ],
    [
        "new_lst = [n for n in lst if n in depend_dict]",
        "new_lst = [n for n in lst if n in"
    ],
    [
        "return [name for name in names if name in vars]",
        "return [name for name in names if name in"
    ],
    [
        "return 'kind(' + string + ')'",
        "return 'kind(' +"
    ],
    [
        "for name, func in [('kind', _kind_func),",
        "for name, func in"
    ],
    [
        "if 'attrspec' in vars[n] and 'parameter' in vars[n]['attrspec']:",
        "if 'attrspec' in vars[n] and 'parameter' in"
    ],
    [
        "v = v.replace('_' + vars[n]['kindselector']['kind'], '')",
        "v = v.replace('_' +"
    ],
    [
        "f'implement evaluation of complex expression {v}\\n')",
        "f'implement evaluation of complex"
    ],
    [
        "params[n] = param_eval(v, g_params, params, dimspec=dimspec)",
        "params[n] = param_eval(v, g_params, params,"
    ],
    [
        "outmess(f'get_parameters:parameter {n!r} does not have value?!\\n')",
        "outmess(f'get_parameters:parameter {n!r} does not have"
    ],
    [
        "if length in ['(:)', '(*)', '*']:",
        "if length in ['(:)', '(*)',"
    ],
    [
        "value = (repr if isinstance(value, str) else str)(value)",
        "value = (repr if"
    ],
    [
        "Sets correct dimension information for each variable/parameter",
        "Sets correct dimension information for"
    ],
    [
        "if block['block'] == 'function' and block['name'] not in vars:",
        "if block['block'] == 'function' and block['name']"
    ],
    [
        "for n in set(vars) | {b['name'] for b in block['body']}:",
        "for n in set(vars) | {b['name'] for"
    ],
    [
        "dep_matches[n] = re.compile(r'.*\\b%s\\b' % (v), re.I).match",
        "dep_matches[n] = re.compile(r'.*\\b%s\\b' %"
    ],
    [
        "if not ('attrspec' in vars[n] and 'external' in vars[n]['attrspec']):",
        "if not ('attrspec' in vars[n] and 'external'"
    ],
    [
        "outmess('analyzevars: typespec of variable %s is not defined in routine %s.\\n' % (",
        "outmess('analyzevars: typespec of variable %s is not defined"
    ],
    [
        "dim, intent, depend, check, note = None, None, None, None, None",
        "dim, intent, depend, check, note = None, None, None, None,"
    ],
    [
        "for c in [x.strip() for x in markoutercomma(intent).split('@,@')]:",
        "for c in [x.strip()"
    ],
    [
        "for c in rmbadname([x.strip() for x in markoutercomma(depend).split('@,@')]):",
        "for c in rmbadname([x.strip()"
    ],
    [
        "for c in [x.strip() for x in markoutercomma(check).split('@,@')]:",
        "for c in [x.strip() for x in"
    ],
    [
        "if dim and 'dimension' not in vars[n]:",
        "if dim and 'dimension' not"
    ],
    [
        "'analyzevars: could not parse dimension for '",
        "'analyzevars: could not parse"
    ],
    [
        "dim_char = ':' if d == ':' else '*'",
        "dim_char = ':' if d == ':' else"
    ],
    [
        "return (s - b) / a",
        "return (s - b) /"
    ],
    [
        "if 'check' not in vars[n] and 'args' in block and n in block['args']:",
        "if 'check' not in vars[n] and 'args' in block and n in"
    ],
    [
        "for v, (solver, deps) in coeffs_and_deps.items():",
        "for v, (solver,"
    ],
    [
        "if solver is not None and v not in all_deps:",
        "if solver is not None and v"
    ],
    [
        "for v, (solver, deps) in coeffs_and_deps.items():",
        "for v, (solver, deps) in"
    ],
    [
        "if ('optional' not in vars[n]['attrspec']) and \\",
        "if ('optional' not in"
    ],
    [
        "if 'result' in block and block['result'] in vars:",
        "if 'result' in block and block['result'] in"
    ],
    [
        "'analyzevars: prefix (%s) were not used\\n' % repr(block['prefix']))",
        "'analyzevars: prefix (%s) were not used\\n' %"
    ],
    [
        "if block['block'] not in ['module', 'pythonmodule', 'python module', 'block data']:",
        "if block['block'] not in ['module', 'pythonmodule', 'python module', 'block"
    ],
    [
        "if name in vars and 'intent' in vars[name]:",
        "if name in vars and 'intent'"
    ],
    [
        "Creates a dictionary of indices and values for each parameter in a",
        "Creates a dictionary of indices and values for each parameter in"
    ],
    [
        "parameter array to be evaluated later.",
        "parameter array to"
    ],
    [
        "WARNING: It is not possible to initialize multidimensional array",
        "WARNING: It is not possible to"
    ],
    [
        "Fortran initialization through array constructor requires the RESHAPE",
        "Fortran initialization through array constructor requires the"
    ],
    [
        "intrinsic function. Since the right-hand side of the parameter declaration",
        "intrinsic function. Since the right-hand side of the parameter"
    ],
    [
        "later, it is not possible to execute a reshape of a parameter array.",
        "later, it is not possible to execute a reshape of a"
    ],
    [
        "One issue remains: if the user wants to access the array parameter from",
        "One issue remains: if the user wants to"
    ],
    [
        "(which is often incompatible with the original fortran indexing)",
        "(which is often incompatible with"
    ],
    [
        "raise ValueError(f'param_eval: dimension {dimspec} can\\'t be parsed')",
        "raise ValueError(f'param_eval: dimension {dimspec} can\\'t be"
    ],
    [
        "raise ValueError('param_eval: multidimensional array parameters '",
        "raise ValueError('param_eval: multidimensional array parameters"
    ],
    [
        "Parses the declaration of an array variable or parameter",
        "Parses the declaration of an array variable or"
    ],
    [
        "`dimension` keyword, and is called recursively if the",
        "`dimension` keyword, and is called"
    ],
    [
        "dimension for this array is a previously defined parameter",
        "dimension for this array is"
    ],
    [
        "Fortran expression describing the dimension of an array.",
        "Fortran expression describing the"
    ],
    [
        "Previously parsed parameters declared in the Fortran source file.",
        "Previously parsed parameters declared in"
    ],
    [
        "* If the line being analyzed is",
        "* If the line being analyzed"
    ],
    [
        "* If the line being analyzed is",
        "* If the line being"
    ],
    [
        "then `d = 'pa'`; since `pa` is a previously parsed parameter,",
        "then `d = 'pa'`; since `pa`"
    ],
    [
        "* If the line being analyzed is",
        "* If the line"
    ],
    [
        "r'(?P<before>.*?)\\b' + p + r'\\b(?P<after>.*)', re.I",
        "r'(?P<before>.*?)\\b' + p +"
    ],
    [
        "if c not in string.ascii_lowercase + string.digits:",
        "if c not in string.ascii_lowercase"
    ],
    [
        "while a in block['vars'] or a in block['args']:",
        "while a in block['vars'] or a in"
    ],
    [
        "while a + str(k) in args:",
        "while a + str(k)"
    ],
    [
        "if 'externals' in block and orig_a in block['externals'] + block['interfaced']:",
        "if 'externals' in block and"
    ],
    [
        "if 'result' in block and block['result'] not in block['vars']:",
        "if 'result' in block and block['result'] not"
    ],
    [
        "if 'name' in m.groupdict() and m.group('name'):",
        "if 'name' in m.groupdict()"
    ],
    [
        "'determineexprtype: selected kind types not supported (%s)\\n' % repr(expr))",
        "'determineexprtype: selected kind types not supported (%s)\\n'"
    ],
    [
        "if 'name' in m.groupdict() and m.group('name'):",
        "if 'name' in"
    ],
    [
        "'determineexprtype: selected kind types not supported (%s)\\n' % repr(expr))",
        "'determineexprtype: selected kind types not supported"
    ],
    [
        "for op in ['+', '-', '*', '/']:",
        "for op in ['+', '-', '*',"
    ],
    [
        "for e in [x.strip() for x in markoutercomma(expr, comma=op).split('@' + op + '@')]:",
        "for e in [x.strip() for x in markoutercomma(expr,"
    ],
    [
        "if t and 'attrspec' in t:",
        "if t and 'attrspec'"
    ],
    [
        "return {'typespec': 'character', 'charselector': {'*': '*'}}",
        "return {'typespec': 'character', 'charselector':"
    ],
    [
        "'determineexprtype: could not determine expressions (%s) type.\\n' % (repr(expr)))",
        "'determineexprtype: could not determine expressions (%s)"
    ],
    [
        "if g and g['block'] in ['function', 'subroutine']:",
        "if g and g['block']"
    ],
    [
        "if onlyfuncs and g['name'] not in onlyfuncs:",
        "if onlyfuncs and g['name'] not in"
    ],
    [
        "if block['block'] == 'function' or argsl:",
        "if block['block'] == 'function' or"
    ],
    [
        "if blocktype == 'function' and 'callback' in intent_lst:",
        "if blocktype == 'function' and 'callback'"
    ],
    [
        "result = ' result (%s)' % block['result']",
        "result = ' result (%s)' %"
    ],
    [
        "block, block['vars'], argsl, tab + tabchar, as_interface=as_interface)",
        "block, block['vars'], argsl, tab +"
    ],
    [
        "if 'from' in block and not as_interface:",
        "if 'from' in block and"
    ],
    [
        "mess = '! in %s' % block['from']",
        "mess = '! in"
    ],
    [
        "% (entry_stmts, tab + tabchar, k, ','.join(i))",
        "% (entry_stmts, tab + tabchar,"
    ],
    [
        "if blocktype == 'block data' and name == '_BLOCK_DATA_':",
        "if blocktype == 'block data' and name"
    ],
    [
        "ret = '%s%s%s %s%s%s %s%s%s%s%s%s%send %s %s' % (",
        "ret = '%s%s%s %s%s%s %s%s%s%s%s%s%send %s"
    ],
    [
        "ret = '%s%scommon %s' % (ret, tab, ','.join(common[k]))",
        "ret = '%s%scommon %s'"
    ],
    [
        "ret = '%s%scommon /%s/ %s' % (ret, tab, k, ','.join(common[k]))",
        "ret = '%s%scommon /%s/ %s'"
    ],
    [
        "ret = '%s%suse %s,' % (ret, tab, m)",
        "ret = '%s%suse %s,' % (ret, tab,"
    ],
    [
        "if 'only' in use[m] and use[m]['only']:",
        "if 'only' in use[m] and"
    ],
    [
        "ret = '%s only:' % (ret)",
        "ret = '%s only:' %"
    ],
    [
        "if 'map' in use[m] and use[m]['map']:",
        "if 'map' in use[m]"
    ],
    [
        "ret = '%s%s%s' % (ret, c, k)",
        "ret = '%s%s%s' % (ret,"
    ],
    [
        "ret = '%s%s%s=>%s' % (ret, c, k, use[m]['map'][k])",
        "ret = '%s%s%s=>%s' %"
    ],
    [
        "if d in vars and 'depend' in vars[d] and a in vars[d]['depend']:",
        "if d in vars and 'depend' in vars[d] and a"
    ],
    [
        "if 'externals' in block and a in block['externals']:",
        "if 'externals' in block and a in"
    ],
    [
        "ret = '%s%sintent(callback) %s' % (ret, tab, a)",
        "ret = '%s%sintent(callback) %s' %"
    ],
    [
        "ret = '%s%sexternal %s' % (ret, tab, a)",
        "ret = '%s%sexternal %s' % (ret, tab,"
    ],
    [
        "ret = '%s%soptional %s' % (ret, tab, a)",
        "ret = '%s%soptional %s' % (ret, tab,"
    ],
    [
        "if a in vars and 'typespec' not in vars[a]:",
        "if a in vars and"
    ],
    [
        "if a == b['name'] and b['block'] == 'function':",
        "if a == b['name']"
    ],
    [
        "if block['block'] != 'function' or block.get('result'):",
        "if block['block'] !="
    ],
    [
        "if 'attrspec' in vars[a] and 'external' in vars[a]['attrspec']:",
        "if 'attrspec' in vars[a] and"
    ],
    [
        "ret = '%s%sexternal %s' % (ret, tab, a)",
        "ret = '%s%sexternal %s' % (ret, tab,"
    ],
    [
        "if vardef == 'type' and 'typename' in vars[a]:",
        "if vardef == 'type' and 'typename' in"
    ],
    [
        "vardef = '%s(%s)' % (vardef, vars[a]['typename'])",
        "vardef = '%s(%s)'"
    ],
    [
        "vardef = '%s*(%s)' % (vardef, selector['*'])",
        "vardef = '%s*(%s)'"
    ],
    [
        "vardef = '%s*%s' % (vardef, selector['*'])",
        "vardef = '%s*%s' %"
    ],
    [
        "vardef = '%s(len=%s' % (vardef, selector['len'])",
        "vardef = '%s(len=%s' %"
    ],
    [
        "vardef = '%s,kind=%s)' % (vardef, selector['kind'])",
        "vardef = '%s,kind=%s)'"
    ],
    [
        "vardef = '%s(kind=%s)' % (vardef, selector['kind'])",
        "vardef = '%s(kind=%s)'"
    ],
    [
        "attr = [l for l in vars[a]['attrspec']",
        "attr = [l for l"
    ],
    [
        "if as_interface and 'intent(in)' in attr and 'intent(out)' in attr:",
        "if as_interface and 'intent(in)' in attr"
    ],
    [
        "vardef = '%s, %s' % (vardef, ','.join(attr))",
        "vardef = '%s, %s'"
    ],
    [
        "vardef = '%s%sintent(%s)' % (vardef, c, ','.join(lst))",
        "vardef = '%s%sintent(%s)' %"
    ],
    [
        "vardef = '%s%scheck(%s)' % (vardef, c, ','.join(vars[a]['check']))",
        "vardef = '%s%scheck(%s)' % (vardef,"
    ],
    [
        "if vars[a]['typespec'] in ['complex', 'double complex']:",
        "if vars[a]['typespec'] in ['complex',"
    ],
    [
        "v = '(%s,%s)' % (v.real, v.imag)",
        "v = '(%s,%s)'"
    ],
    [
        "vardef = '%s :: %s=%s' % (vardef, a, v)",
        "vardef = '%s :: %s=%s' %"
    ],
    [
        "vardef = '%s :: %s' % (vardef, a)",
        "vardef = '%s ::"
    ],
    [
        "ret = '%s%s%s' % (ret, tab, vardef)",
        "ret = '%s%s%s' % (ret, tab,"
    ],
    [
        "! Note: the context of this file is case sensitive.",
        "! Note: the context of this file is"
    ],
    [
        "return header + pyf + footer",
        "return header +"
    ],
    [
        "def traverse(obj, visit, parents=[], result=None, *args, **kwargs):",
        "def traverse(obj, visit, parents=[], result=None, *args,"
    ],
    [
        "def visit(item, parents, result, *args, **kwargs):",
        "def visit(item, parents, result, *args,"
    ],
    [
        "return value of the visit function.",
        "return value of the visit"
    ],
    [
        "The return value of visit must be None, or of the same kind as",
        "The return value of visit must be None,"
    ],
    [
        "If new_index or new_value is None, the return value of visit",
        "If new_index or new_value is None, the return"
    ],
    [
        "is ignored, that is, it will not be added to the result.",
        "is ignored, that is, it will not be"
    ],
    [
        "If the return value is None, the content of obj will be",
        "If the return value is None,"
    ],
    [
        "new_result = visit(obj, parents, result, *args, **kwargs)",
        "new_result = visit(obj, parents, result, *args,"
    ],
    [
        "new_index, new_item = traverse((index, value), visit,",
        "new_index, new_item = traverse((index,"
    ],
    [
        "new_key, new_value = traverse((key, value), visit,",
        "new_key, new_value = traverse((key,"
    ],
    [
        "\"\"\"Previously, Fortran character was incorrectly treated as",
        "\"\"\"Previously, Fortran character was incorrectly treated"
    ],
    [
        "variables in `check`, `dimension`, `=`, and `callstatement`",
        "variables in `check`, `dimension`, `=`, and"
    ],
    [
        "The usage of `char*` in `callprotoargument` expression can be left",
        "The usage of `char*` in `callprotoargument` expression"
    ],
    [
        "unchanged because C `character` is C typedef of `char`, although,",
        "unchanged because C `character` is"
    ],
    [
        "new implementations should use `character*` in the corresponding",
        "new implementations should use `character*`"
    ],
    [
        "value = re.sub(r'[*]\\s*\\b' + varname + r'\\b', varname, value)",
        "value = re.sub(r'[*]\\s*\\b' + varname"
    ],
    [
        "r'(?<![&])\\b' + varname + r'\\b', '&' + varname, new_value)",
        "r'(?<![&])\\b' + varname + r'\\b', '&'"
    ],
    [
        "module blocks but then you should use flag -skipemptyends and also",
        "module blocks but then you should use flag -skipemptyends"
    ],
    [
        "be sure that the files do not contain programs without program",
        "be sure that the files do"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE AT"
    ],
    [
        "applyrules, debugcapi, dictappend, errmess, getargs, hasnote, isarray,",
        "applyrules, debugcapi, dictappend, errmess, getargs, hasnote,"
    ],
    [
        "isstringfunction, issubroutine, l_and, l_not, l_or, outmess, replace,",
        "isstringfunction, issubroutine, l_and, l_not, l_or, outmess,"
    ],
    [
        "if (capi_arglist_list == NULL) goto capi_fail;",
        "if (capi_arglist_list =="
    ],
    [
        "'args': ',', 'optargs': '', 'pyobjfrom': '\\n', 'freemem': '\\n',",
        "'args': ',', 'optargs': '', 'pyobjfrom': '\\n',"
    ],
    [
        "'decl': '/*decl*/', 'pyobjfrom': '/*pyobjfrom*/', 'frompyobj': '/*frompyobj*/',",
        "'decl': '/*decl*/', 'pyobjfrom':"
    ],
    [
        "'args': [], 'optargs': '', 'return': '', 'strarglens': '', 'freemem': '/*freemem*/',",
        "'args': [], 'optargs': '', 'return':"
    ],
    [
        "'args_td': [], 'optargs_td': '', 'strarglens_td': '',",
        "'args_td': [], 'optargs_td': '',"
    ],
    [
        "'args_nm': [], 'optargs_nm': '', 'strarglens_nm': '',",
        "'args_nm': [], 'optargs_nm': '',"
    ],
    [
        "'docreturn': '', 'docsign': '', 'docsignopt': '',",
        "'docreturn': '', 'docsign': '',"
    ],
    [
        "throw_error('intent(c,out) is forbidden for callback scalar arguments')):",
        "throw_error('intent(c,out) is forbidden for"
    ],
    [
        "/* tmp_arr will be inserted to capi_arglist_list that will be",
        "/* tmp_arr will be inserted to capi_arglist_list that will"
    ],
    [
        "destroyed when leaving callback function wrapper together",
        "destroyed when leaving callback function"
    ],
    [
        "/* tmp_arr will be inserted to capi_arglist_list that will be",
        "/* tmp_arr will be inserted to capi_arglist_list that will"
    ],
    [
        "destroyed when leaving callback function wrapper together",
        "destroyed when leaving callback"
    ],
    [
        "if ((capi_tmp = PyTuple_GetItem(capi_return,capi_i++))==NULL) goto capi_fail;",
        "if ((capi_tmp = PyTuple_GetItem(capi_return,capi_i++))==NULL)"
    ],
    [
        "if (capi_tmp != (PyObject *)rv_cb_arr) {",
        "if (capi_tmp != (PyObject *)rv_cb_arr)"
    ],
    [
        "errmess('warning: empty body for %s\\n' % (m['name']))",
        "errmess('warning: empty body for %s\\n'"
    ],
    [
        "outmess('    Constructing call-back function \"cb_%s_in_%s\"\\n' %",
        "outmess(' Constructing call-back function \"cb_%s_in_%s\"\\n'"
    ],
    [
        "if ('_check' in r and r['_check'](rout)) or ('_check' not in r):",
        "if ('_check' in r and r['_check'](rout)) or ('_check' not in"
    ],
    [
        "if '_optional' in r and isoptional(var[a]):",
        "if '_optional' in"
    ],
    [
        "if ('_check' in r and r['_check'](var[a])) or ('_check' not in r):",
        "if ('_check' in r and r['_check'](var[a]))"
    ],
    [
        "if ('_optional' not in r) or ('_optional' in r and isrequired(var[a])):",
        "if ('_optional' not in r) or ('_optional'"
    ],
    [
        "if ('_check' in r and r['_check'](var[a])) or ('_check' not in r):",
        "if ('_check' in r and r['_check'](var[a])) or"
    ],
    [
        "if ('_check' in r and r['_check'](var[a])) or ('_check' not in r):",
        "if ('_check' in r and r['_check'](var[a])) or"
    ],
    [
        "if 'args' in rd and 'optargs' in rd:",
        "if 'args' in rd"
    ],
    [
        "for k in ['docstrreq', 'docstropt', 'docstrout', 'docstrcbs']:",
        "for k in ['docstrreq',"
    ],
    [
        "if k in rd and isinstance(rd[k], list):",
        "if k in rd"
    ],
    [
        "if k in rd and isinstance(rd[k], list):",
        "if k in rd and isinstance(rd[k],"
    ],
    [
        "if not (rd.get('args') or rd.get('optargs') or rd.get('strarglens')):",
        "if not (rd.get('args') or rd.get('optargs')"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the terms",
        "Permission to use, modify, and distribute this software"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE AT YOUR OWN"
    ],
    [
        "Return the directory that contains the ``fortranobject.c`` and ``.h`` files.",
        "Return the directory that contains the ``fortranobject.c`` and"
    ],
    [
        "This function is not needed when building an extension with",
        "This function is not needed when building"
    ],
    [
        "`numpy.distutils` directly from ``.f`` and/or ``.pyf`` files",
        "`numpy.distutils` directly from ``.f``"
    ],
    [
        "``fortranobject.c`` as a source file, and include the ``fortranobject.h``",
        "``fortranobject.c`` as a source file, and include"
    ],
    [
        "header. This function can be used to obtain the directory containing",
        "header. This function can be used to obtain the directory"
    ],
    [
        "Absolute path to the directory containing ``fortranobject.c`` and",
        "Absolute path to the"
    ],
    [
        "building a Python extension using a ``.pyf`` signature file is a two-step",
        "building a Python extension using a"
    ],
    [
        "numpy.get_include : function that returns the numpy include directory",
        "numpy.get_include : function that returns"
    ],
    [
        "raise AttributeError(\"module {!r} has no attribute \"",
        "raise AttributeError(\"module {!r} has"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is given under"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE AT"
    ],
    [
        "* written by Pearu Peterson <pearu@cens.ioc.ee>.",
        "* written by Pearu"
    ],
    [
        "* Generation date: \"\"\" + time.asctime(time.gmtime(generationtime)) + \"\"\"",
        "* Generation date: \"\"\" + time.asctime(time.gmtime(generationtime))"
    ],
    [
        "* Do not edit this file directly unless you know what you are doing!!!",
        "* Do not edit this file directly unless you know what you"
    ],
    [
        "static struct PyModuleDef moduledef = {",
        "static struct PyModuleDef"
    ],
    [
        "s = PyUnicode_FromString(\\\"\"\"\" + numpy_version + \"\"\"\\\");",
        "s = PyUnicode_FromString(\\\"\"\"\" + numpy_version +"
    ],
    [
        "* Store the error object inside the dict, so that it could get deallocated.",
        "* Store the error object inside the dict, so that it"
    ],
    [
        "* (in practice, this is a module, so it likely will not and cannot.)",
        "* (in practice, this is a module, so it likely will not and"
    ],
    [
        "// signal whether this module supports running with the GIL disabled",
        "// signal whether this module supports running with the"
    ],
    [
        "PyObject * volatile capi_buildvalue = NULL;",
        "PyObject * volatile"
    ],
    [
        "'separatorsfor': {'callfortranroutine': '\\n', 'routdebugenter': '\\n', 'decl': '\\n',",
        "'separatorsfor': {'callfortranroutine': '\\n', 'routdebugenter':"
    ],
    [
        "'docstrreq': '\\n', 'docstropt': '\\n', 'docstrout': '\\n',",
        "'docstrreq': '\\n', 'docstropt':"
    ],
    [
        "'kwlist': '', 'kwlistopt': '', 'callfortran': '', 'callfortranappend': '',",
        "'kwlist': '', 'kwlistopt': '', 'callfortran': '', 'callfortranappend':"
    ],
    [
        "'docsign': '', 'docsignopt': '', 'decl': '/*decl*/',",
        "'docsign': '', 'docsignopt':"
    ],
    [
        "'args_capi': '', 'keys_capi': '', 'functype': '',",
        "'args_capi': '', 'keys_capi': '',"
    ],
    [
        "'argformat': '', 'keyformat': '', 'need_cfuncs': '',",
        "'argformat': '', 'keyformat': '', 'need_cfuncs':"
    ],
    [
        "'docreturn': '', 'return': '', 'returnformat': '', 'rformat': '',",
        "'docreturn': '', 'return': '',"
    ],
    [
        "'kwlistxa': '', 'keys_xa': '', 'xaformat': '', 'docsignxa': '', 'docsignxashort': '',",
        "'kwlistxa': '', 'keys_xa': '', 'xaformat': '',"
    ],
    [
        "'need': ['len..', {hasinitvalue: 'forcomb'}, {hasinitvalue: 'CFUNCSMESS'}],",
        "'need': ['len..', {hasinitvalue: 'forcomb'}, {hasinitvalue:"
    ],
    [
        "outmess('    Building module \"%s\"...\\n' % (m['name']))",
        "outmess(' Building module"
    ],
    [
        "if bi['block'] not in ['interface', 'abstract interface']:",
        "if bi['block'] not in ['interface',"
    ],
    [
        "'buildmodule: Could not find the body of interfaced routine \"%s\". Skipping.\\n' % (n), file=sys.stderr)",
        "'buildmodule: Could not find the body of interfaced routine \"%s\". Skipping.\\n' % (n),"
    ],
    [
        "errmess('buildmodule: unknown need %s.\\n' % (repr(k)))",
        "errmess('buildmodule: unknown need %s.\\n' %"
    ],
    [
        "if ('_check' in r and r['_check'](m)) or ('_check' not in r):",
        "if ('_check' in r and r['_check'](m)) or ('_check' not in"
    ],
    [
        "outmess('    Wrote C/API module \"%s\" to file \"%s\"\\n' % (m['name'], fn))",
        "outmess(' Wrote C/API module \"%s\" to file"
    ],
    [
        "outmess('    ReST Documentation is saved to file \"%s/%smodule.rest\"\\n' %",
        "outmess(' ReST Documentation is saved"
    ],
    [
        "outmess('    Documentation is saved to file \"%s/%smodule.tex\"\\n' %",
        "outmess(' Documentation is saved to"
    ],
    [
        "for l in ('\\n\\n'.join(funcwrappers) + '\\n').split('\\n'):",
        "for l in ('\\n\\n'.join(funcwrappers) +"
    ],
    [
        "outmess('            Constructing wrapper function \"%s.%s\"...\\n' %",
        "outmess(' Constructing wrapper"
    ],
    [
        "outmess('        Constructing wrapper function \"%s\"...\\n' % (rout['name']))",
        "outmess(' Constructing wrapper function \"%s\"...\\n'"
    ],
    [
        "if ('_check' in r and r['_check'](rout)) or ('_check' not in r):",
        "if ('_check' in r and r['_check'](rout)) or ('_check'"
    ],
    [
        "if ('_check' in r and r['_check'](var[a])) or ('_check' not in r):",
        "if ('_check' in r and r['_check'](var[a])) or ('_check' not in"
    ],
    [
        "if ('_check' in r and r['_check'](var[a])) or ('_check' not in r):",
        "if ('_check' in r and r['_check'](var[a])) or"
    ],
    [
        "for k in ['docstrreq', 'docstropt', 'docstrout', 'docstrcbs']:",
        "for k in ['docstrreq', 'docstropt', 'docstrout',"
    ],
    [
        "if k in rd and isinstance(rd[k], list):",
        "if k in rd"
    ],
    [
        "if k in rd and isinstance(rd[k], list):",
        "if k in rd and"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is given under"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED."
    ],
    [
        "Description: This program generates a Python C/API file (<modulename>module.c)",
        "Description: This program generates a Python"
    ],
    [
        "that contains wrappers for given fortran functions so that they",
        "that contains wrappers for given"
    ],
    [
        "can be called from Python. With the -c option the corresponding",
        "can be called from Python. With the -c option the"
    ],
    [
        "-h <filename>    Write signatures of the fortran routines to file <filename>",
        "-h <filename> Write signatures of the fortran"
    ],
    [
        "and exit. You can then edit <filename> and use it instead",
        "and exit. You can then edit"
    ],
    [
        "of <fortran files>. If <filename>==stdout then the",
        "of <fortran files>. If <filename>==stdout then"
    ],
    [
        "<fortran functions>  Names of fortran routines for which Python C/API",
        "<fortran functions> Names of fortran routines"
    ],
    [
        "functions will be generated. Default is all that are found",
        "functions will be generated. Default is"
    ],
    [
        "<fortran files>  Paths to fortran/signature files that will be scanned for",
        "<fortran files> Paths to fortran/signature files that will"
    ],
    [
        "<fortran functions> in order to determine their signatures.",
        "<fortran functions> in order"
    ],
    [
        "skip:            Ignore fortran functions that follow until `:'.",
        "skip: Ignore fortran functions that"
    ],
    [
        "only:            Use only fortran functions that follow until `:'.",
        "only: Use only fortran functions that"
    ],
    [
        ":                Get back to <fortran files> mode.",
        ": Get back to"
    ],
    [
        "file <modulename>module.c or extension module <modulename>.",
        "file <modulename>module.c or"
    ],
    [
        "'-include<header>'  Writes additional headers in the C wrapper, can be passed",
        "'-include<header>' Writes additional headers in the C wrapper, can be"
    ],
    [
        "--[no-]lower     Do [not] lower the cases in <fortran files>. By default,",
        "--[no-]lower Do [not] lower the cases in <fortran files>."
    ],
    [
        "--lower is assumed with -h key, and --no-lower without -h key.",
        "--lower is assumed with -h key,"
    ],
    [
        "--short-latex    Create 'incomplete' LaTeX document (without commands",
        "--short-latex Create 'incomplete' LaTeX document"
    ],
    [
        "--debug-capi     Create C/API code that reports the state of the wrappers",
        "--debug-capi Create C/API code that reports the state"
    ],
    [
        "functions. --wrap-functions is default because it ensures",
        "functions. --wrap-functions is default"
    ],
    [
        "--[no-]freethreading-compatible    Create a module that declares it does or",
        "--[no-]freethreading-compatible Create a module that declares"
    ],
    [
        "doesn't require the GIL. The default is",
        "doesn't require the GIL."
    ],
    [
        "compatibility. Inspect the Fortran code you are wrapping for",
        "compatibility. Inspect the Fortran code you"
    ],
    [
        "fortran code for thread safety issues.",
        "fortran code for thread"
    ],
    [
        "--help-link [..] List system resources found by system_info.py. See also",
        "--help-link [..] List system resources found by system_info.py."
    ],
    [
        "--link-<resource> switch below. [..] is optional list",
        "--link-<resource> switch below. [..] is"
    ],
    [
        "--skip-empty-wrappers   Only generate wrapper files when needed.",
        "--skip-empty-wrappers Only generate wrapper"
    ],
    [
        "build backend options (only effective with -c)",
        "build backend options (only effective"
    ],
    [
        "[NO_MESON] is used to indicate an option not meant to be used",
        "[NO_MESON] is used to indicate an option not meant to be"
    ],
    [
        "--fcompiler=         Specify Fortran compiler type by vendor [NO_MESON]",
        "--fcompiler= Specify Fortran compiler type by vendor"
    ],
    [
        "--compiler=          Specify distutils C compiler type [NO_MESON]",
        "--compiler= Specify distutils C"
    ],
    [
        "--help-fcompiler     List available Fortran compilers and exit [NO_MESON]",
        "--help-fcompiler List available Fortran compilers and"
    ],
    [
        "--arch=              Specify architecture specific optimization flags [NO_MESON]",
        "--arch= Specify architecture specific optimization flags"
    ],
    [
        "--noarch             Compile without arch-dependent optimization [NO_MESON]",
        "--noarch Compile without arch-dependent"
    ],
    [
        "Specify a meson dependency for the module. This may",
        "Specify a meson dependency for the module. This"
    ],
    [
        "be passed multiple times for multiple dependencies.",
        "be passed multiple times"
    ],
    [
        "Dependencies are stored in a list for further processing.",
        "Dependencies are stored in a list for further"
    ],
    [
        "This will identify \"lapack\" and \"scalapack\" as dependencies",
        "This will identify \"lapack\""
    ],
    [
        "and remove them from argv, leaving a dependencies list",
        "and remove them from argv, leaving a"
    ],
    [
        "Specify the build backend for the compilation process.",
        "Specify the build backend"
    ],
    [
        "The supported backends are 'meson' and 'distutils'.",
        "The supported backends are 'meson' and"
    ],
    [
        "If not specified, defaults to 'distutils'. On",
        "If not specified, defaults"
    ],
    [
        "Extra options (only effective with -c):",
        "Extra options (only effective with"
    ],
    [
        "--link-<resource>    Link extension module with <resource> as defined",
        "--link-<resource> Link extension module with"
    ],
    [
        "with optimized LAPACK libraries (vecLib on MacOSX,",
        "with optimized LAPACK libraries (vecLib on"
    ],
    [
        "Using the following macros may be required with non-gcc Fortran",
        "Using the following macros may"
    ],
    [
        "interface is printed out at exit (platforms: Linux).",
        "interface is printed out at exit"
    ],
    [
        "array. Integer <int> sets the threshold for array sizes when",
        "array. Integer <int> sets the"
    ],
    [
        "License:     NumPy license (see LICENSE.txt in the NumPy source code)",
        "License: NumPy license (see LICENSE.txt"
    ],
    [
        "files, skipfuncs, onlyfuncs, debug = [], [], [], []",
        "files, skipfuncs, onlyfuncs, debug = [],"
    ],
    [
        "outmess('Creating build directory %s\\n' % (buildpath))",
        "outmess('Creating build directory %s\\n' %"
    ],
    [
        "if signsfile and os.path.isfile(signsfile) and 'h-overwrite' not in options:",
        "if signsfile and os.path.isfile(signsfile) and 'h-overwrite' not"
    ],
    [
        "'Signature file \"%s\" exists!!! Use --overwrite-signature to overwrite.\\n' % (signsfile))",
        "'Signature file \"%s\" exists!!! Use --overwrite-signature to overwrite.\\n' %"
    ],
    [
        "outmess('Saving signatures to file \"%s\"\\n' % (options['signsfile']))",
        "outmess('Saving signatures to file"
    ],
    [
        "modules, mnames, isusedby = [], [], {}",
        "modules, mnames, isusedby = [],"
    ],
    [
        "for module, name in zip(modules, mnames):",
        "for module, name in"
    ],
    [
        "outmess('\\tSkipping module \"%s\" which is used by %s.\\n' % (",
        "outmess('\\tSkipping module \"%s\" which is used by %s.\\n' %"
    ],
    [
        "name, ','.join('\"%s\"' % s for s in isusedby[name])))",
        "name, ','.join('\"%s\"' % s for s"
    ],
    [
        "if u in isusedby and u in mnames:",
        "if u in isusedby and u in"
    ],
    [
        "f'\\tModule \"{name}\" uses nonexisting \"{u}\" '",
        "f'\\tModule \"{name}\" uses nonexisting \"{u}\""
    ],
    [
        "where ``<args>=string.join(<list>,' ')``, but in Python.  Unless",
        "where ``<args>=string.join(<list>,' ')``, but"
    ],
    [
        "``-h`` is used, this function returns a dictionary containing",
        "``-h`` is used, this function returns"
    ],
    [
        "information on generated modules and their dependencies on source",
        "information on generated modules and their dependencies on"
    ],
    [
        "You cannot build extension modules with this function, that is,",
        "You cannot build extension modules"
    ],
    [
        "using ``-c`` is not allowed. Use the ``compile`` command instead.",
        "using ``-c`` is not allowed. Use the ``compile``"
    ],
    [
        "pyf_files, _ = filter_files(\"\", \"[.]pyf([.]src|)\", comline_list)",
        "pyf_files, _ = filter_files(\"\", \"[.]pyf([.]src|)\","
    ],
    [
        "if plist['block'] == 'python module' and '__user__' in plist['name']:",
        "if plist['block'] == 'python module' and '__user__' in"
    ],
    [
        "f'Skipping Makefile build for module \"{plist[\"name\"]}\" '",
        "f'Skipping Makefile build for module"
    ],
    [
        "if 'python module' not in options:",
        "if 'python module' not"
    ],
    [
        "'Tip: If your original code is Fortran source then you must use -m option.\\n')",
        "'Tip: If your original code is Fortran source then you must"
    ],
    [
        "raise TypeError('All blocks must be python module blocks but got %s' % (",
        "raise TypeError('All blocks must be python module blocks but got %s' %"
    ],
    [
        "Filter files by prefix and suffix.",
        "Filter files by prefix"
    ],
    [
        "match = re.compile(prefix + r'.*' + suffix + r'\\Z').match",
        "match = re.compile(prefix + r'.*' +"
    ],
    [
        "for file in [x.strip() for x in files]:",
        "for file in [x.strip() for x"
    ],
    [
        "def __call__(self, parser, namespace, values, option_string=None):",
        "def __call__(self, parser, namespace, values,"
    ],
    [
        "include_paths_set = set(getattr(namespace, 'include_paths', []) or [])",
        "include_paths_set = set(getattr(namespace, 'include_paths', [])"
    ],
    [
        "outmess(\"Use --include-paths or -I instead of --include_paths which will be removed\")",
        "outmess(\"Use --include-paths or -I instead of --include_paths"
    ],
    [
        "if option_string == \"--include-paths\" or option_string == \"--include_paths\":",
        "if option_string == \"--include-paths\""
    ],
    [
        "if MESON_ONLY_VER and backend_key == 'distutils':",
        "if MESON_ONLY_VER and"
    ],
    [
        "Do it all in one call!",
        "Do it all"
    ],
    [
        "sys.argv = [_m for _m in sys.argv if _m not in sysinfo_flags]",
        "sys.argv = [_m for _m in sys.argv"
    ],
    [
        "if fl or a == ':':",
        "if fl or a =="
    ],
    [
        "sys.argv = [_m for _m in sys.argv if _m not in flib_flags]",
        "sys.argv = [_m for _m in"
    ],
    [
        "if not (MESON_ONLY_VER or backend_key == 'meson'):",
        "if not (MESON_ONLY_VER or backend_key"
    ],
    [
        "sys.argv = [_m for _m in sys.argv if _m not in (fc_flags + distutils_flags)]",
        "sys.argv = [_m for _m in sys.argv if _m not in (fc_flags"
    ],
    [
        "if MESON_ONLY_VER or backend_key == 'meson':",
        "if MESON_ONLY_VER or backend_key"
    ],
    [
        "\"--fcompiler cannot be used with meson,\"",
        "\"--fcompiler cannot be used"
    ],
    [
        "\"set compiler with the FC environment variable\\n\"",
        "\"set compiler with the"
    ],
    [
        "sys.argv = [_m for _m in sys.argv if _m not in setup_flags]",
        "sys.argv = [_m for _m in sys.argv if _m"
    ],
    [
        "pyf_files, _sources = filter_files(\"\", \"[.]pyf([.]src|)\", sources)",
        "pyf_files, _sources = filter_files(\"\", \"[.]pyf([.]src|)\","
    ],
    [
        "extra_objects, sources = filter_files('', '[.](o|a|so|dylib)', sources)",
        "extra_objects, sources ="
    ],
    [
        "raise ValueError(\"Only one .pyf file per call\")",
        "raise ValueError(\"Only one .pyf"
    ],
    [
        "f\"{pyff} defines {pyf_modname} to be the modulename.\\n\"",
        "f\"{pyff} defines {pyf_modname} to be"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED."
    ],
    [
        "if vardef == 'type' and 'typename' in vars[a]:",
        "if vardef == 'type' and 'typename' in"
    ],
    [
        "vardef = '%s(%s)' % (vardef, vars[a]['typename'])",
        "vardef = '%s(%s)'"
    ],
    [
        "if selector['*'] in ['*', ':', '(*)']:",
        "if selector['*'] in ['*',"
    ],
    [
        "vardef = '%s(%s=%s)' % (vardef, lk, selector['*'])",
        "vardef = '%s(%s=%s)' %"
    ],
    [
        "vardef = '%s*(%s)' % (vardef, selector['*'])",
        "vardef = '%s*(%s)' % (vardef,"
    ],
    [
        "vardef = '%s*%s' % (vardef, selector['*'])",
        "vardef = '%s*%s'"
    ],
    [
        "vardef = '%s(len=%s' % (vardef, selector['len'])",
        "vardef = '%s(len=%s'"
    ],
    [
        "vardef = '%s,kind=%s)' % (vardef, selector['kind'])",
        "vardef = '%s,kind=%s)' % (vardef,"
    ],
    [
        "vardef = '%s(kind=%s)' % (vardef, selector['kind'])",
        "vardef = '%s(kind=%s)'"
    ],
    [
        "vardef = '%s %s' % (vardef, fa)",
        "vardef = '%s %s' %"
    ],
    [
        "vardef = '%s(%s)' % (vardef, ','.join(vars[a]['dimension']))",
        "vardef = '%s(%s)' % (vardef,"
    ],
    [
        "for i, d in enumerate(v.get('dimension', [])):",
        "for i, d in"
    ],
    [
        "dv = {'typespec': 'integer', 'intent': ['hide']}",
        "dv = {'typespec': 'integer',"
    ],
    [
        "dv['='] = 'shape(%s, %s)' % (a, i)",
        "dv['='] = 'shape(%s, %s)' % (a,"
    ],
    [
        "args = [arg for arg in args if arg != name]",
        "args = [arg for arg in args if arg"
    ],
    [
        "add('use %s, only : %s' % (rout['modulename'], fortranname))",
        "add('use %s, only :"
    ],
    [
        "rl = l_tmpl.replace('@@@NAME@@@', '') + ' ' + fortranname",
        "rl = l_tmpl.replace('@@@NAME@@@', '') + ' '"
    ],
    [
        "if line.lstrip().startswith('use ') and '__user__' not in line:",
        "if line.lstrip().startswith('use ') and '__user__' not in"
    ],
    [
        "sargs = ', '.join([a for a in args if a not in extra_args])",
        "sargs = ', '.join([a for a in args if a"
    ],
    [
        "add('%s = .not.(.not.%s(%s))' % (newname, fortranname, sargs))",
        "add('%s = .not.(.not.%s(%s))' % (newname,"
    ],
    [
        "add('%s = %s(%s)' % (newname, fortranname, sargs))",
        "add('%s = %s(%s)' %"
    ],
    [
        "for i, d in enumerate(v.get('dimension', [])):",
        "for i, d in"
    ],
    [
        "dv = {'typespec': 'integer', 'intent': ['hide']}",
        "dv = {'typespec': 'integer', 'intent':"
    ],
    [
        "dv['='] = 'shape(%s, %s)' % (a, i)",
        "dv['='] = 'shape(%s, %s)' %"
    ],
    [
        "add('use %s, only : %s' % (rout['modulename'], fortranname))",
        "add('use %s, only : %s' % (rout['modulename'],"
    ],
    [
        "if line.lstrip().startswith('use ') and '__user__' not in line:",
        "if line.lstrip().startswith('use ') and '__user__'"
    ],
    [
        "if line.lstrip().startswith('use ') and '__user__' in line:",
        "if line.lstrip().startswith('use ') and '__user__'"
    ],
    [
        "sargs = ', '.join([a for a in args if a not in extra_args])",
        "sargs = ', '.join([a for a in args if a not"
    ],
    [
        "outmess('\\t\\tCreating wrapper for Fortran function \"%s\"(\"%s\")...\\n' % (",
        "outmess('\\t\\tCreating wrapper for Fortran function"
    ],
    [
        "outmess('\\t\\tCreating wrapper for Fortran subroutine \"%s\"(\"%s\")...\\n'",
        "outmess('\\t\\tCreating wrapper for Fortran subroutine"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is given"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE AT YOUR OWN"
    ],
    [
        "Used in Op.RELATIONAL expression to specify the function part.",
        "Used in Op.RELATIONAL expression to specify the"
    ],
    [
        "return {'==': RelOp.EQ, '!=': RelOp.NE, '<': RelOp.LT,",
        "return {'==': RelOp.EQ, '!=':"
    ],
    [
        "'<=': RelOp.LE, '>': RelOp.GT, '>=': RelOp.GE}[s]",
        "'<=': RelOp.LE, '>': RelOp.GT,"
    ],
    [
        "Used in Op.APPLY expression to specify the function part.",
        "Used in Op.APPLY expression to specify"
    ],
    [
        "\"\"\"Represents a Fortran expression as a op-data pair.",
        "\"\"\"Represents a Fortran expression as a"
    ],
    [
        "Expr instances are hashable and sortable.",
        "Expr instances are hashable and"
    ],
    [
        "\"\"\"Parse a Fortran expression to a Expr.",
        "\"\"\"Parse a Fortran expression to a"
    ],
    [
        "assert all(isinstance(item, Expr) for item in data), data",
        "assert all(isinstance(item, Expr) for item in data),"
    ],
    [
        "f'unknown op or missing sanity check: {op}')",
        "f'unknown op or missing"
    ],
    [
        "def __le__(self, other): return self == other or self < other",
        "def __le__(self, other): return self =="
    ],
    [
        "def __gt__(self, other): return not (self <= other)",
        "def __gt__(self, other): return not"
    ],
    [
        "def __ge__(self, other): return not (self < other)",
        "def __ge__(self, other): return not (self"
    ],
    [
        "\"\"\"Return a string representation of Expr.",
        "\"\"\"Return a string representation"
    ],
    [
        "r = '(' + r + ')'",
        "r = '(' +"
    ],
    [
        "r = '[' + r + ']'",
        "r = '[' + r"
    ],
    [
        "term = f'{coeff} * ' + term.tostring(",
        "term = f'{coeff} *"
    ],
    [
        "elif op == ' - ':",
        "elif op == '"
    ],
    [
        "precedence = Precedence.SUM if terms else Precedence.ATOM",
        "precedence = Precedence.SUM if"
    ],
    [
        "factor = ' * '.join([factor] * exp)",
        "factor = ' *"
    ],
    [
        "factors += ['/', '(', ' * '.join(tail), ')']",
        "factors += ['/', '(', '"
    ],
    [
        "precedence = Precedence.PRODUCT if factors else Precedence.ATOM",
        "precedence = Precedence.PRODUCT if"
    ],
    [
        "if name is ArithOp.DIV and language is Language.C:",
        "if name is ArithOp.DIV and language"
    ],
    [
        "args += [k + '=' + v.tostring(Precedence.NONE)",
        "args += [k + '=' +"
    ],
    [
        "r = '&' + self.data.tostring(Precedence.UNARY, language=language)",
        "r = '&' +"
    ],
    [
        "r = '*' + self.data.tostring(Precedence.UNARY, language=language)",
        "r = '*'"
    ],
    [
        "precedence = (Precedence.EQ if rop in (RelOp.EQ, RelOp.NE)",
        "precedence = (Precedence.EQ if rop in (RelOp.EQ,"
    ],
    [
        "return '(' + r + ')'",
        "return '(' +"
    ],
    [
        "if self.op is Op.COMPLEX and other.op in (Op.INTEGER, Op.REAL):",
        "if self.op is Op.COMPLEX and other.op in (Op.INTEGER,"
    ],
    [
        "elif self.op in (Op.INTEGER, Op.REAL) and other.op is Op.COMPLEX:",
        "elif self.op in (Op.INTEGER, Op.REAL) and"
    ],
    [
        "elif self.op is Op.REAL and other.op is Op.INTEGER:",
        "elif self.op is Op.REAL and"
    ],
    [
        "elif self.op is Op.INTEGER and other.op is Op.REAL:",
        "elif self.op is Op.INTEGER"
    ],
    [
        "if self.op is Op.COMPLEX and other.op in (Op.INTEGER, Op.REAL):",
        "if self.op is Op.COMPLEX and other.op in (Op.INTEGER,"
    ],
    [
        "elif other.op is Op.COMPLEX and self.op in (Op.INTEGER, Op.REAL):",
        "elif other.op is Op.COMPLEX and"
    ],
    [
        "elif self.op is Op.REAL and other.op is Op.INTEGER:",
        "elif self.op is Op.REAL and"
    ],
    [
        "elif self.op is Op.INTEGER and other.op is Op.REAL:",
        "elif self.op is Op.INTEGER and"
    ],
    [
        "**{k: as_expr(v) for k, v in kwargs.items()})",
        "**{k: as_expr(v) for k, v in"
    ],
    [
        "ewarn(f'C-index should be a single expression but got `{index}`')",
        "ewarn(f'C-index should be a single expression but got"
    ],
    [
        "\"\"\"Recursively substitute symbols with values in symbols map.",
        "\"\"\"Recursively substitute symbols with values"
    ],
    [
        "Symbols map is a dictionary of symbol-expression pairs.",
        "Symbols map is a dictionary of symbol-expression"
    ],
    [
        "assert paren == 'ROUND', (paren, value)",
        "assert paren == 'ROUND', (paren,"
    ],
    [
        "if self.op in (Op.INTEGER, Op.REAL, Op.STRING):",
        "if self.op in"
    ],
    [
        "ewarn('substitute: empty TERMS expression interpreted as'",
        "ewarn('substitute: empty TERMS expression interpreted"
    ],
    [
        "args = tuple(a.substitute(symbols_map) for a in args)",
        "args = tuple(a.substitute(symbols_map) for a"
    ],
    [
        "operands = tuple(a.substitute(symbols_map) for a in self.data)",
        "operands = tuple(a.substitute(symbols_map) for a in"
    ],
    [
        "raise NotImplementedError(f'substitute method for {self.op}: {self!r}')",
        "raise NotImplementedError(f'substitute method"
    ],
    [
        "\"\"\"Traverse expression tree with visit function.",
        "\"\"\"Traverse expression tree with"
    ],
    [
        "The visit function is applied to an expression with given args",
        "The visit function is applied to an"
    ],
    [
        "Traverse call returns an expression returned by visit when not",
        "Traverse call returns an expression returned by"
    ],
    [
        "None, otherwise return a new normalized expression with",
        "None, otherwise return a"
    ],
    [
        "if self.op in (Op.INTEGER, Op.REAL, Op.STRING, Op.SYMBOL):",
        "if self.op in (Op.INTEGER,"
    ],
    [
        "elif self.op in (Op.COMPLEX, Op.ARRAY, Op.CONCAT, Op.TERNARY):",
        "elif self.op in (Op.COMPLEX,"
    ],
    [
        "kwoperands = {k: v.traverse(visit, *args, **kwargs)",
        "kwoperands = {k:"
    ],
    [
        "\"\"\"Return a set of symbols contained in self.",
        "\"\"\"Return a set of symbols contained in"
    ],
    [
        "\"\"\"Return a set of expressions used as atoms in polynomial self.",
        "\"\"\"Return a set of expressions used as atoms in polynomial"
    ],
    [
        "\"\"\"Return a, b such that a * symbol + b == self.",
        "\"\"\"Return a, b such that a * symbol +"
    ],
    [
        "If self is not linear with respect to symbol, raise RuntimeError.",
        "If self is not linear with respect to"
    ],
    [
        "zero, _ = as_numer_denom(a * symbol - ax)",
        "zero, _ = as_numer_denom(a"
    ],
    [
        "f' {a} * {symbol} + {b} == {self}')",
        "f' {a} * {symbol} + {b} =="
    ],
    [
        "\"\"\"Normalize Expr and apply basic evaluation methods.",
        "\"\"\"Normalize Expr and apply basic"
    ],
    [
        "\"\"\"Convert non-Expr objects to Expr objects.",
        "\"\"\"Convert non-Expr objects"
    ],
    [
        "\"\"\"Return object as SYMBOL expression (variable or unparsed expression).",
        "\"\"\"Return object as SYMBOL expression"
    ],
    [
        "\"\"\"Return object as INTEGER or REAL constant.",
        "\"\"\"Return object as INTEGER or REAL"
    ],
    [
        "raise OpError(f'cannot convert {obj} to INTEGER or REAL constant')",
        "raise OpError(f'cannot convert {obj} to"
    ],
    [
        "raise OpError(f'cannot convert {obj} to INTEGER constant')",
        "raise OpError(f'cannot convert {obj}"
    ],
    [
        "raise OpError(f'cannot convert {obj} to REAL constant')",
        "raise OpError(f'cannot convert {obj} to REAL"
    ],
    [
        "\"\"\"Return object as STRING expression (string literal constant).",
        "\"\"\"Return object as STRING expression (string literal"
    ],
    [
        "\"\"\"Return object as ARRAY expression (array constant).",
        "\"\"\"Return object as ARRAY"
    ],
    [
        "\"\"\"Return object as COMPLEX expression (complex literal constant).",
        "\"\"\"Return object as COMPLEX expression"
    ],
    [
        "\"\"\"Return object as APPLY expression (function call, constructor, etc.)",
        "\"\"\"Return object as APPLY expression (function"
    ],
    [
        "{k: as_expr(v) for k, v in kwargs.items()}))",
        "{k: as_expr(v) for k, v"
    ],
    [
        "raise OpError(f'cannot convert {type(obj)} to terms Expr')",
        "raise OpError(f'cannot convert {type(obj)}"
    ],
    [
        "raise OpError(f'cannot convert {type(obj)} to terms Expr')",
        "raise OpError(f'cannot convert {type(obj)} to terms"
    ],
    [
        "raise OpError(f'cannot convert {type(obj)} to term and coeff')",
        "raise OpError(f'cannot convert {type(obj)} to"
    ],
    [
        "if obj.op in (Op.INTEGER, Op.REAL, Op.COMPLEX, Op.SYMBOL,",
        "if obj.op in (Op.INTEGER, Op.REAL,"
    ],
    [
        "raise OpError(f'cannot convert {type(obj)} to numer and denom')",
        "raise OpError(f'cannot convert {type(obj)}"
    ],
    [
        "\"\"\"Replace quoted substrings of input string.",
        "\"\"\"Replace quoted substrings of input"
    ],
    [
        "Return a new string and a mapping of replacements.",
        "Return a new string and"
    ],
    [
        "s = s.replace(k, kind + v)",
        "s = s.replace(k, kind"
    ],
    [
        "\"\"\"Replace substrings of input that are enclosed in parenthesis.",
        "\"\"\"Replace substrings of input that are enclosed in"
    ],
    [
        "Return a new string and a mapping of replacements.",
        "Return a new string and"
    ],
    [
        "for left_, right_ in (('(/', '/)'),",
        "for left_, right_ in (('(/',"
    ],
    [
        "raise ValueError(f'Mismatch of {left + right} parenthesis in {s!r}')",
        "raise ValueError(f'Mismatch of {left +"
    ],
    [
        "p = {'(': 'ROUND', '[': 'SQUARE', '{': 'CURLY', '(/': 'ROUNDDIV'}[left]",
        "p = {'(': 'ROUND', '[': 'SQUARE', '{': 'CURLY', '(/':"
    ],
    [
        "r, d = replace_parenthesis(s[j + len(right):])",
        "r, d ="
    ],
    [
        "return s[:i] + k + r, d",
        "return s[:i] + k +"
    ],
    [
        "left = {'ROUND': '(', 'SQUARE': '[', 'CURLY': '{', 'ROUNDDIV': '(/'}[p]",
        "left = {'ROUND': '(', 'SQUARE': '[', 'CURLY':"
    ],
    [
        "right = {'ROUND': ')', 'SQUARE': ']', 'CURLY': '}', 'ROUNDDIV': '/)'}[p]",
        "right = {'ROUND': ')', 'SQUARE': ']', 'CURLY': '}', 'ROUNDDIV':"
    ],
    [
        "s = s.replace(k, left + v + right)",
        "s = s.replace(k, left +"
    ],
    [
        "\"\"\"Create an expression from a string.",
        "\"\"\"Create an expression from"
    ],
    [
        "This is a \"lazy\" parser, that is, only arithmetic operations are",
        "This is a \"lazy\" parser, that is,"
    ],
    [
        "resolved, non-arithmetic operations are treated as symbols.",
        "resolved, non-arithmetic operations are treated"
    ],
    [
        "raise ValueError(f'failed to parse `{s}` to Expr instance: got `{r}`')",
        "raise ValueError(f'failed to parse `{s}` to Expr"
    ],
    [
        "\"\"\"Parse string within the given context.",
        "\"\"\"Parse string within"
    ],
    [
        "The context may define the result in case of ambiguous",
        "The context may define the result in case of"
    ],
    [
        "expressions. For instance, consider expressions `f(x, y)` and",
        "expressions. For instance, consider expressions"
    ],
    [
        "`(x, y) + (a, b)` where `f` is a function and pair `(x, y)`",
        "`(x, y) + (a, b)` where `f` is a"
    ],
    [
        "denotes complex number. Specifying context as \"args\" or",
        "denotes complex number. Specifying context as"
    ],
    [
        "\"expr\", the subexpression `(x, y)` will be parse to an",
        "\"expr\", the subexpression `(x, y)`"
    ],
    [
        "argument list or to a complex number, respectively.",
        "argument list or to a"
    ],
    [
        "return type(s)(self.process(s_, context) for s_ in s)",
        "return type(s)(self.process(s_, context) for"
    ],
    [
        "rop = '.' + rop + '.'",
        "rop = '.' + rop"
    ],
    [
        "if self.language is Language.Fortran and '//' in r:",
        "if self.language is Language.Fortran and '//'"
    ],
    [
        "if self.language is not Language.C and '**' in r:",
        "if self.language is not Language.C and"
    ],
    [
        "value, _, _, kind = m.groups()",
        "value, _, _, kind ="
    ],
    [
        "'expr' if paren == 'ROUND' else 'args')",
        "'expr' if paren == 'ROUND' else"
    ],
    [
        "kwargs = {a.left: a.right for a in args",
        "kwargs = {a.left: a.right for a"
    ],
    [
        "args = tuple(a for a in args if not isinstance(a, _Pair))",
        "args = tuple(a for a in args"
    ],
    [
        "f'fromstring: treating {r!r} as symbol (original={self.original})')",
        "f'fromstring: treating {r!r} as symbol"
    ],
    [
        "print('Failed to import new numpy:', e)",
        "print('Failed to import new numpy:',"
    ],
    [
        "print('Found new numpy version %r in %s' %",
        "print('Found new numpy version %r in"
    ],
    [
        "print('Found numpy.distutils version %r in %r' % (",
        "print('Found numpy.distutils version %r"
    ],
    [
        "print('Found numpy_distutils version %r in %r' % (",
        "print('Found numpy_distutils version %r in"
    ],
    [
        "'Checking availability of supported Fortran compilers:')",
        "'Checking availability of"
    ],
    [
        "print('Checking availability of supported Fortran compilers:')",
        "print('Checking availability of supported"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE"
    ],
    [
        "errmess('getctype: function %s has no return value?!\\n' % a)",
        "errmess('getctype: function %s has no return"
    ],
    [
        "errmess('getctype: \"%s %s %s\" not supported.\\n' %",
        "errmess('getctype: \"%s %s %s\""
    ],
    [
        "errmess('getctype: No C-type found in \"%s\", assuming void.\\n' % var)",
        "errmess('getctype: No C-type found in \"%s\","
    ],
    [
        "function uses a heuristic approach that assumes that Fortran",
        "function uses a heuristic approach that assumes that"
    ],
    [
        "arithmetic expressions are valid C arithmetic expressions when",
        "arithmetic expressions are valid C"
    ],
    [
        "mapping Fortran function calls to the corresponding C function/CPP",
        "mapping Fortran function calls to the corresponding"
    ],
    [
        "errmess('getstrlength: function %s has no return value?!\\n' % a)",
        "errmess('getstrlength: function %s has no return value?!\\n' %"
    ],
    [
        "'getstrlength: expected a signature of a string but got: %s\\n' % (repr(var)))",
        "'getstrlength: expected a signature of a string but got:"
    ],
    [
        "if re.match(r'\\(\\s*(\\*|:)\\s*\\)', len) or re.match(r'(\\*|:)', len):",
        "if re.match(r'\\(\\s*(\\*|:)\\s*\\)', len) or"
    ],
    [
        "errmess('getstrlength:intent(hide): expected a string with defined length but got: %s\\n' % (",
        "errmess('getstrlength:intent(hide): expected a string with defined length but got: %s\\n' %"
    ],
    [
        "if d not in ['*', ':', '(*)', '(:)']:",
        "if d not in ['*', ':',"
    ],
    [
        "if d not in ['*', ':', '(*)', '(:)']:",
        "if d not in"
    ],
    [
        "'getarrdims: If in call-back function: array argument %s must have bounded dimensions: got %s\\n' % (repr(a), repr(d)))",
        "'getarrdims: If in call-back function: array argument %s must have bounded dimensions: got %s\\n' % (repr(a),"
    ],
    [
        "errmess('getctype: function %s has no return value?!\\n' % af)",
        "errmess('getctype: function %s has no"
    ],
    [
        "init = ', optional\\\\n    Default: %s' % showinit",
        "init = ', optional\\\\n Default:"
    ],
    [
        "sig = '%s : %s string(len=%s)%s' % (",
        "sig = '%s : %s string(len=%s)%s' %"
    ],
    [
        "sigout = '%s : string(len=%s)' % (out_a, getstrlength(var))",
        "sigout = '%s :"
    ],
    [
        "sig = '%s : %s rank-%s array(\\'%s\\') with bounds (%s)%s' % (a, opt, rank,",
        "sig = '%s : %s rank-%s array(\\'%s\\') with bounds (%s)%s' % (a, opt,"
    ],
    [
        "sigout = '%s : rank-%s array(\\'%s\\') with bounds (%s)'\\",
        "sigout = '%s : rank-%s array(\\'%s\\') with bounds"
    ],
    [
        "sigout = '%s : rank-%s array(\\'%s\\') with bounds (%s) and %s storage'\\",
        "sigout = '%s : rank-%s array(\\'%s\\') with bounds (%s) and %s"
    ],
    [
        "ua = ' => %s' % ua",
        "ua = ' => %s' %"
    ],
    [
        "sig = '%s : call-back function%s' % (a, ua)",
        "sig = '%s : call-back function%s' % (a,"
    ],
    [
        "'getpydocsign: Could not resolve docsignature for \"%s\".\\n' % a)",
        "'getpydocsign: Could not resolve docsignature for \"%s\".\\n' %"
    ],
    [
        "sig = '%s : rank-%s array(\\'%s\\') with bounds (%s)' % (a, rank,",
        "sig = '%s : rank-%s array(\\'%s\\') with"
    ],
    [
        "'getinit: expected complex number `(r,i)\\' but got `%s\\' as initial value of %r.' % (init, a))",
        "'getinit: expected complex number `(r,i)\\' but got `%s\\' as initial value of %r.'"
    ],
    [
        "ret = {'varname': a, 'outvarname': out_a, 'ctype': getctype(var)}",
        "ret = {'varname': a,"
    ],
    [
        "if hasinitvalue(var) and iscomplex(var) and not isarray(var):",
        "if hasinitvalue(var) and iscomplex(var)"
    ],
    [
        "il = [isintent_in, 'input', isintent_out, 'output',",
        "il = [isintent_in,"
    ],
    [
        "iscomplexarray, 'complex array', isstringarray, 'string array',",
        "iscomplexarray, 'complex array', isstringarray, 'string"
    ],
    [
        "map(lambda x, y: '%s|%s' % (x, y), var['dimension'], dim))",
        "map(lambda x, y: '%s|%s' %"
    ],
    [
        "ret['vardebuginfo'] = 'debug-capi:%s %s=%s:%s' % (",
        "ret['vardebuginfo'] = 'debug-capi:%s %s=%s:%s'"
    ],
    [
        "ret['vardebugshowvalue'] = 'debug-capi:slen(%s)=%%d %s=\\\\\"%%s\\\\\"' % (",
        "ret['vardebugshowvalue'] = 'debug-capi:slen(%s)=%%d"
    ],
    [
        "'endtitle': gentitle('end of %s' % name),",
        "'endtitle': gentitle('end of"
    ],
    [
        "ret['callprotoargument'] = getcallprotoargument(rout, lcb_map) or ''",
        "ret['callprotoargument'] = getcallprotoargument(rout,"
    ],
    [
        "ret['routdebugshowvalue'] = 'debug-capi:slen(%s)=%%d %s=\\\\\"%%s\\\\\"' % (",
        "ret['routdebugshowvalue'] = 'debug-capi:slen(%s)=%%d %s=\\\\\"%%s\\\\\"'"
    ],
    [
        "ret = {'name': 'cb_%s_in_%s' % (rout['name'], um),",
        "ret = {'name': 'cb_%s_in_%s' % (rout['name'],"
    ],
    [
        "ret['endtitle'] = gentitle('end of %s' % ret['name'])",
        "ret['endtitle'] = gentitle('end of %s' %"
    ],
    [
        "if 'args' in rout and 'vars' in rout:",
        "if 'args' in rout and"
    ],
    [
        "if hasnote(rout) and isfunction(rout) and 'result' in rout:",
        "if hasnote(rout) and isfunction(rout) and 'result' in"
    ],
    [
        "ret = {'varname': a, 'ctype': getctype(var)}",
        "ret = {'varname': a,"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE AT"
    ],
    [
        "sargs, fargs, efargs, modobjs, notvars, onlyvars = [], [], [], [], [",
        "sargs, fargs, efargs, modobjs, notvars, onlyvars = [], [], [],"
    ],
    [
        "if (n not in notvars and isvariable(var)) and (not l_or(isintent_hide, isprivate)(var)):",
        "if (n not in notvars and isvariable(var)) and (not"
    ],
    [
        "outmess(f\"\\t\\t\\tSkipping {m['name']} since there are no public vars/func in this module...\\n\")",
        "outmess(f\"\\t\\t\\tSkipping {m['name']} since there are no public vars/func in this"
    ],
    [
        "if m['name'] in usenames and containscommon(m):",
        "if m['name'] in"
    ],
    [
        "outmess(f\"\\t\\t\\tSkipping {m['name']} since it is in 'use' and contains a common block...\\n\")",
        "outmess(f\"\\t\\t\\tSkipping {m['name']} since it is in 'use'"
    ],
    [
        "outmess('\\t\\t  Variables: %s\\n' % (' '.join(onlyvars)))",
        "outmess('\\t\\t Variables: %s\\n' % ('"
    ],
    [
        "fadd('use %s, only: d => %s\\n' %",
        "fadd('use %s, only: d => %s\\n'"
    ],
    [
        "(','.join(['s(%s)' % i for i in dms])))",
        "(','.join(['s(%s)' % i for i in"
    ],
    [
        "% (b['name'], m['name'], b['name'], m['name'], b['name']))",
        "% (b['name'], m['name'],"
    ],
    [
        "fadd('use %s, only : %s' % (m['name'], a))",
        "fadd('use %s, only : %s'"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED."
    ],
    [
        "outmess('\\t\\t\\tVariable \"%s<=%s\" is already mapped by \"%s\". Skipping.\\n' % (",
        "outmess('\\t\\t\\tVariable \"%s<=%s\" is already mapped by"
    ],
    [
        "outmess('\\t\\t\\tIgnoring map \"%s=>%s\". See above.\\n' %",
        "outmess('\\t\\t\\tIgnoring map \"%s=>%s\". See"
    ],
    [
        "'\\t\\t\\tNo definition for variable \"%s=>%s\". Skipping.\\n' % (v, r['map'][v]))",
        "'\\t\\t\\tNo definition for variable \"%s=>%s\". Skipping.\\n' %"
    ],
    [
        "ret = dictappend(ret, buildusevar(v, varsmap[v], m['vars'], m['name']))",
        "ret = dictappend(ret, buildusevar(v,"
    ],
    [
        "outmess('\\t\\t\\tConstructing wrapper function for variable \"%s=>%s\"...\\n' % (",
        "outmess('\\t\\t\\tConstructing wrapper function for variable \"%s=>%s\"...\\n' %"
    ],
    [
        "'endtitle': gentitle('end of %s=>%s' % (name, realname)),",
        "'endtitle': gentitle('end of %s=>%s' % (name,"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is given"
    ],
    [
        "terms of the NumPy (BSD style) LICENSE.",
        "terms of the NumPy (BSD"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE AT YOUR OWN"
    ],
    [
        "'isunsigned_shortarray', 'l_and', 'l_not', 'l_or', 'outmess', 'replace',",
        "'isunsigned_shortarray', 'l_and', 'l_not',"
    ],
    [
        "return 'typespec' in var and var['typespec'] == 'character' and \\",
        "return 'typespec' in var and var['typespec'] =="
    ],
    [
        "return 'typespec' in var and var['typespec'] == 'character' and \\",
        "return 'typespec' in var and var['typespec']"
    ],
    [
        "return _ischaracter(var) and 'charselector' not in var",
        "return _ischaracter(var) and 'charselector' not in"
    ],
    [
        "return _ischaracter(var) and 'charselector' in var",
        "return _ischaracter(var) and"
    ],
    [
        "return 'dimension' in var and not isexternal(var)",
        "return 'dimension' in var and not"
    ],
    [
        "return not (isarray(var) or isstring(var) or isexternal(var))",
        "return not (isarray(var) or isstring(var) or"
    ],
    [
        "return isscalar(var) and var.get('typespec') == 'logical'",
        "return isscalar(var) and"
    ],
    [
        "return isscalar(var) and var.get('typespec') == 'integer'",
        "return isscalar(var) and var.get('typespec')"
    ],
    [
        "return isscalar(var) and var.get('typespec') == 'real'",
        "return isscalar(var) and"
    ],
    [
        "if var.get('typespec') not in ['integer', 'logical']:",
        "if var.get('typespec') not in ['integer',"
    ],
    [
        "return isarray(var) and var.get('typespec') == 'integer' \\",
        "return isarray(var) and var.get('typespec') == 'integer'"
    ],
    [
        "return isarray(var) and var.get('typespec') in ['integer', 'logical']\\",
        "return isarray(var) and var.get('typespec')"
    ],
    [
        "return isarray(var) and var.get('typespec') in ['integer', 'logical']\\",
        "return isarray(var) and var.get('typespec') in ['integer',"
    ],
    [
        "return isarray(var) and var.get('typespec') in ['integer', 'logical']\\",
        "return isarray(var) and var.get('typespec') in ['integer',"
    ],
    [
        "return isarray(var) and var.get('typespec') in ['integer', 'logical']\\",
        "return isarray(var) and var.get('typespec') in ['integer',"
    ],
    [
        "return isarray(var) and var.get('typespec') in ['integer', 'logical']\\",
        "return isarray(var) and var.get('typespec') in"
    ],
    [
        "return isarray(var) and var.get('typespec') in ['integer', 'logical']\\",
        "return isarray(var) and var.get('typespec') in"
    ],
    [
        "return isarray(var) and var.get('typespec') in ['integer', 'logical']\\",
        "return isarray(var) and var.get('typespec') in ['integer',"
    ],
    [
        "return isarray(var) and var.get('typespec') in ['integer', 'logical']\\",
        "return isarray(var) and var.get('typespec') in"
    ],
    [
        "return 'attrspec' in var and 'allocatable' in var['attrspec']",
        "return 'attrspec' in var and 'allocatable'"
    ],
    [
        "return not ('dimension' not in var or isstring(var))",
        "return not ('dimension' not in var"
    ],
    [
        "return 'block' in rout and 'module' == rout['block']",
        "return 'block' in rout"
    ],
    [
        "return 'block' in rout and 'function' == rout['block']",
        "return 'block' in rout and 'function'"
    ],
    [
        "return wrapfuncs and isfunction(rout) and (not isexternal(rout))",
        "return wrapfuncs and isfunction(rout)"
    ],
    [
        "return 'block' in rout and 'subroutine' == rout['block']",
        "return 'block' in rout and"
    ],
    [
        "for d in rout['vars'].get(a, {}).get('dimension', []):",
        "for d in rout['vars'].get(a,"
    ],
    [
        "Warning: code with a function returning complex value",
        "Warning: code with a"
    ],
    [
        "may not work correctly with your Fortran compiler.",
        "may not work correctly"
    ],
    [
        "return 'externals' in rout and rout['externals']",
        "return 'externals' in rout and"
    ],
    [
        "return 'vars' in rout and rout['vars']",
        "return 'vars' in rout"
    ],
    [
        "return ('attrspec' in var and 'optional' in var['attrspec'] and",
        "return ('attrspec' in var and"
    ],
    [
        "'required' not in var['attrspec']) and isintent_nothide(var)",
        "'required' not in var['attrspec'])"
    ],
    [
        "return 'attrspec' in var and 'external' in var['attrspec']",
        "return 'attrspec' in var and 'external' in"
    ],
    [
        "if any('dimension' in s for s in var['attrspec']):",
        "if any('dimension' in s for s"
    ],
    [
        "return ('intent' in var and ('inout' in var['intent'] or",
        "return ('intent' in var and ('inout'"
    ],
    [
        "'outin' in var['intent']) and 'in' not in var['intent'] and",
        "'outin' in var['intent']) and 'in' not in"
    ],
    [
        "'hide' not in var['intent'] and 'inplace' not in var['intent'])",
        "'hide' not in var['intent'] and"
    ],
    [
        "return ('intent' in var and ('hide' in var['intent'] or",
        "return ('intent' in var and ('hide'"
    ],
    [
        "('out' in var['intent'] and 'in' not in var['intent'] and",
        "('out' in var['intent'] and 'in'"
    ],
    [
        "isintent_dict = {isintent_in: 'INTENT_IN', isintent_inout: 'INTENT_INOUT',",
        "isintent_dict = {isintent_in: 'INTENT_IN',"
    ],
    [
        "return 'attrspec' in var and 'private' in var['attrspec']",
        "return 'attrspec' in var and 'private'"
    ],
    [
        "mess = '\\n\\n  var = %s\\n  Message: %s\\n' % (var, self.mess)",
        "mess = '\\n\\n var = %s\\n Message: %s\\n' %"
    ],
    [
        "errmess('Failed to use fortranname from %s\\n' %",
        "errmess('Failed to use fortranname from %s\\n'"
    ],
    [
        "r = '\\t/* start ' + blockname + \\",
        "r = '\\t/* start ' + blockname"
    ],
    [
        "errmess(\"%s multiline block should end with `'''`: %s\\n\"",
        "errmess(\"%s multiline block should end with `'''`:"
    ],
    [
        "'warning: callstatement is defined without callprotoargument\\n')",
        "'warning: callstatement is defined without"
    ],
    [
        "sortargs, args = [], rout.get('args', [])",
        "sortargs, args = [], rout.get('args',"
    ],
    [
        "auxvars = [a for a in rout['vars'].keys() if isintent_aux(rout['vars'][a])",
        "auxvars = [a for a in rout['vars'].keys() if"
    ],
    [
        "return '/*%s %s %s*/' % (ln * '*', name, ln * '*')",
        "return '/*%s %s %s*/' % (ln *"
    ],
    [
        "return reduce(lambda x, y, f=flatlist: x + f(y), lst, [])",
        "return reduce(lambda x, y, f=flatlist: x +"
    ],
    [
        "return [replace(str, _m, defaultsep) for _m in d]",
        "return [replace(str, _m, defaultsep) for _m"
    ],
    [
        "return [replace(_m, d, defaultsep) for _m in str]",
        "return [replace(_m, d, defaultsep) for"
    ],
    [
        "if 'separatorsfor' in d and k in d['separatorsfor']:",
        "if 'separatorsfor' in d and"
    ],
    [
        "if '_check' in rules and (not rules['_check'](var)):",
        "if '_check' in rules and (not"
    ],
    [
        "res = applyrules({'needs': rules['need']}, d, var)",
        "res = applyrules({'needs': rules['need']},"
    ],
    [
        "ar = applyrules({k: i}, d, var)",
        "ar = applyrules({k:"
    ],
    [
        "res = applyrules({'supertext': i}, d, var)",
        "res = applyrules({'supertext': i},"
    ],
    [
        "errmess('applyrules: ignoring rule %s.\\n' % repr(rules[k]))",
        "errmess('applyrules: ignoring rule"
    ],
    [
        "all_uses.extend([x for x in modblock.get(\"use\").keys() if \"__\" not in x])",
        "all_uses.extend([x for x in modblock.get(\"use\").keys() if \"__\""
    ],
    [
        "Update the Fortran-to-C type mapping dictionary with new mappings and",
        "Update the Fortran-to-C type mapping dictionary with new mappings"
    ],
    [
        "return a list of successfully mapped C types.",
        "return a list of"
    ],
    [
        "This function integrates a new mapping dictionary into an existing",
        "This function integrates a new mapping dictionary into an"
    ],
    [
        "Fortran-to-C type mapping dictionary. It ensures that all keys are in",
        "Fortran-to-C type mapping dictionary. It ensures"
    ],
    [
        "lowercase and validates new entries against a given C-to-Python mapping",
        "lowercase and validates new entries against"
    ],
    [
        "dictionary. Redefinitions and invalid entries are reported with a warning.",
        "dictionary. Redefinitions and invalid entries are reported with a"
    ],
    [
        "The existing Fortran-to-C type mapping dictionary that will be updated.",
        "The existing Fortran-to-C type mapping dictionary"
    ],
    [
        "It should be a dictionary of dictionaries where the main keys represent",
        "It should be a dictionary of dictionaries where the"
    ],
    [
        "Fortran types and the nested dictionaries map Fortran type specifiers",
        "Fortran types and the nested dictionaries"
    ],
    [
        "Fortran types and values being dictionaries of type specifiers and their",
        "Fortran types and values being dictionaries of type specifiers and"
    ],
    [
        "A dictionary used for validating the C types in `new_map`. It maps C",
        "A dictionary used for validating the C types in `new_map`. It"
    ],
    [
        "types to corresponding Python types and is used to ensure that the C",
        "types to corresponding Python types and is"
    ],
    [
        "types specified in `new_map` are valid.",
        "types specified in `new_map`"
    ],
    [
        "A flag used to provide information about the types mapped",
        "A flag used to provide information about the"
    ],
    [
        "The updated Fortran-to-C type mapping dictionary and a list of",
        "The updated Fortran-to-C type mapping dictionary and a list"
    ],
    [
        "\"\\tIgnoring map {'%s':{'%s':'%s'}}: '%s' must be in %s\\n\"",
        "\"\\tIgnoring map {'%s':{'%s':'%s'}}: '%s'"
    ],
    [
        "Only required declarations/macros/functions will be used.",
        "Only required declarations/macros/functions will"
    ],
    [
        "Permission to use, modify, and distribute this software is given under the",
        "Permission to use, modify, and distribute this software is given"
    ],
    [
        "NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.",
        "NO WARRANTY IS EXPRESSED OR IMPLIED. USE"
    ],
    [
        "\"Use the Meson backend instead, or generate wrappers\"",
        "\"Use the Meson backend instead,"
    ],
    [
        "\" without -c and use a custom build script\",",
        "\" without -c and use a"
    ],
    [
        "\"\"\"Template meson build file generation class.\"\"\"",
        "\"\"\"Template meson build"
    ],
    [
        "f\"'{x}'\" if not (x.startswith(\"'\") and x.endswith(\"'\")) else x",
        "f\"'{x}'\" if not (x.startswith(\"'\") and"
    ],
    [
        "f\"{lib.replace('.', '_')} = declare_dependency(link_args : ['-l{lib}'])\"",
        "f\"{lib.replace('.', '_')} = declare_dependency(link_args :"
    ],
    [
        "[f\"{self.indent}{lib.replace('.', '_')},\" for lib in self.libraries]",
        "[f\"{self.indent}{lib.replace('.', '_')},\" for lib"
    ],
    [
        "\"debug\" if any(\"debug\" in flag for flag in self.fc_flags) else \"release\"",
        "\"debug\" if any(\"debug\" in flag for flag in self.fc_flags) else"
    ],
    [
        "def write_meson_build(self, build_dir: Path) -> None:",
        "def write_meson_build(self, build_dir: Path) ->"
    ],
    [
        "\"\"\"Writes the meson build file at specified location\"\"\"",
        "\"\"\"Writes the meson build"
    ],
    [
        "compile_command = [\"meson\", \"compile\", \"-C\", self.meson_build_dir]",
        "compile_command = [\"meson\","
    ],
    [
        "values = [val.strip(\"'\\\"\") for val in values]",
        "values = [val.strip(\"'\\\"\") for val in"
    ],
    [
        "from numpy.testing import assert_array_equal, assert_equal, assert_raises",
        "from numpy.testing import assert_array_equal,"
    ],
    [
        "o(i, :) = transfer(c(i), o(i, :))",
        "o(i, :) = transfer(c(i),"
    ],
    [
        "o(i, j, :) = transfer(c(i, j), o(i, j, :))",
        "o(i, j, :) = transfer(c(i,"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_input_' + fsuffix)",
        "f = getattr(self.module, self.fprefix"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_output_' + fsuffix)",
        "f = getattr(self.module, self.fprefix + '_output_'"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_array_input_' + fsuffix)",
        "f = getattr(self.module, self.fprefix + '_array_input_'"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_array_output_' + fsuffix)",
        "f = getattr(self.module, self.fprefix + '_array_output_'"
    ],
    [
        "expected = np.array([[list(item) for item in row] for row in a],",
        "expected = np.array([[list(item) for item in row]"
    ],
    [
        "o(i, j) = transfer(c(i, j), o(i, j))",
        "o(i, j) = transfer(c(i,"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_input')",
        "f = getattr(self.module, self.fprefix +"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_input')",
        "f = getattr(self.module, self.fprefix"
    ],
    [
        "raise SystemError(f'{f.__name__} should have failed on empty list')",
        "raise SystemError(f'{f.__name__} should have failed on"
    ],
    [
        "if not str(msg).endswith(' got int instance'):",
        "if not str(msg).endswith('"
    ],
    [
        "raise SystemError(f'{f.__name__} should have failed on int value')",
        "raise SystemError(f'{f.__name__} should have"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_array_input')",
        "f = getattr(self.module, self.fprefix"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_array_input')",
        "f = getattr(self.module, self.fprefix +"
    ],
    [
        "f'{f.__name__} should have failed on wrong input')",
        "f'{f.__name__} should have failed on wrong"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_output')",
        "f = getattr(self.module,"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_array_output')",
        "f = getattr(self.module, self.fprefix +"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_input_output')",
        "f = getattr(self.module,"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_inout')",
        "f = getattr(self.module,"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_inout')",
        "f = getattr(self.module, self.fprefix"
    ],
    [
        "raise SystemError(f'{f.__name__} should have failed on str value')",
        "raise SystemError(f'{f.__name__} should have failed on"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_array_inout')",
        "f = getattr(self.module, self.fprefix"
    ],
    [
        "n = np.array(['A', 'B', 'C'], dtype=dtype, order='F')",
        "n = np.array(['A', 'B',"
    ],
    [
        "a = np.array(['a', 'b', 'c'], dtype=dtype, order='F')",
        "a = np.array(['a', 'b',"
    ],
    [
        "a = np.array(['a', 'b', 'c', 'd'], dtype=dtype)",
        "a = np.array(['a', 'b', 'c',"
    ],
    [
        "assert_array_equal(a, np.array(['a', 'A', 'B', 'C'], dtype=dtype))",
        "assert_array_equal(a, np.array(['a', 'A',"
    ],
    [
        "a = np.array([['a', 'b', 'c']], dtype=dtype, order='F')",
        "a = np.array([['a', 'b',"
    ],
    [
        "a = np.array(['a', 'b', 'c', 'd'], dtype=dtype, order='F')",
        "a = np.array(['a', 'b', 'c', 'd'],"
    ],
    [
        "f'{f.__name__} should have failed on wrong input')",
        "f'{f.__name__} should have failed on wrong"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_return')",
        "f = getattr(self.module, self.fprefix"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_array_return')",
        "f = getattr(self.module, self.fprefix"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_optional')",
        "f = getattr(self.module, self.fprefix +"
    ],
    [
        "if (j>=iachar(\"a\") .and. j<=iachar(\"z\") ) then",
        "if (j>=iachar(\"a\") .and. j<=iachar(\"z\")"
    ],
    [
        "f = getattr(self.module, self.fprefix + '_character_bc_' + state)",
        "f = getattr(self.module, self.fprefix"
    ],
    [
        "reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "reason=\"PyPy cannot modify tp_doc after"
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"common\", \"block.f\")]",
        "sources = [util.getpath(\"tests\", \"src\", \"common\","
    ],
    [
        "Remove leading and trailing whitespace, and convert internal",
        "Remove leading and trailing whitespace, and convert"
    ],
    [
        "stretches of whitespace to a single space.",
        "stretches of whitespace to"
    ],
    [
        "), f\"selectedintkind({i}): expected {selected_int_kind(i)!r} but got {selectedintkind(i)!r}\"",
        "), f\"selectedintkind({i}): expected {selected_int_kind(i)!r}"
    ],
    [
        "Test (processor-dependent) `real` kind_func for real numbers",
        "Test (processor-dependent) `real` kind_func"
    ],
    [
        "), f\"selectedrealkind({i}): expected {selected_real_kind(i)!r} but got {selectedrealkind(i)!r}\"",
        "), f\"selectedrealkind({i}): expected {selected_real_kind(i)!r} but got"
    ],
    [
        "), f\"selectedrealkind({i}): expected {selected_real_kind(i)!r} but got {selectedrealkind(i)!r}\"",
        "), f\"selectedrealkind({i}): expected {selected_real_kind(i)!r} but got"
    ],
    [
        "from numpy._core._type_aliases import c_names_dict as _c_names_dict",
        "from numpy._core._type_aliases import c_names_dict as"
    ],
    [
        "Build the required testing extension module",
        "Build the required testing extension"
    ],
    [
        "wrap = util.build_meson(src, module_name = \"test_array_from_pyobj_ext\")",
        "wrap = util.build_meson(src,"
    ],
    [
        "return all(name in self.intent_list for name in names)",
        "return all(name in self.intent_list"
    ],
    [
        "return len(self.intent_list) == len(names) and self.is_intent(*names)",
        "return len(self.intent_list) == len(names) and"
    ],
    [
        "_cast_dict[\"SHORT\"] = _cast_dict[\"BYTE\"] + [\"UBYTE\", \"SHORT\"]",
        "_cast_dict[\"SHORT\"] = _cast_dict[\"BYTE\"] + [\"UBYTE\","
    ],
    [
        "_cast_dict[\"USHORT\"] = _cast_dict[\"UBYTE\"] + [\"BYTE\", \"USHORT\"]",
        "_cast_dict[\"USHORT\"] = _cast_dict[\"UBYTE\"] +"
    ],
    [
        "_cast_dict[\"INT\"] = _cast_dict[\"SHORT\"] + [\"USHORT\", \"INT\"]",
        "_cast_dict[\"INT\"] = _cast_dict[\"SHORT\"] + [\"USHORT\","
    ],
    [
        "_cast_dict[\"UINT\"] = _cast_dict[\"USHORT\"] + [\"SHORT\", \"UINT\"]",
        "_cast_dict[\"UINT\"] = _cast_dict[\"USHORT\"]"
    ],
    [
        "_cast_dict[\"FLOAT\"] = _cast_dict[\"SHORT\"] + [\"USHORT\", \"FLOAT\"]",
        "_cast_dict[\"FLOAT\"] = _cast_dict[\"SHORT\"] +"
    ],
    [
        "_cast_dict[\"DOUBLE\"] = _cast_dict[\"INT\"] + [\"UINT\", \"FLOAT\", \"DOUBLE\"]",
        "_cast_dict[\"DOUBLE\"] = _cast_dict[\"INT\"] + [\"UINT\","
    ],
    [
        "and (platform.system(), platform.processor()) != (\"Darwin\", \"arm\")):",
        "and (platform.system(), platform.processor()) != (\"Darwin\","
    ],
    [
        "_cast_dict[\"CDOUBLE\"] = _cast_dict[\"DOUBLE\"] + [\"CFLOAT\", \"CDOUBLE\"]",
        "_cast_dict[\"CDOUBLE\"] = _cast_dict[\"DOUBLE\"] + [\"CFLOAT\","
    ],
    [
        "self.type_num = getattr(wrap, 'NPY_' + self.NAME)",
        "self.type_num = getattr(wrap, 'NPY_' +"
    ],
    [
        "return [self.__class__(_m) for _m in _cast_dict[self.NAME]]",
        "return [self.__class__(_m) for"
    ],
    [
        "return [self.__class__(_m) for _m in _type_names]",
        "return [self.__class__(_m) for _m"
    ],
    [
        "def __init__(self, typ, dims, intent, obj):",
        "def __init__(self, typ, dims,"
    ],
    [
        "\"\"\"Check that created array shares data with input array.\"\"\"",
        "\"\"\"Check that created array shares data with"
    ],
    [
        "request.cls.array = lambda self, dims, intent, obj: Array(",
        "request.cls.array = lambda self,"
    ],
    [
        "\"\"\"Test if intent(in) array can be passed without copies\"\"\"",
        "\"\"\"Test if intent(in) array can be passed"
    ],
    [
        "seq = getattr(self, \"num\" + inp)",
        "seq = getattr(self,"
    ],
    [
        "((order == 'C' and intent.in_.c) or intent.in_), obj)",
        "((order == 'C' and intent.in_.c)"
    ],
    [
        "raise SystemError(\"intent(inout) should have failed on sequence\")",
        "raise SystemError(\"intent(inout) should have"
    ],
    [
        "\"intent(inout) should have failed on improper array\")",
        "\"intent(inout) should have failed"
    ],
    [
        "\"intent(cache) should have failed on multisegmented array\")",
        "\"intent(cache) should have failed on multisegmented"
    ],
    [
        "\"intent(cache) should have failed on smaller array\")",
        "\"intent(cache) should have failed on"
    ],
    [
        "\"intent(cache) should have failed on undefined dimensions\")",
        "\"intent(cache) should have failed on undefined"
    ],
    [
        "\"intent(hide) should have failed on undefined dimensions\")",
        "\"intent(hide) should have failed on"
    ],
    [
        "\"but not when run in isolation\",",
        "\"but not when run in"
    ],
    [
        "assert str(Expr(Op.APPLY, (\"f\", (), {}))) == \"f()\"",
        "assert str(Expr(Op.APPLY, (\"f\", (),"
    ],
    [
        "assert str(Expr(Op.APPLY, (\"f\", (x, ), {}))) == \"f(x)\"",
        "assert str(Expr(Op.APPLY, (\"f\", (x,"
    ],
    [
        "assert str(Expr(Op.APPLY, (\"f\", (x, y), {}))) == \"f(x, y)\"",
        "assert str(Expr(Op.APPLY, (\"f\", (x, y),"
    ],
    [
        "assert str(Expr(Op.INDEXING, (\"f\", x))) == \"f[x]\"",
        "assert str(Expr(Op.INDEXING, (\"f\", x))) =="
    ],
    [
        "assert str(as_ternary(x, y, z)) == \"merge(y, z, x)\"",
        "assert str(as_ternary(x, y, z))"
    ],
    [
        "assert str(as_eq(x, y)) == \"x .eq. y\"",
        "assert str(as_eq(x, y)) == \"x"
    ],
    [
        "assert str(as_ne(x, y)) == \"x .ne. y\"",
        "assert str(as_ne(x, y)) =="
    ],
    [
        "assert str(as_lt(x, y)) == \"x .lt. y\"",
        "assert str(as_lt(x, y)) == \"x .lt."
    ],
    [
        "assert str(as_le(x, y)) == \"x .le. y\"",
        "assert str(as_le(x, y)) == \"x"
    ],
    [
        "assert str(as_gt(x, y)) == \"x .gt. y\"",
        "assert str(as_gt(x, y)) == \"x"
    ],
    [
        "assert str(as_ge(x, y)) == \"x .ge. y\"",
        "assert str(as_ge(x, y)) =="
    ],
    [
        "}).tostring(language=language) == \"(x + y) * (x + y)\")",
        "}).tostring(language=language) == \"(x + y) * (x"
    ],
    [
        "x + y).tostring(language=language) == \"x / (x + y)\")",
        "x + y).tostring(language=language) == \"x /"
    ],
    [
        "assert (as_apply(ArithOp.DIV, x - y, x +",
        "assert (as_apply(ArithOp.DIV, x - y, x"
    ],
    [
        "y).tostring(language=language) == \"(x - y) / (x + y)\")",
        "y).tostring(language=language) == \"(x - y) /"
    ],
    [
        "assert (x + (x - y) / (x + y) +",
        "assert (x + (x - y)"
    ],
    [
        "assert as_ternary(x, y, z).tostring(language=language) == \"(x?y:z)\"",
        "assert as_ternary(x, y, z).tostring(language=language)"
    ],
    [
        "assert as_eq(x, y).tostring(language=language) == \"x == y\"",
        "assert as_eq(x, y).tostring(language=language) == \"x"
    ],
    [
        "assert as_ne(x, y).tostring(language=language) == \"x != y\"",
        "assert as_ne(x, y).tostring(language=language) == \"x !="
    ],
    [
        "assert as_lt(x, y).tostring(language=language) == \"x < y\"",
        "assert as_lt(x, y).tostring(language=language) == \"x <"
    ],
    [
        "assert as_le(x, y).tostring(language=language) == \"x <= y\"",
        "assert as_le(x, y).tostring(language=language) == \"x <="
    ],
    [
        "assert as_gt(x, y).tostring(language=language) == \"x > y\"",
        "assert as_gt(x, y).tostring(language=language) == \"x >"
    ],
    [
        "assert as_ge(x, y).tostring(language=language) == \"x >= y\"",
        "assert as_ge(x, y).tostring(language=language) == \"x >="
    ],
    [
        "assert (x + y) * z == x * z + y * z",
        "assert (x + y) * z == x *"
    ],
    [
        "assert z * (x + y) == x * z + y * z",
        "assert z * (x + y) == x * z + y *"
    ],
    [
        "assert s // x == Expr(Op.CONCAT, (s, x))",
        "assert s // x"
    ],
    [
        "assert x // s == Expr(Op.CONCAT, (x, s))",
        "assert x // s"
    ],
    [
        "assert (x + y).substitute({x: z}) == y + z",
        "assert (x + y).substitute({x: z}) == y +"
    ],
    [
        "assert (x * y).substitute({x: z}) == y * z",
        "assert (x * y).substitute({x: z})"
    ],
    [
        "assert (x / y).substitute({x: z}) == z / y",
        "assert (x / y).substitute({x: z}) == z /"
    ],
    [
        "assert x.substitute({x: y + z}) == y + z",
        "assert x.substitute({x: y + z}) == y"
    ],
    [
        "assert a.substitute({x: y + z}) == as_array((y + z, y))",
        "assert a.substitute({x: y + z}) == as_array((y +"
    ],
    [
        "z).substitute({x: y + z}) == as_ternary(y + z, y, z)",
        "z).substitute({x: y + z}) == as_ternary(y"
    ],
    [
        "assert as_eq(x, y).substitute({x: y + z}) == as_eq(y + z, y)",
        "assert as_eq(x, y).substitute({x: y + z}) == as_eq(y + z,"
    ],
    [
        "assert fromstring(\"x + y\") == x + y",
        "assert fromstring(\"x + y\") == x +"
    ],
    [
        "assert fromstring(\"x * y\") == x * y",
        "assert fromstring(\"x * y\")"
    ],
    [
        "assert fromstring(\"x / y\") == x / y",
        "assert fromstring(\"x / y\")"
    ],
    [
        "assert fromstring(\"(x + y) * z\") == (x + y) * z",
        "assert fromstring(\"(x + y) * z\") == (x"
    ],
    [
        "assert fromstring(\"(/x, y/)\") == a, fromstring(\"(/x, y/)\")",
        "assert fromstring(\"(/x, y/)\") == a,"
    ],
    [
        "assert fromstring(\"(/(x+y)*z/)\") == as_array(((x + y) * z, ))",
        "assert fromstring(\"(/(x+y)*z/)\") == as_array(((x + y) * z,"
    ],
    [
        "assert fromstring(\"x?y:z\") == as_ternary(x, y, z)",
        "assert fromstring(\"x?y:z\") == as_ternary(x, y,"
    ],
    [
        "assert fromstring(\"(*x) * (*y)\") == as_deref(x) * as_deref(y)",
        "assert fromstring(\"(*x) * (*y)\")"
    ],
    [
        "assert fromstring(\"(*x) * *y\") == as_deref(x) * as_deref(y)",
        "assert fromstring(\"(*x) * *y\")"
    ],
    [
        "assert fromstring(\"*x * *y\") == as_deref(x) * as_deref(y)",
        "assert fromstring(\"*x * *y\") == as_deref(x)"
    ],
    [
        "assert fromstring(\"*x**y\") == as_deref(x) * as_deref(y)",
        "assert fromstring(\"*x**y\") == as_deref(x) *"
    ],
    [
        "assert fromstring(\"x == y\") == as_eq(x, y)",
        "assert fromstring(\"x == y\") == as_eq(x,"
    ],
    [
        "assert fromstring(\"x != y\") == as_ne(x, y)",
        "assert fromstring(\"x != y\") == as_ne(x,"
    ],
    [
        "assert fromstring(\"x < y\") == as_lt(x, y)",
        "assert fromstring(\"x < y\") == as_lt(x,"
    ],
    [
        "assert fromstring(\"x > y\") == as_gt(x, y)",
        "assert fromstring(\"x > y\")"
    ],
    [
        "assert fromstring(\"x <= y\") == as_le(x, y)",
        "assert fromstring(\"x <= y\") == as_le(x,"
    ],
    [
        "assert fromstring(\"x >= y\") == as_ge(x, y)",
        "assert fromstring(\"x >= y\") == as_ge(x,"
    ],
    [
        "assert fromstring(\"x .eq. y\", language=Language.Fortran) == as_eq(x, y)",
        "assert fromstring(\"x .eq. y\", language=Language.Fortran) =="
    ],
    [
        "assert fromstring(\"x .ne. y\", language=Language.Fortran) == as_ne(x, y)",
        "assert fromstring(\"x .ne. y\", language=Language.Fortran)"
    ],
    [
        "assert fromstring(\"x .lt. y\", language=Language.Fortran) == as_lt(x, y)",
        "assert fromstring(\"x .lt. y\", language=Language.Fortran) =="
    ],
    [
        "assert fromstring(\"x .gt. y\", language=Language.Fortran) == as_gt(x, y)",
        "assert fromstring(\"x .gt. y\", language=Language.Fortran) =="
    ],
    [
        "assert fromstring(\"x .le. y\", language=Language.Fortran) == as_le(x, y)",
        "assert fromstring(\"x .le. y\","
    ],
    [
        "assert fromstring(\"x .ge. y\", language=Language.Fortran) == as_ge(x, y)",
        "assert fromstring(\"x .ge. y\","
    ],
    [
        "f(y, x - z)).traverse(replace_visit) == (z +",
        "f(y, x - z)).traverse(replace_visit)"
    ],
    [
        "assert as_eq(x, y).traverse(replace_visit) == as_eq(z, y)",
        "assert as_eq(x, y).traverse(replace_visit) =="
    ],
    [
        "elif s.op is Op.SYMBOL and s not in function_symbols:",
        "elif s.op is Op.SYMBOL and"
    ],
    [
        "(x + f(y, x - z)).traverse(collect_symbols)",
        "(x + f(y,"
    ],
    [
        "assert symbols == {x, y, z}",
        "assert symbols == {x,"
    ],
    [
        "assert symbols == {x, y, z, f}",
        "assert symbols == {x,"
    ],
    [
        "assert (z * x + y).linear_solve(x) == (z, y)",
        "assert (z * x + y).linear_solve(x) == (z,"
    ],
    [
        "assert ((z + y) * x + y).linear_solve(x) == (z + y, y)",
        "assert ((z + y) * x + y).linear_solve(x) == (z + y,"
    ],
    [
        "assert (z * y * x + y).linear_solve(x) == (z * y, y)",
        "assert (z * y * x + y).linear_solve(x) == (z *"
    ],
    [
        "assert as_numer_denom(x / n) == (x, n)",
        "assert as_numer_denom(x / n)"
    ],
    [
        "assert as_numer_denom(n / x) == (n, x)",
        "assert as_numer_denom(n / x) =="
    ],
    [
        "assert as_numer_denom(x / y) == (x, y)",
        "assert as_numer_denom(x / y) == (x,"
    ],
    [
        "assert as_numer_denom(n + x / y) == (x + n * y, y)",
        "assert as_numer_denom(n + x / y) == (x +"
    ],
    [
        "assert (y(x) + x).polynomial_atoms() == {y(x), x}",
        "assert (y(x) + x).polynomial_atoms() == {y(x),"
    ],
    [
        "assert (y(x) * x[y]).polynomial_atoms() == {y(x), x[y]}",
        "assert (y(x) * x[y]).polynomial_atoms() =="
    ],
    [
        "- building and importing modules on test time, using a temporary location",
        "- building and importing modules on"
    ],
    [
        "- detecting if compilers are present",
        "- detecting if compilers are"
    ],
    [
        "pytest.skip(\"meson not present, skipping compiler dependent test\", allow_module_level=True)",
        "pytest.skip(\"meson not present, skipping"
    ],
    [
        "if (not self.compilers_checked) and (not sys.platform == \"cygwin\"):",
        "if (not self.compilers_checked) and (not sys.platform =="
    ],
    [
        "raise RuntimeError(\"Temporary module name already in use.\")",
        "raise RuntimeError(\"Temporary module name"
    ],
    [
        "def build_module(source_files, options=[], skip=[], only=[], module_name=None):",
        "def build_module(source_files, options=[], skip=[], only=[],"
    ],
    [
        "raise RuntimeError(\"%s is not a file\" % fn)",
        "raise RuntimeError(\"%s is not a file\" %"
    ],
    [
        "if '--freethreading-compatible' not in options and '--no-freethreading-compatible' not in options:",
        "if '--freethreading-compatible' not in options and '--no-freethreading-compatible' not"
    ],
    [
        "Build a module via Meson and import it.",
        "Build a module via"
    ],
    [
        "codes = self.sources if self.sources else []",
        "codes = self.sources if self.sources"
    ],
    [
        "needs_pyf = any(str(fn).endswith(\".pyf\") for fn in codes)",
        "needs_pyf = any(str(fn).endswith(\".pyf\") for fn"
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"callback\", \"foo.f\")]",
        "sources = [util.getpath(\"tests\", \"src\", \"callback\","
    ],
    [
        "reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "reason=\"PyPy cannot modify"
    ],
    [
        "r = t(lambda a: math.degrees(a), fun_extra_args=(math.pi, ))",
        "r = t(lambda a: math.degrees(a), fun_extra_args=(math.pi,"
    ],
    [
        "assert str(msg).startswith(\"cb: Callback global_f not defined\")",
        "assert str(msg).startswith(\"cb: Callback global_f"
    ],
    [
        "Callback tests using Python thread-local storage instead of",
        "Callback tests using Python thread-local storage instead"
    ],
    [
        "\"\"\"The reproduction of the reported issue requires specific input that",
        "\"\"\"The reproduction of the reported issue requires"
    ],
    [
        "extensions may break the issue conditions, so the reproducer is",
        "extensions may break the issue"
    ],
    [
        "implemented as a separate test class. Do not extend this test with",
        "implemented as a separate test class."
    ],
    [
        "reason=\"Callback aborts cause CI failures on macOS\")",
        "reason=\"Callback aborts cause CI failures"
    ],
    [
        "strings = np.array([\"ab\", \"cd\", \"ef\"], dtype=\"c\").T",
        "strings = np.array([\"ab\","
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"string\", \"string.f\")]",
        "sources = [util.getpath(\"tests\","
    ],
    [
        "\"\"\"Return the content of a string buffer as integer value.",
        "\"\"\"Return the content of a string buffer as integer"
    ],
    [
        "for j in range(start, min(end, len(s))):",
        "for j in"
    ],
    [
        "\"WASM/Pyodide does not use or support Fortran\",",
        "\"WASM/Pyodide does not use or support"
    ],
    [
        "\"Editable install doesn't support tests with a compile step\",",
        "\"Editable install doesn't support tests with"
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"quoted_character\", \"foo.f\")]",
        "sources = [util.getpath(\"tests\","
    ],
    [
        "assert self.module.foo() == (b\"'\", b'\"', b\";\", b\"!\", b\"(\", b\")\")",
        "assert self.module.foo() == (b\"'\", b'\"', b\";\", b\"!\","
    ],
    [
        "\"but not when run in isolation\",",
        "\"but not when"
    ],
    [
        "\"but not when run in isolation\",",
        "\"but not when run in"
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"block_docstring\", \"foo.f\")]",
        "sources = [util.getpath(\"tests\","
    ],
    [
        "reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "reason=\"PyPy cannot modify tp_doc after"
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"crackfortran\", \"data_common.f\")]",
        "sources = [util.getpath(\"tests\","
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"crackfortran\", \"data_multiplier.f\")]",
        "sources = [util.getpath(\"tests\", \"src\","
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"crackfortran\", \"data_with_comments.f\")]",
        "sources = [util.getpath(\"tests\", \"src\", \"crackfortran\","
    ],
    [
        "@pytest.mark.xfail(IS_PYPY, reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "@pytest.mark.xfail(IS_PYPY, reason=\"PyPy cannot modify tp_doc after"
    ],
    [
        "compiled_mods = [x for x in dir(self.module) if \"__\" not in x]",
        "compiled_mods = [x for x in"
    ],
    [
        "test_list = [\"a \", \" a\", \"a b c\", \"'abcdefghij'\"]",
        "test_list = [\"a \", \" a\","
    ],
    [
        "assert markinnerspaces(\"a 'b c' \\\\' \\\\'\") == \"a 'b@_@c' \\\\' \\\\'\"",
        "assert markinnerspaces(\"a 'b c' \\\\' \\\\'\") =="
    ],
    [
        "assert markinnerspaces(r'a \"b c\" \\\" \\\"') == r'a \"b@_@c\" \\\" \\\"'",
        "assert markinnerspaces(r'a \"b c\" \\\" \\\"') =="
    ],
    [
        "assert markinnerspaces(\"a 'b c\\\" \\\" d' e\") == \"a 'b@_@c\\\"@_@\\\"@_@d' e\"",
        "assert markinnerspaces(\"a 'b c\\\" \\\" d'"
    ],
    [
        "assert markinnerspaces(\"a \\\"b c' ' d\\\" e\") == \"a \\\"b@_@c'@_@'@_@d\\\" e\"",
        "assert markinnerspaces(\"a \\\"b c' ' d\\\" e\") == \"a"
    ],
    [
        "assert markinnerspaces(\"a 'b c' 'd e'\") == \"a 'b@_@c' 'd@_@e'\"",
        "assert markinnerspaces(\"a 'b c' 'd"
    ],
    [
        "assert markinnerspaces(r'a \"b c\" \"d e\"') == r'a \"b@_@c\" \"d@_@e\"'",
        "assert markinnerspaces(r'a \"b c\" \"d"
    ],
    [
        "\"\"\"This test suite tests various expressions that are used as dimension",
        "\"\"\"This test suite tests various expressions that"
    ],
    [
        "There exists two usage cases where analyzing dimensions",
        "There exists two usage cases where"
    ],
    [
        "In the first case, the size of output arrays must be defined based",
        "In the first case, the size of"
    ],
    [
        "on the inputs to a Fortran function. Because Fortran supports",
        "on the inputs to a Fortran"
    ],
    [
        "arbitrary bases for indexing, for instance, `arr(lower:upper)`,",
        "arbitrary bases for indexing,"
    ],
    [
        "`lower` and `upper` are arbitrary expressions of input parameters.",
        "`lower` and `upper` are arbitrary expressions of input"
    ],
    [
        "expressions to valid C expressions (an alternative approach is",
        "expressions to valid C expressions (an"
    ],
    [
        "that a developer specifies the corresponding C expressions in a",
        "that a developer specifies the corresponding C expressions"
    ],
    [
        "In the second case, when user provides an input array with a given",
        "In the second case, when user provides an input array with a"
    ],
    [
        "size but some hidden parameters used in dimensions specifications",
        "size but some hidden parameters"
    ],
    [
        "need to be determined based on the input array size. This is a",
        "need to be determined based on the input array size. This"
    ],
    [
        "size of input array. In the case when this equation cannot be",
        "size of input array. In the case when this equation cannot"
    ],
    [
        "solved (e.g. because the input array size is wrong), raise an",
        "solved (e.g. because the input array size is"
    ],
    [
        "error before calling the Fortran function (that otherwise would",
        "error before calling the Fortran"
    ],
    [
        "likely crash Python process when the size of input arrays is",
        "likely crash Python process when the size of input"
    ],
    [
        "is linear with respect to unknown parameter.",
        "is linear with respect"
    ],
    [
        "reason=\"test requires charset_normalizer which is not installed\",",
        "reason=\"test requires charset_normalizer which is"
    ],
    [
        "assert False, f\"'crackfortran.crackfortran' raised an exception {exc}\"",
        "assert False, f\"'crackfortran.crackfortran' raised an exception"
    ],
    [
        "ret = crackfortran.param_eval(v, g_params, params, dimspec=dimspec)",
        "ret = crackfortran.param_eval(v, g_params,"
    ],
    [
        "ret = crackfortran.param_eval(v, g_params, params, dimspec=dimspec)",
        "ret = crackfortran.param_eval(v, g_params, params,"
    ],
    [
        "ret = crackfortran.param_eval(v, g_params, params, dimspec=None)",
        "ret = crackfortran.param_eval(v, g_params,"
    ],
    [
        "with pytest.raises(ValueError, match='aborting directly') as exc:",
        "with pytest.raises(ValueError, match='aborting"
    ],
    [
        "pytest.skip(\"CLI command needs a Fortran compiler\")",
        "pytest.skip(\"CLI command needs"
    ],
    [
        "\"\"\"Takes in a temporary file for testing and returns the expected output and input paths",
        "\"\"\"Takes in a temporary file for testing and returns the expected"
    ],
    [
        "Here expected output is essentially one of any of the possible generated",
        "Here expected output is essentially one of any of the"
    ],
    [
        "exist, and module names are typically incorrect",
        "exist, and module names are typically"
    ],
    [
        "The name of the module, untitled by default",
        "The name of the module, untitled"
    ],
    [
        "The possible paths which are generated, not all of which exist",
        "The possible paths which are generated, not all"
    ],
    [
        "\"\"\"Check that module names are handled correctly",
        "\"\"\"Check that module names are handled"
    ],
    [
        "Essentially, the -m name cannot be used to import the module, so the module",
        "Essentially, the -m name cannot be used to import the module, so the"
    ],
    [
        "named in the .pyf needs to be used instead",
        "named in the .pyf needs to be used"
    ],
    [
        "CLI :: -m and a .pyf file",
        "CLI :: -m and"
    ],
    [
        "gen_paths = [item.name for item in ipath.parent.rglob(\"*\") if item.is_file()]",
        "gen_paths = [item.name for item in"
    ],
    [
        "with pytest.raises(ValueError, match=\"Only one .pyf file per call\"):",
        "with pytest.raises(ValueError, match=\"Only one .pyf"
    ],
    [
        "\"\"\"Ensures that a signature file is generated via the CLI",
        "\"\"\"Ensures that a signature file is generated via"
    ],
    [
        "assert \"Saving signatures to file\" in out",
        "assert \"Saving signatures to"
    ],
    [
        "\"\"\"Ensures that a signature file can be dumped to stdout",
        "\"\"\"Ensures that a signature file can be dumped"
    ],
    [
        "assert \"Saving signatures to file\" in out",
        "assert \"Saving signatures to file\" in"
    ],
    [
        "assert \"function hi() ! in \" in out",
        "assert \"function hi() !"
    ],
    [
        "\"\"\"Ensures that the CLI refuses to overwrite signature files",
        "\"\"\"Ensures that the CLI refuses to"
    ],
    [
        "assert \"Use --overwrite-signature to overwrite\" in err",
        "assert \"Use --overwrite-signature to overwrite\""
    ],
    [
        "\"\"\"Check that modules are named correctly",
        "\"\"\"Check that modules"
    ],
    [
        "CLI :: --fcompiler --help-link --backend distutils",
        "CLI :: --fcompiler --help-link"
    ],
    [
        "assert \"--fcompiler cannot be used with meson\" in out",
        "assert \"--fcompiler cannot be used"
    ],
    [
        "assert \"Use --dep for meson builds\" in out",
        "assert \"Use --dep for"
    ],
    [
        "\"\"\"Tests that functions can be skipped",
        "\"\"\"Tests that functions can be"
    ],
    [
        "f'buildmodule: Could not found the body of interfaced routine \"{skey}\". Skipping.'",
        "f'buildmodule: Could not found the body of interfaced routine \"{skey}\"."
    ],
    [
        "assert f'Constructing wrapper function \"{rkey}\"' in out",
        "assert f'Constructing wrapper function"
    ],
    [
        "\"\"\"Test that functions can be kept by only:",
        "\"\"\"Test that functions can be kept"
    ],
    [
        "f'buildmodule: Could not find the body of interfaced routine \"{skey}\". Skipping.'",
        "f'buildmodule: Could not find the body of interfaced routine \"{skey}\"."
    ],
    [
        "assert f'Constructing wrapper function \"{rkey}\"' in out",
        "assert f'Constructing wrapper function \"{rkey}\"'"
    ],
    [
        "\"\"\"Tests that it is possible to return to file processing mode",
        "\"\"\"Tests that it is possible to"
    ],
    [
        "f'buildmodule: Could not find the body of interfaced routine \"{skey}\". Skipping.'",
        "f'buildmodule: Could not find the body of interfaced"
    ],
    [
        "assert f'Constructing wrapper function \"{rkey}\"' in out",
        "assert f'Constructing wrapper function \"{rkey}\"'"
    ],
    [
        "\"\"\"Checks the generation of files based on a module name",
        "\"\"\"Checks the generation of files based on a module"
    ],
    [
        "\"\"\"Check that pyf files are correctly generated with module structure",
        "\"\"\"Check that pyf files are correctly generated"
    ],
    [
        "CLI :: -m <name> -h pyf_file",
        "CLI :: -m"
    ],
    [
        "assert \"python module hi\" in pyfdat",
        "assert \"python module hi\" in"
    ],
    [
        "\"\"\"Lowers cases by flag or when -h is present",
        "\"\"\"Lowers cases by flag or when"
    ],
    [
        "\"\"\"Lowers cases in signature files by flag or when -h is present",
        "\"\"\"Lowers cases in signature files by flag or when -h"
    ],
    [
        "\"\"\"Ensures that the build directory can be specified",
        "\"\"\"Ensures that the build"
    ],
    [
        "assert f\"Wrote C/API module \\\"{mname}\\\"\" in out",
        "assert f\"Wrote C/API module \\\"{mname}\\\"\" in"
    ],
    [
        "\"\"\"Ensures that the build directory can be specified",
        "\"\"\"Ensures that the build"
    ],
    [
        "assert \"Saving signatures to file\" in out",
        "assert \"Saving signatures to file\""
    ],
    [
        "\"\"\"Ensures that TeX documentation is written out",
        "\"\"\"Ensures that TeX documentation is"
    ],
    [
        "assert \"Documentation is saved to file\" in out",
        "assert \"Documentation is saved to file\" in"
    ],
    [
        "\"\"\"Ensures that TeX documentation is written out",
        "\"\"\"Ensures that TeX documentation is"
    ],
    [
        "assert \"Documentation is saved to file\" not in out",
        "assert \"Documentation is saved to"
    ],
    [
        "\"\"\"Ensures that truncated documentation is written out",
        "\"\"\"Ensures that truncated documentation"
    ],
    [
        "TODO: Test to ensure this has no effect without --latex-doc",
        "TODO: Test to ensure this has no"
    ],
    [
        "assert \"Documentation is saved to file\" in out",
        "assert \"Documentation is saved"
    ],
    [
        "\"\"\"Ensures that RsT documentation is written out",
        "\"\"\"Ensures that RsT documentation is written"
    ],
    [
        "assert \"ReST Documentation is saved to file\" in out",
        "assert \"ReST Documentation is saved"
    ],
    [
        "assert r\".. -*- rest -*-\" in orst.read()",
        "assert r\".. -*- rest"
    ],
    [
        "\"\"\"Ensures that TeX documentation is written out",
        "\"\"\"Ensures that TeX documentation"
    ],
    [
        "assert \"ReST Documentation is saved to file\" not in out",
        "assert \"ReST Documentation is saved to file\""
    ],
    [
        "\"\"\"Ensures that debugging wrappers are written",
        "\"\"\"Ensures that debugging"
    ],
    [
        "@pytest.mark.skip(reason=\"Consistently fails on CI; noisy so skip not xfail.\")",
        "@pytest.mark.skip(reason=\"Consistently fails on CI; noisy"
    ],
    [
        "cmd_run = shlex.split(f\"{sys.executable} -c \\\"import blah; blah.hi()\\\"\")",
        "cmd_run = shlex.split(f\"{sys.executable} -c \\\"import blah;"
    ],
    [
        "TODO: Document this in the help string",
        "TODO: Document this in the help"
    ],
    [
        "\"\"\"Check that Fortran-to-Python KIND specs can be passed",
        "\"\"\"Check that Fortran-to-Python KIND specs can be"
    ],
    [
        "@pytest.mark.skip(reason=\"Consistently fails on CI; noisy so skip not xfail.\")",
        "@pytest.mark.skip(reason=\"Consistently fails on CI; noisy"
    ],
    [
        "cmd_run = shlex.split(f\"{sys.executable} -c \\\"import blah; blah.hi()\\\"\")",
        "cmd_run = shlex.split(f\"{sys.executable} -c \\\"import"
    ],
    [
        "cmd = f\"{sys.executable} -c \\\"import blah; blah.hi();\"",
        "cmd = f\"{sys.executable} -c"
    ],
    [
        "cmd += \"import sys; assert sys._is_gil_enabled() is True\\\"\"",
        "cmd += \"import sys;"
    ],
    [
        "assert \"The global interpreter lock (GIL) has been enabled to load module 'blah'\" in rout.stderr",
        "assert \"The global interpreter lock (GIL) has been enabled to load module 'blah'\" in"
    ],
    [
        "cmd = f\"{sys.executable} -c \\\"import blah; blah.hi();\"",
        "cmd = f\"{sys.executable} -c \\\"import"
    ],
    [
        "cmd += \"import sys; assert sys._is_gil_enabled() is False\\\"\"",
        "cmd += \"import sys;"
    ],
    [
        "assert \"lparen got assign\" not in str(rerr)",
        "assert \"lparen got assign\" not in"
    ],
    [
        "@pytest.mark.skipif(platform.system() not in ['Linux', 'Darwin'], reason='Unsupported on this platform for now')",
        "@pytest.mark.skipif(platform.system() not in ['Linux', 'Darwin'], reason='Unsupported on this"
    ],
    [
        "\"\"\"Common test support for all numpy test scripts.",
        "\"\"\"Common test support for all numpy"
    ],
    [
        "This single module should provide all the common functionality for numpy tests",
        "This single module should provide all the common functionality for numpy"
    ],
    [
        "in a single location, so that test scripts can just import it and work right",
        "in a single location, so that test scripts can just import it"
    ],
    [
        "\"\"\"Tools for testing implementations of __array_function__ and ufunc overrides",
        "\"\"\"Tools for testing implementations of __array_function__"
    ],
    [
        "from numpy._core.overrides import ARRAY_FUNCTIONS as _array_functions",
        "from numpy._core.overrides import ARRAY_FUNCTIONS"
    ],
    [
        "from numpy import ufunc as _ufunc",
        "from numpy import"
    ],
    [
        "\"\"\"List all numpy ufuncs overridable via `__array_ufunc__`",
        "\"\"\"List all numpy ufuncs overridable via"
    ],
    [
        "A set containing all overridable ufuncs in the public numpy API.",
        "A set containing all overridable ufuncs in the public"
    ],
    [
        "ufuncs = {obj for obj in _umath.__dict__.values()",
        "ufuncs = {obj for obj in"
    ],
    [
        "\"\"\"Determine if a function can be overridden via `__array_ufunc__`",
        "\"\"\"Determine if a function can be overridden"
    ],
    [
        "Function that may be overridable via `__array_ufunc__`",
        "Function that may be overridable via"
    ],
    [
        "`True` if `func` is overridable via `__array_ufunc__` and",
        "`True` if `func` is overridable"
    ],
    [
        "This function is equivalent to ``isinstance(func, np.ufunc)`` and",
        "This function is equivalent"
    ],
    [
        "will work correctly for ufuncs defined outside of Numpy.",
        "will work correctly for ufuncs defined outside of"
    ],
    [
        "\"\"\"List all numpy functions overridable via `__array_function__`",
        "\"\"\"List all numpy functions overridable"
    ],
    [
        "A set containing all functions in the public numpy API that are",
        "A set containing all functions in the public numpy API"
    ],
    [
        "\"\"\"Determine if a Numpy function can be overridden via `__array_function__`",
        "\"\"\"Determine if a Numpy function"
    ],
    [
        "Function that may be overridable via `__array_function__`",
        "Function that may be overridable via"
    ],
    [
        "`True` if `func` is a function in the Numpy API that is",
        "`True` if `func` is a function in the"
    ],
    [
        "overridable via `__array_function__` and `False` otherwise.",
        "overridable via `__array_function__` and `False`"
    ],
    [
        "\"\"\"Prints type-coercion tables for the built-in NumPy types",
        "\"\"\"Prints type-coercion tables for the built-in NumPy"
    ],
    [
        "\"\"\"Prints new casts, the values given are default \"can-cast\" values, not",
        "\"\"\"Prints new casts, the values given are"
    ],
    [
        "cast_info = namedtuple(\"cast_info\", [\"can_cast\", \"legacy\", \"flags\"])",
        "cast_info = namedtuple(\"cast_info\", [\"can_cast\", \"legacy\","
    ],
    [
        "no_cast_info = cast_info(\" \", \" \", \" \")",
        "no_cast_info = cast_info(\" \", \" \","
    ],
    [
        "legacy = \"L\" if cast[\"legacy\"] else \".\"",
        "legacy = \"L\" if cast[\"legacy\"]"
    ],
    [
        "print(\"L denotes a legacy cast . a non-legacy one.\")",
        "print(\"L denotes a legacy cast . a non-legacy"
    ],
    [
        "\"\"\"Test two arrays with different shapes are found not equal.\"\"\"",
        "\"\"\"Test two arrays with different shapes are"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among violations:"
    ],
    [
        "'Max relative difference among violations: inf\\n')",
        "'Max relative difference among violations:"
    ],
    [
        "\"\"\"Test arrays with nan values in them.\"\"\"",
        "\"\"\"Test arrays with nan values in"
    ],
    [
        "\"\"\"Test two arrays with different shapes are found not equal.\"\"\"",
        "\"\"\"Test two arrays with different shapes are found"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among violations:"
    ],
    [
        "\"\"\"Test comparing an array with a scalar when all values are equal.\"\"\"",
        "\"\"\"Test comparing an array with a scalar when all values"
    ],
    [
        "\"\"\"Test comparing an array with a scalar when not all values equal.\"\"\"",
        "\"\"\"Test comparing an array with a scalar when not"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among violations:"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference"
    ],
    [
        "\"\"\"Test comparing an array with a scalar with strict option.\"\"\"",
        "\"\"\"Test comparing an array with a scalar"
    ],
    [
        "\"\"\"Test comparing two arrays with strict option.\"\"\"",
        "\"\"\"Test comparing two arrays"
    ],
    [
        "\"\"\"Test comparing two arrays with strict option.\"\"\"",
        "\"\"\"Test comparing two arrays with strict"
    ],
    [
        "err_msg = 'There is a mismatch'",
        "err_msg = 'There"
    ],
    [
        "b = ('\\nItems are not equal: There is a mismatch\\n ACTUAL: array(['",
        "b = ('\\nItems are not equal: There is a mismatch\\n"
    ],
    [
        "err_msg = 'There is a mismatch'",
        "err_msg = 'There is a"
    ],
    [
        "a = build_err_msg([x, y], err_msg, verbose=False)",
        "a = build_err_msg([x, y],"
    ],
    [
        "b = '\\nItems are not equal: There is a mismatch'",
        "b = '\\nItems are not equal: There is"
    ],
    [
        "err_msg = 'There is a mismatch'",
        "err_msg = 'There is"
    ],
    [
        "a = build_err_msg([x, y], err_msg, names=('FOO', 'BAR'))",
        "a = build_err_msg([x, y], err_msg, names=('FOO',"
    ],
    [
        "b = ('\\nItems are not equal: There is a mismatch\\n FOO: array(['",
        "b = ('\\nItems are not equal: There"
    ],
    [
        "err_msg = 'There is a mismatch'",
        "err_msg = 'There"
    ],
    [
        "b = ('\\nItems are not equal: There is a mismatch\\n ACTUAL: array(['",
        "b = ('\\nItems are not equal: There"
    ],
    [
        "for a, b in itertools.product(dts, dts):",
        "for a, b in itertools.product(dts,"
    ],
    [
        "for a, b in itertools.product(tds, tds):",
        "for a, b in itertools.product(tds,"
    ],
    [
        "for a, b in itertools.product(tds, dts):",
        "for a, b in"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among violations:"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among violations:"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among violations:"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference"
    ],
    [
        "\"\"\"Check the message is formatted correctly for the decimal value.",
        "\"\"\"Check the message is formatted correctly for"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference among"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference among"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among"
    ],
    [
        "\"\"\"Check the message is formatted correctly \"\"\"",
        "\"\"\"Check the message is formatted"
    ],
    [
        "\"\"\"when either x or y is a scalar.\"\"\"",
        "\"\"\"when either x or y"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among violations:"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference among"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among violations:"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among"
    ],
    [
        "\"\"\"Test the behavior of the `strict` option.\"\"\"",
        "\"\"\"Test the behavior of the"
    ],
    [
        "\"assert_warns does not preserver warnings state\")",
        "\"assert_warns does not"
    ],
    [
        "\"assert_warns does not preserver warnings state\")",
        "\"assert_warns does not preserver warnings"
    ],
    [
        "raise AssertionError(\"wrong warning caught by assert_warn\")",
        "raise AssertionError(\"wrong warning caught by"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among violations:"
    ],
    [
        "a = np.array([x, y, x, y])",
        "a = np.array([x,"
    ],
    [
        "b = np.array([x, y, x, x])",
        "b = np.array([x, y,"
    ],
    [
        "b = np.array([x, y, x, x])",
        "b = np.array([x, y, x,"
    ],
    [
        "c = np.array([x, y, x, z])",
        "c = np.array([x, y, x,"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among violations:"
    ],
    [
        "\"\"\"Check the message is formatted correctly when overflow can occur",
        "\"\"\"Check the message is formatted"
    ],
    [
        "\"\"\"Test the behavior of the `strict` option.\"\"\"",
        "\"\"\"Test the behavior of the `strict`"
    ],
    [
        "y = x + x * eps * nulp",
        "y = x + x *"
    ],
    [
        "y = x - x * epsneg * nulp",
        "y = x - x * epsneg"
    ],
    [
        "y = x + x * eps * nulp",
        "y = x + x *"
    ],
    [
        "y = x - x * epsneg * nulp",
        "y = x - x * epsneg"
    ],
    [
        "assert_equal(msg, \"Differences in strings:\\n- foo\\n+ hello\")",
        "assert_equal(msg, \"Differences in strings:\\n- foo\\n+"
    ],
    [
        "Test that in cases where the garbage cannot be collected, we raise an",
        "Test that in cases where the garbage cannot be collected, we raise"
    ],
    [
        "error, instead of hanging forever trying to clear it.",
        "error, instead of hanging forever trying"
    ],
    [
        "An object that not only contains a reference cycle, but creates new",
        "An object that not only contains a reference cycle, but"
    ],
    [
        "cycles whenever it's garbage-collected and its __del__ runs",
        "cycles whenever it's garbage-collected and"
    ],
    [
        "pytest.skip(\"GC does not call __del__ on cyclic objects\")",
        "pytest.skip(\"GC does not call __del__"
    ],
    [
        "Build a c-extension module on-the-fly in tests.",
        "Build a c-extension module on-the-fly in"
    ],
    [
        "Build and imports a c-extension module `modname` from a list of function",
        "Build and imports a c-extension module `modname` from"
    ],
    [
        "Each fragment is a sequence of func_name, calling convention, snippet.",
        "Each fragment is a sequence"
    ],
    [
        "Where to build the module, usually a temporary directory",
        "Where to build the module, usually a"
    ],
    [
        "Extra directories to find include files when compiling",
        "Extra directories to find include files when"
    ],
    [
        "Code to appear in the module PyMODINIT_FUNC",
        "Code to appear in the module"
    ],
    [
        "The module will have been loaded and is ready for use",
        "The module will have been loaded and is"
    ],
    [
        ">>> functions = [(\"test_bytes\", \"METH_O\", \\\"\\\"\\\"",
        ">>> functions = [(\"test_bytes\", \"METH_O\","
    ],
    [
        "body = prologue + _make_methods(functions, modname)",
        "body = prologue + _make_methods(functions,"
    ],
    [
        "Build an extension module and return the filename of the resulting",
        "Build an extension module and return the filename of"
    ],
    [
        "name of the module, possibly including dots if it is a module inside a",
        "name of the module, possibly including dots if it is"
    ],
    [
        "Where to build the module, usually a temporary directory",
        "Where to build the module, usually a"
    ],
    [
        "Extra directories to find include files when compiling",
        "Extra directories to find include files"
    ],
    [
        "Libraries to link into the extension module",
        "Libraries to link into the extension"
    ],
    [
        "Where to find the libraries, ``-L`` passed to the linker",
        "Where to find the libraries, ``-L``"
    ],
    [
        "include_dirs = include_dirs if include_dirs else []",
        "include_dirs = include_dirs if include_dirs"
    ],
    [
        "libraries = libraries if libraries else []",
        "libraries = libraries if"
    ],
    [
        "library_dirs = library_dirs if library_dirs else []",
        "library_dirs = library_dirs if library_dirs"
    ],
    [
        "\"\"\"Helper function to create a file ``source.c`` in `dirname` that contains",
        "\"\"\"Helper function to create a file ``source.c`` in `dirname`"
    ],
    [
        "the string in `source`. Returns the file name",
        "the string in `source`. Returns"
    ],
    [
        "\"\"\" Turns the name, signature, code in functions into complete functions",
        "\"\"\" Turns the name, signature, code in"
    ],
    [
        "and lists them in a methods_table. Then turns the methods_table into a",
        "and lists them in a methods_table. Then turns the methods_table into"
    ],
    [
        "``PyMethodDef`` structure and returns the resulting code fragment ready",
        "``PyMethodDef`` structure and returns the resulting code fragment"
    ],
    [
        "for funcname, flags, code in functions:",
        "for funcname, flags,"
    ],
    [
        "cfuncname = \"%s_%s\" % (modname, funcname)",
        "cfuncname = \"%s_%s\" % (modname,"
    ],
    [
        "signature = '(PyObject *self, PyObject *args, PyObject *kwargs)'",
        "signature = '(PyObject *self, PyObject *args,"
    ],
    [
        "signature = '(PyObject *self, PyObject *args)'",
        "signature = '(PyObject"
    ],
    [
        "\"{\\\"%s\\\", (PyCFunction)%s, %s},\" % (funcname, cfuncname, flags))",
        "\"{\\\"%s\\\", (PyCFunction)%s, %s},\" % (funcname, cfuncname,"
    ],
    [
        "static struct PyModuleDef moduledef = {",
        "static struct PyModuleDef"
    ],
    [
        "\"\"\" % {'methods': '\\n'.join(methods_table), 'modname': modname}",
        "\"\"\" % {'methods': '\\n'.join(methods_table),"
    ],
    [
        "\"\"\" Combines the code fragments into source code ready to be compiled",
        "\"\"\" Combines the code fragments into"
    ],
    [
        "'name': name, 'init': init, 'body': body,",
        "'name': name, 'init': init, 'body':"
    ],
    [
        "with open(cfile.parent / \"meson.build\", \"wt\") as fid:",
        "with open(cfile.parent / \"meson.build\","
    ],
    [
        "link_dirs = ['-L' + d for d in library_dirs]",
        "link_dirs = ['-L' + d for d"
    ],
    [
        "os.rename(str(build_dir / so_name), cfile.parent / so_name)",
        "os.rename(str(build_dir / so_name), cfile.parent"
    ],
    [
        "from numpy import isfinite, isnan, isinf",
        "from numpy import isfinite,"
    ],
    [
        "'''Raise this exception to mark a test as a known failing test.'''",
        "'''Raise this exception to mark a test as a known"
    ],
    [
        "if not IS_EDITABLE and np_dist.locate_file('numpy') != NUMPY_ROOT:",
        "if not IS_EDITABLE and np_dist.locate_file('numpy')"
    ],
    [
        "HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None and not IS_PYSTON",
        "HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None and"
    ],
    [
        "Assert that works in release mode.",
        "Assert that works"
    ],
    [
        "Accepts callable msg to allow deferring evaluation until failure.",
        "Accepts callable msg to allow deferring evaluation"
    ],
    [
        "The Python built-in ``assert`` does not work when executing code in",
        "The Python built-in ``assert`` does not work"
    ],
    [
        "optimized mode (the ``-O`` flag) - no byte-code is generated for it.",
        "optimized mode (the ``-O`` flag) -"
    ],
    [
        "For documentation on usage, refer to the Python documentation.",
        "For documentation on usage, refer to"
    ],
    [
        "Return virtual memory size in bytes of the running python.",
        "Return virtual memory size in bytes of the running"
    ],
    [
        "Return memory usage of running python. [Not implemented]",
        "Return memory usage of running"
    ],
    [
        "def build_err_msg(arrays, err_msg, header='Items are not equal:',",
        "def build_err_msg(arrays, err_msg, header='Items"
    ],
    [
        "r = f'[repr failed for <{type(a).__name__}>: {exc}]'",
        "r = f'[repr failed for"
    ],
    [
        "def assert_equal(actual, desired, err_msg='', verbose=True, *, strict=False):",
        "def assert_equal(actual, desired, err_msg='', verbose=True,"
    ],
    [
        "Raises an AssertionError if two objects are not equal.",
        "Raises an AssertionError if two objects are not"
    ],
    [
        "Given two objects (scalars, lists, tuples, dictionaries or numpy arrays),",
        "Given two objects (scalars, lists,"
    ],
    [
        "check that all elements of these objects are equal. An exception is raised",
        "check that all elements of these objects"
    ],
    [
        "This function handles NaN comparisons as if NaN was a \"normal\" number.",
        "This function handles NaN comparisons as if NaN was"
    ],
    [
        "That is, AssertionError is not raised if both objects have NaNs in the same",
        "That is, AssertionError is not raised if"
    ],
    [
        "positions.  This is in contrast to the IEEE standard on NaNs, which says",
        "positions. This is in contrast to the IEEE"
    ],
    [
        "that NaN compared to anything must return False.",
        "that NaN compared to anything"
    ],
    [
        "The error message to be printed in case of failure.",
        "The error message to be"
    ],
    [
        "If True, the conflicting values are appended to the error message.",
        "If True, the conflicting values are appended"
    ],
    [
        "If True and either of the `actual` and `desired` arguments is an array,",
        "If True and either of the `actual` and `desired` arguments"
    ],
    [
        "raise an ``AssertionError`` when either the shape or the data type of",
        "raise an ``AssertionError`` when either the shape or"
    ],
    [
        "the arguments does not match. If neither argument is an array, this",
        "the arguments does not match. If neither argument is"
    ],
    [
        "If actual and desired are not equal.",
        "If actual and desired are not"
    ],
    [
        "By default, when one of `actual` and `desired` is a scalar and the other is",
        "By default, when one of `actual` and `desired` is a scalar and the other"
    ],
    [
        "an array, the function checks that each element of the array is equal to",
        "an array, the function checks that each element of the array is"
    ],
    [
        "the scalar. This behaviour can be disabled by setting ``strict==True``.",
        "the scalar. This behaviour can be"
    ],
    [
        "The following comparison does not raise an exception.  There are NaNs",
        "The following comparison does not raise an exception. There"
    ],
    [
        "in the inputs, but they are in the same positions.",
        "in the inputs, but they are in the same"
    ],
    [
        "As mentioned in the Notes section, `assert_equal` has special",
        "As mentioned in the Notes section, `assert_equal` has"
    ],
    [
        "handling for scalars when one of the arguments is an array.",
        "handling for scalars when one of the"
    ],
    [
        "Use `strict` to raise an AssertionError when comparing a scalar with an",
        "Use `strict` to raise an AssertionError when"
    ],
    [
        "The `strict` parameter also ensures that the array data types match:",
        "The `strict` parameter also ensures that the array"
    ],
    [
        "if isinstance(desired, (list, tuple)) and isinstance(actual, (list, tuple)):",
        "if isinstance(desired, (list, tuple)) and"
    ],
    [
        "from numpy._core import ndarray, isscalar, signbit",
        "from numpy._core import ndarray, isscalar,"
    ],
    [
        "from numpy import iscomplexobj, real, imag",
        "from numpy import iscomplexobj, real,"
    ],
    [
        "if isinstance(actual, ndarray) or isinstance(desired, ndarray):",
        "if isinstance(actual, ndarray) or"
    ],
    [
        "msg = build_err_msg([actual, desired], err_msg, verbose=verbose)",
        "msg = build_err_msg([actual, desired], err_msg,"
    ],
    [
        "raise NotImplementedError('cannot compare to a scalar '",
        "raise NotImplementedError('cannot compare to a"
    ],
    [
        "Test if two objects are equal, and print an error message if test fails.",
        "Test if two objects are equal, and print"
    ],
    [
        "The test is performed with ``actual == desired``.",
        "The test is performed with"
    ],
    [
        "The object to test for equality against `desired`.",
        "The object to test"
    ],
    [
        "AssertionError: Test XYZ of func xyz failed",
        "AssertionError: Test XYZ of func xyz"
    ],
    [
        "Raises an AssertionError if two items are not equal up to desired",
        "Raises an AssertionError if two items are not equal up"
    ],
    [
        ".. note:: It is recommended to use one of `assert_allclose`,",
        ".. note:: It is recommended to use"
    ],
    [
        "instead of this function for more consistent floating point",
        "instead of this function for more consistent floating"
    ],
    [
        "The test verifies that the elements of `actual` and `desired` satisfy::",
        "The test verifies that the elements of `actual`"
    ],
    [
        "That is a looser test than originally documented, but agrees with what the",
        "That is a looser test than originally documented, but agrees"
    ],
    [
        "actual implementation in `assert_array_almost_equal` did up to rounding",
        "actual implementation in `assert_array_almost_equal` did up to"
    ],
    [
        "vagaries. An exception is raised at conflicting values. For ndarrays this",
        "vagaries. An exception is raised at conflicting values. For ndarrays"
    ],
    [
        "The error message to be printed in case of failure.",
        "The error message to be printed in"
    ],
    [
        "If True, the conflicting values are appended to the error message.",
        "If True, the conflicting values are appended to the"
    ],
    [
        "If actual and desired are not equal up to specified precision.",
        "If actual and desired are not equal"
    ],
    [
        "assert_allclose: Compare two array_like objects for equality with desired",
        "assert_allclose: Compare two array_like objects for equality"
    ],
    [
        "from numpy import iscomplexobj, real, imag",
        "from numpy import"
    ],
    [
        "header = ('Arrays are not almost equal to %d decimals' % decimal)",
        "header = ('Arrays are not almost equal to %d decimals' %"
    ],
    [
        "if isinstance(actual, (ndarray, tuple, list)) \\",
        "if isinstance(actual, (ndarray, tuple, list))"
    ],
    [
        "Raises an AssertionError if two items are not equal up to significant",
        "Raises an AssertionError if two items"
    ],
    [
        ".. note:: It is recommended to use one of `assert_allclose`,",
        ".. note:: It is recommended"
    ],
    [
        "instead of this function for more consistent floating point",
        "instead of this function for more"
    ],
    [
        "Given two numbers, check that they are approximately equal.",
        "Given two numbers, check that they are approximately"
    ],
    [
        "Approximately equal is defined as the number of significant digits",
        "Approximately equal is defined as the number of significant"
    ],
    [
        "The error message to be printed in case of failure.",
        "The error message to be printed in"
    ],
    [
        "If True, the conflicting values are appended to the error message.",
        "If True, the conflicting values are"
    ],
    [
        "If actual and desired are not equal up to specified precision.",
        "If actual and desired are not equal up"
    ],
    [
        "assert_allclose: Compare two array_like objects for equality with desired",
        "assert_allclose: Compare two array_like objects for equality"
    ],
    [
        "the evaluated condition that raises the exception is",
        "the evaluated condition that"
    ],
    [
        "(actual, desired) = map(float, (actual, desired))",
        "(actual, desired) ="
    ],
    [
        "header='Items are not equal to %d significant digits:' % significant,",
        "header='Items are not equal to"
    ],
    [
        "def assert_array_compare(comparison, x, y, err_msg='', verbose=True, header='',",
        "def assert_array_compare(comparison, x, y, err_msg='', verbose=True,"
    ],
    [
        "Combine results of running func on x and y, checking that they are True",
        "Combine results of running func on x and y, checking"
    ],
    [
        "if np.bool(x_id == y_id).all() != True:",
        "if np.bool(x_id =="
    ],
    [
        "cond = x.shape == y.shape and x.dtype == y.dtype",
        "cond = x.shape == y.shape and"
    ],
    [
        "cond = (x.shape == () or y.shape == ()) or x.shape == y.shape",
        "cond = (x.shape == () or y.shape == ()) or x.shape =="
    ],
    [
        "reason = f'\\n(shapes {x.shape}, {y.shape} mismatch)'",
        "reason = f'\\n(shapes"
    ],
    [
        "reason = f'\\n(dtypes {x.dtype}, {y.dtype} mismatch)'",
        "reason = f'\\n(dtypes {x.dtype}, {y.dtype}"
    ],
    [
        "flagged = func_assert_same_pos(x, y, func=isnan, hasval='nan')",
        "flagged = func_assert_same_pos(x, y, func=isnan,"
    ],
    [
        "if equal_nan and x.dtype.type == y.dtype.type:",
        "if equal_nan and x.dtype.type"
    ],
    [
        "flagged = func_assert_same_pos(x, y, func=isnat, hasval=\"NaT\")",
        "flagged = func_assert_same_pos(x, y, func=isnat,"
    ],
    [
        "if equal_nan and dt == y.dtype and hasattr(dt, 'na_object'):",
        "if equal_nan and dt == y.dtype and"
    ],
    [
        "if getattr(error, 'dtype', object_) == object_:",
        "if getattr(error, 'dtype', object_)"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among violations:"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among violations:"
    ],
    [
        "if getattr(error, 'dtype', object_) == object_:",
        "if getattr(error, 'dtype', object_)"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference among"
    ],
    [
        "msg = build_err_msg([x, y], err_msg, verbose=verbose, header=header,",
        "msg = build_err_msg([x, y],"
    ],
    [
        "def assert_array_equal(actual, desired, err_msg='', verbose=True, *,",
        "def assert_array_equal(actual, desired, err_msg='',"
    ],
    [
        "Raises an AssertionError if two array_like objects are not equal.",
        "Raises an AssertionError if two array_like"
    ],
    [
        "Given two array_like objects, check that the shape is equal and all",
        "Given two array_like objects, check that the"
    ],
    [
        "elements of these objects are equal (but see the Notes for the special",
        "elements of these objects are equal (but see the Notes for"
    ],
    [
        "handling of a scalar). An exception is raised at shape mismatch or",
        "handling of a scalar). An exception is raised at"
    ],
    [
        "conflicting values. In contrast to the standard usage in numpy, NaNs",
        "conflicting values. In contrast to the standard usage in"
    ],
    [
        "are compared like numbers, no assertion is raised if both objects have",
        "are compared like numbers, no assertion is"
    ],
    [
        "The usual caution for verifying equality with floating point numbers is",
        "The usual caution for verifying equality with"
    ],
    [
        ".. note:: When either `actual` or `desired` is already an instance of",
        ".. note:: When either `actual` or `desired` is already an instance"
    ],
    [
        "`numpy.ndarray` and `desired` is not a ``dict``, the behavior of",
        "`numpy.ndarray` and `desired` is not a ``dict``, the"
    ],
    [
        "``assert_equal(actual, desired)`` is identical to the behavior of this",
        "``assert_equal(actual, desired)`` is identical to the behavior of"
    ],
    [
        "function. Otherwise, this function performs `np.asanyarray` on the",
        "function. Otherwise, this function performs `np.asanyarray`"
    ],
    [
        "inputs before comparison, whereas `assert_equal` defines special",
        "inputs before comparison, whereas `assert_equal`"
    ],
    [
        "comparison rules for common Python types. For example, only",
        "comparison rules for common Python types. For"
    ],
    [
        "`assert_equal` can be used to compare nested Python lists. In new code,",
        "`assert_equal` can be used to compare"
    ],
    [
        "consider using only `assert_equal`, explicitly converting either",
        "consider using only `assert_equal`, explicitly converting"
    ],
    [
        "`actual` or `desired` to arrays if the behavior of `assert_array_equal`",
        "`actual` or `desired` to arrays if"
    ],
    [
        "The error message to be printed in case of failure.",
        "The error message to be printed in case of"
    ],
    [
        "If True, the conflicting values are appended to the error message.",
        "If True, the conflicting values are"
    ],
    [
        "If True, raise an AssertionError when either the shape or the data",
        "If True, raise an AssertionError when either"
    ],
    [
        "type of the array_like objects does not match. The special",
        "type of the array_like objects does not match."
    ],
    [
        "handling for scalars mentioned in the Notes section is disabled.",
        "handling for scalars mentioned in the"
    ],
    [
        "If actual and desired objects are not equal.",
        "If actual and desired objects are not"
    ],
    [
        "assert_allclose: Compare two array_like objects for equality with desired",
        "assert_allclose: Compare two array_like objects"
    ],
    [
        "When one of `actual` and `desired` is a scalar and the other is array_like,",
        "When one of `actual` and `desired` is"
    ],
    [
        "the function checks that each element of the array_like object is equal to",
        "the function checks that each element of the array_like object is equal"
    ],
    [
        "the scalar. This behaviour can be disabled with the `strict` parameter.",
        "the scalar. This behaviour can be disabled with the `strict`"
    ],
    [
        "The first assert does not raise an exception:",
        "The first assert does not raise an"
    ],
    [
        "Assert fails with numerical imprecision with floats:",
        "Assert fails with numerical"
    ],
    [
        "Use `assert_allclose` or one of the nulp (number of floating point values)",
        "Use `assert_allclose` or one of the"
    ],
    [
        "As mentioned in the Notes section, `assert_array_equal` has special",
        "As mentioned in the Notes section, `assert_array_equal`"
    ],
    [
        "Use `strict` to raise an AssertionError when comparing a scalar with an",
        "Use `strict` to raise an AssertionError when"
    ],
    [
        "The `strict` parameter also ensures that the array data types match:",
        "The `strict` parameter also ensures that the array"
    ],
    [
        "Raises an AssertionError if two objects are not equal up to desired",
        "Raises an AssertionError if two objects are"
    ],
    [
        ".. note:: It is recommended to use one of `assert_allclose`,",
        ".. note:: It is recommended to"
    ],
    [
        "instead of this function for more consistent floating point",
        "instead of this function for more consistent"
    ],
    [
        "The test verifies identical shapes and that the elements of ``actual`` and",
        "The test verifies identical shapes and that"
    ],
    [
        "That is a looser test than originally documented, but agrees with what the",
        "That is a looser test than originally documented, but"
    ],
    [
        "actual implementation did up to rounding vagaries. An exception is raised",
        "actual implementation did up to rounding vagaries. An exception"
    ],
    [
        "at shape mismatch or conflicting values. In contrast to the standard usage",
        "at shape mismatch or conflicting values."
    ],
    [
        "in numpy, NaNs are compared like numbers, no assertion is raised if both",
        "in numpy, NaNs are compared like numbers,"
    ],
    [
        "objects have NaNs in the same positions.",
        "objects have NaNs in the same"
    ],
    [
        "The error message to be printed in case of failure.",
        "The error message to be printed in case of"
    ],
    [
        "If True, the conflicting values are appended to the error message.",
        "If True, the conflicting values are appended to the error"
    ],
    [
        "If actual and desired are not equal up to specified precision.",
        "If actual and desired are not equal up to"
    ],
    [
        "assert_allclose: Compare two array_like objects for equality with desired",
        "assert_allclose: Compare two array_like objects for equality"
    ],
    [
        "the first assert does not raise an exception",
        "the first assert does"
    ],
    [
        "from numpy._core.fromnumeric import any as npany",
        "from numpy._core.fromnumeric import any"
    ],
    [
        "header=('Arrays are not almost equal to %d decimals' % decimal),",
        "header=('Arrays are not almost equal"
    ],
    [
        "def assert_array_less(x, y, err_msg='', verbose=True, *, strict=False):",
        "def assert_array_less(x, y, err_msg='',"
    ],
    [
        "Raises an AssertionError if two array_like objects are not ordered by less",
        "Raises an AssertionError if two array_like objects are not"
    ],
    [
        "Given two array_like objects `x` and `y`, check that the shape is equal and",
        "Given two array_like objects `x` and `y`, check that the"
    ],
    [
        "all elements of `x` are strictly less than the corresponding elements of",
        "all elements of `x` are strictly"
    ],
    [
        "`y` (but see the Notes for the special handling of a scalar). An exception",
        "`y` (but see the Notes for the special"
    ],
    [
        "is raised at shape mismatch or values that are not correctly ordered. In",
        "is raised at shape mismatch or values that are"
    ],
    [
        "contrast to the  standard usage in NumPy, no assertion is raised if both",
        "contrast to the standard usage in NumPy, no assertion is raised if"
    ],
    [
        "objects have NaNs in the same positions.",
        "objects have NaNs in the"
    ],
    [
        "The error message to be printed in case of failure.",
        "The error message to be"
    ],
    [
        "If True, the conflicting values are appended to the error message.",
        "If True, the conflicting values are appended to"
    ],
    [
        "If True, raise an AssertionError when either the shape or the data",
        "If True, raise an AssertionError when either the shape"
    ],
    [
        "type of the array_like objects does not match. The special",
        "type of the array_like objects"
    ],
    [
        "handling for scalars mentioned in the Notes section is disabled.",
        "handling for scalars mentioned in the Notes"
    ],
    [
        "If x is not strictly smaller than y, element-wise.",
        "If x is not strictly smaller than y,"
    ],
    [
        "assert_array_almost_equal: test objects for equality up to precision",
        "assert_array_almost_equal: test objects for equality"
    ],
    [
        "When one of `x` and `y` is a scalar and the other is array_like, the",
        "When one of `x` and `y` is a scalar and the other"
    ],
    [
        "function performs the comparison as though the scalar were broadcasted",
        "function performs the comparison as though the scalar"
    ],
    [
        "to the shape of the array. This behaviour can be disabled with the `strict`",
        "to the shape of the array. This behaviour"
    ],
    [
        "The following assertion passes because each finite element of `x` is",
        "The following assertion passes because each"
    ],
    [
        "strictly less than the corresponding element of `y`, and the NaNs are in",
        "strictly less than the corresponding element of `y`, and"
    ],
    [
        "The following assertion fails because the zeroth element of `x` is no",
        "The following assertion fails because the zeroth element"
    ],
    [
        "longer strictly less than the zeroth element of `y`.",
        "longer strictly less than the zeroth element"
    ],
    [
        "Arrays are not strictly ordered `x < y`",
        "Arrays are not strictly"
    ],
    [
        "Here, `y` is a scalar, so each element of `x` is compared to `y`, and",
        "Here, `y` is a scalar, so each element of"
    ],
    [
        "However, with ``strict=True``, the assertion will fail because the shapes",
        "However, with ``strict=True``, the assertion will fail because"
    ],
    [
        "Arrays are not strictly ordered `x < y`",
        "Arrays are not strictly ordered `x <"
    ],
    [
        "With ``strict=True``, the assertion also fails if the dtypes of the two",
        "With ``strict=True``, the assertion also fails if the dtypes of"
    ],
    [
        "Arrays are not strictly ordered `x < y`",
        "Arrays are not strictly ordered"
    ],
    [
        "header='Arrays are not strictly ordered `x < y`',",
        "header='Arrays are not strictly ordered `x <"
    ],
    [
        "Test if two strings are equal.",
        "Test if two"
    ],
    [
        "If the given strings are equal, `assert_string_equal` does nothing.",
        "If the given strings are equal, `assert_string_equal`"
    ],
    [
        "If they are not equal, an AssertionError is raised, and the diff",
        "If they are not equal, an AssertionError is raised,"
    ],
    [
        "The string to test for equality against the expected string.",
        "The string to test for"
    ],
    [
        "Run doctests found in the given file.",
        "Run doctests found in"
    ],
    [
        "By default `rundocs` raises an AssertionError on failure.",
        "By default `rundocs` raises an AssertionError"
    ],
    [
        "The path to the file for which the doctests are run.",
        "The path to the file for which the doctests"
    ],
    [
        "Whether to raise an AssertionError when a doctest fails. Default is",
        "Whether to raise an AssertionError when a doctest fails."
    ],
    [
        "The doctests can be run by the user/developer by adding the ``doctests``",
        "The doctests can be run by the user/developer"
    ],
    [
        "argument to the ``test()`` call. For example, to run all tests (including",
        "argument to the ``test()`` call. For example, to"
    ],
    [
        "raise AssertionError(\"Some doctests failed:\\n%s\" % \"\\n\".join(msg))",
        "raise AssertionError(\"Some doctests failed:\\n%s\""
    ],
    [
        "Fail unless an exception of class exception_class is thrown",
        "Fail unless an exception of class exception_class"
    ],
    [
        "by callable when invoked with arguments args and keyword",
        "by callable when invoked with arguments args and"
    ],
    [
        "arguments kwargs. If a different type of exception is",
        "arguments kwargs. If a different type"
    ],
    [
        "thrown, it will not be caught, and the test case will be",
        "thrown, it will not be caught, and the test case will"
    ],
    [
        "deemed to have suffered an error, exactly as for an",
        "deemed to have suffered an error, exactly as"
    ],
    [
        "Alternatively, `assert_raises` can be used as a context manager:",
        "Alternatively, `assert_raises` can be used as"
    ],
    [
        "Fail unless an exception of class exception_class and with message that",
        "Fail unless an exception of class exception_class and with message"
    ],
    [
        "matches expected_regexp is thrown by callable when invoked with arguments",
        "matches expected_regexp is thrown by callable when invoked with"
    ],
    [
        "Alternatively, can be used as a context manager like `assert_raises`.",
        "Alternatively, can be used as"
    ],
    [
        "Apply a decorator to all methods in a class matching a regular expression.",
        "Apply a decorator to all methods in"
    ],
    [
        "The given decorator is applied to all public methods of `cls` that are",
        "The given decorator is applied to all"
    ],
    [
        "matched by the regular expression `testmatch`",
        "matched by the regular"
    ],
    [
        "(``testmatch.search(methodname)``). Methods that are private, i.e. start",
        "(``testmatch.search(methodname)``). Methods that are private, i.e."
    ],
    [
        "testmatch : compiled regexp or str, optional",
        "testmatch : compiled regexp or str,"
    ],
    [
        "The regular expression. Default value is None, in which case the",
        "The regular expression. Default value is None, in which case"
    ],
    [
        "If `testmatch` is a string, it is compiled to a regular expression",
        "If `testmatch` is a string, it is compiled to a regular"
    ],
    [
        "methods = [_m for _m in cls_attr.values() if isfunction(_m)]",
        "methods = [_m for _m in"
    ],
    [
        "Return elapsed time for executing code in the namespace of the caller.",
        "Return elapsed time for executing code in the namespace of the"
    ],
    [
        "The supplied code string is compiled with the Python builtin ``compile``.",
        "The supplied code string is compiled with the Python"
    ],
    [
        "fast on this timescale, it can be executed many times to get reasonable",
        "fast on this timescale, it can be executed many times"
    ],
    [
        "A label to identify `code_str` with. This is passed into ``compile``",
        "A label to identify `code_str` with. This is passed into"
    ],
    [
        "as the second argument (for run-time error messages).",
        "as the second argument (for run-time error"
    ],
    [
        "Total elapsed time in seconds for executing `code_str` `times` times.",
        "Total elapsed time in seconds for executing `code_str` `times`"
    ],
    [
        "code = compile(code_str, f'Test name: {label} ', 'exec')",
        "code = compile(code_str, f'Test"
    ],
    [
        "Used in a few regression tests.",
        "Used in a"
    ],
    [
        "Raises an AssertionError if two objects are not equal up to desired",
        "Raises an AssertionError if two objects are not equal up"
    ],
    [
        "Given two array_like objects, check that their shapes and all elements",
        "Given two array_like objects, check that"
    ],
    [
        "are equal (but see the Notes for the special handling of a scalar). An",
        "are equal (but see the Notes for the special handling of"
    ],
    [
        "exception is raised if the shapes mismatch or any values conflict. In",
        "exception is raised if the shapes mismatch"
    ],
    [
        "contrast to the standard usage in numpy, NaNs are compared like numbers,",
        "contrast to the standard usage in numpy, NaNs are"
    ],
    [
        "no assertion is raised if both objects have NaNs in the same positions.",
        "no assertion is raised if both objects have NaNs in the"
    ],
    [
        "The test is equivalent to ``allclose(actual, desired, rtol, atol)`` (note",
        "The test is equivalent to ``allclose(actual, desired, rtol,"
    ],
    [
        "that ``allclose`` has different default values). It compares the difference",
        "that ``allclose`` has different default values). It compares the"
    ],
    [
        "between `actual` and `desired` to ``atol + rtol * abs(desired)``.",
        "between `actual` and `desired` to ``atol +"
    ],
    [
        "If True, NaNs will compare equal.",
        "If True, NaNs"
    ],
    [
        "The error message to be printed in case of failure.",
        "The error message to be printed"
    ],
    [
        "If True, the conflicting values are appended to the error message.",
        "If True, the conflicting values are appended to the"
    ],
    [
        "If True, raise an ``AssertionError`` when either the shape or the data",
        "If True, raise an ``AssertionError`` when either the shape or the"
    ],
    [
        "type of the arguments does not match. The special handling of scalars",
        "type of the arguments does not match. The special"
    ],
    [
        "mentioned in the Notes section is disabled.",
        "mentioned in the Notes section is"
    ],
    [
        "If actual and desired are not equal up to specified precision.",
        "If actual and desired are not equal"
    ],
    [
        "When one of `actual` and `desired` is a scalar and the other is",
        "When one of `actual` and `desired` is a"
    ],
    [
        "array_like, the function performs the comparison as if the scalar were",
        "array_like, the function performs the comparison as if"
    ],
    [
        "broadcasted to the shape of the array.",
        "broadcasted to the shape of"
    ],
    [
        "This behaviour can be disabled with the `strict` parameter.",
        "This behaviour can be disabled"
    ],
    [
        "As mentioned in the Notes section, `assert_allclose` has special",
        "As mentioned in the Notes"
    ],
    [
        "handling for scalars. Here, the test checks that the value of `numpy.sin`",
        "handling for scalars. Here, the test checks that"
    ],
    [
        "is nearly zero at integer multiples of Ï€.",
        "is nearly zero at integer multiples of"
    ],
    [
        "Use `strict` to raise an ``AssertionError`` when comparing an array",
        "Use `strict` to raise an ``AssertionError`` when"
    ],
    [
        "with one or more dimensions against a scalar.",
        "with one or more dimensions against"
    ],
    [
        "The `strict` parameter also ensures that the array data types match:",
        "The `strict` parameter also ensures that"
    ],
    [
        "header = f'Not equal to tolerance rtol={rtol:g}, atol={atol:g}'",
        "header = f'Not equal to tolerance"
    ],
    [
        "Compare two arrays relatively to their spacing.",
        "Compare two arrays relatively to"
    ],
    [
        "This is a relatively robust method to compare two arrays whose amplitude",
        "This is a relatively robust method to compare two arrays whose"
    ],
    [
        "The maximum number of unit in the last place for tolerance (see Notes).",
        "The maximum number of unit in the last"
    ],
    [
        "If the spacing between `x` and `y` for one or more elements is larger",
        "If the spacing between `x` and `y` for"
    ],
    [
        "assert_array_max_ulp : Check that all items of arrays differ in at most",
        "assert_array_max_ulp : Check that all items of arrays differ in"
    ],
    [
        "N Units in the Last Place.",
        "N Units in"
    ],
    [
        "spacing : Return the distance between x and the nearest adjacent number.",
        "spacing : Return the distance between"
    ],
    [
        "An assertion is raised if the following condition is not met::",
        "An assertion is raised if the"
    ],
    [
        "abs(x - y) <= nulp * spacing(maximum(abs(x), abs(y)))",
        "abs(x - y) <= nulp *"
    ],
    [
        "ref = nulp * np.spacing(np.where(ax > ay, ax, ay))",
        "ref = nulp * np.spacing(np.where(ax > ay, ax,"
    ],
    [
        "if not np.all(np.abs(x - y) <= ref):",
        "if not np.all(np.abs(x -"
    ],
    [
        "msg = f\"Arrays are not equal to {nulp} ULP\"",
        "msg = f\"Arrays are not equal to {nulp}"
    ],
    [
        "msg = f\"Arrays are not equal to {nulp} ULP (max is {max_nulp:g})\"",
        "msg = f\"Arrays are not equal to {nulp} ULP (max"
    ],
    [
        "Check that all items of arrays differ in at most N Units in the Last Place.",
        "Check that all items of arrays differ in at"
    ],
    [
        "The maximum number of units in the last place that elements of `a` and",
        "The maximum number of units in the last place that"
    ],
    [
        "Data-type to convert `a` and `b` to if given. Default is None.",
        "Data-type to convert `a` and `b`"
    ],
    [
        "Array containing number of representable floating point numbers between",
        "Array containing number of representable floating point numbers"
    ],
    [
        "If one or more elements differ by more than `maxulp`.",
        "If one or more elements differ by more"
    ],
    [
        "For computing the ULP difference, this API does not differentiate between",
        "For computing the ULP difference, this"
    ],
    [
        "assert_array_almost_equal_nulp : Compare two arrays relatively to their",
        "assert_array_almost_equal_nulp : Compare two"
    ],
    [
        "raise AssertionError(\"Arrays are not almost equal up to %g \"",
        "raise AssertionError(\"Arrays are not almost equal up"
    ],
    [
        "\"ULP (max difference is %g ULP)\" %",
        "\"ULP (max difference is %g"
    ],
    [
        "\"\"\"For each item in x and y, return the number of representable floating",
        "\"\"\"For each item in x and y, return the"
    ],
    [
        "Data-type to convert `x` and `y` to if given. Default is None.",
        "Data-type to convert `x` and `y` to if given."
    ],
    [
        "number of representable floating point numbers between each item in x",
        "number of representable floating point numbers between each"
    ],
    [
        "For computing the ULP difference, this API does not differentiate between",
        "For computing the ULP difference, this API does not"
    ],
    [
        "raise NotImplementedError(\"_nulp not implemented for complex array\")",
        "raise NotImplementedError(\"_nulp not implemented for complex"
    ],
    [
        "raise ValueError(\"Arrays do not have the same shape: %s - %s\" %",
        "raise ValueError(\"Arrays do not have the"
    ],
    [
        "diff = np.asarray(rx - ry, dtype=vdt)",
        "diff = np.asarray(rx -"
    ],
    [
        "\"\"\"Return the signed-magnitude interpretation of the binary representation",
        "\"\"\"Return the signed-magnitude interpretation of"
    ],
    [
        "name_str = f' when calling {name}' if name is not None else ''",
        "name_str = f' when calling {name}' if name is not None"
    ],
    [
        "raise AssertionError(\"No warning raised\" + name_str)",
        "raise AssertionError(\"No warning"
    ],
    [
        "Fail unless the given callable throws the specified warning.",
        "Fail unless the given callable"
    ],
    [
        "A warning of class warning_class should be thrown by the callable when",
        "A warning of class warning_class should"
    ],
    [
        "invoked with arguments args and keyword arguments kwargs.",
        "invoked with arguments args"
    ],
    [
        "If a different type of warning is thrown, it will not be caught.",
        "If a different type of warning is thrown, it will not"
    ],
    [
        "If called with all arguments other than the warning class omitted, may be",
        "If called with all arguments other than the warning class omitted,"
    ],
    [
        "The class defining the warning that `func` is expected to throw.",
        "The class defining the warning that"
    ],
    [
        "if not args and not kwargs:",
        "if not args and not"
    ],
    [
        "\"assert_warns does not use 'match' kwarg, \"",
        "\"assert_warns does not use 'match' kwarg,"
    ],
    [
        "raise RuntimeError(\"assert_warns(...) needs at least one arg\")",
        "raise RuntimeError(\"assert_warns(...) needs at least one"
    ],
    [
        "name_str = f' when calling {name}' if name is not None else ''",
        "name_str = f' when calling {name}' if name is not"
    ],
    [
        "Fail if the given callable produces any warnings.",
        "Fail if the given callable"
    ],
    [
        "If called with all arguments omitted, may be used as a context manager::",
        "If called with all arguments omitted, may be used as"
    ],
    [
        "generator producing data with different alignment and offsets",
        "generator producing data with different alignment"
    ],
    [
        "'unary': create data for unary operations, creates one input",
        "'unary': create data for unary operations,"
    ],
    [
        "'binary': create data for unary operations, creates two input",
        "'binary': create data for unary"
    ],
    [
        "maximum size of data to produce",
        "maximum size of data to"
    ],
    [
        "if type is 'unary' yields one output, one input array and a message",
        "if type is 'unary' yields one output, one input array and"
    ],
    [
        "if type is 'binary' yields one output array, two input array and a message",
        "if type is 'binary' yields one output array, two input array"
    ],
    [
        "ufmt = 'unary offset=(%d, %d), size=%d, dtype=%r, %s'",
        "ufmt = 'unary offset=(%d, %d), size=%d,"
    ],
    [
        "bfmt = 'binary offset=(%d, %d, %d), size=%d, dtype=%r, %s'",
        "bfmt = 'binary offset=(%d, %d,"
    ],
    [
        "yield out, inp(), ufmt % (o, o, s, dtype, 'out of place')",
        "yield out, inp(), ufmt % (o, o,"
    ],
    [
        "yield d, d, ufmt % (o, o, s, dtype, 'in place')",
        "yield d, d, ufmt % (o,"
    ],
    [
        "(o, o, o, s, dtype, 'out of place')",
        "(o, o, o, s, dtype,"
    ],
    [
        "\"Ignoring this exception due to disabled feature\"",
        "\"Ignoring this exception due to disabled"
    ],
    [
        "\"\"\"Context manager to provide a temporary test folder.",
        "\"\"\"Context manager to provide a temporary test"
    ],
    [
        "All arguments are passed as this to the underlying tempfile.mkdtemp",
        "All arguments are passed as this to the"
    ],
    [
        "Context manager that returns the path to a closed temporary file. Its",
        "Context manager that returns the path to a closed temporary"
    ],
    [
        "parameters are the same as for tempfile.mkstemp and are passed directly",
        "parameters are the same as for tempfile.mkstemp and"
    ],
    [
        "to that function. The underlying file is removed when the context is",
        "to that function. The underlying file is"
    ],
    [
        "exited, so it should be closed at that time.",
        "exited, so it should be closed"
    ],
    [
        "Windows does not allow a temporary file to be opened if it is already",
        "Windows does not allow a temporary file to"
    ],
    [
        "open, so the underlying file must be closed after opening before it",
        "open, so the underlying file must be"
    ],
    [
        "\"\"\" Context manager that resets warning registry for catching warnings",
        "\"\"\" Context manager that resets warning registry"
    ],
    [
        "Warnings can be slippery, because, whenever a warning is triggered, Python",
        "Warnings can be slippery, because, whenever a warning is"
    ],
    [
        "adds a ``__warningregistry__`` member to the *calling* module.  This makes",
        "adds a ``__warningregistry__`` member to the *calling*"
    ],
    [
        "it impossible to retrigger the warning in this module, whatever you put in",
        "it impossible to retrigger the warning in"
    ],
    [
        "the warnings filters.  This context manager accepts a sequence of `modules`",
        "the warnings filters. This context manager"
    ],
    [
        "as a keyword argument to its constructor and:",
        "as a keyword argument to"
    ],
    [
        "* stores and removes any ``__warningregistry__`` entries in given `modules`",
        "* stores and removes any"
    ],
    [
        "* resets ``__warningregistry__`` to its previous state on exit.",
        "* resets ``__warningregistry__`` to its previous state on"
    ],
    [
        "This makes it possible to trigger any warning afresh inside the context",
        "This makes it possible to trigger any warning afresh inside"
    ],
    [
        "manager without disturbing the state of warnings outside.",
        "manager without disturbing the state of"
    ],
    [
        "Specifies whether warnings should be captured by a custom",
        "Specifies whether warnings should be captured by"
    ],
    [
        "implementation of ``warnings.showwarning()`` and be appended to a list",
        "implementation of ``warnings.showwarning()`` and be"
    ],
    [
        "returned by the context manager. Otherwise None is returned by the",
        "returned by the context manager. Otherwise None"
    ],
    [
        "context manager. The objects appended to the list are arguments whose",
        "context manager. The objects appended to the list are arguments"
    ],
    [
        "attributes mirror the arguments to ``showwarning()``.",
        "attributes mirror the"
    ],
    [
        "Sequence of modules for which to reset warnings registry on entry and",
        "Sequence of modules for which to reset warnings registry on"
    ],
    [
        "restore on exit. To work correctly, all 'ignore' filters should",
        "restore on exit. To work correctly, all"
    ],
    [
        "filter by one of these modules.",
        "filter by one"
    ],
    [
        "Context manager and decorator doing much the same as",
        "Context manager and decorator doing much the same"
    ],
    [
        "However, it also provides a filter mechanism to work around",
        "However, it also provides a"
    ],
    [
        "after they have been ignored once (even within catch_warnings). It",
        "after they have been ignored"
    ],
    [
        "means that no \"ignore\" filter can be used easily, since following",
        "means that no \"ignore\" filter can be"
    ],
    [
        "tests might need to see the warning. Additionally it allows easier",
        "tests might need to see the warning. Additionally it"
    ],
    [
        "specificity for testing warnings and can be nested.",
        "specificity for testing warnings and can"
    ],
    [
        "One of \"always\", \"once\", \"module\", or \"location\". Analogous to",
        "One of \"always\", \"once\", \"module\", or"
    ],
    [
        "the usual warnings module filter mode, it is useful to reduce",
        "the usual warnings module filter mode, it"
    ],
    [
        "noise mostly on the outmost level. Unsuppressed and unrecorded",
        "noise mostly on the outmost level. Unsuppressed"
    ],
    [
        "warnings will be forwarded based on this rule. Defaults to \"always\".",
        "warnings will be forwarded based on this rule."
    ],
    [
        "\"location\" is equivalent to the warnings \"default\", match by exact",
        "\"location\" is equivalent to the warnings \"default\", match"
    ],
    [
        "location the warning warning originated from.",
        "location the warning warning originated"
    ],
    [
        "Filters added inside the context manager will be discarded again",
        "Filters added inside the context manager"
    ],
    [
        "when leaving it. Upon entering all filters defined outside a",
        "when leaving it. Upon entering all filters defined"
    ],
    [
        "When a recording filter is added, matching warnings are stored in the",
        "When a recording filter is added, matching warnings are"
    ],
    [
        "``log`` attribute as well as in the list returned by ``record``.",
        "``log`` attribute as well as in the list"
    ],
    [
        "If filters are added and the ``module`` keyword is given, the",
        "If filters are added and the ``module`` keyword is given,"
    ],
    [
        "warning registry of this module will additionally be cleared when",
        "warning registry of this module"
    ],
    [
        "applying it, entering the context, or exiting it. This could cause",
        "applying it, entering the context, or exiting it. This could"
    ],
    [
        "warnings to appear a second time after leaving the context if they",
        "warnings to appear a second time after"
    ],
    [
        "were configured to be printed once (default) and were already",
        "were configured to be printed once (default) and were"
    ],
    [
        "printed before the context was entered.",
        "printed before the context was"
    ],
    [
        "Nesting this context manager will work as expected when the",
        "Nesting this context manager will work"
    ],
    [
        "forwarding rule is \"always\" (default). Unfiltered and unrecorded",
        "forwarding rule is \"always\" (default)."
    ],
    [
        "warnings will be passed out and be matched by the outer level.",
        "warnings will be passed out and be matched"
    ],
    [
        "On the outmost level they will be printed (or caught by another",
        "On the outmost level they will be printed (or caught by"
    ],
    [
        "warnings context). The forwarding rule argument can modify this",
        "warnings context). The forwarding rule"
    ],
    [
        "Like ``catch_warnings`` this context manager is not threadsafe.",
        "Like ``catch_warnings`` this context manager is not"
    ],
    [
        "log = sup.record(FutureWarning, \"Does this occur?\")",
        "log = sup.record(FutureWarning, \"Does"
    ],
    [
        "if forwarding_rule not in {\"always\", \"module\", \"once\", \"location\"}:",
        "if forwarding_rule not in {\"always\", \"module\", \"once\","
    ],
    [
        "def _filter(self, category=Warning, message=\"\", module=None, record=False):",
        "def _filter(self, category=Warning, message=\"\","
    ],
    [
        "module_regex = module.__name__.replace('.', r'\\.') + '$'",
        "module_regex = module.__name__.replace('.',"
    ],
    [
        "(category, message, re.compile(message, re.I), module, record))",
        "(category, message, re.compile(message, re.I), module,"
    ],
    [
        "(category, message, re.compile(message, re.I), module, record))",
        "(category, message, re.compile(message,"
    ],
    [
        "Add a new suppressing filter or apply it if the state is entered.",
        "Add a new suppressing filter or apply it if"
    ],
    [
        "Regular expression matching the warning message.",
        "Regular expression matching"
    ],
    [
        "Module to filter for. Note that the module (and its file)",
        "Module to filter for. Note that the module (and its"
    ],
    [
        "must match exactly and cannot be a submodule. This may make",
        "must match exactly and cannot be a"
    ],
    [
        "When added within a context, filters are only added inside",
        "When added within a context, filters are only added"
    ],
    [
        "the context and will be forgotten when the context is exited.",
        "the context and will be forgotten when the context is"
    ],
    [
        "Append a new recording filter or apply it if the state is entered.",
        "Append a new recording filter or apply it if"
    ],
    [
        "All warnings matching will be appended to the ``log`` attribute.",
        "All warnings matching will be appended to the"
    ],
    [
        "Regular expression matching the warning message.",
        "Regular expression matching the"
    ],
    [
        "Module to filter for. Note that the module (and its file)",
        "Module to filter for. Note that the module (and its"
    ],
    [
        "must match exactly and cannot be a submodule. This may make",
        "must match exactly and cannot be a submodule. This may"
    ],
    [
        "A list which will be filled with all matched warnings.",
        "A list which will be filled"
    ],
    [
        "When added within a context, filters are only added inside",
        "When added within a context, filters are"
    ],
    [
        "the context and will be forgotten when the context is exited.",
        "the context and will be forgotten when the context"
    ],
    [
        "for cat, mess, _, mod, log in self._suppressions:",
        "for cat, mess, _,"
    ],
    [
        "module_regex = mod.__name__.replace('.', r'\\.') + '$'",
        "module_regex = mod.__name__.replace('.', r'\\.') +"
    ],
    [
        "def _showwarning(self, message, category, filename, lineno,",
        "def _showwarning(self, message, category,"
    ],
    [
        "for cat, _, pattern, mod, rec in (",
        "for cat, _, pattern, mod, rec in"
    ],
    [
        "signature = (message.args, category, filename, lineno)",
        "signature = (message.args, category, filename,"
    ],
    [
        "Function decorator to apply certain suppressions to a whole",
        "Function decorator to apply certain suppressions to a"
    ],
    [
        "\"Unable to fully collect garbage - perhaps a __del__ method \"",
        "\"Unable to fully collect garbage -"
    ],
    [
        "name_str = f' when calling {name}' if name is not None else ''",
        "name_str = f' when calling {name}' if"
    ],
    [
        "\"Reference cycles were found{}: {} objects were collected, \"",
        "\"Reference cycles were found{}: {}"
    ],
    [
        "\"of which {} are shown below:{}\"",
        "\"of which {} are shown"
    ],
    [
        "\"\\n  {} object with id={}:\\n    {}\".format(",
        "\"\\n {} object"
    ],
    [
        "Fail if the given callable produces any reference cycles.",
        "Fail if the given callable produces any"
    ],
    [
        "If called with all arguments omitted, may be used as a context manager::",
        "If called with all arguments omitted, may"
    ],
    [
        "Nothing. The result is deliberately discarded to ensure that all cycles",
        "Nothing. The result is deliberately discarded to"
    ],
    [
        "Break reference cycles by calling gc.collect",
        "Break reference cycles by calling"
    ],
    [
        "Objects can call other objects' methods (for instance, another object's",
        "Objects can call other objects' methods (for"
    ],
    [
        "__del__) inside their own __del__. On PyPy, the interpreter only runs",
        "__del__) inside their own __del__. On PyPy, the"
    ],
    [
        "between calls to gc.collect, so multiple calls are needed to completely",
        "between calls to gc.collect, so multiple calls are needed"
    ],
    [
        "\"\"\"Decorator to skip a test if not enough memory is available\"\"\"",
        "\"\"\"Decorator to skip a test if not enough"
    ],
    [
        "Check whether `free_bytes` amount of memory is currently free.",
        "Check whether `free_bytes` amount of memory is currently"
    ],
    [
        "Returns: None if enough memory available, otherwise error message",
        "Returns: None if enough memory available, otherwise error"
    ],
    [
        "raise ValueError(f'Invalid environment variable {env_var}: {exc}')",
        "raise ValueError(f'Invalid environment"
    ],
    [
        "msg = (\"Could not determine available memory; set NPY_AVAILABLE_MEM \"",
        "msg = (\"Could not determine available memory; set"
    ],
    [
        "msg = f'{free_bytes_gb} GB memory required, but {mem_free_gb} GB available'",
        "msg = f'{free_bytes_gb} GB memory required, but {mem_free_gb}"
    ],
    [
        "return msg if mem_free < free_bytes else None",
        "return msg if mem_free"
    ],
    [
        "raise ValueError(f'value {size_str!r} not a valid size')",
        "raise ValueError(f'value {size_str!r} not"
    ],
    [
        "\"\"\"Return available memory in bytes, or None if unknown.\"\"\"",
        "\"\"\"Return available memory in bytes, or None if"
    ],
    [
        "Decorator to temporarily turn off tracing for the duration of a test.",
        "Decorator to temporarily turn off tracing for the"
    ],
    [
        "Needed in tests that check refcounting, otherwise the tracing itself",
        "Needed in tests that check refcounting,"
    ],
    [
        "\"\"\"Runs a function many times in parallel\"\"\"",
        "\"\"\"Runs a function many times"
    ],
    [
        "all_args = [(func, i, *args) for i in range(max_workers)]",
        "all_args = [(func, i, *args) for i in"
    ],
    [
        "all_args = [(func, *args) for i in range(max_workers)]",
        "all_args = [(func, *args) for i"
    ],
    [
        "if len(futures) < max_workers and pass_barrier:",
        "if len(futures) < max_workers and"
    ],
    [
        "if na_object is pd_NA or na_object != \"unset\":",
        "if na_object is pd_NA or na_object !="
    ],
    [
        "\"\"\"A collection of functions designed to help I/O with ascii files.",
        "\"\"\"A collection of functions designed to help I/O with"
    ],
    [
        "\"\"\"Decode bytes from binary input streams.",
        "\"\"\"Decode bytes from"
    ],
    [
        "Check whether obj behaves like a string.",
        "Check whether obj behaves like"
    ],
    [
        "Check whether obj behaves like a bytes object.",
        "Check whether obj behaves"
    ],
    [
        "Returns whether one or several fields of a dtype are nested.",
        "Returns whether one or several fields"
    ],
    [
        "If `ndtype` does not have a `names` attribute.",
        "If `ndtype` does not have a"
    ],
    [
        "return any(ndtype[name].names is not None for name in ndtype.names or ())",
        "return any(ndtype[name].names is not None for"
    ],
    [
        "Unpack a structured data-type by collapsing nested fields and/or fields",
        "Unpack a structured data-type by collapsing"
    ],
    [
        "Note that the field names are lost.",
        "Note that the field"
    ],
    [
        "If True, transform a field with a shape into several fields. Default is",
        "If True, transform a field with a shape into several"
    ],
    [
        "Object to split a string at a given delimiter or at given places.",
        "Object to split a string at a given"
    ],
    [
        "delimiter : str, int, or sequence of ints, optional",
        "delimiter : str, int, or sequence of ints,"
    ],
    [
        "If a string, character used to delimit consecutive fields.",
        "If a string, character used to delimit"
    ],
    [
        "If an integer or a sequence of integers, width(s) of each field.",
        "If an integer or a sequence"
    ],
    [
        "Whether to strip each individual field. Default is True.",
        "Whether to strip each individual field. Default is"
    ],
    [
        "Wrapper to strip each member of the output of `method`.",
        "Wrapper to strip each member of the output of"
    ],
    [
        "Function that takes a single argument and returns a sequence of",
        "Function that takes a single argument and"
    ],
    [
        "The result of wrapping `method`. `wrapped` takes a single input",
        "The result of wrapping `method`. `wrapped` takes"
    ],
    [
        "argument and returns a list of strings that are stripped of",
        "argument and returns a list of strings that are stripped"
    ],
    [
        "return lambda input: [_.strip() for _ in method(input)]",
        "return lambda input: [_.strip() for"
    ],
    [
        "if (delimiter is None) or isinstance(delimiter, str):",
        "if (delimiter is None) or"
    ],
    [
        "\"\"\"Chop off comments, strip, and split at delimiter. \"\"\"",
        "\"\"\"Chop off comments, strip, and split"
    ],
    [
        "return [line[s] for s in slices]",
        "return [line[s] for s in"
    ],
    [
        "return [line[s] for s in slices]",
        "return [line[s] for s"
    ],
    [
        "Object to validate a list of strings to use as field names.",
        "Object to validate a list of strings to"
    ],
    [
        "The strings are stripped of any non alphanumeric character, and spaces",
        "The strings are stripped of any non alphanumeric"
    ],
    [
        "are replaced by '_'. During instantiation, the user can define a list",
        "are replaced by '_'. During instantiation, the user can define a"
    ],
    [
        "of names to exclude, as well as a list of invalid characters. Names in",
        "of names to exclude, as well as"
    ],
    [
        "the exclusion list are appended a '_' character.",
        "the exclusion list are appended"
    ],
    [
        "Once an instance has been created, it can be called with a list of",
        "Once an instance has been created, it can"
    ],
    [
        "names, and a list of valid names will be created.  The `__call__`",
        "names, and a list of valid names will be created. The"
    ],
    [
        "method accepts an optional keyword \"default\" that sets the default name",
        "method accepts an optional keyword \"default\" that"
    ],
    [
        "in case of ambiguity. By default this is 'f', so that names will",
        "in case of ambiguity. By default this is"
    ],
    [
        "A list of names to exclude. This list is appended to the default",
        "A list of names to exclude. This"
    ],
    [
        "list ['return', 'file', 'print']. Excluded names are appended an",
        "list ['return', 'file', 'print']. Excluded names are appended"
    ],
    [
        "underscore: for example, `file` becomes `file_` if supplied.",
        "underscore: for example, `file` becomes"
    ],
    [
        "A string combining invalid characters that must be deleted from the",
        "A string combining invalid characters that must be deleted from"
    ],
    [
        "case_sensitive : {True, False, 'upper', 'lower'}, optional",
        "case_sensitive : {True, False, 'upper',"
    ],
    [
        "* If True, field names are case-sensitive.",
        "* If True, field names are"
    ],
    [
        "* If False or 'upper', field names are converted to upper case.",
        "* If False or 'upper', field"
    ],
    [
        "* If 'lower', field names are converted to lower case.",
        "* If 'lower', field names are converted"
    ],
    [
        "Character(s) used in replacement of white spaces.",
        "Character(s) used in replacement"
    ],
    [
        "Calling an instance of `NameValidator` is the same as calling its",
        "Calling an instance of `NameValidator` is the"
    ],
    [
        "if (case_sensitive is None) or (case_sensitive is True):",
        "if (case_sensitive is None)"
    ],
    [
        "elif (case_sensitive is False) or case_sensitive.startswith('u'):",
        "elif (case_sensitive is False) or"
    ],
    [
        "msg = 'unrecognized case_sensitive value %s.' % case_sensitive",
        "msg = 'unrecognized case_sensitive value %s.'"
    ],
    [
        "Validate a list of strings as field names for a structured array.",
        "Validate a list of strings as field names"
    ],
    [
        "Default format string, used if validating a given string",
        "Default format string, used if validating"
    ],
    [
        "Final number of validated names, used to expand or shrink the",
        "Final number of validated names, used"
    ],
    [
        "The list of validated field names.",
        "The list of"
    ],
    [
        "A `NameValidator` instance can be called directly, which is the",
        "A `NameValidator` instance can be called directly, which"
    ],
    [
        "same as calling `validate`. For examples, see `NameValidator`.",
        "same as calling `validate`."
    ],
    [
        "names = list(names) + [''] * (nbfields - nbnames)",
        "names = list(names) + [''] * (nbfields"
    ],
    [
        "item = ''.join([c for c in item if c not in deletechars])",
        "item = ''.join([c for c in"
    ],
    [
        "Tries to transform a string supposed to represent a boolean to a boolean.",
        "Tries to transform a string supposed to represent"
    ],
    [
        "The string that is transformed to a boolean.",
        "The string that is transformed to a"
    ],
    [
        "If the string is not 'True' or 'False' (case independent)",
        "If the string is not 'True' or 'False'"
    ],
    [
        "Exception raised when an error occurs in a converter for string values.",
        "Exception raised when an error occurs in a"
    ],
    [
        "Exception raised when an attempt is made to upgrade a locked converter.",
        "Exception raised when an attempt is made to upgrade a"
    ],
    [
        "Warning issued when a string converter has a problem.",
        "Warning issued when a string converter"
    ],
    [
        "In `genfromtxt` a `ConversionWarning` is issued if raising exceptions",
        "In `genfromtxt` a `ConversionWarning` is issued if raising"
    ],
    [
        "is explicitly suppressed with the \"invalid_raise\" keyword.",
        "is explicitly suppressed with the"
    ],
    [
        "Factory class for function transforming a string into another object",
        "Factory class for function transforming a string into"
    ],
    [
        "After initialization, an instance can be called to transform a string",
        "After initialization, an instance can be called to"
    ],
    [
        "into another object. If the string is recognized as representing a",
        "into another object. If the string is"
    ],
    [
        "missing value, a default value is returned.",
        "missing value, a default value is"
    ],
    [
        "Default value to return when the input corresponds to a missing",
        "Default value to return when the"
    ],
    [
        "Integer representing the order of the conversion.",
        "Integer representing the order"
    ],
    [
        "Sequence of tuples (dtype, function, default value) to evaluate in",
        "Sequence of tuples (dtype, function, default value)"
    ],
    [
        "dtype_or_func : {None, dtype, function}, optional",
        "dtype_or_func : {None, dtype,"
    ],
    [
        "If a `dtype`, specifies the input data type, used to define a basic",
        "If a `dtype`, specifies the input data type, used to define a"
    ],
    [
        "function and a default value for missing data. For example, when",
        "function and a default value for missing data."
    ],
    [
        "`dtype` is float, the `func` attribute is set to `float` and the",
        "`dtype` is float, the `func` attribute is set to `float` and"
    ],
    [
        "default value to `np.nan`.  If a function, this function is used to",
        "default value to `np.nan`. If a function, this"
    ],
    [
        "convert a string to another object. In this case, it is recommended",
        "convert a string to another object. In this case, it"
    ],
    [
        "to give an associated default value as input.",
        "to give an associated"
    ],
    [
        "Value to return by default, that is, when the string to be",
        "Value to return by default, that is, when the string"
    ],
    [
        "converted is flagged as missing. If not given, `StringConverter`",
        "converted is flagged as missing. If"
    ],
    [
        "tries to supply a reasonable default value.",
        "tries to supply a reasonable"
    ],
    [
        "missing_values : {None, sequence of str}, optional",
        "missing_values : {None, sequence"
    ],
    [
        "``None`` or sequence of strings indicating a missing value. If ``None``",
        "``None`` or sequence of strings indicating a missing value."
    ],
    [
        "then missing values are indicated by empty entries. The default is",
        "then missing values are indicated by empty"
    ],
    [
        "Whether the StringConverter should be locked to prevent automatic",
        "Whether the StringConverter should be locked to"
    ],
    [
        "upgrade or not. Default is False.",
        "upgrade or not."
    ],
    [
        "\"\"\"Returns the dtype of the input variable.\"\"\"",
        "\"\"\"Returns the dtype of"
    ],
    [
        "\"\"\"Returns the type of the dtype of the input variable.\"\"\"",
        "\"\"\"Returns the type of the"
    ],
    [
        "Upgrade the mapper of a StringConverter by adding a new function and",
        "Upgrade the mapper of a StringConverter by adding a"
    ],
    [
        "The input function (or sequence of functions) and its associated",
        "The input function (or sequence of functions) and its"
    ],
    [
        "default value (if any) is inserted in penultimate position of the",
        "default value (if any) is inserted in penultimate"
    ],
    [
        "mapper.  The corresponding type is estimated from the dtype of the",
        "mapper. The corresponding type is estimated from the dtype"
    ],
    [
        "for fct, dft in zip(func, default):",
        "for fct, dft in zip(func,"
    ],
    [
        "for i, (deftype, func, default_def) in enumerate(cls._mapper):",
        "for i, (deftype, func, default_def) in"
    ],
    [
        "for i, (deftype, func, default_def) in enumerate(cls._mapper):",
        "for i, (deftype, func, default_def)"
    ],
    [
        "errmsg = (\"The input argument `dtype` is neither a\"",
        "errmsg = (\"The input argument `dtype` is"
    ],
    [
        "\" function nor a dtype (got '%s' instead)\")",
        "\" function nor a dtype (got '%s'"
    ],
    [
        "self._status, (_, func, default_def) = self._find_map_entry(dtype)",
        "self._status, (_, func,"
    ],
    [
        "raise ValueError(\"Cannot convert string '%s'\" % value)",
        "raise ValueError(\"Cannot convert string '%s'\" %"
    ],
    [
        "errmsg = \"Converter is locked and cannot be upgraded\"",
        "errmsg = \"Converter is locked"
    ],
    [
        "errmsg = \"Could not find a valid conversion function\"",
        "errmsg = \"Could not find a valid conversion"
    ],
    [
        "Find the best converter for a given string, and return the result.",
        "Find the best converter for a given string, and return the"
    ],
    [
        "The supplied string `value` is converted by testing different",
        "The supplied string `value` is converted by"
    ],
    [
        "converters in order. First the `func` method of the",
        "converters in order. First the `func` method of"
    ],
    [
        "`StringConverter` instance is tried, if this fails other available",
        "`StringConverter` instance is tried, if this fails other"
    ],
    [
        "converters are tried.  The order in which these other converters",
        "converters are tried. The order in which"
    ],
    [
        "are tried is determined by the `_status` attribute of the instance.",
        "are tried is determined by the `_status` attribute"
    ],
    [
        "The result of converting `value` with the appropriate converter.",
        "The result of converting `value` with the appropriate"
    ],
    [
        "Value to return by default, that is, when the string to be",
        "Value to return by default, that is,"
    ],
    [
        "converted is flagged as missing. If not given,",
        "converted is flagged as missing. If not"
    ],
    [
        "`StringConverter` tries to supply a reasonable default value.",
        "`StringConverter` tries to supply a reasonable"
    ],
    [
        "A string representing a standard input value of the converter.",
        "A string representing a standard input value of the"
    ],
    [
        "This string is used to help defining a reasonable default",
        "This string is used to help defining"
    ],
    [
        "missing_values : {sequence of str, None}, optional",
        "missing_values : {sequence of"
    ],
    [
        "Sequence of strings indicating a missing value. If ``None``, then",
        "Sequence of strings indicating a missing value."
    ],
    [
        "the existing `missing_values` are cleared. The default is ``''``.",
        "the existing `missing_values` are cleared."
    ],
    [
        "Whether the StringConverter should be locked to prevent",
        "Whether the StringConverter should be locked"
    ],
    [
        "automatic upgrade or not. Default is False.",
        "automatic upgrade or not. Default"
    ],
    [
        "`update` takes the same parameters as the constructor of",
        "`update` takes the same parameters as"
    ],
    [
        "`StringConverter`, except that `func` does not accept a `dtype`",
        "`StringConverter`, except that `func` does not accept"
    ],
    [
        "whereas `dtype_or_func` in the constructor does.",
        "whereas `dtype_or_func` in the constructor"
    ],
    [
        "if not all(isinstance(v, str) for v in missing_values):",
        "if not all(isinstance(v, str) for v in"
    ],
    [
        "raise TypeError(\"missing_values must be strings or unicode\")",
        "raise TypeError(\"missing_values must be strings or"
    ],
    [
        "Convenience function to create a `np.dtype` object.",
        "Convenience function to create"
    ],
    [
        "The function processes the input `dtype` and matches it with the given",
        "The function processes the input `dtype` and matches it"
    ],
    [
        "Definition of the dtype. Can be any string or dictionary recognized",
        "Definition of the dtype. Can be"
    ],
    [
        "by the `np.dtype` function, or a sequence of types.",
        "by the `np.dtype` function, or a sequence of"
    ],
    [
        "names : str or sequence, optional",
        "names : str or"
    ],
    [
        "Sequence of strings to use as field names for a structured dtype.",
        "Sequence of strings to use as field"
    ],
    [
        "For convenience, `names` can be a string of a comma-separated list",
        "For convenience, `names` can be a string"
    ],
    [
        "Format string used to define missing names, such as ``\"f%i\"``",
        "Format string used to define missing"
    ],
    [
        "A series of optional arguments used to initialize a",
        "A series of optional arguments used to initialize"
    ],
    [
        "ndtype = np.dtype({\"formats\": ndtype, \"names\": names})",
        "ndtype = np.dtype({\"formats\": ndtype, \"names\":"
    ],
    [
        "numbered_names = tuple(\"f%i\" % i for i in range(len(ndtype.names)))",
        "numbered_names = tuple(\"f%i\" % i"
    ],
    [
        "if ((ndtype.names == numbered_names) and (defaultfmt != \"f%i\")):",
        "if ((ndtype.names == numbered_names)"
    ],
    [
        "Mixin classes for custom array types that don't inherit from ndarray.",
        "Mixin classes for custom array types that don't inherit from"
    ],
    [
        "\"\"\"True when __array_ufunc__ is set to None.\"\"\"",
        "\"\"\"True when __array_ufunc__ is set to"
    ],
    [
        "\"\"\"Implement a forward binary method with a ufunc, e.g., __add__.\"\"\"",
        "\"\"\"Implement a forward binary method"
    ],
    [
        "\"\"\"Implement a reflected binary method with a ufunc, e.g., __radd__.\"\"\"",
        "\"\"\"Implement a reflected binary method with"
    ],
    [
        "\"\"\"Implement an in-place binary method with a ufunc, e.g., __iadd__.\"\"\"",
        "\"\"\"Implement an in-place binary method"
    ],
    [
        "\"\"\"Implement forward, reflected and inplace binary methods with a ufunc.\"\"\"",
        "\"\"\"Implement forward, reflected and inplace binary methods with"
    ],
    [
        "\"\"\"Implement a unary special method with a ufunc.\"\"\"",
        "\"\"\"Implement a unary special method with a"
    ],
    [
        "\"\"\"Mixin defining all operator special methods using __array_ufunc__.",
        "\"\"\"Mixin defining all operator"
    ],
    [
        "This class implements the special methods for almost all of Python's",
        "This class implements the special methods for almost"
    ],
    [
        "builtin operators defined in the `operator` module, including comparisons",
        "builtin operators defined in the `operator` module, including"
    ],
    [
        "(``==``, ``>``, etc.) and arithmetic (``+``, ``*``, ``-``, etc.), by",
        "(``==``, ``>``, etc.) and arithmetic (``+``, ``*``,"
    ],
    [
        "deferring to the ``__array_ufunc__`` method, which subclasses must",
        "deferring to the ``__array_ufunc__`` method,"
    ],
    [
        "It is useful for writing classes that do not inherit from `numpy.ndarray`,",
        "It is useful for writing classes that do"
    ],
    [
        "but that should support arithmetic and numpy universal functions like",
        "but that should support arithmetic"
    ],
    [
        "As an trivial example, consider this implementation of an ``ArrayLike``",
        "As an trivial example, consider this implementation"
    ],
    [
        "class that simply wraps a NumPy array and ensures that the result of any",
        "class that simply wraps a NumPy array and"
    ],
    [
        "arithmetic operation is also an ``ArrayLike`` object:",
        "arithmetic operation is also an"
    ],
    [
        "...     def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "... def __array_ufunc__(self, ufunc, method,"
    ],
    [
        "...         for x in inputs + out:",
        "... for x in inputs"
    ],
    [
        "...         inputs = tuple(x.value if isinstance(x, ArrayLike) else x",
        "... inputs = tuple(x.value if isinstance(x, ArrayLike)"
    ],
    [
        "...                 x.value if isinstance(x, ArrayLike) else x",
        "... x.value if isinstance(x, ArrayLike) else"
    ],
    [
        "...         result = getattr(ufunc, method)(*inputs, **kwargs)",
        "... result = getattr(ufunc, method)(*inputs,"
    ],
    [
        "...             return tuple(type(self)(x) for x in result)",
        "... return tuple(type(self)(x) for x"
    ],
    [
        "...         return '%s(%r)' % (type(self).__name__, self.value)",
        "... return '%s(%r)' % (type(self).__name__,"
    ],
    [
        "In interactions between ``ArrayLike`` objects and numbers or numpy arrays,",
        "In interactions between ``ArrayLike`` objects and numbers or numpy"
    ],
    [
        "the result is always another ``ArrayLike``:",
        "the result is always"
    ],
    [
        "Note that unlike ``numpy.ndarray``, ``ArrayLike`` does not allow operations",
        "Note that unlike ``numpy.ndarray``, ``ArrayLike`` does not"
    ],
    [
        "with arbitrary, unrecognized types. This ensures that interactions with",
        "with arbitrary, unrecognized types. This"
    ],
    [
        "ArrayLike preserve a well-defined casting hierarchy.",
        "ArrayLike preserve a well-defined casting"
    ],
    [
        "from numpy._core import umath as um",
        "from numpy._core import umath as"
    ],
    [
        "__add__, __radd__, __iadd__ = _numeric_methods(um.add, 'add')",
        "__add__, __radd__, __iadd__"
    ],
    [
        "__sub__, __rsub__, __isub__ = _numeric_methods(um.subtract, 'sub')",
        "__sub__, __rsub__, __isub__"
    ],
    [
        "__mul__, __rmul__, __imul__ = _numeric_methods(um.multiply, 'mul')",
        "__mul__, __rmul__, __imul__ ="
    ],
    [
        "__mod__, __rmod__, __imod__ = _numeric_methods(um.remainder, 'mod')",
        "__mod__, __rmod__, __imod__"
    ],
    [
        "__pow__, __rpow__, __ipow__ = _numeric_methods(um.power, 'pow')",
        "__pow__, __rpow__, __ipow__ ="
    ],
    [
        "__and__, __rand__, __iand__ = _numeric_methods(um.bitwise_and, 'and')",
        "__and__, __rand__, __iand__"
    ],
    [
        "__xor__, __rxor__, __ixor__ = _numeric_methods(um.bitwise_xor, 'xor')",
        "__xor__, __rxor__, __ixor__ ="
    ],
    [
        "__or__, __ror__, __ior__ = _numeric_methods(um.bitwise_or, 'or')",
        "__or__, __ror__, __ior__ ="
    ],
    [
        "__all__ = ['poly', 'roots', 'polyint', 'polyder', 'polyadd',",
        "__all__ = ['poly', 'roots',"
    ],
    [
        "from numpy.lib._type_check_impl import iscomplex, real, imag, mintypecode",
        "from numpy.lib._type_check_impl import iscomplex, real, imag,"
    ],
    [
        "from numpy.linalg import eigvals, lstsq, inv",
        "from numpy.linalg import eigvals, lstsq,"
    ],
    [
        "Find the coefficients of a polynomial with the given sequence of roots.",
        "Find the coefficients of a polynomial"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences"
    ],
    [
        "Returns the coefficients of the polynomial whose leading coefficient",
        "Returns the coefficients of the polynomial whose"
    ],
    [
        "is one for the given sequence of zeros (multiple roots must be included",
        "is one for the given sequence of zeros (multiple roots must be"
    ],
    [
        "in the sequence as many times as their multiplicity; see Examples).",
        "in the sequence as many times as their multiplicity; see"
    ],
    [
        "A square matrix (or array, which will be treated as a matrix) can also",
        "A square matrix (or array, which will be treated as a matrix)"
    ],
    [
        "be given, in which case the coefficients of the characteristic polynomial",
        "be given, in which case the"
    ],
    [
        "seq_of_zeros : array_like, shape (N,) or (N, N)",
        "seq_of_zeros : array_like, shape (N,) or"
    ],
    [
        "A sequence of polynomial roots, or a square array or matrix object.",
        "A sequence of polynomial roots, or a"
    ],
    [
        "roots : Return the roots of a polynomial.",
        "roots : Return the roots of"
    ],
    [
        "polyfit : Least squares polynomial fit.",
        "polyfit : Least squares"
    ],
    [
        "Specifying the roots of a polynomial still leaves one degree of",
        "Specifying the roots of a polynomial still leaves"
    ],
    [
        "freedom, typically represented by an undetermined leading",
        "freedom, typically represented by an undetermined"
    ],
    [
        "the first one in the returned array - is always taken as one. (If",
        "the first one in the returned array - is always taken as"
    ],
    [
        "for some reason you have one other point, the only automatic way",
        "for some reason you have one other point, the only automatic"
    ],
    [
        "presently to leverage that information is to use ``polyfit``.)",
        "presently to leverage that information"
    ],
    [
        "The characteristic polynomial, :math:`p_a(t)`, of an `n`-by-`n`",
        "The characteristic polynomial, :math:`p_a(t)`, of"
    ],
    [
        ":math:`p_a(t) = \\\\mathrm{det}(t\\\\, \\\\mathbf{I} - \\\\mathbf{A})`,",
        ":math:`p_a(t) = \\\\mathrm{det}(t\\\\, \\\\mathbf{I}"
    ],
    [
        "Given a sequence of a polynomial's zeros:",
        "Given a sequence of"
    ],
    [
        "Return the roots of a polynomial with coefficients given in p.",
        "Return the roots of a polynomial"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences can be found in"
    ],
    [
        "An array containing the roots of the polynomial.",
        "An array containing the roots"
    ],
    [
        "poly : Find the coefficients of a polynomial with a given sequence",
        "poly : Find the coefficients of a polynomial with a given"
    ],
    [
        "polyfit : Least squares polynomial fit.",
        "polyfit : Least squares"
    ],
    [
        "The algorithm relies on computing the eigenvalues of the",
        "The algorithm relies on computing the eigenvalues"
    ],
    [
        "Return an antiderivative (indefinite integral) of a polynomial.",
        "Return an antiderivative (indefinite"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in `numpy.polynomial` is"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences"
    ],
    [
        "The returned order `m` antiderivative `P` of polynomial `p` satisfies",
        "The returned order `m` antiderivative `P`"
    ],
    [
        "integration constants `k`. The constants determine the low-order",
        "integration constants `k`. The constants determine"
    ],
    [
        "k : list of `m` scalars or scalar, optional",
        "k : list of `m` scalars or"
    ],
    [
        "Integration constants. They are given in the order of integration:",
        "Integration constants. They are given in the order of"
    ],
    [
        "those corresponding to highest-order terms come first.",
        "those corresponding to highest-order"
    ],
    [
        "If ``None`` (default), all constants are assumed to be zero.",
        "If ``None`` (default), all constants are assumed to be"
    ],
    [
        "polyder : derivative of a polynomial",
        "polyder : derivative of"
    ],
    [
        "The defining property of the antiderivative:",
        "The defining property of"
    ],
    [
        "The integration constants default to zero, but can be specified:",
        "The integration constants default to zero,"
    ],
    [
        "integrations. Constant of the highest-order polynomial term comes first:",
        "integrations. Constant of the highest-order polynomial term comes"
    ],
    [
        "raise ValueError(\"Order of integral must be positive (see polyder)\")",
        "raise ValueError(\"Order of integral must be positive"
    ],
    [
        "Return the derivative of the specified order of a polynomial.",
        "Return the derivative of the specified order"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences can be found in"
    ],
    [
        "A new polynomial representing the derivative.",
        "A new polynomial"
    ],
    [
        "polyint : Anti-derivative of a polynomial.",
        "polyint : Anti-derivative of"
    ],
    [
        "We can verify this, approximating the derivative with",
        "We can verify this,"
    ],
    [
        "raise ValueError(\"Order of derivative must be positive (see polyint)\")",
        "raise ValueError(\"Order of derivative must be positive"
    ],
    [
        "def _polyfit_dispatcher(x, y, deg, rcond=None, full=None, w=None, cov=None):",
        "def _polyfit_dispatcher(x, y, deg, rcond=None, full=None, w=None,"
    ],
    [
        "def polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False):",
        "def polyfit(x, y, deg, rcond=None, full=False, w=None,"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in `numpy.polynomial` is"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences can"
    ],
    [
        "to points `(x, y)`. Returns a vector of coefficients `p` that minimises",
        "to points `(x, y)`. Returns a vector of"
    ],
    [
        "method is recommended for new code as it is more stable numerically. See",
        "method is recommended for new code as it"
    ],
    [
        "the documentation of the method for more information.",
        "the documentation of the method"
    ],
    [
        "x-coordinates of the M sample points ``(x[i], y[i])``.",
        "x-coordinates of the M sample"
    ],
    [
        "y : array_like, shape (M,) or (M, K)",
        "y : array_like, shape (M,) or (M,"
    ],
    [
        "y-coordinates of the sample points. Several data sets of sample",
        "y-coordinates of the sample points. Several"
    ],
    [
        "points sharing the same x-coordinates can be fitted at once by",
        "points sharing the same x-coordinates can be fitted at"
    ],
    [
        "Relative condition number of the fit. Singular values smaller than",
        "Relative condition number of the fit."
    ],
    [
        "this relative to the largest singular value will be ignored. The",
        "this relative to the largest singular value will be"
    ],
    [
        "default value is len(x)*eps, where eps is the relative precision of",
        "default value is len(x)*eps, where eps is"
    ],
    [
        "Switch determining nature of return value. When it is False (the",
        "Switch determining nature of return value. When it"
    ],
    [
        "default) just the coefficients are returned, when True diagnostic",
        "default) just the coefficients are returned, when"
    ],
    [
        "information from the singular value decomposition is also returned.",
        "information from the singular value"
    ],
    [
        "w : array_like, shape (M,), optional",
        "w : array_like, shape (M,),"
    ],
    [
        "Weights. If not None, the weight ``w[i]`` applies to the unsquared",
        "Weights. If not None, the weight ``w[i]`` applies to"
    ],
    [
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are",
        "residual ``y[i] - y_hat[i]`` at ``x[i]``."
    ],
    [
        "chosen so that the errors of the products ``w[i]*y[i]`` all have the",
        "chosen so that the errors of the products"
    ],
    [
        "same variance.  When using inverse-variance weighting, use",
        "same variance. When using inverse-variance"
    ],
    [
        "cov : bool or str, optional",
        "cov : bool or str,"
    ],
    [
        "If given and not `False`, return not just the estimate but also its",
        "If given and not `False`, return not just the estimate"
    ],
    [
        "covariance matrix. By default, the covariance are scaled by",
        "covariance matrix. By default, the covariance are"
    ],
    [
        "to be unreliable except in a relative sense and everything is scaled",
        "to be unreliable except in a relative sense and everything"
    ],
    [
        "``cov='unscaled'``, as is relevant for the case that the weights are",
        "``cov='unscaled'``, as is relevant for the"
    ],
    [
        "coefficients for `k`-th data set are in ``p[:,k]``.",
        "coefficients for `k`-th data set are in"
    ],
    [
        "These values are only returned if ``full == True``",
        "These values are only returned"
    ],
    [
        "- residuals -- sum of squared residuals of the least squares fit",
        "- residuals -- sum of squared residuals of the least"
    ],
    [
        "- rank -- the effective rank of the scaled Vandermonde",
        "- rank -- the effective rank of the scaled"
    ],
    [
        "- singular_values -- singular values of the scaled Vandermonde",
        "- singular_values -- singular values of the"
    ],
    [
        "- rcond -- value of `rcond`.",
        "- rcond -- value of"
    ],
    [
        "Present only if ``full == False`` and ``cov == True``.  The covariance",
        "Present only if ``full == False`` and"
    ],
    [
        "matrix of the polynomial coefficient estimates.  The diagonal of",
        "matrix of the polynomial coefficient estimates. The diagonal"
    ],
    [
        "this matrix are the variance estimates for each coefficient.  If y",
        "this matrix are the variance estimates"
    ],
    [
        "The rank of the coefficient matrix in the least-squares fit is",
        "The rank of the coefficient matrix"
    ],
    [
        "deficient. The warning is only raised if ``full == False``.",
        "deficient. The warning is only raised"
    ],
    [
        "The warnings can be turned off by",
        "The warnings can be turned"
    ],
    [
        "linalg.lstsq : Computes a least-squares fit.",
        "linalg.lstsq : Computes"
    ],
    [
        "The solution minimizes the squared error",
        "The solution minimizes"
    ],
    [
        "The coefficient matrix of the coefficients `p` is a Vandermonde matrix.",
        "The coefficient matrix of the coefficients `p` is a Vandermonde"
    ],
    [
        "`polyfit` issues a `~exceptions.RankWarning` when the least-squares fit is",
        "`polyfit` issues a `~exceptions.RankWarning` when the least-squares"
    ],
    [
        "badly conditioned. This implies that the best fit is not well-defined due",
        "badly conditioned. This implies that the best fit is"
    ],
    [
        "to numerical error. The results may be improved by lowering the polynomial",
        "to numerical error. The results may be improved by"
    ],
    [
        "degree or by replacing `x` by `x` - `x`.mean(). The `rcond` parameter",
        "degree or by replacing `x` by"
    ],
    [
        "can also be set to a value smaller than its default, but the resulting",
        "can also be set to a value smaller than its"
    ],
    [
        "fit may be spurious: including contributions from the small singular",
        "fit may be spurious: including"
    ],
    [
        "values can add numerical noise to the result.",
        "values can add numerical noise"
    ],
    [
        "Note that fitting polynomial coefficients is inherently badly conditioned",
        "Note that fitting polynomial coefficients is inherently badly"
    ],
    [
        "when the degree of the polynomial is large or the interval of sample points",
        "when the degree of the polynomial is large or the interval of"
    ],
    [
        "is badly centered. The quality of the fit should always be checked in these",
        "is badly centered. The quality of the fit should always be checked in"
    ],
    [
        "cases. When polynomial fits are not satisfactory, splines may be a good",
        "cases. When polynomial fits are not satisfactory, splines"
    ],
    [
        "raise TypeError(\"expected non-empty vector for x\")",
        "raise TypeError(\"expected non-empty vector"
    ],
    [
        "raise TypeError(\"expected x and y to have same length\")",
        "raise TypeError(\"expected x and y to"
    ],
    [
        "raise TypeError(\"expected w and y to have the same length\")",
        "raise TypeError(\"expected w and y to have the same"
    ],
    [
        "c, resids, rank, s = lstsq(lhs, rhs, rcond)",
        "c, resids, rank, s ="
    ],
    [
        "if rank != order and not full:",
        "if rank != order and"
    ],
    [
        "msg = \"Polyfit may be poorly conditioned\"",
        "msg = \"Polyfit may be poorly"
    ],
    [
        "return c, resids, rank, s, rcond",
        "return c, resids, rank,"
    ],
    [
        "raise ValueError(\"the number of data points must exceed order \"",
        "raise ValueError(\"the number of data"
    ],
    [
        "fac = resids / (len(x) - order)",
        "fac = resids / (len(x) -"
    ],
    [
        "return c, Vbase[:, :, NX.newaxis] * fac",
        "return c, Vbase[:, :,"
    ],
    [
        "Evaluate a polynomial at specific values.",
        "Evaluate a polynomial at specific"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences can"
    ],
    [
        "If `p` is of length N, this function returns the value::",
        "If `p` is of length N, this function"
    ],
    [
        "If `x` is a sequence, then ``p(x)`` is returned for each element of ``x``.",
        "If `x` is a sequence, then ``p(x)`` is"
    ],
    [
        "If `x` is another polynomial then the composite polynomial ``p(x(t))``",
        "If `x` is another polynomial then"
    ],
    [
        "to zero) from highest degree to the constant term, or an",
        "to zero) from highest degree to the constant term,"
    ],
    [
        "polynomials, i.e., `x` is \"substituted\" in `p` and the simplified",
        "polynomials, i.e., `x` is \"substituted\" in `p`"
    ],
    [
        "result is returned. In addition, the type of `x` - array_like or",
        "result is returned. In addition, the type"
    ],
    [
        "for polynomials of high degree the values may be inaccurate due to",
        "for polynomials of high degree the"
    ],
    [
        "If `x` is a subtype of `ndarray` the return value will be of the same type.",
        "If `x` is a subtype of `ndarray` the return value will be of"
    ],
    [
        "trans. Ed.), *Handbook of Mathematics*, New York, Van Nostrand",
        "trans. Ed.), *Handbook of Mathematics*, New York,"
    ],
    [
        "y = y * x + pv",
        "y = y * x +"
    ],
    [
        "Find the sum of two polynomials.",
        "Find the sum"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in `numpy.polynomial`"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences"
    ],
    [
        "Returns the polynomial resulting from the sum of two input polynomials.",
        "Returns the polynomial resulting from the sum of"
    ],
    [
        "coefficients, from highest to lowest degree.",
        "coefficients, from highest to"
    ],
    [
        "polynomial coefficients from highest to lowest degree.",
        "polynomial coefficients from highest to"
    ],
    [
        "poly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval",
        "poly, polyadd, polyder, polydiv, polyfit, polyint, polysub,"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in `numpy.polynomial`"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences"
    ],
    [
        "Find the product of two polynomials.",
        "Find the product of two"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in `numpy.polynomial` is"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences can"
    ],
    [
        "Finds the polynomial resulting from the multiplication of the two input",
        "Finds the polynomial resulting from the multiplication of the"
    ],
    [
        "of polynomial coefficients, from highest to lowest degree.",
        "of polynomial coefficients, from highest"
    ],
    [
        "The polynomial resulting from the multiplication of the inputs. If",
        "The polynomial resulting from the multiplication of"
    ],
    [
        "poly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval",
        "poly, polyadd, polyder, polydiv, polyfit, polyint,"
    ],
    [
        "convolve : Array convolution. Same output as polymul, but has parameter",
        "convolve : Array convolution. Same output as polymul, but has"
    ],
    [
        "Returns the quotient and remainder of polynomial division.",
        "Returns the quotient and remainder of polynomial"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences can be found in"
    ],
    [
        "The input arrays are the coefficients (including any coefficients",
        "The input arrays are the"
    ],
    [
        "equal to zero) of the \"numerator\" (dividend) and \"denominator\"",
        "equal to zero) of the \"numerator\" (dividend)"
    ],
    [
        "Coefficients, including those equal to zero, of the quotient.",
        "Coefficients, including those equal to zero, of"
    ],
    [
        "Coefficients, including those equal to zero, of the remainder.",
        "Coefficients, including those equal to zero, of"
    ],
    [
        "poly, polyadd, polyder, polydiv, polyfit, polyint, polymul, polysub",
        "poly, polyadd, polyder, polydiv, polyfit, polyint, polymul,"
    ],
    [
        "not equal `v.ndim`. In other words, all four possible combinations -",
        "not equal `v.ndim`. In other words,"
    ],
    [
        "new polynomial API defined in `numpy.polynomial` is preferred.",
        "new polynomial API defined in `numpy.polynomial`"
    ],
    [
        "A summary of the differences can be found in the",
        "A summary of the differences"
    ],
    [
        "A convenience class, used to encapsulate \"natural\" operations on",
        "A convenience class, used to"
    ],
    [
        "polynomials so that said operations may take on their customary",
        "polynomials so that said operations may"
    ],
    [
        "The polynomial's coefficients, in decreasing powers, or if",
        "The polynomial's coefficients, in decreasing powers, or"
    ],
    [
        "the value of the second parameter is True, the polynomial's",
        "the value of the second parameter is"
    ],
    [
        "If True, `c_or_r` specifies the polynomial's roots; the default",
        "If True, `c_or_r` specifies the polynomial's"
    ],
    [
        "Changes the variable used when printing `p` from `x` to `variable`",
        "Changes the variable used when printing `p`"
    ],
    [
        "Display the order (the leading zero-coefficients are removed):",
        "Display the order (the leading zero-coefficients"
    ],
    [
        "Show the coefficient of the k-th power in the polynomial",
        "Show the coefficient of the k-th power in"
    ],
    [
        "Polynomials can be added, subtracted, multiplied, and divided",
        "Polynomials can be added, subtracted, multiplied, and"
    ],
    [
        "``asarray(p)`` gives the coefficient array, so polynomials can be",
        "``asarray(p)`` gives the coefficient array, so polynomials can"
    ],
    [
        "used in all functions that accept arrays:",
        "used in all functions"
    ],
    [
        "The variable used in the string representation of `p` can be modified,",
        "The variable used in the string"
    ],
    [
        "Construct a polynomial from its roots:",
        "Construct a polynomial from"
    ],
    [
        "This is the same polynomial as obtained by:",
        "This is the same polynomial"
    ],
    [
        "\"\"\" The name of the polynomial variable \"\"\"",
        "\"\"\" The name of the polynomial variable"
    ],
    [
        "\"\"\" The order or degree of the polynomial \"\"\"",
        "\"\"\" The order or degree of the"
    ],
    [
        "c = coef = coefficients = coeffs",
        "c = coef = coefficients"
    ],
    [
        "msg = (\"In the future extra properties will not be copied \"",
        "msg = (\"In the future extra properties"
    ],
    [
        "coefstr = '(%s + %sj)' % (fmt_float(real(coeff)),",
        "coefstr = '(%s + %sj)' %"
    ],
    [
        "newstr = '%s %s' % (coefstr, var)",
        "newstr = '%s %s' %"
    ],
    [
        "newstr = '%s**%d' % (var, power,)",
        "newstr = '%s**%d' % (var,"
    ],
    [
        "newstr = '%s %s**%d' % (coefstr, var, power)",
        "newstr = '%s %s**%d'"
    ],
    [
        "thestr = \"%s + %s\" % (thestr, newstr)",
        "thestr = \"%s + %s\" % (thestr,"
    ],
    [
        "raise ValueError(\"Power to non-negative integers only.\")",
        "raise ValueError(\"Power to non-negative integers"
    ],
    [
        "raise ValueError(\"Does not support negative powers.\")",
        "raise ValueError(\"Does not"
    ],
    [
        "zr = NX.zeros(key - self.order, self.coeffs.dtype)",
        "zr = NX.zeros(key -"
    ],
    [
        "Return an antiderivative (indefinite integral) of this polynomial.",
        "Return an antiderivative (indefinite integral)"
    ],
    [
        "Refer to `polyint` for full documentation.",
        "Refer to `polyint` for full"
    ],
    [
        "Return a derivative of this polynomial.",
        "Return a derivative of this"
    ],
    [
        "Refer to `polyder` for full documentation.",
        "Refer to `polyder` for full"
    ],
    [
        "Collection of utilities to manipulate structured arrays.",
        "Collection of utilities to"
    ],
    [
        "Most of these functions were initially implemented by John Hunter for",
        "Most of these functions were initially implemented"
    ],
    [
        "matplotlib.  They have been rewritten and extended for convenience.",
        "matplotlib. They have been rewritten and"
    ],
    [
        "Fills fields from output with fields from input,",
        "Fills fields from output with fields from"
    ],
    [
        "* `output` should be at least the same size as `input`",
        "* `output` should be at least the"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions"
    ],
    [
        "Produce a list of name/dtype pairs corresponding to the dtype fields",
        "Produce a list of name/dtype pairs corresponding"
    ],
    [
        "Similar to dtype.descr, but the second item of each tuple is a dtype, not a",
        "Similar to dtype.descr, but the second item of each tuple"
    ],
    [
        "string. As a result, this handles subarray dtypes",
        "string. As a result, this handles"
    ],
    [
        "Can be passed to the dtype constructor to reconstruct the dtype, noting that",
        "Can be passed to the dtype constructor to"
    ],
    [
        "fields = ((name, dtype.fields[name]) for name in dtype.names)",
        "fields = ((name, dtype.fields[name]) for name"
    ],
    [
        "Returns the field names of the input datatype as a tuple. Input datatype",
        "Returns the field names of the input datatype as a"
    ],
    [
        "must have fields otherwise error is raised.",
        "must have fields otherwise error is"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions as"
    ],
    [
        ">>> adtype = np.dtype([('a', int), ('b', [('ba', int), ('bb', int)])])",
        ">>> adtype = np.dtype([('a', int), ('b',"
    ],
    [
        "Returns the field names of the input datatype as a tuple. Input datatype",
        "Returns the field names of the input"
    ],
    [
        "must have fields otherwise error is raised.",
        "must have fields otherwise error is"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions"
    ],
    [
        ">>> adtype = np.dtype([('a', int), ('b', [('ba', int), ('bb', int)])])",
        ">>> adtype = np.dtype([('a', int), ('b', [('ba',"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import"
    ],
    [
        "Combine the dtype description of a series of arrays.",
        "Combine the dtype description of a series of"
    ],
    [
        "Returns a dictionary with fields indexing lists of their parent fields.",
        "Returns a dictionary with fields indexing"
    ],
    [
        "This function is used to simplify access to fields nested in other fields.",
        "This function is used to simplify access to fields nested"
    ],
    [
        "Last processed field name (used internally during recursion).",
        "Last processed field name (used"
    ],
    [
        "Dictionary of parent fields (used internally during recursion).",
        "Dictionary of parent fields"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions as"
    ],
    [
        "...                            ('BB', [('BBA', int), ('BBB', int)])])])",
        "... ('BB', [('BBA',"
    ],
    [
        "{'A': [], 'B': [], 'BA': ['B'], 'BB': ['B'], 'BBA': ['B', 'BB'], 'BBB': ['B', 'BB']}",
        "{'A': [], 'B': [], 'BA': ['B'], 'BB': ['B'], 'BBA':"
    ],
    [
        "lastparent = list((parents.get(lastname, []) or []))",
        "lastparent = list((parents.get(lastname,"
    ],
    [
        "Returns an iterator of concatenated fields from a sequence of arrays,",
        "Returns an iterator of concatenated fields from"
    ],
    [
        "Returns an iterator of concatenated fields from a sequence of arrays.",
        "Returns an iterator of concatenated fields from a sequence of"
    ],
    [
        "Returns an iterator of concatenated items from a sequence of arrays.",
        "Returns an iterator of concatenated items from a sequence of"
    ],
    [
        "Value used to pad shorter iterables.",
        "Value used to"
    ],
    [
        "Private function: return a recarray, a ndarray, a MaskedArray",
        "Private function: return a recarray,"
    ],
    [
        "or a MaskedRecords depending on the input parameters",
        "or a MaskedRecords depending on"
    ],
    [
        "Update the fill_value and masked data of `output`",
        "Update the fill_value and masked"
    ],
    [
        "from the default given in a dictionary defaults.",
        "from the default given in"
    ],
    [
        "(data, mask, fill_value) = (output.data, output.mask, output.fill_value)",
        "(data, mask, fill_value) = (output.data, output.mask,"
    ],
    [
        "for (k, v) in (defaults or {}).items():",
        "for (k, v) in (defaults"
    ],
    [
        "Filling value used to pad missing data on the shorter arrays.",
        "Filling value used to pad missing data on the shorter"
    ],
    [
        "Whether to return a masked array or not.",
        "Whether to return a"
    ],
    [
        "Whether to return a recarray (MaskedRecords) or not.",
        "Whether to return a recarray (MaskedRecords) or"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import"
    ],
    [
        "* Without a mask, the missing value will be filled with something,",
        "* Without a mask, the missing value will be"
    ],
    [
        "depending on what its corresponding type:",
        "depending on what its corresponding"
    ],
    [
        "* XXX: I just obtained these values empirically",
        "* XXX: I just obtained these"
    ],
    [
        "if not flatten or _zip_dtype((seqarrays,), flatten=True) == seqdtype:",
        "if not flatten or _zip_dtype((seqarrays,), flatten=True) =="
    ],
    [
        "seqarrays = [np.asanyarray(_m) for _m in seqarrays]",
        "seqarrays = [np.asanyarray(_m) for _m in"
    ],
    [
        "sizes = tuple(a.size for a in seqarrays)",
        "sizes = tuple(a.size for a"
    ],
    [
        "for (a, n) in zip(seqarrays, sizes):",
        "for (a, n) in"
    ],
    [
        "for (a, n) in zip(seqarrays, sizes):",
        "for (a, n) in zip(seqarrays,"
    ],
    [
        "Return a new array with fields in `drop_names` dropped.",
        "Return a new array with"
    ],
    [
        "String or sequence of strings corresponding to the names of the",
        "String or sequence of strings corresponding"
    ],
    [
        "Whether to return a masked array or not.",
        "Whether to return a masked array or"
    ],
    [
        "asrecarray : string or sequence, optional",
        "asrecarray : string or"
    ],
    [
        "Whether to return a recarray or a mrecarray (`asrecarray=True`) or",
        "Whether to return a recarray or"
    ],
    [
        "a plain ndarray or masked array with flexible dtype. The default",
        "a plain ndarray or masked array with flexible dtype. The"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions as"
    ],
    [
        "Return a new array keeping only the fields in `keep_names`,",
        "Return a new array keeping only"
    ],
    [
        "and preserving the order of those fields.",
        "and preserving the order of"
    ],
    [
        "String or sequence of strings corresponding to the names of the",
        "String or sequence of strings corresponding to"
    ],
    [
        "fields to keep. Order of the names will be preserved.",
        "fields to keep. Order of the"
    ],
    [
        "Whether to return a masked array or not.",
        "Whether to return a masked array"
    ],
    [
        "asrecarray : string or sequence, optional",
        "asrecarray : string or"
    ],
    [
        "Whether to return a recarray or a mrecarray (`asrecarray=True`) or",
        "Whether to return a recarray or"
    ],
    [
        "a plain ndarray or masked array with flexible dtype. The default",
        "a plain ndarray or masked array with flexible dtype."
    ],
    [
        "newdtype = [(n, base.dtype[n]) for n in keep_names]",
        "newdtype = [(n, base.dtype[n]) for n"
    ],
    [
        "Returns a new numpy.recarray with fields in `drop_names` dropped.",
        "Returns a new numpy.recarray with fields in"
    ],
    [
        "Rename the fields from a flexible-datatype ndarray or recarray.",
        "Rename the fields from a flexible-datatype ndarray"
    ],
    [
        "Input array whose fields must be modified.",
        "Input array whose fields must be"
    ],
    [
        "Dictionary mapping old field names to their new version.",
        "Dictionary mapping old field names to their new"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import"
    ],
    [
        "Add new fields to an existing array.",
        "Add new fields to an existing"
    ],
    [
        "The names of the fields are given with the `names` arguments,",
        "The names of the fields are given with the `names`"
    ],
    [
        "the corresponding values with the `data` arguments.",
        "the corresponding values with the `data`"
    ],
    [
        "If a single field is appended, `names`, `data` and `dtypes` do not have",
        "If a single field is appended, `names`, `data` and `dtypes` do not"
    ],
    [
        "to be lists but just values.",
        "to be lists"
    ],
    [
        "String or sequence of strings corresponding to the names",
        "String or sequence of strings corresponding to the"
    ],
    [
        "data : array or sequence of arrays",
        "data : array or"
    ],
    [
        "Array or sequence of arrays storing the fields to add to the base.",
        "Array or sequence of arrays storing the fields to add to"
    ],
    [
        "dtypes : sequence of datatypes, optional",
        "dtypes : sequence"
    ],
    [
        "If None, the datatypes are estimated from the `data`.",
        "If None, the datatypes are"
    ],
    [
        "Filling value used to pad missing data on the shorter arrays.",
        "Filling value used to pad missing data"
    ],
    [
        "Whether to return a masked array or not.",
        "Whether to return a masked array"
    ],
    [
        "Whether to return a recarray (MaskedRecords) or not.",
        "Whether to return a recarray"
    ],
    [
        "msg = \"The number of arrays does not match the number of names\"",
        "msg = \"The number of arrays does not match the number of"
    ],
    [
        "data = [np.array(a, copy=None, subok=True) for a in data]",
        "data = [np.array(a, copy=None, subok=True) for a"
    ],
    [
        "data = [a.view([(name, a.dtype)]) for (name, a) in zip(names, data)]",
        "data = [a.view([(name, a.dtype)]) for (name, a) in"
    ],
    [
        "msg = \"The dtypes argument must be None, a dtype, or a list.\"",
        "msg = \"The dtypes argument must be None, a dtype,"
    ],
    [
        "data = [np.array(a, copy=None, subok=True, dtype=d).view([(n, d)])",
        "data = [np.array(a, copy=None, subok=True,"
    ],
    [
        "for (a, n, d) in zip(data, names, dtypes)]",
        "for (a, n, d) in zip(data,"
    ],
    [
        "Add new fields to an existing array.",
        "Add new fields to an existing"
    ],
    [
        "The names of the fields are given with the `names` arguments,",
        "The names of the fields are given with"
    ],
    [
        "the corresponding values with the `data` arguments.",
        "the corresponding values with the"
    ],
    [
        "If a single field is appended, `names`, `data` and `dtypes` do not have",
        "If a single field is appended, `names`,"
    ],
    [
        "to be lists but just values.",
        "to be lists but"
    ],
    [
        "String or sequence of strings corresponding to the names",
        "String or sequence of strings corresponding to"
    ],
    [
        "data : array or sequence of arrays",
        "data : array or sequence"
    ],
    [
        "Array or sequence of arrays storing the fields to add to the base.",
        "Array or sequence of arrays storing the fields to add"
    ],
    [
        "dtypes : sequence of datatypes, optional",
        "dtypes : sequence of datatypes,"
    ],
    [
        "If None, the datatypes are estimated from the `data`.",
        "If None, the datatypes are estimated"
    ],
    [
        "Re-pack the fields of a structured array or dtype in memory.",
        "Re-pack the fields of a structured array or dtype in"
    ],
    [
        "The memory layout of structured datatypes allows fields at arbitrary",
        "The memory layout of structured"
    ],
    [
        "byte offsets. This means the fields can be separated by padding bytes,",
        "byte offsets. This means the fields can be separated"
    ],
    [
        "their offsets can be non-monotonically increasing, and they can overlap.",
        "their offsets can be non-monotonically"
    ],
    [
        "This method removes any overlaps and reorders the fields in memory so they",
        "This method removes any overlaps and reorders"
    ],
    [
        "have increasing byte offsets, and adds or removes padding bytes depending",
        "have increasing byte offsets, and adds or removes padding"
    ],
    [
        "on the `align` option, which behaves like the `align` option to",
        "on the `align` option, which behaves like the `align`"
    ],
    [
        "If `align=False`, this method produces a \"packed\" memory layout in which",
        "If `align=False`, this method produces a"
    ],
    [
        "each field starts at the byte the previous field ended, and any padding",
        "each field starts at the byte the previous field"
    ],
    [
        "If `align=True`, this methods produces an \"aligned\" memory layout in which",
        "If `align=True`, this methods produces an"
    ],
    [
        "each field's offset is a multiple of its alignment, and the total itemsize",
        "each field's offset is a multiple of its"
    ],
    [
        "is a multiple of the largest alignment, by adding padding bytes as needed.",
        "is a multiple of the largest alignment, by adding padding bytes"
    ],
    [
        "array or dtype for which to repack the fields.",
        "array or dtype for which to repack the"
    ],
    [
        "If true, use an \"aligned\" memory layout, otherwise use a \"packed\" layout.",
        "If true, use an \"aligned\" memory layout,"
    ],
    [
        "If True, also repack nested structures.",
        "If True, also"
    ],
    [
        "Copy of `a` with fields repacked, or `a` itself if no repacking was",
        "Copy of `a` with fields repacked, or"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions as"
    ],
    [
        "Returns a flat list of (dtype, count, offset) tuples of all the",
        "Returns a flat list of (dtype, count, offset) tuples of all"
    ],
    [
        "scalar fields in the dtype \"dt\", including nested fields, in left",
        "scalar fields in the dtype \"dt\", including nested fields,"
    ],
    [
        "fields.append((np.dtype((f_dt, (n,))), n, f_offset + offset))",
        "fields.append((np.dtype((f_dt, (n,))), n,"
    ],
    [
        "subfields = _get_fields_and_offsets(f_dt, f_offset + offset)",
        "subfields = _get_fields_and_offsets(f_dt,"
    ],
    [
        "fields.extend([(d, c, o + i * size) for d, c, o in subfields])",
        "fields.extend([(d, c, o + i * size) for d, c, o in"
    ],
    [
        "Returns the stride between the fields, or None if the stride is not",
        "Returns the stride between the fields, or None if the"
    ],
    [
        "constant. The values in \"counts\" designate the lengths of",
        "constant. The values in \"counts\""
    ],
    [
        "subarrays. Subarrays are treated as many contiguous fields, with",
        "subarrays. Subarrays are treated as many contiguous fields,"
    ],
    [
        "The new array will have a new last dimension equal in size to the",
        "The new array will have a new last"
    ],
    [
        "number of field-elements of the input array. If not supplied, the output",
        "number of field-elements of the input array."
    ],
    [
        "datatype is determined from the numpy type promotion rules applied to all",
        "datatype is determined from the numpy"
    ],
    [
        "Nested fields, as well as each element of any subarray fields, all count",
        "Nested fields, as well as each element of any subarray fields,"
    ],
    [
        "Structured array or dtype to convert. Cannot contain object datatype.",
        "Structured array or dtype to convert. Cannot contain"
    ],
    [
        "The dtype of the output unstructured array.",
        "The dtype of the output unstructured"
    ],
    [
        "If true, always return a copy. If false, a view is returned if",
        "If true, always return a copy. If false, a view is"
    ],
    [
        "possible, such as when the `dtype` and strides of the fields are",
        "possible, such as when the `dtype` and"
    ],
    [
        "suitable and the array subtype is one of `numpy.ndarray`,",
        "suitable and the array subtype"
    ],
    [
        "A view can now be returned if the fields are separated by a",
        "A view can now be returned if the"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv',"
    ],
    [
        "See casting argument of `numpy.ndarray.astype`. Controls what kind of",
        "See casting argument of `numpy.ndarray.astype`. Controls what kind"
    ],
    [
        "Unstructured array with one more dimension.",
        "Unstructured array with one"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions"
    ],
    [
        "raise ValueError('arr must be a structured array')",
        "raise ValueError('arr must be a structured"
    ],
    [
        "raise ValueError(\"arr has no fields. Unable to guess dtype\")",
        "raise ValueError(\"arr has no fields."
    ],
    [
        "raise NotImplementedError(\"arr with no fields is not supported\")",
        "raise NotImplementedError(\"arr with no"
    ],
    [
        "names = ['f{}'.format(n) for n in range(n_fields)]",
        "names = ['f{}'.format(n) for"
    ],
    [
        "out_dtype = np.result_type(*[dt.base for dt in dts])",
        "out_dtype = np.result_type(*[dt.base for dt"
    ],
    [
        "can_view = type(arr) in (np.ndarray, np.recarray, np.memmap)",
        "can_view = type(arr) in"
    ],
    [
        "if (not copy) and can_view and all(dt.base == out_dtype for dt in dts):",
        "if (not copy) and can_view and all(dt.base == out_dtype"
    ],
    [
        "new_shape = arr.shape + (sum(counts), out_dtype.itemsize)",
        "new_shape = arr.shape"
    ],
    [
        "'formats': [(out_dtype, dt.shape) for dt in dts]})",
        "'formats': [(out_dtype, dt.shape) for dt"
    ],
    [
        "The last dimension of the input array is converted into a structure, with",
        "The last dimension of the input array is converted into a structure,"
    ],
    [
        "number of field-elements equal to the size of the last dimension of the",
        "number of field-elements equal to the size"
    ],
    [
        "input array. By default all output fields have the input array's dtype, but",
        "input array. By default all output fields have the"
    ],
    [
        "an output structured dtype with an equal number of fields-elements can be",
        "an output structured dtype with an"
    ],
    [
        "Nested fields, as well as each element of any subarray fields, all count",
        "Nested fields, as well as each element of any"
    ],
    [
        "Unstructured array or dtype to convert.",
        "Unstructured array or"
    ],
    [
        "The structured dtype of the output array",
        "The structured dtype of the"
    ],
    [
        "names : list of strings, optional",
        "names : list"
    ],
    [
        "If dtype is not supplied, this specifies the field names for the output",
        "If dtype is not supplied, this specifies the field names"
    ],
    [
        "dtype, in order. The field dtypes will be the same as the input array.",
        "dtype, in order. The field dtypes will be the same as the"
    ],
    [
        "Whether to create an aligned memory layout.",
        "Whether to create an"
    ],
    [
        "See copy argument to `numpy.ndarray.astype`. If true, always return a",
        "See copy argument to `numpy.ndarray.astype`."
    ],
    [
        "copy. If false, and `dtype` requirements are satisfied, a view is",
        "copy. If false, and `dtype` requirements are satisfied, a view"
    ],
    [
        "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
        "casting : {'no', 'equiv', 'safe',"
    ],
    [
        "See casting argument of `numpy.ndarray.astype`. Controls what kind of",
        "See casting argument of `numpy.ndarray.astype`. Controls what kind"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions as"
    ],
    [
        "raise ValueError('arr must have at least one dimension')",
        "raise ValueError('arr must have"
    ],
    [
        "names = ['f{}'.format(n) for n in range(n_elem)]",
        "names = ['f{}'.format(n) for n in"
    ],
    [
        "out_dtype = np.dtype([(n, arr.dtype) for n in names], align=align)",
        "out_dtype = np.dtype([(n, arr.dtype) for n in names],"
    ],
    [
        "raise ValueError(\"don't supply both dtype and names\")",
        "raise ValueError(\"don't supply both dtype and"
    ],
    [
        "dts, counts, offsets = [], [], []",
        "dts, counts, offsets ="
    ],
    [
        "raise ValueError('The length of the last dimension of arr must '",
        "raise ValueError('The length of the last dimension of"
    ],
    [
        "'be equal to the number of fields in dtype')",
        "'be equal to the number of fields"
    ],
    [
        "raise ValueError(\"align was True but dtype is not aligned\")",
        "raise ValueError(\"align was True but dtype"
    ],
    [
        "names = ['f{}'.format(n) for n in range(len(fields))]",
        "names = ['f{}'.format(n) for"
    ],
    [
        "'formats': [(arr.dtype, dt.shape) for dt in dts]})",
        "'formats': [(arr.dtype, dt.shape) for"
    ],
    [
        "Apply function 'func' as a reduction across fields of a structured array.",
        "Apply function 'func' as a reduction across fields"
    ],
    [
        "This is similar to `numpy.apply_along_axis`, but treats the fields of a",
        "This is similar to `numpy.apply_along_axis`, but treats the fields of"
    ],
    [
        "structured array as an extra axis. The fields are all first cast to a",
        "structured array as an extra axis. The fields are all first"
    ],
    [
        "common type following the type-promotion rules from `numpy.result_type`",
        "common type following the"
    ],
    [
        "Function to apply on the \"field\" dimension. This function must",
        "Function to apply on the \"field\" dimension. This"
    ],
    [
        "support an `axis` argument, like `numpy.mean`, `numpy.sum`, etc.",
        "support an `axis` argument, like `numpy.mean`, `numpy.sum`,"
    ],
    [
        "Structured array for which to apply func.",
        "Structured array for which to apply"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions"
    ],
    [
        "raise ValueError('arr must be a structured array')",
        "raise ValueError('arr must be a structured"
    ],
    [
        "Assigns values from one structured array to another by field name.",
        "Assigns values from one structured array to another by"
    ],
    [
        "copies fields \"by position\", meaning that the first field from the src is",
        "copies fields \"by position\", meaning that the first field from"
    ],
    [
        "copied to the first field of the dst, and so on, regardless of field name.",
        "copied to the first field of the dst, and"
    ],
    [
        "This function instead copies \"by field name\", such that fields in the dst",
        "This function instead copies \"by field name\", such that fields in the"
    ],
    [
        "are assigned from the identically named field in the src. This applies",
        "are assigned from the identically named field in the"
    ],
    [
        "recursively for nested structures. This is how structure assignment worked",
        "recursively for nested structures. This is how structure"
    ],
    [
        "The source and destination arrays during assignment.",
        "The source and destination"
    ],
    [
        "If True, fields in the dst for which there was no matching",
        "If True, fields in the dst for which"
    ],
    [
        "Casts a structured array to a new dtype using assignment by field-name.",
        "Casts a structured array to a new"
    ],
    [
        "This function assigns from the old to the new array by name, so the",
        "This function assigns from the old to the new array by name,"
    ],
    [
        "value of a field in the output array is the value of the field with the",
        "value of a field in the output array is the value"
    ],
    [
        "same name in the source array. This has the effect of creating a new",
        "same name in the source array. This"
    ],
    [
        "ndarray containing only the fields \"required\" by the required_dtype.",
        "ndarray containing only the fields \"required\" by"
    ],
    [
        "If a field name in the required_dtype does not exist in the",
        "If a field name in the required_dtype does not exist in"
    ],
    [
        "array with the new dtype, with field values copied from the fields in",
        "array with the new dtype, with field values copied from the fields"
    ],
    [
        "the input array with the same name",
        "the input array with the"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import"
    ],
    [
        "Dictionary mapping field names to the corresponding default values.",
        "Dictionary mapping field names to the corresponding default"
    ],
    [
        "Whether to return a MaskedArray (or MaskedRecords is",
        "Whether to return a MaskedArray (or MaskedRecords"
    ],
    [
        "Whether to return a recarray (or MaskedRecords if `usemask==True`)",
        "Whether to return a recarray (or"
    ],
    [
        "Whether automatically cast the type of the field to the maximum.",
        "Whether automatically cast the type of the"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import recfunctions as"
    ],
    [
        "mask=[(False, False,  True), (False, False,  True),",
        "mask=[(False, False, True), (False, False,"
    ],
    [
        "(False, False, False), (False, False, False),",
        "(False, False, False), (False, False,"
    ],
    [
        "seqarrays = [np.asanyarray(a).ravel() for a in arrays]",
        "seqarrays = [np.asanyarray(a).ravel() for a in"
    ],
    [
        "nrecords = [len(a) for a in seqarrays]",
        "nrecords = [len(a) for a"
    ],
    [
        "ndtype = [a.dtype for a in seqarrays]",
        "ndtype = [a.dtype for"
    ],
    [
        "fldnames = [d.names for d in ndtype]",
        "fldnames = [d.names for d in"
    ],
    [
        "names = [n for n, d in newdescr]",
        "names = [n for n, d in"
    ],
    [
        "raise TypeError(\"Incompatible type '%s' <> '%s'\" %",
        "raise TypeError(\"Incompatible type '%s' <>"
    ],
    [
        "Find the duplicates in a structured array along a given key",
        "Find the duplicates in a structured array along"
    ],
    [
        "Name of the fields along which to check the duplicates.",
        "Name of the fields along"
    ],
    [
        "If None, the search is performed by records",
        "If None, the search is"
    ],
    [
        "Whether masked data should be discarded or considered as duplicates.",
        "Whether masked data should be discarded or"
    ],
    [
        "Whether to return the indices of the duplicated values.",
        "Whether to return the indices"
    ],
    [
        ">>> from numpy.lib import recfunctions as rfn",
        ">>> from numpy.lib import"
    ],
    [
        "The key should be either a string or a sequence of string corresponding",
        "The key should be either a string or a sequence"
    ],
    [
        "to the fields used to join the array.  An exception is raised if the",
        "to the fields used to join the array. An exception is"
    ],
    [
        "will make the output quite unreliable. Note that duplicates are not",
        "will make the output quite unreliable. Note that duplicates"
    ],
    [
        "A string or a sequence of strings corresponding to the fields used",
        "A string or a sequence of strings corresponding to the fields"
    ],
    [
        "jointype : {'inner', 'outer', 'leftouter'}, optional",
        "jointype : {'inner', 'outer', 'leftouter'},"
    ],
    [
        "If 'outer', returns the common elements as well as the elements of",
        "If 'outer', returns the common elements as well"
    ],
    [
        "Dictionary mapping field names to the corresponding default values.",
        "Dictionary mapping field names to the"
    ],
    [
        "Whether to return a MaskedArray (or MaskedRecords is",
        "Whether to return a"
    ],
    [
        "Whether to return a recarray (or MaskedRecords if `usemask==True`)",
        "Whether to return a recarray"
    ],
    [
        "* The output is sorted along the key.",
        "* The output is sorted"
    ],
    [
        "* A temporary array is formed by dropping the fields not in the key for",
        "* A temporary array is formed by dropping the fields not in the key"
    ],
    [
        "the two arrays and concatenating the result. This array is then",
        "the two arrays and concatenating the result. This"
    ],
    [
        "sorted, and the common entries selected. The output is constructed by",
        "sorted, and the common entries selected."
    ],
    [
        "filling the fields with the selected entries. Matching is not",
        "filling the fields with the selected entries. Matching"
    ],
    [
        "preserved if there are some duplicates...",
        "preserved if there are some"
    ],
    [
        "if jointype not in ('inner', 'outer', 'leftouter'):",
        "if jointype not in ('inner', 'outer',"
    ],
    [
        "\"The 'jointype' argument should be in 'inner', \"",
        "\"The 'jointype' argument should be in 'inner',"
    ],
    [
        "\"'outer' or 'leftouter' (got '%s' instead)\" % jointype",
        "\"'outer' or 'leftouter' (got '%s' instead)\""
    ],
    [
        "raise ValueError(\"duplicate join key %r\" % dup)",
        "raise ValueError(\"duplicate join key"
    ],
    [
        "msg += \"can't both be empty\"",
        "msg += \"can't both be"
    ],
    [
        "names = [name for name, dtype in ndtype]",
        "names = [name for name,"
    ],
    [
        "kwargs = {'usemask': usemask, 'asrecarray': asrecarray}",
        "kwargs = {'usemask': usemask,"
    ],
    [
        "Alternative to join_by, that always returns a np.recarray.",
        "Alternative to join_by, that always returns a"
    ],
    [
        "'defaults': defaults, 'usemask': False, 'asrecarray': True}",
        "'defaults': defaults, 'usemask': False,"
    ],
    [
        "Container class for backward compatibility with NumArray.",
        "Container class for backward"
    ],
    [
        "The user_array.container class exists for backward compatibility with NumArray",
        "The user_array.container class exists for backward"
    ],
    [
        "and is not meant to be used in new code. If you need to create an array",
        "and is not meant to be used in new code. If you need to create an"
    ],
    [
        "container class, we recommend either creating a class that wraps an ndarray",
        "container class, we recommend either creating a"
    ],
    [
        "array, asarray, absolute, add, subtract, multiply, divide,",
        "array, asarray, absolute, add, subtract,"
    ],
    [
        "remainder, power, left_shift, right_shift, bitwise_and, bitwise_or,",
        "remainder, power, left_shift,"
    ],
    [
        "bitwise_xor, invert, less, less_equal, not_equal, equal, greater,",
        "bitwise_xor, invert, less, less_equal, not_equal, equal,"
    ],
    [
        "greater_equal, shape, reshape, arange, sin, sqrt, transpose",
        "greater_equal, shape, reshape, arange, sin, sqrt,"
    ],
    [
        "return self.__class__.__name__ + \"(\" + repr(self.array) + \")\"",
        "return self.__class__.__name__ + \"(\" + repr(self.array) +"
    ],
    [
        "Returns pointers to the end-points of an array.",
        "Returns pointers to the"
    ],
    [
        "Input array. It must conform to the Python-side of the array",
        "Input array. It must conform to the Python-side"
    ],
    [
        "The first integer is the first byte of the array, the second",
        "The first integer is the first byte of the array, the"
    ],
    [
        "integer is just past the last byte of the array.  If `a` is not",
        "integer is just past the last byte of the array."
    ],
    [
        "contiguous it will not use every byte between the (`low`, `high`)",
        "contiguous it will not use every byte between the"
    ],
    [
        ">>> high - low == I.size*I.itemsize",
        ">>> high -"
    ],
    [
        ">>> high - low == I.size*I.itemsize",
        ">>> high -"
    ],
    [
        "for shape, stride in zip(ashape, astrides):",
        "for shape, stride"
    ],
    [
        "Set operations for arrays based on sorting.",
        "Set operations for arrays"
    ],
    [
        "For floating point arrays, inaccurate results may appear due to usual round-off",
        "For floating point arrays, inaccurate results may appear due"
    ],
    [
        "Speed could be gained in some operations by an implementation of",
        "Speed could be gained in some"
    ],
    [
        "`numpy.sort`, that can provide directly the permutation vectors, thus avoiding",
        "`numpy.sort`, that can provide directly the permutation vectors,"
    ],
    [
        "The differences between consecutive elements of an array.",
        "The differences between consecutive elements of an"
    ],
    [
        "If necessary, will be flattened before the differences are taken.",
        "If necessary, will be flattened before the differences"
    ],
    [
        "Number(s) to append at the end of the returned differences.",
        "Number(s) to append at the end of"
    ],
    [
        "Number(s) to prepend at the beginning of the returned differences.",
        "Number(s) to prepend at the"
    ],
    [
        "When applied to masked arrays, this function drops the mask information",
        "When applied to masked arrays, this function drops"
    ],
    [
        "if the `to_begin` and/or `to_end` parameters are used.",
        "if the `to_begin` and/or"
    ],
    [
        "if to_begin is None and to_end is None:",
        "if to_begin is None"
    ],
    [
        "raise TypeError(\"dtype of `to_begin` must be compatible \"",
        "raise TypeError(\"dtype of `to_begin` must be"
    ],
    [
        "\"with input `ary` under the `same_kind` rule.\")",
        "\"with input `ary` under the `same_kind`"
    ],
    [
        "raise TypeError(\"dtype of `to_end` must be compatible \"",
        "raise TypeError(\"dtype of `to_end` must"
    ],
    [
        "\"with input `ary` under the `same_kind` rule.\")",
        "\"with input `ary` under the `same_kind`"
    ],
    [
        "result = np.empty_like(ary, shape=l_diff + l_begin + l_end)",
        "result = np.empty_like(ary, shape=l_diff + l_begin"
    ],
    [
        "\"\"\" Unpacks one-element tuples for use as return values \"\"\"",
        "\"\"\" Unpacks one-element tuples for use as return"
    ],
    [
        "Find the unique elements of an array.",
        "Find the unique elements"
    ],
    [
        "Returns the sorted unique elements of an array. There are three optional",
        "Returns the sorted unique elements of an"
    ],
    [
        "outputs in addition to the unique elements:",
        "outputs in addition to the"
    ],
    [
        "* the indices of the input array that give the unique values",
        "* the indices of the input array that give the unique"
    ],
    [
        "* the indices of the unique array that reconstruct the input array",
        "* the indices of the unique array"
    ],
    [
        "* the number of times each unique value comes up in the input array",
        "* the number of times each unique value comes up in the"
    ],
    [
        "Input array. Unless `axis` is specified, this will be flattened if it",
        "Input array. Unless `axis` is specified, this will"
    ],
    [
        "If True, also return the indices of `ar` (along the specified axis,",
        "If True, also return the indices of"
    ],
    [
        "if provided, or in the flattened array) that result in the unique array.",
        "if provided, or in the flattened array) that"
    ],
    [
        "If True, also return the indices of the unique array (for the specified",
        "If True, also return the indices of the unique array (for"
    ],
    [
        "axis, if provided) that can be used to reconstruct `ar`.",
        "axis, if provided) that can be used"
    ],
    [
        "If True, also return the number of times each unique item appears",
        "If True, also return the number of times each unique"
    ],
    [
        "axis : int or None, optional",
        "axis : int or"
    ],
    [
        "The axis to operate on. If None, `ar` will be flattened. If an integer,",
        "The axis to operate on. If None, `ar` will be flattened. If an"
    ],
    [
        "the subarrays indexed by the given axis will be flattened and treated",
        "the subarrays indexed by the given axis"
    ],
    [
        "see the notes for more details.  Object arrays or structured arrays",
        "see the notes for more details. Object arrays or"
    ],
    [
        "that contain objects are not supported if the `axis` kwarg is used. The",
        "that contain objects are not supported if the `axis`"
    ],
    [
        "If True, collapses multiple NaN values in the return array into one.",
        "If True, collapses multiple NaN values in the return array"
    ],
    [
        "The indices of the first occurrences of the unique values in the",
        "The indices of the first occurrences of the unique values in"
    ],
    [
        "original array. Only provided if `return_index` is True.",
        "original array. Only provided if `return_index` is"
    ],
    [
        "The indices to reconstruct the original array from the",
        "The indices to reconstruct the"
    ],
    [
        "unique array. Only provided if `return_inverse` is True.",
        "unique array. Only provided"
    ],
    [
        "The number of times each of the unique values comes up in the",
        "The number of times each of the unique values comes up in"
    ],
    [
        "original array. Only provided if `return_counts` is True.",
        "original array. Only provided"
    ],
    [
        "repeat : Repeat elements of an array.",
        "repeat : Repeat elements of"
    ],
    [
        "sort : Return a sorted copy of an array.",
        "sort : Return a sorted copy of an"
    ],
    [
        "When an axis is specified the subarrays indexed by the axis are sorted.",
        "When an axis is specified the subarrays indexed by the"
    ],
    [
        "This is done by making the specified axis the first dimension of the array",
        "This is done by making the specified axis the first dimension"
    ],
    [
        "(move the axis to the first dimension to keep the order of the other axes)",
        "(move the axis to the first dimension to keep the order"
    ],
    [
        "and then flattening the subarrays in C order. The flattened subarrays are",
        "and then flattening the subarrays in C order. The"
    ],
    [
        "then viewed as a structured type with each element given a label, with the",
        "then viewed as a structured type with each element"
    ],
    [
        "flattened subarrays are sorted in lexicographic order starting with the",
        "flattened subarrays are sorted in lexicographic order starting with"
    ],
    [
        "Like np.sort, NaN will sort to the end of the values.",
        "Like np.sort, NaN will sort to the"
    ],
    [
        "For complex arrays all NaN values are considered equivalent",
        "For complex arrays all NaN values are considered"
    ],
    [
        "(no matter whether the NaN is in the real or imaginary part).",
        "(no matter whether the NaN is in the real or imaginary"
    ],
    [
        "As the representant for the returned array the smallest one in the",
        "As the representant for the returned array"
    ],
    [
        "lexicographical order is chosen - see np.sort for how the lexicographical",
        "lexicographical order is chosen - see np.sort for"
    ],
    [
        "order is defined for complex arrays.",
        "order is defined for"
    ],
    [
        "For multi-dimensional inputs, ``unique_inverse`` is reshaped",
        "For multi-dimensional inputs,"
    ],
    [
        "such that the input can be reconstructed using",
        "such that the input can be reconstructed"
    ],
    [
        "``np.take(unique, unique_inverse, axis=axis)``. The result is",
        "``np.take(unique, unique_inverse, axis=axis)``. The result"
    ],
    [
        "when ``axis`` was not ``None``.  This was reverted, but",
        "when ``axis`` was not ``None``."
    ],
    [
        "Return the indices of the original array that give the unique values:",
        "Return the indices of the original array"
    ],
    [
        ">>> a = np.array(['a', 'b', 'b', 'c', 'a'])",
        ">>> a = np.array(['a', 'b', 'b', 'c',"
    ],
    [
        ">>> u, indices = np.unique(a, return_index=True)",
        ">>> u, indices"
    ],
    [
        "Reconstruct the input array from the unique values and inverse:",
        "Reconstruct the input array from the unique values and"
    ],
    [
        ">>> u, indices = np.unique(a, return_inverse=True)",
        ">>> u, indices ="
    ],
    [
        "Reconstruct the input values from the unique values and counts:",
        "Reconstruct the input values from the unique values"
    ],
    [
        ">>> values, counts = np.unique(a, return_counts=True)",
        ">>> values, counts"
    ],
    [
        "msg = 'The axis argument to unique is not supported for dtype {dt}'",
        "msg = 'The axis argument to unique is"
    ],
    [
        "Find the unique elements of an array, ignoring shape.",
        "Find the unique elements of"
    ],
    [
        "perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')",
        "perm = ar.argsort(kind='mergesort' if return_index else"
    ],
    [
        "ret += (inv_idx.reshape(inverse_shape) if axis is None else inv_idx,)",
        "ret += (inv_idx.reshape(inverse_shape) if axis is"
    ],
    [
        "Find the unique elements of an array, and counts, inverse, and indices.",
        "Find the unique elements of an"
    ],
    [
        "This function is an Array API compatible alternative to::",
        "This function is an Array API"
    ],
    [
        "but returns a namedtuple for easier access to each output.",
        "but returns a namedtuple for easier"
    ],
    [
        "* values - The unique elements of an input array.",
        "* values - The unique elements of an input"
    ],
    [
        "* indices - The first occurring indices for each unique element.",
        "* indices - The first occurring indices"
    ],
    [
        "* inverse_indices - The indices from the set of unique elements",
        "* inverse_indices - The indices from the"
    ],
    [
        "* counts - The corresponding counts for each unique element.",
        "* counts - The corresponding counts for each unique"
    ],
    [
        "unique : Find the unique elements of an array.",
        "unique : Find the unique elements of"
    ],
    [
        "Find the unique elements and counts of an input array `x`.",
        "Find the unique elements and counts of an input"
    ],
    [
        "This function is an Array API compatible alternative to::",
        "This function is an Array API compatible"
    ],
    [
        "but returns a namedtuple for easier access to each output.",
        "but returns a namedtuple for easier access"
    ],
    [
        "* values - The unique elements of an input array.",
        "* values - The unique elements"
    ],
    [
        "* counts - The corresponding counts for each unique element.",
        "* counts - The corresponding counts for each"
    ],
    [
        "unique : Find the unique elements of an array.",
        "unique : Find the unique elements of"
    ],
    [
        "Find the unique elements of `x` and indices to reconstruct `x`.",
        "Find the unique elements of `x` and indices"
    ],
    [
        "This function is an Array API compatible alternative to::",
        "This function is an Array API compatible"
    ],
    [
        "but returns a namedtuple for easier access to each output.",
        "but returns a namedtuple for"
    ],
    [
        "* values - The unique elements of an input array.",
        "* values - The unique elements"
    ],
    [
        "* inverse_indices - The indices from the set of unique elements",
        "* inverse_indices - The indices from the set of unique"
    ],
    [
        "unique : Find the unique elements of an array.",
        "unique : Find the unique elements of an"
    ],
    [
        "Returns the unique elements of an input array `x`.",
        "Returns the unique elements of an"
    ],
    [
        "This function is an Array API compatible alternative to::",
        "This function is an Array API compatible alternative"
    ],
    [
        "The unique elements of an input array.",
        "The unique elements of an"
    ],
    [
        "unique : Find the unique elements of an array.",
        "unique : Find the unique elements"
    ],
    [
        "Find the intersection of two arrays.",
        "Find the intersection of"
    ],
    [
        "Return the sorted, unique values that are in both of the input arrays.",
        "Return the sorted, unique values that are in both of"
    ],
    [
        "If True, the input arrays are both assumed to be unique, which",
        "If True, the input arrays are both assumed to be unique,"
    ],
    [
        "unique, incorrect results and out-of-bounds indices could result.",
        "unique, incorrect results and out-of-bounds"
    ],
    [
        "If True, the indices which correspond to the intersection of the two",
        "If True, the indices which correspond to the intersection"
    ],
    [
        "arrays are returned. The first instance of a value is used if there are",
        "arrays are returned. The first instance of a"
    ],
    [
        "Only provided if `return_indices` is True.",
        "Only provided if `return_indices` is"
    ],
    [
        "Only provided if `return_indices` is True.",
        "Only provided if `return_indices` is"
    ],
    [
        "To intersect more than two arrays, use functools.reduce:",
        "To intersect more than two"
    ],
    [
        "To return the indices of the values common to the input arrays",
        "To return the indices of the values common to"
    ],
    [
        "Find the set exclusive-or of two arrays.",
        "Find the set exclusive-or of"
    ],
    [
        "Return the sorted, unique values that are in only one (not both) of the",
        "Return the sorted, unique values that are in only one (not both) of"
    ],
    [
        "If True, the input arrays are both assumed to be unique, which",
        "If True, the input arrays are"
    ],
    [
        "can speed up the calculation. Default is False.",
        "can speed up the calculation. Default is"
    ],
    [
        "If True, the input arrays are both assumed to be unique, which",
        "If True, the input arrays are both assumed to be unique,"
    ],
    [
        "can speed up the calculation.  Default is False.",
        "can speed up the calculation. Default is"
    ],
    [
        "If True, the values in the returned array are inverted (that is,",
        "If True, the values in the returned array"
    ],
    [
        "kind : {None, 'sort', 'table'}, optional",
        "kind : {None, 'sort',"
    ],
    [
        "The algorithm to use. This will not affect the final result,",
        "The algorithm to use. This will"
    ],
    [
        "but will affect the speed and memory use. The default, None,",
        "but will affect the speed and memory"
    ],
    [
        "will select automatically based on memory considerations.",
        "will select automatically based on memory"
    ],
    [
        "* If 'sort', will use a mergesort-based approach. This will have",
        "* If 'sort', will use a mergesort-based"
    ],
    [
        "* If 'table', will use a lookup table approach similar",
        "* If 'table', will use a lookup table approach"
    ],
    [
        "to a counting sort. This is only available for boolean and",
        "to a counting sort. This is only available for boolean"
    ],
    [
        "integer arrays. This will have a memory usage of the",
        "integer arrays. This will have a memory"
    ],
    [
        "has no effect when the 'table' option is used.",
        "has no effect when the 'table' option"
    ],
    [
        "* If None, will automatically choose 'table' if",
        "* If None, will automatically choose"
    ],
    [
        "the required memory allocation is less than or equal to",
        "the required memory allocation is less"
    ],
    [
        "otherwise will use 'sort'. This is done to not use",
        "otherwise will use 'sort'. This is done to"
    ],
    [
        "a large amount of memory by default, even though",
        "a large amount of memory by"
    ],
    [
        "'table' may be faster in most cases. If 'table' is chosen,",
        "'table' may be faster in most cases. If"
    ],
    [
        "isin                  : Version of this function that preserves the",
        "isin : Version of this"
    ],
    [
        "equivalent to ``np.array([item in b for item in a])``.",
        "equivalent to ``np.array([item in b for item"
    ],
    [
        "Using ``kind='table'`` tends to be faster than `kind='sort'` if the",
        "Using ``kind='table'`` tends to be faster than"
    ],
    [
        "but may use greater memory. The default value for `kind` will",
        "but may use greater memory. The"
    ],
    [
        "be automatically selected based only on memory usage, so one may",
        "be automatically selected based only on"
    ],
    [
        "manually set ``kind='table'`` if memory constraints can be relaxed.",
        "manually set ``kind='table'`` if memory"
    ],
    [
        "array([ True, False,  True, False,  True])",
        "array([ True, False,"
    ],
    [
        "if kind not in {None, 'sort', 'table'}:",
        "if kind not in"
    ],
    [
        "f\"Invalid kind: '{kind}'. Please use None, 'sort' or 'table'.\")",
        "f\"Invalid kind: '{kind}'. Please use None,"
    ],
    [
        "use_table_method = is_int_arrays and kind in {None, 'table'}",
        "use_table_method = is_int_arrays and kind in"
    ],
    [
        "\"maximum integer of the datatype. \"",
        "\"maximum integer of the datatype."
    ],
    [
        "\"Please set `kind` to None or 'sort'.\"",
        "\"Please set `kind` to None"
    ],
    [
        "\"The 'table' method is only \"",
        "\"The 'table' method"
    ],
    [
        "\"supported for boolean or integer arrays. \"",
        "\"supported for boolean or integer arrays."
    ],
    [
        "\"Please select 'sort' or None for kind.\"",
        "\"Please select 'sort' or None"
    ],
    [
        "def isin(element, test_elements, assume_unique=False, invert=False, *,",
        "def isin(element, test_elements, assume_unique=False,"
    ],
    [
        "Calculates ``element in test_elements``, broadcasting over `element` only.",
        "Calculates ``element in test_elements``, broadcasting"
    ],
    [
        "Returns a boolean array of the same shape as `element` that is True",
        "Returns a boolean array of the same shape as `element` that is"
    ],
    [
        "where an element of `element` is in `test_elements` and False otherwise.",
        "where an element of `element` is"
    ],
    [
        "The values against which to test each value of `element`.",
        "The values against which to test each value of"
    ],
    [
        "This argument is flattened if it is an array or array_like.",
        "This argument is flattened if it"
    ],
    [
        "See notes for behavior with non-array-like parameters.",
        "See notes for behavior with"
    ],
    [
        "If True, the input arrays are both assumed to be unique, which",
        "If True, the input arrays are both assumed to be"
    ],
    [
        "can speed up the calculation.  Default is False.",
        "can speed up the calculation. Default"
    ],
    [
        "If True, the values in the returned array are inverted, as if",
        "If True, the values in the returned array are inverted, as"
    ],
    [
        "calculating `element not in test_elements`. Default is False.",
        "calculating `element not in"
    ],
    [
        "``np.isin(a, b, invert=True)`` is equivalent to (but faster",
        "``np.isin(a, b, invert=True)`` is equivalent to (but"
    ],
    [
        "kind : {None, 'sort', 'table'}, optional",
        "kind : {None,"
    ],
    [
        "The algorithm to use. This will not affect the final result,",
        "The algorithm to use. This will"
    ],
    [
        "but will affect the speed and memory use. The default, None,",
        "but will affect the speed and memory use. The"
    ],
    [
        "will select automatically based on memory considerations.",
        "will select automatically based on"
    ],
    [
        "* If 'sort', will use a mergesort-based approach. This will have",
        "* If 'sort', will use a mergesort-based approach. This"
    ],
    [
        "`element` and `test_elements`, not accounting for size of dtypes.",
        "`element` and `test_elements`, not accounting"
    ],
    [
        "* If 'table', will use a lookup table approach similar",
        "* If 'table', will use a"
    ],
    [
        "to a counting sort. This is only available for boolean and",
        "to a counting sort. This is"
    ],
    [
        "integer arrays. This will have a memory usage of the",
        "integer arrays. This will have"
    ],
    [
        "size of `element` plus the max-min value of `test_elements`.",
        "size of `element` plus the max-min value of"
    ],
    [
        "`assume_unique` has no effect when the 'table' option is used.",
        "`assume_unique` has no effect when the 'table' option is"
    ],
    [
        "* If None, will automatically choose 'table' if",
        "* If None, will automatically"
    ],
    [
        "the required memory allocation is less than or equal to",
        "the required memory allocation is less than or equal"
    ],
    [
        "otherwise will use 'sort'. This is done to not use",
        "otherwise will use 'sort'. This is done"
    ],
    [
        "a large amount of memory by default, even though",
        "a large amount of memory by default, even"
    ],
    [
        "'table' may be faster in most cases. If 'table' is chosen,",
        "'table' may be faster in most cases. If"
    ],
    [
        "Has the same shape as `element`. The values `element[isin]`",
        "Has the same shape as `element`. The values"
    ],
    [
        "`isin` is an element-wise function version of the python keyword `in`.",
        "`isin` is an element-wise function version of the python"
    ],
    [
        "``isin(a, b)`` is roughly equivalent to",
        "``isin(a, b)`` is"
    ],
    [
        "`element` and `test_elements` are converted to arrays if they are not",
        "`element` and `test_elements` are converted to arrays if they"
    ],
    [
        "already. If `test_elements` is a set (or other non-sequence collection)",
        "already. If `test_elements` is a set (or other"
    ],
    [
        "it will be converted to an object array with one element, rather than an",
        "it will be converted to an object array with"
    ],
    [
        "array of the values contained in `test_elements`. This is a consequence",
        "array of the values contained in `test_elements`. This is a"
    ],
    [
        "of the `array` constructor's way of handling non-sequence collections.",
        "of the `array` constructor's way of handling"
    ],
    [
        "Converting the set to a list usually gives the desired behavior.",
        "Converting the set to a list usually gives the"
    ],
    [
        "Using ``kind='table'`` tends to be faster than `kind='sort'` if the",
        "Using ``kind='table'`` tends to be"
    ],
    [
        "but may use greater memory. The default value for `kind` will",
        "but may use greater memory. The default value for `kind`"
    ],
    [
        "be automatically selected based only on memory usage, so one may",
        "be automatically selected based only on memory"
    ],
    [
        "manually set ``kind='table'`` if memory constraints can be relaxed.",
        "manually set ``kind='table'`` if memory"
    ],
    [
        "The indices of the matched values can be obtained with `nonzero`:",
        "The indices of the matched values can be obtained with"
    ],
    [
        "The test can also be inverted:",
        "The test can also"
    ],
    [
        ">>> mask = np.isin(element, test_elements, invert=True)",
        ">>> mask = np.isin(element,"
    ],
    [
        "Because of how `array` handles sets, the following does not",
        "Because of how `array` handles sets, the"
    ],
    [
        "Casting the set to a list gives the expected result:",
        "Casting the set to a list"
    ],
    [
        "Find the union of two arrays.",
        "Find the union"
    ],
    [
        "Return the unique, sorted array of values that are in either of the two",
        "Return the unique, sorted array of values that are in either"
    ],
    [
        "Unique, sorted union of the input arrays.",
        "Unique, sorted union of the input"
    ],
    [
        "To find the union of more than two arrays, use functools.reduce:",
        "To find the union of more than two arrays, use"
    ],
    [
        "Find the set difference of two arrays.",
        "Find the set difference of two"
    ],
    [
        "If True, the input arrays are both assumed to be unique, which",
        "If True, the input arrays are both assumed"
    ],
    [
        "can speed up the calculation.  Default is False.",
        "can speed up the calculation. Default"
    ],
    [
        "is sorted when `assume_unique=False`, but otherwise only sorted",
        "is sorted when `assume_unique=False`, but otherwise only"
    ],
    [
        "Utilities that manipulate strides to achieve desirable effects.",
        "Utilities that manipulate strides to achieve"
    ],
    [
        "An explanation of strides can be found in the :ref:`arrays.ndarray`.",
        "An explanation of strides can be found in"
    ],
    [
        "\"\"\"Dummy object that just exists to hang __array_interface__ dictionaries",
        "\"\"\"Dummy object that just exists to hang __array_interface__"
    ],
    [
        "and possibly keep alive a reference to a base array.",
        "and possibly keep alive a reference"
    ],
    [
        "def as_strided(x, shape=None, strides=None, subok=False, writeable=True):",
        "def as_strided(x, shape=None,"
    ],
    [
        "Create a view into the array with the given shape and strides.",
        "Create a view into the array with the given"
    ],
    [
        ".. warning:: This function has to be used with extreme care, see notes.",
        ".. warning:: This function has to be used with extreme care, see"
    ],
    [
        "shape : sequence of int, optional",
        "shape : sequence of"
    ],
    [
        "The shape of the new array. Defaults to ``x.shape``.",
        "The shape of the new array. Defaults to"
    ],
    [
        "strides : sequence of int, optional",
        "strides : sequence"
    ],
    [
        "The strides of the new array. Defaults to ``x.strides``.",
        "The strides of the new"
    ],
    [
        "If set to False, the returned array will always be readonly.",
        "If set to False, the returned array will"
    ],
    [
        "Otherwise it will be writable if the original array was. It",
        "Otherwise it will be writable if the original"
    ],
    [
        "is advisable to set this to False if possible (see Notes).",
        "is advisable to set this to False if"
    ],
    [
        "broadcast_to : broadcast an array to a given shape.",
        "broadcast_to : broadcast an array to a given"
    ],
    [
        "userfriendly and safe function for a creation of sliding window views.",
        "userfriendly and safe function for a creation of sliding"
    ],
    [
        "``as_strided`` creates a view into the array given the exact strides",
        "``as_strided`` creates a view into the"
    ],
    [
        "and shape. This means it manipulates the internal data structure of",
        "and shape. This means it manipulates the"
    ],
    [
        "ndarray and, if done incorrectly, the array elements can point to",
        "ndarray and, if done incorrectly, the array elements can point"
    ],
    [
        "invalid memory and can corrupt results or crash your program.",
        "invalid memory and can corrupt results or crash"
    ],
    [
        "It is advisable to always use the original ``x.strides`` when",
        "It is advisable to always use the original"
    ],
    [
        "calculating new strides to avoid reliance on a contiguous memory",
        "calculating new strides to avoid reliance"
    ],
    [
        "Furthermore, arrays created with this function often contain self",
        "Furthermore, arrays created with this function often"
    ],
    [
        "overlapping memory, so that two elements are identical.",
        "overlapping memory, so that two elements"
    ],
    [
        "Vectorized write operations on such arrays will typically be",
        "Vectorized write operations on such"
    ],
    [
        "unpredictable. They may even give different results for small, large,",
        "unpredictable. They may even give different results"
    ],
    [
        "Since writing to these arrays has to be tested and done with great",
        "Since writing to these arrays has to"
    ],
    [
        "care, you may want to use ``writeable=False`` to avoid accidental write",
        "care, you may want to use ``writeable=False``"
    ],
    [
        "For these reasons it is advisable to avoid ``as_strided`` when",
        "For these reasons it is advisable to avoid"
    ],
    [
        "Create a sliding window view into the array with the given window shape.",
        "Create a sliding window view into the array with the given window"
    ],
    [
        "Also known as rolling or moving window, the window slides across all",
        "Also known as rolling or moving window,"
    ],
    [
        "dimensions of the array and extracts subsets of the array at all window",
        "dimensions of the array and extracts subsets of"
    ],
    [
        "Array to create the sliding window view from.",
        "Array to create the"
    ],
    [
        "window_shape : int or tuple of int",
        "window_shape : int or tuple"
    ],
    [
        "Size of window over each axis that takes part in the sliding window.",
        "Size of window over each axis that takes"
    ],
    [
        "If `axis` is not present, must have same length as the number of input",
        "If `axis` is not present, must have same length as"
    ],
    [
        "array dimensions. Single integers `i` are treated as if they were the",
        "array dimensions. Single integers `i` are treated as if"
    ],
    [
        "axis : int or tuple of int, optional",
        "axis : int or tuple of int,"
    ],
    [
        "Axis or axes along which the sliding window is applied.",
        "Axis or axes along which the"
    ],
    [
        "By default, the sliding window is applied to all axes and",
        "By default, the sliding window is applied to all axes"
    ],
    [
        "`window_shape[i]` will refer to axis `i` of `x`.",
        "`window_shape[i]` will refer to"
    ],
    [
        "If `axis` is given as a `tuple of int`, `window_shape[i]` will refer to",
        "If `axis` is given as a `tuple of int`, `window_shape[i]` will refer"
    ],
    [
        "Single integers `i` are treated as if they were the tuple `(i,)`.",
        "Single integers `i` are treated as if they were the tuple"
    ],
    [
        "If True, sub-classes will be passed-through, otherwise the returned",
        "If True, sub-classes will be passed-through, otherwise the"
    ],
    [
        "array will be forced to be a base-class array (default).",
        "array will be forced to"
    ],
    [
        "When true, allow writing to the returned view. The default is false,",
        "When true, allow writing to the returned view. The default"
    ],
    [
        "as this should be used with caution: the returned view contains the",
        "as this should be used with"
    ],
    [
        "same memory location multiple times, so writing to one location will",
        "same memory location multiple times, so writing to one"
    ],
    [
        "Sliding window view of the array. The sliding window dimensions are",
        "Sliding window view of the array."
    ],
    [
        "inserted at the end, and the original dimensions are trimmed as",
        "inserted at the end, and the original dimensions"
    ],
    [
        "required by the size of the sliding window.",
        "required by the size of the"
    ],
    [
        "That is, ``view.shape = x_shape_trimmed + window_shape``, where",
        "That is, ``view.shape = x_shape_trimmed + window_shape``,"
    ],
    [
        "``x_shape_trimmed`` is ``x.shape`` with every entry reduced by one less",
        "``x_shape_trimmed`` is ``x.shape`` with every entry reduced by"
    ],
    [
        "lib.stride_tricks.as_strided: A lower-level and less safe routine for",
        "lib.stride_tricks.as_strided: A lower-level and less safe routine"
    ],
    [
        "creating arbitrary views from custom shape and strides.",
        "creating arbitrary views from custom shape and"
    ],
    [
        "broadcast_to: broadcast an array to a given shape.",
        "broadcast_to: broadcast an array to a"
    ],
    [
        "For many applications using a sliding window view can be convenient, but",
        "For many applications using a sliding window view can be"
    ],
    [
        "potentially very slow. Often specialized solutions exist, for example:",
        "potentially very slow. Often specialized solutions"
    ],
    [
        "- moving window functions provided by",
        "- moving window functions"
    ],
    [
        "As a rough estimate, a sliding window approach with an input size of `N`",
        "As a rough estimate, a sliding window approach with an"
    ],
    [
        "and a window size of `W` will scale as `O(N*W)` where frequently a special",
        "and a window size of `W` will scale as `O(N*W)`"
    ],
    [
        "algorithm can achieve `O(N)`. That means that the sliding window variant",
        "algorithm can achieve `O(N)`. That means that the sliding"
    ],
    [
        "Nevertheless, for small window sizes, when no custom algorithm exists, or",
        "Nevertheless, for small window sizes, when no custom algorithm exists,"
    ],
    [
        "as a prototyping and developing tool, this function can be a good solution.",
        "as a prototyping and developing tool, this function can be a"
    ],
    [
        "This also works in more dimensions, e.g.",
        "This also works in more dimensions,"
    ],
    [
        "The axis can be specified explicitly:",
        "The axis can be"
    ],
    [
        "The same axis can be used several times. In that case, every use reduces",
        "The same axis can be used several times. In"
    ],
    [
        "Combining with stepped slicing (`::step`), this can be used to take sliding",
        "Combining with stepped slicing (`::step`), this"
    ],
    [
        "or views which move by multiple elements",
        "or views which move by multiple"
    ],
    [
        "A common application of `sliding_window_view` is the calculation of running",
        "A common application of `sliding_window_view` is the calculation of"
    ],
    [
        "statistics. The simplest example is the",
        "statistics. The simplest example is"
    ],
    [
        "Note that a sliding window approach is often **not** optimal (see Notes).",
        "Note that a sliding window approach is often **not** optimal (see"
    ],
    [
        "raise ValueError('`window_shape` cannot contain negative values')",
        "raise ValueError('`window_shape` cannot contain"
    ],
    [
        "raise ValueError(f'Since axis is `None`, must provide '",
        "raise ValueError(f'Since axis is `None`,"
    ],
    [
        "f'window_shape for all dimensions of `x`; '",
        "f'window_shape for all dimensions of"
    ],
    [
        "raise ValueError(f'Must provide matching length window_shape and '",
        "raise ValueError(f'Must provide matching length window_shape and"
    ],
    [
        "out_strides = x.strides + tuple(x.strides[ax] for ax in axis)",
        "out_strides = x.strides + tuple(x.strides[ax]"
    ],
    [
        "for ax, dim in zip(axis, window_shape):",
        "for ax, dim"
    ],
    [
        "'window shape cannot be larger than input array shape')",
        "'window shape cannot be larger"
    ],
    [
        "shape = tuple(shape) if np.iterable(shape) else (shape,)",
        "shape = tuple(shape) if"
    ],
    [
        "raise ValueError('cannot broadcast a non-scalar to a scalar array')",
        "raise ValueError('cannot broadcast a non-scalar to a scalar"
    ],
    [
        "raise ValueError('all elements of broadcast shape must be non-'",
        "raise ValueError('all elements of broadcast shape must be"
    ],
    [
        "(array,), flags=['multi_index', 'refs_ok', 'zerosize_ok'] + extras,",
        "(array,), flags=['multi_index', 'refs_ok',"
    ],
    [
        "\"\"\"Broadcast an array to a new shape.",
        "\"\"\"Broadcast an array to"
    ],
    [
        "The shape of the desired array. A single integer ``i`` is interpreted",
        "The shape of the desired array. A single"
    ],
    [
        "If True, then sub-classes will be passed-through, otherwise",
        "If True, then sub-classes will"
    ],
    [
        "the returned array will be forced to be a base-class array (default).",
        "the returned array will be forced to be"
    ],
    [
        "A readonly view on the original array with the given shape. It is",
        "A readonly view on the original array with the given shape. It"
    ],
    [
        "typically not contiguous. Furthermore, more than one element of a",
        "typically not contiguous. Furthermore, more than one element"
    ],
    [
        "broadcasted array may refer to a single memory location.",
        "broadcasted array may refer to"
    ],
    [
        "If the array is not compatible with the new shape according to NumPy's",
        "If the array is not compatible with the new"
    ],
    [
        "\"\"\"Returns the shape of the arrays that would result from broadcasting the",
        "\"\"\"Returns the shape of the arrays that would result from"
    ],
    [
        "Broadcast the input shapes into a single shape.",
        "Broadcast the input shapes into a single"
    ],
    [
        ":ref:`Learn more about broadcasting here <basics.broadcasting>`.",
        ":ref:`Learn more about"
    ],
    [
        "*args : tuples of ints, or ints",
        "*args : tuples of ints, or"
    ],
    [
        "The shapes to be broadcast against each other.",
        "The shapes to be broadcast against each"
    ],
    [
        "If the shapes are not compatible and cannot be broadcast according",
        "If the shapes are not compatible and cannot be"
    ],
    [
        "Broadcast any number of arrays against each other.",
        "Broadcast any number of arrays"
    ],
    [
        "If True, then sub-classes will be passed-through, otherwise",
        "If True, then sub-classes will be passed-through,"
    ],
    [
        "the returned arrays will be forced to be a base-class array (default).",
        "the returned arrays will be forced to"
    ],
    [
        "These arrays are views on the original arrays.  They are typically",
        "These arrays are views on the original arrays. They are"
    ],
    [
        "not contiguous.  Furthermore, more than one element of a",
        "not contiguous. Furthermore, more than one"
    ],
    [
        "broadcasted array may refer to a single memory location. If you need",
        "broadcasted array may refer to a"
    ],
    [
        "to write to the arrays, make copies first. While you can set the",
        "to write to the arrays, make copies first. While you"
    ],
    [
        "``writable`` flag True, writing to a single output value may end up",
        "``writable`` flag True, writing to a single"
    ],
    [
        "changing more than one location in the output array.",
        "changing more than one location in"
    ],
    [
        "The output is currently marked so that if written to, a deprecation",
        "The output is currently marked so that if written"
    ],
    [
        "warning will be emitted. A future version will set the",
        "warning will be emitted. A future"
    ],
    [
        "``writable`` flag False so writing to it will raise an error.",
        "``writable`` flag False so writing to it will raise an"
    ],
    [
        "Here is a useful idiom for getting contiguous copies instead of",
        "Here is a useful idiom for getting"
    ],
    [
        ">>> [np.array(a) for a in np.broadcast_arrays(x, y)]",
        ">>> [np.array(a) for a"
    ],
    [
        "args = [np.array(_m, copy=None, subok=subok) for _m in args]",
        "args = [np.array(_m, copy=None, subok=subok) for _m in"
    ],
    [
        "result = [array if array.shape == shape",
        "result = [array if"
    ],
    [
        "\"\"\"Utility to compare (NumPy) version strings.",
        "\"\"\"Utility to compare (NumPy) version"
    ],
    [
        "The NumpyVersion class allows properly comparing numpy version strings.",
        "The NumpyVersion class allows properly comparing numpy"
    ],
    [
        "The LooseVersion and StrictVersion classes that distutils provides don't",
        "The LooseVersion and StrictVersion classes that"
    ],
    [
        "work; they don't recognize anything like alpha/beta/rc/dev versions.",
        "work; they don't recognize anything like"
    ],
    [
        "\"\"\"Parse and compare numpy version strings.",
        "\"\"\"Parse and compare numpy version"
    ],
    [
        "NumPy has the following versioning scheme (numbers given are examples; they",
        "NumPy has the following versioning scheme"
    ],
    [
        "Comparing needs to be done against a valid version string or other",
        "Comparing needs to be done against a valid version"
    ],
    [
        "`NumpyVersion` instance. Note that all development versions of the same",
        "`NumpyVersion` instance. Note that all development"
    ],
    [
        "ValueError: Not a valid numpy version string",
        "ValueError: Not a valid numpy version"
    ],
    [
        "raise ValueError(\"Not a valid numpy version string\")",
        "raise ValueError(\"Not a valid numpy version"
    ],
    [
        "self.major, self.minor, self.bugfix = [int(x) for x in",
        "self.major, self.minor, self.bugfix = [int(x) for"
    ],
    [
        "pre_rel = [m for m in [alpha, beta, rc] if m is not None]",
        "pre_rel = [m for m in [alpha, beta, rc] if m"
    ],
    [
        "raise ValueError(\"Invalid object to compare with NumpyVersion.\")",
        "raise ValueError(\"Invalid object to compare"
    ],
    [
        "__all__ = ['iscomplexobj', 'isrealobj', 'imag', 'iscomplex',",
        "__all__ = ['iscomplexobj', 'isrealobj', 'imag',"
    ],
    [
        "from numpy._core.numeric import asarray, asanyarray, isnan, zeros",
        "from numpy._core.numeric import asarray,"
    ],
    [
        "Return the character for the minimum-size type to which given types can",
        "Return the character for the minimum-size"
    ],
    [
        "The returned type character must represent the smallest size dtype such",
        "The returned type character must represent"
    ],
    [
        "that an array of the returned type can handle the data from an array of",
        "that an array of the returned type can handle"
    ],
    [
        "all types in `typechars` (or if `typechars` is an array, then its",
        "all types in `typechars` (or if `typechars` is an"
    ],
    [
        "typechars : list of str or array_like",
        "typechars : list of"
    ],
    [
        "If a list of strings, each string should represent a dtype.",
        "If a list of strings, each"
    ],
    [
        "If array_like, the character representation of the array dtype is used.",
        "If array_like, the character representation of the array"
    ],
    [
        "typeset : str or list of str, optional",
        "typeset : str or"
    ],
    [
        "The set of characters that the returned character is chosen from.",
        "The set of characters that the"
    ],
    [
        "The default character, this is returned if none of the characters in",
        "The default character, this is returned if none of"
    ],
    [
        "`typechars` matches a character in `typeset`.",
        "`typechars` matches a"
    ],
    [
        "The character representing the minimum-size type that was found.",
        "The character representing the minimum-size type"
    ],
    [
        "typecodes = ((isinstance(t, str) and t) or asarray(t).dtype.char",
        "typecodes = ((isinstance(t, str) and t)"
    ],
    [
        "intersection = {t for t in typecodes if t in typeset}",
        "intersection = {t for t in typecodes if t in"
    ],
    [
        "if 'F' in intersection and 'd' in intersection:",
        "if 'F' in intersection and 'd' in"
    ],
    [
        "Return the real part of the complex argument.",
        "Return the real part of the complex"
    ],
    [
        "The real component of the complex argument. If `val` is real, the type",
        "The real component of the complex argument. If"
    ],
    [
        "of `val` is used for the output.  If `val` has complex elements, the",
        "of `val` is used for the output. If `val` has"
    ],
    [
        "Return the imaginary part of the complex argument.",
        "Return the imaginary part of the"
    ],
    [
        "The imaginary component of the complex argument. If `val` is real,",
        "The imaginary component of the complex argument. If"
    ],
    [
        "the type of `val` is used for the output.  If `val` has complex",
        "the type of `val` is used for the"
    ],
    [
        "elements, the returned type is float.",
        "elements, the returned"
    ],
    [
        "Returns a bool array, where True if input element is complex.",
        "Returns a bool array, where True if input element"
    ],
    [
        "What is tested is whether the input has a non-zero imaginary part, not if",
        "What is tested is whether the input has"
    ],
    [
        "iscomplexobj : Return True if x is a complex type or an array of complex",
        "iscomplexobj : Return True if x is a complex type or an"
    ],
    [
        "array([ True, False, False, False, False,  True])",
        "array([ True, False, False,"
    ],
    [
        "Returns a bool array, where True if input element is real.",
        "Returns a bool array, where True if input element"
    ],
    [
        "If element has complex type with zero imaginary part, the return value",
        "If element has complex type with"
    ],
    [
        "Boolean array of same shape as `x`.",
        "Boolean array of same shape"
    ],
    [
        "`isreal` may behave unexpectedly for string or object arrays (see examples)",
        "`isreal` may behave unexpectedly for string or object arrays (see"
    ],
    [
        "isrealobj : Return True if x is not a complex type.",
        "isrealobj : Return True if x"
    ],
    [
        "array([False,  True,  True,  True,  True, False])",
        "array([False, True, True, True,"
    ],
    [
        "The function does not work on string arrays.",
        "The function does not work"
    ],
    [
        "Returns True for all elements in input array of ``dtype=object`` even if",
        "Returns True for all elements in input array"
    ],
    [
        "any of the elements is complex.",
        "any of the"
    ],
    [
        "isreal should not be used with object arrays",
        "isreal should not be used"
    ],
    [
        "Check for a complex type or an array of complex numbers.",
        "Check for a complex type or an"
    ],
    [
        "The type of the input is checked, not the value. Even if the input",
        "The type of the input is checked, not the value. Even if the"
    ],
    [
        "has an imaginary part equal to zero, `iscomplexobj` evaluates to True.",
        "has an imaginary part equal to"
    ],
    [
        "The input can be of any type and shape.",
        "The input can be of any"
    ],
    [
        "The return value, True if `x` is of a complex type or has at least",
        "The return value, True if `x` is of a complex type or has at"
    ],
    [
        "Return True if x is a not complex type or an array of complex numbers.",
        "Return True if x is a not complex type"
    ],
    [
        "The type of the input is checked, not the value. So even if the input",
        "The type of the input is checked, not"
    ],
    [
        "has an imaginary part equal to zero, `isrealobj` evaluates to False",
        "has an imaginary part equal to zero, `isrealobj` evaluates to"
    ],
    [
        "if the data type is complex.",
        "if the data type is"
    ],
    [
        "The input can be of any type and shape.",
        "The input can be of any type and"
    ],
    [
        "The return value, False if `x` is of a complex type.",
        "The return value, False if `x` is"
    ],
    [
        "The function is only meant for arrays with numerical values but it",
        "The function is only meant for arrays with numerical"
    ],
    [
        "accepts all other objects. Since it assumes array input, the return",
        "accepts all other objects. Since it assumes array input,"
    ],
    [
        "value of other objects may be True.",
        "value of other objects"
    ],
    [
        "def _nan_to_num_dispatcher(x, copy=None, nan=None, posinf=None, neginf=None):",
        "def _nan_to_num_dispatcher(x, copy=None, nan=None, posinf=None,"
    ],
    [
        "Replace NaN with zero and infinity with large finite numbers (default",
        "Replace NaN with zero and infinity with large finite numbers"
    ],
    [
        "behaviour) or with the numbers defined by the user using the `nan`,",
        "behaviour) or with the numbers defined by the user using the"
    ],
    [
        "If `x` is inexact, NaN is replaced by zero or by the user defined value in",
        "If `x` is inexact, NaN is replaced by zero or by the user"
    ],
    [
        "`nan` keyword, infinity is replaced by the largest finite floating point",
        "`nan` keyword, infinity is replaced by the largest finite floating"
    ],
    [
        "values representable by ``x.dtype`` or by the user defined value in",
        "values representable by ``x.dtype`` or by the"
    ],
    [
        "`posinf` keyword and -infinity is replaced by the most negative finite",
        "`posinf` keyword and -infinity is replaced by the"
    ],
    [
        "floating point values representable by ``x.dtype`` or by the user defined",
        "floating point values representable by ``x.dtype`` or by the user"
    ],
    [
        "For complex dtypes, the above is applied to each of the real and",
        "For complex dtypes, the above is applied"
    ],
    [
        "If `x` is not inexact, then no replacements are made.",
        "If `x` is not inexact, then no"
    ],
    [
        "Whether to create a copy of `x` (True) or to replace values",
        "Whether to create a copy of `x`"
    ],
    [
        "in-place (False). The in-place operation only occurs if",
        "in-place (False). The in-place operation only"
    ],
    [
        "casting to an array does not require a copy.",
        "casting to an array does not require a"
    ],
    [
        "Value to be used to fill NaN values. If no value is passed",
        "Value to be used to fill NaN values. If no value"
    ],
    [
        "Value to be used to fill positive infinity values. If no value is",
        "Value to be used to fill positive infinity"
    ],
    [
        "passed then positive infinity values will be replaced with a very",
        "passed then positive infinity values will be replaced with"
    ],
    [
        "Value to be used to fill negative infinity values. If no value is",
        "Value to be used to fill negative infinity values. If no"
    ],
    [
        "passed then negative infinity values will be replaced with a very",
        "passed then negative infinity values will"
    ],
    [
        "`x`, with the non-finite values replaced. If `copy` is False, this may",
        "`x`, with the non-finite values replaced. If `copy`"
    ],
    [
        "isinf : Shows which elements are positive or negative infinity.",
        "isinf : Shows which elements"
    ],
    [
        "isneginf : Shows which elements are negative infinity.",
        "isneginf : Shows which"
    ],
    [
        "isposinf : Shows which elements are positive infinity.",
        "isposinf : Shows which elements are positive"
    ],
    [
        "isnan : Shows which elements are Not a Number (NaN).",
        "isnan : Shows which elements are Not"
    ],
    [
        "isfinite : Shows which elements are finite (not NaN, not infinity)",
        "isfinite : Shows which elements are finite"
    ],
    [
        "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic",
        "NumPy uses the IEEE Standard for Binary Floating-Point"
    ],
    [
        ">>> y = np.array([complex(np.inf, np.nan), np.nan, complex(np.nan, np.inf)])",
        ">>> y = np.array([complex(np.inf, np.nan), np.nan, complex(np.nan,"
    ],
    [
        "return x[()] if isscalar else x",
        "return x[()] if isscalar else"
    ],
    [
        "dest = (x.real, x.imag) if iscomplex else (x,)",
        "dest = (x.real, x.imag)"
    ],
    [
        "return x[()] if isscalar else x",
        "return x[()] if isscalar else"
    ],
    [
        "If input is complex with all imaginary parts close to zero, return",
        "If input is complex with all imaginary parts close to zero,"
    ],
    [
        "\"Close to zero\" is defined as `tol` * (machine epsilon of the type for",
        "\"Close to zero\" is defined as `tol` * (machine epsilon of the"
    ],
    [
        "Tolerance in machine epsilons for the complex part of the elements",
        "Tolerance in machine epsilons for the complex part"
    ],
    [
        "If `a` is real, the type of `a` is used for the output.  If `a`",
        "If `a` is real, the type of `a`"
    ],
    [
        "has complex elements, the returned type is float.",
        "has complex elements, the returned type is"
    ],
    [
        "Machine epsilon varies from machine to machine and between data types",
        "Machine epsilon varies from machine to machine and between"
    ],
    [
        "but Python floats on most platforms have a machine epsilon equal to",
        "but Python floats on most platforms have a machine"
    ],
    [
        "out the machine epsilon for floats.",
        "out the machine"
    ],
    [
        "Return a description for the given data type code.",
        "Return a description for the"
    ],
    [
        "Description of the input data type code.",
        "Description of the input data type"
    ],
    [
        "...              'S', 'U', 'V', 'b', 'd', 'g', 'f', 'i', 'h', 'l', 'q']",
        "... 'S', 'U', 'V', 'b', 'd', 'g', 'f', 'i', 'h',"
    ],
    [
        "...     print(typechar, ' : ', np.typename(typechar))",
        "... print(typechar, '"
    ],
    [
        "G  :  complex long double precision",
        "G : complex long"
    ],
    [
        "Q  :  unsigned long long integer",
        "Q : unsigned long"
    ],
    [
        "Return a scalar type which is common to the input arrays.",
        "Return a scalar type which is common to the"
    ],
    [
        "The return type will always be an inexact (i.e. floating point) scalar",
        "The return type will always be an"
    ],
    [
        "type, even if all the arrays are integer arrays. If one of the inputs is",
        "type, even if all the arrays are integer arrays. If one of the inputs"
    ],
    [
        "an integer array, the minimum precision type that is returned is a",
        "an integer array, the minimum precision type that is returned"
    ],
    [
        "returned dtype without loss of information.",
        "returned dtype without loss"
    ],
    [
        "raise TypeError(\"can't get common type for non-numeric array\")",
        "raise TypeError(\"can't get common type for"
    ],
    [
        "Wrapper functions to more user-friendly calling of certain math functions",
        "Wrapper functions to more user-friendly calling of certain"
    ],
    [
        "whose output data-type is different than the input data-type in certain",
        "whose output data-type is different than the"
    ],
    [
        "For example, for functions like `log` with branch cuts, the versions in this",
        "For example, for functions like `log` with branch cuts, the versions in"
    ],
    [
        "module provide the mathematically valid answers in the complex plane::",
        "module provide the mathematically valid answers"
    ],
    [
        "Similarly, `sqrt`, other base logarithms, `power` and trig functions are",
        "Similarly, `sqrt`, other base logarithms, `power` and"
    ],
    [
        "correctly handled.  See their respective docstrings for specific examples.",
        "correctly handled. See their respective docstrings"
    ],
    [
        "\"\"\"Convert its input `arr` to a complex array.",
        "\"\"\"Convert its input `arr`"
    ],
    [
        "The input is returned as a complex array of the smallest type that will fit",
        "The input is returned as a complex array"
    ],
    [
        "the original data: types like single, byte, short, etc. become csingle,",
        "the original data: types like single, byte, short, etc. become"
    ],
    [
        "A copy of the input is always made.",
        "A copy of the input is"
    ],
    [
        "An array with the same input data as the input but in complex form.",
        "An array with the same input data as the input"
    ],
    [
        "First, consider an input of type short:",
        "First, consider an input"
    ],
    [
        "If the input is of type double, the output is correspondingly of the",
        "If the input is of type double,"
    ],
    [
        "Note that even if the input was complex to begin with, a copy is still",
        "Note that even if the input was complex to begin with, a copy is"
    ],
    [
        "made, since the astype() method always copies:",
        "made, since the astype() method"
    ],
    [
        "if issubclass(arr.dtype.type, (nt.single, nt.byte, nt.short, nt.ubyte,",
        "if issubclass(arr.dtype.type, (nt.single,"
    ],
    [
        "\"\"\"Convert `x` to complex if it has real, negative components.",
        "\"\"\"Convert `x` to complex if it"
    ],
    [
        "Otherwise, output is just the array version of the input (via asarray).",
        "Otherwise, output is just the array version of the input (via"
    ],
    [
        "\"\"\"Convert `x` to double if it has real, negative components.",
        "\"\"\"Convert `x` to double if it has"
    ],
    [
        "Otherwise, output is just the array version of the input (via asarray).",
        "Otherwise, output is just the array version of the input"
    ],
    [
        "Otherwise, output is just the array version of the input (via asarray).",
        "Otherwise, output is just the array version of the"
    ],
    [
        "Compute the square root of x.",
        "Compute the square root"
    ],
    [
        "For negative input elements, a complex value is returned",
        "For negative input elements, a"
    ],
    [
        "The square root of `x`. If `x` was a scalar, so is `out`,",
        "The square root of `x`. If `x` was"
    ],
    [
        "For real, non-negative inputs this works just like `numpy.sqrt`:",
        "For real, non-negative inputs this works just like"
    ],
    [
        "But it automatically handles negative inputs:",
        "But it automatically handles"
    ],
    [
        "For more control, explicitly use complex() as follows:",
        "For more control, explicitly use"
    ],
    [
        "Compute the natural logarithm of `x`.",
        "Compute the natural logarithm of"
    ],
    [
        "Return the \"principal value\" (for a description of this, see `numpy.log`)",
        "Return the \"principal value\" (for a"
    ],
    [
        "returns ``-inf`` and ``log(np.inf)`` returns ``inf``). Otherwise, the",
        "returns ``-inf`` and ``log(np.inf)``"
    ],
    [
        "The value(s) whose log is (are) required.",
        "The value(s) whose log is"
    ],
    [
        "The log of the `x` value(s). If `x` was a scalar, so is `out`,",
        "The log of the `x` value(s). If `x` was a scalar,"
    ],
    [
        "(note, however, that otherwise `numpy.log` and this `log` are identical,",
        "(note, however, that otherwise `numpy.log`"
    ],
    [
        "Negative arguments are handled \"correctly\" (recall that",
        "Negative arguments are handled \"correctly\" (recall"
    ],
    [
        "Return the \"principal value\" (for a description of this, see",
        "Return the \"principal value\" (for a"
    ],
    [
        "returns ``inf``). Otherwise, the complex principle value is returned.",
        "returns ``inf``). Otherwise, the complex principle"
    ],
    [
        "otherwise an array object is returned.",
        "otherwise an array"
    ],
    [
        "(We set the printing precision so the example can be auto-tested)",
        "(We set the printing precision so the example can be"
    ],
    [
        "Take log base n of x.",
        "Take log base n of"
    ],
    [
        "If `x` contains negative inputs, the answer is computed and returned in the",
        "If `x` contains negative inputs, the answer is computed and returned"
    ],
    [
        "The integer base(s) in which the log is taken.",
        "The integer base(s) in which"
    ],
    [
        "The value(s) whose log base `n` is (are) required.",
        "The value(s) whose log base"
    ],
    [
        "The log base `n` of the `x` value(s). If `x` was a scalar, so is",
        "The log base `n` of the `x` value(s). If"
    ],
    [
        "`out`, otherwise an array is returned.",
        "`out`, otherwise an array is"
    ],
    [
        "Return the \"principal value\" (for a description of this, see",
        "Return the \"principal value\" (for a description of this,"
    ],
    [
        "``inf``). Otherwise, the complex principle value is returned.",
        "``inf``). Otherwise, the complex"
    ],
    [
        "We set the printing precision so the example can be auto-tested:",
        "We set the printing precision so the"
    ],
    [
        "Return x to the power p, (x**p).",
        "Return x to the"
    ],
    [
        "If `x` contains negative values, the output is converted to the",
        "If `x` contains negative values, the output is converted"
    ],
    [
        "The power(s) to which `x` is raised. If `x` contains multiple values,",
        "The power(s) to which `x` is raised. If `x` contains multiple"
    ],
    [
        "`p` has to either be a scalar, or contain the same number of values",
        "`p` has to either be a scalar, or contain the"
    ],
    [
        "as `x`. In the latter case, the result is",
        "as `x`. In the latter"
    ],
    [
        "The result of ``x**p``. If `x` and `p` are scalars, so is `out`,",
        "The result of ``x**p``. If `x` and `p` are scalars, so is"
    ],
    [
        "Compute the inverse cosine of x.",
        "Compute the inverse"
    ],
    [
        "Return the \"principal value\" (for a description of this, see",
        "Return the \"principal value\" (for a"
    ],
    [
        "`numpy.arccos`) of the inverse cosine of `x`. For real `x` such that",
        "`numpy.arccos`) of the inverse cosine of `x`."
    ],
    [
        "The value(s) whose arccos is (are) required.",
        "The value(s) whose arccos"
    ],
    [
        "The inverse cosine(s) of the `x` value(s). If `x` was a scalar, so",
        "The inverse cosine(s) of the `x` value(s)."
    ],
    [
        "is `out`, otherwise an array object is returned.",
        "is `out`, otherwise an"
    ],
    [
        "For an arccos() that returns ``NAN`` when real `x` is not in the",
        "For an arccos() that returns ``NAN`` when real `x` is"
    ],
    [
        "Compute the inverse sine of x.",
        "Compute the inverse sine of"
    ],
    [
        "Return the \"principal value\" (for a description of this, see",
        "Return the \"principal value\" (for a description of this,"
    ],
    [
        "`numpy.arcsin`) of the inverse sine of `x`. For real `x` such that",
        "`numpy.arcsin`) of the inverse sine of `x`. For real `x` such"
    ],
    [
        "The value(s) whose arcsin is (are) required.",
        "The value(s) whose arcsin"
    ],
    [
        "The inverse sine(s) of the `x` value(s). If `x` was a scalar, so",
        "The inverse sine(s) of the `x` value(s). If `x` was a scalar,"
    ],
    [
        "is `out`, otherwise an array object is returned.",
        "is `out`, otherwise an"
    ],
    [
        "For an arcsin() that returns ``NAN`` when real `x` is not in the",
        "For an arcsin() that returns ``NAN`` when real `x` is not"
    ],
    [
        "Compute the inverse hyperbolic tangent of `x`.",
        "Compute the inverse hyperbolic tangent of"
    ],
    [
        "Return the \"principal value\" (for a description of this, see",
        "Return the \"principal value\" (for a description of this,"
    ],
    [
        "`numpy.arctanh`) of ``arctanh(x)``. For real `x` such that",
        "`numpy.arctanh`) of ``arctanh(x)``. For real `x` such"
    ],
    [
        "The value(s) whose arctanh is (are) required.",
        "The value(s) whose arctanh is"
    ],
    [
        "The inverse hyperbolic tangent(s) of the `x` value(s). If `x` was",
        "The inverse hyperbolic tangent(s) of the"
    ],
    [
        "a scalar so is `out`, otherwise an array is returned.",
        "a scalar so is `out`, otherwise"
    ],
    [
        "For an arctanh() that returns ``NAN`` when real `x` is not in the",
        "For an arctanh() that returns ``NAN`` when real `x` is"
    ],
    [
        "``numpy.lib`` is mostly a space for implementing functions that don't",
        "``numpy.lib`` is mostly a space for implementing functions"
    ],
    [
        "belong in core or in another NumPy submodule with a clear purpose",
        "belong in core or in another"
    ],
    [
        "``numpy.lib``'s private submodules contain basic functions that are used by",
        "``numpy.lib``'s private submodules contain basic functions that are used"
    ],
    [
        "other public modules and are useful to have in the main name-space.",
        "other public modules and are useful to have in the main"
    ],
    [
        "\"format\", \"introspect\", \"mixins\", \"NumpyVersion\", \"npyio\", \"scimath\",",
        "\"format\", \"introspect\", \"mixins\","
    ],
    [
        "\"`np.lib.math` is a deprecated alias for the standard library \"",
        "\"`np.lib.math` is a deprecated alias for the"
    ],
    [
        "\"numpy.lib.emath was an alias for emath module that was removed \"",
        "\"numpy.lib.emath was an alias for emath module that was"
    ],
    [
        "f\"numpy.lib.{attr} is now private. If you are using a public \"",
        "f\"numpy.lib.{attr} is now private. If you are using a"
    ],
    [
        "\"function, it should be available in the main numpy namespace, \"",
        "\"function, it should be available in the main numpy"
    ],
    [
        "\"numpy.lib.arrayterator submodule is now private. To access \"",
        "\"numpy.lib.arrayterator submodule is now"
    ],
    [
        "raise AttributeError(\"module {!r} has no attribute \"",
        "raise AttributeError(\"module {!r} has"
    ],
    [
        "A buffered iterator for big arrays.",
        "A buffered iterator for"
    ],
    [
        "This module solves the problem of iterating over a big file-based array",
        "This module solves the problem of iterating over a"
    ],
    [
        "without having to read it into memory. The `Arrayterator` class wraps",
        "without having to read it into"
    ],
    [
        "an array object, and when iterated it will return sub-arrays with at most",
        "an array object, and when iterated it will return sub-arrays"
    ],
    [
        "`Arrayterator` creates a buffered iterator for reading big arrays in small",
        "`Arrayterator` creates a buffered iterator for reading big arrays in"
    ],
    [
        "contiguous blocks. The class is useful for objects stored in the",
        "contiguous blocks. The class is useful for objects stored in"
    ],
    [
        "file system. It allows iteration over the object *without* reading",
        "file system. It allows iteration over the object *without*"
    ],
    [
        "everything in memory; instead, small blocks are read and iterated over.",
        "everything in memory; instead, small blocks"
    ],
    [
        "`Arrayterator` can be used with any object that supports multidimensional",
        "`Arrayterator` can be used with any"
    ],
    [
        "slices. This includes NumPy arrays, but also variables from",
        "slices. This includes NumPy arrays, but"
    ],
    [
        "The buffer size. If `buf_size` is supplied, the maximum amount of",
        "The buffer size. If `buf_size` is supplied, the maximum amount"
    ],
    [
        "data that will be read into memory is `buf_size` elements.",
        "data that will be read into memory is `buf_size`"
    ],
    [
        "Default is None, which will read as many element as possible",
        "Default is None, which will read as many element as"
    ],
    [
        "numpy.memmap : Create a memory-map to an array stored",
        "numpy.memmap : Create a memory-map"
    ],
    [
        "in a binary file on disk.",
        "in a binary file"
    ],
    [
        "The algorithm works by first finding a \"running dimension\", along which",
        "The algorithm works by first finding a \"running"
    ],
    [
        "the blocks will be extracted. Given an array of dimensions",
        "the blocks will be extracted. Given an array of"
    ],
    [
        "first dimension will be used. If, on the other hand,",
        "first dimension will be used. If,"
    ],
    [
        "Blocks are extracted along this dimension, and when the last block is",
        "Blocks are extracted along this dimension, and when"
    ],
    [
        "returned the process continues from the next dimension, until all",
        "returned the process continues from"
    ],
    [
        "Now we can iterate over ``a_itor``, and it will return arrays of size",
        "Now we can iterate over ``a_itor``, and it"
    ],
    [
        "two. Since `buf_size` was smaller than any dimension, the first",
        "two. Since `buf_size` was smaller than"
    ],
    [
        "dimension will be iterated over first:",
        "dimension will be iterated over"
    ],
    [
        "index += (slice(None),) * (dims - len(index))",
        "index += (slice(None),) *"
    ],
    [
        "for i, (start, stop, step, slice_) in enumerate(",
        "for i, (start, stop, step, slice_) in"
    ],
    [
        "out.stop[i] = start + (slice_.stop or stop - start)",
        "out.stop[i] = start + (slice_.stop or"
    ],
    [
        "slice_ = tuple(slice(*t) for t in zip(",
        "slice_ = tuple(slice(*t) for t"
    ],
    [
        "This iterator returns elements of the array to be iterated over in",
        "This iterator returns elements of the array to be"
    ],
    [
        "The shape of the array to be iterated over.",
        "The shape of the array to be"
    ],
    [
        "count = self.buf_size or reduce(mul, self.shape)",
        "count = self.buf_size"
    ],
    [
        "stop[i] = start[i] + count * step[i]",
        "stop[i] = start[i] + count *"
    ],
    [
        "slice_ = tuple(slice(*t) for t in zip(start, stop, step))",
        "slice_ = tuple(slice(*t) for t in"
    ],
    [
        "Returns a dictionary containing the currently supported CPU dispatched",
        "Returns a dictionary containing the currently"
    ],
    [
        "Regular expression to filter by function name.",
        "Regular expression to filter by function"
    ],
    [
        "Regular expression to filter by data type.",
        "Regular expression to filter by"
    ],
    [
        "A dictionary where keys are optimized function names and values are",
        "A dictionary where keys are optimized function names and values"
    ],
    [
        "nested dictionaries indicating supported targets based on data types.",
        "nested dictionaries indicating supported targets based on data"
    ],
    [
        "Retrieve dispatch information for functions named 'add' or 'sub' and",
        "Retrieve dispatch information for functions named 'add' or 'sub'"
    ],
    [
        "k: v for k, v in targets.items()",
        "k: v for k,"
    ],
    [
        "from numpy._core.numeric import asarray, zeros, zeros_like, array, asanyarray",
        "from numpy._core.numeric import asarray,"
    ],
    [
        "raise IndexError('`indices` must be an integer array')",
        "raise IndexError('`indices` must be an integer"
    ],
    [
        "\"`indices` and `arr` must have the same number of dimensions\")",
        "\"`indices` and `arr` must have"
    ],
    [
        "for dim, n in zip(dest_dims, arr_shape):",
        "for dim, n in"
    ],
    [
        "the index and data arrays, and uses the former to look up values in the",
        "the index and data arrays, and uses the former to look up values in"
    ],
    [
        "latter. These slices can be different lengths.",
        "latter. These slices can be different"
    ],
    [
        "Functions returning an index along an axis, like `argsort` and",
        "Functions returning an index along an axis, like `argsort`"
    ],
    [
        "`argpartition`, produce suitable indices for this function.",
        "`argpartition`, produce suitable indices for"
    ],
    [
        "arr : ndarray (Ni..., M, Nk...)",
        "arr : ndarray (Ni..., M,"
    ],
    [
        "indices : ndarray (Ni..., J, Nk...)",
        "indices : ndarray (Ni...,"
    ],
    [
        "dimension of arr, but dimensions Ni and Nj only need to broadcast",
        "dimension of arr, but dimensions Ni and"
    ],
    [
        "This is equivalent to (but faster than) the following use of `ndindex` and",
        "This is equivalent to (but faster than)"
    ],
    [
        "`s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::",
        "`s_`, which sets each of ``ii`` and ``kk`` to a tuple"
    ],
    [
        "out = np.empty(Ni + (J,) + Nk)",
        "out = np.empty(Ni + (J,)"
    ],
    [
        "Equivalently, eliminating the inner loop, the last two lines would be::",
        "Equivalently, eliminating the inner loop, the last two lines"
    ],
    [
        "We can sort either by using sort directly, or argsort and this function",
        "We can sort either by using sort directly, or argsort"
    ],
    [
        "The same works for max and min, if you maintain the trivial dimension",
        "The same works for max and min,"
    ],
    [
        "If we want to get the max and min at the same time, we can stack the",
        "If we want to get the max and min"
    ],
    [
        "'when axis=None, `indices` must have a single dimension.')",
        "'when axis=None, `indices` must have a single"
    ],
    [
        "the index and data arrays, and uses the former to place values into the",
        "the index and data arrays, and uses the former to place values into"
    ],
    [
        "latter. These slices can be different lengths.",
        "latter. These slices can"
    ],
    [
        "Functions returning an index along an axis, like `argsort` and",
        "Functions returning an index along an"
    ],
    [
        "`argpartition`, produce suitable indices for this function.",
        "`argpartition`, produce suitable indices for this"
    ],
    [
        "arr : ndarray (Ni..., M, Nk...)",
        "arr : ndarray"
    ],
    [
        "indices : ndarray (Ni..., J, Nk...)",
        "indices : ndarray (Ni..., J,"
    ],
    [
        "values : array_like (Ni..., J, Nk...)",
        "values : array_like (Ni..., J,"
    ],
    [
        "values to insert at those indices. Its shape and dimension are",
        "values to insert at those indices. Its shape and"
    ],
    [
        "broadcast to match that of `indices`.",
        "broadcast to match that"
    ],
    [
        "This is equivalent to (but faster than) the following use of `ndindex` and",
        "This is equivalent to (but faster than) the following use"
    ],
    [
        "`s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::",
        "`s_`, which sets each of ``ii`` and ``kk``"
    ],
    [
        "Equivalently, eliminating the inner loop, the last two lines would be::",
        "Equivalently, eliminating the inner loop, the last two lines"
    ],
    [
        "We can replace the maximum values with:",
        "We can replace the maximum values"
    ],
    [
        "'when axis=None, `indices` must have a single dimension.')",
        "'when axis=None, `indices` must have"
    ],
    [
        "This is equivalent to (but faster than) the following use of `ndindex` and",
        "This is equivalent to (but faster than) the following use of"
    ],
    [
        "`s_`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of indices::",
        "`s_`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple"
    ],
    [
        "out[ii + jj + kk] = f[jj]",
        "out[ii + jj + kk]"
    ],
    [
        "Equivalently, eliminating the inner loop, this can be expressed as::",
        "Equivalently, eliminating the inner loop, this"
    ],
    [
        "slices of `arr` along the specified axis.",
        "slices of `arr` along the specified"
    ],
    [
        "Axis along which `arr` is sliced.",
        "Axis along which `arr` is"
    ],
    [
        "arr : ndarray (Ni..., M, Nk...)",
        "arr : ndarray (Ni...,"
    ],
    [
        "out : ndarray  (Ni..., Nj..., Nk...)",
        "out : ndarray (Ni...,"
    ],
    [
        "The output array. The shape of `out` is identical to the shape of",
        "The output array. The shape of `out` is identical"
    ],
    [
        "`arr`, except along the `axis` dimension. This axis is removed, and",
        "`arr`, except along the `axis` dimension. This"
    ],
    [
        "replaced with new dimensions equal to the shape of the return value",
        "replaced with new dimensions equal to the shape of"
    ],
    [
        "apply_over_axes : Apply a function repeatedly over multiple axes.",
        "apply_over_axes : Apply a function repeatedly over"
    ],
    [
        "`outarr` is the same as `arr`.",
        "`outarr` is the same"
    ],
    [
        "For a function that returns a higher dimensional array, those dimensions",
        "For a function that returns a"
    ],
    [
        "are inserted in place of the `axis` dimension.",
        "are inserted in place of the"
    ],
    [
        "inds = (ind + (Ellipsis,) for ind in inds)",
        "inds = (ind + (Ellipsis,) for ind"
    ],
    [
        "buff_dims[buff.ndim - res.ndim : buff.ndim] +",
        "buff_dims[buff.ndim - res.ndim : buff.ndim]"
    ],
    [
        "Apply a function repeatedly over multiple axes.",
        "Apply a function repeatedly"
    ],
    [
        "`func` is called as `res = func(a, axis)`, where `axis` is the first",
        "`func` is called as `res = func(a, axis)`, where `axis` is the"
    ],
    [
        "element of `axes`.  The result `res` of the function call must have",
        "element of `axes`. The result `res` of"
    ],
    [
        "either the same dimensions as `a` or one less dimension.  If `res`",
        "either the same dimensions as `a` or one less"
    ],
    [
        "has one less dimension than `a`, a dimension is inserted before",
        "has one less dimension than `a`, a dimension is inserted"
    ],
    [
        "`axis`.  The call to `func` is then repeated for each axis in `axes`,",
        "`axis`. The call to `func` is then repeated"
    ],
    [
        "with `res` as the first argument.",
        "with `res` as the"
    ],
    [
        "This function must take two arguments, `func(a, axis)`.",
        "This function must take"
    ],
    [
        "Axes over which `func` is applied; the elements must be integers.",
        "Axes over which `func` is applied; the elements must be"
    ],
    [
        "The output array.  The number of dimensions is the same as `a`,",
        "The output array. The number of dimensions"
    ],
    [
        "but the shape can be different.  This depends on whether `func`",
        "but the shape can be different."
    ],
    [
        "changes the shape of its output with respect to its input.",
        "changes the shape of its output with"
    ],
    [
        "This function is equivalent to tuple axis arguments to reorderable ufuncs",
        "This function is equivalent to tuple axis"
    ],
    [
        "with keepdims=True. Tuple axis arguments to ufuncs have been available since",
        "with keepdims=True. Tuple axis arguments to ufuncs"
    ],
    [
        "Tuple axis arguments to ufuncs are equivalent:",
        "Tuple axis arguments to ufuncs are"
    ],
    [
        "raise ValueError(\"function is not returning \"",
        "raise ValueError(\"function is"
    ],
    [
        "\"an array of the correct shape\")",
        "\"an array of"
    ],
    [
        "Expand the shape of an array.",
        "Expand the shape"
    ],
    [
        "Insert a new axis that will appear at the `axis` position in the expanded",
        "Insert a new axis that will appear at the"
    ],
    [
        "axis : int or tuple of ints",
        "axis : int or"
    ],
    [
        "Position in the expanded axes where the new axis (or axes) is placed.",
        "Position in the expanded axes where the new"
    ],
    [
        "Passing an axis where ``axis > a.ndim`` will be treated as",
        "Passing an axis where ``axis > a.ndim`` will be treated"
    ],
    [
        "View of `a` with the number of dimensions increased.",
        "View of `a` with the number of"
    ],
    [
        "squeeze : The inverse operation, removing singleton dimensions",
        "squeeze : The inverse operation,"
    ],
    [
        "reshape : Insert, remove, and combine dimensions, and resize existing ones",
        "reshape : Insert, remove, and combine"
    ],
    [
        "The following is equivalent to ``x[np.newaxis, :]`` or ``x[np.newaxis]``:",
        "The following is equivalent to"
    ],
    [
        "The following is equivalent to ``x[:, np.newaxis]``:",
        "The following is equivalent"
    ],
    [
        "``axis`` may also be a tuple:",
        "``axis`` may also be a"
    ],
    [
        "Note that some examples may use ``None`` instead of ``np.newaxis``.  These",
        "Note that some examples may use ``None`` instead"
    ],
    [
        "if type(axis) not in (tuple, list):",
        "if type(axis) not"
    ],
    [
        "Arrays to stack. All of them must have the same first dimension.",
        "Arrays to stack. All of them must have the"
    ],
    [
        "The array formed by stacking the given arrays.",
        "The array formed by stacking the"
    ],
    [
        "Stack arrays in sequence depth wise (along third axis).",
        "Stack arrays in sequence depth"
    ],
    [
        "instance, for pixel-data with a height (first axis), width (second axis),",
        "instance, for pixel-data with a height (first axis), width"
    ],
    [
        "and r/g/b channels (third axis). The functions `concatenate`, `stack` and",
        "and r/g/b channels (third axis). The functions `concatenate`,"
    ],
    [
        "`block` provide more general stacking and concatenation operations.",
        "`block` provide more general stacking and concatenation"
    ],
    [
        "The arrays must have the same shape along all but the third axis.",
        "The arrays must have the same shape along all but the"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of arrays along"
    ],
    [
        "stack : Join a sequence of arrays along a new axis.",
        "stack : Join a sequence of"
    ],
    [
        "block : Assemble an nd-array from nested lists of blocks.",
        "block : Assemble an nd-array from nested"
    ],
    [
        "vstack : Stack arrays in sequence vertically (row wise).",
        "vstack : Stack arrays in sequence vertically"
    ],
    [
        "hstack : Stack arrays in sequence horizontally (column wise).",
        "hstack : Stack arrays in"
    ],
    [
        "dsplit : Split array along third axis.",
        "dsplit : Split array"
    ],
    [
        "Split an array into multiple sub-arrays.",
        "Split an array into multiple"
    ],
    [
        "Please refer to the ``split`` documentation.  The only difference",
        "Please refer to the ``split`` documentation. The"
    ],
    [
        "between these functions is that ``array_split`` allows",
        "between these functions is that ``array_split``"
    ],
    [
        "`indices_or_sections` to be an integer that does *not* equally",
        "`indices_or_sections` to be an integer that"
    ],
    [
        "divide the axis. For an array of length l that should be split",
        "divide the axis. For an array of length"
    ],
    [
        "and the rest of size l//n.",
        "and the rest of size"
    ],
    [
        "split : Split array into multiple sub-arrays of equal size.",
        "split : Split array into multiple"
    ],
    [
        "Split an array into multiple sub-arrays as views into `ary`.",
        "Split an array into multiple sub-arrays as"
    ],
    [
        "Array to be divided into sub-arrays.",
        "Array to be"
    ],
    [
        "If `indices_or_sections` is an integer, N, the array will be divided",
        "If `indices_or_sections` is an integer, N, the array"
    ],
    [
        "into N equal arrays along `axis`.  If such a split is not possible,",
        "into N equal arrays along `axis`. If such a split is"
    ],
    [
        "indicate where along `axis` the array is split.  For example,",
        "indicate where along `axis` the array is"
    ],
    [
        "If an index exceeds the dimension of the array along `axis`,",
        "If an index exceeds the dimension of the array"
    ],
    [
        "an empty sub-array is returned correspondingly.",
        "an empty sub-array is returned"
    ],
    [
        "A list of sub-arrays as views into `ary`.",
        "A list of sub-arrays as views"
    ],
    [
        "If `indices_or_sections` is given as an integer, but",
        "If `indices_or_sections` is given as an integer,"
    ],
    [
        "a split does not result in equal division.",
        "a split does not result"
    ],
    [
        "array_split : Split an array into multiple sub-arrays of equal or",
        "array_split : Split an array into multiple sub-arrays"
    ],
    [
        "near-equal size.  Does not raise an exception if",
        "near-equal size. Does not raise"
    ],
    [
        "an equal division cannot be made.",
        "an equal division cannot"
    ],
    [
        "hsplit : Split array into multiple sub-arrays horizontally (column-wise).",
        "hsplit : Split array into multiple sub-arrays"
    ],
    [
        "vsplit : Split array into multiple sub-arrays vertically (row wise).",
        "vsplit : Split array into multiple sub-arrays"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of arrays along an"
    ],
    [
        "stack : Join a sequence of arrays along a new axis.",
        "stack : Join a sequence of arrays along a"
    ],
    [
        "hstack : Stack arrays in sequence horizontally (column wise).",
        "hstack : Stack arrays in sequence horizontally"
    ],
    [
        "vstack : Stack arrays in sequence vertically (row wise).",
        "vstack : Stack arrays in sequence vertically"
    ],
    [
        "dstack : Stack arrays in sequence depth wise (along third dimension).",
        "dstack : Stack arrays in sequence depth"
    ],
    [
        "'array split does not result in an equal division') from None",
        "'array split does not result in an equal"
    ],
    [
        "Split an array into multiple sub-arrays horizontally (column-wise).",
        "Split an array into"
    ],
    [
        "Please refer to the `split` documentation.  `hsplit` is equivalent",
        "Please refer to the `split` documentation. `hsplit`"
    ],
    [
        "split : Split an array into multiple sub-arrays of equal size.",
        "split : Split an array into"
    ],
    [
        "With a higher dimensional array the split is still along the second axis.",
        "With a higher dimensional array the split is still along the"
    ],
    [
        "Split an array into multiple sub-arrays vertically (row-wise).",
        "Split an array into multiple"
    ],
    [
        "Please refer to the ``split`` documentation.  ``vsplit`` is equivalent",
        "Please refer to the ``split`` documentation."
    ],
    [
        "first axis regardless of the array dimension.",
        "first axis regardless of the array"
    ],
    [
        "split : Split an array into multiple sub-arrays of equal size.",
        "split : Split an array into multiple"
    ],
    [
        "With a higher dimensional array the split is still along the first axis.",
        "With a higher dimensional array the split is still along"
    ],
    [
        "Please refer to the `split` documentation.  `dsplit` is equivalent",
        "Please refer to the `split` documentation. `dsplit` is"
    ],
    [
        "split : Split an array into multiple sub-arrays of equal size.",
        "split : Split an array into multiple sub-arrays of"
    ],
    [
        "\"\"\"Find the wrapper for the array with the highest priority.",
        "\"\"\"Find the wrapper for the array with the"
    ],
    [
        "In case of ties, leftmost wins. If no wrapper is found, return None.",
        "In case of ties, leftmost wins. If no wrapper is"
    ],
    [
        "x.__array_wrap__) for i, x in enumerate(args)",
        "x.__array_wrap__) for i,"
    ],
    [
        "Computes the Kronecker product, a composite array made of blocks of the",
        "Computes the Kronecker product, a composite"
    ],
    [
        "second array scaled by the first.",
        "second array scaled by"
    ],
    [
        "The function assumes that the number of dimensions of `a` and `b`",
        "The function assumes that the number of dimensions of `a` and"
    ],
    [
        "are the same, if necessary prepending the smallest with ones.",
        "are the same, if necessary"
    ],
    [
        "The elements are products of elements from `a` and `b`, organized",
        "The elements are products of elements from `a` and"
    ],
    [
        "a = array(a, copy=None, subok=True, ndmin=b.ndim)",
        "a = array(a, copy=None, subok=True,"
    ],
    [
        "is_any_mat = isinstance(a, matrix) or isinstance(b, matrix)",
        "is_any_mat = isinstance(a, matrix) or"
    ],
    [
        "a_arr = expand_dims(a, axis=tuple(range(ndb - nda)))",
        "a_arr = expand_dims(a, axis=tuple(range(ndb -"
    ],
    [
        "b_arr = expand_dims(b, axis=tuple(range(nda - ndb)))",
        "b_arr = expand_dims(b, axis=tuple(range(nda -"
    ],
    [
        "result = _nx.multiply(a_arr, b_arr, subok=(not is_any_mat))",
        "result = _nx.multiply(a_arr,"
    ],
    [
        "return result if not is_any_mat else matrix(result, copy=False)",
        "return result if not is_any_mat"
    ],
    [
        "Construct an array by repeating A the number of times given by reps.",
        "Construct an array by repeating A the number of"
    ],
    [
        "If `reps` has length ``d``, the result will have dimension of",
        "If `reps` has length ``d``, the result"
    ],
    [
        "If ``A.ndim < d``, `A` is promoted to be d-dimensional by prepending new",
        "If ``A.ndim < d``, `A` is promoted to"
    ],
    [
        "behavior, promote `A` to d-dimensions manually before calling this",
        "behavior, promote `A` to d-dimensions"
    ],
    [
        "Note : Although tile may be used for broadcasting, it is strongly",
        "Note : Although tile may be used for broadcasting, it is"
    ],
    [
        "recommended to use numpy's broadcasting operations and functions.",
        "recommended to use numpy's broadcasting operations"
    ],
    [
        "The number of repetitions of `A` along each axis.",
        "The number of repetitions of"
    ],
    [
        "repeat : Repeat elements of an array.",
        "repeat : Repeat elements"
    ],
    [
        "broadcast_to : Broadcast an array to a new shape",
        "broadcast_to : Broadcast an array to a"
    ],
    [
        "c = _nx.array(A, copy=None, subok=True, ndmin=d)",
        "c = _nx.array(A, copy=None,"
    ],
    [
        "shape_out = tuple(s * t for s, t in zip(c.shape, tup))",
        "shape_out = tuple(s * t for s, t in zip(c.shape,"
    ],
    [
        "for dim_in, nrep in zip(c.shape, tup):",
        "for dim_in, nrep in zip(c.shape,"
    ],
    [
        "This implementation avoids the problem of signed integer arrays having a",
        "This implementation avoids the problem of signed integer"
    ],
    [
        "peak-to-peak value that cannot be represented with the array's data type.",
        "peak-to-peak value that cannot be represented"
    ],
    [
        "This function returns an unsigned value for signed integer arrays.",
        "This function returns an unsigned value for signed integer"
    ],
    [
        "Bin width is inversely proportional to the data size. Used by many",
        "Bin width is inversely proportional to the data size."
    ],
    [
        "Input data that is to be histogrammed, trimmed to range. May not",
        "Input data that is to be histogrammed, trimmed to range. May"
    ],
    [
        "h : An estimate of the optimal bin width for the given data.",
        "h : An estimate of the optimal bin width for the given"
    ],
    [
        "A very simplistic estimator based on the assumption of normality of",
        "A very simplistic estimator based on"
    ],
    [
        "the data. This estimator has poor performance for non-normal data,",
        "the data. This estimator has poor performance"
    ],
    [
        "which becomes especially obvious for large data sets. The estimate",
        "which becomes especially obvious for large data sets."
    ],
    [
        "depends only on size of the data.",
        "depends only on size"
    ],
    [
        "Input data that is to be histogrammed, trimmed to range. May not",
        "Input data that is to be histogrammed, trimmed to range. May"
    ],
    [
        "h : An estimate of the optimal bin width for the given data.",
        "h : An estimate of the optimal bin"
    ],
    [
        "Another simple estimator with no normality assumption. It has better",
        "Another simple estimator with no"
    ],
    [
        "performance for large data than Sturges, but tends to overestimate",
        "performance for large data than Sturges, but tends to"
    ],
    [
        "the number of bins. The number of bins is proportional to the cube",
        "the number of bins. The number of bins is proportional"
    ],
    [
        "root of data size (asymptotically optimal). The estimate depends",
        "root of data size (asymptotically optimal). The estimate"
    ],
    [
        "only on size of the data.",
        "only on size"
    ],
    [
        "Input data that is to be histogrammed, trimmed to range. May not",
        "Input data that is to be"
    ],
    [
        "h : An estimate of the optimal bin width for the given data.",
        "h : An estimate of the optimal bin width for"
    ],
    [
        "The binwidth is proportional to the standard deviation of the data",
        "The binwidth is proportional to the standard deviation"
    ],
    [
        "and inversely proportional to the cube root of data size",
        "and inversely proportional to the cube root of data"
    ],
    [
        "Input data that is to be histogrammed, trimmed to range. May not",
        "Input data that is to be histogrammed, trimmed"
    ],
    [
        "h : An estimate of the optimal bin width for the given data.",
        "h : An estimate of the optimal bin width"
    ],
    [
        "Histogram bin estimator based on minimizing the estimated integrated squared error (ISE).",
        "Histogram bin estimator based on minimizing the"
    ],
    [
        "The number of bins is chosen by minimizing the estimated ISE against the unknown true distribution.",
        "The number of bins is chosen by minimizing the"
    ],
    [
        "The ISE is estimated using cross-validation and can be regarded as a generalization of Scott's rule.",
        "The ISE is estimated using cross-validation and can be regarded"
    ],
    [
        "This paper by Stone appears to be the origination of this rule.",
        "This paper by Stone appears to be the"
    ],
    [
        "Input data that is to be histogrammed, trimmed to range. May not",
        "Input data that is to be histogrammed,"
    ],
    [
        "The lower and upper range of the bins.",
        "The lower and upper range of"
    ],
    [
        "h : An estimate of the optimal bin width for the given data.",
        "h : An estimate of the optimal"
    ],
    [
        "warnings.warn(\"The number of bins estimated may be suboptimal.\",",
        "warnings.warn(\"The number of bins estimated may"
    ],
    [
        "Improved version of Sturges' formula which works better for",
        "Improved version of Sturges' formula which works better"
    ],
    [
        "Input data that is to be histogrammed, trimmed to range. May not",
        "Input data that is to be histogrammed, trimmed to range."
    ],
    [
        "h : An estimate of the optimal bin width for the given data.",
        "h : An estimate of the optimal bin width for the given"
    ],
    [
        "The Freedman-Diaconis rule uses interquartile range (IQR) to",
        "The Freedman-Diaconis rule uses interquartile range (IQR)"
    ],
    [
        "estimate binwidth. It is considered a variation of the Scott rule",
        "estimate binwidth. It is considered a variation of the Scott"
    ],
    [
        "with more robustness as the IQR is less affected by outliers than",
        "with more robustness as the IQR"
    ],
    [
        "the standard deviation. However, the IQR depends on fewer points",
        "the standard deviation. However, the IQR depends on fewer"
    ],
    [
        "than the standard deviation, so it is less accurate, especially for",
        "than the standard deviation, so it"
    ],
    [
        "Binwidth is inversely proportional to the cube root of data size",
        "Binwidth is inversely proportional to the cube root of"
    ],
    [
        "Input data that is to be histogrammed, trimmed to range. May not",
        "Input data that is to be histogrammed,"
    ],
    [
        "h : An estimate of the optimal bin width for the given data.",
        "h : An estimate of the optimal bin width for"
    ],
    [
        "Histogram bin estimator that uses the minimum width of the",
        "Histogram bin estimator that uses the minimum width of"
    ],
    [
        "Freedman-Diaconis and Sturges estimators if the FD bin width is non-zero.",
        "Freedman-Diaconis and Sturges estimators if the"
    ],
    [
        "The FD estimator is usually the most robust method, but its width",
        "The FD estimator is usually the most"
    ],
    [
        "estimate tends to be too large for small `x` and bad for data with limited",
        "estimate tends to be too large for small `x`"
    ],
    [
        "and is the default in the R language. This method gives good off-the-shelf",
        "and is the default in the R language. This method gives good"
    ],
    [
        "use, so we revert to the Sturges estimator, which only uses the size of the",
        "use, so we revert to the Sturges estimator, which only"
    ],
    [
        "Input data that is to be histogrammed, trimmed to range. May not",
        "Input data that is to be histogrammed, trimmed to range."
    ],
    [
        "h : An estimate of the optimal bin width for the given data.",
        "h : An estimate of the optimal"
    ],
    [
        "\"\"\" Check a and weights have matching shapes, and ravel both \"\"\"",
        "\"\"\" Check a and weights have matching"
    ],
    [
        "warnings.warn(\"Converting input from {} to {} for compatibility.\"",
        "warnings.warn(\"Converting input from {} to"
    ],
    [
        "'weights should have the same shape as a.')",
        "'weights should have the same shape"
    ],
    [
        "Determine the outer bin edges to use, from either the data or the range",
        "Determine the outer bin edges to use, from either the data"
    ],
    [
        "'max must be larger than min in range parameter.')",
        "'max must be larger than min in range"
    ],
    [
        "\"supplied range of [{}, {}] is not finite\".format(first_edge, last_edge))",
        "\"supplied range of [{}, {}] is"
    ],
    [
        "\"autodetected range of [{}, {}] is not finite\".format(first_edge, last_edge))",
        "\"autodetected range of [{}, {}] is not"
    ],
    [
        "Subtract two values where a >= b, and produce an unsigned result",
        "Subtract two values where a >= b, and produce an unsigned"
    ],
    [
        "This is needed when finding the difference between the upper and lower",
        "This is needed when finding the difference between"
    ],
    [
        "Computes the bins used internally by `histogram`.",
        "Computes the bins used internally"
    ],
    [
        "The upper bound, lowerbound, and number of bins, used in the optimized",
        "The upper bound, lowerbound, and number"
    ],
    [
        "implementation of `histogram` that works on uniform bins.",
        "implementation of `histogram` that works on uniform"
    ],
    [
        "\"{!r} is not a valid estimator for `bins`\".format(bin_name))",
        "\"{!r} is not a valid"
    ],
    [
        "raise TypeError(\"Automated estimation of the number of \"",
        "raise TypeError(\"Automated estimation of the"
    ],
    [
        "\"bins is not supported for weighted data\")",
        "\"bins is not supported for weighted"
    ],
    [
        "n_equal_bins = int(np.ceil(_unsigned_subtract(last_edge, first_edge) / width))",
        "n_equal_bins = int(np.ceil(_unsigned_subtract(last_edge, first_edge) /"
    ],
    [
        "'`bins` must be an integer, a string, or an array') from e",
        "'`bins` must be an integer, a"
    ],
    [
        "raise ValueError('`bins` must be positive, when an integer')",
        "raise ValueError('`bins` must be positive,"
    ],
    [
        "'`bins` must increase monotonically, when an array')",
        "'`bins` must increase monotonically,"
    ],
    [
        "f'Too many bins for data range. Cannot create {n_equal_bins} '",
        "f'Too many bins for data range. Cannot create {n_equal_bins}"
    ],
    [
        "Like `searchsorted`, but where the last item in `v` is placed on the right.",
        "Like `searchsorted`, but where the last item in `v` is placed"
    ],
    [
        "In the context of a histogram, this makes the last bin edge inclusive",
        "In the context of a histogram, this makes the last bin"
    ],
    [
        "Function to calculate only the edges of the bins used by the `histogram`",
        "Function to calculate only the edges of the bins"
    ],
    [
        "Input data. The histogram is computed over the flattened array.",
        "Input data. The histogram is computed over"
    ],
    [
        "bins : int or sequence of scalars or str, optional",
        "bins : int or sequence"
    ],
    [
        "If `bins` is an int, it defines the number of equal-width",
        "If `bins` is an int, it defines the"
    ],
    [
        "sequence, it defines the bin edges, including the rightmost",
        "sequence, it defines the bin"
    ],
    [
        "edge, allowing for non-uniform bin widths.",
        "edge, allowing for non-uniform bin"
    ],
    [
        "If `bins` is a string from the list below, `histogram_bin_edges` will",
        "If `bins` is a string from the list"
    ],
    [
        "use the method chosen to calculate the optimal bin width and",
        "use the method chosen to calculate the optimal bin"
    ],
    [
        "consequently the number of bins (see the Notes section for more detail",
        "consequently the number of bins (see the Notes section for"
    ],
    [
        "on the estimators) from the data that falls within the requested range.",
        "on the estimators) from the data that"
    ],
    [
        "While the bin width will be optimal for the actual data",
        "While the bin width will be optimal for the actual"
    ],
    [
        "in the range, the number of bins will be computed to fill the",
        "in the range, the number of bins will be computed"
    ],
    [
        "entire range, including the empty portions. For visualisation,",
        "entire range, including the"
    ],
    [
        "using the 'auto' option is suggested. Weighted data is not",
        "using the 'auto' option is"
    ],
    [
        "supported for automated bin size selection.",
        "supported for automated"
    ],
    [
        "Minimum bin width between the 'sturges' and 'fd' estimators.",
        "Minimum bin width between the"
    ],
    [
        "Robust (resilient to outliers) estimator that takes into",
        "Robust (resilient to outliers) estimator that takes"
    ],
    [
        "account data variability and data size.",
        "account data variability and"
    ],
    [
        "An improved version of Sturges' estimator that works better",
        "An improved version of Sturges' estimator that works"
    ],
    [
        "Less robust estimator that takes into account data variability",
        "Less robust estimator that takes into account"
    ],
    [
        "Estimator based on leave-one-out cross-validation estimate of",
        "Estimator based on leave-one-out"
    ],
    [
        "the integrated squared error. Can be regarded as a generalization",
        "the integrated squared error. Can be"
    ],
    [
        "Estimator does not take variability into account, only data",
        "Estimator does not take variability into account, only"
    ],
    [
        "size. Commonly overestimates number of bins required.",
        "size. Commonly overestimates number"
    ],
    [
        "R's default method, only accounts for data size. Only",
        "R's default method, only accounts for data"
    ],
    [
        "optimal for gaussian data and underestimates number of bins",
        "optimal for gaussian data and underestimates number"
    ],
    [
        "Square root (of data size) estimator, used by Excel and",
        "Square root (of data size) estimator, used"
    ],
    [
        "other programs for its speed and simplicity.",
        "other programs for its speed"
    ],
    [
        "The lower and upper range of the bins.  If not provided, range",
        "The lower and upper range of the bins."
    ],
    [
        "is simply ``(a.min(), a.max())``.  Values outside the range are",
        "is simply ``(a.min(), a.max())``. Values outside"
    ],
    [
        "ignored. The first element of the range must be less than or",
        "ignored. The first element of the range"
    ],
    [
        "equal to the second. `range` affects the automatic bin",
        "equal to the second. `range` affects"
    ],
    [
        "computation as well. While bin width is computed to be optimal",
        "computation as well. While bin width is computed to be"
    ],
    [
        "based on the actual data within `range`, the bin count will fill",
        "based on the actual data within `range`, the bin"
    ],
    [
        "the entire range including portions containing no data.",
        "the entire range including portions containing"
    ],
    [
        "An array of weights, of the same shape as `a`.  Each value in",
        "An array of weights, of the same shape as"
    ],
    [
        "`a` only contributes its associated weight towards the bin count",
        "`a` only contributes its associated weight towards the"
    ],
    [
        "but may be in the future.",
        "but may be in the"
    ],
    [
        "bin_edges : array of dtype float",
        "bin_edges : array of"
    ],
    [
        "The edges to pass into `histogram`",
        "The edges to"
    ],
    [
        "The methods to estimate the optimal number of bins are well founded",
        "The methods to estimate the optimal number of bins"
    ],
    [
        "in literature, and are inspired by the choices R provides for",
        "in literature, and are inspired by the choices R"
    ],
    [
        "histogram visualisation. Note that having the number of bins",
        "histogram visualisation. Note that having the number"
    ],
    [
        "why it appears in most estimators. These are simply plug-in methods",
        "why it appears in most estimators. These"
    ],
    [
        "that give good starting points for number of bins. In the equations",
        "that give good starting points for number of bins. In the"
    ],
    [
        "below, :math:`h` is the binwidth and :math:`n_h` is the number of",
        "below, :math:`h` is the binwidth and"
    ],
    [
        "bins. All estimators that compute bin counts are recast to bin width",
        "bins. All estimators that compute bin counts are recast"
    ],
    [
        "using the `ptp` of the data. The final bin count is obtained from",
        "using the `ptp` of the data. The final bin count is"
    ],
    [
        "``np.round(np.ceil(range / h))``. The final bin width is often less",
        "``np.round(np.ceil(range / h))``. The final bin width"
    ],
    [
        "than what is returned by the estimators below.",
        "than what is returned by the estimators"
    ],
    [
        "'auto' (minimum bin width of the 'sturges' and 'fd' estimators)",
        "'auto' (minimum bin width of the"
    ],
    [
        "A compromise to get a good value. For small datasets the Sturges",
        "A compromise to get a good value."
    ],
    [
        "value will usually be chosen, while larger datasets will usually",
        "value will usually be chosen, while"
    ],
    [
        "default to FD.  Avoids the overly conservative behaviour of FD",
        "default to FD. Avoids the"
    ],
    [
        "and Sturges for small and large datasets respectively.",
        "and Sturges for small"
    ],
    [
        "The binwidth is proportional to the interquartile range (IQR)",
        "The binwidth is proportional to the"
    ],
    [
        "and inversely proportional to cube root of a.size. Can be too",
        "and inversely proportional to cube root"
    ],
    [
        "conservative for small datasets, but is quite good for large",
        "conservative for small datasets, but is quite good"
    ],
    [
        "datasets. The IQR is very robust to outliers.",
        "datasets. The IQR is very"
    ],
    [
        "The binwidth is proportional to the standard deviation of the",
        "The binwidth is proportional to the standard deviation of"
    ],
    [
        "data and inversely proportional to cube root of ``x.size``. Can",
        "data and inversely proportional to"
    ],
    [
        "be too conservative for small datasets, but is quite good for",
        "be too conservative for small datasets, but"
    ],
    [
        "large datasets. The standard deviation is not very robust to",
        "large datasets. The standard deviation is not very robust"
    ],
    [
        "outliers. Values are very similar to the Freedman-Diaconis",
        "outliers. Values are very"
    ],
    [
        "estimator in the absence of outliers.",
        "estimator in the absence"
    ],
    [
        "The number of bins is only proportional to cube root of",
        "The number of bins is only proportional to cube"
    ],
    [
        "``a.size``. It tends to overestimate the number of bins and it",
        "``a.size``. It tends to overestimate the"
    ],
    [
        "does not take into account data variability.",
        "does not take into account"
    ],
    [
        "estimator assumes normality of data and is too conservative for",
        "estimator assumes normality of data and is"
    ],
    [
        "larger, non-normal datasets. This is the default method in R's",
        "larger, non-normal datasets. This is the default method in"
    ],
    [
        "An improved version of Sturges' formula that produces better",
        "An improved version of Sturges' formula"
    ],
    [
        "estimates for non-normal datasets. This estimator attempts to",
        "estimates for non-normal datasets."
    ],
    [
        "account for the skew of the data.",
        "account for the skew"
    ],
    [
        ".. math:: n_h = \\sqrt n",
        ".. math:: n_h"
    ],
    [
        "The simplest and fastest estimator. Only takes into account the",
        "The simplest and fastest estimator. Only takes into"
    ],
    [
        "Additionally, if the data is of integer dtype, then the binwidth will never",
        "Additionally, if the data is of integer dtype, then the binwidth will"
    ],
    [
        "For consistency with histogram, an array of pre-computed bins is",
        "For consistency with histogram, an array of pre-computed bins"
    ],
    [
        "This function allows one set of bins to be computed, and reused across",
        "This function allows one set of bins to be computed, and reused"
    ],
    [
        "Which gives more easily comparable results than using separate bins for",
        "Which gives more easily comparable results than using separate"
    ],
    [
        "bin_edges, _ = _get_bin_edges(a, bins, range, weights)",
        "bin_edges, _ = _get_bin_edges(a, bins,"
    ],
    [
        "Compute the histogram of a dataset.",
        "Compute the histogram of a"
    ],
    [
        "Input data. The histogram is computed over the flattened array.",
        "Input data. The histogram is computed over the"
    ],
    [
        "bins : int or sequence of scalars or str, optional",
        "bins : int or sequence of scalars or str,"
    ],
    [
        "If `bins` is an int, it defines the number of equal-width",
        "If `bins` is an int, it defines"
    ],
    [
        "sequence, it defines a monotonically increasing array of bin edges,",
        "sequence, it defines a monotonically increasing"
    ],
    [
        "including the rightmost edge, allowing for non-uniform bin widths.",
        "including the rightmost edge, allowing for"
    ],
    [
        "If `bins` is a string, it defines the method used to calculate the",
        "If `bins` is a string, it defines the"
    ],
    [
        "optimal bin width, as defined by `histogram_bin_edges`.",
        "optimal bin width, as"
    ],
    [
        "The lower and upper range of the bins.  If not provided, range",
        "The lower and upper range of the bins. If"
    ],
    [
        "is simply ``(a.min(), a.max())``.  Values outside the range are",
        "is simply ``(a.min(), a.max())``. Values outside"
    ],
    [
        "ignored. The first element of the range must be less than or",
        "ignored. The first element of the range must be less than"
    ],
    [
        "equal to the second. `range` affects the automatic bin",
        "equal to the second. `range` affects the automatic"
    ],
    [
        "computation as well. While bin width is computed to be optimal",
        "computation as well. While bin width is"
    ],
    [
        "based on the actual data within `range`, the bin count will fill",
        "based on the actual data within `range`, the bin count will"
    ],
    [
        "the entire range including portions containing no data.",
        "the entire range including portions containing"
    ],
    [
        "An array of weights, of the same shape as `a`.  Each value in",
        "An array of weights, of the same shape as `a`. Each"
    ],
    [
        "`a` only contributes its associated weight towards the bin count",
        "`a` only contributes its associated weight"
    ],
    [
        "normalized, so that the integral of the density over the range",
        "normalized, so that the integral of the density over the"
    ],
    [
        "Please note that the ``dtype`` of `weights` will also become the",
        "Please note that the ``dtype`` of `weights` will also become"
    ],
    [
        "``dtype`` of the returned accumulator (`hist`), so it must be",
        "``dtype`` of the returned accumulator (`hist`), so it"
    ],
    [
        "large enough to hold accumulated values as well.",
        "large enough to hold accumulated values as"
    ],
    [
        "If ``False``, the result will contain the number of samples in",
        "If ``False``, the result will contain the number of"
    ],
    [
        "each bin. If ``True``, the result is the value of the",
        "each bin. If ``True``, the result is the"
    ],
    [
        "probability *density* function at the bin, normalized such that",
        "probability *density* function at the"
    ],
    [
        "width are chosen; it is not a probability *mass* function.",
        "width are chosen; it is not a probability"
    ],
    [
        "The values of the histogram. See `density` and `weights` for a",
        "The values of the histogram. See"
    ],
    [
        "description of the possible semantics.  If `weights` are given,",
        "description of the possible semantics. If `weights`"
    ],
    [
        "``hist.dtype`` will be taken from `weights`.",
        "``hist.dtype`` will be taken"
    ],
    [
        "bin_edges : array of dtype float",
        "bin_edges : array of"
    ],
    [
        "All but the last (righthand-most) bin is half-open.  In other words,",
        "All but the last (righthand-most) bin is half-open. In other"
    ],
    [
        ">>> hist, bin_edges = np.histogram(a, density=True)",
        ">>> hist, bin_edges = np.histogram(a,"
    ],
    [
        "bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)",
        "bin_edges, uniform_bins = _get_bin_edges(a, bins, range,"
    ],
    [
        "if uniform_bins is not None and simple_weights:",
        "if uniform_bins is not None"
    ],
    [
        "f_indices = ((_unsigned_subtract(tmp_a, first_edge) / norm_denom)",
        "f_indices = ((_unsigned_subtract(tmp_a,"
    ],
    [
        "return n / db / n.sum(), bin_edges",
        "return n / db"
    ],
    [
        "Compute the multidimensional histogram of some data.",
        "Compute the multidimensional histogram of"
    ],
    [
        "sample : (N, D) array, or (N, D) array_like",
        "sample : (N, D) array, or (N,"
    ],
    [
        "Note the unusual interpretation of sample when an array_like:",
        "Note the unusual interpretation of"
    ],
    [
        "* When an array, each row is a coordinate in a D-dimensional space -",
        "* When an array, each row is"
    ],
    [
        "* When an array_like, each element is the list of values for single",
        "* When an array_like, each element is the list"
    ],
    [
        "coordinate - such as ``histogramdd((X, Y, Z))``.",
        "coordinate - such as"
    ],
    [
        "The first form should be preferred.",
        "The first form"
    ],
    [
        "bins : sequence or int, optional",
        "bins : sequence or"
    ],
    [
        "* A sequence of arrays describing the monotonically increasing bin",
        "* A sequence of arrays describing"
    ],
    [
        "* The number of bins for each dimension (nx, ny, ... =bins)",
        "* The number of bins for each dimension (nx, ny,"
    ],
    [
        "* The number of bins for all dimensions (nx=ny=...=bins).",
        "* The number of bins for all"
    ],
    [
        "A sequence of length D, each an optional (lower, upper) tuple giving",
        "A sequence of length D, each an optional (lower,"
    ],
    [
        "the outer bin edges to be used if the edges are not given explicitly in",
        "the outer bin edges to be used if"
    ],
    [
        "An entry of None in the sequence results in the minimum and maximum",
        "An entry of None in the sequence"
    ],
    [
        "values being used for the corresponding dimension.",
        "values being used for the"
    ],
    [
        "The default, None, is equivalent to passing a tuple of D None values.",
        "The default, None, is equivalent to passing a tuple"
    ],
    [
        "If False, the default, returns the number of samples in each bin.",
        "If False, the default, returns the number of samples in each"
    ],
    [
        "If True, returns the probability *density* function at the bin,",
        "If True, returns the probability *density*"
    ],
    [
        "An array of values `w_i` weighing each sample `(x_i, y_i, z_i, ...)`.",
        "An array of values `w_i` weighing each sample `(x_i, y_i, z_i,"
    ],
    [
        "the values of the returned histogram are equal to the sum of the",
        "the values of the returned histogram are"
    ],
    [
        "weights belonging to the samples falling into each bin.",
        "weights belonging to the samples"
    ],
    [
        "The multidimensional histogram of sample x. See density and weights",
        "The multidimensional histogram of sample x. See density"
    ],
    [
        "A tuple of D arrays describing the bin edges for each dimension.",
        "A tuple of D arrays describing"
    ],
    [
        "'The dimension of bins must be equal to the dimension of the '",
        "'The dimension of bins must be equal to the dimension of"
    ],
    [
        "raise ValueError('range argument must have one entry per dimension')",
        "raise ValueError('range argument must have one entry per"
    ],
    [
        "'`bins[{}]` must be positive, when an integer'.format(i))",
        "'`bins[{}]` must be positive,"
    ],
    [
        "smin, smax = _get_outer_edges(sample[:, i], range[i])",
        "smin, smax = _get_outer_edges(sample[:, i],"
    ],
    [
        "\"`bins[{}]` must be an integer, when a scalar\".format(i)",
        "\"`bins[{}]` must be an integer, when a"
    ],
    [
        "'`bins[{}]` must be monotonically increasing, when an array'",
        "'`bins[{}]` must be monotonically"
    ],
    [
        "The arraypad module contains a group of functions to pad values onto the edges",
        "The arraypad module contains a group of functions"
    ],
    [
        "Rounds arr inplace if destination dtype is integer.",
        "Rounds arr inplace if destination"
    ],
    [
        "The dtype of the destination array.",
        "The dtype of the destination"
    ],
    [
        "Construct tuple of slices to slice an array in the given dimension.",
        "Construct tuple of slices to slice an array in"
    ],
    [
        "The slice for the given dimension.",
        "The slice for"
    ],
    [
        "The axis to which `sl` is applied. All other dimensions are left",
        "The axis to which `sl` is applied. All other dimensions are"
    ],
    [
        "A tuple with slices matching `shape` in length.",
        "A tuple with slices"
    ],
    [
        "return (slice(None),) * axis + (sl,) + (...,)",
        "return (slice(None),) * axis"
    ],
    [
        "Get a view of the current region of interest during iterative padding.",
        "Get a view of the current region of interest during iterative"
    ],
    [
        "When padding multiple dimensions iteratively corner values are",
        "When padding multiple dimensions"
    ],
    [
        "unnecessarily overwritten multiple times. This function reduces the",
        "unnecessarily overwritten multiple times. This"
    ],
    [
        "working area for the first dimensions so that corners are excluded.",
        "working area for the first dimensions so that"
    ],
    [
        "The array with the region of interest.",
        "The array with the region"
    ],
    [
        "Denotes the area with original values of the unpadded array.",
        "Denotes the area with original values"
    ],
    [
        "The currently padded dimension assuming that `axis` is padded before",
        "The currently padded dimension assuming that"
    ],
    [
        "The region of interest of the original `array`.",
        "The region of interest"
    ],
    [
        "sl = (slice(None),) * axis + original_area_slice[axis:]",
        "sl = (slice(None),) *"
    ],
    [
        "Pad array on all sides with either a single value or undefined values.",
        "Pad array on all sides with either a"
    ],
    [
        "pad_width : sequence of tuple[int, int]",
        "pad_width : sequence of"
    ],
    [
        "Pad width on both sides for each dimension in `arr`.",
        "Pad width on both sides for each dimension in"
    ],
    [
        "If provided the padded area is filled with this value, otherwise",
        "If provided the padded area is"
    ],
    [
        "The padded array with the same dtype as`array`. Its order will default",
        "The padded array with the same dtype"
    ],
    [
        "to C-style if `array` is not F-contiguous.",
        "to C-style if `array` is not"
    ],
    [
        "A tuple of slices pointing to the area of the original array.",
        "A tuple of slices pointing to"
    ],
    [
        "for size, (left, right) in zip(array.shape, pad_width)",
        "for size, (left, right) in zip(array.shape,"
    ],
    [
        "for size, (left, right) in zip(array.shape, pad_width)",
        "for size, (left, right)"
    ],
    [
        "Set empty-padded area in given dimension.",
        "Set empty-padded area"
    ],
    [
        "Array with the pad area which is modified inplace.",
        "Array with the pad area"
    ],
    [
        "Dimension with the pad area to set.",
        "Dimension with the pad"
    ],
    [
        "Pair of widths that mark the pad area on both sides in the given",
        "Pair of widths that mark the pad area on"
    ],
    [
        "value_pair : tuple of scalars or ndarrays",
        "value_pair : tuple of"
    ],
    [
        "Values inserted into the pad area on each side. It must match or be",
        "Values inserted into the pad area on each side. It must"
    ],
    [
        "broadcastable to the shape of `arr`.",
        "broadcastable to the shape of"
    ],
    [
        "Retrieve edge values from empty-padded array in given dimension.",
        "Retrieve edge values from empty-padded array in given"
    ],
    [
        "Dimension in which the edges are considered.",
        "Dimension in which the edges are"
    ],
    [
        "Pair of widths that mark the pad area on both sides in the given",
        "Pair of widths that mark the pad area on both sides"
    ],
    [
        "Edge values of the valid area in `padded` in the given dimension. Its",
        "Edge values of the valid area in `padded` in the given dimension."
    ],
    [
        "shape will always match `padded` except for the dimension given by",
        "shape will always match `padded` except for the"
    ],
    [
        "Construct linear ramps for empty-padded array in given dimension.",
        "Construct linear ramps for empty-padded array in given"
    ],
    [
        "Dimension in which the ramps are constructed.",
        "Dimension in which the ramps"
    ],
    [
        "Pair of widths that mark the pad area on both sides in the given",
        "Pair of widths that mark the pad area"
    ],
    [
        "End values for the linear ramps which form the edge of the fully padded",
        "End values for the linear ramps which form the edge of"
    ],
    [
        "array. These values are included in the linear ramps.",
        "array. These values are included in"
    ],
    [
        "Linear ramps to set on both sides of `padded`.",
        "Linear ramps to set on both"
    ],
    [
        "for end_value, edge, width in zip(",
        "for end_value, edge, width in"
    ],
    [
        "def _get_stats(padded, axis, width_pair, length_pair, stat_func):",
        "def _get_stats(padded, axis, width_pair,"
    ],
    [
        "Calculate statistic for the empty-padded array in given dimension.",
        "Calculate statistic for the empty-padded array in"
    ],
    [
        "Dimension in which the statistic is calculated.",
        "Dimension in which the statistic"
    ],
    [
        "Pair of widths that mark the pad area on both sides in the given",
        "Pair of widths that mark the pad area"
    ],
    [
        "Gives the number of values in valid area from each side that is",
        "Gives the number of values in valid area from each side"
    ],
    [
        "taken into account when calculating the statistic. If None the entire",
        "taken into account when calculating the"
    ],
    [
        "valid area in `padded` is considered.",
        "valid area in `padded` is"
    ],
    [
        "Function to compute statistic. The expected signature is",
        "Function to compute statistic. The expected"
    ],
    [
        "``stat_func(x: ndarray, axis: int, keepdims: bool) -> ndarray``.",
        "``stat_func(x: ndarray, axis: int, keepdims:"
    ],
    [
        "Calculated statistic for both sides of `padded`.",
        "Calculated statistic for both"
    ],
    [
        "if left_length is None or max_length < left_length:",
        "if left_length is None"
    ],
    [
        "if right_length is None or max_length < right_length:",
        "if right_length is None or"
    ],
    [
        "if left_length == right_length == max_length:",
        "if left_length =="
    ],
    [
        "Pad `axis` of `arr` with reflection.",
        "Pad `axis` of"
    ],
    [
        "Axis along which to pad `arr`.",
        "Axis along which"
    ],
    [
        "Pair of widths that mark the pad area on both sides in the given",
        "Pair of widths that mark the pad area on both sides in the"
    ],
    [
        "Controls method of reflection; options are 'even' or 'odd'.",
        "Controls method of reflection; options are 'even'"
    ],
    [
        "Original length of data on `axis` of `arr`.",
        "Original length of data on"
    ],
    [
        "If true, edge value is included in reflection, otherwise the edge",
        "If true, edge value is included"
    ],
    [
        "value forms the symmetric axis to the reflection.",
        "value forms the symmetric axis to the"
    ],
    [
        "New index positions of padding to do along the `axis`. If these are",
        "New index positions of padding to do along the `axis`."
    ],
    [
        "old_length = padded.shape[axis] - right_pad - left_pad",
        "old_length = padded.shape[axis] - right_pad -"
    ],
    [
        "old_length = old_length // original_period * original_period",
        "old_length = old_length // original_period *"
    ],
    [
        "Pad `axis` of `arr` with wrapped values.",
        "Pad `axis` of `arr` with wrapped"
    ],
    [
        "Axis along which to pad `arr`.",
        "Axis along which to pad"
    ],
    [
        "Pair of widths that mark the pad area on both sides in the given",
        "Pair of widths that mark the pad area on both"
    ],
    [
        "Original length of data on `axis` of `arr`.",
        "Original length of data on"
    ],
    [
        "New index positions of padding to do along the `axis`. If these are",
        "New index positions of padding to do along the `axis`."
    ],
    [
        "period = padded.shape[axis] - right_pad - left_pad",
        "period = padded.shape[axis] -"
    ],
    [
        "period = period // original_period * original_period",
        "period = period //"
    ],
    [
        "slice_start = slice_end - min(period, left_pad)",
        "slice_start = slice_end"
    ],
    [
        "pad_area = _slice_at_axis(slice(left_pad - period, left_pad), axis)",
        "pad_area = _slice_at_axis(slice(left_pad -"
    ],
    [
        "slice_end = slice_start + min(period, right_pad)",
        "slice_end = slice_start + min(period,"
    ],
    [
        "A helper function for `pad` that prepares and validates arguments like",
        "A helper function for `pad` that"
    ],
    [
        "Number of pairs the broadcasted `x` will have.",
        "Number of pairs the broadcasted `x`"
    ],
    [
        "If `x` is not None, try to round each element of `x` to an integer",
        "If `x` is not None, try to round each element of `x` to"
    ],
    [
        "(dtype `np.intp`) and ensure every element is positive.",
        "(dtype `np.intp`) and ensure every element is"
    ],
    [
        "If `as_index` is True and `x` contains negative elements.",
        "If `as_index` is True and"
    ],
    [
        "raise ValueError(\"index can't contain negative values\")",
        "raise ValueError(\"index can't contain"
    ],
    [
        "raise ValueError(\"index can't contain negative values\")",
        "raise ValueError(\"index can't contain negative"
    ],
    [
        "raise ValueError(\"index can't contain negative values\")",
        "raise ValueError(\"index can't"
    ],
    [
        "array : array_like of rank N",
        "array : array_like of rank"
    ],
    [
        "Number of values padded to the edges of each axis.",
        "Number of values padded to the"
    ],
    [
        "``(before, after)`` or ``((before, after),)`` yields same before",
        "``(before, after)`` or ``((before, after),)`` yields"
    ],
    [
        "and after pad for each axis.",
        "and after pad"
    ],
    [
        "``(pad,)`` or ``int`` is a shortcut for before = after = pad width",
        "``(pad,)`` or ``int`` is a shortcut for before = after"
    ],
    [
        "mode : str or function, optional",
        "mode : str or function,"
    ],
    [
        "One of the following string values or a user supplied function.",
        "One of the following string values or a user"
    ],
    [
        "Pads with the edge values of array.",
        "Pads with the edge values"
    ],
    [
        "Pads with the linear ramp between end_value and the",
        "Pads with the linear ramp between end_value"
    ],
    [
        "Pads with the maximum value of all or part of the",
        "Pads with the maximum value of all or part of"
    ],
    [
        "Pads with the mean value of all or part of the",
        "Pads with the mean value of"
    ],
    [
        "Pads with the median value of all or part of the",
        "Pads with the median value of all or part"
    ],
    [
        "Pads with the minimum value of all or part of the",
        "Pads with the minimum value of all"
    ],
    [
        "Pads with the reflection of the vector mirrored on",
        "Pads with the reflection of the vector"
    ],
    [
        "the first and last values of the vector along each",
        "the first and last values of the"
    ],
    [
        "Pads with the reflection of the vector mirrored",
        "Pads with the reflection of the"
    ],
    [
        "along the edge of the array.",
        "along the edge of the"
    ],
    [
        "Pads with the wrap of the vector along the axis.",
        "Pads with the wrap of the vector"
    ],
    [
        "The first values are used to pad the end and the",
        "The first values are used to"
    ],
    [
        "end values are used to pad the beginning.",
        "end values are used to pad"
    ],
    [
        "stat_length : sequence or int, optional",
        "stat_length : sequence or"
    ],
    [
        "Used in 'maximum', 'mean', 'median', and 'minimum'.  Number of",
        "Used in 'maximum', 'mean', 'median', and 'minimum'. Number"
    ],
    [
        "values at edge of each axis used to calculate the statistic value.",
        "values at edge of each axis used to calculate"
    ],
    [
        "``(before, after)`` or ``((before, after),)`` yields same before",
        "``(before, after)`` or ``((before, after),)`` yields"
    ],
    [
        "and after statistic lengths for each axis.",
        "and after statistic lengths"
    ],
    [
        "``(stat_length,)`` or ``int`` is a shortcut for",
        "``(stat_length,)`` or ``int`` is a shortcut"
    ],
    [
        "``before = after = statistic`` length for all axes.",
        "``before = after = statistic``"
    ],
    [
        "Default is ``None``, to use the entire axis.",
        "Default is ``None``, to"
    ],
    [
        "constant_values : sequence or scalar, optional",
        "constant_values : sequence or"
    ],
    [
        "Used in 'constant'.  The values to set the padded values for each",
        "Used in 'constant'. The values to set the padded values"
    ],
    [
        "``(before, after)`` or ``((before, after),)`` yields same before",
        "``(before, after)`` or ``((before, after),)`` yields"
    ],
    [
        "and after constants for each axis.",
        "and after constants"
    ],
    [
        "``(constant,)`` or ``constant`` is a shortcut for",
        "``(constant,)`` or ``constant`` is a"
    ],
    [
        "``before = after = constant`` for all axes.",
        "``before = after = constant``"
    ],
    [
        "end_values : sequence or scalar, optional",
        "end_values : sequence or"
    ],
    [
        "Used in 'linear_ramp'.  The values used for the ending value of the",
        "Used in 'linear_ramp'. The values used for"
    ],
    [
        "linear_ramp and that will form the edge of the padded array.",
        "linear_ramp and that will form the"
    ],
    [
        "``(before, after)`` or ``((before, after),)`` yields same before",
        "``(before, after)`` or ``((before, after),)`` yields same"
    ],
    [
        "and after end values for each axis.",
        "and after end values for each"
    ],
    [
        "``(constant,)`` or ``constant`` is a shortcut for",
        "``(constant,)`` or ``constant`` is a shortcut"
    ],
    [
        "``before = after = constant`` for all axes.",
        "``before = after = constant`` for"
    ],
    [
        "Used in 'reflect', and 'symmetric'.  The 'even' style is the",
        "Used in 'reflect', and 'symmetric'. The 'even' style is"
    ],
    [
        "default with an unaltered reflection around the edge value.  For",
        "default with an unaltered reflection around the edge"
    ],
    [
        "the 'odd' style, the extended part of the array is created by",
        "the 'odd' style, the extended part of"
    ],
    [
        "subtracting the reflected values from two times the edge value.",
        "subtracting the reflected values from"
    ],
    [
        "Padded array of rank equal to `array` with shape increased",
        "Padded array of rank equal"
    ],
    [
        "axes is calculated from padding of previous axes.  This is easiest to",
        "axes is calculated from padding of previous axes. This is"
    ],
    [
        "are calculated by using padded values from the first axis.",
        "are calculated by using padded"
    ],
    [
        "values padded at the beginning of vector where",
        "values padded at the beginning of"
    ],
    [
        "Any keyword arguments the function requires.",
        "Any keyword arguments"
    ],
    [
        ">>> def pad_with(vector, pad_width, iaxis, kwargs):",
        ">>> def pad_with(vector, pad_width,"
    ],
    [
        "raise TypeError('`pad_width` must be of integral type.')",
        "raise TypeError('`pad_width` must be of"
    ],
    [
        "inds = (ind + (Ellipsis,) for ind in inds)",
        "inds = (ind + (Ellipsis,) for ind in"
    ],
    [
        "'empty': [], 'edge': [], 'wrap': [],",
        "'empty': [], 'edge':"
    ],
    [
        "raise ValueError(\"mode '{}' is not supported\".format(mode)) from None",
        "raise ValueError(\"mode '{}' is"
    ],
    [
        "raise ValueError(\"unsupported keyword arguments for mode '{}': {}\"",
        "raise ValueError(\"unsupported keyword arguments for mode '{}':"
    ],
    [
        "stat_functions = {\"maximum\": np.amax, \"minimum\": np.amin,",
        "stat_functions = {\"maximum\": np.amax, \"minimum\":"
    ],
    [
        "for axis, width_pair, value_pair in zip(axes, pad_width, values):",
        "for axis, width_pair, value_pair in zip(axes, pad_width,"
    ],
    [
        "for axis, width_pair in zip(axes, pad_width):",
        "for axis, width_pair in zip(axes,"
    ],
    [
        "\"can't extend empty axis {} using modes other than \"",
        "\"can't extend empty axis {}"
    ],
    [
        "for axis, width_pair in zip(axes, pad_width):",
        "for axis, width_pair in"
    ],
    [
        "for axis, width_pair, value_pair in zip(axes, pad_width, end_values):",
        "for axis, width_pair, value_pair in zip(axes,"
    ],
    [
        "ramp_pair = _get_linear_ramps(roi, axis, width_pair, value_pair)",
        "ramp_pair = _get_linear_ramps(roi,"
    ],
    [
        "for axis, width_pair, length_pair in zip(axes, pad_width, length):",
        "for axis, width_pair, length_pair in"
    ],
    [
        "stat_pair = _get_stats(roi, axis, width_pair, length_pair, func)",
        "stat_pair = _get_stats(roi, axis, width_pair, length_pair,"
    ],
    [
        "for axis, (left_index, right_index) in zip(axes, pad_width):",
        "for axis, (left_index, right_index)"
    ],
    [
        "edge_pair = _get_edges(padded, axis, (left_index, right_index))",
        "edge_pair = _get_edges(padded, axis,"
    ],
    [
        "for axis, (left_index, right_index) in zip(axes, pad_width):",
        "for axis, (left_index, right_index) in"
    ],
    [
        "original_period = padded.shape[axis] - right_index - left_index",
        "original_period = padded.shape[axis] - right_index -"
    ],
    [
        "Module of functions that are like ufuncs in acting on arrays and optionally",
        "Module of functions that are like ufuncs in"
    ],
    [
        "storing results in an output array.",
        "storing results in an output"
    ],
    [
        "Round to nearest integer towards zero.",
        "Round to nearest integer towards"
    ],
    [
        "Round an array of floats element-wise to nearest integer towards zero.",
        "Round an array of floats element-wise"
    ],
    [
        "The rounded values have the same data-type as the input.",
        "The rounded values have the"
    ],
    [
        "A location into which the result is stored. If provided, it must have",
        "A location into which the result is stored."
    ],
    [
        "a shape that the input broadcasts to. If not provided or None, a",
        "a shape that the input broadcasts to. If"
    ],
    [
        "An array with the same dimensions and data-type as the input.",
        "An array with the same dimensions and data-type as the"
    ],
    [
        "If second argument is not supplied then a new array is returned",
        "If second argument is not supplied then"
    ],
    [
        "If a second argument is supplied the result is stored there.",
        "If a second argument is supplied the"
    ],
    [
        "The return value ``out`` is then a reference to that array.",
        "The return value ``out`` is then"
    ],
    [
        "around : Round to given number of decimals",
        "around : Round to given number"
    ],
    [
        "if out is None and type(res) is nx.ndarray:",
        "if out is None and"
    ],
    [
        "Test element-wise for positive infinity, return result as bool array.",
        "Test element-wise for positive infinity, return result as bool"
    ],
    [
        "A location into which the result is stored. If provided, it must have a",
        "A location into which the result is stored. If provided, it must"
    ],
    [
        "shape that the input broadcasts to. If not provided or None, a",
        "shape that the input broadcasts to."
    ],
    [
        "A boolean array with the same dimensions as the input.",
        "A boolean array with the same dimensions as the"
    ],
    [
        "If second argument is not supplied then a boolean array is returned",
        "If second argument is not supplied then a boolean"
    ],
    [
        "with values True where the corresponding element of the input is",
        "with values True where the corresponding element of the"
    ],
    [
        "positive infinity and values False where the element of the input is",
        "positive infinity and values False where the"
    ],
    [
        "If a second argument is supplied the result is stored there. If the",
        "If a second argument is supplied the result is"
    ],
    [
        "type of that array is a numeric type the result is represented as zeros",
        "type of that array is a numeric"
    ],
    [
        "and ones, if the type is boolean then as False and True.",
        "and ones, if the type is boolean then"
    ],
    [
        "The return value `out` is then a reference to that array.",
        "The return value `out` is then a"
    ],
    [
        "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic",
        "NumPy uses the IEEE Standard for"
    ],
    [
        "Errors result if the second argument is also supplied when x is a scalar",
        "Errors result if the second argument is also supplied when x"
    ],
    [
        "input, if first and second arguments have different shapes, or if the",
        "input, if first and second arguments"
    ],
    [
        "raise TypeError(f'This operation is not supported for {dtype} values '",
        "raise TypeError(f'This operation is not supported for {dtype} values"
    ],
    [
        "'because it would be ambiguous.') from e",
        "'because it would be"
    ],
    [
        "Test element-wise for negative infinity, return result as bool array.",
        "Test element-wise for negative infinity, return result as bool"
    ],
    [
        "A location into which the result is stored. If provided, it must have a",
        "A location into which the result is"
    ],
    [
        "shape that the input broadcasts to. If not provided or None, a",
        "shape that the input broadcasts to. If not provided or"
    ],
    [
        "A boolean array with the same dimensions as the input.",
        "A boolean array with the same dimensions as"
    ],
    [
        "If second argument is not supplied then a numpy boolean array is",
        "If second argument is not supplied then a numpy boolean array"
    ],
    [
        "returned with values True where the corresponding element of the",
        "returned with values True where the corresponding element"
    ],
    [
        "input is negative infinity and values False where the element of",
        "input is negative infinity and values False where the"
    ],
    [
        "the input is not negative infinity.",
        "the input is"
    ],
    [
        "If a second argument is supplied the result is stored there. If the",
        "If a second argument is supplied the result is stored there."
    ],
    [
        "type of that array is a numeric type the result is represented as",
        "type of that array is a numeric type the"
    ],
    [
        "zeros and ones, if the type is boolean then as False and True. The",
        "zeros and ones, if the type is"
    ],
    [
        "return value `out` is then a reference to that array.",
        "return value `out` is then a reference to that"
    ],
    [
        "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic",
        "NumPy uses the IEEE Standard for Binary Floating-Point"
    ],
    [
        "Errors result if the second argument is also supplied when x is a scalar",
        "Errors result if the second argument is also supplied when x is a"
    ],
    [
        "input, if first and second arguments have different shapes, or if the",
        "input, if first and second arguments"
    ],
    [
        "raise TypeError(f'This operation is not supported for {dtype} values '",
        "raise TypeError(f'This operation is not supported for {dtype} values"
    ],
    [
        "'because it would be ambiguous.') from e",
        "'because it would be"
    ],
    [
        "'savetxt', 'loadtxt', 'genfromtxt', 'load', 'save', 'savez',",
        "'savetxt', 'loadtxt', 'genfromtxt', 'load',"
    ],
    [
        "Convert attribute look-ups to getitems on the object passed in.",
        "Convert attribute look-ups to getitems on"
    ],
    [
        "Object on which attribute look-up is performed.",
        "Object on which attribute"
    ],
    [
        ">>> from numpy.lib._npyio_impl import BagObj as BO",
        ">>> from numpy.lib._npyio_impl import BagObj"
    ],
    [
        "...         result = \"Doesn't matter what you want, \"",
        "... result = \"Doesn't matter what"
    ],
    [
        "...         return result + \"you're gonna get this\"",
        "... return result +"
    ],
    [
        "\"Doesn't matter what you want, you're gonna get this\"",
        "\"Doesn't matter what you want,"
    ],
    [
        "\"Doesn't matter what you want, you're gonna get this\"",
        "\"Doesn't matter what you want, you're gonna"
    ],
    [
        "Enables dir(bagobj) to list the files in an NpzFile.",
        "Enables dir(bagobj) to list the"
    ],
    [
        "This also enables tab-completion in an interpreter or IPython.",
        "This also enables tab-completion in an interpreter"
    ],
    [
        "pathlib.Path objects. `args` and `kwargs` are passed to the zipfile.ZipFile",
        "pathlib.Path objects. `args` and `kwargs` are passed"
    ],
    [
        "A dictionary-like object with lazy-loading of files in the zipped",
        "A dictionary-like object with lazy-loading"
    ],
    [
        "`NpzFile` is used to load files in the NumPy ``.npz`` data archive",
        "`NpzFile` is used to load files in the"
    ],
    [
        "format. It assumes that files in the archive have a ``.npy`` extension,",
        "format. It assumes that files in the archive have a"
    ],
    [
        "The arrays and file strings are lazily loaded on either",
        "The arrays and file strings are lazily loaded on"
    ],
    [
        "getitem access using ``obj['key']`` or attribute lookup using",
        "getitem access using ``obj['key']`` or attribute lookup"
    ],
    [
        "``obj.f.key``. A list of all files (without ``.npy`` extensions) can",
        "``obj.f.key``. A list of all files"
    ],
    [
        "be obtained with ``obj.files`` and the ZipFile object itself using",
        "be obtained with ``obj.files`` and"
    ],
    [
        "List of all files in the archive with a ``.npy`` extension.",
        "List of all files in the archive with a"
    ],
    [
        "The ZipFile object initialized with the zipped archive.",
        "The ZipFile object initialized with the"
    ],
    [
        "An object on which attribute can be performed as an alternative",
        "An object on which attribute can be performed"
    ],
    [
        "to getitem access on the `NpzFile` instance itself.",
        "to getitem access on the `NpzFile`"
    ],
    [
        "Allow loading pickled data. Default: False",
        "Allow loading pickled data."
    ],
    [
        "Additional keyword arguments to pass on to pickle.load.",
        "Additional keyword arguments to pass on to"
    ],
    [
        "These are only useful when loading object arrays saved on",
        "These are only useful when"
    ],
    [
        "Maximum allowed size of the header.  Large headers may not be safe",
        "Maximum allowed size of the header. Large headers may not be"
    ],
    [
        "to load securely and thus require explicitly passing a larger value.",
        "to load securely and thus require"
    ],
    [
        "This option is ignored when `allow_pickle` is passed.  In that case",
        "This option is ignored when `allow_pickle` is"
    ],
    [
        "the file is by definition trusted and the limit is unnecessary.",
        "the file is by definition trusted and"
    ],
    [
        "fid : file, str, or pathlib.Path",
        "fid : file, str, or"
    ],
    [
        "The zipped archive to open. This is either a file-like object",
        "The zipped archive to open. This is either"
    ],
    [
        "or a string containing the path to the archive.",
        "or a string containing the path to"
    ],
    [
        "Whether NpzFile should close the file handle.",
        "Whether NpzFile should close the"
    ],
    [
        "Requires that `fid` is a file-like object.",
        "Requires that `fid` is a file-like"
    ],
    [
        "NpzFile 'object' with keys: x, y",
        "NpzFile 'object' with"
    ],
    [
        "raise KeyError(f\"{key} is not a file in the archive\")",
        "raise KeyError(f\"{key} is not a"
    ],
    [
        "return (key in self._files or key in self.files)",
        "return (key in self._files"
    ],
    [
        "return f\"NpzFile {filename!r} with keys: {array_names}\"",
        "return f\"NpzFile {filename!r}"
    ],
    [
        "D.get(k,[,d]) returns D[k] if k in D, else d.  d defaults to None.",
        "D.get(k,[,d]) returns D[k] if k in D,"
    ],
    [
        "D.items() returns a set-like object providing a view on the items",
        "D.items() returns a set-like object providing a view"
    ],
    [
        "D.keys() returns a set-like object providing a view on the keys",
        "D.keys() returns a set-like object providing"
    ],
    [
        "D.values() returns a set-like object providing a view on the values",
        "D.values() returns a set-like object providing a view on"
    ],
    [
        "Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.",
        "Load arrays or pickled objects from ``.npy``, ``.npz``"
    ],
    [
        ".. warning:: Loading files that contain object arrays uses the ``pickle``",
        ".. warning:: Loading files that contain object arrays"
    ],
    [
        "module, which is not secure against erroneous or maliciously",
        "module, which is not secure against erroneous or"
    ],
    [
        "constructed data. Consider passing ``allow_pickle=False`` to",
        "constructed data. Consider passing ``allow_pickle=False``"
    ],
    [
        "load data that is known not to contain object arrays for the",
        "load data that is known not"
    ],
    [
        "file : file-like object, string, or pathlib.Path",
        "file : file-like object, string, or"
    ],
    [
        "The file to read. File-like objects must support the",
        "The file to read. File-like objects"
    ],
    [
        "``seek()`` and ``read()`` methods and must always",
        "``seek()`` and ``read()`` methods"
    ],
    [
        "be opened in binary mode.  Pickled files require that the",
        "be opened in binary mode. Pickled files"
    ],
    [
        "file-like object support the ``readline()`` method as well.",
        "file-like object support the ``readline()`` method as"
    ],
    [
        "mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional",
        "mmap_mode : {None, 'r+', 'r', 'w+', 'c'},"
    ],
    [
        "If not None, then memory-map the file, using the given mode (see",
        "If not None, then memory-map the file,"
    ],
    [
        "`numpy.memmap` for a detailed description of the modes).  A",
        "`numpy.memmap` for a detailed description"
    ],
    [
        "memory-mapped array is kept on disk. However, it can be accessed",
        "memory-mapped array is kept on disk. However, it"
    ],
    [
        "and sliced like any ndarray.  Memory mapping is especially useful",
        "and sliced like any ndarray. Memory mapping is"
    ],
    [
        "for accessing small fragments of large files without reading the",
        "for accessing small fragments of large files"
    ],
    [
        "Allow loading pickled object arrays stored in npy files. Reasons for",
        "Allow loading pickled object arrays stored in npy"
    ],
    [
        "disallowing pickles include security, as loading pickled data can",
        "disallowing pickles include security, as"
    ],
    [
        "execute arbitrary code. If pickles are disallowed, loading object",
        "execute arbitrary code. If pickles are disallowed,"
    ],
    [
        "which includes npy/npz files containing object arrays. If `fix_imports`",
        "which includes npy/npz files containing object"
    ],
    [
        "'ASCII', and 'bytes' are not allowed, as they can corrupt numerical",
        "'ASCII', and 'bytes' are not allowed, as they can corrupt"
    ],
    [
        "Maximum allowed size of the header.  Large headers may not be safe",
        "Maximum allowed size of the header. Large headers may"
    ],
    [
        "to load securely and thus require explicitly passing a larger value.",
        "to load securely and thus require explicitly"
    ],
    [
        "This option is ignored when `allow_pickle` is passed.  In that case",
        "This option is ignored when `allow_pickle` is"
    ],
    [
        "the file is by definition trusted and the limit is unnecessary.",
        "the file is by definition trusted and the limit"
    ],
    [
        "result : array, tuple, dict, etc.",
        "result : array,"
    ],
    [
        "Data stored in the file. For ``.npz`` files, the returned instance",
        "Data stored in the file. For ``.npz`` files,"
    ],
    [
        "of NpzFile class must be closed to avoid leaking file descriptors.",
        "of NpzFile class must be closed"
    ],
    [
        "If the input file does not exist or cannot be read.",
        "If the input file does not exist or cannot be"
    ],
    [
        "If ``allow_pickle=True``, but the file cannot be loaded as a pickle.",
        "If ``allow_pickle=True``, but the file cannot be loaded as"
    ],
    [
        "The file contains an object array, but ``allow_pickle=False`` given.",
        "The file contains an object array, but ``allow_pickle=False``"
    ],
    [
        "When calling ``np.load`` multiple times on the same file handle,",
        "When calling ``np.load`` multiple times"
    ],
    [
        "if all data has already been read",
        "if all data has already"
    ],
    [
        "memmap : Create a memory-map to an array stored in a file on disk.",
        "memmap : Create a memory-map to an array stored in a"
    ],
    [
        "lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.",
        "lib.format.open_memmap : Create or load a"
    ],
    [
        "- If the file contains pickle data, then whatever object is stored",
        "- If the file contains pickle"
    ],
    [
        "- If the file is a ``.npy`` file, then a single array is returned.",
        "- If the file is a ``.npy`` file, then a single array is"
    ],
    [
        "- If the file is a ``.npz`` file, then a dictionary-like object is",
        "- If the file is a ``.npz`` file, then a dictionary-like"
    ],
    [
        "returned, containing ``{filename: array}`` key-value pairs, one for",
        "returned, containing ``{filename: array}`` key-value pairs, one"
    ],
    [
        "- If the file is a ``.npz`` file, the returned value supports the",
        "- If the file is a ``.npz`` file, the returned"
    ],
    [
        "context manager protocol in a similar fashion to the open function::",
        "context manager protocol in a similar"
    ],
    [
        "The underlying file descriptor is closed when exiting the 'with'",
        "The underlying file descriptor is closed when"
    ],
    [
        "Store data to disk, and load it again:",
        "Store data to disk,"
    ],
    [
        "Store compressed data to disk, and load it again:",
        "Store compressed data to disk, and load it"
    ],
    [
        "Mem-map the stored array, and then access the second row",
        "Mem-map the stored array, and"
    ],
    [
        "pickle_kwargs = {'encoding': encoding, 'fix_imports': fix_imports}",
        "pickle_kwargs = {'encoding': encoding, 'fix_imports':"
    ],
    [
        "raise EOFError(\"No data left in file\")",
        "raise EOFError(\"No data"
    ],
    [
        "\"This file contains pickled (object) data. If you trust \"",
        "\"This file contains pickled (object) data. If you trust"
    ],
    [
        "\"the file you can load it unsafely using the \"",
        "\"the file you can load"
    ],
    [
        "f\"Failed to interpret file {file!r} as a pickle\") from e",
        "f\"Failed to interpret file {file!r} as a"
    ],
    [
        "Save an array to a binary file in NumPy ``.npy`` format.",
        "Save an array to a binary file in NumPy ``.npy``"
    ],
    [
        "file : file, str, or pathlib.Path",
        "file : file, str,"
    ],
    [
        "File or filename to which the data is saved. If file is a file-object,",
        "File or filename to which the data is saved. If file"
    ],
    [
        "then the filename is unchanged.  If file is a string or Path,",
        "then the filename is unchanged. If"
    ],
    [
        "a ``.npy`` extension will be appended to the filename if it does not",
        "a ``.npy`` extension will be appended to"
    ],
    [
        "Allow saving object arrays using Python pickles. Reasons for",
        "Allow saving object arrays using Python pickles. Reasons"
    ],
    [
        "disallowing pickles include security (loading pickled data can execute",
        "disallowing pickles include security (loading pickled data"
    ],
    [
        "arbitrary code) and portability (pickled objects may not be loadable",
        "arbitrary code) and portability (pickled objects may not"
    ],
    [
        "on different Python installations, for example if the stored objects",
        "on different Python installations, for example"
    ],
    [
        "require libraries that are not available, and not all pickled data is",
        "require libraries that are not available, and not all pickled data"
    ],
    [
        "compatible between different versions of Python).",
        "compatible between different versions"
    ],
    [
        "The `fix_imports` flag is deprecated and has no effect.",
        "The `fix_imports` flag is deprecated and has"
    ],
    [
        "savez : Save several arrays into a ``.npz`` archive",
        "savez : Save several arrays into"
    ],
    [
        "For a description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.",
        "For a description of the"
    ],
    [
        "Any data saved to the file is appended to the end of the file.",
        "Any data saved to the file is appended to the end of"
    ],
    [
        ">>> with open('test.npy', 'wb') as f:",
        ">>> with open('test.npy', 'wb') as"
    ],
    [
        ">>> with open('test.npy', 'rb') as f:",
        ">>> with open('test.npy', 'rb')"
    ],
    [
        "\"The 'fix_imports' flag is deprecated and has no effect. \"",
        "\"The 'fix_imports' flag is deprecated and has no"
    ],
    [
        "\"\"\"Save several arrays into a single file in uncompressed ``.npz`` format.",
        "\"\"\"Save several arrays into a single file"
    ],
    [
        "Provide arrays as keyword arguments to store them under the",
        "Provide arrays as keyword arguments to store"
    ],
    [
        "corresponding name in the output file: ``savez(fn, x=x, y=y)``.",
        "corresponding name in the output"
    ],
    [
        "If arrays are specified as positional arguments, i.e., ``savez(fn,",
        "If arrays are specified as positional"
    ],
    [
        "file : file, str, or pathlib.Path",
        "file : file,"
    ],
    [
        "Either the filename (string) or an open file (file-like object)",
        "Either the filename (string) or an open file"
    ],
    [
        "where the data will be saved. If file is a string or a Path, the",
        "where the data will be saved. If file is a string"
    ],
    [
        "``.npz`` extension will be appended to the filename if it is not",
        "``.npz`` extension will be appended to the filename if it is"
    ],
    [
        "Arrays to save to the file. Please use keyword arguments (see",
        "Arrays to save to the file. Please use keyword arguments"
    ],
    [
        "`kwds` below) to assign names to arrays.  Arrays specified as",
        "`kwds` below) to assign names to"
    ],
    [
        "Allow saving object arrays using Python pickles. Reasons for",
        "Allow saving object arrays using Python"
    ],
    [
        "disallowing pickles include security (loading pickled data can execute",
        "disallowing pickles include security (loading pickled"
    ],
    [
        "arbitrary code) and portability (pickled objects may not be loadable",
        "arbitrary code) and portability (pickled objects may"
    ],
    [
        "on different Python installations, for example if the stored objects",
        "on different Python installations, for"
    ],
    [
        "require libraries that are not available, and not all pickled data is",
        "require libraries that are not available, and not all pickled data"
    ],
    [
        "compatible between different versions of Python).",
        "compatible between different versions"
    ],
    [
        "Arrays to save to the file. Each array will be saved to the",
        "Arrays to save to the file. Each array will be saved"
    ],
    [
        "output file with its corresponding keyword name.",
        "output file with its corresponding"
    ],
    [
        "save : Save a single array to a binary file in NumPy format.",
        "save : Save a single array to a binary file in"
    ],
    [
        "savetxt : Save an array to a file as plain text.",
        "savetxt : Save an array to a file as"
    ],
    [
        "savez_compressed : Save several arrays into a compressed ``.npz`` archive",
        "savez_compressed : Save several arrays"
    ],
    [
        "The ``.npz`` file format is a zipped archive of files named after the",
        "The ``.npz`` file format is a zipped archive of files named"
    ],
    [
        "variables they contain.  The archive is not compressed and each file",
        "variables they contain. The archive is not"
    ],
    [
        "in the archive contains one variable in ``.npy`` format. For a",
        "in the archive contains one variable in ``.npy`` format."
    ],
    [
        "description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.",
        "description of the ``.npy`` format, see"
    ],
    [
        "When opening the saved ``.npz`` file with `load` a `~lib.npyio.NpzFile`",
        "When opening the saved ``.npz`` file with"
    ],
    [
        "object is returned. This is a dictionary-like object which can be queried",
        "object is returned. This is a dictionary-like object which can"
    ],
    [
        "for its list of arrays (with the ``.files`` attribute), and for the arrays",
        "for its list of arrays (with the ``.files`` attribute), and for the"
    ],
    [
        "Keys passed in `kwds` are used as filenames inside the ZIP archive.",
        "Keys passed in `kwds` are used as filenames"
    ],
    [
        "Therefore, keys should be valid filenames; e.g., avoid keys that begin with",
        "Therefore, keys should be valid filenames; e.g., avoid keys that"
    ],
    [
        "When naming variables with keyword arguments, it is not possible to name a",
        "When naming variables with keyword arguments, it is not possible to"
    ],
    [
        "variable ``file``, as this would cause the ``file`` argument to be defined",
        "variable ``file``, as this would cause"
    ],
    [
        "twice in the call to ``savez``.",
        "twice in the"
    ],
    [
        "Using `savez` with \\\\*args, the arrays are saved with default names.",
        "Using `savez` with \\\\*args, the arrays"
    ],
    [
        "Using `savez` with \\\\**kwds, the arrays are saved with the keyword names.",
        "Using `savez` with \\\\**kwds, the arrays are saved with the keyword"
    ],
    [
        "Save several arrays into a single file in compressed ``.npz`` format.",
        "Save several arrays into a single file in"
    ],
    [
        "Provide arrays as keyword arguments to store them under the",
        "Provide arrays as keyword arguments to store them"
    ],
    [
        "corresponding name in the output file: ``savez_compressed(fn, x=x, y=y)``.",
        "corresponding name in the output file: ``savez_compressed(fn,"
    ],
    [
        "If arrays are specified as positional arguments, i.e.,",
        "If arrays are specified as positional arguments,"
    ],
    [
        "file : file, str, or pathlib.Path",
        "file : file, str, or"
    ],
    [
        "Either the filename (string) or an open file (file-like object)",
        "Either the filename (string) or an"
    ],
    [
        "where the data will be saved. If file is a string or a Path, the",
        "where the data will be saved. If file is a string"
    ],
    [
        "``.npz`` extension will be appended to the filename if it is not",
        "``.npz`` extension will be appended to"
    ],
    [
        "Arrays to save to the file. Please use keyword arguments (see",
        "Arrays to save to the file. Please"
    ],
    [
        "`kwds` below) to assign names to arrays.  Arrays specified as",
        "`kwds` below) to assign names to arrays. Arrays specified"
    ],
    [
        "Allow saving object arrays using Python pickles. Reasons for",
        "Allow saving object arrays using"
    ],
    [
        "disallowing pickles include security (loading pickled data can execute",
        "disallowing pickles include security (loading pickled data can"
    ],
    [
        "arbitrary code) and portability (pickled objects may not be loadable",
        "arbitrary code) and portability (pickled objects may not be"
    ],
    [
        "on different Python installations, for example if the stored objects",
        "on different Python installations, for example if"
    ],
    [
        "require libraries that are not available, and not all pickled data is",
        "require libraries that are not available,"
    ],
    [
        "compatible between different versions of Python).",
        "compatible between different"
    ],
    [
        "Arrays to save to the file. Each array will be saved to the",
        "Arrays to save to the file. Each array will be saved"
    ],
    [
        "output file with its corresponding keyword name.",
        "output file with its"
    ],
    [
        "numpy.save : Save a single array to a binary file in NumPy format.",
        "numpy.save : Save a single array to a binary file in"
    ],
    [
        "numpy.savetxt : Save an array to a file as plain text.",
        "numpy.savetxt : Save an array to a file"
    ],
    [
        "numpy.savez : Save several arrays into an uncompressed ``.npz`` file format",
        "numpy.savez : Save several arrays into"
    ],
    [
        "numpy.load : Load the files created by savez_compressed.",
        "numpy.load : Load the files created by"
    ],
    [
        "The ``.npz`` file format is a zipped archive of files named after the",
        "The ``.npz`` file format is a zipped archive"
    ],
    [
        "variables they contain.  The archive is compressed with",
        "variables they contain. The archive"
    ],
    [
        "``zipfile.ZIP_DEFLATED`` and each file in the archive contains one variable",
        "``zipfile.ZIP_DEFLATED`` and each file in the archive contains one"
    ],
    [
        "in ``.npy`` format. For a description of the ``.npy`` format, see",
        "in ``.npy`` format. For a description of"
    ],
    [
        "When opening the saved ``.npz`` file with `load` a `~lib.npyio.NpzFile`",
        "When opening the saved ``.npz`` file"
    ],
    [
        "object is returned. This is a dictionary-like object which can be queried",
        "object is returned. This is a dictionary-like object"
    ],
    [
        "for its list of arrays (with the ``.files`` attribute), and for the arrays",
        "for its list of arrays (with the ``.files``"
    ],
    [
        "def _savez(file, args, kwds, compress, allow_pickle=True, pickle_kwargs=None):",
        "def _savez(file, args, kwds, compress, allow_pickle=True,"
    ],
    [
        "\"Cannot use un-named variables and keyword %s\" % key)",
        "\"Cannot use un-named variables and keyword"
    ],
    [
        "\"\"\"Just checks if the param ndmin is supported on",
        "\"\"\"Just checks if the param"
    ],
    [
        "_ensure_ndmin_ndarray. It is intended to be used as",
        "_ensure_ndmin_ndarray. It is intended to"
    ],
    [
        "raise ValueError(f\"Illegal value of ndmin keyword: {ndmin}\")",
        "raise ValueError(f\"Illegal value of"
    ],
    [
        "\"\"\"This is a helper function of loadtxt and genfromtxt to ensure",
        "\"\"\"This is a helper function of loadtxt and genfromtxt"
    ],
    [
        "^^ whenever this changes, keep in sync with",
        "^^ whenever this changes,"
    ],
    [
        "raise TypeError(f\"{name} must be an integer\") from None",
        "raise TypeError(f\"{name} must be an"
    ],
    [
        "Generator that consumes a line iterated iterable and strips out the",
        "Generator that consumes a line iterated iterable and strips out"
    ],
    [
        "multiple (or multi-character) comments from lines.",
        "multiple (or multi-character)"
    ],
    [
        "This is a pre-processing step to achieve feature parity with loadtxt",
        "This is a pre-processing step to achieve feature parity with"
    ],
    [
        "(we assume that this feature is a nieche feature).",
        "(we assume that this feature is a"
    ],
    [
        "Read a NumPy array from a text file.",
        "Read a NumPy array from"
    ],
    [
        "This is a helper function for loadtxt.",
        "This is a helper"
    ],
    [
        "fname : file, str, or pathlib.Path",
        "fname : file,"
    ],
    [
        "The filename or the file to be read.",
        "The filename or the file to be"
    ],
    [
        "Field delimiter of the fields in line of the file.",
        "Field delimiter of the fields in"
    ],
    [
        "Default is a comma, ','.  If None any sequence of whitespace is",
        "Default is a comma, ','. If None"
    ],
    [
        "comment : str or sequence of str or None, optional",
        "comment : str or sequence of"
    ],
    [
        "Character that begins a comment.  All text from the comment",
        "Character that begins a comment. All text"
    ],
    [
        "character to the end of the line is ignored.",
        "character to the end of"
    ],
    [
        "Multiple comments or multiple-character comment strings are supported,",
        "Multiple comments or multiple-character comment strings are"
    ],
    [
        "but may be slower and `quote` must be empty if used.",
        "but may be slower and `quote` must"
    ],
    [
        "Use None to disable all use of comments.",
        "Use None to disable all use of"
    ],
    [
        "quote : str or None, optional",
        "quote : str or"
    ],
    [
        "Character that is used to quote string fields. Default is '\"'",
        "Character that is used to quote string"
    ],
    [
        "(a double quote). Use None to disable quote support.",
        "(a double quote). Use None to"
    ],
    [
        "A one-dimensional array of integer column numbers.  These are the",
        "A one-dimensional array of integer"
    ],
    [
        "columns from the file to be included in the array.  If this value",
        "columns from the file to be included"
    ],
    [
        "is not given, all the columns are used.",
        "is not given, all"
    ],
    [
        "Number of lines to skip before interpreting the data in the file.",
        "Number of lines to skip before interpreting the"
    ],
    [
        "Maximum number of rows of data to read.  Default is to read the",
        "Maximum number of rows of data to read. Default is to"
    ],
    [
        "converters : dict or callable, optional",
        "converters : dict or callable,"
    ],
    [
        "A function to parse all columns strings into the desired value, or",
        "A function to parse all columns"
    ],
    [
        "a dictionary mapping column number to a parser function.",
        "a dictionary mapping column number to a parser"
    ],
    [
        "Converters can also be used to provide a default value for missing",
        "Converters can also be used to provide a default"
    ],
    [
        "Minimum dimension of the array returned.",
        "Minimum dimension of the array"
    ],
    [
        "If True, the returned array is transposed, so that arguments may be",
        "If True, the returned array is transposed, so that arguments may"
    ],
    [
        "unpacked using ``x, y, z = read(...)``.  When used with a structured",
        "unpacked using ``x, y, z = read(...)``. When"
    ],
    [
        "data-type, arrays are returned for each field.  Default is False.",
        "data-type, arrays are returned for each"
    ],
    [
        "A NumPy dtype instance, can be a structured dtype to map to the",
        "A NumPy dtype instance, can be a structured dtype"
    ],
    [
        "Encoding used to decode the inputfile. The special value 'bytes'",
        "Encoding used to decode the"
    ],
    [
        "(the default) enables backwards-compatible behavior for `converters`,",
        "(the default) enables backwards-compatible behavior for"
    ],
    [
        "ensuring that inputs to the converter functions are encoded",
        "ensuring that inputs to the converter functions are"
    ],
    [
        "bytes objects. The special value 'bytes' has no additional effect if",
        "bytes objects. The special value 'bytes' has no additional"
    ],
    [
        "``converters=None``. If encoding is ``'bytes'`` or ``None``, the",
        "``converters=None``. If encoding is ``'bytes'`` or ``None``,"
    ],
    [
        "raise TypeError(\"a dtype must be provided.\")",
        "raise TypeError(\"a dtype"
    ],
    [
        "if dtype.kind in 'SUM' and (",
        "if dtype.kind in"
    ],
    [
        "\"comments cannot be an empty string. Use comments=None to \"",
        "\"comments cannot be an empty string. Use"
    ],
    [
        "f\"Comment characters '{comments}' cannot include the \"",
        "f\"Comment characters '{comments}' cannot include"
    ],
    [
        "\"when multiple comments or a multi-character comment is \"",
        "\"when multiple comments or a multi-character comment"
    ],
    [
        "\"given, quotes are not supported.  In this case quotechar \"",
        "\"given, quotes are not supported. In this case quotechar"
    ],
    [
        "f\"fname must be a string, filehandle, list of strings,\\n\"",
        "f\"fname must be a string, filehandle, list"
    ],
    [
        "f\"or generator. Got {type(fname)} instead.\") from e",
        "f\"or generator. Got {type(fname)} instead.\")"
    ],
    [
        "f'loadtxt: input contained no data: \"{fname}\"',",
        "f'loadtxt: input contained no data:"
    ],
    [
        "return [arr[field] for field in dt.names]",
        "return [arr[field] for"
    ],
    [
        "Load data from a text file.",
        "Load data from a"
    ],
    [
        "fname : file, str, pathlib.Path, list of str, generator",
        "fname : file, str, pathlib.Path, list of"
    ],
    [
        "File, filename, list, or generator to read.  If the filename",
        "File, filename, list, or generator to"
    ],
    [
        "that generators must return bytes or strings. The strings",
        "that generators must return bytes"
    ],
    [
        "in a list or produced by a generator are treated as lines.",
        "in a list or produced by a generator are"
    ],
    [
        "Data-type of the resulting array; default: float.  If this is a",
        "Data-type of the resulting array; default: float. If this is"
    ],
    [
        "each row will be interpreted as an element of the array.  In this",
        "each row will be interpreted as an element of"
    ],
    [
        "case, the number of columns used must match the number of fields in",
        "case, the number of columns used must match"
    ],
    [
        "comments : str or sequence of str or None, optional",
        "comments : str or sequence"
    ],
    [
        "The characters or list of characters used to indicate the start of a",
        "The characters or list of characters used to indicate"
    ],
    [
        "comment. None implies no comments. For backwards compatibility, byte",
        "comment. None implies no comments."
    ],
    [
        "The character used to separate the values. For backwards compatibility,",
        "The character used to separate the values. For"
    ],
    [
        "Only single character delimiters are supported. Newline characters",
        "Only single character delimiters are"
    ],
    [
        "cannot be used as the delimiter.",
        "cannot be used as the"
    ],
    [
        "converters : dict or callable, optional",
        "converters : dict or"
    ],
    [
        "Converter functions to customize value parsing. If `converters` is",
        "Converter functions to customize value"
    ],
    [
        "callable, the function is applied to all columns, else it must be a",
        "callable, the function is applied to all columns, else it must be"
    ],
    [
        "dict that maps column number to a parser function.",
        "dict that maps column number to a parser"
    ],
    [
        "The ability to pass a single callable to be applied to all columns",
        "The ability to pass a single callable to be applied to all"
    ],
    [
        "usecols : int or sequence, optional",
        "usecols : int or sequence,"
    ],
    [
        "The default, None, results in all columns being read.",
        "The default, None, results in all"
    ],
    [
        "If True, the returned array is transposed, so that arguments may be",
        "If True, the returned array is transposed, so that arguments"
    ],
    [
        "unpacked using ``x, y, z = loadtxt(...)``.  When used with a",
        "unpacked using ``x, y, z = loadtxt(...)``."
    ],
    [
        "structured data-type, arrays are returned for each field.",
        "structured data-type, arrays are returned for each"
    ],
    [
        "The returned array will have at least `ndmin` dimensions.",
        "The returned array will have at least"
    ],
    [
        "Otherwise mono-dimensional axes will be squeezed.",
        "Otherwise mono-dimensional axes"
    ],
    [
        "Encoding used to decode the inputfile. Does not apply to input streams.",
        "Encoding used to decode the inputfile. Does"
    ],
    [
        "The special value 'bytes' enables backward compatibility workarounds",
        "The special value 'bytes'"
    ],
    [
        "that ensures you receive byte arrays as results if possible and passes",
        "that ensures you receive byte arrays as results if"
    ],
    [
        "unicode arrays and pass strings as input to converters.  If set to None",
        "unicode arrays and pass strings as input to converters. If set to"
    ],
    [
        "the system default is used. The default value is None.",
        "the system default is used. The default value is"
    ],
    [
        "compatibility. The default is now ``None``.",
        "compatibility. The default is now"
    ],
    [
        "Read `max_rows` rows of content after `skiprows` lines. The default is",
        "Read `max_rows` rows of content after `skiprows` lines. The"
    ],
    [
        "to read all the rows. Note that empty rows containing no data such as",
        "to read all the rows. Note that empty rows"
    ],
    [
        "empty lines and comment lines are not counted towards `max_rows`,",
        "empty lines and comment lines are not counted"
    ],
    [
        "while such lines are counted in `skiprows`.",
        "while such lines are counted in"
    ],
    [
        "Lines containing no data, including comment lines (e.g., lines",
        "Lines containing no data, including comment"
    ],
    [
        "quotechar : unicode character or None, optional",
        "quotechar : unicode character"
    ],
    [
        "The character used to denote the start and end of a quoted item.",
        "The character used to denote the start and end of a"
    ],
    [
        "Occurrences of the delimiter or comment characters are ignored within",
        "Occurrences of the delimiter or comment characters are ignored"
    ],
    [
        "a quoted item. The default value is ``quotechar=None``, which means",
        "a quoted item. The default"
    ],
    [
        "If two consecutive instances of `quotechar` are found within a quoted",
        "If two consecutive instances of `quotechar` are found within a"
    ],
    [
        "field, the first is treated as an escape character. See examples.",
        "field, the first is treated as an escape character."
    ],
    [
        "Data read from the text file.",
        "Data read from the"
    ],
    [
        "genfromtxt : Load data with missing values handled as specified.",
        "genfromtxt : Load data with missing values"
    ],
    [
        "scipy.io.loadmat : reads MATLAB data files",
        "scipy.io.loadmat : reads"
    ],
    [
        "This function aims to be a fast reader for simply formatted files.  The",
        "This function aims to be a fast reader for"
    ],
    [
        "`genfromtxt` function provides more sophisticated handling of, e.g.,",
        "`genfromtxt` function provides more sophisticated handling of,"
    ],
    [
        "Each row in the input text file must have the same number of values to be",
        "Each row in the input text file must"
    ],
    [
        "able to read all values. If all rows do not have same number of values, a",
        "able to read all values. If all rows do not have"
    ],
    [
        "subset of up to n columns (where n is the least number of values present",
        "subset of up to n columns (where n"
    ],
    [
        "in all rows) can be read by specifying the columns via `usecols`.",
        "in all rows) can be read by specifying the columns via"
    ],
    [
        "The strings produced by the Python float.hex method can be used as",
        "The strings produced by the Python float.hex method can be used"
    ],
    [
        ">>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),",
        ">>> np.loadtxt(d, dtype={'names': ('gender', 'age',"
    ],
    [
        "The `converters` argument is used to specify functions to preprocess the",
        "The `converters` argument is used to"
    ],
    [
        "text prior to parsing. `converters` can be a dictionary that maps",
        "text prior to parsing. `converters` can be a"
    ],
    [
        "`converters` can be a callable instead of a dictionary, in which case it",
        "`converters` can be a callable instead of a dictionary, in which"
    ],
    [
        "This example shows how `converters` can be used to convert a field",
        "This example shows how `converters` can be used"
    ],
    [
        "with a trailing minus sign into a negative number.",
        "with a trailing minus sign into"
    ],
    [
        "Using a callable as the converter can be particularly useful for handling",
        "Using a callable as the converter can be"
    ],
    [
        "values with different formatting, e.g. floats with underscores:",
        "values with different formatting, e.g. floats with"
    ],
    [
        "This idea can be extended to automatically handle values specified in",
        "This idea can be extended to automatically handle values specified"
    ],
    [
        "many different formats, such as hex values:",
        "many different formats, such as hex"
    ],
    [
        "Or a format where the ``-`` sign comes after the number:",
        "Or a format where the ``-`` sign comes after the"
    ],
    [
        "Support for quoted fields is enabled with the `quotechar` parameter.",
        "Support for quoted fields is enabled with the"
    ],
    [
        "Comment and delimiter characters are ignored when they appear within a",
        "Comment and delimiter characters are ignored when they appear"
    ],
    [
        "Quoted fields can be separated by multiple whitespace characters:",
        "Quoted fields can be separated"
    ],
    [
        "Two consecutive quote characters within a quoted field are treated as a",
        "Two consecutive quote characters within a quoted field are treated as"
    ],
    [
        ">>> s = StringIO('\"Hello, my name is \"\"Monty\"\"!\"')",
        ">>> s = StringIO('\"Hello, my name is"
    ],
    [
        "Read subset of columns when all rows do not contain equal number of values:",
        "Read subset of columns when all rows do"
    ],
    [
        "arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,",
        "arr = _read(fname,"
    ],
    [
        "def _savetxt_dispatcher(fname, X, fmt=None, delimiter=None, newline=None,",
        "def _savetxt_dispatcher(fname, X, fmt=None,"
    ],
    [
        "Save an array to a text file.",
        "Save an array to a text"
    ],
    [
        "fname : filename, file handle or pathlib.Path",
        "fname : filename, file"
    ],
    [
        "If the filename ends in ``.gz``, the file is automatically saved in",
        "If the filename ends in ``.gz``, the"
    ],
    [
        "compressed gzip format.  `loadtxt` understands gzipped files",
        "compressed gzip format. `loadtxt` understands"
    ],
    [
        "Data to be saved to a text file.",
        "Data to be saved to a"
    ],
    [
        "fmt : str or sequence of strs, optional",
        "fmt : str or sequence of"
    ],
    [
        "case `delimiter` is ignored. For complex `X`, the legal options",
        "case `delimiter` is ignored. For complex `X`, the legal"
    ],
    [
        "like ``' (%s+%sj)' % (fmt, fmt)``",
        "like ``' (%s+%sj)' % (fmt,"
    ],
    [
        "* a full string specifying every real and imaginary part, e.g.",
        "* a full string specifying every real and imaginary part,"
    ],
    [
        "* a list of specifiers, one per column - in this case, the real",
        "* a list of specifiers, one per column - in this case, the"
    ],
    [
        "and imaginary part must have separate specifiers,",
        "and imaginary part must"
    ],
    [
        "String that will be written at the beginning of the file.",
        "String that will be written at"
    ],
    [
        "String that will be written at the end of the file.",
        "String that will be written at the end of the"
    ],
    [
        "String that will be prepended to the ``header`` and ``footer`` strings,",
        "String that will be prepended to the ``header`` and ``footer``"
    ],
    [
        "Encoding used to encode the outputfile. Does not apply to output",
        "Encoding used to encode the outputfile. Does not apply"
    ],
    [
        "save : Save an array to a binary file in NumPy ``.npy`` format",
        "save : Save an array to a binary file in NumPy"
    ],
    [
        "savez : Save several arrays into an uncompressed ``.npz`` archive",
        "savez : Save several arrays"
    ],
    [
        "savez_compressed : Save several arrays into a compressed ``.npz`` archive",
        "savez_compressed : Save several arrays into a compressed"
    ],
    [
        "Further explanation of the `fmt` parameter",
        "Further explanation of"
    ],
    [
        "``+`` : Forces to precede result with + or -.",
        "``+`` : Forces to precede"
    ],
    [
        "Minimum number of characters to be printed. The value is not truncated",
        "Minimum number of characters to be"
    ],
    [
        "- For integer specifiers (eg. ``d,i,o,x``), the minimum number of",
        "- For integer specifiers (eg. ``d,i,o,x``), the minimum"
    ],
    [
        "- For ``e, E`` and ``f`` specifiers, the number of digits to print",
        "- For ``e, E`` and ``f`` specifiers, the number of digits"
    ],
    [
        "- For ``g`` and ``G``, the maximum number of significant digits.",
        "- For ``g`` and ``G``, the maximum number of significant"
    ],
    [
        "- For ``s``, the maximum number of characters.",
        "- For ``s``, the"
    ],
    [
        "``d`` or ``i`` : signed decimal integer",
        "``d`` or ``i`` : signed decimal"
    ],
    [
        "``e`` or ``E`` : scientific notation with ``e`` or ``E``.",
        "``e`` or ``E`` : scientific"
    ],
    [
        "``g,G`` : use the shorter of ``e,E`` or ``f``",
        "``g,G`` : use the shorter of ``e,E`` or"
    ],
    [
        "This explanation of ``fmt`` is not complete, for an exhaustive",
        "This explanation of ``fmt`` is not complete, for an"
    ],
    [
        "\"\"\"Convert to bytes on bytestream inputs.",
        "\"\"\"Convert to bytes on bytestream"
    ],
    [
        "raise ValueError('fname must be a string or file handle')",
        "raise ValueError('fname must be a string or file"
    ],
    [
        "raise AttributeError('fmt has wrong shape.  %s' % str(fmt))",
        "raise AttributeError('fmt has wrong shape. %s'"
    ],
    [
        "error = ValueError('fmt has wrong number of %% formats:  %s' % fmt)",
        "error = ValueError('fmt has wrong number of"
    ],
    [
        "fmt = [' (%s+%sj)' % (fmt, fmt), ] * ncol",
        "fmt = [' (%s+%sj)' % (fmt, fmt),"
    ],
    [
        "fmt = [fmt, ] * ncol",
        "fmt = [fmt, ] *"
    ],
    [
        "elif ((not iscomplex_X) and n_fmt_chars != ncol):",
        "elif ((not iscomplex_X) and n_fmt_chars !="
    ],
    [
        "raise ValueError('invalid fmt: %r' % (fmt,))",
        "raise ValueError('invalid fmt: %r'"
    ],
    [
        "header = header.replace('\\n', '\\n' + comments)",
        "header = header.replace('\\n',"
    ],
    [
        "v = format % tuple(row) + newline",
        "v = format % tuple(row)"
    ],
    [
        "raise TypeError(\"Mismatch between array dtype ('%s') and \"",
        "raise TypeError(\"Mismatch between array dtype ('%s') and"
    ],
    [
        "footer = footer.replace('\\n', '\\n' + comments)",
        "footer = footer.replace('\\n',"
    ],
    [
        "Construct an array from a text file, using regular expression parsing.",
        "Construct an array from a text file, using"
    ],
    [
        "The returned array is always a structured array, and is constructed from",
        "The returned array is always a"
    ],
    [
        "all matches of the regular expression in the file. Groups in the regular",
        "all matches of the regular expression in the file. Groups"
    ],
    [
        "expression are converted to fields of the structured array.",
        "expression are converted to fields"
    ],
    [
        "file : file, str, or pathlib.Path",
        "file : file, str, or"
    ],
    [
        "Filename or file object to read.",
        "Filename or file object to"
    ],
    [
        "Regular expression used to parse the file.",
        "Regular expression used to parse"
    ],
    [
        "Groups in the regular expression correspond to fields in the dtype.",
        "Groups in the regular expression correspond to fields in the"
    ],
    [
        "dtype : dtype or list of dtypes",
        "dtype : dtype or"
    ],
    [
        "Dtype for the structured array; must be a structured datatype.",
        "Dtype for the structured array; must be"
    ],
    [
        "Encoding used to decode the inputfile. Does not apply to input streams.",
        "Encoding used to decode the inputfile. Does not apply"
    ],
    [
        "The output array, containing the part of the content of `file` that",
        "The output array, containing the part of the content"
    ],
    [
        "was matched by `regexp`. `output` is always a structured array.",
        "was matched by `regexp`. `output` is always a structured"
    ],
    [
        "When `dtype` is not a valid dtype for a structured array.",
        "When `dtype` is not a valid dtype for a"
    ],
    [
        "Dtypes for structured arrays can be specified in several forms, but all",
        "Dtypes for structured arrays can be specified in several forms,"
    ],
    [
        "forms specify at least the data type and field name. For details see",
        "forms specify at least the data type and field name. For details"
    ],
    [
        "raise TypeError('dtype must be a structured datatype.')",
        "raise TypeError('dtype must be a"
    ],
    [
        "if isinstance(content, bytes) and isinstance(regexp, str):",
        "if isinstance(content, bytes)"
    ],
    [
        "Load data from a text file, with missing values handled as specified.",
        "Load data from a text file, with missing values"
    ],
    [
        "Each line past the first `skip_header` lines is split at the `delimiter`",
        "Each line past the first `skip_header` lines is split at"
    ],
    [
        "character, and characters following the `comments` character are discarded.",
        "character, and characters following the `comments`"
    ],
    [
        "fname : file, str, pathlib.Path, list of str, generator",
        "fname : file, str, pathlib.Path, list of"
    ],
    [
        "File, filename, list, or generator to read.  If the filename",
        "File, filename, list, or generator to"
    ],
    [
        "that generators must return bytes or strings. The strings",
        "that generators must return bytes or strings."
    ],
    [
        "in a list or produced by a generator are treated as lines.",
        "in a list or produced by a"
    ],
    [
        "Data type of the resulting array.",
        "Data type of the"
    ],
    [
        "If None, the dtypes will be determined by the contents of each",
        "If None, the dtypes will be determined by the contents of"
    ],
    [
        "The character used to indicate the start of a comment.",
        "The character used to indicate the start of a"
    ],
    [
        "All the characters occurring on a line after a comment are discarded.",
        "All the characters occurring on a line after a comment are"
    ],
    [
        "delimiter : str, int, or sequence, optional",
        "delimiter : str, int, or"
    ],
    [
        "The string used to separate values.  By default, any consecutive",
        "The string used to separate values. By"
    ],
    [
        "whitespaces act as delimiter.  An integer or sequence of integers",
        "whitespaces act as delimiter. An integer or"
    ],
    [
        "can also be provided as width(s) of each field.",
        "can also be provided as width(s) of"
    ],
    [
        "The number of lines to skip at the beginning of the file.",
        "The number of lines to skip"
    ],
    [
        "The number of lines to skip at the end of the file.",
        "The number of lines to skip at"
    ],
    [
        "The set of functions that convert the data of a column to a value.",
        "The set of functions that convert the data of a column to"
    ],
    [
        "The converters can also be used to provide a default value",
        "The converters can also be used to provide a default"
    ],
    [
        "The set of strings corresponding to missing data.",
        "The set of strings corresponding"
    ],
    [
        "The set of values to be used as default when the data are missing.",
        "The set of values to be used as default when the data"
    ],
    [
        "names : {None, True, str, sequence}, optional",
        "names : {None, True, str,"
    ],
    [
        "If `names` is True, the field names are read from the first line after",
        "If `names` is True, the field names are"
    ],
    [
        "the first `skip_header` lines. This line can optionally be preceded",
        "the first `skip_header` lines. This line"
    ],
    [
        "by a comment delimiter. Any content before the comment delimiter is",
        "by a comment delimiter. Any content before the comment delimiter"
    ],
    [
        "discarded. If `names` is a sequence or a single-string of",
        "discarded. If `names` is a sequence or a single-string"
    ],
    [
        "comma-separated names, the names will be used to define the field",
        "comma-separated names, the names will be used to"
    ],
    [
        "names in a structured dtype. If `names` is None, the names of the",
        "names in a structured dtype. If `names` is None, the"
    ],
    [
        "dtype fields will be used, if any.",
        "dtype fields will be used, if"
    ],
    [
        "A list of names to exclude. This list is appended to the default list",
        "A list of names to exclude. This list"
    ],
    [
        "['return','file','print']. Excluded names are appended with an",
        "['return','file','print']. Excluded names are appended"
    ],
    [
        "underscore: for example, `file` would become `file_`.",
        "underscore: for example, `file` would"
    ],
    [
        "A string combining invalid characters that must be deleted from the",
        "A string combining invalid characters that must be deleted"
    ],
    [
        "Whether to automatically strip white spaces from the variables.",
        "Whether to automatically strip white spaces from the"
    ],
    [
        "Character(s) used in replacement of white spaces in the variable",
        "Character(s) used in replacement of white spaces"
    ],
    [
        "names. By default, use a '_'.",
        "names. By default,"
    ],
    [
        "case_sensitive : {True, False, 'upper', 'lower'}, optional",
        "case_sensitive : {True, False, 'upper', 'lower'},"
    ],
    [
        "If True, field names are case sensitive.",
        "If True, field names are case"
    ],
    [
        "If False or 'upper', field names are converted to upper case.",
        "If False or 'upper', field names"
    ],
    [
        "If 'lower', field names are converted to lower case.",
        "If 'lower', field names are converted"
    ],
    [
        "If True, the returned array is transposed, so that arguments may be",
        "If True, the returned array is transposed, so that arguments"
    ],
    [
        "unpacked using ``x, y, z = genfromtxt(...)``.  When used with a",
        "unpacked using ``x, y, z = genfromtxt(...)``. When used"
    ],
    [
        "structured data-type, arrays are returned for each field.",
        "structured data-type, arrays are returned for"
    ],
    [
        "If True, return a masked array.",
        "If True, return a"
    ],
    [
        "If False, return a regular array.",
        "If False, return"
    ],
    [
        "If True, do not raise errors for invalid values.",
        "If True, do not raise errors for"
    ],
    [
        "If True, an exception is raised if an inconsistency is detected in the",
        "If True, an exception is raised if an"
    ],
    [
        "If False, a warning is emitted and the offending lines are skipped.",
        "If False, a warning is emitted and the"
    ],
    [
        "The maximum number of rows to read. Must not be used with skip_footer",
        "The maximum number of rows to read."
    ],
    [
        "Encoding used to decode the inputfile. Does not apply when `fname`",
        "Encoding used to decode the inputfile. Does not"
    ],
    [
        "is a file object. The special value 'bytes' enables backward",
        "is a file object. The special"
    ],
    [
        "compatibility workarounds that ensure that you receive byte arrays",
        "compatibility workarounds that ensure that you receive byte"
    ],
    [
        "Override this value to receive unicode arrays and pass strings",
        "Override this value to receive unicode arrays"
    ],
    [
        "as input to converters.  If set to None the system default is used.",
        "as input to converters. If set to None the"
    ],
    [
        "compatibility. The default is now ``None``.",
        "compatibility. The default is"
    ],
    [
        "Data read from the text file. If `usemask` is True, this is a",
        "Data read from the text file. If"
    ],
    [
        "numpy.loadtxt : equivalent function when no data is missing.",
        "numpy.loadtxt : equivalent function when no"
    ],
    [
        "* When spaces are used as delimiters, or when no delimiter has been given",
        "* When spaces are used as delimiters,"
    ],
    [
        "as input, there should not be any missing data between two fields.",
        "as input, there should not be any missing data between two"
    ],
    [
        "* When variables are named (either by a flexible dtype or with a `names`",
        "* When variables are named (either by a flexible dtype or with a"
    ],
    [
        "sequence), there must not be any header in the file (else a ValueError",
        "sequence), there must not be any header in the"
    ],
    [
        "* Individual values are not stripped of spaces by default.",
        "* Individual values are not stripped of spaces by"
    ],
    [
        "When using a custom converter, make sure the function does remove spaces.",
        "When using a custom converter, make"
    ],
    [
        "* Custom converters may receive unexpected values due to dtype",
        "* Custom converters may receive unexpected values due to"
    ],
    [
        "Comma delimited file with mixed dtype",
        "Comma delimited file"
    ],
    [
        ">>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],",
        ">>> data ="
    ],
    [
        "\"The keywords 'skip_footer' and 'max_rows' can not be \"",
        "\"The keywords 'skip_footer' and 'max_rows' can not be"
    ],
    [
        "\"The input argument 'converter' should be a valid dictionary \"",
        "\"The input argument 'converter' should be"
    ],
    [
        "\"fname must be a string, a filehandle, a sequence of strings,\\n\"",
        "\"fname must be a string, a filehandle, a"
    ],
    [
        "f\"or an iterator of strings. Got {type(fname)} instead.\"",
        "f\"or an iterator of strings."
    ],
    [
        "if (names is True) and (comments is not None):",
        "if (names is True) and (comments is"
    ],
    [
        "usecols = [_.strip() for _ in usecols.split(\",\")]",
        "usecols = [_.strip() for _"
    ],
    [
        "names = validate_names([str(_.strip()) for _ in first_values])",
        "names = validate_names([str(_.strip()) for _ in"
    ],
    [
        "names = validate_names([_.strip() for _ in names.split(',')])",
        "names = validate_names([_.strip() for _ in"
    ],
    [
        "if (dtype is not None) and (len(dtype) > nbcols):",
        "if (dtype is not None) and (len(dtype)"
    ],
    [
        "dtype = np.dtype([descr[_] for _ in usecols])",
        "dtype = np.dtype([descr[_] for _"
    ],
    [
        "elif (names is not None) and (len(names) > nbcols):",
        "elif (names is not None) and (len(names) >"
    ],
    [
        "names = [names[_] for _ in usecols]",
        "names = [names[_] for"
    ],
    [
        "elif (names is not None) and (dtype is not None):",
        "elif (names is not None) and (dtype is"
    ],
    [
        "missing_values = [[''] for _ in range(nbcols)]",
        "missing_values = [[''] for _ in"
    ],
    [
        "val = [str(_) for _ in val]",
        "val = [str(_) for"
    ],
    [
        "for (value, entry) in zip(user_missing_values, missing_values):",
        "for (value, entry) in"
    ],
    [
        "for (miss, fill) in zip(missing_values, filling_values)",
        "for (miss, fill)"
    ],
    [
        "for (dt, miss, fill) in zipit]",
        "for (dt, miss,"
    ],
    [
        "for (i, line) in enumerate(itertools.chain([first_line, ], fhd)):",
        "for (i, line) in enumerate(itertools.chain([first_line,"
    ],
    [
        "values = [values[_] for _ in usecols]",
        "values = [values[_] for _"
    ],
    [
        "current_column = [itemgetter(i)(_m) for _m in rows]",
        "current_column = [itemgetter(i)(_m) for _m"
    ],
    [
        "nbrows = len(rows) + nbinvalid - skip_footer",
        "nbrows = len(rows) + nbinvalid"
    ],
    [
        "nbinvalid_skipped = len([_ for _ in invalid",
        "nbinvalid_skipped = len([_ for _ in"
    ],
    [
        "errmsg = [template % (i, nb)",
        "errmsg = [template %"
    ],
    [
        "zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]",
        "zip(*[[conv._loose_call(_r) for _r in"
    ],
    [
        "zip(*[[conv._strict_call(_r) for _r in map(itemgetter(i), rows)]",
        "zip(*[[conv._strict_call(_r) for _r in"
    ],
    [
        "column_types = [conv.type for conv in converters]",
        "column_types = [conv.type for"
    ],
    [
        "strcolidx = [i for (i, v) in enumerate(column_types)",
        "strcolidx = [i for"
    ],
    [
        "\"Reading unicode strings without specifying the encoding \"",
        "\"Reading unicode strings without"
    ],
    [
        "\"argument is deprecated. Set the encoding, use None for the \"",
        "\"argument is deprecated. Set the encoding, use"
    ],
    [
        "data = [encode_unicode_cols(r) for r in data]",
        "data = [encode_unicode_cols(r) for r in"
    ],
    [
        "n_chars = max(len(row[i]) for row in data)",
        "n_chars = max(len(row[i]) for row in"
    ],
    [
        "for c, c_type in zip(converters, column_types)",
        "for c, c_type in"
    ],
    [
        "ddtype = [(defaultfmt % i, dt)",
        "ddtype = [(defaultfmt % i,"
    ],
    [
        "mdtype = [(defaultfmt % i, bool)",
        "mdtype = [(defaultfmt"
    ],
    [
        "mdtype = list(zip(names, [bool] * len(sized_column_types)))",
        "mdtype = list(zip(names,"
    ],
    [
        "if names and dtype.names is not None:",
        "if names and dtype.names is"
    ],
    [
        "if 'O' in (_.char for _ in dtype_flat):",
        "if 'O' in (_.char"
    ],
    [
        "\"Nested fields involving objects are not supported...\")",
        "\"Nested fields involving objects"
    ],
    [
        "rows = np.array(data, dtype=[('', _) for _ in dtype_flat])",
        "rows = np.array(data, dtype=[('', _) for"
    ],
    [
        "masks, dtype=np.dtype([('', bool) for t in dtype_flat]))",
        "masks, dtype=np.dtype([('', bool) for t"
    ],
    [
        "for i, ttype in enumerate([conv.type for conv in converters]):",
        "for i, ttype in enumerate([conv.type for conv"
    ],
    [
        "ttype = (ttype, max(len(row[i]) for row in data))",
        "ttype = (ttype, max(len(row[i]) for row"
    ],
    [
        "mdtype = [(_, bool) for _ in dtype.names]",
        "mdtype = [(_, bool)"
    ],
    [
        "for (name, conv) in zip(names, converters):",
        "for (name, conv) in"
    ],
    [
        "missing_values = [conv(_) for _ in conv.missing_values",
        "missing_values = [conv(_) for"
    ],
    [
        "return [output[field] for field in names]",
        "return [output[field] for"
    ],
    [
        "Load ASCII data from a file and return it in a record array.",
        "Load ASCII data from a file and return"
    ],
    [
        "If ``usemask=False`` a standard `recarray` is returned,",
        "If ``usemask=False`` a standard `recarray` is"
    ],
    [
        "if ``usemask=True`` a MaskedRecords array is returned.",
        "if ``usemask=True`` a MaskedRecords array"
    ],
    [
        "fname, kwargs : For a description of input parameters, see `genfromtxt`.",
        "fname, kwargs : For a description"
    ],
    [
        "By default, `dtype` is None, which means that the data-type of the output",
        "By default, `dtype` is None, which means that the"
    ],
    [
        "array will be determined from the data.",
        "array will be determined"
    ],
    [
        "Load ASCII data stored in a comma-separated file.",
        "Load ASCII data stored in a comma-separated"
    ],
    [
        "The returned array is a record array (if ``usemask=False``, see",
        "The returned array is a"
    ],
    [
        "`recarray`) or a masked record array (if ``usemask=True``,",
        "`recarray`) or a masked record array (if"
    ],
    [
        "Use `numpy.genfromtxt` with comma as `delimiter` instead.",
        "Use `numpy.genfromtxt` with comma as `delimiter`"
    ],
    [
        "fname, kwargs : For a description of input parameters, see `genfromtxt`.",
        "fname, kwargs : For a description of input parameters, see"
    ],
    [
        "numpy.genfromtxt : generic function to load ASCII data.",
        "numpy.genfromtxt : generic function"
    ],
    [
        "By default, `dtype` is None, which means that the data-type of the output",
        "By default, `dtype` is None, which means that the data-type"
    ],
    [
        "array will be determined from the data.",
        "array will be determined from"
    ],
    [
        "\"use `numpy.genfromtxt` with comma as `delimiter` instead. \"",
        "\"use `numpy.genfromtxt` with comma as `delimiter`"
    ],
    [
        "'ravel_multi_index', 'unravel_index', 'mgrid', 'ogrid', 'r_', 'c_',",
        "'ravel_multi_index', 'unravel_index', 'mgrid', 'ogrid', 'r_',"
    ],
    [
        "'s_', 'index_exp', 'ix_', 'ndenumerate', 'ndindex', 'fill_diagonal',",
        "'s_', 'index_exp', 'ix_',"
    ],
    [
        "Construct an open mesh from multiple sequences.",
        "Construct an open mesh"
    ],
    [
        "and the dimension with the non-unit shape value cycles through all",
        "and the dimension with the non-unit"
    ],
    [
        "Using `ix_` one can quickly construct index arrays that will index",
        "Using `ix_` one can quickly construct index"
    ],
    [
        "Each sequence should be of integer or boolean type.",
        "Each sequence should be of integer"
    ],
    [
        "Boolean sequences will be interpreted as boolean masks for the",
        "Boolean sequences will be interpreted as"
    ],
    [
        "corresponding dimension (equivalent to passing in",
        "corresponding dimension (equivalent to"
    ],
    [
        "N arrays with N dimensions each, with N the number of input",
        "N arrays with N dimensions each, with N the"
    ],
    [
        "sequences. Together these arrays form an open mesh.",
        "sequences. Together these arrays"
    ],
    [
        ">>> ixgrid = np.ix_([True, True], [False, False, True, False, True])",
        ">>> ixgrid = np.ix_([True, True], [False, False, True, False,"
    ],
    [
        "``grid = nd_grid()`` creates an instance which will return a mesh-grid",
        "``grid = nd_grid()`` creates an instance"
    ],
    [
        "when indexed.  The dimension and number of the output arrays are equal",
        "when indexed. The dimension and number of the output arrays"
    ],
    [
        "to the number of indexing dimensions.  If the step length is not a",
        "to the number of indexing dimensions. If the"
    ],
    [
        "complex number, then the stop is not inclusive.",
        "complex number, then the stop is not"
    ],
    [
        "integer part of its magnitude is interpreted as specifying the",
        "integer part of its magnitude is interpreted"
    ],
    [
        "number of points to create between the start and stop values, where",
        "number of points to create between the start and"
    ],
    [
        "If instantiated with an argument of ``sparse=True``, the mesh-grid is",
        "If instantiated with an argument of ``sparse=True``,"
    ],
    [
        "open (or not fleshed out) so that only one-dimension of each returned",
        "open (or not fleshed out) so that only one-dimension"
    ],
    [
        "Whether the grid is sparse or not. Default is False.",
        "Whether the grid is sparse or not. Default is"
    ],
    [
        "Two instances of `nd_grid` are made available in the NumPy namespace,",
        "Two instances of `nd_grid` are made available"
    ],
    [
        "`mgrid` and `ogrid`, approximately defined as::",
        "`mgrid` and `ogrid`, approximately"
    ],
    [
        "Users should use these pre-defined instances instead of using `nd_grid`",
        "Users should use these pre-defined instances"
    ],
    [
        "for _x, _t in zip(size, (typ,) * len(size))]",
        "for _x, _t in zip(size,"
    ],
    [
        "nn[k] = (nn[k] * step + start)",
        "nn[k] = (nn[k] * step"
    ],
    [
        "An instance which returns a dense multi-dimensional \"meshgrid\".",
        "An instance which returns a"
    ],
    [
        "An instance which returns a dense (or fleshed out) mesh-grid",
        "An instance which returns a dense"
    ],
    [
        "when indexed, so that each returned argument has the same shape.",
        "when indexed, so that each returned argument has"
    ],
    [
        "The dimensions and number of the output arrays are equal to the",
        "The dimensions and number of the output"
    ],
    [
        "number of indexing dimensions.  If the step length is not a complex",
        "number of indexing dimensions. If the step length is not a"
    ],
    [
        "number, then the stop is not inclusive.",
        "number, then the stop is"
    ],
    [
        "the integer part of its magnitude is interpreted as specifying the",
        "the integer part of its magnitude is interpreted"
    ],
    [
        "number of points to create between the start and stop values, where",
        "number of points to create between the"
    ],
    [
        "A single array, containing a set of `ndarray`\\\\ s all of the same",
        "A single array, containing a set of `ndarray`\\\\ s"
    ],
    [
        "dimensions. stacked along the first axis.",
        "dimensions. stacked along"
    ],
    [
        "ogrid : like `mgrid` but returns open (not fleshed out) mesh grids",
        "ogrid : like `mgrid` but returns open"
    ],
    [
        "meshgrid: return coordinate matrices from coordinate vectors",
        "meshgrid: return coordinate matrices from coordinate"
    ],
    [
        "An instance which returns an open multi-dimensional \"meshgrid\".",
        "An instance which returns an"
    ],
    [
        "An instance which returns an open (i.e. not fleshed out) mesh-grid",
        "An instance which returns an open (i.e. not fleshed"
    ],
    [
        "when indexed, so that only one dimension of each returned array is",
        "when indexed, so that only one dimension of each returned array"
    ],
    [
        "equal to the number of indexing dimensions.  If the step length is",
        "equal to the number of indexing dimensions. If"
    ],
    [
        "not a complex number, then the stop is not inclusive.",
        "not a complex number, then"
    ],
    [
        "the integer part of its magnitude is interpreted as specifying the",
        "the integer part of its magnitude is interpreted as specifying"
    ],
    [
        "number of points to create between the start and stop values, where",
        "number of points to create between the start and stop"
    ],
    [
        "mesh-grid : ndarray or tuple of ndarrays",
        "mesh-grid : ndarray or"
    ],
    [
        "If the input is a single slice, returns an array.",
        "If the input is a"
    ],
    [
        "If the input is multiple slices, returns a tuple of arrays, with",
        "If the input is multiple slices, returns a"
    ],
    [
        "mgrid : like `ogrid` but returns dense (or fleshed out) mesh grids",
        "mgrid : like `ogrid` but returns"
    ],
    [
        "meshgrid: return coordinate matrices from coordinate vectors",
        "meshgrid: return coordinate matrices from coordinate"
    ],
    [
        "Translates slice objects to concatenation along an axis.",
        "Translates slice objects to concatenation along"
    ],
    [
        "For detailed documentation on usage, see `r_`.",
        "For detailed documentation on"
    ],
    [
        "raise ValueError(\"special directives must be the \"",
        "raise ValueError(\"special directives must"
    ],
    [
        "raise ValueError(\"unknown special directive\") from e",
        "raise ValueError(\"unknown special directive\")"
    ],
    [
        "newobj = array(item, copy=None, subok=True, ndmin=ndmin)",
        "newobj = array(item, copy=None,"
    ],
    [
        "ndmin=ndmin, dtype=final_dtype) for obj in objs]",
        "ndmin=ndmin, dtype=final_dtype) for obj in"
    ],
    [
        "Translates slice objects to concatenation along the first axis.",
        "Translates slice objects to concatenation"
    ],
    [
        "This is a simple way to build up arrays quickly. There are two use cases.",
        "This is a simple way to build up arrays quickly. There"
    ],
    [
        "If slice notation is used, the syntax ``start:stop:step`` is equivalent",
        "If slice notation is used, the syntax ``start:stop:step`` is"
    ],
    [
        "to ``np.arange(start, stop, step)`` inside of the brackets. However, if",
        "to ``np.arange(start, stop, step)`` inside of the"
    ],
    [
        "interpreted as a number-of-points desired and the start and stop are",
        "interpreted as a number-of-points desired and the start and stop"
    ],
    [
        "inclusive. In other words ``start:stop:stepj`` is interpreted as",
        "inclusive. In other words ``start:stop:stepj`` is"
    ],
    [
        "After expansion of slice notation, all comma separated sequences are",
        "After expansion of slice notation,"
    ],
    [
        "Optional character strings placed as the first element of the index",
        "Optional character strings placed as the first"
    ],
    [
        "expression can be used to change the output. The strings 'r' or 'c' result",
        "expression can be used to change the output. The strings"
    ],
    [
        "A string integer specifies which axis to stack multiple comma separated",
        "A string integer specifies which axis to"
    ],
    [
        "arrays along. A string of two comma-separated integers allows indication",
        "arrays along. A string of two comma-separated integers"
    ],
    [
        "of the minimum number of dimensions to force each entry into as the",
        "of the minimum number of dimensions to force each"
    ],
    [
        "second integer (the axis to concatenate along is still the first integer).",
        "second integer (the axis to concatenate"
    ],
    [
        "A string with three comma-separated integers allows specification of the",
        "A string with three comma-separated integers allows"
    ],
    [
        "axis to concatenate along, the minimum number of dimensions to force the",
        "axis to concatenate along, the minimum number of dimensions to"
    ],
    [
        "entries to, and which axis should contain the start of the arrays which",
        "entries to, and which axis should contain the start of the arrays"
    ],
    [
        "are less than the specified number of dimensions. In other words the third",
        "are less than the specified number of dimensions."
    ],
    [
        "of the arrays that have their shapes upgraded. By default, they are placed",
        "of the arrays that have their shapes upgraded."
    ],
    [
        "in the front of the shape tuple. The third argument allows you to specify",
        "in the front of the shape tuple. The third argument"
    ],
    [
        "where the start of the array should be instead. Thus, a third argument of",
        "where the start of the array should be instead. Thus,"
    ],
    [
        "specify where in the new shape tuple the last dimension of upgraded arrays",
        "specify where in the new shape tuple the last"
    ],
    [
        "Not a function, so takes no parameters",
        "Not a function, so takes"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of arrays along"
    ],
    [
        "c_ : Translates slice objects to concatenation along the second axis.",
        "c_ : Translates slice objects to"
    ],
    [
        "String integers specify the axis to concatenate along or the minimum",
        "String integers specify the axis to concatenate along or"
    ],
    [
        "number of dimensions to force entries into.",
        "number of dimensions to force"
    ],
    [
        "Using 'r' or 'c' as a first string argument creates a matrix.",
        "Using 'r' or 'c' as a first string argument creates a"
    ],
    [
        "Translates slice objects to concatenation along the second axis.",
        "Translates slice objects to concatenation"
    ],
    [
        "useful because of its common occurrence. In particular, arrays will be",
        "useful because of its common occurrence. In particular,"
    ],
    [
        "r_ : For more detailed documentation.",
        "r_ : For"
    ],
    [
        "Return an iterator yielding pairs of array coordinates and values.",
        "Return an iterator yielding pairs of array coordinates and"
    ],
    [
        ">>> for index, x in np.ndenumerate(a):",
        ">>> for index, x"
    ],
    [
        "Standard iterator method, returns the index tuple and array value.",
        "Standard iterator method, returns the"
    ],
    [
        "The indices of the current iteration.",
        "The indices of"
    ],
    [
        "The array element of the current iteration.",
        "The array element of the current"
    ],
    [
        "An N-dimensional iterator object to index arrays.",
        "An N-dimensional iterator object"
    ],
    [
        "Given the shape of an array, an `ndindex` instance iterates over",
        "Given the shape of an array, an"
    ],
    [
        "the N-dimensional index of the array. At each iteration a tuple",
        "the N-dimensional index of the array. At each iteration a"
    ],
    [
        "of indices is returned, the last dimension is iterated over first.",
        "of indices is returned, the last dimension is"
    ],
    [
        "shape : ints, or a single tuple of ints",
        "shape : ints, or a single"
    ],
    [
        "The size of each dimension of the array can be passed as",
        "The size of each dimension of"
    ],
    [
        "individual parameters or as the elements of a tuple.",
        "individual parameters or as the elements of a"
    ],
    [
        "Increment the multi-dimensional index by one.",
        "Increment the multi-dimensional index by"
    ],
    [
        "This method is for backward compatibility only: do not use.",
        "This method is for backward compatibility"
    ],
    [
        "started emitting DeprecationWarning as of this version.",
        "started emitting DeprecationWarning as of"
    ],
    [
        "\"`ndindex.ndincr()` is deprecated, use `next(ndindex)` instead\",",
        "\"`ndindex.ndincr()` is deprecated, use"
    ],
    [
        "Standard iterator method, updates the index and returns the index",
        "Standard iterator method, updates the index"
    ],
    [
        "Returns a tuple containing the indices of the current",
        "Returns a tuple containing the indices of the"
    ],
    [
        "A nicer way to build up index tuples for arrays.",
        "A nicer way to build"
    ],
    [
        "Use one of the two predefined instances ``index_exp`` or `s_`",
        "Use one of the two predefined instances ``index_exp``"
    ],
    [
        "For any index combination, including slicing and axis insertion,",
        "For any index combination, including"
    ],
    [
        "``a[indices]`` is the same as ``a[np.index_exp[indices]]`` for any",
        "``a[indices]`` is the same as ``a[np.index_exp[indices]]`` for"
    ],
    [
        "array `a`. However, ``np.index_exp[indices]`` can be used anywhere",
        "array `a`. However, ``np.index_exp[indices]``"
    ],
    [
        "in Python code and returns a tuple of slice objects that can be",
        "in Python code and returns a tuple of slice objects"
    ],
    [
        "used in the construction of complex index expressions.",
        "used in the construction of"
    ],
    [
        "If True, always returns a tuple.",
        "If True, always returns"
    ],
    [
        "s_ : Predefined instance without tuple conversion:",
        "s_ : Predefined instance"
    ],
    [
        "The ``index_exp`` is another predefined instance that",
        "The ``index_exp`` is another"
    ],
    [
        "You can do all this with :class:`slice` plus a few special objects,",
        "You can do all this with"
    ],
    [
        "but there's a lot to remember and this version is simpler because",
        "but there's a lot to remember and this version is"
    ],
    [
        "it uses the standard array indexing syntax.",
        "it uses the standard"
    ],
    [
        "if self.maketuple and not isinstance(item, tuple):",
        "if self.maketuple and not isinstance(item,"
    ],
    [
        "\"\"\"Fill the main diagonal of the given array of any dimensionality.",
        "\"\"\"Fill the main diagonal of the"
    ],
    [
        "values ``a[i, ..., i]`` with indices ``i`` all identical.  This function",
        "values ``a[i, ..., i]`` with indices ``i`` all identical."
    ],
    [
        "modifies the input array in-place without returning a value.",
        "modifies the input array in-place"
    ],
    [
        "Array whose diagonal is to be filled in-place.",
        "Array whose diagonal is to be filled"
    ],
    [
        "Value(s) to write on the diagonal. If `val` is scalar, the value is",
        "Value(s) to write on the diagonal. If `val`"
    ],
    [
        "written along the diagonal. If array-like, the flattened `val` is",
        "written along the diagonal. If array-like, the flattened"
    ],
    [
        "written along the diagonal, repeating if necessary to fill all",
        "written along the diagonal, repeating if"
    ],
    [
        "diagonal \"wrapped\" after N columns. You can have this behavior",
        "diagonal \"wrapped\" after N columns. You can"
    ],
    [
        "with this option. This affects only tall matrices.",
        "with this option. This affects only tall"
    ],
    [
        "This functionality can be obtained via `diag_indices`, but internally",
        "This functionality can be obtained via `diag_indices`, but"
    ],
    [
        "this version uses a much faster implementation that never constructs the",
        "this version uses a much faster"
    ],
    [
        "We only show a few blocks for clarity:",
        "We only show a few blocks for"
    ],
    [
        "The wrap option affects only tall matrices:",
        "The wrap option affects only tall"
    ],
    [
        "The anti-diagonal can be filled by reversing the order of elements",
        "The anti-diagonal can be filled by reversing the"
    ],
    [
        "Note that the order in which the diagonal is filled varies depending",
        "Note that the order in which"
    ],
    [
        "raise ValueError(\"All dimensions of input must be of equal length\")",
        "raise ValueError(\"All dimensions of input"
    ],
    [
        "Return the indices to access the main diagonal of an array.",
        "Return the indices to access the main diagonal of"
    ],
    [
        "This returns a tuple of indices that can be used to access the main",
        "This returns a tuple of indices that can"
    ],
    [
        "The size, along each dimension, of the arrays for which the returned",
        "The size, along each dimension, of the arrays for"
    ],
    [
        "Return the indices to access the main diagonal of an n-dimensional array.",
        "Return the indices to access the main diagonal"
    ],
    [
        "Get the indices of the diagonal elements.",
        "Get the indices of"
    ],
    [
        "This is simply syntactic sugar for diag_indices.",
        "This is simply syntactic sugar for"
    ],
    [
        "raise ValueError(\"All dimensions of input must be of equal length\")",
        "raise ValueError(\"All dimensions of input must be"
    ],
    [
        "asanyarray, arange, zeros, greater_equal, multiply, ones,",
        "asanyarray, arange, zeros,"
    ],
    [
        "'diag', 'diagflat', 'eye', 'fliplr', 'flipud', 'tri', 'triu',",
        "'diag', 'diagflat', 'eye', 'fliplr', 'flipud', 'tri',"
    ],
    [
        "\"\"\" get small int that fits the range \"\"\"",
        "\"\"\" get small int that fits the"
    ],
    [
        "direction. Columns are preserved, but appear in a different order than",
        "direction. Columns are preserved, but appear in a different"
    ],
    [
        "A view of `m` with the columns reversed.  Since a view",
        "A view of `m` with the columns reversed. Since"
    ],
    [
        "flipud : Flip array in the up/down direction.",
        "flipud : Flip array in the"
    ],
    [
        "flip : Flip array in one or more dimensions.",
        "flip : Flip array in one"
    ],
    [
        "direction. Rows are preserved, but appear in a different order than before.",
        "direction. Rows are preserved, but appear"
    ],
    [
        "A view of `m` with the rows reversed.  Since a view is",
        "A view of `m` with the"
    ],
    [
        "fliplr : Flip array in the left/right direction.",
        "fliplr : Flip array in the left/right"
    ],
    [
        "flip : Flip array in one or more dimensions.",
        "flip : Flip array in one"
    ],
    [
        "Number of rows in the output.",
        "Number of rows"
    ],
    [
        "Number of columns in the output. If None, defaults to `N`.",
        "Number of columns in the output."
    ],
    [
        "a positive value refers to an upper diagonal, and a negative value",
        "a positive value refers to an"
    ],
    [
        "Whether the output should be stored in row-major (C-style) or",
        "Whether the output should be stored in row-major"
    ],
    [
        "The device on which to place the created array. Default: None.",
        "The device on which to place the created array. Default:"
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be ``\"cpu\"``"
    ],
    [
        "I : ndarray of shape (N,M)",
        "I : ndarray of"
    ],
    [
        "An array where all elements are equal to zero, except for the `k`-th",
        "An array where all elements are equal"
    ],
    [
        "diagonal, whose values are equal to one.",
        "diagonal, whose values are equal to"
    ],
    [
        "like, N, M=M, k=k, dtype=dtype, order=order, device=device",
        "like, N, M=M, k=k, dtype=dtype,"
    ],
    [
        "m = zeros((N, M), dtype=dtype, order=order, device=device)",
        "m = zeros((N, M),"
    ],
    [
        "Extract a diagonal or construct a diagonal array.",
        "Extract a diagonal or construct"
    ],
    [
        "See the more detailed documentation for ``numpy.diagonal`` if you use this",
        "See the more detailed documentation for ``numpy.diagonal``"
    ],
    [
        "function to extract a diagonal and wish to write to the resulting array;",
        "function to extract a diagonal and wish"
    ],
    [
        "whether it returns a copy or a view depends on what version of numpy you",
        "whether it returns a copy or a view depends on what version of numpy"
    ],
    [
        "The extracted diagonal or constructed diagonal array.",
        "The extracted diagonal or"
    ],
    [
        "triu : Upper triangle of an array.",
        "triu : Upper triangle of an"
    ],
    [
        "tril : Lower triangle of an array.",
        "tril : Lower triangle"
    ],
    [
        "Create a two-dimensional array with the flattened input as a diagonal.",
        "Create a two-dimensional array with the"
    ],
    [
        "Input data, which is flattened and set as the `k`-th",
        "Input data, which is flattened"
    ],
    [
        "a positive (negative) `k` giving the number of the diagonal above",
        "a positive (negative) `k` giving the"
    ],
    [
        "fi = i + k + i * n",
        "fi = i + k"
    ],
    [
        "fi = i + (i - k) * n",
        "fi = i + (i"
    ],
    [
        "An array with ones at and below the given diagonal and zeros elsewhere.",
        "An array with ones at and below the given diagonal and zeros"
    ],
    [
        "Number of rows in the array.",
        "Number of rows"
    ],
    [
        "Number of columns in the array.",
        "Number of columns in the"
    ],
    [
        "By default, `M` is taken equal to `N`.",
        "By default, `M` is taken equal"
    ],
    [
        "The sub-diagonal at and below which the array is filled.",
        "The sub-diagonal at and below which the array is"
    ],
    [
        "Data type of the returned array.  The default is float.",
        "Data type of the returned array."
    ],
    [
        "tri : ndarray of shape (N, M)",
        "tri : ndarray of"
    ],
    [
        "Array with its lower triangle filled with ones and zero elsewhere;",
        "Array with its lower triangle filled with"
    ],
    [
        "return _tri_with_like(like, N, M=M, k=k, dtype=dtype)",
        "return _tri_with_like(like, N, M=M, k=k,"
    ],
    [
        "arange(-k, M - k, dtype=_min_int(-k, M - k)))",
        "arange(-k, M - k,"
    ],
    [
        "Return a copy of an array with elements above the `k`-th diagonal zeroed.",
        "Return a copy of an array with elements"
    ],
    [
        "m : array_like, shape (..., M, N)",
        "m : array_like, shape"
    ],
    [
        "tril : ndarray, shape (..., M, N)",
        "tril : ndarray, shape (..., M,"
    ],
    [
        "Lower triangle of `m`, of same shape and data-type as `m`.",
        "Lower triangle of `m`, of same shape and"
    ],
    [
        "triu : same thing, only for the upper triangle",
        "triu : same thing, only"
    ],
    [
        "Return a copy of an array with the elements below the `k`-th diagonal",
        "Return a copy of an array with the elements below the"
    ],
    [
        "Please refer to the documentation for `tril` for further details.",
        "Please refer to the documentation for"
    ],
    [
        "tril : lower triangle of an array",
        "tril : lower triangle of"
    ],
    [
        "The columns of the output matrix are powers of the input vector. The",
        "The columns of the output matrix are powers of the"
    ],
    [
        "order of the powers is determined by the `increasing` boolean argument.",
        "order of the powers is determined"
    ],
    [
        "Specifically, when `increasing` is False, the `i`-th output column is",
        "Specifically, when `increasing` is False, the `i`-th"
    ],
    [
        "a matrix with a geometric progression in each row is named for Alexandre-",
        "a matrix with a geometric progression in each row is named"
    ],
    [
        "Number of columns in the output.  If `N` is not specified, a square",
        "Number of columns in the output. If `N` is not specified,"
    ],
    [
        "array is returned (``N = len(x)``).",
        "array is returned (``N"
    ],
    [
        "Order of the powers of the columns.  If True, the powers increase",
        "Order of the powers of the columns. If True, the powers"
    ],
    [
        "from left to right, if False (the default) they are reversed.",
        "from left to right, if False (the default)"
    ],
    [
        "Vandermonde matrix.  If `increasing` is False, the first column is",
        "Vandermonde matrix. If `increasing` is False, the first column"
    ],
    [
        "The determinant of a square Vandermonde matrix is the product",
        "The determinant of a square Vandermonde matrix is"
    ],
    [
        "of the differences between the values of the input vector:",
        "of the differences between the values of the input"
    ],
    [
        "raise ValueError(\"x must be a one-dimensional array or sequence.\")",
        "raise ValueError(\"x must be a"
    ],
    [
        "v = empty((len(x), N), dtype=promote_types(x.dtype, int))",
        "v = empty((len(x),"
    ],
    [
        "Compute the bi-dimensional histogram of two data samples.",
        "Compute the bi-dimensional histogram of two"
    ],
    [
        "An array containing the x coordinates of the points to be",
        "An array containing the x coordinates"
    ],
    [
        "An array containing the y coordinates of the points to be",
        "An array containing the y coordinates of"
    ],
    [
        "bins : int or array_like or [int, int] or [array, array], optional",
        "bins : int or array_like or [int, int] or"
    ],
    [
        "* If int, the number of bins for the two dimensions (nx=ny=bins).",
        "* If int, the number of bins for the two dimensions"
    ],
    [
        "* If array_like, the bin edges for the two dimensions",
        "* If array_like, the bin edges for the two"
    ],
    [
        "* If [int, int], the number of bins in each dimension",
        "* If [int, int], the number"
    ],
    [
        "* If [array, array], the bin edges in each dimension",
        "* If [array, array], the"
    ],
    [
        "* A combination [int, array] or [array, int], where int",
        "* A combination [int, array] or [array, int], where"
    ],
    [
        "is the number of bins and array is the bin edges.",
        "is the number of bins and array"
    ],
    [
        "The leftmost and rightmost edges of the bins along each dimension",
        "The leftmost and rightmost edges of the"
    ],
    [
        "(if not specified explicitly in the `bins` parameters):",
        "(if not specified explicitly in the `bins`"
    ],
    [
        "``[[xmin, xmax], [ymin, ymax]]``. All values outside of this range",
        "``[[xmin, xmax], [ymin, ymax]]``. All values outside of this"
    ],
    [
        "will be considered outliers and not tallied in the histogram.",
        "will be considered outliers and not"
    ],
    [
        "If False, the default, returns the number of samples in each bin.",
        "If False, the default, returns the number of samples in each"
    ],
    [
        "If True, returns the probability *density* function at the bin,",
        "If True, returns the probability *density* function at the"
    ],
    [
        "An array of values ``w_i`` weighing each sample ``(x_i, y_i)``.",
        "An array of values ``w_i`` weighing each"
    ],
    [
        "False, the values of the returned histogram are equal to the sum of",
        "False, the values of the returned histogram are equal to the sum"
    ],
    [
        "the weights belonging to the samples falling into each bin.",
        "the weights belonging to the samples falling"
    ],
    [
        "The bi-dimensional histogram of samples `x` and `y`. Values in `x`",
        "The bi-dimensional histogram of samples `x` and `y`. Values"
    ],
    [
        "are histogrammed along the first dimension and values in `y` are",
        "are histogrammed along the first dimension and values in"
    ],
    [
        "The bin edges along the first dimension.",
        "The bin edges along the first"
    ],
    [
        "The bin edges along the second dimension.",
        "The bin edges along the second"
    ],
    [
        "When `density` is True, then the returned histogram is the sample",
        "When `density` is True, then the returned histogram is the"
    ],
    [
        "density, defined such that the sum over bins of the product",
        "density, defined such that the sum over bins"
    ],
    [
        "Please note that the histogram does not follow the Cartesian convention",
        "Please note that the histogram does not follow the"
    ],
    [
        "where `x` values are on the abscissa and `y` values on the ordinate",
        "where `x` values are on the abscissa and"
    ],
    [
        "axis.  Rather, `x` is histogrammed along the first dimension of the",
        "axis. Rather, `x` is histogrammed along the first dimension"
    ],
    [
        "array (vertical), and `y` along the second dimension of the array",
        "array (vertical), and `y` along the second dimension of the"
    ],
    [
        "(horizontal).  This ensures compatibility with `histogramdd`.",
        "(horizontal). This ensures"
    ],
    [
        "Next we create a histogram H with random bin content:",
        "Next we create a histogram H with"
    ],
    [
        ":func:`imshow <matplotlib.pyplot.imshow>` can only display square bins:",
        ":func:`imshow <matplotlib.pyplot.imshow>` can only"
    ],
    [
        ":func:`pcolormesh <matplotlib.pyplot.pcolormesh>` can display actual edges:",
        ":func:`pcolormesh <matplotlib.pyplot.pcolormesh>` can"
    ],
    [
        ">>> X, Y = np.meshgrid(xedges, yedges)",
        ">>> X, Y ="
    ],
    [
        ":class:`NonUniformImage <matplotlib.image.NonUniformImage>` can be used to",
        ":class:`NonUniformImage <matplotlib.image.NonUniformImage>` can"
    ],
    [
        "display actual bin edges with interpolation:",
        "display actual bin edges"
    ],
    [
        "Now we can plot the histogram using",
        "Now we can plot the histogram"
    ],
    [
        "raise ValueError('x and y must have the same length.')",
        "raise ValueError('x and y must have the"
    ],
    [
        "hist, edges = histogramdd([x, y], bins, range, density, weights)",
        "hist, edges = histogramdd([x, y], bins, range,"
    ],
    [
        "Return the indices to access (n, n) arrays, given a masking function.",
        "Return the indices to access (n, n) arrays, given"
    ],
    [
        "Assume `mask_func` is a function that, for a square array a of size",
        "Assume `mask_func` is a function that, for a square array a"
    ],
    [
        "``(n, n)`` with a possible offset argument `k`, when called as",
        "``(n, n)`` with a possible offset argument"
    ],
    [
        "``mask_func(a, k)`` returns a new array with zeros in certain locations",
        "``mask_func(a, k)`` returns a new array with"
    ],
    [
        "(functions like `triu` or `tril` do precisely this). Then this function",
        "(functions like `triu` or `tril` do precisely this). Then this"
    ],
    [
        "returns the indices where the non-zero values would be located.",
        "returns the indices where the non-zero"
    ],
    [
        "The returned indices will be valid to access arrays of shape (n, n).",
        "The returned indices will be valid to access arrays"
    ],
    [
        "A function whose call signature is similar to that of `triu`, `tril`.",
        "A function whose call signature is similar to"
    ],
    [
        "That is, ``mask_func(x, k)`` returns a boolean array, shaped like `x`.",
        "That is, ``mask_func(x, k)`` returns a boolean"
    ],
    [
        "`k` is an optional argument to the function.",
        "`k` is an optional argument"
    ],
    [
        "An optional argument which is passed through to `mask_func`. Functions",
        "An optional argument which is"
    ],
    [
        "like `triu`, `tril` take a second argument that is interpreted as an",
        "like `triu`, `tril` take a second argument that is interpreted as"
    ],
    [
        "The `n` arrays of indices corresponding to the locations where",
        "The `n` arrays of indices corresponding"
    ],
    [
        "These are the indices that would allow you to access the upper triangular",
        "These are the indices that would allow you to access the upper"
    ],
    [
        "An offset can be passed also to the masking function.  This gets us the",
        "An offset can be passed also to the masking"
    ],
    [
        "indices starting on the first diagonal right of the main one:",
        "indices starting on the first diagonal right"
    ],
    [
        "with which we now extract only three elements:",
        "with which we now extract only three"
    ],
    [
        "Return the indices for the lower-triangle of an (n, m) array.",
        "Return the indices for the lower-triangle of an (n,"
    ],
    [
        "The row dimension of the arrays for which the returned",
        "The row dimension of the arrays for which the"
    ],
    [
        "Diagonal offset (see `tril` for details).",
        "Diagonal offset (see"
    ],
    [
        "The column dimension of the arrays for which the returned",
        "The column dimension of the arrays for"
    ],
    [
        "By default `m` is taken equal to `n`.",
        "By default `m` is"
    ],
    [
        "The row and column indices, respectively. The row indices are sorted",
        "The row and column indices, respectively."
    ],
    [
        "in non-decreasing order, and the correspdonding column indices are",
        "in non-decreasing order, and the"
    ],
    [
        "triu_indices : similar function, for upper-triangular.",
        "triu_indices : similar function, for"
    ],
    [
        "mask_indices : generic function accepting an arbitrary mask function.",
        "mask_indices : generic function accepting"
    ],
    [
        "lower triangular part starting at the main diagonal, and one starting two",
        "lower triangular part starting at the main diagonal, and one"
    ],
    [
        "Note that row indices (first array) are non-decreasing, and the corresponding",
        "Note that row indices (first array)"
    ],
    [
        "column indices (second array) are strictly increasing for each row.",
        "column indices (second array) are"
    ],
    [
        "Here is how they can be used with a sample array:",
        "Here is how they can be used with a"
    ],
    [
        "These cover almost the whole array (two diagonals right of the main one):",
        "These cover almost the whole array (two diagonals right"
    ],
    [
        "tri_ = tri(n, m, k=k, dtype=bool)",
        "tri_ = tri(n, m, k=k,"
    ],
    [
        "Return the indices for the lower-triangle of arr.",
        "Return the indices for"
    ],
    [
        "The indices will be valid for square arrays whose dimensions are",
        "The indices will be valid for square arrays"
    ],
    [
        "Diagonal offset (see `tril` for details).",
        "Diagonal offset (see `tril`"
    ],
    [
        "Pass the array to get the indices of the lower triangular elements.",
        "Pass the array to get the indices of the lower triangular"
    ],
    [
        "This is syntactic sugar for tril_indices().",
        "This is syntactic sugar for"
    ],
    [
        "Use the `k` parameter to return the indices for the lower triangular array",
        "Use the `k` parameter to return the"
    ],
    [
        "Return the indices for the upper-triangle of an (n, m) array.",
        "Return the indices for the upper-triangle of an"
    ],
    [
        "The size of the arrays for which the returned indices will",
        "The size of the arrays for which the returned"
    ],
    [
        "Diagonal offset (see `triu` for details).",
        "Diagonal offset (see `triu`"
    ],
    [
        "The column dimension of the arrays for which the returned",
        "The column dimension of the arrays for which"
    ],
    [
        "By default `m` is taken equal to `n`.",
        "By default `m` is"
    ],
    [
        "The row and column indices, respectively. The row indices are sorted",
        "The row and column indices, respectively. The"
    ],
    [
        "in non-decreasing order, and the correspdonding column indices are",
        "in non-decreasing order, and the correspdonding column indices"
    ],
    [
        "tril_indices : similar function, for lower-triangular.",
        "tril_indices : similar function, for"
    ],
    [
        "mask_indices : generic function accepting an arbitrary mask function.",
        "mask_indices : generic function accepting an"
    ],
    [
        "upper triangular part starting at the main diagonal, and one starting two",
        "upper triangular part starting at the main"
    ],
    [
        "Note that row indices (first array) are non-decreasing, and the corresponding",
        "Note that row indices (first array) are"
    ],
    [
        "column indices (second array) are strictly increasing for each row.",
        "column indices (second array) are strictly increasing"
    ],
    [
        "Here is how they can be used with a sample array:",
        "Here is how they can be used with"
    ],
    [
        "These cover only a small part of the whole array (two diagonals right",
        "These cover only a small part of the whole array (two diagonals"
    ],
    [
        "Return the indices for the upper-triangle of arr.",
        "Return the indices for the upper-triangle of"
    ],
    [
        "The indices will be valid for square arrays.",
        "The indices will be valid for"
    ],
    [
        "Diagonal offset (see `triu` for details).",
        "Diagonal offset (see `triu` for"
    ],
    [
        "Indices for the upper-triangle of `arr`.",
        "Indices for the"
    ],
    [
        "Pass the array to get the indices of the upper triangular elements.",
        "Pass the array to get the indices of the upper"
    ],
    [
        "This is syntactic sugar for triu_indices().",
        "This is syntactic"
    ],
    [
        "Use the `k` parameter to return the indices for the upper triangular array",
        "Use the `k` parameter to return the indices for the"
    ],
    [
        "A simple format for saving numpy arrays to disk with the full",
        "A simple format for saving numpy arrays to"
    ],
    [
        "The ``.npy`` format is the standard binary file format in NumPy for",
        "The ``.npy`` format is the standard binary file format in NumPy"
    ],
    [
        "persisting a *single* arbitrary NumPy array on disk. The format stores all",
        "persisting a *single* arbitrary NumPy array on disk. The"
    ],
    [
        "of the shape and dtype information necessary to reconstruct the array",
        "of the shape and dtype information necessary"
    ],
    [
        "correctly even on another machine with a different architecture.",
        "correctly even on another machine with"
    ],
    [
        "The format is designed to be as simple as possible while achieving",
        "The format is designed to be as simple as possible"
    ],
    [
        "The ``.npz`` format is the standard format for persisting *multiple* NumPy",
        "The ``.npz`` format is the standard format for persisting"
    ],
    [
        "arrays on disk. A ``.npz`` file is a zip file containing multiple ``.npy``",
        "arrays on disk. A ``.npz`` file is a zip file containing multiple"
    ],
    [
        "- Can represent all NumPy arrays including nested record arrays and",
        "- Can represent all NumPy arrays including nested"
    ],
    [
        "- Represents the data in its native binary form.",
        "- Represents the data in its native binary"
    ],
    [
        "- Stores all of the necessary information to reconstruct the array",
        "- Stores all of the necessary information"
    ],
    [
        "including shape and dtype on a machine of a different",
        "including shape and dtype on a machine of"
    ],
    [
        "architecture.  Both little-endian and big-endian arrays are",
        "architecture. Both little-endian and big-endian arrays"
    ],
    [
        "supported, and a file with little-endian numbers will yield",
        "supported, and a file with little-endian numbers will"
    ],
    [
        "a little-endian array on any machine reading the file. The",
        "a little-endian array on any machine reading the"
    ],
    [
        "types are described in terms of their actual sizes. For example,",
        "types are described in terms of their actual sizes. For"
    ],
    [
        "- Is straightforward to reverse engineer. Datasets often live longer than",
        "- Is straightforward to reverse engineer."
    ],
    [
        "the programs that created them. A competent developer should be",
        "the programs that created them."
    ],
    [
        "able to create a solution in their preferred programming language to",
        "able to create a solution in"
    ],
    [
        "read most ``.npy`` files that they have been given without much",
        "read most ``.npy`` files that they have"
    ],
    [
        "- Allows memory-mapping of the data. See `open_memmap`.",
        "- Allows memory-mapping of the"
    ],
    [
        "- Can be read from a filelike stream object instead of an actual file.",
        "- Can be read from a filelike stream object instead of"
    ],
    [
        "- Stores object arrays, i.e. arrays containing elements that are arbitrary",
        "- Stores object arrays, i.e. arrays containing elements that"
    ],
    [
        "Python objects. Files with object arrays are not to be mmapable, but",
        "Python objects. Files with object arrays are"
    ],
    [
        "can be read and written to disk.",
        "can be read and"
    ],
    [
        "- Arbitrary subclasses of numpy.ndarray are not completely preserved.",
        "- Arbitrary subclasses of numpy.ndarray"
    ],
    [
        "Subclasses will be accepted for writing, but only the array data will",
        "Subclasses will be accepted for writing, but only the array data"
    ],
    [
        "be written out. A regular numpy.ndarray object will be created",
        "be written out. A regular"
    ],
    [
        "Due to limitations in the interpretation of structured dtypes, dtypes",
        "Due to limitations in the"
    ],
    [
        "etc. Such arrays will not round-trip through the format entirely",
        "etc. Such arrays will not round-trip through the"
    ],
    [
        "accurately. The data is intact; only the field names will differ. We are",
        "accurately. The data is intact; only the field names will differ. We"
    ],
    [
        "working on a fix for this. This fix will not require a change in the",
        "working on a fix for this. This fix will not require a"
    ],
    [
        "file format. The arrays with such structures can still be saved and",
        "file format. The arrays with such structures"
    ],
    [
        "restored, and the correct dtype may be restored by using the",
        "restored, and the correct dtype may be restored by"
    ],
    [
        "We recommend using the ``.npy`` and ``.npz`` extensions for files saved",
        "We recommend using the ``.npy`` and ``.npz``"
    ],
    [
        "in this format. This is by no means a requirement; applications may wish",
        "in this format. This is by no means"
    ],
    [
        "to use these file formats but use an extension specific to the",
        "to use these file formats but use an extension specific to"
    ],
    [
        "application. In the absence of an obvious alternative, however,",
        "application. In the absence of"
    ],
    [
        "we suggest using ``.npy`` and ``.npz``.",
        "we suggest using ``.npy``"
    ],
    [
        "The version numbering of these formats is independent of NumPy version",
        "The version numbering of these formats is independent of NumPy"
    ],
    [
        "numbering. If the format is upgraded, the code in `numpy.io` will still",
        "numbering. If the format is upgraded, the code in `numpy.io`"
    ],
    [
        "to the version of the numpy package.",
        "to the version of the numpy"
    ],
    [
        "The next HEADER_LEN bytes form the header data describing the array's",
        "The next HEADER_LEN bytes form the header data"
    ],
    [
        "format. It is an ASCII string which contains a Python literal expression",
        "format. It is an ASCII string which contains a"
    ],
    [
        "of a dictionary. It is terminated by a newline (``\\\\n``) and padded with",
        "of a dictionary. It is terminated by a newline (``\\\\n``)"
    ],
    [
        "An object that can be passed as an argument to the `numpy.dtype`",
        "An object that can be passed as an argument to"
    ],
    [
        "constructor to create the array's dtype.",
        "constructor to create the array's"
    ],
    [
        "Whether the array data is Fortran-contiguous or not. Since",
        "Whether the array data is Fortran-contiguous or"
    ],
    [
        "Fortran-contiguous arrays are a common form of non-C-contiguity,",
        "Fortran-contiguous arrays are a"
    ],
    [
        "we allow them to be written directly to disk for efficiency.",
        "we allow them to be written directly to disk for"
    ],
    [
        "For repeatability and readability, the dictionary keys are sorted in",
        "For repeatability and readability, the dictionary keys"
    ],
    [
        "alphabetic order. This is for convenience only. A writer SHOULD implement",
        "alphabetic order. This is for convenience only. A"
    ],
    [
        "this if possible. A reader MUST NOT depend on this.",
        "this if possible. A reader MUST NOT depend"
    ],
    [
        "Following the header comes the array data. If the dtype contains Python",
        "Following the header comes the array data. If"
    ],
    [
        "objects (i.e. ``dtype.hasobject is True``), then the data is a Python",
        "objects (i.e. ``dtype.hasobject is True``), then"
    ],
    [
        "pickle of the array. Otherwise the data is the contiguous (either C-",
        "pickle of the array. Otherwise the"
    ],
    [
        "or Fortran-, depending on ``fortran_order``) bytes of the array.",
        "or Fortran-, depending on ``fortran_order``)"
    ],
    [
        "Consumers can figure out the number of bytes by multiplying the number",
        "Consumers can figure out the number of"
    ],
    [
        "of elements given by the shape (noting that ``shape=()`` means there is",
        "of elements given by the shape (noting"
    ],
    [
        "The description of the fourth element of the header therefore has become:",
        "The description of the fourth element of the header therefore"
    ],
    [
        "The ``.npy`` format, including motivation for creating it and a comparison of",
        "The ``.npy`` format, including motivation for creating it and a comparison"
    ],
    [
        "evolved with time and this document is more current.",
        "evolved with time and this document"
    ],
    [
        "\"\"\" Return the magic string for the given file format version.",
        "\"\"\" Return the magic string for the given file"
    ],
    [
        "ValueError if the version cannot be formatted.",
        "ValueError if the version cannot be"
    ],
    [
        "\"\"\" Read the magic string to get the version of the file format.",
        "\"\"\" Read the magic string to get the version of the"
    ],
    [
        "magic_str = _read_bytes(fp, MAGIC_LEN, \"magic string\")",
        "magic_str = _read_bytes(fp, MAGIC_LEN,"
    ],
    [
        "msg = \"the magic string is not correct; expected %r, got %r\"",
        "msg = \"the magic string is not correct; expected %r,"
    ],
    [
        "Get a serializable descriptor from the dtype.",
        "Get a serializable descriptor from"
    ],
    [
        "The .descr attribute of a dtype object cannot be round-tripped through",
        "The .descr attribute of a dtype object cannot be round-tripped"
    ],
    [
        "a descr which looks like a record array with one field with '' as",
        "a descr which looks like a record array with"
    ],
    [
        "a name. The dtype() constructor interprets this as a request to give",
        "a name. The dtype() constructor interprets"
    ],
    [
        "a default name.  Instead, we construct descriptor that can be passed to",
        "a default name. Instead, we construct descriptor that can"
    ],
    [
        "The dtype of the array that will be written to disk.",
        "The dtype of the array that will be"
    ],
    [
        "An object that can be passed to `numpy.dtype()` in order to",
        "An object that can be passed to `numpy.dtype()` in"
    ],
    [
        "warnings.warn(\"metadata on a dtype is not saved to an npy/npz. \"",
        "warnings.warn(\"metadata on a dtype is not saved to an"
    ],
    [
        "\"Use another format (such as pickle) to store it.\",",
        "\"Use another format (such as pickle)"
    ],
    [
        "warnings.warn(\"Custom dtypes are saved as python objects using the \"",
        "warnings.warn(\"Custom dtypes are saved as python objects using"
    ],
    [
        "\"pickle protocol. Loading this file requires \"",
        "\"pickle protocol. Loading this"
    ],
    [
        "Returns a dtype based off the given description.",
        "Returns a dtype based off the"
    ],
    [
        "This is essentially the reverse of `~lib.format.dtype_to_descr`. It will",
        "This is essentially the reverse of `~lib.format.dtype_to_descr`."
    ],
    [
        "remove the valueless padding fields created by, i.e. simple fields like",
        "remove the valueless padding fields created by, i.e. simple fields"
    ],
    [
        "The object retrieved by dtype.descr. Can be passed to",
        "The object retrieved by dtype.descr. Can be"
    ],
    [
        "`numpy.dtype` in order to replicate the input dtype.",
        "`numpy.dtype` in order to replicate the input"
    ],
    [
        "The dtype constructed by the description.",
        "The dtype constructed"
    ],
    [
        "is_pad = (name == '' and dt.type is numpy.void and dt.names is None)",
        "is_pad = (name == '' and dt.type"
    ],
    [
        "title, name = name if isinstance(name, tuple) else (None, name)",
        "title, name = name if isinstance(name, tuple) else (None,"
    ],
    [
        "return numpy.dtype({'names': names, 'formats': formats, 'titles': titles,",
        "return numpy.dtype({'names': names, 'formats': formats, 'titles':"
    ],
    [
        "\"\"\" Get the dictionary of header metadata from a numpy.ndarray.",
        "\"\"\" Get the dictionary of header metadata"
    ],
    [
        "This has the appropriate entries for writing its string representation",
        "This has the appropriate entries for writing its"
    ],
    [
        "to the header of the file.",
        "to the header of"
    ],
    [
        "Takes a stringified header, and attaches the prefix and padding to it",
        "Takes a stringified header, and attaches the prefix and"
    ],
    [
        "padlen = ARRAY_ALIGN - ((MAGIC_LEN + struct.calcsize(fmt) + hlen) % ARRAY_ALIGN)",
        "padlen = ARRAY_ALIGN - ((MAGIC_LEN + struct.calcsize(fmt) + hlen) %"
    ],
    [
        "header_prefix = magic(*version) + struct.pack(fmt, hlen + padlen)",
        "header_prefix = magic(*version) + struct.pack(fmt, hlen +"
    ],
    [
        "msg = \"Header length {} too big for version={}\".format(hlen, version)",
        "msg = \"Header length {} too big"
    ],
    [
        "return header_prefix + header + b' ' * padlen + b'\\n'",
        "return header_prefix + header + b' ' * padlen"
    ],
    [
        "Like `_wrap_header`, but chooses an appropriate version given the contents",
        "Like `_wrap_header`, but chooses an appropriate version given"
    ],
    [
        "\"\"\" Write the header for an array and returns the version used",
        "\"\"\" Write the header for an array and returns"
    ],
    [
        "This has the appropriate entries for writing its string representation",
        "This has the appropriate entries for writing"
    ],
    [
        "to the header of the file.",
        "to the header"
    ],
    [
        "None means use oldest that works. Providing an explicit version will",
        "None means use oldest that works."
    ],
    [
        "raise a ValueError if the format does not allow saving this data.",
        "raise a ValueError if the format does not allow"
    ],
    [
        "header.append(\"'%s': %s, \" % (key, repr(value)))",
        "header.append(\"'%s': %s, \" % (key,"
    ],
    [
        "header += \" \" * ((GROWTH_AXIS_MAX_DIGITS - len(repr(",
        "header += \" \" *"
    ],
    [
        "This has the appropriate entries for writing its string",
        "This has the appropriate entries for"
    ],
    [
        "representation to the header of the file.",
        "representation to the header"
    ],
    [
        "This has the appropriate entries for writing its string",
        "This has the appropriate entries for"
    ],
    [
        "representation to the header of the file.",
        "representation to the header"
    ],
    [
        "This will leave the file object located just after the header.",
        "This will leave the file object located just after the"
    ],
    [
        "A file object or something with a `.read()` method like a file.",
        "A file object or something with"
    ],
    [
        "The array data will be written out directly if it is either",
        "The array data will be written out directly if"
    ],
    [
        "C-contiguous or Fortran-contiguous. Otherwise, it will be made",
        "C-contiguous or Fortran-contiguous. Otherwise, it will"
    ],
    [
        "The dtype of the file's data.",
        "The dtype of"
    ],
    [
        "Maximum allowed size of the header.  Large headers may not be safe",
        "Maximum allowed size of the header. Large headers may not"
    ],
    [
        "to load securely and thus require explicitly passing a larger value.",
        "to load securely and thus require"
    ],
    [
        "This will leave the file object located just after the header.",
        "This will leave the file object located"
    ],
    [
        "A file object or something with a `.read()` method like a file.",
        "A file object or something with a `.read()` method"
    ],
    [
        "Maximum allowed size of the header.  Large headers may not be safe",
        "Maximum allowed size of the header. Large headers may"
    ],
    [
        "to load securely and thus require explicitly passing a larger value.",
        "to load securely and thus require explicitly passing a larger"
    ],
    [
        "The array data will be written out directly if it is either",
        "The array data will be written out directly if it is"
    ],
    [
        "C-contiguous or Fortran-contiguous. Otherwise, it will be made",
        "C-contiguous or Fortran-contiguous. Otherwise, it"
    ],
    [
        "The dtype of the file's data.",
        "The dtype of"
    ],
    [
        "\"\"\"Clean up 'L' in npz header ints.",
        "\"\"\"Clean up 'L' in"
    ],
    [
        "Cleans up the 'L' in strings representing integers. Needed to allow npz",
        "Cleans up the 'L' in strings"
    ],
    [
        "hlength_str = _read_bytes(fp, struct.calcsize(hlength_type), \"array header length\")",
        "hlength_str = _read_bytes(fp, struct.calcsize(hlength_type),"
    ],
    [
        "header = _read_bytes(fp, header_length, \"array header\")",
        "header = _read_bytes(fp, header_length, \"array"
    ],
    [
        "f\"Header info length ({len(header)}) is large and may not be safe \"",
        "f\"Header info length ({len(header)}) is large and"
    ],
    [
        "\"To allow loading, adjust `max_header_size` or fully trust \"",
        "\"To allow loading, adjust `max_header_size`"
    ],
    [
        "\"For safety against large resource use or crashes, sandboxing \"",
        "\"For safety against large resource use or"
    ],
    [
        "msg = \"Cannot parse header: {!r}\"",
        "msg = \"Cannot"
    ],
    [
        "\"Reading `.npy` or `.npz` file required additional \"",
        "\"Reading `.npy` or `.npz` file"
    ],
    [
        "\"file again to speed up loading and avoid this warning.\",",
        "\"file again to speed up loading"
    ],
    [
        "msg = \"Cannot parse header: {!r}\"",
        "msg = \"Cannot parse header:"
    ],
    [
        "msg = \"Header is not a dictionary: {!r}\"",
        "msg = \"Header is"
    ],
    [
        "msg = \"Header does not contain the correct keys: {!r}\"",
        "msg = \"Header does not contain"
    ],
    [
        "not all(isinstance(x, int) for x in d['shape'])):",
        "not all(isinstance(x, int) for x in"
    ],
    [
        "msg = \"shape is not valid: {!r}\"",
        "msg = \"shape is"
    ],
    [
        "msg = \"fortran_order is not a valid bool: {!r}\"",
        "msg = \"fortran_order is not"
    ],
    [
        "msg = \"descr is not a valid dtype descriptor: {!r}\"",
        "msg = \"descr is not a valid dtype descriptor:"
    ],
    [
        "def write_array(fp, array, version=None, allow_pickle=True, pickle_kwargs=None):",
        "def write_array(fp, array, version=None,"
    ],
    [
        "Write an array to an NPY file, including a header.",
        "Write an array to an NPY file,"
    ],
    [
        "If the array is neither C-contiguous nor Fortran-contiguous AND the",
        "If the array is neither C-contiguous"
    ],
    [
        "file_like object is not a real file object, this function will have to",
        "file_like object is not a real file object, this function will"
    ],
    [
        "An open, writable file object, or similar object with a",
        "An open, writable file object, or similar"
    ],
    [
        "The array to write to disk.",
        "The array to"
    ],
    [
        "version : (int, int) or None, optional",
        "version : (int, int) or"
    ],
    [
        "The version number of the format. None means use the oldest",
        "The version number of the format. None"
    ],
    [
        "supported version that is able to store the data.  Default: None",
        "supported version that is able to store"
    ],
    [
        "Whether to allow writing pickled data. Default: True",
        "Whether to allow writing"
    ],
    [
        "Additional keyword arguments to pass to pickle.dump, excluding",
        "Additional keyword arguments to"
    ],
    [
        "'protocol'. These are only useful when pickling objects in object",
        "'protocol'. These are only useful when"
    ],
    [
        "If the array cannot be persisted. This includes the case of",
        "If the array cannot be persisted."
    ],
    [
        "allow_pickle=False and array being an object array.",
        "allow_pickle=False and array being"
    ],
    [
        "If the array contains Python objects as part of its dtype, the",
        "If the array contains Python objects as part of"
    ],
    [
        "process of pickling them may raise various errors if the objects",
        "process of pickling them may raise various errors"
    ],
    [
        "raise ValueError(\"Object arrays cannot be saved when \"",
        "raise ValueError(\"Object arrays cannot"
    ],
    [
        "raise ValueError(\"User-defined dtypes cannot be saved \"",
        "raise ValueError(\"User-defined dtypes cannot be"
    ],
    [
        "Read an array from an NPY file.",
        "Read an array from"
    ],
    [
        "If this is not a real file object, then this may take extra memory",
        "If this is not a real file object, then this"
    ],
    [
        "Whether to allow writing pickled data. Default: False",
        "Whether to allow writing pickled data. Default:"
    ],
    [
        "Additional keyword arguments to pass to pickle.load. These are only",
        "Additional keyword arguments to pass to pickle.load."
    ],
    [
        "Maximum allowed size of the header.  Large headers may not be safe",
        "Maximum allowed size of the header. Large headers may not be"
    ],
    [
        "to load securely and thus require explicitly passing a larger value.",
        "to load securely and thus require explicitly"
    ],
    [
        "This option is ignored when `allow_pickle` is passed.  In that case",
        "This option is ignored when `allow_pickle` is passed. In that"
    ],
    [
        "the file is by definition trusted and the limit is unnecessary.",
        "the file is by definition trusted"
    ],
    [
        "The array from the data on disk.",
        "The array from the data on"
    ],
    [
        "If the data is invalid, or allow_pickle=False and the file contains",
        "If the data is invalid, or allow_pickle=False"
    ],
    [
        "raise ValueError(\"Object arrays cannot be loaded when \"",
        "raise ValueError(\"Object arrays cannot"
    ],
    [
        "raise UnicodeError(\"Unpickling a python object failed: %r\\n\"",
        "raise UnicodeError(\"Unpickling a python object failed:"
    ],
    [
        "\"You may need to pass the encoding= option \"",
        "\"You may need to pass the encoding= option"
    ],
    [
        "\"to numpy.load\" % (err,)) from err",
        "\"to numpy.load\" % (err,)) from"
    ],
    [
        "max_read_count = BUFFER_SIZE // min(BUFFER_SIZE, dtype.itemsize)",
        "max_read_count = BUFFER_SIZE // min(BUFFER_SIZE,"
    ],
    [
        "read_count = min(max_read_count, count - i)",
        "read_count = min(max_read_count, count -"
    ],
    [
        "data = _read_bytes(fp, read_size, \"array data\")",
        "data = _read_bytes(fp,"
    ],
    [
        "array[i:i + read_count] = numpy.frombuffer(data, dtype=dtype,",
        "array[i:i + read_count] = numpy.frombuffer(data,"
    ],
    [
        "Open a .npy file as a memory-mapped array.",
        "Open a .npy file as a memory-mapped"
    ],
    [
        "This may be used to read an existing file or create a new one.",
        "This may be used to read an"
    ],
    [
        "The name of the file on disk.  This may *not* be a file-like",
        "The name of the file on disk."
    ],
    [
        "The mode in which to open the file; the default is 'r+'.  In",
        "The mode in which to open the file; the default"
    ],
    [
        "addition to the standard file modes, 'c' is also accepted to mean",
        "addition to the standard file modes, 'c' is also accepted"
    ],
    [
        "\"copy on write.\"  See `memmap` for the available mode strings.",
        "\"copy on write.\" See `memmap`"
    ],
    [
        "The data type of the array if we are creating a new file in \"write\"",
        "The data type of the array if we are creating a"
    ],
    [
        "mode, if not, `dtype` is ignored.  The default value is None, which",
        "mode, if not, `dtype` is ignored. The default"
    ],
    [
        "The shape of the array if we are creating a new file in \"write\"",
        "The shape of the array if we"
    ],
    [
        "mode, in which case this parameter is required.  Otherwise, this",
        "mode, in which case this parameter is required. Otherwise,"
    ],
    [
        "parameter is ignored and is thus optional.",
        "parameter is ignored and is"
    ],
    [
        "Whether the array should be Fortran-contiguous (True) or",
        "Whether the array should be"
    ],
    [
        "C-contiguous (False, the default) if we are creating a new file in",
        "C-contiguous (False, the default) if we are creating a new file"
    ],
    [
        "version : tuple of int (major, minor) or None",
        "version : tuple of int (major, minor)"
    ],
    [
        "If the mode is a \"write\" mode, then this is the version of the file",
        "If the mode is a \"write\" mode, then this is"
    ],
    [
        "format used to create the file.  None means use the oldest",
        "format used to create the file. None means"
    ],
    [
        "supported version that is able to store the data.  Default: None",
        "supported version that is able to"
    ],
    [
        "Maximum allowed size of the header.  Large headers may not be safe",
        "Maximum allowed size of the header. Large headers may not be"
    ],
    [
        "to load securely and thus require explicitly passing a larger value.",
        "to load securely and thus require"
    ],
    [
        "If the data or the mode is invalid.",
        "If the data or the mode"
    ],
    [
        "If the file is not found or cannot be opened correctly.",
        "If the file is not found or cannot"
    ],
    [
        "raise ValueError(\"Filename must be a string or a path-like object.\"",
        "raise ValueError(\"Filename must be a string or"
    ],
    [
        "\"  Memmap cannot use existing file handles.\")",
        "\" Memmap cannot use existing file"
    ],
    [
        "msg = \"Array can't be memory-mapped: Python objects in dtype.\"",
        "msg = \"Array can't be memory-mapped: Python objects"
    ],
    [
        "with open(os.fspath(filename), mode + 'b') as fp:",
        "with open(os.fspath(filename), mode + 'b') as"
    ],
    [
        "msg = \"Array can't be memory-mapped: Python objects in dtype.\"",
        "msg = \"Array can't be"
    ],
    [
        "marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,",
        "marray = numpy.memmap(filename, dtype=dtype,"
    ],
    [
        "def _read_bytes(fp, size, error_template=\"ran out of data\"):",
        "def _read_bytes(fp, size, error_template=\"ran out of"
    ],
    [
        "Read from file-like object until size bytes are read.",
        "Read from file-like object until size bytes"
    ],
    [
        "Raises ValueError if not EOF is encountered before size bytes are read.",
        "Raises ValueError if not EOF is"
    ],
    [
        "Non-blocking objects only supported if they derive from io objects.",
        "Non-blocking objects only supported if"
    ],
    [
        "msg = \"EOF: reading %s, expected %d bytes got %d\"",
        "msg = \"EOF: reading %s, expected %d"
    ],
    [
        "raise ValueError(msg % (error_template, size, len(data)))",
        "raise ValueError(msg % (error_template, size,"
    ],
    [
        "if not isinstance(f, (io.FileIO, io.BufferedReader, io.BufferedWriter)):",
        "if not isinstance(f, (io.FileIO,"
    ],
    [
        "ones, zeros_like, arange, concatenate, array, asarray, asanyarray, empty,",
        "ones, zeros_like, arange, concatenate, array, asarray, asanyarray,"
    ],
    [
        "ndarray, take, dot, where, intp, integer, isscalar, absolute",
        "ndarray, take, dot, where, intp,"
    ],
    [
        "ravel, nonzero, partition, mean, any, sum",
        "ravel, nonzero, partition,"
    ],
    [
        "interp as compiled_interp, interp_complex as compiled_interp_complex",
        "interp as compiled_interp,"
    ],
    [
        "'select', 'piecewise', 'trim_zeros', 'copy', 'iterable', 'percentile',",
        "'select', 'piecewise', 'trim_zeros',"
    ],
    [
        "'diff', 'gradient', 'angle', 'unwrap', 'sort_complex', 'flip',",
        "'diff', 'gradient', 'angle',"
    ],
    [
        "'get_virtual_index': lambda n, quantiles: _inverted_cdf(n, quantiles),",
        "'get_virtual_index': lambda n, quantiles: _inverted_cdf(n,"
    ],
    [
        "Rotation direction is from the first towards the second axis.",
        "Rotation direction is from the first towards"
    ],
    [
        "Array of two or more dimensions.",
        "Array of two or more"
    ],
    [
        "The array is rotated in the plane defined by the axes.",
        "The array is rotated in the plane defined by the"
    ],
    [
        "flip : Reverse the order of elements in an array along the given axis.",
        "flip : Reverse the order of elements"
    ],
    [
        "fliplr : Flip an array horizontally.",
        "fliplr : Flip an array"
    ],
    [
        "flipud : Flip an array vertically.",
        "flipud : Flip an"
    ],
    [
        "raise ValueError(\"Axes={} out of range for array of ndim={}.\"",
        "raise ValueError(\"Axes={} out of range for"
    ],
    [
        "Reverse the order of elements in an array along the given axis.",
        "Reverse the order of elements in an array along the"
    ],
    [
        "The shape of the array is preserved, but the elements are reordered.",
        "The shape of the array is"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int"
    ],
    [
        "Axis or axes along which to flip over. The default,",
        "Axis or axes along which to flip"
    ],
    [
        "axis=None, will flip over all of the axes of the input array.",
        "axis=None, will flip over all of the axes of"
    ],
    [
        "If axis is negative it counts from the last to the first axis.",
        "If axis is negative it counts from the last"
    ],
    [
        "If axis is a tuple of ints, flipping is performed on all of the axes",
        "If axis is a tuple of ints, flipping is performed on all"
    ],
    [
        "A view of `m` with the entries of axis reversed.  Since a view is",
        "A view of `m` with the entries of axis reversed."
    ],
    [
        "returned, this operation is done in constant time.",
        "returned, this operation is done in"
    ],
    [
        "Check whether or not an object can be iterated over.",
        "Check whether or not an"
    ],
    [
        "Return ``True`` if the object has an iterator method or is a",
        "Return ``True`` if the object has an iterator method"
    ],
    [
        "In most cases, the results of ``np.iterable(obj)`` are consistent with",
        "In most cases, the results of ``np.iterable(obj)``"
    ],
    [
        "``isinstance(obj, collections.abc.Iterable)``. One notable exception is",
        "``isinstance(obj, collections.abc.Iterable)``. One"
    ],
    [
        "We assume, weights is not None.",
        "We assume, weights"
    ],
    [
        "\"Axis must be specified when shapes of a and weights \"",
        "\"Axis must be specified when shapes of"
    ],
    [
        "if wgt.shape != tuple(a.shape[ax] for ax in axis):",
        "if wgt.shape != tuple(a.shape[ax] for ax"
    ],
    [
        "\"Shape of weights must be consistent with \"",
        "\"Shape of weights must be"
    ],
    [
        "\"shape of a along specified axis.\")",
        "\"shape of a along"
    ],
    [
        "def _average_dispatcher(a, axis=None, weights=None, returned=None, *,",
        "def _average_dispatcher(a, axis=None, weights=None,"
    ],
    [
        "def average(a, axis=None, weights=None, returned=False, *,",
        "def average(a, axis=None,"
    ],
    [
        "Compute the weighted average along the specified axis.",
        "Compute the weighted average along the"
    ],
    [
        "Array containing data to be averaged. If `a` is not an array, a",
        "Array containing data to be averaged. If `a` is not an"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple"
    ],
    [
        "Axis or axes along which to average `a`.  The default,",
        "Axis or axes along which to average"
    ],
    [
        "`axis=None`, will average over all of the elements of the input array.",
        "`axis=None`, will average over all of the"
    ],
    [
        "If axis is negative it counts from the last to the first axis.",
        "If axis is negative it counts from the"
    ],
    [
        "If axis is a tuple of ints, averaging is performed on all of the axes",
        "If axis is a tuple of ints, averaging"
    ],
    [
        "specified in the tuple instead of a single axis or all the axes as",
        "specified in the tuple instead of a"
    ],
    [
        "An array of weights associated with the values in `a`. Each value in",
        "An array of weights associated with the values in `a`. Each"
    ],
    [
        "`a` contributes to the average according to its associated weight.",
        "`a` contributes to the average according to its"
    ],
    [
        "The array of weights must be the same shape as `a` if no axis is",
        "The array of weights must be the same shape as `a`"
    ],
    [
        "specified, otherwise the weights must have dimensions and shape",
        "specified, otherwise the weights must"
    ],
    [
        "consistent with `a` along the specified axis.",
        "consistent with `a` along the specified"
    ],
    [
        "If `weights=None`, then all data in `a` are assumed to have a",
        "If `weights=None`, then all data in `a` are assumed"
    ],
    [
        "avg = sum(a * weights) / sum(weights)",
        "avg = sum(a * weights)"
    ],
    [
        "where the sum is over all included elements.",
        "where the sum is over all included"
    ],
    [
        "The only constraint on the values of `weights` is that `sum(weights)`",
        "The only constraint on the values of `weights`"
    ],
    [
        "Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)",
        "Default is `False`. If `True`,"
    ],
    [
        "is returned, otherwise only the average is returned.",
        "is returned, otherwise only the average is"
    ],
    [
        "If `weights=None`, `sum_of_weights` is equivalent to the number of",
        "If `weights=None`, `sum_of_weights` is equivalent to the number"
    ],
    [
        "elements over which the average is taken.",
        "elements over which the average is"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With this"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly against the original"
    ],
    [
        "*Note:* `keepdims` will not work with instances of `numpy.matrix`",
        "*Note:* `keepdims` will not work with instances of"
    ],
    [
        "or other classes whose methods do not support `keepdims`.",
        "or other classes whose methods do not"
    ],
    [
        "retval, [sum_of_weights] : array_type or double",
        "retval, [sum_of_weights] : array_type or"
    ],
    [
        "Return the average along the specified axis. When `returned` is `True`,",
        "Return the average along the specified axis. When `returned` is"
    ],
    [
        "return a tuple with the average as the first element and the sum",
        "return a tuple with the average as the first element and"
    ],
    [
        "of the weights as the second element. `sum_of_weights` is of the",
        "of the weights as the second element. `sum_of_weights` is of"
    ],
    [
        "same type as `retval`. The result dtype follows a general pattern.",
        "same type as `retval`. The result dtype follows"
    ],
    [
        "if `a` is integral. Otherwise, if `weights` is not None and `a` is non-",
        "if `a` is integral. Otherwise, if `weights` is not None and"
    ],
    [
        "integral, the result type will be the type of lowest precision capable of",
        "integral, the result type will be the type of lowest precision"
    ],
    [
        "representing values of both `a` and `weights`. If `a` happens to be",
        "representing values of both `a` and"
    ],
    [
        "integral, the previous rules still applies but the result dtype will",
        "integral, the previous rules still applies but"
    ],
    [
        "When all weights along axis are zero. See `numpy.ma.average` for a",
        "When all weights along axis are zero. See `numpy.ma.average` for"
    ],
    [
        "version robust to this type of error.",
        "version robust to this type"
    ],
    [
        "When `weights` does not have the same shape as `a`, and `axis=None`.",
        "When `weights` does not have the same shape as"
    ],
    [
        "When `weights` does not have dimensions and shape consistent with `a`",
        "When `weights` does not have dimensions and shape"
    ],
    [
        "ma.average : average for masked arrays -- useful if your data contains",
        "ma.average : average for masked arrays -- useful if"
    ],
    [
        "numpy.result_type : Returns the type that results from applying the",
        "numpy.result_type : Returns the type that results from"
    ],
    [
        "numpy type promotion rules to the arguments.",
        "numpy type promotion rules to the"
    ],
    [
        "TypeError: Axis must be specified when shapes of a and weights differ.",
        "TypeError: Axis must be specified when shapes"
    ],
    [
        "ValueError: Shape of weights must be consistent",
        "ValueError: Shape of weights must be"
    ],
    [
        "with shape of a along specified axis.",
        "with shape of a"
    ],
    [
        "\"Weights sum to zero, can't be normalized\")",
        "\"Weights sum to zero,"
    ],
    [
        "avg = avg_as_array = np.multiply(a, wgt,",
        "avg = avg_as_array = np.multiply(a,"
    ],
    [
        "\"\"\"Convert the input to an array, checking for NaNs or Infs.",
        "\"\"\"Convert the input to an array, checking"
    ],
    [
        "Input data, in any form that can be converted to an array.  This",
        "Input data, in any form that can be converted"
    ],
    [
        "includes lists, lists of tuples, tuples, tuples of tuples, tuples",
        "includes lists, lists of tuples, tuples, tuples of"
    ],
    [
        "of lists and ndarrays.  Success requires no NaNs or Infs.",
        "of lists and ndarrays. Success requires no NaNs"
    ],
    [
        "By default, the data-type is inferred from the input data.",
        "By default, the data-type is"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A',"
    ],
    [
        "Memory layout.  'A' and 'K' depend on the order of input array a.",
        "Memory layout. 'A' and 'K' depend on the"
    ],
    [
        "'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise",
        "'A' (any) means 'F' if `a` is Fortran"
    ],
    [
        "Array interpretation of `a`.  No copy is performed if the input",
        "Array interpretation of `a`. No copy is performed if"
    ],
    [
        "is already an ndarray.  If `a` is a subclass of ndarray, a base",
        "is already an ndarray. If `a` is a"
    ],
    [
        "Raises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).",
        "Raises ValueError if `a` contains NaN (Not"
    ],
    [
        "asanyarray : Similar function which passes through subclasses.",
        "asanyarray : Similar function which"
    ],
    [
        "ascontiguousarray : Convert input to a contiguous array.",
        "ascontiguousarray : Convert input"
    ],
    [
        "asfortranarray : Convert input to an ndarray with column-major",
        "asfortranarray : Convert input to an"
    ],
    [
        "fromiter : Create an array from an iterator.",
        "fromiter : Create an array from an"
    ],
    [
        "fromfunction : Construct an array by executing a function on grid",
        "fromfunction : Construct an array by"
    ],
    [
        "Convert a list into an array. If all elements are finite, then",
        "Convert a list into an array. If all elements are finite,"
    ],
    [
        "Raises ValueError if array_like contains Nans or Infs.",
        "Raises ValueError if array_like contains Nans"
    ],
    [
        "if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():",
        "if a.dtype.char in typecodes['AllFloat'] and"
    ],
    [
        "\"array must not contain infs or NaNs\")",
        "\"array must not contain"
    ],
    [
        "def _piecewise_dispatcher(x, condlist, funclist, *args, **kw):",
        "def _piecewise_dispatcher(x, condlist, funclist, *args,"
    ],
    [
        "def piecewise(x, condlist, funclist, *args, **kw):",
        "def piecewise(x, condlist,"
    ],
    [
        "Given a set of conditions and corresponding functions, evaluate each",
        "Given a set of conditions and"
    ],
    [
        "function on the input data wherever its condition is true.",
        "function on the input data"
    ],
    [
        "condlist : list of bool arrays or bool scalars",
        "condlist : list of bool arrays or bool"
    ],
    [
        "Each boolean array corresponds to a function in `funclist`.  Wherever",
        "Each boolean array corresponds to a function in"
    ],
    [
        "`condlist[i]` is True, `funclist[i](x)` is used as the output value.",
        "`condlist[i]` is True, `funclist[i](x)` is used as"
    ],
    [
        "Each boolean array in `condlist` selects a piece of `x`,",
        "Each boolean array in `condlist` selects"
    ],
    [
        "and should therefore be of the same shape as `x`.",
        "and should therefore be of the same"
    ],
    [
        "The length of `condlist` must correspond to that of `funclist`.",
        "The length of `condlist` must correspond to that of"
    ],
    [
        "If one extra function is given, i.e. if",
        "If one extra function is given,"
    ],
    [
        "is the default value, used wherever all conditions are false.",
        "is the default value, used wherever all conditions"
    ],
    [
        "funclist : list of callables, f(x,*args,**kw), or scalars",
        "funclist : list of"
    ],
    [
        "Each function is evaluated over `x` wherever its corresponding",
        "Each function is evaluated over `x` wherever"
    ],
    [
        "array or a scalar value as output.  If, instead of a callable,",
        "array or a scalar value as"
    ],
    [
        "a scalar is provided then a constant function (``lambda x: scalar``) is",
        "a scalar is provided then a constant function (``lambda"
    ],
    [
        "Any further arguments given to `piecewise` are passed to the functions",
        "Any further arguments given to `piecewise` are passed"
    ],
    [
        "Keyword arguments used in calling `piecewise` are passed to the",
        "Keyword arguments used in calling `piecewise` are"
    ],
    [
        "functions upon execution, i.e., if called",
        "functions upon execution, i.e., if"
    ],
    [
        "The output is the same shape and type as x and is found by",
        "The output is the same shape and type as x and is found"
    ],
    [
        "calling the functions in `funclist` on the appropriate portions of `x`,",
        "calling the functions in `funclist` on the appropriate portions"
    ],
    [
        "as defined by the boolean arrays in `condlist`.  Portions not covered",
        "as defined by the boolean arrays in `condlist`."
    ],
    [
        "This is similar to choose or select, except that functions are",
        "This is similar to choose or"
    ],
    [
        "evaluated on elements of `x` that satisfy the corresponding condition from",
        "evaluated on elements of `x` that satisfy"
    ],
    [
        "Apply the same function to a scalar value.",
        "Apply the same function"
    ],
    [
        "\"with {} condition(s), either {} or {} functions are expected\"",
        "\"with {} condition(s), either {} or {} functions are"
    ],
    [
        "for cond, func in zip(condlist, funclist):",
        "for cond, func"
    ],
    [
        "Return an array drawn from elements in choicelist, depending on conditions.",
        "Return an array drawn from elements in choicelist, depending"
    ],
    [
        "condlist : list of bool ndarrays",
        "condlist : list of bool"
    ],
    [
        "The list of conditions which determine from which array in `choicelist`",
        "The list of conditions which determine from which array in"
    ],
    [
        "the output elements are taken. When multiple conditions are satisfied,",
        "the output elements are taken."
    ],
    [
        "the first one encountered in `condlist` is used.",
        "the first one encountered in `condlist` is"
    ],
    [
        "The list of arrays from which the output elements are taken. It has",
        "The list of arrays from which the output elements are"
    ],
    [
        "to be of the same length as `condlist`.",
        "to be of the same"
    ],
    [
        "The element inserted in `output` when all conditions evaluate to False.",
        "The element inserted in `output` when all conditions evaluate"
    ],
    [
        "The output at position m is the m-th element of the array in",
        "The output at position m is the m-th element"
    ],
    [
        "`choicelist` where the m-th element of the corresponding array in",
        "`choicelist` where the m-th element of the corresponding array"
    ],
    [
        "where : Return elements from one of two arrays depending on condition.",
        "where : Return elements from one of"
    ],
    [
        "are squared, and elements not meeting either of these conditions",
        "are squared, and elements not meeting"
    ],
    [
        "When multiple conditions are satisfied, the first one encountered in",
        "When multiple conditions are satisfied, the first one"
    ],
    [
        "'list of cases must be same length as list of conditions')",
        "'list of cases must be same length as"
    ],
    [
        "raise ValueError(\"select with an empty condition list is not possible\")",
        "raise ValueError(\"select with an empty condition list is"
    ],
    [
        "choice if type(choice) in (int, float, complex) else np.asarray(choice)",
        "choice if type(choice) in (int,"
    ],
    [
        "choicelist.append(default if type(default) in (int, float, complex)",
        "choicelist.append(default if type(default) in (int, float,"
    ],
    [
        "msg = f'Choicelist and default value do not have a common dtype: {e}'",
        "msg = f'Choicelist and default value do not have a common dtype:"
    ],
    [
        "'invalid entry {} in condlist: should be boolean ndarray'.format(i))",
        "'invalid entry {} in condlist: should"
    ],
    [
        "for choice, cond in zip(choicelist, condlist):",
        "for choice, cond"
    ],
    [
        "Return an array copy of the given object.",
        "Return an array copy of the given"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F', 'A',"
    ],
    [
        "Controls the memory layout of the copy. 'C' means C-order,",
        "Controls the memory layout of the copy."
    ],
    [
        "'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,",
        "'F' means F-order, 'A' means 'F' if `a` is"
    ],
    [
        "'C' otherwise. 'K' means match the layout of `a` as closely",
        "'C' otherwise. 'K' means match the layout of `a` as"
    ],
    [
        "as possible. (Note that this function and :meth:`ndarray.copy` are very",
        "as possible. (Note that this function and :meth:`ndarray.copy` are"
    ],
    [
        "similar, but have different default values for their order=",
        "similar, but have different default values for their"
    ],
    [
        "If True, then sub-classes will be passed-through, otherwise the",
        "If True, then sub-classes will be passed-through,"
    ],
    [
        "returned array will be forced to be a base-class array (defaults to False).",
        "returned array will be forced to be a base-class array (defaults"
    ],
    [
        "ndarray.copy : Preferred method for creating an array copy",
        "ndarray.copy : Preferred method for"
    ],
    [
        "The copy made of the data is shallow, i.e., for arrays with object dtype,",
        "The copy made of the data is shallow, i.e.,"
    ],
    [
        "the new array will point to the same objects.",
        "the new array will point to"
    ],
    [
        "Create an array x, with a reference y and a copy z:",
        "Create an array x, with a"
    ],
    [
        "Note that, when we modify x, y changes, but not z:",
        "Note that, when we modify x, y changes, but"
    ],
    [
        "Note that, np.copy clears previously set WRITEABLE=False flag.",
        "Note that, np.copy clears previously set WRITEABLE=False"
    ],
    [
        "Return the gradient of an N-dimensional array.",
        "Return the gradient of"
    ],
    [
        "The gradient is computed using second order accurate central differences",
        "The gradient is computed using"
    ],
    [
        "in the interior points and either first or second order accurate one-sides",
        "in the interior points and either first or"
    ],
    [
        "(forward or backwards) differences at the boundaries.",
        "(forward or backwards) differences"
    ],
    [
        "The returned gradient hence has the same shape as the input array.",
        "The returned gradient hence has the"
    ],
    [
        "An N-dimensional array containing samples of a scalar function.",
        "An N-dimensional array containing samples"
    ],
    [
        "varargs : list of scalar or array, optional",
        "varargs : list of scalar or array,"
    ],
    [
        "Spacing between f values. Default unitary spacing for all dimensions.",
        "Spacing between f values. Default unitary spacing for all"
    ],
    [
        "dimension of F. The length of the array must match the size of",
        "dimension of F. The length of the array must match the size"
    ],
    [
        "If `axis` is given, the number of varargs must equal the number of axes specified in the axis parameter.",
        "If `axis` is given, the number of varargs must equal the number of axes specified in"
    ],
    [
        "Gradient is calculated using N-th order accurate differences",
        "Gradient is calculated using N-th order"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple of"
    ],
    [
        "Gradient is calculated only along the given axis or axes",
        "Gradient is calculated only along the given axis"
    ],
    [
        "The default (axis = None) is to calculate the gradient for all the axes",
        "The default (axis = None) is to"
    ],
    [
        "of the input array. axis may be negative, in which case it counts from",
        "of the input array. axis may be negative, in"
    ],
    [
        "the last to the first axis.",
        "the last to the"
    ],
    [
        "gradient : ndarray or tuple of ndarray",
        "gradient : ndarray or tuple"
    ],
    [
        "A tuple of ndarrays (or a single ndarray if there is only one",
        "A tuple of ndarrays (or a single"
    ],
    [
        "dimension) corresponding to the derivatives of f with respect",
        "dimension) corresponding to the derivatives of f with"
    ],
    [
        "to each dimension. Each derivative has the same shape as f.",
        "to each dimension. Each derivative has the same"
    ],
    [
        "Spacing can be also specified with an array that represents the coordinates",
        "Spacing can be also specified with"
    ],
    [
        "of the values F along the dimensions.",
        "of the values F along the"
    ],
    [
        "For two dimensional arrays, the return will be two arrays ordered by",
        "For two dimensional arrays, the return will"
    ],
    [
        "axis. In this example the first array stands for the gradient in",
        "axis. In this example the first array stands for the"
    ],
    [
        "rows and the second one in columns direction:",
        "rows and the second"
    ],
    [
        "In this example the spacing is also specified:",
        "In this example the"
    ],
    [
        "It is possible to specify how boundaries are treated using `edge_order`",
        "It is possible to specify how boundaries are treated"
    ],
    [
        "The `axis` keyword can be used to specify a subset of axes of which the",
        "The `axis` keyword can be used to specify a subset of axes of which"
    ],
    [
        "The `varargs` argument defines the spacing between sample points in the",
        "The `varargs` argument defines the spacing between"
    ],
    [
        "input array. It can take two forms:",
        "input array. It can"
    ],
    [
        "It's possible to provide different data for spacing along each dimension.",
        "It's possible to provide different data for"
    ],
    [
        "The number of arguments must match the number of dimensions in the input",
        "The number of arguments must match the"
    ],
    [
        ">>> xs, ys = np.meshgrid(x, y)",
        ">>> xs, ys"
    ],
    [
        "Mixing scalars and arrays is also allowed:",
        "Mixing scalars and arrays"
    ],
    [
        "derivatives) and let :math:`h_{*}` be a non-homogeneous stepsize, we",
        "derivatives) and let :math:`h_{*}` be"
    ],
    [
        "minimize the \"consistency error\" :math:`\\\\eta_{i}` between the true gradient",
        "minimize the \"consistency error\" :math:`\\\\eta_{i}` between the"
    ],
    [
        "and its estimate from a linear combination of the neighboring grid-points:",
        "and its estimate from a linear"
    ],
    [
        "By substituting :math:`f(x_{i} + h_{d})` and :math:`f(x_{i} - h_{s})`",
        "By substituting :math:`f(x_{i} + h_{d})`"
    ],
    [
        "with their Taylor series expansion, this translates into solving",
        "with their Taylor series expansion, this translates into"
    ],
    [
        "It is worth noting that if :math:`h_{s}=h_{d}`",
        "It is worth noting that if"
    ],
    [
        "we find the standard second order approximation:",
        "we find the standard second order"
    ],
    [
        "With a similar procedure the forward/backward approximations used for",
        "With a similar procedure the forward/backward approximations"
    ],
    [
        "(Texts in Applied Mathematics). New York: Springer.",
        "(Texts in Applied Mathematics). New York:"
    ],
    [
        "in Geophysical Fluid Dynamics. New York: Springer.",
        "in Geophysical Fluid Dynamics. New"
    ],
    [
        "\"the length of the corresponding dimension\")",
        "\"the length of the corresponding"
    ],
    [
        "for axis, ax_dx in zip(axes, dx):",
        "for axis, ax_dx"
    ],
    [
        "\"Shape of array too small to calculate a numerical gradient, \"",
        "\"Shape of array too small to calculate a"
    ],
    [
        "a.shape = b.shape = c.shape = shape",
        "a.shape = b.shape = c.shape ="
    ],
    [
        "def _diff_dispatcher(a, n=None, axis=None, prepend=None, append=None):",
        "def _diff_dispatcher(a, n=None, axis=None,"
    ],
    [
        "Calculate the n-th discrete difference along the given axis.",
        "Calculate the n-th discrete difference"
    ],
    [
        "the given axis, higher differences are calculated by using `diff`",
        "the given axis, higher differences"
    ],
    [
        "The number of times values are differenced. If zero, the input",
        "The number of times values are differenced. If zero,"
    ],
    [
        "The axis along which the difference is taken, default is the",
        "The axis along which the difference"
    ],
    [
        "Values to prepend or append to `a` along axis prior to",
        "Values to prepend or append to"
    ],
    [
        "performing the difference.  Scalar values are expanded to",
        "performing the difference. Scalar values are"
    ],
    [
        "of the input array in along all other axes.  Otherwise the",
        "of the input array in along all other axes."
    ],
    [
        "dimension and shape must match `a` except along axis.",
        "dimension and shape must match `a` except"
    ],
    [
        "The n-th differences. The shape of the output is the same as `a`",
        "The n-th differences. The shape of the output is"
    ],
    [
        "except along `axis` where the dimension is smaller by `n`. The",
        "except along `axis` where the dimension is"
    ],
    [
        "type of the output is the same as the type of the difference",
        "type of the output is the same as the"
    ],
    [
        "between any two elements of `a`. This is the same as the type of",
        "between any two elements of `a`. This is"
    ],
    [
        "Type is preserved for boolean arrays, so the result will contain",
        "Type is preserved for boolean arrays, so the result will"
    ],
    [
        "`False` when consecutive elements are the same and `True` when they",
        "`False` when consecutive elements are the"
    ],
    [
        "For unsigned integer arrays, the results will also be unsigned. This",
        "For unsigned integer arrays, the results"
    ],
    [
        "should not be surprising, as the result is consistent with",
        "should not be surprising, as the result is"
    ],
    [
        "If this is not desirable, then the array should be cast to a larger",
        "If this is not desirable, then the"
    ],
    [
        "\"order must be non-negative but got \" + repr(n))",
        "\"order must be non-negative but got \""
    ],
    [
        "raise ValueError(\"diff requires input that is at least one dimensional\")",
        "raise ValueError(\"diff requires input that is at"
    ],
    [
        "op = not_equal if a.dtype == np.bool else subtract",
        "op = not_equal if a.dtype =="
    ],
    [
        "def _interp_dispatcher(x, xp, fp, left=None, right=None, period=None):",
        "def _interp_dispatcher(x, xp, fp,"
    ],
    [
        "def interp(x, xp, fp, left=None, right=None, period=None):",
        "def interp(x, xp, fp,"
    ],
    [
        "One-dimensional linear interpolation for monotonically increasing sample points.",
        "One-dimensional linear interpolation for monotonically increasing"
    ],
    [
        "Returns the one-dimensional piecewise linear interpolant to a function",
        "Returns the one-dimensional piecewise linear interpolant"
    ],
    [
        "with given discrete data points (`xp`, `fp`), evaluated at `x`.",
        "with given discrete data points (`xp`, `fp`), evaluated"
    ],
    [
        "The x-coordinates at which to evaluate the interpolated values.",
        "The x-coordinates at which to evaluate the"
    ],
    [
        "The x-coordinates of the data points, must be increasing if argument",
        "The x-coordinates of the data points, must"
    ],
    [
        "`period` is not specified. Otherwise, `xp` is internally sorted after",
        "`period` is not specified. Otherwise,"
    ],
    [
        "normalizing the periodic boundaries with ``xp = xp % period``.",
        "normalizing the periodic boundaries with ``xp = xp %"
    ],
    [
        "The y-coordinates of the data points, same length as `xp`.",
        "The y-coordinates of the data points,"
    ],
    [
        "left : optional float or complex corresponding to fp",
        "left : optional float or complex"
    ],
    [
        "right : optional float or complex corresponding to fp",
        "right : optional float or complex"
    ],
    [
        "period : None or float, optional",
        "period : None or float,"
    ],
    [
        "A period for the x-coordinates. This parameter allows the proper",
        "A period for the x-coordinates. This parameter allows the"
    ],
    [
        "interpolation of angular x-coordinates. Parameters `left` and `right`",
        "interpolation of angular x-coordinates. Parameters"
    ],
    [
        "are ignored if `period` is specified.",
        "are ignored if"
    ],
    [
        "y : float or complex (corresponding to fp) or ndarray",
        "y : float or complex (corresponding"
    ],
    [
        "The interpolated values, same shape as `x`.",
        "The interpolated values, same shape as"
    ],
    [
        "If `xp` and `fp` have different length",
        "If `xp` and `fp` have different"
    ],
    [
        "The x-coordinate sequence is expected to be increasing, but this is not",
        "The x-coordinate sequence is expected to be"
    ],
    [
        "explicitly enforced.  However, if the sequence `xp` is non-increasing,",
        "explicitly enforced. However, if the sequence"
    ],
    [
        "Note that, since NaN is unsortable, `xp` also cannot contain NaNs.",
        "Note that, since NaN is unsortable,"
    ],
    [
        "A simple check for `xp` being strictly increasing is::",
        "A simple check for `xp` being strictly"
    ],
    [
        "Plot an interpolant to the sine function:",
        "Plot an interpolant to the"
    ],
    [
        ">>> yinterp = np.interp(xvals, x, y)",
        ">>> yinterp ="
    ],
    [
        "raise ValueError(\"period must be a non-zero value\")",
        "raise ValueError(\"period must be"
    ],
    [
        "raise ValueError(\"fp and xp are not of the same length\")",
        "raise ValueError(\"fp and xp are not"
    ],
    [
        "return interp_func(x, xp, fp, left, right)",
        "return interp_func(x, xp, fp, left,"
    ],
    [
        "Return the angle of the complex argument.",
        "Return the angle of the"
    ],
    [
        "A complex number or sequence of complex numbers.",
        "A complex number or sequence of complex"
    ],
    [
        "Return angle in degrees if True, radians if False (default).",
        "Return angle in degrees if True,"
    ],
    [
        "The counterclockwise angle from the positive real axis on the complex",
        "The counterclockwise angle from the positive real axis on"
    ],
    [
        "This function passes the imaginary and real parts of the argument to",
        "This function passes the imaginary and real parts of the"
    ],
    [
        "def _unwrap_dispatcher(p, discont=None, axis=None, *, period=None):",
        "def _unwrap_dispatcher(p, discont=None, axis=None, *,"
    ],
    [
        "Unwrap by taking the complement of large deltas with respect to the period.",
        "Unwrap by taking the complement of large deltas"
    ],
    [
        "This unwraps a signal `p` by changing elements which have an absolute",
        "This unwraps a signal `p` by changing elements which"
    ],
    [
        ":math:`\\pi`, this unwraps a radian phase `p` such that adjacent differences",
        ":math:`\\pi`, this unwraps a radian phase"
    ],
    [
        "To have an effect different from the default, `discont` should be",
        "To have an effect different from the default, `discont`"
    ],
    [
        "Axis along which unwrap will operate, default is the last axis.",
        "Axis along which unwrap will operate, default is the last"
    ],
    [
        "Size of the range over which the input wraps. By default, it is",
        "Size of the range over which the input"
    ],
    [
        "but larger than `discont`, no unwrapping is done because taking",
        "but larger than `discont`, no unwrapping is"
    ],
    [
        "the complement would only make the discontinuity larger.",
        "the complement would only make"
    ],
    [
        "ddmod = mod(dd - interval_low, period) + interval_low",
        "ddmod = mod(dd - interval_low,"
    ],
    [
        "Sort a complex array using the real part first, then the imaginary part.",
        "Sort a complex array using the real part first, then"
    ],
    [
        "Always returns a sorted complex array.",
        "Always returns a sorted complex"
    ],
    [
        "\"\"\"Return indices of the first and last non-zero element.",
        "\"\"\"Return indices of the first and last"
    ],
    [
        "Two arrays containing the indices of the first and last non-zero",
        "Two arrays containing the indices of the first and"
    ],
    [
        "start = stop = np.array([], dtype=np.intp)",
        "start = stop"
    ],
    [
        "\"\"\"Remove values along a dimension which are zero along all other.",
        "\"\"\"Remove values along a dimension which are"
    ],
    [
        "trim : {\"fb\", \"f\", \"b\"}, optional",
        "trim : {\"fb\", \"f\", \"b\"},"
    ],
    [
        "A string with 'f' representing trim from front and 'b' to trim from",
        "A string with 'f' representing trim from"
    ],
    [
        "back. By default, zeros are trimmed on both sides.",
        "back. By default, zeros are trimmed on both"
    ],
    [
        "Front and back refer to the edges of a dimension, with \"front\" referring",
        "Front and back refer to the edges of a"
    ],
    [
        "axis : int or sequence, optional",
        "axis : int or sequence,"
    ],
    [
        "If None, `filt` is cropped such that the smallest bounding box is",
        "If None, `filt` is cropped such that the smallest"
    ],
    [
        "returned that still contains all values which are not zero.",
        "returned that still contains all values"
    ],
    [
        "If an axis is specified, `filt` will be sliced in that dimension only",
        "If an axis is specified, `filt` will be sliced in"
    ],
    [
        "on the sides specified by `trim`. The remaining area will be the",
        "on the sides specified by `trim`. The remaining"
    ],
    [
        "smallest that still contains all values wich are not zero.",
        "smallest that still contains all values"
    ],
    [
        "The result of trimming the input. The number of dimensions and the",
        "The result of trimming the input. The"
    ],
    [
        "For all-zero arrays, the first axis is trimmed first.",
        "For all-zero arrays, the first"
    ],
    [
        "The input data type is preserved, list/tuple in means list/tuple out.",
        "The input data type is preserved, list/tuple"
    ],
    [
        "if trim not in {\"fb\", \"bf\", \"f\", \"b\"}:",
        "if trim not in {\"fb\","
    ],
    [
        "raise ValueError(f\"unexpected character(s) in `trim`: {trim!r}\")",
        "raise ValueError(f\"unexpected character(s) in"
    ],
    [
        "start = stop = np.zeros(filt_.ndim, dtype=np.intp)",
        "start = stop"
    ],
    [
        "sl = tuple(slice(*x) for x in zip(start, stop))",
        "sl = tuple(slice(*x) for x"
    ],
    [
        "sl = (slice(None),) * axis + (slice(start[axis], stop[axis]),) + (...,)",
        "sl = (slice(None),) * axis"
    ],
    [
        "Return the elements of an array that satisfy some condition.",
        "Return the elements of an array that satisfy some"
    ],
    [
        "This is equivalent to ``np.compress(ravel(condition), ravel(arr))``.  If",
        "This is equivalent to"
    ],
    [
        "`condition` is boolean ``np.extract`` is equivalent to ``arr[condition]``.",
        "`condition` is boolean ``np.extract`` is equivalent to"
    ],
    [
        "Note that `place` does the exact opposite of `extract`.",
        "Note that `place` does the exact"
    ],
    [
        "An array whose nonzero or True entries indicate the elements of `arr`",
        "An array whose nonzero or True entries"
    ],
    [
        "Input array of the same size as `condition`.",
        "Input array of the same"
    ],
    [
        "Change elements of an array based on conditional and input values.",
        "Change elements of an array based on conditional"
    ],
    [
        "Similar to ``np.copyto(arr, vals, where=mask)``, the difference is that",
        "Similar to ``np.copyto(arr, vals, where=mask)``, the difference is"
    ],
    [
        "`place` uses the first N elements of `vals`, where N is the number of",
        "`place` uses the first N elements of `vals`,"
    ],
    [
        "True values in `mask`, while `copyto` uses the elements where `mask`",
        "True values in `mask`, while `copyto`"
    ],
    [
        "Note that `extract` does the exact opposite of `place`.",
        "Note that `extract` does the exact"
    ],
    [
        "Boolean mask array. Must have the same size as `a`.",
        "Boolean mask array. Must have the same size"
    ],
    [
        "Values to put into `a`. Only the first N elements are used, where",
        "Values to put into `a`. Only the first N"
    ],
    [
        "N is the number of True values in `mask`. If `vals` is smaller",
        "N is the number of True values in `mask`. If `vals` is"
    ],
    [
        "than N, it will be repeated, and if elements of `a` are to be masked,",
        "than N, it will be repeated, and if elements of `a` are"
    ],
    [
        "Display a message on a device.",
        "Display a message"
    ],
    [
        "Use your own printing function instead.",
        "Use your own printing function"
    ],
    [
        "Device to write message. If None, defaults to ``sys.stdout`` which is",
        "Device to write message. If None,"
    ],
    [
        "very similar to ``print``. `device` needs to have ``write()`` and",
        "very similar to ``print``. `device` needs to"
    ],
    [
        "Option whether to print a line feed or not. Defaults to True.",
        "Option whether to print a line feed or not."
    ],
    [
        "If `device` does not have a ``write()`` or ``flush()`` method.",
        "If `device` does not have a"
    ],
    [
        "Besides ``sys.stdout``, a file-like object can also be used as it has",
        "Besides ``sys.stdout``, a file-like object can also be used"
    ],
    [
        ">>> np.disp('\"Display\" in a file', device=buf)",
        ">>> np.disp('\"Display\" in a"
    ],
    [
        "\"use your own printing function instead. \"",
        "\"use your own printing"
    ],
    [
        "Parse string signatures for a generalized universal function.",
        "Parse string signatures for a"
    ],
    [
        "Generalized universal function signature, e.g., ``(m,n),(n,p)->(m,p)``",
        "Generalized universal function"
    ],
    [
        "Tuple of input and output core dimensions parsed from the signature, each",
        "Tuple of input and output core dimensions"
    ],
    [
        "'not a valid gufunc signature: {}'.format(signature))",
        "'not a valid gufunc signature:"
    ],
    [
        "Incrementally check and update core dimension sizes for a single argument.",
        "Incrementally check and update core dimension sizes"
    ],
    [
        "Sizes of existing core dimensions. Will be updated in-place.",
        "Sizes of existing core dimensions. Will be"
    ],
    [
        "'%d-dimensional argument does not have enough '",
        "'%d-dimensional argument does not"
    ],
    [
        "'dimensions for all core dimensions %r'",
        "'dimensions for all core dimensions"
    ],
    [
        "for dim, size in zip(core_dims, core_shape):",
        "for dim, size in zip(core_dims,"
    ],
    [
        "'inconsistent size for core dimension %r: %r vs %r'",
        "'inconsistent size for core dimension %r: %r vs"
    ],
    [
        "Parse broadcast and core dimensions for vectorize with a signature.",
        "Parse broadcast and core dimensions for vectorize with"
    ],
    [
        "Tuple of input arguments to examine.",
        "Tuple of input arguments"
    ],
    [
        "List of core dimensions corresponding to each input.",
        "List of core dimensions corresponding"
    ],
    [
        "Common shape to broadcast all non-core dimensions to.",
        "Common shape to broadcast all"
    ],
    [
        "Common sizes for named core dimensions.",
        "Common sizes for named"
    ],
    [
        "for arg, core_dims in zip(args, input_core_dims):",
        "for arg, core_dims"
    ],
    [
        "\"\"\"Helper for calculating broadcast shapes with core dimensions.\"\"\"",
        "\"\"\"Helper for calculating broadcast shapes with core"
    ],
    [
        "return [broadcast_shape + tuple(dim_sizes[dim] for dim in core_dims)",
        "return [broadcast_shape + tuple(dim_sizes[dim] for dim in"
    ],
    [
        "\"\"\"Helper for creating output arrays in vectorize.\"\"\"",
        "\"\"\"Helper for creating output arrays in"
    ],
    [
        "for shape, dtype in zip(shapes, dtypes))",
        "for shape, dtype in"
    ],
    [
        "Returns an object that acts like pyfunc, but takes arrays as input.",
        "Returns an object that acts like pyfunc,"
    ],
    [
        "Define a vectorized function which takes a nested sequence of objects or",
        "Define a vectorized function which takes a nested"
    ],
    [
        "numpy arrays as inputs and returns a single numpy array or a tuple of numpy",
        "numpy arrays as inputs and returns a single numpy"
    ],
    [
        "arrays. The vectorized function evaluates `pyfunc` over successive tuples",
        "arrays. The vectorized function evaluates"
    ],
    [
        "of the input arrays like the python map function, except it uses the",
        "of the input arrays like the python map function,"
    ],
    [
        "The data type of the output of `vectorized` is determined by calling",
        "The data type of the output of `vectorized` is"
    ],
    [
        "the function with the first element of the input.  This can be avoided",
        "the function with the first element of the input. This"
    ],
    [
        "Can be omitted to produce a decorator with keyword arguments.",
        "Can be omitted to produce a decorator with keyword"
    ],
    [
        "otypes : str or list of dtypes, optional",
        "otypes : str or list"
    ],
    [
        "The output data type. It must be specified as either a string of",
        "The output data type. It must be specified"
    ],
    [
        "typecode characters or a list of data type specifiers. There should",
        "typecode characters or a list of"
    ],
    [
        "be one data type specifier for each output.",
        "be one data type specifier"
    ],
    [
        "The docstring for the function. If None, the docstring will be the",
        "The docstring for the function. If None, the"
    ],
    [
        "Set of strings or integers representing the positional or keyword",
        "Set of strings or integers representing the positional"
    ],
    [
        "arguments for which the function will not be vectorized. These will be",
        "arguments for which the function will not"
    ],
    [
        "If `True`, then cache the first function call that determines the number",
        "If `True`, then cache the first function call that"
    ],
    [
        "of outputs if `otypes` is not provided.",
        "of outputs if `otypes`"
    ],
    [
        "Generalized universal function signature, e.g., ``(m,n),(n)->(m)`` for",
        "Generalized universal function signature,"
    ],
    [
        "vectorized matrix-vector multiplication. If provided, ``pyfunc`` will",
        "vectorized matrix-vector multiplication. If provided,"
    ],
    [
        "be called with (and expected to return) arrays with shapes given by the",
        "be called with (and expected to return) arrays"
    ],
    [
        "size of corresponding core dimensions. By default, ``pyfunc`` is",
        "size of corresponding core dimensions. By default, ``pyfunc``"
    ],
    [
        "assumed to take scalars as input and output.",
        "assumed to take scalars as input and"
    ],
    [
        "A vectorized function if ``pyfunc`` was provided,",
        "A vectorized function if ``pyfunc`` was"
    ],
    [
        "frompyfunc : Takes an arbitrary Python function and returns a ufunc",
        "frompyfunc : Takes an arbitrary Python function and"
    ],
    [
        "The `vectorize` function is provided primarily for convenience, not for",
        "The `vectorize` function is provided"
    ],
    [
        "performance. The implementation is essentially a for loop.",
        "performance. The implementation is"
    ],
    [
        "If `otypes` is not specified, then a call to the function with the",
        "If `otypes` is not specified, then a call to"
    ],
    [
        "first argument will be used to determine the number of outputs.  The",
        "first argument will be used to determine the number of"
    ],
    [
        "results of this call will be cached if `cache` is `True` to prevent",
        "results of this call will be cached"
    ],
    [
        "calling the function twice.  However, to implement the cache, the",
        "calling the function twice. However, to implement the cache,"
    ],
    [
        "original function must be wrapped which will slow down subsequent",
        "original function must be wrapped which will slow"
    ],
    [
        "calls, so only do this if your function is expensive.",
        "calls, so only do this if your function is"
    ],
    [
        "The new keyword argument interface and `excluded` argument support",
        "The new keyword argument interface and `excluded` argument"
    ],
    [
        "...     \"Return a-b if a>b, otherwise return a+b\"",
        "... \"Return a-b if a>b,"
    ],
    [
        "The docstring is taken from the input function to `vectorize` unless it",
        "The docstring is taken from the input function to"
    ],
    [
        "'Return a-b if a>b, otherwise return a+b'",
        "'Return a-b if a>b, otherwise return"
    ],
    [
        ">>> vfunc = np.vectorize(myfunc, doc='Vectorized `myfunc`')",
        ">>> vfunc = np.vectorize(myfunc, doc='Vectorized"
    ],
    [
        "The output type is determined by evaluating the first element of the input,",
        "The output type is determined by evaluating"
    ],
    [
        "The `excluded` argument can be used to prevent vectorizing over certain",
        "The `excluded` argument can be used"
    ],
    [
        "arguments.  This can be useful for array-like arguments of a fixed length",
        "arguments. This can be useful for"
    ],
    [
        "such as the coefficients for a polynomial as in `polyval`:",
        "such as the coefficients for a polynomial"
    ],
    [
        "Here, we exclude the zeroth argument from vectorization whether it is",
        "Here, we exclude the zeroth argument from vectorization whether"
    ],
    [
        "The `signature` argument allows for vectorizing functions that act on",
        "The `signature` argument allows for vectorizing functions that"
    ],
    [
        "non-scalar arrays of fixed length. For example, you can use it for a",
        "non-scalar arrays of fixed length. For example,"
    ],
    [
        "vectorized calculation of Pearson correlation coefficient and its p-value:",
        "vectorized calculation of Pearson correlation"
    ],
    [
        "Decorator syntax is supported.  The decorator can be called as",
        "Decorator syntax is supported. The decorator can be"
    ],
    [
        "a function to provide keyword arguments:",
        "a function to"
    ],
    [
        "if (pyfunc != np._NoValue) and (not callable(pyfunc)):",
        "if (pyfunc != np._NoValue)"
    ],
    [
        "if pyfunc != np._NoValue and hasattr(pyfunc, '__name__'):",
        "if pyfunc != np._NoValue and"
    ],
    [
        "if doc is None and hasattr(pyfunc, '__doc__'):",
        "if doc is None and"
    ],
    [
        "raise ValueError(\"Invalid otype specified: %s\" % (char,))",
        "raise ValueError(\"Invalid otype specified: %s\" %"
    ],
    [
        "otypes = [_get_vectorize_dtype(_nx.dtype(x)) for x in otypes]",
        "otypes = [_get_vectorize_dtype(_nx.dtype(x)) for x in"
    ],
    [
        "Return arrays with the results of `pyfunc` broadcast (vectorized) over",
        "Return arrays with the results of `pyfunc` broadcast (vectorized)"
    ],
    [
        "`args` and `kwargs` not in `excluded`.",
        "`args` and `kwargs` not in"
    ],
    [
        "if not kwargs and not excluded:",
        "if not kwargs and"
    ],
    [
        "names = [_n for _n in kwargs if _n not in excluded]",
        "names = [_n for _n in kwargs if _n"
    ],
    [
        "inds = [_i for _i in range(nargs) if _i not in excluded]",
        "inds = [_i for _i in range(nargs)"
    ],
    [
        "vargs = [args[_i] for _i in inds]",
        "vargs = [args[_i] for"
    ],
    [
        "raise ValueError('args can not be empty')",
        "raise ValueError('args can not"
    ],
    [
        "if func is not self.pyfunc or nin not in self._ufunc:",
        "if func is not self.pyfunc or nin not"
    ],
    [
        "args = [asarray(arg) for arg in args]",
        "args = [asarray(arg) for arg in"
    ],
    [
        "\"\"\"Vectorized call to `func` over positional `args`.\"\"\"",
        "\"\"\"Vectorized call to `func`"
    ],
    [
        "inputs = [asanyarray(a, dtype=object) for a in args]",
        "inputs = [asanyarray(a, dtype=object) for"
    ],
    [
        "for x, t in zip(outputs, otypes))",
        "for x, t in"
    ],
    [
        "\"\"\"Vectorized call over positional arguments with a signature.\"\"\"",
        "\"\"\"Vectorized call over positional"
    ],
    [
        "raise TypeError('wrong number of positional arguments: '",
        "raise TypeError('wrong number of"
    ],
    [
        "args = tuple(asanyarray(arg) for arg in args)",
        "args = tuple(asanyarray(arg) for arg"
    ],
    [
        "for arg, shape in zip(args, input_shapes)]",
        "for arg, shape"
    ],
    [
        "results = func(*(arg[index] for arg in args))",
        "results = func(*(arg[index] for arg in"
    ],
    [
        "'wrong number of outputs from pyfunc: expected %r, got %r'",
        "'wrong number of outputs from pyfunc: expected %r, got"
    ],
    [
        "for result, core_dims in zip(results, output_core_dims):",
        "for result, core_dims in"
    ],
    [
        "for output, result in zip(outputs, results):",
        "for output, result in zip(outputs,"
    ],
    [
        "raise ValueError('cannot call `vectorize` with a signature '",
        "raise ValueError('cannot call `vectorize` with a"
    ],
    [
        "def _cov_dispatcher(m, y=None, rowvar=None, bias=None, ddof=None,",
        "def _cov_dispatcher(m, y=None, rowvar=None,"
    ],
    [
        "def cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None,",
        "def cov(m, y=None, rowvar=True,"
    ],
    [
        "Estimate a covariance matrix, given data and weights.",
        "Estimate a covariance matrix,"
    ],
    [
        "Covariance indicates the level to which two variables vary together.",
        "Covariance indicates the level to"
    ],
    [
        "then the covariance matrix element :math:`C_{ij}` is the covariance of",
        "then the covariance matrix element :math:`C_{ij}` is"
    ],
    [
        ":math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance",
        ":math:`x_i` and :math:`x_j`. The element"
    ],
    [
        "See the notes for an outline of the algorithm.",
        "See the notes for an outline of the"
    ],
    [
        "Each row of `m` represents a variable, and each column a single",
        "Each row of `m` represents a variable, and"
    ],
    [
        "observation of all those variables. Also see `rowvar` below.",
        "observation of all those variables. Also"
    ],
    [
        "An additional set of variables and observations. `y` has the same form",
        "An additional set of variables and observations. `y` has the"
    ],
    [
        "If `rowvar` is True (default), then each row represents a",
        "If `rowvar` is True (default), then"
    ],
    [
        "variable, with observations in the columns. Otherwise, the relationship",
        "variable, with observations in the columns. Otherwise,"
    ],
    [
        "is transposed: each column represents a variable, while the rows",
        "is transposed: each column represents"
    ],
    [
        "number of observations given (unbiased estimate). If `bias` is True,",
        "number of observations given (unbiased estimate). If `bias` is"
    ],
    [
        "then normalization is by ``N``. These values can be overridden by using",
        "then normalization is by ``N``. These values"
    ],
    [
        "If not ``None`` the default value implied by `bias` is overridden.",
        "If not ``None`` the default value implied by"
    ],
    [
        "the simple average. See the notes for the details. The default value",
        "the simple average. See the notes for the details. The default"
    ],
    [
        "typically large for observations considered \"important\" and smaller for",
        "typically large for observations considered"
    ],
    [
        "weights can be used to assign probabilities to observation vectors.",
        "weights can be used to"
    ],
    [
        "Data-type of the result. By default, the return data-type will have",
        "Data-type of the result. By default, the return data-type will"
    ],
    [
        "The covariance matrix of the variables.",
        "The covariance matrix of the"
    ],
    [
        "Assume that the observations are in the columns of the observation",
        "Assume that the observations are in the columns of the"
    ],
    [
        "array `m` and let ``f = fweights`` and ``a = aweights`` for brevity. The",
        "array `m` and let ``f = fweights`` and ``a = aweights`` for"
    ],
    [
        "steps to compute the weighted covariance are as follows::",
        "steps to compute the weighted covariance"
    ],
    [
        ">>> w = f * a",
        ">>> w = f"
    ],
    [
        "correlate perfectly, but in opposite directions:",
        "correlate perfectly, but in opposite"
    ],
    [
        "Further, note how `x` and `y` are combined:",
        "Further, note how `x` and `y`"
    ],
    [
        "if ddof is not None and ddof != int(ddof):",
        "if ddof is not None and ddof"
    ],
    [
        "\"incompatible numbers of samples and fweights\")",
        "\"incompatible numbers of samples"
    ],
    [
        "\"incompatible numbers of samples and aweights\")",
        "\"incompatible numbers of samples"
    ],
    [
        "fact = w_sum - ddof * sum(w * aweights) / w_sum",
        "fact = w_sum - ddof * sum(w"
    ],
    [
        "def _corrcoef_dispatcher(x, y=None, rowvar=None, bias=None, ddof=None, *,",
        "def _corrcoef_dispatcher(x, y=None, rowvar=None, bias=None, ddof=None,"
    ],
    [
        "def corrcoef(x, y=None, rowvar=True, bias=np._NoValue, ddof=np._NoValue, *,",
        "def corrcoef(x, y=None, rowvar=True,"
    ],
    [
        "Please refer to the documentation for `cov` for more detail.  The",
        "Please refer to the documentation for `cov`"
    ],
    [
        "relationship between the correlation coefficient matrix, `R`, and the",
        "relationship between the correlation coefficient matrix, `R`, and"
    ],
    [
        ".. math:: R_{ij} = \\\\frac{ C_{ij} } { \\\\sqrt{ C_{ii} C_{jj} } }",
        ".. math:: R_{ij} = \\\\frac{ C_{ij} } { \\\\sqrt{ C_{ii} C_{jj}"
    ],
    [
        "Each row of `x` represents a variable, and each column a single",
        "Each row of `x` represents a variable, and each"
    ],
    [
        "observation of all those variables. Also see `rowvar` below.",
        "observation of all those variables."
    ],
    [
        "An additional set of variables and observations. `y` has the same",
        "An additional set of variables and observations. `y`"
    ],
    [
        "If `rowvar` is True (default), then each row represents a",
        "If `rowvar` is True (default), then"
    ],
    [
        "variable, with observations in the columns. Otherwise, the relationship",
        "variable, with observations in the columns. Otherwise, the"
    ],
    [
        "is transposed: each column represents a variable, while the rows",
        "is transposed: each column represents a variable, while"
    ],
    [
        "Has no effect, do not use.",
        "Has no effect,"
    ],
    [
        "Has no effect, do not use.",
        "Has no effect,"
    ],
    [
        "Data-type of the result. By default, the return data-type will have",
        "Data-type of the result. By default, the"
    ],
    [
        "The correlation coefficient matrix of the variables.",
        "The correlation coefficient matrix"
    ],
    [
        "Due to floating point rounding the resulting array may not be Hermitian,",
        "Due to floating point rounding the"
    ],
    [
        "much help in the complex case.",
        "much help in the"
    ],
    [
        "This function accepts but discards arguments `bias` and `ddof`.  This is",
        "This function accepts but discards arguments"
    ],
    [
        "for backwards compatibility with previous versions of this function.  These",
        "for backwards compatibility with previous versions of this function."
    ],
    [
        "arguments had no effect on the return values of the function and can be",
        "arguments had no effect on the return"
    ],
    [
        "safely ignored in this and previous versions of numpy.",
        "safely ignored in this and previous versions of"
    ],
    [
        "In this example we generate two random arrays, ``xarr`` and ``yarr``, and",
        "In this example we generate two random arrays, ``xarr`` and"
    ],
    [
        "compute the row-wise and column-wise Pearson correlation coefficients,",
        "compute the row-wise and column-wise Pearson"
    ],
    [
        "``R``. Since ``rowvar`` is  true by  default, we first find the row-wise",
        "``R``. Since ``rowvar`` is true by default,"
    ],
    [
        "Pearson correlation coefficients between the variables of ``xarr``.",
        "Pearson correlation coefficients between"
    ],
    [
        "If we add another set of variables and observations ``yarr``, we can",
        "If we add another set of variables and observations ``yarr``,"
    ],
    [
        "compute the row-wise Pearson correlation coefficients between the",
        "compute the row-wise Pearson correlation coefficients"
    ],
    [
        "Finally if we use the option ``rowvar=False``, the columns are now",
        "Finally if we use the option ``rowvar=False``,"
    ],
    [
        "being treated as the variables and we will find the column-wise Pearson",
        "being treated as the variables and we"
    ],
    [
        "correlation coefficients between variables in ``xarr`` and ``yarr``.",
        "correlation coefficients between variables"
    ],
    [
        "if bias is not np._NoValue or ddof is not np._NoValue:",
        "if bias is not np._NoValue or ddof is not"
    ],
    [
        "warnings.warn('bias and ddof have no effect and are deprecated',",
        "warnings.warn('bias and ddof have no effect"
    ],
    [
        "c = cov(x, y, rowvar, dtype=dtype)",
        "c = cov(x, y,"
    ],
    [
        "The Blackman window is a taper formed by using the first three",
        "The Blackman window is a taper formed"
    ],
    [
        "terms of a summation of cosines. It was designed to have close to the",
        "terms of a summation of cosines. It"
    ],
    [
        "minimal leakage possible.  It is close to optimal, only slightly worse",
        "minimal leakage possible. It is close to optimal,"
    ],
    [
        "Number of points in the output window. If zero or less, an empty",
        "Number of points in the output window. If zero or less,"
    ],
    [
        "The window, with the maximum value normalized to one (the value one",
        "The window, with the maximum value normalized to one (the value"
    ],
    [
        "appears only if the number of samples is odd).",
        "appears only if the number"
    ],
    [
        "The Blackman window is defined as",
        "The Blackman window is"
    ],
    [
        "Most references to the Blackman window come from the signal processing",
        "Most references to the Blackman window come from the signal"
    ],
    [
        "literature, where it is used as one of many windowing functions for",
        "literature, where it is used as"
    ],
    [
        "smoothing values.  It is also known as an apodization (which means",
        "smoothing values. It is also known as an"
    ],
    [
        "\"removing the foot\", i.e. smoothing discontinuities at the beginning",
        "\"removing the foot\", i.e. smoothing discontinuities at"
    ],
    [
        "and end of the sampled signal) or tapering function. It is known as a",
        "and end of the sampled signal) or"
    ],
    [
        "\"near optimal\" tapering function, almost as good (by some measures)",
        "\"near optimal\" tapering function, almost as good (by"
    ],
    [
        "Oppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing.",
        "Oppenheim, A.V., and R.W."
    ],
    [
        "Plot the window and the frequency response.",
        "Plot the window and"
    ],
    [
        "The Bartlett window is very similar to a triangular window, except",
        "The Bartlett window is very similar to a"
    ],
    [
        "that the end points are at zero.  It is often used in signal",
        "that the end points are at zero. It is often"
    ],
    [
        "processing for tapering a signal, without generating too much",
        "processing for tapering a signal, without generating too"
    ],
    [
        "Number of points in the output window. If zero or less, an",
        "Number of points in the output window. If zero"
    ],
    [
        "The triangular window, with the maximum value normalized to one",
        "The triangular window, with the maximum"
    ],
    [
        "(the value one appears only if the number of samples is odd), with",
        "(the value one appears only if the number of"
    ],
    [
        "the first and last samples equal to zero.",
        "the first and last samples"
    ],
    [
        "The Bartlett window is defined as",
        "The Bartlett window"
    ],
    [
        "Most references to the Bartlett window come from the signal processing",
        "Most references to the Bartlett window come from the signal"
    ],
    [
        "literature, where it is used as one of many windowing functions for",
        "literature, where it is used as one of many windowing"
    ],
    [
        "smoothing values.  Note that convolution with this window produces linear",
        "smoothing values. Note that convolution with"
    ],
    [
        "interpolation.  It is also known as an apodization (which means \"removing",
        "interpolation. It is also known as an"
    ],
    [
        "the foot\", i.e. smoothing discontinuities at the beginning and end of the",
        "the foot\", i.e. smoothing discontinuities at the beginning and end of"
    ],
    [
        "sampled signal) or tapering function. The Fourier transform of the",
        "sampled signal) or tapering function."
    ],
    [
        "Bartlett window is the product of two sinc functions. Note the excellent",
        "Bartlett window is the product of two"
    ],
    [
        "Plot the window and its frequency response (requires SciPy and matplotlib).",
        "Plot the window and its frequency response (requires SciPy"
    ],
    [
        "The Hanning window is a taper formed by using a weighted cosine.",
        "The Hanning window is a taper formed by using a"
    ],
    [
        "Number of points in the output window. If zero or less, an",
        "Number of points in the output window. If zero"
    ],
    [
        "The window, with the maximum value normalized to one (the value",
        "The window, with the maximum value normalized to one"
    ],
    [
        "one appears only if `M` is odd).",
        "one appears only if `M` is"
    ],
    [
        "The Hanning window is defined as",
        "The Hanning window"
    ],
    [
        "The Hanning was named for Julius von Hann, an Austrian meteorologist.",
        "The Hanning was named for Julius von Hann, an Austrian"
    ],
    [
        "It is also known as the Cosine Bell. Some authors prefer that it be",
        "It is also known as the Cosine Bell. Some authors prefer that"
    ],
    [
        "called a Hann window, to help avoid confusion with the very similar",
        "called a Hann window, to help"
    ],
    [
        "Most references to the Hanning window come from the signal processing",
        "Most references to the Hanning window come from the signal"
    ],
    [
        "literature, where it is used as one of many windowing functions for",
        "literature, where it is used as one of many windowing"
    ],
    [
        "smoothing values.  It is also known as an apodization (which means",
        "smoothing values. It is also known as"
    ],
    [
        "\"removing the foot\", i.e. smoothing discontinuities at the beginning",
        "\"removing the foot\", i.e. smoothing discontinuities"
    ],
    [
        "and end of the sampled signal) or tapering function.",
        "and end of the sampled signal) or tapering"
    ],
    [
        "Plot the window and its frequency response.",
        "Plot the window and its frequency"
    ],
    [
        "plt.title(\"Frequency response of the Hann window\")",
        "plt.title(\"Frequency response of"
    ],
    [
        "The Hamming window is a taper formed by using a weighted cosine.",
        "The Hamming window is a taper formed by"
    ],
    [
        "Number of points in the output window. If zero or less, an",
        "Number of points in the output window. If zero or"
    ],
    [
        "The window, with the maximum value normalized to one (the value",
        "The window, with the maximum value"
    ],
    [
        "one appears only if the number of samples is odd).",
        "one appears only if the number of samples is"
    ],
    [
        "The Hamming window is defined as",
        "The Hamming window is"
    ],
    [
        "The Hamming was named for R. W. Hamming, an associate of J. W. Tukey",
        "The Hamming was named for R. W. Hamming, an"
    ],
    [
        "and is described in Blackman and Tukey. It was recommended for",
        "and is described in Blackman and Tukey."
    ],
    [
        "smoothing the truncated autocovariance function in the time domain.",
        "smoothing the truncated autocovariance function in the time"
    ],
    [
        "Most references to the Hamming window come from the signal processing",
        "Most references to the Hamming window come from the"
    ],
    [
        "literature, where it is used as one of many windowing functions for",
        "literature, where it is used as one of many windowing"
    ],
    [
        "smoothing values.  It is also known as an apodization (which means",
        "smoothing values. It is also known"
    ],
    [
        "\"removing the foot\", i.e. smoothing discontinuities at the beginning",
        "\"removing the foot\", i.e. smoothing"
    ],
    [
        "and end of the sampled signal) or tapering function.",
        "and end of the sampled signal) or"
    ],
    [
        "Plot the window and the frequency response.",
        "Plot the window and"
    ],
    [
        "out : ndarray, shape = x.shape, dtype = float",
        "out : ndarray, shape = x.shape, dtype ="
    ],
    [
        "The modified Bessel function evaluated at each of the elements of `x`.",
        "The modified Bessel function evaluated at each of the"
    ],
    [
        "The scipy implementation is recommended over this function: it is a",
        "The scipy implementation is recommended over this function:"
    ],
    [
        "proper ufunc written in C, and more than an order of magnitude faster.",
        "proper ufunc written in C, and more than an order"
    ],
    [
        "polynomial expansions are employed in each interval. Relative error on",
        "polynomial expansions are employed in each interval. Relative"
    ],
    [
        "The Kaiser window is a taper formed by using a Bessel function.",
        "The Kaiser window is a taper formed by using a"
    ],
    [
        "Number of points in the output window. If zero or less, an",
        "Number of points in the output"
    ],
    [
        "The window, with the maximum value normalized to one (the value",
        "The window, with the maximum value"
    ],
    [
        "one appears only if the number of samples is odd).",
        "one appears only if the number of samples"
    ],
    [
        "The Kaiser window is defined as",
        "The Kaiser window"
    ],
    [
        "The Kaiser was named for Jim Kaiser, who discovered a simple",
        "The Kaiser was named for Jim Kaiser, who discovered a"
    ],
    [
        "approximation to the DPSS window based on Bessel functions.  The Kaiser",
        "approximation to the DPSS window based on Bessel functions."
    ],
    [
        "window is a very good approximation to the Digital Prolate Spheroidal",
        "window is a very good approximation to the Digital"
    ],
    [
        "Sequence, or Slepian window, which is the transform which maximizes the",
        "Sequence, or Slepian window, which is the transform which"
    ],
    [
        "energy in the main lobe of the window relative to total energy.",
        "energy in the main lobe of the"
    ],
    [
        "The Kaiser can approximate many other windows by varying the beta",
        "The Kaiser can approximate many other windows by"
    ],
    [
        "gets large, the window narrows, and so the number of samples needs to be",
        "gets large, the window narrows, and so the number of"
    ],
    [
        "large enough to sample the increasingly narrow spike, otherwise NaNs will",
        "large enough to sample the increasingly narrow spike, otherwise"
    ],
    [
        "Most references to the Kaiser window come from the signal processing",
        "Most references to the Kaiser window come"
    ],
    [
        "literature, where it is used as one of many windowing functions for",
        "literature, where it is used as one of many windowing"
    ],
    [
        "smoothing values.  It is also known as an apodization (which means",
        "smoothing values. It is also known"
    ],
    [
        "\"removing the foot\", i.e. smoothing discontinuities at the beginning",
        "\"removing the foot\", i.e. smoothing discontinuities at"
    ],
    [
        "and end of the sampled signal) or tapering function.",
        "and end of the sampled signal)"
    ],
    [
        "Plot the window and the frequency response.",
        "Plot the window and the"
    ],
    [
        "The sinc function is equal to :math:`\\sin(\\pi x)/(\\pi x)` for any argument",
        "The sinc function is equal to :math:`\\sin(\\pi x)/(\\pi x)`"
    ],
    [
        "only everywhere continuous but also infinitely differentiable.",
        "only everywhere continuous but also infinitely"
    ],
    [
        "Note the normalization factor of ``pi`` used in the definition.",
        "Note the normalization factor of"
    ],
    [
        "This is the most commonly used definition in signal processing.",
        "This is the most commonly"
    ],
    [
        "Use ``sinc(x / np.pi)`` to obtain the unnormalized sinc function",
        "Use ``sinc(x / np.pi)`` to obtain the unnormalized sinc"
    ],
    [
        ":math:`\\sin(x)/x` that is more common in mathematics.",
        ":math:`\\sin(x)/x` that is more"
    ],
    [
        "Array (possibly multi-dimensional) of values for which to calculate",
        "Array (possibly multi-dimensional) of values for which to"
    ],
    [
        "``sinc(x)``, which has the same shape as the input.",
        "``sinc(x)``, which has the same shape as"
    ],
    [
        "The name sinc is short for \"sine cardinal\" or \"sinus cardinalis\".",
        "The name sinc is short for \"sine cardinal\""
    ],
    [
        "The sinc function is used in various signal processing applications,",
        "The sinc function is used in various signal"
    ],
    [
        "including in anti-aliasing, in the construction of a Lanczos resampling",
        "including in anti-aliasing, in the construction of a Lanczos"
    ],
    [
        "For bandlimited interpolation of discrete-time signals, the ideal",
        "For bandlimited interpolation of discrete-time signals, the"
    ],
    [
        "interpolation kernel is proportional to the sinc function.",
        "interpolation kernel is proportional to the"
    ],
    [
        "Call `func` with `a` as first argument swapping the axes to use extended",
        "Call `func` with `a` as first argument swapping"
    ],
    [
        "axis on functions that don't support it natively.",
        "axis on functions that don't"
    ],
    [
        "Input array or object that can be converted to an array.",
        "Input array or object that can be converted to"
    ],
    [
        "Reduction function capable of receiving a single axis argument.",
        "Reduction function capable of receiving a single"
    ],
    [
        "It is called with `a` as first argument followed by `kwargs`.",
        "It is called with `a` as"
    ],
    [
        "additional keyword arguments to pass to `func`.",
        "additional keyword arguments to pass"
    ],
    [
        "which can be used to reshape the result to the same shape a ufunc with",
        "which can be used to reshape the result to"
    ],
    [
        "kwargs['out'] = out[(Ellipsis, ) + index_out]",
        "kwargs['out'] = out[(Ellipsis, ) +"
    ],
    [
        "kwargs['out'] = out[(Ellipsis, ) + index_out]",
        "kwargs['out'] = out[(Ellipsis, ) +"
    ],
    [
        "index_r = (np.newaxis, ) * nd",
        "index_r = (np.newaxis,"
    ],
    [
        "np.newaxis if i in axis else slice(None)",
        "np.newaxis if i in axis else"
    ],
    [
        "r = r[(Ellipsis, ) + index_r]",
        "r = r[(Ellipsis, )"
    ],
    [
        "def median(a, axis=None, out=None, overwrite_input=False, keepdims=False):",
        "def median(a, axis=None,"
    ],
    [
        "Compute the median along the specified axis.",
        "Compute the median along"
    ],
    [
        "Returns the median of the array elements.",
        "Returns the median of the"
    ],
    [
        "Input array or object that can be converted to an array.",
        "Input array or object that can be"
    ],
    [
        "axis : {int, sequence of int, None}, optional",
        "axis : {int, sequence"
    ],
    [
        "Axis or axes along which the medians are computed. The default,",
        "Axis or axes along which the"
    ],
    [
        "axis=None, will compute the median along a flattened version of",
        "axis=None, will compute the median along"
    ],
    [
        "the array. If a sequence of axes, the array is first flattened",
        "the array. If a sequence of axes, the array"
    ],
    [
        "along the given axes, then the median is computed along the",
        "along the given axes, then the median is computed along"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the"
    ],
    [
        "have the same shape and buffer length as the expected output,",
        "have the same shape and buffer length as"
    ],
    [
        "but the type (of the output) will be cast if necessary.",
        "but the type (of the output)"
    ],
    [
        "If True, then allow use of memory of input array `a` for",
        "If True, then allow use of memory of input array"
    ],
    [
        "calculations. The input array will be modified by the call to",
        "calculations. The input array will be"
    ],
    [
        "`median`. This will save memory when you do not need to preserve",
        "`median`. This will save memory when you do not need to"
    ],
    [
        "the contents of the input array. Treat the input as undefined,",
        "the contents of the input array. Treat"
    ],
    [
        "but it will probably be fully or partially sorted. Default is",
        "but it will probably be fully"
    ],
    [
        "False. If `overwrite_input` is ``True`` and `a` is not already an",
        "False. If `overwrite_input` is ``True`` and `a`"
    ],
    [
        "`ndarray`, an error will be raised.",
        "`ndarray`, an error will be"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With this"
    ],
    [
        "the result will broadcast correctly against the original `arr`.",
        "the result will broadcast correctly against the original"
    ],
    [
        "A new array holding the result. If the input contains integers",
        "A new array holding the result. If the input contains"
    ],
    [
        "same as that of the input. If `out` is specified, that array is",
        "same as that of the input. If `out` is"
    ],
    [
        "Given a vector ``V`` of length ``N``, the median of ``V`` is the",
        "Given a vector ``V`` of length ``N``, the median"
    ],
    [
        "middle value of a sorted copy of ``V``, ``V_sorted`` - i",
        "middle value of a sorted copy of ``V``, ``V_sorted`` -"
    ],
    [
        "two middle values of ``V_sorted`` when ``N`` is even.",
        "two middle values of ``V_sorted``"
    ],
    [
        "return _ureduce(a, func=_median, keepdims=keepdims, axis=axis, out=out,",
        "return _ureduce(a, func=_median, keepdims=keepdims, axis=axis,"
    ],
    [
        "supports_nans = np.issubdtype(a.dtype, np.inexact) or a.dtype.kind in 'Mm'",
        "supports_nans = np.issubdtype(a.dtype, np.inexact) or a.dtype.kind in"
    ],
    [
        "def _percentile_dispatcher(a, q, axis=None, out=None, overwrite_input=None,",
        "def _percentile_dispatcher(a, q,"
    ],
    [
        "Compute the q-th percentile of the data along the specified axis.",
        "Compute the q-th percentile of the data along"
    ],
    [
        "Returns the q-th percentile(s) of the array elements.",
        "Returns the q-th percentile(s) of"
    ],
    [
        "a : array_like of real numbers",
        "a : array_like of real"
    ],
    [
        "Input array or object that can be converted to an array.",
        "Input array or object that can be converted"
    ],
    [
        "Percentage or sequence of percentages for the percentiles to compute.",
        "Percentage or sequence of percentages for the percentiles to"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple of int,"
    ],
    [
        "Axis or axes along which the percentiles are computed. The",
        "Axis or axes along which the percentiles are computed."
    ],
    [
        "default is to compute the percentile(s) along a flattened",
        "default is to compute the percentile(s) along"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place"
    ],
    [
        "have the same shape and buffer length as the expected output,",
        "have the same shape and buffer length as the expected"
    ],
    [
        "but the type (of the output) will be cast if necessary.",
        "but the type (of the output)"
    ],
    [
        "If True, then allow the input array `a` to be modified by intermediate",
        "If True, then allow the input array `a` to be modified"
    ],
    [
        "calculations, to save memory. In this case, the contents of the input",
        "calculations, to save memory. In this case, the contents of the"
    ],
    [
        "`a` after this function completes is undefined.",
        "`a` after this function"
    ],
    [
        "This parameter specifies the method to use for estimating the",
        "This parameter specifies the method to"
    ],
    [
        "percentile.  There are many different methods, some unique to NumPy.",
        "percentile. There are many different methods, some"
    ],
    [
        "See the notes for explanation.  The options sorted by their R type",
        "See the notes for explanation. The options sorted by their"
    ],
    [
        "The first three methods are discontinuous.  NumPy further defines the",
        "The first three methods are discontinuous. NumPy further defines"
    ],
    [
        "This argument was previously called \"interpolation\" and only",
        "This argument was previously"
    ],
    [
        "offered the \"linear\" default and last four options.",
        "offered the \"linear\" default and last four"
    ],
    [
        "If this is set to True, the axes which are reduced are left in",
        "If this is set to True, the axes"
    ],
    [
        "the result as dimensions with size one. With this option, the",
        "the result as dimensions with size"
    ],
    [
        "result will broadcast correctly against the original array `a`.",
        "result will broadcast correctly against the original"
    ],
    [
        "An array of weights associated with the values in `a`. Each value in",
        "An array of weights associated with the values in"
    ],
    [
        "`a` contributes to the percentile according to its associated weight.",
        "`a` contributes to the percentile according to its associated"
    ],
    [
        "the size of `a` along the given axis) or of the same shape as `a`.",
        "the size of `a` along the given axis) or of"
    ],
    [
        "If `weights=None`, then all data in `a` are assumed to have a",
        "If `weights=None`, then all data in `a` are"
    ],
    [
        "See the notes for more details.",
        "See the notes for more"
    ],
    [
        "Deprecated name for the method keyword argument.",
        "Deprecated name for the method keyword"
    ],
    [
        "If `q` is a single percentile and `axis=None`, then the result",
        "If `q` is a single percentile and"
    ],
    [
        "is a scalar. If multiple percentiles are given, first axis of",
        "is a scalar. If multiple percentiles are given,"
    ],
    [
        "the result corresponds to the percentiles. The other axes are",
        "the result corresponds to the percentiles."
    ],
    [
        "the axes that remain after the reduction of `a`. If the input",
        "the axes that remain after the"
    ],
    [
        "same as that of the input. If `out` is specified, that array is",
        "same as that of the input. If"
    ],
    [
        "The behavior of `numpy.percentile` with percentage `q` is",
        "The behavior of `numpy.percentile` with percentage `q`"
    ],
    [
        "For more information, please see `numpy.quantile`.",
        "For more information, please"
    ],
    [
        ">>> assert not np.all(a == b)",
        ">>> assert not np.all(a"
    ],
    [
        "The different methods can be visualized graphically:",
        "The different methods can be visualized"
    ],
    [
        "for method, style, color in lines:",
        "for method, style,"
    ],
    [
        "title='Percentiles for different methods and data: ' + str(a),",
        "title='Percentiles for different methods and data:"
    ],
    [
        "raise TypeError(\"a must be an array of real numbers\")",
        "raise TypeError(\"a must be an array of real"
    ],
    [
        "msg = (\"Only method 'inverted_cdf' supports weights. \"",
        "msg = (\"Only method"
    ],
    [
        "a, q, axis, out, overwrite_input, method, keepdims, weights)",
        "a, q, axis, out, overwrite_input, method,"
    ],
    [
        "def _quantile_dispatcher(a, q, axis=None, out=None, overwrite_input=None,",
        "def _quantile_dispatcher(a, q, axis=None, out=None,"
    ],
    [
        "Compute the q-th quantile of the data along the specified axis.",
        "Compute the q-th quantile of the data"
    ],
    [
        "a : array_like of real numbers",
        "a : array_like of real"
    ],
    [
        "Input array or object that can be converted to an array.",
        "Input array or object that can be converted to"
    ],
    [
        "Probability or sequence of probabilities of the quantiles to compute.",
        "Probability or sequence of probabilities of the"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple"
    ],
    [
        "Axis or axes along which the quantiles are computed. The default is",
        "Axis or axes along which the quantiles are computed."
    ],
    [
        "to compute the quantile(s) along a flattened version of the array.",
        "to compute the quantile(s) along a flattened"
    ],
    [
        "Alternative output array in which to place the result. It must have",
        "Alternative output array in which to"
    ],
    [
        "the same shape and buffer length as the expected output, but the",
        "the same shape and buffer length as the expected output,"
    ],
    [
        "type (of the output) will be cast if necessary.",
        "type (of the output) will be cast if"
    ],
    [
        "If True, then allow the input array `a` to be modified by",
        "If True, then allow the input array `a` to"
    ],
    [
        "intermediate calculations, to save memory. In this case, the",
        "intermediate calculations, to save memory. In"
    ],
    [
        "contents of the input `a` after this function completes is",
        "contents of the input `a` after this function completes"
    ],
    [
        "This parameter specifies the method to use for estimating the",
        "This parameter specifies the method to use"
    ],
    [
        "quantile.  There are many different methods, some unique to NumPy.",
        "quantile. There are many different methods,"
    ],
    [
        "The first three methods are discontinuous. For backward compatibility",
        "The first three methods are discontinuous. For backward"
    ],
    [
        "with previous versions of NumPy, the following discontinuous variations",
        "with previous versions of NumPy, the following discontinuous"
    ],
    [
        "This argument was previously called \"interpolation\" and only",
        "This argument was previously"
    ],
    [
        "offered the \"linear\" default and last four options.",
        "offered the \"linear\" default and"
    ],
    [
        "If this is set to True, the axes which are reduced are left in",
        "If this is set to True, the axes which are reduced"
    ],
    [
        "the result as dimensions with size one. With this option, the",
        "the result as dimensions with size one. With this option,"
    ],
    [
        "result will broadcast correctly against the original array `a`.",
        "result will broadcast correctly against"
    ],
    [
        "An array of weights associated with the values in `a`. Each value in",
        "An array of weights associated with the values in `a`. Each"
    ],
    [
        "`a` contributes to the quantile according to its associated weight.",
        "`a` contributes to the quantile"
    ],
    [
        "the size of `a` along the given axis) or of the same shape as `a`.",
        "the size of `a` along the given axis) or of the same shape as"
    ],
    [
        "If `weights=None`, then all data in `a` are assumed to have a",
        "If `weights=None`, then all data in `a` are"
    ],
    [
        "See the notes for more details.",
        "See the notes for"
    ],
    [
        "Deprecated name for the method keyword argument.",
        "Deprecated name for the"
    ],
    [
        "If `q` is a single probability and `axis=None`, then the result",
        "If `q` is a single probability and `axis=None`, then"
    ],
    [
        "is a scalar. If multiple probability levels are given, first axis",
        "is a scalar. If multiple probability"
    ],
    [
        "of the result corresponds to the quantiles. The other axes are",
        "of the result corresponds to the quantiles."
    ],
    [
        "the axes that remain after the reduction of `a`. If the input",
        "the axes that remain after the reduction of `a`. If the"
    ],
    [
        "same as that of the input. If `out` is specified, that array is",
        "same as that of the input. If `out` is specified, that array"
    ],
    [
        "Given a sample `a` from an underlying distribution, `quantile` provides a",
        "Given a sample `a` from an"
    ],
    [
        "nonparametric estimate of the inverse cumulative distribution function.",
        "nonparametric estimate of the"
    ],
    [
        "By default, this is done by interpolating between adjacent elements in",
        "By default, this is done by interpolating between"
    ],
    [
        "``y``, a sorted copy of `a`::",
        "``y``, a sorted copy of"
    ],
    [
        "where the index ``j`` and coefficient ``g`` are the integral and",
        "where the index ``j`` and coefficient ``g`` are"
    ],
    [
        "where ``m`` may be defined according to several different conventions.",
        "where ``m`` may be defined according to"
    ],
    [
        "The preferred convention may be selected using the ``method`` parameter:",
        "The preferred convention may be"
    ],
    [
        "The table above includes only the estimators from H&F that are continuous",
        "The table above includes only the estimators from H&F"
    ],
    [
        "defined as above, ``m`` is defined as follows, and ``g`` is a function",
        "defined as above, ``m`` is defined as follows,"
    ],
    [
        "For backward compatibility with previous versions of NumPy, `quantile`",
        "For backward compatibility with previous"
    ],
    [
        "provides four additional discontinuous estimators. Like",
        "provides four additional"
    ],
    [
        "but ``g`` is defined as follows.",
        "but ``g`` is defined"
    ],
    [
        "More formally, the quantile at probability level :math:`q` of a cumulative",
        "More formally, the quantile at probability level :math:`q` of a"
    ],
    [
        "distribution function :math:`F(y)=P(Y \\\\leq y)` with probability measure",
        "distribution function :math:`F(y)=P(Y \\\\leq y)` with"
    ],
    [
        ":math:`P` is defined as any number :math:`x` that fulfills the",
        ":math:`P` is defined as any number"
    ],
    [
        ".. math:: P(Y < x) \\\\leq q \\\\quad\\\\text{and}\\\\quad P(Y \\\\leq x) \\\\geq q",
        ".. math:: P(Y < x) \\\\leq q \\\\quad\\\\text{and}\\\\quad P(Y \\\\leq x)"
    ],
    [
        "Sample quantiles, the result of `quantile`, provide nonparametric",
        "Sample quantiles, the result of `quantile`,"
    ],
    [
        "estimation of the underlying population counterparts, represented by the",
        "estimation of the underlying population"
    ],
    [
        "unknown :math:`F`, given a data vector `a` of length ``n``.",
        "unknown :math:`F`, given a data"
    ],
    [
        "Some of the estimators above arise when one considers :math:`F` as the",
        "Some of the estimators above arise"
    ],
    [
        "empirical distribution function of the data, i.e.",
        "empirical distribution function of the data,"
    ],
    [
        "Then, different methods correspond to different choices of :math:`x` that",
        "Then, different methods correspond to"
    ],
    [
        "fulfill the above coverage conditions. Methods that follow this approach",
        "fulfill the above coverage conditions. Methods that follow"
    ],
    [
        "For weighted quantiles, the coverage conditions still hold. The",
        "For weighted quantiles, the coverage conditions still hold."
    ],
    [
        "empirical cumulative distribution is simply replaced by its weighted",
        "empirical cumulative distribution is simply"
    ],
    [
        ">>> assert not np.all(a == b)",
        ">>> assert not"
    ],
    [
        "See also `numpy.percentile` for a visualization of most methods.",
        "See also `numpy.percentile` for a visualization"
    ],
    [
        "raise TypeError(\"a must be an array of real numbers\")",
        "raise TypeError(\"a must be an array"
    ],
    [
        "if isinstance(q, (int, float)) and a.dtype.kind == \"f\":",
        "if isinstance(q, (int, float)) and a.dtype.kind =="
    ],
    [
        "msg = (\"Only method 'inverted_cdf' supports weights. \"",
        "msg = (\"Only method 'inverted_cdf'"
    ],
    [
        "a, q, axis, out, overwrite_input, method, keepdims, weights)",
        "a, q, axis, out, overwrite_input,"
    ],
    [
        "f\"the `interpolation=` argument to {fname} was renamed to \"",
        "f\"the `interpolation=` argument to {fname}"
    ],
    [
        "\"Users of the modes 'nearest', 'lower', 'higher', or \"",
        "\"Users of the modes 'nearest',"
    ],
    [
        "\"'midpoint' are encouraged to review the method they used. \"",
        "\"'midpoint' are encouraged to review the"
    ],
    [
        "\"You shall not pass both `method` and `interpolation`!\\n\"",
        "\"You shall not pass both `method`"
    ],
    [
        "\"(`interpolation` is Deprecated in favor of `method`)\")",
        "\"(`interpolation` is Deprecated in"
    ],
    [
        "def _compute_virtual_index(n, quantiles, alpha: float, beta: float):",
        "def _compute_virtual_index(n, quantiles, alpha:"
    ],
    [
        "Compute the floating point indexes of an array for the linear",
        "Compute the floating point indexes of an array"
    ],
    [
        "A constant used to correct the index computed.",
        "A constant used to correct"
    ],
    [
        "A constant used to correct the index computed.",
        "A constant used to correct the"
    ],
    [
        "alpha and beta values depend on the chosen method",
        "alpha and beta values depend"
    ],
    [
        "Hyndman&Fan paper \"Sample Quantiles in Statistical Packages\",",
        "Hyndman&Fan paper \"Sample Quantiles"
    ],
    [
        "return n * quantiles + (",
        "return n *"
    ],
    [
        "Compute gamma (a.k.a 'm' or 'weight') for the linear interpolation",
        "Compute gamma (a.k.a 'm' or"
    ],
    [
        "The indexes where the percentile is supposed to be found in the sorted",
        "The indexes where the percentile is supposed to be"
    ],
    [
        "The interpolation method chosen, which may have a specific rule",
        "The interpolation method chosen, which may have a specific"
    ],
    [
        "gamma is usually the fractional part of virtual_indexes but can be modified",
        "gamma is usually the fractional part of virtual_indexes but can"
    ],
    [
        "Compute the linear interpolation weighted by gamma on each point of",
        "Compute the linear interpolation weighted by gamma"
    ],
    [
        "lerp_interpolation = asanyarray(add(a, diff_b_a * t, out=out))",
        "lerp_interpolation = asanyarray(add(a, diff_b_a *"
    ],
    [
        "axis: int | None = None,",
        "axis: int | None ="
    ],
    [
        "wgt = None if weights is None else weights.ravel()",
        "wgt = None if weights is None"
    ],
    [
        "wgt = None if weights is None else weights.flatten()",
        "wgt = None if weights is"
    ],
    [
        "Get the valid indexes of arr neighbouring virtual_indexes.",
        "Get the valid indexes of arr"
    ],
    [
        "This is a companion function to linear interpolation of",
        "This is a companion function to linear interpolation"
    ],
    [
        "A Tuple of virtual_indexes neighbouring indexes",
        "A Tuple of virtual_indexes"
    ],
    [
        "Private function that doesn't support extended axis or keepdims.",
        "Private function that doesn't support extended axis or"
    ],
    [
        "These methods are extended to this function using _ureduce",
        "These methods are extended to"
    ],
    [
        "It computes the quantiles of the array for the given axis.",
        "It computes the quantiles of the"
    ],
    [
        "A linear interpolation is performed based on the `interpolation`.",
        "A linear interpolation is performed"
    ],
    [
        "np.issubdtype(arr.dtype, np.inexact) or arr.dtype.kind in 'Mm'",
        "np.issubdtype(arr.dtype, np.inexact) or arr.dtype.kind"
    ],
    [
        "f\"{method!r} is not a valid method. Use one of: \"",
        "f\"{method!r} is not a valid method. Use"
    ],
    [
        "supports_integers = method == 'linear' and int_virtual_indices",
        "supports_integers = method == 'linear'"
    ],
    [
        "msg = (f\"Wrong shape of argument 'out', shape={r_shape} is \"",
        "msg = (f\"Wrong shape of argument 'out', shape={r_shape} is"
    ],
    [
        "arr[np.s_[:, ] + kk], cdf[np.s_[:, ] + kk]",
        "arr[np.s_[:, ] + kk],"
    ],
    [
        "if result.shape == () and result.dtype == np.dtype(\"O\"):",
        "if result.shape == ()"
    ],
    [
        "Integrate along the given axis using the composite trapezoidal rule.",
        "Integrate along the given axis using the"
    ],
    [
        "If `x` is provided, the integration happens in sequence along its",
        "If `x` is provided, the integration"
    ],
    [
        "elements - they are not sorted.",
        "elements - they are not"
    ],
    [
        "When `x` is specified, this integrates along the parametric curve,",
        "When `x` is specified, this integrates"
    ],
    [
        "The sample points corresponding to the `y` values. If `x` is None,",
        "The sample points corresponding to the `y` values. If `x` is"
    ],
    [
        "the sample points are assumed to be evenly spaced `dx` apart. The",
        "the sample points are assumed to be"
    ],
    [
        "The axis along which to integrate.",
        "The axis along"
    ],
    [
        "Definite integral of `y` = n-dimensional array as approximated along",
        "Definite integral of `y` = n-dimensional"
    ],
    [
        "will be taken from `y` array, by default x-axis distances between",
        "will be taken from `y` array, by default x-axis"
    ],
    [
        "or with `dx` scalar.  Return value will be equal to combined area under",
        "or with `dx` scalar. Return value will be equal to"
    ],
    [
        "Use the trapezoidal rule on evenly spaced points:",
        "Use the trapezoidal rule"
    ],
    [
        "The spacing between sample points can be selected by either the",
        "The spacing between sample points can be selected"
    ],
    [
        "Using a decreasing ``x`` corresponds to integrating in reverse:",
        "Using a decreasing ``x`` corresponds to integrating in"
    ],
    [
        "More generally ``x`` is used to integrate along a parametric curve. We can",
        "More generally ``x`` is used to integrate along a parametric"
    ],
    [
        "Or estimate the area of a circle, noting we repeat the sample which closes",
        "Or estimate the area of a circle, noting we repeat the sample"
    ],
    [
        "``np.trapezoid`` can be applied along a specified axis to do multiple",
        "``np.trapezoid`` can be applied along a specified axis to do"
    ],
    [
        "Please use `trapezoid` instead, or one of the numerical integration",
        "Please use `trapezoid` instead, or one of"
    ],
    [
        "\"`trapz` is deprecated. Use `trapezoid` instead, or one of the \"",
        "\"`trapz` is deprecated. Use `trapezoid` instead,"
    ],
    [
        "Return a tuple of coordinate matrices from coordinate vectors.",
        "Return a tuple of coordinate matrices from coordinate"
    ],
    [
        "Make N-D coordinate arrays for vectorized evaluations of",
        "Make N-D coordinate arrays for"
    ],
    [
        "N-D scalar/vector fields over N-D grids, given",
        "N-D scalar/vector fields over N-D"
    ],
    [
        "Cartesian ('xy', default) or matrix ('ij') indexing of output.",
        "Cartesian ('xy', default) or matrix ('ij') indexing of"
    ],
    [
        "If True the shape of the returned coordinate array for dimension *i*",
        "If True the shape of the returned"
    ],
    [
        "intended to be use with :ref:`basics.broadcasting`.  When all",
        "intended to be use with"
    ],
    [
        "coordinates are used in an expression, broadcasting still leads to a",
        "coordinates are used in an expression, broadcasting still leads to"
    ],
    [
        "If False, a view into the original arrays are returned in order to",
        "If False, a view into the original arrays are returned in order"
    ],
    [
        "conserve memory.  Default is True.  Please note that",
        "conserve memory. Default is True. Please"
    ],
    [
        "``sparse=False, copy=False`` will likely return non-contiguous",
        "``sparse=False, copy=False`` will"
    ],
    [
        "arrays.  Furthermore, more than one element of a broadcast array",
        "arrays. Furthermore, more than one element of a broadcast"
    ],
    [
        "may refer to a single memory location.  If you need to write to the",
        "may refer to a single memory location. If you"
    ],
    [
        "with the elements of `xi` repeated to fill the matrix along",
        "with the elements of `xi` repeated"
    ],
    [
        "This function supports both indexing conventions through the indexing",
        "This function supports both indexing"
    ],
    [
        "keyword argument.  Giving the string 'ij' returns a meshgrid with",
        "keyword argument. Giving the string 'ij' returns a meshgrid"
    ],
    [
        "matrix indexing, while 'xy' returns a meshgrid with Cartesian indexing.",
        "matrix indexing, while 'xy' returns a meshgrid"
    ],
    [
        "with inputs of length M, N and P, outputs are of shape (N, M, P) for",
        "with inputs of length M, N and P, outputs are of shape (N, M,"
    ],
    [
        "'xy' indexing and (M, N, P) for 'ij' indexing.  The difference is",
        "'xy' indexing and (M, N, P) for 'ij'"
    ],
    [
        "illustrated by the following code snippet::",
        "illustrated by the following"
    ],
    [
        "xv, yv = np.meshgrid(x, y, indexing='ij')",
        "xv, yv = np.meshgrid(x, y,"
    ],
    [
        "xv, yv = np.meshgrid(x, y, indexing='xy')",
        "xv, yv = np.meshgrid(x, y,"
    ],
    [
        "mgrid : Construct a multi-dimensional \"meshgrid\" using indexing notation.",
        "mgrid : Construct a multi-dimensional"
    ],
    [
        "ogrid : Construct an open multi-dimensional \"meshgrid\" using indexing",
        "ogrid : Construct an open"
    ],
    [
        ">>> xv, yv = np.meshgrid(x, y)",
        ">>> xv, yv"
    ],
    [
        "The result of `meshgrid` is a coordinate grid:",
        "The result of `meshgrid`"
    ],
    [
        ">>> plt.plot(xv, yv, marker='o', color='k', linestyle='none')",
        ">>> plt.plot(xv, yv, marker='o',"
    ],
    [
        "You can create sparse output arrays to save memory and computation time.",
        "You can create sparse output arrays"
    ],
    [
        ">>> xv, yv = np.meshgrid(x, y, sparse=True)",
        ">>> xv, yv = np.meshgrid(x, y,"
    ],
    [
        "`meshgrid` is very useful to evaluate functions on a grid. If the",
        "`meshgrid` is very useful to evaluate functions on a"
    ],
    [
        "function depends on all coordinates, both dense and sparse outputs can be",
        "function depends on all coordinates, both dense and sparse outputs can"
    ],
    [
        ">>> xx, yy = np.meshgrid(x, y)",
        ">>> xx, yy"
    ],
    [
        ">>> xs, ys = np.meshgrid(x, y, sparse=True)",
        ">>> xs, ys ="
    ],
    [
        ">>> h = plt.contourf(x, y, zs)",
        ">>> h ="
    ],
    [
        "if indexing not in ['xy', 'ij']:",
        "if indexing not in"
    ],
    [
        "\"Valid values for `indexing` are 'xy' and 'ij'.\")",
        "\"Valid values for `indexing` are 'xy' and"
    ],
    [
        "output = tuple(x.copy() for x in output)",
        "output = tuple(x.copy() for x"
    ],
    [
        "Return a new array with sub-arrays along an axis deleted. For a one",
        "Return a new array with sub-arrays along an axis deleted. For a"
    ],
    [
        "dimensional array, this returns those entries not returned by",
        "dimensional array, this returns those entries not"
    ],
    [
        "obj : slice, int, array-like of ints or bools",
        "obj : slice, int, array-like"
    ],
    [
        "Indicate indices of sub-arrays to remove along the specified axis.",
        "Indicate indices of sub-arrays to remove along the specified"
    ],
    [
        "Boolean indices are now treated as a mask of elements to remove,",
        "Boolean indices are now treated as a"
    ],
    [
        "The axis along which to delete the subarray defined by `obj`.",
        "The axis along which to delete the subarray defined by"
    ],
    [
        "If `axis` is None, `obj` is applied to the flattened array.",
        "If `axis` is None, `obj` is applied to the"
    ],
    [
        "A copy of `arr` with the elements specified by `obj` removed. Note",
        "A copy of `arr` with the elements specified by `obj` removed."
    ],
    [
        "that `delete` does not occur in-place. If `axis` is None, `out` is",
        "that `delete` does not occur in-place. If `axis` is"
    ],
    [
        "insert : Insert elements into an array.",
        "insert : Insert elements into an"
    ],
    [
        "append : Append elements at the end of an array.",
        "append : Append elements at"
    ],
    [
        "Often it is preferable to use a boolean mask. For example:",
        "Often it is preferable to use a boolean mask. For"
    ],
    [
        "arrorder = 'F' if arr.flags.fnc else 'C'",
        "arrorder = 'F' if"
    ],
    [
        "slobj[axis] = slice(stop - numtodel, None)",
        "slobj[axis] = slice(stop -"
    ],
    [
        "keep = ones(stop - start, dtype=bool)",
        "keep = ones(stop -"
    ],
    [
        "slobj[axis] = slice(start, stop - numtodel)",
        "slobj[axis] = slice(start, stop"
    ],
    [
        "if isinstance(obj, (int, integer)) and not isinstance(obj, bool):",
        "if isinstance(obj, (int, integer)) and not"
    ],
    [
        "if (obj < -N or obj >= N):",
        "if (obj < -N or"
    ],
    [
        "\"index %i is out of bounds for axis %i with \"",
        "\"index %i is out of bounds for axis %i with"
    ],
    [
        "\"size %i\" % (obj, axis, N))",
        "\"size %i\" % (obj,"
    ],
    [
        "raise ValueError('boolean array argument obj to delete '",
        "raise ValueError('boolean array argument obj to"
    ],
    [
        "'must be one dimensional and match the axis '",
        "'must be one dimensional and"
    ],
    [
        "Insert values along the given axis before the given indices.",
        "Insert values along the given"
    ],
    [
        "obj : slice, int, array-like of ints or bools",
        "obj : slice, int, array-like"
    ],
    [
        "Object that defines the index or indices before which `values` is",
        "Object that defines the index or indices before"
    ],
    [
        "Boolean indices are now treated as a mask of elements to insert,",
        "Boolean indices are now treated as a mask of elements to"
    ],
    [
        "Support for multiple insertions when `obj` is a single scalar or a",
        "Support for multiple insertions when `obj` is a"
    ],
    [
        "sequence with one element (similar to calling insert multiple",
        "sequence with one element (similar to calling insert"
    ],
    [
        "Values to insert into `arr`. If the type of `values` is different",
        "Values to insert into `arr`. If the type of"
    ],
    [
        "from that of `arr`, `values` is converted to the type of `arr`.",
        "from that of `arr`, `values` is converted to the"
    ],
    [
        "`values` should be shaped so that ``arr[...,obj,...] = values``",
        "`values` should be shaped so that ``arr[...,obj,...]"
    ],
    [
        "Axis along which to insert `values`.  If `axis` is None then `arr`",
        "Axis along which to insert `values`. If `axis` is None"
    ],
    [
        "A copy of `arr` with `values` inserted.  Note that `insert`",
        "A copy of `arr` with `values` inserted."
    ],
    [
        "does not occur in-place: a new array is returned. If",
        "does not occur in-place: a new array"
    ],
    [
        "`axis` is None, `out` is a flattened array.",
        "`axis` is None, `out` is a flattened"
    ],
    [
        "append : Append elements at the end of an array.",
        "append : Append elements at the end of"
    ],
    [
        "concatenate : Join a sequence of arrays along an existing axis.",
        "concatenate : Join a sequence of arrays"
    ],
    [
        "delete : Delete elements from an array.",
        "delete : Delete elements"
    ],
    [
        "arrorder = 'F' if arr.flags.fnc else 'C'",
        "arrorder = 'F' if arr.flags.fnc"
    ],
    [
        "raise ValueError('boolean array argument obj to insert '",
        "raise ValueError('boolean array argument obj to"
    ],
    [
        "\"index array argument obj to insert must be one dimensional \"",
        "\"index array argument obj to insert must"
    ],
    [
        "if index < -N or index > N:",
        "if index < -N or index >"
    ],
    [
        "raise IndexError(f\"index {obj} is out of bounds for axis {axis} \"",
        "raise IndexError(f\"index {obj} is out of bounds for"
    ],
    [
        "values = array(values, copy=None, ndmin=arr.ndim, dtype=arr.dtype)",
        "values = array(values,"
    ],
    [
        "slobj[axis] = slice(index, index + numnew)",
        "slobj[axis] = slice(index, index"
    ],
    [
        "slobj[axis] = slice(index + numnew, None)",
        "slobj[axis] = slice(index +"
    ],
    [
        "Append values to the end of an array.",
        "Append values to the end"
    ],
    [
        "Values are appended to a copy of this array.",
        "Values are appended to a copy of this"
    ],
    [
        "These values are appended to a copy of `arr`.  It must be of the",
        "These values are appended to a copy"
    ],
    [
        "correct shape (the same shape as `arr`, excluding `axis`).  If",
        "correct shape (the same shape as"
    ],
    [
        "`axis` is not specified, `values` can be any shape and will be",
        "`axis` is not specified, `values` can be any shape and"
    ],
    [
        "The axis along which `values` are appended.  If `axis` is not",
        "The axis along which `values` are appended."
    ],
    [
        "given, both `arr` and `values` are flattened before use.",
        "given, both `arr` and `values` are flattened"
    ],
    [
        "A copy of `arr` with `values` appended to `axis`.  Note that",
        "A copy of `arr` with `values` appended"
    ],
    [
        "`append` does not occur in-place: a new array is allocated and",
        "`append` does not occur in-place: a"
    ],
    [
        "filled.  If `axis` is None, `out` is a flattened array.",
        "filled. If `axis` is None, `out` is a"
    ],
    [
        "insert : Insert elements into an array.",
        "insert : Insert elements"
    ],
    [
        "delete : Delete elements from an array.",
        "delete : Delete elements"
    ],
    [
        "When `axis` is specified, `values` must have the correct shape.",
        "When `axis` is specified, `values` must have the"
    ],
    [
        "ValueError: all the input arrays must have same number of dimensions, but",
        "ValueError: all the input arrays must have same number"
    ],
    [
        "Return the indices of the bins to which each value in input array belongs.",
        "Return the indices of the bins to which each value"
    ],
    [
        "`right`    order of bins  returned index `i` satisfies",
        "`right` order of bins returned index `i`"
    ],
    [
        "Indicating whether the intervals include the right or the left bin",
        "Indicating whether the intervals include the right or the"
    ],
    [
        "edge. Default behavior is (right==False) indicating that the interval",
        "edge. Default behavior is (right==False) indicating that the"
    ],
    [
        "does not include the right edge. The left bin end is open in this",
        "does not include the right edge. The left"
    ],
    [
        "Output array of indices, of same shape as `x`.",
        "Output array of indices, of same"
    ],
    [
        "If the type of the input is complex.",
        "If the type of"
    ],
    [
        "If values in `x` are such that they fall outside the bin range,",
        "If values in `x` are such that they fall"
    ],
    [
        "attempting to index `bins` with the indices that `digitize` returns",
        "attempting to index `bins` with the indices that `digitize`"
    ],
    [
        "`numpy.digitize` is  implemented in terms of `numpy.searchsorted`.",
        "`numpy.digitize` is implemented in terms"
    ],
    [
        "This means that a binary search is used to bin the values, which scales",
        "This means that a binary search is used"
    ],
    [
        "much better for larger number of bins than the previous linear search.",
        "much better for larger number of bins than the previous linear"
    ],
    [
        "For monotonically *increasing* `bins`, the following are equivalent::",
        "For monotonically *increasing* `bins`, the"
    ],
    [
        "Note that as the order of the arguments are reversed, the side must be too.",
        "Note that as the order of the arguments are reversed, the side must be"
    ],
    [
        "The `searchsorted` call is marginally faster, as it does not do any",
        "The `searchsorted` call is marginally faster, as it does"
    ],
    [
        "monotonicity checks. Perhaps more importantly, it supports all dtypes.",
        "monotonicity checks. Perhaps more importantly,"
    ],
    [
        "raise TypeError(\"x may not be complex\")",
        "raise TypeError(\"x may"
    ],
    [
        "raise ValueError(\"bins must be monotonically increasing or decreasing\")",
        "raise ValueError(\"bins must be monotonically increasing"
    ],
    [
        "side = 'left' if right else 'right'",
        "side = 'left' if right"
    ],
    [
        "- `nanmin` -- minimum non-NaN value",
        "- `nanmin` -- minimum"
    ],
    [
        "- `nanmax` -- maximum non-NaN value",
        "- `nanmax` -- maximum non-NaN"
    ],
    [
        "- `nanargmin` -- index of minimum non-NaN value",
        "- `nanargmin` -- index of minimum non-NaN"
    ],
    [
        "- `nanargmax` -- index of maximum non-NaN value",
        "- `nanargmax` -- index of"
    ],
    [
        "- `nansum` -- sum of non-NaN values",
        "- `nansum` -- sum"
    ],
    [
        "- `nanprod` -- product of non-NaN values",
        "- `nanprod` -- product"
    ],
    [
        "- `nancumsum` -- cumulative sum of non-NaN values",
        "- `nancumsum` -- cumulative sum of non-NaN"
    ],
    [
        "- `nancumprod` -- cumulative product of non-NaN values",
        "- `nancumprod` -- cumulative product"
    ],
    [
        "- `nanmean` -- mean of non-NaN values",
        "- `nanmean` -- mean of"
    ],
    [
        "- `nanvar` -- variance of non-NaN values",
        "- `nanvar` -- variance"
    ],
    [
        "- `nanstd` -- standard deviation of non-NaN values",
        "- `nanstd` -- standard deviation"
    ],
    [
        "- `nanmedian` -- median of non-NaN values",
        "- `nanmedian` -- median"
    ],
    [
        "- `nanquantile` -- qth quantile of non-NaN values",
        "- `nanquantile` -- qth quantile"
    ],
    [
        "- `nanpercentile` -- qth percentile of non-NaN values",
        "- `nanpercentile` -- qth percentile of non-NaN"
    ],
    [
        "from numpy.lib import _function_base_impl as fnb",
        "from numpy.lib import _function_base_impl as"
    ],
    [
        "'nansum', 'nanmax', 'nanmin', 'nanargmax', 'nanargmin', 'nanmean',",
        "'nansum', 'nanmax', 'nanmin', 'nanargmax',"
    ],
    [
        "Alternate output array in which to place the result.  The default",
        "Alternate output array in which to place the result."
    ],
    [
        "is ``None``; if provided, it must have the same shape as the",
        "is ``None``; if provided, it must have the same"
    ],
    [
        "expected output and will prevent the allocation of a new array.",
        "expected output and will prevent the"
    ],
    [
        "y : bool ndarray or True",
        "y : bool ndarray or"
    ],
    [
        "A bool array where ``np.nan`` positions are marked with ``False``",
        "A bool array where ``np.nan``"
    ],
    [
        "and other positions are marked with ``True``. If the type of ``a``",
        "and other positions are marked with ``True``. If"
    ],
    [
        "is such that it can't possibly contain ``np.nan``, returns ``True``.",
        "is such that it can't possibly contain ``np.nan``,"
    ],
    [
        "If `a` is of inexact type, make a copy of `a`, replace NaNs with",
        "If `a` is of inexact type, make a copy of"
    ],
    [
        "the `val` value, and return the copy together with a boolean mask",
        "the `val` value, and return the copy together with a"
    ],
    [
        "marking the locations where NaNs were present. If `a` is not of",
        "marking the locations where NaNs were present. If `a`"
    ],
    [
        "inexact type, do nothing and return `a` together with a mask of None.",
        "inexact type, do nothing and return `a` together with a mask"
    ],
    [
        "Note that scalars will end up as array scalars, which is important",
        "Note that scalars will end up as array"
    ],
    [
        "for using the result as the value of the out argument in some",
        "for using the result as the value of the out"
    ],
    [
        "NaN values are set to val before doing the operation.",
        "NaN values are set to val before"
    ],
    [
        "If `a` is of inexact type, return a copy of `a` with the NaNs",
        "If `a` is of inexact type, return a"
    ],
    [
        "replaced by the fill value, otherwise return `a`.",
        "replaced by the fill"
    ],
    [
        "If `a` is of inexact type, return a boolean mask marking locations of",
        "If `a` is of inexact type, return"
    ],
    [
        "Replace values in `a` with NaN where `mask` is True.  This differs from",
        "Replace values in `a` with NaN where `mask` is True."
    ],
    [
        "copyto in that it will deal with the case where `a` is a numpy scalar.",
        "copyto in that it will deal with the case where `a` is"
    ],
    [
        "a : ndarray or numpy scalar",
        "a : ndarray or numpy"
    ],
    [
        "Array or numpy scalar some of whose values are to be replaced",
        "Array or numpy scalar some of whose values are"
    ],
    [
        "Boolean array. Where True the corresponding element of `a` is",
        "Boolean array. Where True the corresponding"
    ],
    [
        "Array with elements replaced or scalar `val`.",
        "Array with elements replaced"
    ],
    [
        "Presumably faster as it incurs fewer copies",
        "Presumably faster as it incurs fewer"
    ],
    [
        "Second array with nan element positions of first array removed.",
        "Second array with nan element positions of first"
    ],
    [
        "True if `res` can be modified in place, given the constraint on the",
        "True if `res` can be modified in place,"
    ],
    [
        "Compute a/b ignoring invalid results. If `a` is an array the division",
        "Compute a/b ignoring invalid results. If `a` is an array"
    ],
    [
        "is done in place. If `a` is a scalar, then its type is preserved in the",
        "is done in place. If `a` is a scalar, then its"
    ],
    [
        "output. If out is None, then a is used instead so that the division",
        "output. If out is None, then a is"
    ],
    [
        "is in place. Note that this is only called with `a` an inexact type.",
        "is in place. Note that this is only"
    ],
    [
        "Numerator. Expected to be of inexact type but not checked.",
        "Numerator. Expected to be of inexact"
    ],
    [
        "Alternate output array in which to place the result.  The default",
        "Alternate output array in which to place the"
    ],
    [
        "is ``None``; if provided, it must have the same shape as the",
        "is ``None``; if provided, it must have the same shape"
    ],
    [
        "expected output, but the type will be cast if necessary.",
        "expected output, but the type will"
    ],
    [
        "The return value is a/b. If `a` was an ndarray the division is done",
        "The return value is a/b. If `a`"
    ],
    [
        "in place. If `a` is a numpy scalar, the division preserves its type.",
        "in place. If `a` is a numpy scalar,"
    ],
    [
        "def nanmin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,",
        "def nanmin(a, axis=None,"
    ],
    [
        "Return minimum of an array or minimum along an axis, ignoring any NaNs.",
        "Return minimum of an array or minimum along an axis,"
    ],
    [
        "When all-NaN slices are encountered a ``RuntimeWarning`` is raised and",
        "When all-NaN slices are encountered a ``RuntimeWarning`` is raised"
    ],
    [
        "Nan is returned for that slice.",
        "Nan is returned for"
    ],
    [
        "Array containing numbers whose minimum is desired. If `a` is not an",
        "Array containing numbers whose minimum is desired. If"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple of int, None},"
    ],
    [
        "Axis or axes along which the minimum is computed. The default is to compute",
        "Axis or axes along which the minimum is computed."
    ],
    [
        "the minimum of the flattened array.",
        "the minimum of the flattened"
    ],
    [
        "Alternate output array in which to place the result.  The default",
        "Alternate output array in which to place"
    ],
    [
        "is ``None``; if provided, it must have the same shape as the",
        "is ``None``; if provided, it must"
    ],
    [
        "expected output, but the type will be cast if necessary. See",
        "expected output, but the type will"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly against the"
    ],
    [
        "If the value is anything but the default, then",
        "If the value is anything"
    ],
    [
        "`keepdims` will be passed through to the `min` method",
        "`keepdims` will be passed through to"
    ],
    [
        "of sub-classes of `ndarray`.  If the sub-classes methods",
        "of sub-classes of `ndarray`. If the sub-classes"
    ],
    [
        "does not implement `keepdims` any exceptions will be raised.",
        "does not implement `keepdims` any exceptions will"
    ],
    [
        "The maximum value of an output element. Must be present to allow",
        "The maximum value of an output element. Must be"
    ],
    [
        "computation on empty slice. See `~numpy.ufunc.reduce` for details.",
        "computation on empty slice. See `~numpy.ufunc.reduce`"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like"
    ],
    [
        "Elements to compare for the minimum. See `~numpy.ufunc.reduce`",
        "Elements to compare for"
    ],
    [
        "An array with the same shape as `a`, with the specified axis",
        "An array with the same shape as `a`, with the specified"
    ],
    [
        "scalar is returned.  The same dtype as `a` is returned.",
        "scalar is returned. The same dtype as"
    ],
    [
        "The maximum value of an array along a given axis, ignoring any NaNs.",
        "The maximum value of an array along a given axis, ignoring"
    ],
    [
        "The minimum value of an array along a given axis, propagating any NaNs.",
        "The minimum value of an array along a given axis, propagating"
    ],
    [
        "Element-wise minimum of two arrays, ignoring any NaNs.",
        "Element-wise minimum of two arrays,"
    ],
    [
        "Element-wise minimum of two arrays, propagating any NaNs.",
        "Element-wise minimum of two arrays,"
    ],
    [
        "Shows which elements are Not a Number (NaN).",
        "Shows which elements are"
    ],
    [
        "Shows which elements are neither NaN nor infinity.",
        "Shows which elements are neither"
    ],
    [
        "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic",
        "NumPy uses the IEEE Standard for"
    ],
    [
        "Positive infinity is treated as a very large number and negative",
        "Positive infinity is treated as a very large"
    ],
    [
        "infinity is treated as a very small (i.e. negative) number.",
        "infinity is treated as a very"
    ],
    [
        "If the input has a integer type the function is equivalent to np.min.",
        "If the input has a integer type the function"
    ],
    [
        "When positive infinity and negative infinity are present:",
        "When positive infinity and"
    ],
    [
        "if type(a) is np.ndarray and a.dtype != np.object_:",
        "if type(a) is np.ndarray and a.dtype"
    ],
    [
        "res = np.fmin.reduce(a, axis=axis, out=out, **kwargs)",
        "res = np.fmin.reduce(a, axis=axis,"
    ],
    [
        "res = np.amin(a, axis=axis, out=out, **kwargs)",
        "res = np.amin(a,"
    ],
    [
        "def nanmax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,",
        "def nanmax(a, axis=None, out=None, keepdims=np._NoValue,"
    ],
    [
        "Return the maximum of an array or maximum along an axis, ignoring any",
        "Return the maximum of an array or maximum along an"
    ],
    [
        "NaNs.  When all-NaN slices are encountered a ``RuntimeWarning`` is",
        "NaNs. When all-NaN slices are encountered a"
    ],
    [
        "raised and NaN is returned for that slice.",
        "raised and NaN is"
    ],
    [
        "Array containing numbers whose maximum is desired. If `a` is not an",
        "Array containing numbers whose maximum is desired."
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple of int,"
    ],
    [
        "Axis or axes along which the maximum is computed. The default is to compute",
        "Axis or axes along which the maximum is computed. The default is"
    ],
    [
        "the maximum of the flattened array.",
        "the maximum of the flattened"
    ],
    [
        "Alternate output array in which to place the result.  The default",
        "Alternate output array in which to place the result. The"
    ],
    [
        "is ``None``; if provided, it must have the same shape as the",
        "is ``None``; if provided, it must"
    ],
    [
        "expected output, but the type will be cast if necessary. See",
        "expected output, but the type will be"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly against the"
    ],
    [
        "If the value is anything but the default, then",
        "If the value is anything"
    ],
    [
        "`keepdims` will be passed through to the `max` method",
        "`keepdims` will be passed through to"
    ],
    [
        "of sub-classes of `ndarray`.  If the sub-classes methods",
        "of sub-classes of `ndarray`. If the sub-classes"
    ],
    [
        "does not implement `keepdims` any exceptions will be raised.",
        "does not implement `keepdims` any"
    ],
    [
        "The minimum value of an output element. Must be present to allow",
        "The minimum value of an output element. Must be present to"
    ],
    [
        "computation on empty slice. See `~numpy.ufunc.reduce` for details.",
        "computation on empty slice. See `~numpy.ufunc.reduce`"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of bool,"
    ],
    [
        "Elements to compare for the maximum. See `~numpy.ufunc.reduce`",
        "Elements to compare for"
    ],
    [
        "An array with the same shape as `a`, with the specified axis removed.",
        "An array with the same shape as `a`,"
    ],
    [
        "returned.  The same dtype as `a` is returned.",
        "returned. The same dtype as `a` is"
    ],
    [
        "The minimum value of an array along a given axis, ignoring any NaNs.",
        "The minimum value of an array along a given axis, ignoring"
    ],
    [
        "The maximum value of an array along a given axis, propagating any NaNs.",
        "The maximum value of an array along a given axis,"
    ],
    [
        "Element-wise maximum of two arrays, ignoring any NaNs.",
        "Element-wise maximum of two"
    ],
    [
        "Element-wise maximum of two arrays, propagating any NaNs.",
        "Element-wise maximum of two arrays, propagating"
    ],
    [
        "Shows which elements are Not a Number (NaN).",
        "Shows which elements are Not"
    ],
    [
        "Shows which elements are neither NaN nor infinity.",
        "Shows which elements are"
    ],
    [
        "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic",
        "NumPy uses the IEEE Standard for"
    ],
    [
        "Positive infinity is treated as a very large number and negative",
        "Positive infinity is treated as a very large number and"
    ],
    [
        "infinity is treated as a very small (i.e. negative) number.",
        "infinity is treated as a"
    ],
    [
        "If the input has a integer type the function is equivalent to np.max.",
        "If the input has a integer type the function is equivalent"
    ],
    [
        "When positive infinity and negative infinity are present:",
        "When positive infinity and negative infinity"
    ],
    [
        "if type(a) is np.ndarray and a.dtype != np.object_:",
        "if type(a) is np.ndarray and a.dtype !="
    ],
    [
        "res = np.fmax.reduce(a, axis=axis, out=out, **kwargs)",
        "res = np.fmax.reduce(a, axis=axis,"
    ],
    [
        "res = np.amax(a, axis=axis, out=out, **kwargs)",
        "res = np.amax(a, axis=axis, out=out,"
    ],
    [
        "def _nanargmin_dispatcher(a, axis=None, out=None, *, keepdims=None):",
        "def _nanargmin_dispatcher(a, axis=None,"
    ],
    [
        "def nanargmin(a, axis=None, out=None, *, keepdims=np._NoValue):",
        "def nanargmin(a, axis=None,"
    ],
    [
        "Return the indices of the minimum values in the specified axis ignoring",
        "Return the indices of the minimum values in the"
    ],
    [
        "NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the results",
        "NaNs. For all-NaN slices ``ValueError``"
    ],
    [
        "cannot be trusted if a slice contains only NaNs and Infs.",
        "cannot be trusted if a slice contains"
    ],
    [
        "Axis along which to operate.  By default flattened input is used.",
        "Axis along which to operate. By"
    ],
    [
        "If provided, the result will be inserted into this array. It should",
        "If provided, the result will be"
    ],
    [
        "be of the appropriate shape and dtype.",
        "be of the appropriate"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with"
    ],
    [
        "the result will broadcast correctly against the array.",
        "the result will broadcast"
    ],
    [
        "An array of indices or a single index value.",
        "An array of indices or a single"
    ],
    [
        "if mask is not None and mask.size:",
        "if mask is not"
    ],
    [
        "res = np.argmin(a, axis=axis, out=out, keepdims=keepdims)",
        "res = np.argmin(a,"
    ],
    [
        "def _nanargmax_dispatcher(a, axis=None, out=None, *, keepdims=None):",
        "def _nanargmax_dispatcher(a, axis=None, out=None,"
    ],
    [
        "def nanargmax(a, axis=None, out=None, *, keepdims=np._NoValue):",
        "def nanargmax(a, axis=None, out=None, *,"
    ],
    [
        "Return the indices of the maximum values in the specified axis ignoring",
        "Return the indices of the maximum"
    ],
    [
        "NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the",
        "NaNs. For all-NaN slices ``ValueError`` is"
    ],
    [
        "results cannot be trusted if a slice contains only NaNs and -Infs.",
        "results cannot be trusted if a slice contains"
    ],
    [
        "Axis along which to operate.  By default flattened input is used.",
        "Axis along which to operate. By default flattened"
    ],
    [
        "If provided, the result will be inserted into this array. It should",
        "If provided, the result will be inserted into"
    ],
    [
        "be of the appropriate shape and dtype.",
        "be of the appropriate"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one."
    ],
    [
        "the result will broadcast correctly against the array.",
        "the result will broadcast"
    ],
    [
        "An array of indices or a single index value.",
        "An array of indices or a single"
    ],
    [
        "if mask is not None and mask.size:",
        "if mask is not None"
    ],
    [
        "res = np.argmax(a, axis=axis, out=out, keepdims=keepdims)",
        "res = np.argmax(a, axis=axis,"
    ],
    [
        "def _nansum_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,",
        "def _nansum_dispatcher(a, axis=None, dtype=None,"
    ],
    [
        "def nansum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,",
        "def nansum(a, axis=None,"
    ],
    [
        "Return the sum of array elements over a given axis treating Not a",
        "Return the sum of array elements over a"
    ],
    [
        "empty. In later versions zero is returned.",
        "empty. In later versions"
    ],
    [
        "Array containing numbers whose sum is desired. If `a` is not an",
        "Array containing numbers whose sum is desired. If `a`"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple"
    ],
    [
        "Axis or axes along which the sum is computed. The default is to compute the",
        "Axis or axes along which the sum is computed."
    ],
    [
        "The type of the returned array and of the accumulator in which the",
        "The type of the returned array and of the accumulator in"
    ],
    [
        "elements are summed.  By default, the dtype of `a` is used.  An",
        "elements are summed. By default, the dtype of `a` is"
    ],
    [
        "exception is when `a` has an integer type with less precision than",
        "exception is when `a` has an integer type with less precision"
    ],
    [
        "the platform (u)intp. In that case, the default will be either",
        "the platform (u)intp. In that case, the default will be"
    ],
    [
        "bits. For inexact inputs, dtype must be inexact.",
        "bits. For inexact inputs, dtype"
    ],
    [
        "Alternate output array in which to place the result.  The default",
        "Alternate output array in which to"
    ],
    [
        "is ``None``. If provided, it must have the same shape as the",
        "is ``None``. If provided, it must have the"
    ],
    [
        "expected output, but the type will be cast if necessary.  See",
        "expected output, but the type will"
    ],
    [
        ":ref:`ufuncs-output-type` for more details. The casting of NaN to integer",
        ":ref:`ufuncs-output-type` for more details. The casting of"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With this"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly"
    ],
    [
        "If the value is anything but the default, then",
        "If the value is anything but the default,"
    ],
    [
        "`keepdims` will be passed through to the `mean` or `sum` methods",
        "`keepdims` will be passed through to the `mean`"
    ],
    [
        "of sub-classes of `ndarray`.  If the sub-classes methods",
        "of sub-classes of `ndarray`. If the sub-classes"
    ],
    [
        "does not implement `keepdims` any exceptions will be raised.",
        "does not implement `keepdims` any exceptions will be"
    ],
    [
        "Starting value for the sum. See `~numpy.ufunc.reduce` for details.",
        "Starting value for the sum. See"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like"
    ],
    [
        "Elements to include in the sum. See `~numpy.ufunc.reduce` for details.",
        "Elements to include in the sum. See"
    ],
    [
        "A new array holding the result is returned unless `out` is",
        "A new array holding the result is returned unless"
    ],
    [
        "specified, in which it is returned. The result has the same",
        "specified, in which it is returned. The result has"
    ],
    [
        "size as `a`, and the same shape as `a` if `axis` is not None",
        "size as `a`, and the same shape as `a` if `axis` is"
    ],
    [
        "numpy.sum : Sum across array propagating NaNs.",
        "numpy.sum : Sum across array propagating"
    ],
    [
        "isnan : Show which elements are NaN.",
        "isnan : Show which elements are"
    ],
    [
        "isfinite : Show which elements are not NaN or +/-inf.",
        "isfinite : Show which elements are not NaN or"
    ],
    [
        "If both positive and negative infinity are present, the sum will be Not",
        "If both positive and negative infinity are present, the sum will be"
    ],
    [
        "return np.sum(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims,",
        "return np.sum(a, axis=axis, dtype=dtype, out=out,"
    ],
    [
        "def _nanprod_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,",
        "def _nanprod_dispatcher(a, axis=None,"
    ],
    [
        "def nanprod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,",
        "def nanprod(a, axis=None,"
    ],
    [
        "Return the product of array elements over a given axis treating Not a",
        "Return the product of array elements over a given"
    ],
    [
        "One is returned for slices that are all-NaN or empty.",
        "One is returned for slices that are all-NaN"
    ],
    [
        "Array containing numbers whose product is desired. If `a` is not an",
        "Array containing numbers whose product is"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple of int,"
    ],
    [
        "Axis or axes along which the product is computed. The default is to compute",
        "Axis or axes along which the product is computed. The"
    ],
    [
        "the product of the flattened array.",
        "the product of"
    ],
    [
        "The type of the returned array and of the accumulator in which the",
        "The type of the returned array and"
    ],
    [
        "elements are summed.  By default, the dtype of `a` is used.  An",
        "elements are summed. By default, the"
    ],
    [
        "exception is when `a` has an integer type with less precision than",
        "exception is when `a` has an integer type with less precision"
    ],
    [
        "the platform (u)intp. In that case, the default will be either",
        "the platform (u)intp. In that case, the default will be"
    ],
    [
        "bits. For inexact inputs, dtype must be inexact.",
        "bits. For inexact inputs,"
    ],
    [
        "Alternate output array in which to place the result.  The default",
        "Alternate output array in which to place"
    ],
    [
        "is ``None``. If provided, it must have the same shape as the",
        "is ``None``. If provided, it must have the same"
    ],
    [
        "expected output, but the type will be cast if necessary. See",
        "expected output, but the type will be"
    ],
    [
        ":ref:`ufuncs-output-type` for more details. The casting of NaN to integer",
        ":ref:`ufuncs-output-type` for more details. The casting of NaN to"
    ],
    [
        "If True, the axes which are reduced are left in the result as",
        "If True, the axes which are reduced are left in the"
    ],
    [
        "dimensions with size one. With this option, the result will",
        "dimensions with size one. With this option, the result"
    ],
    [
        "broadcast correctly against the original `arr`.",
        "broadcast correctly against the original"
    ],
    [
        "The starting value for this product. See `~numpy.ufunc.reduce`",
        "The starting value for"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of"
    ],
    [
        "Elements to include in the product. See `~numpy.ufunc.reduce`",
        "Elements to include in the product."
    ],
    [
        "A new array holding the result is returned unless `out` is",
        "A new array holding the result is returned unless `out`"
    ],
    [
        "specified, in which case it is returned.",
        "specified, in which case it is"
    ],
    [
        "numpy.prod : Product across array propagating NaNs.",
        "numpy.prod : Product across array propagating"
    ],
    [
        "isnan : Show which elements are NaN.",
        "isnan : Show which"
    ],
    [
        "return np.prod(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims,",
        "return np.prod(a, axis=axis, dtype=dtype,"
    ],
    [
        "Return the cumulative sum of array elements over a given axis treating Not a",
        "Return the cumulative sum of array elements over a given"
    ],
    [
        "Numbers (NaNs) as zero.  The cumulative sum does not change when NaNs are",
        "Numbers (NaNs) as zero. The cumulative sum does not change when NaNs"
    ],
    [
        "encountered and leading NaNs are replaced by zeros.",
        "encountered and leading NaNs are replaced by"
    ],
    [
        "Zeros are returned for slices that are all-NaN or empty.",
        "Zeros are returned for slices that are"
    ],
    [
        "Axis along which the cumulative sum is computed. The default",
        "Axis along which the cumulative sum is computed."
    ],
    [
        "(None) is to compute the cumsum over the flattened array.",
        "(None) is to compute the"
    ],
    [
        "Type of the returned array and of the accumulator in which the",
        "Type of the returned array and of"
    ],
    [
        "elements are summed.  If `dtype` is not specified, it defaults",
        "elements are summed. If `dtype`"
    ],
    [
        "to the dtype of `a`, unless `a` has an integer dtype with a",
        "to the dtype of `a`, unless `a` has"
    ],
    [
        "precision less than that of the default platform integer.  In",
        "precision less than that of the"
    ],
    [
        "that case, the default platform integer is used.",
        "that case, the default platform"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the result."
    ],
    [
        "have the same shape and buffer length as the expected output",
        "have the same shape and buffer length as"
    ],
    [
        "but the type will be cast if necessary. See :ref:`ufuncs-output-type` for",
        "but the type will be cast"
    ],
    [
        "A new array holding the result is returned unless `out` is",
        "A new array holding the result"
    ],
    [
        "specified, in which it is returned. The result has the same",
        "specified, in which it is returned. The"
    ],
    [
        "size as `a`, and the same shape as `a` if `axis` is not None",
        "size as `a`, and the same shape as `a` if `axis` is not"
    ],
    [
        "numpy.cumsum : Cumulative sum across array propagating NaNs.",
        "numpy.cumsum : Cumulative sum across array"
    ],
    [
        "isnan : Show which elements are NaN.",
        "isnan : Show which elements are"
    ],
    [
        "Return the cumulative product of array elements over a given axis treating Not a",
        "Return the cumulative product of array elements"
    ],
    [
        "Numbers (NaNs) as one.  The cumulative product does not change when NaNs are",
        "Numbers (NaNs) as one. The cumulative product does not"
    ],
    [
        "encountered and leading NaNs are replaced by ones.",
        "encountered and leading NaNs are"
    ],
    [
        "Ones are returned for slices that are all-NaN or empty.",
        "Ones are returned for slices that"
    ],
    [
        "Axis along which the cumulative product is computed.  By default",
        "Axis along which the cumulative product"
    ],
    [
        "Type of the returned array, as well as of the accumulator in which",
        "Type of the returned array, as well as of the accumulator"
    ],
    [
        "the elements are multiplied.  If *dtype* is not specified, it",
        "the elements are multiplied. If *dtype* is"
    ],
    [
        "defaults to the dtype of `a`, unless `a` has an integer dtype with",
        "defaults to the dtype of `a`, unless `a` has an"
    ],
    [
        "a precision less than that of the default platform integer.  In",
        "a precision less than that of the default platform"
    ],
    [
        "that case, the default platform integer is used instead.",
        "that case, the default platform"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the"
    ],
    [
        "have the same shape and buffer length as the expected output",
        "have the same shape and buffer length as"
    ],
    [
        "but the type of the resulting values will be cast if necessary.",
        "but the type of the resulting values will be cast if"
    ],
    [
        "A new array holding the result is returned unless `out` is",
        "A new array holding the result"
    ],
    [
        "specified, in which case it is returned.",
        "specified, in which case it is"
    ],
    [
        "numpy.cumprod : Cumulative product across array propagating NaNs.",
        "numpy.cumprod : Cumulative product across array"
    ],
    [
        "isnan : Show which elements are NaN.",
        "isnan : Show which elements"
    ],
    [
        "def _nanmean_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,",
        "def _nanmean_dispatcher(a, axis=None,"
    ],
    [
        "def nanmean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,",
        "def nanmean(a, axis=None,"
    ],
    [
        "Compute the arithmetic mean along the specified axis, ignoring NaNs.",
        "Compute the arithmetic mean along the specified"
    ],
    [
        "Returns the average of the array elements.  The average is taken over",
        "Returns the average of the array elements."
    ],
    [
        "the flattened array by default, otherwise over the specified axis.",
        "the flattened array by default, otherwise over the specified"
    ],
    [
        "For all-NaN slices, NaN is returned and a `RuntimeWarning` is raised.",
        "For all-NaN slices, NaN is returned and"
    ],
    [
        "Array containing numbers whose mean is desired. If `a` is not an",
        "Array containing numbers whose mean is desired. If `a`"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple of"
    ],
    [
        "Axis or axes along which the means are computed. The default is to compute",
        "Axis or axes along which the means are computed. The default is"
    ],
    [
        "the mean of the flattened array.",
        "the mean of the flattened"
    ],
    [
        "Type to use in computing the mean.  For integer inputs, the default",
        "Type to use in computing the mean. For integer"
    ],
    [
        "Alternate output array in which to place the result.  The default",
        "Alternate output array in which to place"
    ],
    [
        "is ``None``; if provided, it must have the same shape as the",
        "is ``None``; if provided, it must have the same shape as"
    ],
    [
        "expected output, but the type will be cast if necessary.",
        "expected output, but the type will be"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes which"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly against"
    ],
    [
        "If the value is anything but the default, then",
        "If the value is anything but the default,"
    ],
    [
        "`keepdims` will be passed through to the `mean` or `sum` methods",
        "`keepdims` will be passed through to the `mean` or `sum`"
    ],
    [
        "of sub-classes of `ndarray`.  If the sub-classes methods",
        "of sub-classes of `ndarray`."
    ],
    [
        "does not implement `keepdims` any exceptions will be raised.",
        "does not implement `keepdims` any exceptions will be"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of bool,"
    ],
    [
        "Elements to include in the mean. See `~numpy.ufunc.reduce` for details.",
        "Elements to include in the mean. See `~numpy.ufunc.reduce`"
    ],
    [
        "m : ndarray, see dtype parameter above",
        "m : ndarray, see dtype parameter"
    ],
    [
        "If `out=None`, returns a new array containing the mean values,",
        "If `out=None`, returns a new array"
    ],
    [
        "otherwise a reference to the output array is returned. Nan is",
        "otherwise a reference to the output"
    ],
    [
        "returned for slices that contain only NaNs.",
        "returned for slices that contain only"
    ],
    [
        "mean : Arithmetic mean taken while not ignoring NaNs",
        "mean : Arithmetic mean taken while"
    ],
    [
        "The arithmetic mean is the sum of the non-NaN elements along the axis",
        "The arithmetic mean is the sum of the"
    ],
    [
        "divided by the number of non-NaN elements.",
        "divided by the number of non-NaN"
    ],
    [
        "Note that for floating-point input, the mean is computed using the same",
        "Note that for floating-point input, the mean"
    ],
    [
        "precision the input has.  Depending on the input data, this can cause",
        "precision the input has. Depending on"
    ],
    [
        "higher-precision accumulator using the `dtype` keyword can alleviate",
        "higher-precision accumulator using the `dtype` keyword"
    ],
    [
        "return np.mean(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,",
        "return np.mean(arr, axis=axis, dtype=dtype, out=out,"
    ],
    [
        "if dtype is not None and not issubclass(dtype.type, np.inexact):",
        "if dtype is not None and not"
    ],
    [
        "raise TypeError(\"If a is inexact, then dtype must be inexact\")",
        "raise TypeError(\"If a is inexact, then dtype must be"
    ],
    [
        "if out is not None and not issubclass(out.dtype.type, np.inexact):",
        "if out is not None and not issubclass(out.dtype.type,"
    ],
    [
        "raise TypeError(\"If a is inexact, then out must be inexact\")",
        "raise TypeError(\"If a is inexact, then out"
    ],
    [
        "cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims,",
        "cnt = np.sum(~mask, axis=axis, dtype=np.intp,"
    ],
    [
        "tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,",
        "tot = np.sum(arr, axis=axis,"
    ],
    [
        "Private function that doesn't support extended axis or keepdims.",
        "Private function that doesn't support extended axis"
    ],
    [
        "These methods are extended to this function using _ureduce",
        "These methods are extended to this function"
    ],
    [
        "sort + indexing median, faster for small medians along multiple",
        "sort + indexing median, faster"
    ],
    [
        "dimensions due to the high overhead of apply_along_axis",
        "dimensions due to the high overhead"
    ],
    [
        "def nanmedian(a, axis=None, out=None, overwrite_input=False, keepdims=np._NoValue):",
        "def nanmedian(a, axis=None,"
    ],
    [
        "Compute the median along the specified axis, while ignoring NaNs.",
        "Compute the median along the specified axis,"
    ],
    [
        "Returns the median of the array elements.",
        "Returns the median of the array"
    ],
    [
        "Input array or object that can be converted to an array.",
        "Input array or object that can be converted"
    ],
    [
        "axis : {int, sequence of int, None}, optional",
        "axis : {int, sequence of"
    ],
    [
        "Axis or axes along which the medians are computed. The default",
        "Axis or axes along which the medians are computed. The"
    ],
    [
        "is to compute the median along a flattened version of the array.",
        "is to compute the median along a"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place"
    ],
    [
        "have the same shape and buffer length as the expected output,",
        "have the same shape and buffer"
    ],
    [
        "but the type (of the output) will be cast if necessary.",
        "but the type (of the output)"
    ],
    [
        "If True, then allow use of memory of input array `a` for",
        "If True, then allow use of memory of input"
    ],
    [
        "calculations. The input array will be modified by the call to",
        "calculations. The input array will be modified by the"
    ],
    [
        "`median`. This will save memory when you do not need to preserve",
        "`median`. This will save memory when you"
    ],
    [
        "the contents of the input array. Treat the input as undefined,",
        "the contents of the input array. Treat the input"
    ],
    [
        "but it will probably be fully or partially sorted. Default is",
        "but it will probably be fully or partially sorted. Default"
    ],
    [
        "False. If `overwrite_input` is ``True`` and `a` is not already an",
        "False. If `overwrite_input` is ``True`` and `a`"
    ],
    [
        "`ndarray`, an error will be raised.",
        "`ndarray`, an error"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With this"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly against the"
    ],
    [
        "If this is anything but the default value it will be passed",
        "If this is anything but the default value it will be"
    ],
    [
        "through (in the special case of an empty array) to the",
        "through (in the special case of an empty array)"
    ],
    [
        "`mean` function of the underlying array.  If the array is",
        "`mean` function of the underlying array. If the array"
    ],
    [
        "a sub-class and `mean` does not have the kwarg `keepdims` this",
        "a sub-class and `mean` does not have the kwarg"
    ],
    [
        "A new array holding the result. If the input contains integers",
        "A new array holding the result. If the"
    ],
    [
        "same as that of the input. If `out` is specified, that array is",
        "same as that of the input. If"
    ],
    [
        "Given a vector ``V`` of length ``N``, the median of ``V`` is the",
        "Given a vector ``V`` of length ``N``,"
    ],
    [
        "middle value of a sorted copy of ``V``, ``V_sorted`` - i.e.,",
        "middle value of a sorted copy of"
    ],
    [
        "middle values of ``V_sorted`` when ``N`` is even.",
        "middle values of ``V_sorted`` when"
    ],
    [
        "Compute the qth percentile of the data along the specified axis,",
        "Compute the qth percentile of the"
    ],
    [
        "Returns the qth percentile(s) of the array elements.",
        "Returns the qth percentile(s) of the array"
    ],
    [
        "Input array or object that can be converted to an array, containing",
        "Input array or object that can be"
    ],
    [
        "Percentile or sequence of percentiles to compute, which must be",
        "Percentile or sequence of percentiles to compute,"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple"
    ],
    [
        "Axis or axes along which the percentiles are computed. The default",
        "Axis or axes along which the percentiles are"
    ],
    [
        "is to compute the percentile(s) along a flattened version of the",
        "is to compute the percentile(s) along a flattened version"
    ],
    [
        "Alternative output array in which to place the result. It must have",
        "Alternative output array in which to"
    ],
    [
        "the same shape and buffer length as the expected output, but the",
        "the same shape and buffer length as"
    ],
    [
        "type (of the output) will be cast if necessary.",
        "type (of the output) will"
    ],
    [
        "If True, then allow the input array `a` to be modified by",
        "If True, then allow the input array `a`"
    ],
    [
        "intermediate calculations, to save memory. In this case, the",
        "intermediate calculations, to save memory. In this case,"
    ],
    [
        "contents of the input `a` after this function completes is",
        "contents of the input `a` after this function"
    ],
    [
        "This parameter specifies the method to use for estimating the",
        "This parameter specifies the method"
    ],
    [
        "percentile.  There are many different methods, some unique to NumPy.",
        "percentile. There are many different methods, some unique to"
    ],
    [
        "See the notes for explanation.  The options sorted by their R type",
        "See the notes for explanation. The options sorted by their R"
    ],
    [
        "The first three methods are discontinuous.  NumPy further defines the",
        "The first three methods are discontinuous. NumPy further"
    ],
    [
        "This argument was previously called \"interpolation\" and only",
        "This argument was previously"
    ],
    [
        "offered the \"linear\" default and last four options.",
        "offered the \"linear\" default and last four"
    ],
    [
        "If this is set to True, the axes which are reduced are left in",
        "If this is set to True, the axes which are"
    ],
    [
        "the result as dimensions with size one. With this option, the",
        "the result as dimensions with size one."
    ],
    [
        "result will broadcast correctly against the original array `a`.",
        "result will broadcast correctly against the original"
    ],
    [
        "If this is anything but the default value it will be passed",
        "If this is anything but the default value"
    ],
    [
        "through (in the special case of an empty array) to the",
        "through (in the special case of an"
    ],
    [
        "`mean` function of the underlying array.  If the array is",
        "`mean` function of the underlying array."
    ],
    [
        "a sub-class and `mean` does not have the kwarg `keepdims` this",
        "a sub-class and `mean` does not"
    ],
    [
        "An array of weights associated with the values in `a`. Each value in",
        "An array of weights associated with the values in `a`."
    ],
    [
        "`a` contributes to the percentile according to its associated weight.",
        "`a` contributes to the percentile according to its associated"
    ],
    [
        "the size of `a` along the given axis) or of the same shape as `a`.",
        "the size of `a` along the given axis) or of the"
    ],
    [
        "If `weights=None`, then all data in `a` are assumed to have a",
        "If `weights=None`, then all data in"
    ],
    [
        "Deprecated name for the method keyword argument.",
        "Deprecated name for the method"
    ],
    [
        "If `q` is a single percentile and `axis=None`, then the result",
        "If `q` is a single percentile and `axis=None`, then the"
    ],
    [
        "is a scalar. If multiple percentiles are given, first axis of",
        "is a scalar. If multiple percentiles are given,"
    ],
    [
        "the result corresponds to the percentiles. The other axes are",
        "the result corresponds to the percentiles."
    ],
    [
        "the axes that remain after the reduction of `a`. If the input",
        "the axes that remain after the reduction"
    ],
    [
        "same as that of the input. If `out` is specified, that array is",
        "same as that of the input. If `out`"
    ],
    [
        "The behavior of `numpy.nanpercentile` with percentage `q` is that of",
        "The behavior of `numpy.nanpercentile` with percentage `q` is that"
    ],
    [
        "For more information, please see `numpy.quantile`.",
        "For more information,"
    ],
    [
        "raise TypeError(\"a must be an array of real numbers\")",
        "raise TypeError(\"a must be an array of"
    ],
    [
        "msg = (\"Only method 'inverted_cdf' supports weights. \"",
        "msg = (\"Only method 'inverted_cdf'"
    ],
    [
        "a, q, axis, out, overwrite_input, method, keepdims, weights)",
        "a, q, axis, out, overwrite_input, method, keepdims,"
    ],
    [
        "def _nanquantile_dispatcher(a, q, axis=None, out=None, overwrite_input=None,",
        "def _nanquantile_dispatcher(a, q, axis=None,"
    ],
    [
        "Compute the qth quantile of the data along the specified axis,",
        "Compute the qth quantile of the data along the"
    ],
    [
        "Returns the qth quantile(s) of the array elements.",
        "Returns the qth quantile(s) of the"
    ],
    [
        "Input array or object that can be converted to an array, containing",
        "Input array or object that can"
    ],
    [
        "Probability or sequence of probabilities for the quantiles to compute.",
        "Probability or sequence of probabilities for the quantiles"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple of"
    ],
    [
        "Axis or axes along which the quantiles are computed. The",
        "Axis or axes along which the quantiles are computed."
    ],
    [
        "default is to compute the quantile(s) along a flattened",
        "default is to compute the quantile(s) along a"
    ],
    [
        "Alternative output array in which to place the result. It must",
        "Alternative output array in which to place the result."
    ],
    [
        "have the same shape and buffer length as the expected output,",
        "have the same shape and buffer length as"
    ],
    [
        "but the type (of the output) will be cast if necessary.",
        "but the type (of the output) will be cast"
    ],
    [
        "If True, then allow the input array `a` to be modified by intermediate",
        "If True, then allow the input array `a` to"
    ],
    [
        "calculations, to save memory. In this case, the contents of the input",
        "calculations, to save memory. In this case, the contents of the"
    ],
    [
        "`a` after this function completes is undefined.",
        "`a` after this function completes is"
    ],
    [
        "This parameter specifies the method to use for estimating the",
        "This parameter specifies the method to use"
    ],
    [
        "quantile.  There are many different methods, some unique to NumPy.",
        "quantile. There are many different methods, some unique"
    ],
    [
        "See the notes for explanation.  The options sorted by their R type",
        "See the notes for explanation. The options"
    ],
    [
        "The first three methods are discontinuous.  NumPy further defines the",
        "The first three methods are discontinuous. NumPy"
    ],
    [
        "This argument was previously called \"interpolation\" and only",
        "This argument was previously called \"interpolation\" and"
    ],
    [
        "offered the \"linear\" default and last four options.",
        "offered the \"linear\" default"
    ],
    [
        "If this is set to True, the axes which are reduced are left in",
        "If this is set to True, the axes which"
    ],
    [
        "the result as dimensions with size one. With this option, the",
        "the result as dimensions with size"
    ],
    [
        "result will broadcast correctly against the original array `a`.",
        "result will broadcast correctly against the original array"
    ],
    [
        "If this is anything but the default value it will be passed",
        "If this is anything but the default value"
    ],
    [
        "through (in the special case of an empty array) to the",
        "through (in the special case of"
    ],
    [
        "`mean` function of the underlying array.  If the array is",
        "`mean` function of the underlying"
    ],
    [
        "a sub-class and `mean` does not have the kwarg `keepdims` this",
        "a sub-class and `mean` does not"
    ],
    [
        "An array of weights associated with the values in `a`. Each value in",
        "An array of weights associated with the values in `a`. Each value"
    ],
    [
        "`a` contributes to the quantile according to its associated weight.",
        "`a` contributes to the quantile according to"
    ],
    [
        "the size of `a` along the given axis) or of the same shape as `a`.",
        "the size of `a` along the given axis) or of"
    ],
    [
        "If `weights=None`, then all data in `a` are assumed to have a",
        "If `weights=None`, then all data in"
    ],
    [
        "Deprecated name for the method keyword argument.",
        "Deprecated name for the method keyword"
    ],
    [
        "If `q` is a single probability and `axis=None`, then the result",
        "If `q` is a single probability and `axis=None`, then the"
    ],
    [
        "is a scalar. If multiple probability levels are given, first axis of",
        "is a scalar. If multiple probability levels are"
    ],
    [
        "the result corresponds to the quantiles. The other axes are",
        "the result corresponds to the quantiles. The other"
    ],
    [
        "the axes that remain after the reduction of `a`. If the input",
        "the axes that remain after the reduction"
    ],
    [
        "same as that of the input. If `out` is specified, that array is",
        "same as that of the input. If"
    ],
    [
        "The behavior of `numpy.nanquantile` is the same as that of",
        "The behavior of `numpy.nanquantile` is the same as that"
    ],
    [
        "For more information, please see `numpy.quantile`.",
        "For more information, please see"
    ],
    [
        "raise TypeError(\"a must be an array of real numbers\")",
        "raise TypeError(\"a must be an array"
    ],
    [
        "if isinstance(q, (int, float)) and a.dtype.kind == \"f\":",
        "if isinstance(q, (int, float)) and a.dtype.kind =="
    ],
    [
        "msg = (\"Only method 'inverted_cdf' supports weights. \"",
        "msg = (\"Only method 'inverted_cdf' supports weights."
    ],
    [
        "a, q, axis, out, overwrite_input, method, keepdims, weights)",
        "a, q, axis, out, overwrite_input, method,"
    ],
    [
        "axis: int | None = None,",
        "axis: int | None"
    ],
    [
        "Private function that doesn't support extended axis or keepdims.",
        "Private function that doesn't support extended axis"
    ],
    [
        "These methods are extended to this function using _ureduce",
        "These methods are extended to this"
    ],
    [
        "wgt = None if weights is None else weights.ravel()",
        "wgt = None if weights is None"
    ],
    [
        "from_ax = [axis + i for i in range(q.ndim)]",
        "from_ax = [axis + i"
    ],
    [
        "def _nanvar_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,",
        "def _nanvar_dispatcher(a, axis=None, dtype=None,"
    ],
    [
        "Compute the variance along the specified axis, while ignoring NaNs.",
        "Compute the variance along the"
    ],
    [
        "Returns the variance of the array elements, a measure of the spread of",
        "Returns the variance of the array elements, a measure of"
    ],
    [
        "a distribution.  The variance is computed for the flattened array by",
        "a distribution. The variance is computed for the flattened array"
    ],
    [
        "default, otherwise over the specified axis.",
        "default, otherwise over"
    ],
    [
        "For all-NaN slices or slices with zero degrees of freedom, NaN is",
        "For all-NaN slices or slices with zero degrees of"
    ],
    [
        "returned and a `RuntimeWarning` is raised.",
        "returned and a `RuntimeWarning`"
    ],
    [
        "Array containing numbers whose variance is desired.  If `a` is not an",
        "Array containing numbers whose variance is desired. If `a`"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple"
    ],
    [
        "Axis or axes along which the variance is computed.  The default is to compute",
        "Axis or axes along which the variance is computed."
    ],
    [
        "the variance of the flattened array.",
        "the variance of"
    ],
    [
        "Type to use in computing the variance.  For arrays of integer type",
        "Type to use in computing the variance. For arrays"
    ],
    [
        "Alternate output array in which to place the result.  It must have",
        "Alternate output array in which to place the result."
    ],
    [
        "the same shape as the expected output, but the type is cast if",
        "the same shape as the expected output, but the"
    ],
    [
        "\"Delta Degrees of Freedom\": the divisor used in the calculation is",
        "\"Delta Degrees of Freedom\": the divisor used in"
    ],
    [
        "``N - ddof``, where ``N`` represents the number of non-NaN",
        "``N - ddof``, where ``N`` represents the number of"
    ],
    [
        "elements. By default `ddof` is zero.",
        "elements. By default `ddof` is"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the axes"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly against"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like"
    ],
    [
        "Elements to include in the variance. See `~numpy.ufunc.reduce` for",
        "Elements to include in the variance."
    ],
    [
        "Provide the mean to prevent its recalculation. The mean should have",
        "Provide the mean to prevent its recalculation."
    ],
    [
        "a shape as if it was calculated with ``keepdims=True``.",
        "a shape as if it was"
    ],
    [
        "The axis for the calculation of the mean should be the same as used in",
        "The axis for the calculation of the mean should"
    ],
    [
        "the call to this var function.",
        "the call to"
    ],
    [
        "Array API compatible name for the ``ddof`` parameter. Only one of them",
        "Array API compatible name for the ``ddof`` parameter. Only one of"
    ],
    [
        "can be provided at the same time.",
        "can be provided at the"
    ],
    [
        "variance : ndarray, see dtype parameter above",
        "variance : ndarray, see"
    ],
    [
        "If `out` is None, return a new array containing the variance,",
        "If `out` is None, return a"
    ],
    [
        "otherwise return a reference to the output array. If ddof is >= the",
        "otherwise return a reference to the output array."
    ],
    [
        "number of non-NaN elements in a slice or the slice contains only",
        "number of non-NaN elements in a slice or the slice contains"
    ],
    [
        "NaNs, then the result for that slice is NaN.",
        "NaNs, then the result for that"
    ],
    [
        "var : Variance while not ignoring NaNs",
        "var : Variance while not"
    ],
    [
        "The variance is the average of the squared deviations from the mean,",
        "The variance is the average of the squared deviations from the"
    ],
    [
        "The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.",
        "The mean is normally calculated as ``x.sum() / N``,"
    ],
    [
        "If, however, `ddof` is specified, the divisor ``N - ddof`` is used",
        "If, however, `ddof` is specified, the divisor ``N - ddof``"
    ],
    [
        "unbiased estimator of the variance of a hypothetical infinite",
        "unbiased estimator of the variance of a"
    ],
    [
        "Note that for complex numbers, the absolute value is taken before",
        "Note that for complex numbers, the absolute value"
    ],
    [
        "squaring, so that the result is always real and nonnegative.",
        "squaring, so that the result is"
    ],
    [
        "For floating-point input, the variance is computed using the same",
        "For floating-point input, the variance is"
    ],
    [
        "precision the input has.  Depending on the input data, this can cause",
        "precision the input has. Depending on the"
    ],
    [
        "below).  Specifying a higher-accuracy accumulator using the ``dtype``",
        "below). Specifying a higher-accuracy"
    ],
    [
        "For this function to work on sub-classes of ndarray, they must define",
        "For this function to work on sub-classes of ndarray,"
    ],
    [
        "return np.var(arr, axis=axis, dtype=dtype, out=out, ddof=ddof,",
        "return np.var(arr, axis=axis, dtype=dtype, out=out,"
    ],
    [
        "if dtype is not None and not issubclass(dtype.type, np.inexact):",
        "if dtype is not None and"
    ],
    [
        "raise TypeError(\"If a is inexact, then dtype must be inexact\")",
        "raise TypeError(\"If a is inexact,"
    ],
    [
        "if out is not None and not issubclass(out.dtype.type, np.inexact):",
        "if out is not None and not"
    ],
    [
        "raise TypeError(\"If a is inexact, then out must be inexact\")",
        "raise TypeError(\"If a is inexact, then"
    ],
    [
        "\"ddof and correction can't be provided simultaneously.\"",
        "\"ddof and correction can't be provided"
    ],
    [
        "cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=_keepdims,",
        "cnt = np.sum(~mask, axis=axis,"
    ],
    [
        "sqr = np.multiply(arr, arr.conj(), out=arr, where=where).real",
        "sqr = np.multiply(arr,"
    ],
    [
        "sqr = np.multiply(arr, arr, out=arr, where=where)",
        "sqr = np.multiply(arr, arr,"
    ],
    [
        "var = np.sum(sqr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,",
        "var = np.sum(sqr, axis=axis,"
    ],
    [
        "def _nanstd_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,",
        "def _nanstd_dispatcher(a, axis=None,"
    ],
    [
        "Compute the standard deviation along the specified axis, while",
        "Compute the standard deviation along the specified axis,"
    ],
    [
        "Returns the standard deviation, a measure of the spread of a",
        "Returns the standard deviation, a measure of the spread of"
    ],
    [
        "distribution, of the non-NaN array elements. The standard deviation is",
        "distribution, of the non-NaN array elements."
    ],
    [
        "computed for the flattened array by default, otherwise over the",
        "computed for the flattened array by"
    ],
    [
        "For all-NaN slices or slices with zero degrees of freedom, NaN is",
        "For all-NaN slices or slices with zero degrees of freedom,"
    ],
    [
        "returned and a `RuntimeWarning` is raised.",
        "returned and a `RuntimeWarning`"
    ],
    [
        "Calculate the standard deviation of the non-NaN values.",
        "Calculate the standard deviation of"
    ],
    [
        "axis : {int, tuple of int, None}, optional",
        "axis : {int, tuple of int,"
    ],
    [
        "Axis or axes along which the standard deviation is computed. The default is",
        "Axis or axes along which the standard deviation is"
    ],
    [
        "to compute the standard deviation of the flattened array.",
        "to compute the standard deviation of the flattened"
    ],
    [
        "Type to use in computing the standard deviation. For arrays of",
        "Type to use in computing the standard deviation. For"
    ],
    [
        "is the same as the array type.",
        "is the same as the"
    ],
    [
        "Alternative output array in which to place the result. It must have",
        "Alternative output array in which to place the result. It"
    ],
    [
        "the same shape as the expected output but the type (of the",
        "the same shape as the expected output but"
    ],
    [
        "calculated values) will be cast if necessary.",
        "calculated values) will be cast"
    ],
    [
        "Means Delta Degrees of Freedom.  The divisor used in calculations",
        "Means Delta Degrees of Freedom."
    ],
    [
        "is ``N - ddof``, where ``N`` represents the number of non-NaN",
        "is ``N - ddof``, where ``N`` represents the number of"
    ],
    [
        "elements.  By default `ddof` is zero.",
        "elements. By default"
    ],
    [
        "If this is set to True, the axes which are reduced are left",
        "If this is set to True, the"
    ],
    [
        "in the result as dimensions with size one. With this option,",
        "in the result as dimensions with size one. With"
    ],
    [
        "the result will broadcast correctly against the original `a`.",
        "the result will broadcast correctly against the"
    ],
    [
        "If this value is anything but the default it is passed through",
        "If this value is anything but the default it is"
    ],
    [
        "as-is to the relevant functions of the sub-classes.  If these",
        "as-is to the relevant functions of the"
    ],
    [
        "functions do not have a `keepdims` kwarg, a RuntimeError will",
        "functions do not have a"
    ],
    [
        "where : array_like of bool, optional",
        "where : array_like of"
    ],
    [
        "Elements to include in the standard deviation.",
        "Elements to include in"
    ],
    [
        "Provide the mean to prevent its recalculation. The mean should have",
        "Provide the mean to prevent its recalculation. The mean"
    ],
    [
        "a shape as if it was calculated with ``keepdims=True``.",
        "a shape as if it was"
    ],
    [
        "The axis for the calculation of the mean should be the same as used in",
        "The axis for the calculation of the mean"
    ],
    [
        "the call to this std function.",
        "the call to this"
    ],
    [
        "Array API compatible name for the ``ddof`` parameter. Only one of them",
        "Array API compatible name for the ``ddof`` parameter. Only one"
    ],
    [
        "can be provided at the same time.",
        "can be provided at the same"
    ],
    [
        "standard_deviation : ndarray, see dtype parameter above.",
        "standard_deviation : ndarray, see"
    ],
    [
        "If `out` is None, return a new array containing the standard",
        "If `out` is None, return a new"
    ],
    [
        "deviation, otherwise return a reference to the output array. If",
        "deviation, otherwise return a reference to the"
    ],
    [
        "ddof is >= the number of non-NaN elements in a slice or the slice",
        "ddof is >= the number of non-NaN elements"
    ],
    [
        "contains only NaNs, then the result for that slice is NaN.",
        "contains only NaNs, then the result for that slice"
    ],
    [
        "The standard deviation is the square root of the average of the squared",
        "The standard deviation is the square root of"
    ],
    [
        "The average squared deviation is normally calculated as",
        "The average squared deviation is normally calculated"
    ],
    [
        "``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is",
        "``x.sum() / N``, where ``N = len(x)``."
    ],
    [
        "specified, the divisor ``N - ddof`` is used instead. In standard",
        "specified, the divisor ``N - ddof`` is used instead. In"
    ],
    [
        "likelihood estimate of the variance for normally distributed variables.",
        "likelihood estimate of the variance"
    ],
    [
        "The standard deviation computed in this function is the square root of",
        "The standard deviation computed in this function"
    ],
    [
        "unbiased estimate of the standard deviation per se.",
        "unbiased estimate of the standard"
    ],
    [
        "Note that, for complex numbers, `std` takes the absolute value before",
        "Note that, for complex numbers, `std` takes the absolute"
    ],
    [
        "squaring, so that the result is always real and nonnegative.",
        "squaring, so that the result is always real"
    ],
    [
        "For floating-point input, the *std* is computed using the same",
        "For floating-point input, the *std*"
    ],
    [
        "precision the input has. Depending on the input data, this can cause",
        "precision the input has. Depending on the input data, this can"
    ],
    [
        "below).  Specifying a higher-accuracy accumulator using the `dtype`",
        "below). Specifying a higher-accuracy accumulator using"
    ],
    [
        "var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,",
        "var = nanvar(a, axis=axis, dtype=dtype,"
    ],
    [
        "\"\"\"A file interface for handling local and remote data files.",
        "\"\"\"A file interface for handling local and remote data"
    ],
    [
        "The goal of datasource is to abstract some of the file system operations",
        "The goal of datasource is to abstract some"
    ],
    [
        "when dealing with data files so the researcher doesn't have to know all the",
        "when dealing with data files so the researcher doesn't have to"
    ],
    [
        "low-level details.  Through datasource, a researcher can obtain and use a",
        "low-level details. Through datasource, a researcher can obtain"
    ],
    [
        "file with one function call, regardless of location of the file.",
        "file with one function call, regardless of"
    ],
    [
        "DataSource is meant to augment standard python libraries, not replace them.",
        "DataSource is meant to augment standard python libraries,"
    ],
    [
        "It should work seamlessly with standard file IO operations and the os",
        "It should work seamlessly with standard file IO"
    ],
    [
        "DataSource files can originate locally or remotely:",
        "DataSource files can originate locally or"
    ],
    [
        "- URLs (http, ftp, ...) : 'http://www.scipy.org/not/real/data.txt'",
        "- URLs (http, ftp, ...)"
    ],
    [
        "DataSource files can also be compressed or uncompressed.  Currently only",
        "DataSource files can also be compressed or uncompressed."
    ],
    [
        "\"\"\"Check mode and that encoding and newline are compatible.",
        "\"\"\"Check mode and that encoding and newline"
    ],
    [
        "raise ValueError(\"Invalid mode: %r\" % (mode,))",
        "raise ValueError(\"Invalid mode:"
    ],
    [
        "raise ValueError(\"Argument 'encoding' not supported in binary mode\")",
        "raise ValueError(\"Argument 'encoding' not supported"
    ],
    [
        "raise ValueError(\"Argument 'newline' not supported in binary mode\")",
        "raise ValueError(\"Argument 'newline' not"
    ],
    [
        "Container for different methods to open (un-)compressed files.",
        "Container for different methods to open (un-)compressed"
    ],
    [
        "`_FileOpeners` contains a dictionary that holds one method for each",
        "`_FileOpeners` contains a dictionary that holds"
    ],
    [
        "supported file format. Attribute lookup is implemented in such a way",
        "supported file format. Attribute lookup is"
    ],
    [
        "that an instance of `_FileOpeners` itself can be indexed with the keys",
        "that an instance of `_FileOpeners` itself can be indexed"
    ],
    [
        "of that dictionary. Currently uncompressed files as well as files",
        "of that dictionary. Currently uncompressed files"
    ],
    [
        "`_file_openers`, an instance of `_FileOpeners`, is made available for",
        "`_file_openers`, an instance of `_FileOpeners`,"
    ],
    [
        "Return the keys of currently supported file openers.",
        "Return the keys of currently supported"
    ],
    [
        "The keys are None for uncompressed files and the file extension",
        "The keys are None for uncompressed files"
    ],
    [
        "strings (i.e. ``'.gz'``, ``'.xz'``) for supported compression",
        "strings (i.e. ``'.gz'``, ``'.xz'``) for supported"
    ],
    [
        "def open(path, mode='r', destpath=os.curdir, encoding=None, newline=None):",
        "def open(path, mode='r', destpath=os.curdir, encoding=None,"
    ],
    [
        "Open `path` with `mode` and return the file object.",
        "Open `path` with `mode` and return the file"
    ],
    [
        "If ``path`` is an URL, it will be downloaded, stored in the",
        "If ``path`` is an URL, it will be downloaded,"
    ],
    [
        "`DataSource` `destpath` directory and opened from there.",
        "`DataSource` `destpath` directory and opened"
    ],
    [
        "Local file path or URL to open.",
        "Local file path or URL to"
    ],
    [
        "Mode to open `path`. Mode 'r' for reading, 'w' for writing, 'a' to",
        "Mode to open `path`. Mode 'r' for"
    ],
    [
        "append. Available modes depend on the type of object specified by",
        "append. Available modes depend on the"
    ],
    [
        "Path to the directory where the source file gets downloaded to for",
        "Path to the directory where the source file gets"
    ],
    [
        "use.  If `destpath` is None, a temporary directory will be created.",
        "use. If `destpath` is None, a temporary directory will"
    ],
    [
        "The default path is the current directory.",
        "The default path is the current"
    ],
    [
        "Open text file with given encoding. The default encoding will be",
        "Open text file with given encoding. The default"
    ],
    [
        "Newline to use when reading text file.",
        "Newline to use when reading"
    ],
    [
        "This is a convenience function that instantiates a `DataSource` and",
        "This is a convenience function"
    ],
    [
        "returns the file object from ``DataSource.open(path)``.",
        "returns the file object"
    ],
    [
        "A generic data source file (file, http, ftp, ...).",
        "A generic data source file (file, http, ftp,"
    ],
    [
        "DataSources can be local files or remote files/URLs.  The files may",
        "DataSources can be local files or remote files/URLs. The"
    ],
    [
        "also be compressed or uncompressed. DataSource hides some of the",
        "also be compressed or uncompressed. DataSource hides"
    ],
    [
        "low-level details of downloading the file, allowing you to simply pass",
        "low-level details of downloading the file, allowing you to"
    ],
    [
        "in a valid file path (or URL) and obtain a file object.",
        "in a valid file path (or URL) and obtain"
    ],
    [
        "destpath : str or None, optional",
        "destpath : str"
    ],
    [
        "Path to the directory where the source file gets downloaded to for",
        "Path to the directory where the source file gets downloaded"
    ],
    [
        "use.  If `destpath` is None, a temporary directory will be created.",
        "use. If `destpath` is None, a temporary"
    ],
    [
        "The default path is the current directory.",
        "The default path is"
    ],
    [
        "URLs require a scheme string (``http://``) to be used, without it they",
        "URLs require a scheme string (``http://``) to be used,"
    ],
    [
        "Temporary directories are deleted when the DataSource is deleted.",
        "Temporary directories are deleted when the DataSource is"
    ],
    [
        "\"\"\"Create a DataSource with a local path at destpath.\"\"\"",
        "\"\"\"Create a DataSource with a local"
    ],
    [
        "\"\"\"Test if the filename is a zip file by looking at the file extension.",
        "\"\"\"Test if the filename is a zip file by looking at the"
    ],
    [
        "\"\"\"Test if the given mode will open a file for writing.\"\"\"",
        "\"\"\"Test if the given mode will open a file for"
    ],
    [
        "return any(c in _writemodes for c in mode)",
        "return any(c in _writemodes for c in"
    ],
    [
        "\"\"\"Split zip extension from filename and return filename.",
        "\"\"\"Split zip extension from filename"
    ],
    [
        "\"\"\"Return a tuple containing compressed filename variations.\"\"\"",
        "\"\"\"Return a tuple containing"
    ],
    [
        "\"\"\"Test if path is a net location.  Tests the scheme and netloc.\"\"\"",
        "\"\"\"Test if path is a net location. Tests the"
    ],
    [
        "scheme, netloc, upath, uparams, uquery, ufrag = urlparse(path)",
        "scheme, netloc, upath, uparams, uquery, ufrag ="
    ],
    [
        "\"\"\"Cache the file specified by path.",
        "\"\"\"Cache the file specified"
    ],
    [
        "Creates a copy of the file in the datasource cache.",
        "Creates a copy of the"
    ],
    [
        "\"\"\"Searches for ``path`` and returns full path if found.",
        "\"\"\"Searches for ``path`` and returns full path"
    ],
    [
        "If path is an URL, _findfile will cache a local copy and return the",
        "If path is an URL, _findfile will cache a local copy"
    ],
    [
        "path to the cached file.  If path is a local file, _findfile will",
        "path to the cached file. If path is a"
    ],
    [
        "return a path to that local file.",
        "return a path to that"
    ],
    [
        "The search will include possible compressed versions of the file",
        "The search will include possible compressed versions of"
    ],
    [
        "and return the first occurrence found.",
        "and return the"
    ],
    [
        "Return absolute path of file in the DataSource directory.",
        "Return absolute path of file in the"
    ],
    [
        "If `path` is an URL, then `abspath` will return either the location",
        "If `path` is an URL, then `abspath` will"
    ],
    [
        "the file exists locally or the location it would exist when opened",
        "the file exists locally or the"
    ],
    [
        "Can be a local file or a remote URL.",
        "Can be a local file or a"
    ],
    [
        "Complete path, including the `DataSource` destination directory.",
        "Complete path, including the `DataSource` destination"
    ],
    [
        "The functionality is based on `os.path.abspath`.",
        "The functionality is"
    ],
    [
        "scheme, netloc, upath, uparams, uquery, ufrag = urlparse(path)",
        "scheme, netloc, upath, uparams,"
    ],
    [
        "\"\"\"Return a sanitised relative path for which",
        "\"\"\"Return a sanitised relative path"
    ],
    [
        "Test if `path` exists as (and in this order):",
        "Test if `path` exists as (and in this"
    ],
    [
        "- a remote URL that has been downloaded and stored locally in the",
        "- a remote URL that has been downloaded and stored locally in"
    ],
    [
        "- a remote URL that has not been downloaded, but is valid and",
        "- a remote URL that has not been downloaded, but is"
    ],
    [
        "Can be a local file or a remote URL.",
        "Can be a local file or a"
    ],
    [
        "When `path` is an URL, `exists` will return True if it's either",
        "When `path` is an URL, `exists` will return True if it's"
    ],
    [
        "stored locally in the `DataSource` directory, or is a valid remote",
        "stored locally in the `DataSource` directory, or is a"
    ],
    [
        "URL.  `DataSource` does not discriminate between the two, the file",
        "URL. `DataSource` does not discriminate"
    ],
    [
        "is accessible if it exists in either location.",
        "is accessible if it exists in"
    ],
    [
        "def open(self, path, mode='r', encoding=None, newline=None):",
        "def open(self, path, mode='r',"
    ],
    [
        "If `path` is an URL, it will be downloaded, stored in the",
        "If `path` is an URL, it will be downloaded, stored in"
    ],
    [
        "`DataSource` directory and opened from there.",
        "`DataSource` directory and opened"
    ],
    [
        "Local file path or URL to open.",
        "Local file path or URL to"
    ],
    [
        "mode : {'r', 'w', 'a'}, optional",
        "mode : {'r', 'w', 'a'},"
    ],
    [
        "Mode to open `path`.  Mode 'r' for reading, 'w' for writing,",
        "Mode to open `path`. Mode 'r' for"
    ],
    [
        "'a' to append. Available modes depend on the type of object",
        "'a' to append. Available modes depend on the type of"
    ],
    [
        "specified by `path`. Default is 'r'.",
        "specified by `path`. Default"
    ],
    [
        "Open text file with given encoding. The default encoding will be",
        "Open text file with given encoding. The"
    ],
    [
        "Newline to use when reading text file.",
        "Newline to use when"
    ],
    [
        "A data repository where multiple DataSource's share a base",
        "A data repository where multiple DataSource's share"
    ],
    [
        "`Repository` extends `DataSource` by prepending a base URL (or",
        "`Repository` extends `DataSource` by prepending a"
    ],
    [
        "directory) to all the files it handles. Use `Repository` when you will",
        "directory) to all the files it handles. Use `Repository` when you"
    ],
    [
        "be working with multiple files from one base URL.  Initialize",
        "be working with multiple files from one"
    ],
    [
        "`Repository` with the base URL, then refer to each file by its filename",
        "`Repository` with the base URL, then refer to each file by its"
    ],
    [
        "Path to the local directory or remote location that contains the",
        "Path to the local directory or remote"
    ],
    [
        "destpath : str or None, optional",
        "destpath : str"
    ],
    [
        "Path to the directory where the source file gets downloaded to for",
        "Path to the directory where the source file gets downloaded to"
    ],
    [
        "use.  If `destpath` is None, a temporary directory will be created.",
        "use. If `destpath` is None, a temporary directory"
    ],
    [
        "The default path is the current directory.",
        "The default path is the"
    ],
    [
        "To analyze all files in the repository, do something like this",
        "To analyze all files in the repository, do something"
    ],
    [
        "(note: this is not self-contained code)::",
        "(note: this is not self-contained"
    ],
    [
        "Similarly you could use a URL for a repository::",
        "Similarly you could use a URL for a"
    ],
    [
        "\"\"\"Create a Repository with a shared url or directory of baseurl.\"\"\"",
        "\"\"\"Create a Repository with a shared url or directory of"
    ],
    [
        "\"\"\"Return complete path for path.  Prepends baseurl if necessary.\"\"\"",
        "\"\"\"Return complete path for path."
    ],
    [
        "\"\"\"Extend DataSource method to prepend baseurl to ``path``.\"\"\"",
        "\"\"\"Extend DataSource method to prepend"
    ],
    [
        "Return absolute path of file in the Repository directory.",
        "Return absolute path of file in the"
    ],
    [
        "If `path` is an URL, then `abspath` will return either the location",
        "If `path` is an URL, then `abspath` will return either"
    ],
    [
        "the file exists locally or the location it would exist when opened",
        "the file exists locally or the location it would exist when"
    ],
    [
        "Can be a local file or a remote URL. This may, but does not",
        "Can be a local file or a remote URL. This"
    ],
    [
        "have to, include the `baseurl` with which the `Repository` was",
        "have to, include the `baseurl` with which"
    ],
    [
        "Complete path, including the `DataSource` destination directory.",
        "Complete path, including the `DataSource` destination"
    ],
    [
        "Test if path exists prepending Repository base URL to path.",
        "Test if path exists prepending"
    ],
    [
        "Test if `path` exists as (and in this order):",
        "Test if `path` exists as (and"
    ],
    [
        "- a remote URL that has been downloaded and stored locally in the",
        "- a remote URL that has been downloaded and stored locally in"
    ],
    [
        "- a remote URL that has not been downloaded, but is valid and",
        "- a remote URL that has not"
    ],
    [
        "Can be a local file or a remote URL. This may, but does not",
        "Can be a local file or a remote URL. This may, but does"
    ],
    [
        "have to, include the `baseurl` with which the `Repository` was",
        "have to, include the `baseurl` with which the `Repository`"
    ],
    [
        "When `path` is an URL, `exists` will return True if it's either",
        "When `path` is an URL, `exists` will return True"
    ],
    [
        "stored locally in the `DataSource` directory, or is a valid remote",
        "stored locally in the `DataSource` directory, or"
    ],
    [
        "URL.  `DataSource` does not discriminate between the two, the file",
        "URL. `DataSource` does not discriminate between"
    ],
    [
        "is accessible if it exists in either location.",
        "is accessible if it"
    ],
    [
        "def open(self, path, mode='r', encoding=None, newline=None):",
        "def open(self, path,"
    ],
    [
        "Open and return file-like object prepending Repository base URL.",
        "Open and return file-like object prepending Repository base"
    ],
    [
        "If `path` is an URL, it will be downloaded, stored in the",
        "If `path` is an URL, it will be downloaded, stored in"
    ],
    [
        "DataSource directory and opened from there.",
        "DataSource directory and"
    ],
    [
        "Local file path or URL to open. This may, but does not have to,",
        "Local file path or URL to open. This may,"
    ],
    [
        "include the `baseurl` with which the `Repository` was",
        "include the `baseurl` with"
    ],
    [
        "mode : {'r', 'w', 'a'}, optional",
        "mode : {'r',"
    ],
    [
        "Mode to open `path`.  Mode 'r' for reading, 'w' for writing,",
        "Mode to open `path`. Mode 'r' for reading,"
    ],
    [
        "'a' to append. Available modes depend on the type of object",
        "'a' to append. Available modes depend on"
    ],
    [
        "specified by `path`. Default is 'r'.",
        "specified by `path`. Default"
    ],
    [
        "Open text file with given encoding. The default encoding will be",
        "Open text file with given encoding."
    ],
    [
        "Newline to use when reading text file.",
        "Newline to use when reading text"
    ],
    [
        "List files in the source Repository.",
        "List files in the source"
    ],
    [
        "files : list of str or pathlib.Path",
        "files : list of"
    ],
    [
        "List of file names (not containing a directory part).",
        "List of file names (not containing a directory"
    ],
    [
        "Does not currently work for remote repositories.",
        "Does not currently work"
    ],
    [
        "\"Directory listing of URLs, not supported yet.\")",
        "\"Directory listing of URLs, not supported"
    ],
    [
        "Print information about various resources in the system",
        "Print information about various resources in the"
    ],
    [
        "including available intrinsic support and BLAS/LAPACK library",
        "including available intrinsic support and"
    ],
    [
        "show_config : Show libraries in the system on which NumPy was built.",
        "show_config : Show libraries in the system on which NumPy was"
    ],
    [
        "print(\"WARNING: `threadpoolctl` not found in system!\"",
        "print(\"WARNING: `threadpoolctl` not found in"
    ],
    [
        "\" Install it by `pip install threadpoolctl`.\"",
        "\" Install it by `pip"
    ],
    [
        "\" Once installed, try `np.show_runtime` again\"",
        "\" Once installed, try `np.show_runtime`"
    ],
    [
        "\" for more detailed build information\")",
        "\" for more detailed build"
    ],
    [
        "Return the directory that contains the NumPy \\\\*.h header files.",
        "Return the directory that contains the NumPy \\\\*.h"
    ],
    [
        "Extension modules that need to compile against NumPy may need to use this",
        "Extension modules that need to compile against NumPy may need to use"
    ],
    [
        "function to locate the appropriate include directory.",
        "function to locate the"
    ],
    [
        "When using ``setuptools``, for example in ``setup.py``::",
        "When using ``setuptools``, for"
    ],
    [
        "that is likely preferred for build systems other than ``setuptools``::",
        "that is likely preferred for build systems"
    ],
    [
        "Decorator class to deprecate old functions.",
        "Decorator class to"
    ],
    [
        "depdoc = \"`%s` is deprecated!\" % old_name",
        "depdoc = \"`%s` is deprecated!\""
    ],
    [
        "depdoc = \"`%s` is deprecated, use `%s` instead!\" % \\",
        "depdoc = \"`%s` is deprecated, use `%s`"
    ],
    [
        "doc = indent * ' ' + doc",
        "doc = indent * '"
    ],
    [
        "depdoc = textwrap.indent(depdoc, ' ' * indent)",
        "depdoc = textwrap.indent(depdoc, ' ' *"
    ],
    [
        "Determines the leading whitespace that could be removed from all the lines.",
        "Determines the leading whitespace that could"
    ],
    [
        "indent = min(indent, len(line) - content)",
        "indent = min(indent, len(line) -"
    ],
    [
        "Issues a DeprecationWarning, adds warning to `old_name`'s",
        "Issues a DeprecationWarning, adds"
    ],
    [
        "docstring, rebinds ``old_name.__name__`` and returns the new",
        "docstring, rebinds ``old_name.__name__`` and returns"
    ],
    [
        "This function may also be used as a decorator.",
        "This function may also be"
    ],
    [
        "The name of the function to be deprecated. Default is None, in",
        "The name of the function to be deprecated. Default is"
    ],
    [
        "which case the name of `func` is used.",
        "which case the name of `func` is"
    ],
    [
        "The new name for the function. Default is None, in which case the",
        "The new name for the function. Default is"
    ],
    [
        "deprecation message is that `old_name` is deprecated. If given, the",
        "deprecation message is that `old_name` is deprecated. If"
    ],
    [
        "deprecation message is that `old_name` is deprecated and `new_name`",
        "deprecation message is that `old_name` is deprecated"
    ],
    [
        "Additional explanation of the deprecation.  Displayed in the",
        "Additional explanation of the deprecation."
    ],
    [
        "Note that ``olduint`` returns a value after printing Deprecation",
        "Note that ``olduint`` returns a value after"
    ],
    [
        "\"use `warn` with `DeprecationWarning` instead. \"",
        "\"use `warn` with"
    ],
    [
        "Deprecates a function and includes the deprecation in its docstring.",
        "Deprecates a function and includes the"
    ],
    [
        "This function is used as a decorator. It returns an object that can be",
        "This function is used as a decorator. It returns"
    ],
    [
        "used to issue a DeprecationWarning, by passing the to-be decorated",
        "used to issue a DeprecationWarning, by passing"
    ],
    [
        "function as argument, this adds warning to the to-be decorated function's",
        "function as argument, this adds warning"
    ],
    [
        "docstring and returns the new function object.",
        "docstring and returns the new function"
    ],
    [
        "deprecate : Decorate a function such that it issues a",
        "deprecate : Decorate a function such that it"
    ],
    [
        "Additional explanation of the deprecation. Displayed in the",
        "Additional explanation of the deprecation. Displayed in"
    ],
    [
        "\"use `warn` with `DeprecationWarning` instead. \"",
        "\"use `warn` with `DeprecationWarning`"
    ],
    [
        "k = k + len(argument) + len(addstr)",
        "k = k + len(argument) +"
    ],
    [
        "newstr = newstr + addstr + argument",
        "newstr = newstr + addstr +"
    ],
    [
        "module = __import__(module, globals(), locals(), [])",
        "module = __import__(module, globals(),"
    ],
    [
        "Copied over from the numarray module prior to its removal.",
        "Copied over from the numarray"
    ],
    [
        "Adapted somewhat as only numpy is an option now.",
        "Adapted somewhat as only numpy is"
    ],
    [
        "\"data pointer: %s%s\" % (hex(obj.ctypes._as_parameter_.value), extra),",
        "\"data pointer: %s%s\""
    ],
    [
        "print(\"%s%s%s\" % (tic, sys.byteorder, tic), file=output)",
        "print(\"%s%s%s\" % (tic, sys.byteorder, tic),"
    ],
    [
        "Get help information for an array, function, class, or module.",
        "Get help information for an array, function, class,"
    ],
    [
        "object : object or str, optional",
        "object : object or str,"
    ],
    [
        "Input object or name to get information about. If `object` is",
        "Input object or name to get information"
    ],
    [
        "an `ndarray` instance, information about the array is printed.",
        "an `ndarray` instance, information about"
    ],
    [
        "If `object` is a numpy object, its docstring is given. If it is",
        "If `object` is a numpy object, its"
    ],
    [
        "a string, available modules are searched for matching objects.",
        "a string, available modules are searched for"
    ],
    [
        "If None, information about `info` itself is returned.",
        "If None, information about"
    ],
    [
        "output : file like object, optional",
        "output : file"
    ],
    [
        "File like object that the output is written to, default is",
        "File like object that the output is"
    ],
    [
        "``None``, in which case ``sys.stdout`` will be used.",
        "``None``, in which case ``sys.stdout`` will"
    ],
    [
        "The object has to be opened in 'w' or 'a' mode.",
        "The object has to be opened in"
    ],
    [
        "When used interactively with an object, ``np.info(obj)`` is equivalent",
        "When used interactively with an object, ``np.info(obj)`` is"
    ],
    [
        "to ``help(obj)`` on the Python prompt or ``obj?`` on the IPython",
        "to ``help(obj)`` on the Python prompt or ``obj?``"
    ],
    [
        "Evaluate the polynomial p at x.",
        "Evaluate the polynomial p"
    ],
    [
        "When using a string for `object` it is possible to get multiple results.",
        "When using a string for `object` it is possible to get multiple"
    ],
    [
        "*** Repeat reference found in numpy.fft.fftpack ***",
        "*** Repeat reference found in numpy.fft.fftpack"
    ],
    [
        "When the argument is an array, information about the array is printed.",
        "When the argument is an array, information"
    ],
    [
        "\"*** Repeat reference found in %s *** \" % namestr,",
        "\"*** Repeat reference found in %s *** \" %"
    ],
    [
        "print(\"     *** Found in %s ***\" % namestr, file=output)",
        "print(\" *** Found in %s ***\" % namestr,"
    ],
    [
        "print(\"Help for %s not found.\" % object, file=output)",
        "print(\"Help for %s not found.\" %"
    ],
    [
        "\"*** Total of %d references found. ***\" % numfound,",
        "\"*** Total of %d references found."
    ],
    [
        "if len(name + arguments) > maxwidth:",
        "if len(name + arguments)"
    ],
    [
        "print(\" \" + argstr + \"\\n\", file=output)",
        "print(\" \" + argstr + \"\\n\","
    ],
    [
        "if len(name + arguments) > maxwidth:",
        "if len(name + arguments) >"
    ],
    [
        "print(\" \" + argstr + \"\\n\", file=output)",
        "print(\" \" + argstr +"
    ],
    [
        "print(\"  %s  --  %s\" % (meth, methstr), file=output)",
        "print(\" %s -- %s\""
    ],
    [
        "Evaluate a string containing a Python literal expression without",
        "Evaluate a string containing a Python literal"
    ],
    [
        "allowing the execution of arbitrary non-literal code.",
        "allowing the execution of arbitrary"
    ],
    [
        "This function is identical to :py:meth:`ast.literal_eval` and",
        "This function is identical"
    ],
    [
        "has the same security implications.  It may not always be safe",
        "has the same security implications. It"
    ],
    [
        "If the code has invalid Python syntax, or if it contains",
        "If the code has invalid Python syntax, or"
    ],
    [
        "\"`safe_eval` is deprecated. Use `ast.literal_eval` instead. \"",
        "\"`safe_eval` is deprecated. Use `ast.literal_eval`"
    ],
    [
        "\"Be aware of security implications, such as memory exhaustion \"",
        "\"Be aware of security implications, such as"
    ],
    [
        "Utility function to check median result from data for NaN values at the end",
        "Utility function to check median result from data for NaN values"
    ],
    [
        "and return NaN in that case. Input result can also be a MaskedArray.",
        "and return NaN in that case. Input result can also be"
    ],
    [
        "Sorted input data to median function",
        "Sorted input data to"
    ],
    [
        "Axis along which the median was computed.",
        "Axis along which the median was"
    ],
    [
        "Median or NaN in axes which contained NaN in the input.  If the input",
        "Median or NaN in axes which contained NaN in the input."
    ],
    [
        "was an array, NaN will be inserted in-place.  If a scalar, either the",
        "was an array, NaN will be inserted in-place. If a"
    ],
    [
        "input itself or a scalar NaN.",
        "input itself or a"
    ],
    [
        "Returns a string containing the CPU features supported",
        "Returns a string containing the CPU features"
    ],
    [
        "The format of the string can be explained as follows:",
        "The format of the string can be explained"
    ],
    [
        "- Dispatched features supported by the running machine end with `*`.",
        "- Dispatched features supported by the running machine"
    ],
    [
        "- Dispatched features not supported by the running machine",
        "- Dispatched features not supported by the running"
    ],
    [
        "- Remaining features represent the baseline.",
        "- Remaining features represent the"
    ],
    [
        "str: A formatted string indicating the supported CPU features.",
        "str: A formatted string indicating the"
    ],
    [
        "Returns the dtype unchanged if it contained no metadata or a copy of the",
        "Returns the dtype unchanged if it contained no metadata or a copy"
    ],
    [
        "dtype if it (or any of its structure dtypes) contained metadata.",
        "dtype if it (or any of its"
    ],
    [
        "This utility is used by `np.save` and `np.savez` to drop metadata before",
        "This utility is used by `np.save`"
    ],
    [
        "Due to its limitation this function may move to a more appropriate",
        "Due to its limitation this function"
    ],
    [
        "home or change in the future and is considered semi-public API only.",
        "home or change in the future and is"
    ],
    [
        "This function does not preserve more strange things like record dtypes",
        "This function does not preserve more strange"
    ],
    [
        "and user dtypes may simply return the wrong thing.  If you need to be",
        "and user dtypes may simply return the wrong thing."
    ],
    [
        "sure about the latter, check the result with:",
        "sure about the latter,"
    ],
    [
        "found_metadata = dtype.metadata is not None",
        "found_metadata = dtype.metadata is not"
    ],
    [
        "'names': names, 'formats': formats, 'offsets': offsets, 'titles': titles,",
        "'names': names, 'formats': formats, 'offsets':"
    ],
    [
        "if dtype.metadata is None and new_subdtype is subdtype:",
        "if dtype.metadata is None and new_subdtype is"
    ],
    [
        "common_type, mintypecode, isreal, iscomplex, isposinf, isneginf,",
        "common_type, mintypecode, isreal, iscomplex,"
    ],
    [
        "def __array_function__(self, function, types, args, kwargs):",
        "def __array_function__(self, function, types, args,"
    ],
    [
        "assert_(r == ((ShouldDispatch,), (s_d, xy), {}))",
        "assert_(r == ((ShouldDispatch,),"
    ],
    [
        "assert_(r == ((ShouldDispatch,), (xy, s_d), {}))",
        "assert_(r == ((ShouldDispatch,), (xy,"
    ],
    [
        "assert_(r, ((ShouldDispatch,), (xy, xy), {'bins': s_d}))",
        "assert_(r, ((ShouldDispatch,), (xy, xy), {'bins':"
    ],
    [
        "assert_(r, ((ShouldDispatch,), (xy, xy), {'weights': s_d}))",
        "assert_(r, ((ShouldDispatch,), (xy,"
    ],
    [
        "match='x and y must have the same length.'):",
        "match='x and y must"
    ],
    [
        "for dtype in np.typecodes['AllFloat'] + np.typecodes['AllInteger']:",
        "for dtype in np.typecodes['AllFloat']"
    ],
    [
        "for dtype in np.typecodes['AllFloat'] + np.typecodes['AllInteger']:",
        "for dtype in"
    ],
    [
        "TYPE_CODES = np.typecodes[\"AllInteger\"] + np.typecodes[\"AllFloat\"] + \"O\"",
        "TYPE_CODES = np.typecodes[\"AllInteger\"] + np.typecodes[\"AllFloat\"] +"
    ],
    [
        "assert_equal(q * a + r, b)",
        "assert_equal(q * a +"
    ],
    [
        "\"\"\" Coefficients should be modifiable \"\"\"",
        "\"\"\" Coefficients should be"
    ],
    [
        "names = ['A', 'a', 'b', 'c']",
        "names = ['A', 'a', 'b',"
    ],
    [
        "names = ['dates', 'data', 'Other Data', 'mask']",
        "names = ['dates', 'data', 'Other Data',"
    ],
    [
        "\"Tests the use of missing values.\"",
        "\"Tests the use of"
    ],
    [
        "\"Make sure that string-to-object functions are properly recognized\"",
        "\"Make sure that string-to-object"
    ],
    [
        "\"Make sure we don't lose an explicit default\"",
        "\"Make sure we don't"
    ],
    [
        "\"Check that we're not losing missing values\"",
        "\"Check that we're not losing missing"
    ],
    [
        "ndtype = [('A', int), ('B', float)]",
        "ndtype = [('A', int),"
    ],
    [
        "np.dtype([('a', int), ('b', float), ('c', float)]))",
        "np.dtype([('a', int), ('b', float),"
    ],
    [
        "np.dtype([(_, float) for _ in ('a', 'b', 'c')]))",
        "np.dtype([(_, float) for _ in ('a', 'b',"
    ],
    [
        "apply_along_axis, apply_over_axes, array_split, split, hsplit, dsplit,",
        "apply_along_axis, apply_over_axes, array_split,"
    ],
    [
        "vsplit, dstack, column_stack, kron, tile, expand_dims, take_along_axis,",
        "vsplit, dstack, column_stack, kron, tile, expand_dims,"
    ],
    [
        "\"\"\" hack in keepdims behavior into a function taking an axis \"\"\"",
        "\"\"\" hack in keepdims behavior into a function taking"
    ],
    [
        "\"\"\" Test it translates from arg<func> to <func> \"\"\"",
        "\"\"\" Test it translates from"
    ],
    [
        "for func, argfunc, kwargs in funcs:",
        "for func, argfunc, kwargs in"
    ],
    [
        "for axis in list(range(a.ndim)) + [None]:",
        "for axis in list(range(a.ndim))"
    ],
    [
        "\"\"\" Test it errors when indices has too few dimensions \"\"\"",
        "\"\"\" Test it errors when indices has too"
    ],
    [
        "\"\"\" Test everything is ok with empty results, even with inserted dims \"\"\"",
        "\"\"\" Test everything is ok with empty results,"
    ],
    [
        "\"\"\" Test that non-indexing dimensions are broadcast in both directions \"\"\"",
        "\"\"\" Test that non-indexing dimensions are"
    ],
    [
        "for axis in list(range(a_base.ndim)) + [None]:",
        "for axis in"
    ],
    [
        "\"\"\" Test that non-indexing dimensions are broadcast in both directions \"\"\"",
        "\"\"\" Test that non-indexing dimensions are broadcast"
    ],
    [
        "\"\"\"produces an asymmetric non-square matrix from x\"\"\"",
        "\"\"\"produces an asymmetric non-square"
    ],
    [
        "\"\"\"produces an asymmetric non-square matrix from x\"\"\"",
        "\"\"\"produces an asymmetric non-square matrix"
    ],
    [
        "\"\"\" This will fail if we change default axis",
        "\"\"\" This will fail if we"
    ],
    [
        "with pytest.raises(TypeError, match=\"arrays to stack must be\"):",
        "with pytest.raises(TypeError, match=\"arrays to"
    ],
    [
        "with pytest.raises(TypeError, match=\"arrays to stack must be\"):",
        "with pytest.raises(TypeError, match=\"arrays to stack must"
    ],
    [
        "k.shape, expected_shape), \"Unexpected shape from kron\"",
        "k.shape, expected_shape), \"Unexpected"
    ],
    [
        "for x, y in zip(res, desired):",
        "for x, y"
    ],
    [
        "from numpy import fix, isposinf, isneginf",
        "from numpy import fix,"
    ],
    [
        "tgt = np.array([True, False, False, False, False, False])",
        "tgt = np.array([True, False, False, False,"
    ],
    [
        "tgt = np.array([False, True, False, False, False, False])",
        "tgt = np.array([False, True, False, False, False,"
    ],
    [
        "mgrid, ogrid, ndenumerate, fill_diagonal, diag_indices, diag_indices_from,",
        "mgrid, ogrid, ndenumerate, fill_diagonal, diag_indices,"
    ],
    [
        "index_exp, ndindex, c_, r_, s_, ix_",
        "index_exp, ndindex, c_, r_,"
    ],
    [
        "for f, b in zip(grid_full, grid_broadcast):",
        "for f, b"
    ],
    [
        "def test_mgrid_size_none_handling(self, start, stop, step, expected):",
        "def test_mgrid_size_none_handling(self, start, stop,"
    ],
    [
        "arrays = np.ix_(*[func(sz) for sz in sizes])",
        "arrays = np.ix_(*[func(sz) for"
    ],
    [
        "for k, (a, sz) in enumerate(zip(arrays, sizes)):",
        "for k, (a, sz)"
    ],
    [
        "bool_a = [True, False, True, True]",
        "bool_a = [True, False,"
    ],
    [
        "start = [randint(dim) for dim in shape]",
        "start = [randint(dim) for dim in"
    ],
    [
        "slice_ = tuple(slice(*t) for t in zip(start, stop, step))",
        "slice_ = tuple(slice(*t) for t"
    ],
    [
        "Writes encode strings to bytes if needed, reads return bytes.",
        "Writes encode strings to bytes if needed,"
    ],
    [
        "This makes it easier to emulate files opened in binary mode",
        "This makes it easier to emulate files"
    ],
    [
        "without needing to explicitly convert strings to bytes in",
        "without needing to explicitly convert strings"
    ],
    [
        "BytesIO.writelines(self, [asbytes(s) for s in lines])",
        "BytesIO.writelines(self, [asbytes(s) for"
    ],
    [
        "This function is available in the datetime module only from Python >=",
        "This function is available in the datetime module only from"
    ],
    [
        "Function used to save arrays to file.",
        "Function used to save"
    ],
    [
        "If true, store the file on disk, instead of in a",
        "If true, store the file on"
    ],
    [
        "msg = \"Failed to load data from a file: %s\" % e",
        "msg = \"Failed to load data from"
    ],
    [
        "test_header_footer = 'Test header / footer'",
        "test_header_footer = 'Test"
    ],
    [
        "b = np.loadtxt(os.path.join(tmpdir, 'test.csv' + suffix),",
        "b = np.loadtxt(os.path.join(tmpdir, 'test.csv' +"
    ],
    [
        "raise MemoryError(\"Child process raised a MemoryError exception\")",
        "raise MemoryError(\"Child process raised a"
    ],
    [
        "pytest.xfail(\"subprocess got a SIGKILL, apparently free memory was not sufficient\")",
        "pytest.xfail(\"subprocess got a SIGKILL, apparently free memory was"
    ],
    [
        "mydescriptor = {'names': ('gender', 'age', 'weight'),",
        "mydescriptor = {'names':"
    ],
    [
        "dt = np.dtype([('x', int), ('y', [('t', int), ('s', float)])])",
        "dt = np.dtype([('x', int), ('y', [('t', int), ('s',"
    ],
    [
        "with pytest.warns(UserWarning, match=\"input contained no data\"):",
        "with pytest.warns(UserWarning, match=\"input"
    ],
    [
        "ndtype = [('idx', int), ('code', object)]",
        "ndtype = [('idx', int), ('code',"
    ],
    [
        "func = lambda s: strptime(s.strip(), \"%Y-%m-%d\")",
        "func = lambda"
    ],
    [
        "Ensure that fromhex is only used for values with the correct prefix and",
        "Ensure that fromhex is only used for values with the"
    ],
    [
        "Ensure that the exception message raised during failed floating point",
        "Ensure that the exception message raised"
    ],
    [
        "dt = {'names': ('x', 'y', 'z', 'comment'),",
        "dt = {'names': ('x', 'y', 'z',"
    ],
    [
        "a = np.array([b'start ', b'  ', b''])",
        "a = np.array([b'start ', b' ',"
    ],
    [
        "a, b, c = np.loadtxt(txt, dtype=dt, unpack=True)",
        "a, b, c = np.loadtxt(txt,"
    ],
    [
        "with pytest.warns(UserWarning, match=\"input contained no data\"):",
        "with pytest.warns(UserWarning, match=\"input contained no"
    ],
    [
        "res = np.loadtxt(data, dtype=int, skiprows=skip, delimiter=\",\",",
        "res = np.loadtxt(data, dtype=int,"
    ],
    [
        "descriptor = {'names': ('gender', 'age', 'weight'),",
        "descriptor = {'names': ('gender',"
    ],
    [
        "kwargs = {\"dtype\": int, \"delimiter\": ','}",
        "kwargs = {\"dtype\":"
    ],
    [
        "dtype=[(_, float) for _ in \"ABC\"])",
        "dtype=[(_, float) for _ in"
    ],
    [
        "fancydtype = np.dtype([('x', int), ('y', [('t', int), ('s', float)])])",
        "fancydtype = np.dtype([('x', int), ('y', [('t', int),"
    ],
    [
        "descriptor = {'names': ('g', 'a', 'w'),",
        "descriptor = {'names': ('g',"
    ],
    [
        "with pytest.raises(TypeError, match='fname must be a string,'):",
        "with pytest.raises(TypeError, match='fname must be"
    ],
    [
        "test = np.genfromtxt(data, dtype=(int, int), comments=None, names=True)",
        "test = np.genfromtxt(data, dtype=(int, int), comments=None,"
    ],
    [
        "test = np.genfromtxt(data, usecols=('A', 'C', 'D'),",
        "test = np.genfromtxt(data,"
    ],
    [
        "test = np.genfromtxt(data, usecols=('A', 'C', 'D'), names=True,",
        "test = np.genfromtxt(data, usecols=('A',"
    ],
    [
        "'date': lambda s: strptime(s, '%Y-%m-%d %H:%M:%SZ')}",
        "'date': lambda s: strptime(s,"
    ],
    [
        "ndtype = [('idx', int), ('code', object)]",
        "ndtype = [('idx',"
    ],
    [
        "func = lambda s: strptime(s.strip(), \"%Y-%m-%d\")",
        "func = lambda s:"
    ],
    [
        "ndtype = [('nest', [('idx', int), ('code', object)])]",
        "ndtype = [('nest', [('idx',"
    ],
    [
        "ndtype = [('idx', int), ('code', object), ('nest', [])]",
        "ndtype = [('idx', int), ('code', object), ('nest',"
    ],
    [
        "test = np.genfromtxt(data, delimiter=\",\", names=None, dtype=float,",
        "test = np.genfromtxt(data, delimiter=\",\", names=None,"
    ],
    [
        "test = np.genfromtxt(path, delimiter=\",\", names=None, dtype=float,",
        "test = np.genfromtxt(path, delimiter=\",\", names=None,"
    ],
    [
        "kwargs = {\"names\": \"a, b, c\"}",
        "kwargs = {\"names\":"
    ],
    [
        "fancydtype = np.dtype([('x', int), ('y', [('t', int), ('s', float)])])",
        "fancydtype = np.dtype([('x', int), ('y', [('t', int), ('s',"
    ],
    [
        "test = np.genfromtxt(data, dtype=fancydtype, delimiter=',', usemask=True)",
        "test = np.genfromtxt(data, dtype=fancydtype, delimiter=',',"
    ],
    [
        "kwargs = {\"delimiter\": \",\", \"missing_values\": \"N/A\", \"names\": True}",
        "kwargs = {\"delimiter\": \",\", \"missing_values\": \"N/A\","
    ],
    [
        "test = np.genfromtxt(data, dtype=None, usemask=True, **kwargs)",
        "test = np.genfromtxt(data, dtype=None,"
    ],
    [
        "basekwargs = {\"dtype\": None, \"delimiter\": \",\", \"names\": True}",
        "basekwargs = {\"dtype\": None, \"delimiter\": \",\","
    ],
    [
        "mdtype = [('A', int), ('B', float), ('C', complex)]",
        "mdtype = [('A', int),"
    ],
    [
        "dtype=[(_, int) for _ in \"abc\"])",
        "dtype=[(_, int) for _"
    ],
    [
        "kwargs = {\"delimiter\": \",\", \"dtype\": None, \"names\": True}",
        "kwargs = {\"delimiter\": \",\", \"dtype\":"
    ],
    [
        "kwargs = {\"delimiter\": \",\", \"dtype\": None, \"names\": True,",
        "kwargs = {\"delimiter\": \",\", \"dtype\": None,"
    ],
    [
        "kwargs = {\"delimiter\": \",\", \"converters\": converters,",
        "kwargs = {\"delimiter\": \",\", \"converters\":"
    ],
    [
        "\"dtype\": [(_, int) for _ in 'abcde'], \"encoding\": \"bytes\"}",
        "\"dtype\": [(_, int) for _ in 'abcde'],"
    ],
    [
        "dtype=[(_, float) for _ in \"abc\"])",
        "dtype=[(_, float) for _ in"
    ],
    [
        "dtype=[(_, float) for _ in \"abc\"])",
        "dtype=[(_, float) for _ in"
    ],
    [
        "kwargs = {\"delimiter\": \",\", \"dtype\": None, \"encoding\": \"bytes\"}",
        "kwargs = {\"delimiter\": \",\", \"dtype\":"
    ],
    [
        "ctrl_dtype = [(\"AA\", int), (\"B_B\", int), (\"CC\", float)]",
        "ctrl_dtype = [(\"AA\", int), (\"B_B\","
    ],
    [
        "ctrl_dtype = [(\"A.A\", int), (\"B (B)\", int), (\"C:C\", float)]",
        "ctrl_dtype = [(\"A.A\", int), (\"B"
    ],
    [
        "ctrl_dtype = [(\"A.A\", int), (\"B_(B)\", int), (\"C:C\", float)]",
        "ctrl_dtype = [(\"A.A\", int), (\"B_(B)\","
    ],
    [
        "ctrl_dtype = [(\"AA\", int), (\"B_B\", int), (\"CC\", int)]",
        "ctrl_dtype = [(\"AA\", int), (\"B_B\","
    ],
    [
        "ctrl_dtype = [(\"A.A\", int), (\"B (B)\", int), (\"C:C\", int)]",
        "ctrl_dtype = [(\"A.A\", int), (\"B"
    ],
    [
        "ctrl_dtype = [(\"A.A\", int), (\"B_(B)\", int), (\"C:C\", int)]",
        "ctrl_dtype = [(\"A.A\", int), (\"B_(B)\","
    ],
    [
        "kwargs = {\"delimiter\": \",\", \"names\": True}",
        "kwargs = {\"delimiter\": \",\", \"names\":"
    ],
    [
        "dtype=[('A', int), ('B', int), ('C', float)])",
        "dtype=[('A', int), ('B',"
    ],
    [
        "dtype=[('A', int), ('B', int), ('C', float)])",
        "dtype=[('A', int), ('B',"
    ],
    [
        "s = norm + enc + norm",
        "s = norm + enc"
    ],
    [
        "s = norm + enc + norm",
        "s = norm + enc +"
    ],
    [
        "kwargs = {\"delimiter\": \",\", \"missing_values\": \"N/A\", \"names\": True}",
        "kwargs = {\"delimiter\": \",\", \"missing_values\": \"N/A\", \"names\":"
    ],
    [
        "test = recfromtxt(data, dtype=None, usemask=True, **kwargs)",
        "test = recfromtxt(data,"
    ],
    [
        "kwargs = {\"missing_values\": \"N/A\", \"names\": True, \"case_sensitive\": True,",
        "kwargs = {\"missing_values\": \"N/A\", \"names\":"
    ],
    [
        "test = recfromcsv(data, dtype=None, usemask=True, **kwargs)",
        "test = recfromcsv(data, dtype=None, usemask=True,"
    ],
    [
        "dtype = [('a', int), ('b', float)]",
        "dtype = [('a', int), ('b',"
    ],
    [
        "a, b, c = np.loadtxt(txt, delimiter=\",\", unpack=True)",
        "a, b, c ="
    ],
    [
        "a, b, c = np.genfromtxt(txt, dtype=dt, unpack=True)",
        "a, b, c ="
    ],
    [
        "for arr, result in zip(expected, test):",
        "for arr, result in"
    ],
    [
        "kwargs = {\"delimiter\": \",\", \"missing_values\": \"N/A\", \"names\": True}",
        "kwargs = {\"delimiter\": \",\", \"missing_values\":"
    ],
    [
        "\"missing_values\": \"N/A\", \"names\": True, \"case_sensitive\": True",
        "\"missing_values\": \"N/A\", \"names\": True, \"case_sensitive\":"
    ],
    [
        "with pytest.raises(ValueError, match=\"Object arrays cannot be saved when.*\"):",
        "with pytest.raises(ValueError, match=\"Object arrays"
    ],
    [
        "with pytest.raises(ValueError, match=\"Object arrays cannot be saved when.*\"):",
        "with pytest.raises(ValueError, match=\"Object arrays"
    ],
    [
        "assert_equal(high - low, a.size * a.itemsize)",
        "assert_equal(high - low,"
    ],
    [
        "assert_equal(high - low, b.size * b.itemsize)",
        "assert_equal(high - low, b.size *"
    ],
    [
        "assert_equal(high - low, b.size * b.itemsize)",
        "assert_equal(high - low, b.size"
    ],
    [
        "msg = 'dtype of `{}` must be compatible'.format(expected)",
        "msg = 'dtype of `{}` must be"
    ],
    [
        "ec = np.array([True, False, True, True])",
        "ec = np.array([True,"
    ],
    [
        "c = isin(a, b, assume_unique=True, kind=kind)",
        "c = isin(a,"
    ],
    [
        "ec = np.array([False, False, True, True])",
        "ec = np.array([False, False,"
    ],
    [
        "c = isin(a, b, assume_unique=True, kind=kind)",
        "c = isin(a, b, assume_unique=True,"
    ],
    [
        "ec = np.array([True, False, True, False])",
        "ec = np.array([True,"
    ],
    [
        "c = isin(a, b, assume_unique=True, kind=kind)",
        "c = isin(a, b,"
    ],
    [
        "ec = [False, True, False, True, True, True, True, True, True,",
        "ec = [False, True, False, True, True,"
    ],
    [
        "ec = [True, True, True, True, True, True, True, True, True, True,",
        "ec = [True, True, True, True, True, True, True,"
    ],
    [
        "ec = np.array([True, False, True, True])",
        "ec = np.array([True,"
    ],
    [
        "ec = np.array([True, False, True, True, True])",
        "ec = np.array([True, False, True, True,"
    ],
    [
        "a = np.array(['a', 'b', 'c', 'd', 'e', 'c', 'e', 'b'])",
        "a = np.array(['a', 'b', 'c', 'd',"
    ],
    [
        "ec = np.array([True, False, True, False, False, True, False, False])",
        "ec = np.array([True, False, True, False, False, True,"
    ],
    [
        "\"\"\"Hit the standard isin code with integers\"\"\"",
        "\"\"\"Hit the standard isin code"
    ],
    [
        "ec = np.array([True, False, True, True])",
        "ec = np.array([True, False,"
    ],
    [
        "\"\"\"Test that isin works for boolean input\"\"\"",
        "\"\"\"Test that isin works for"
    ],
    [
        "\"\"\"Test that isin works for timedelta input\"\"\"",
        "\"\"\"Test that isin works for"
    ],
    [
        "\"\"\"Test that isin works as expected for mixed dtype input.\"\"\"",
        "\"\"\"Test that isin works as expected for mixed"
    ],
    [
        "expected = np.array([True, True, False, False])",
        "expected = np.array([True, True,"
    ],
    [
        "expect_failure = kind == \"table\" and (",
        "expect_failure = kind =="
    ],
    [
        "\"\"\"Test that isin works as expected for bool/int input.\"\"\"",
        "\"\"\"Test that isin works as expected"
    ],
    [
        "a = np.array([True, False, False], dtype=bool)",
        "a = np.array([True,"
    ],
    [
        "expected = np.array([False, True, True], dtype=bool)",
        "expected = np.array([False, True, True],"
    ],
    [
        "expected = np.array([True, True, True, True], dtype=bool)",
        "expected = np.array([True, True, True,"
    ],
    [
        "\"\"\"Test that isin raises expected errors.\"\"\"",
        "\"\"\"Test that isin"
    ],
    [
        "v, j = unique(a, True, False, False)",
        "v, j = unique(a, True,"
    ],
    [
        "v, j = unique(a, False, True, False)",
        "v, j = unique(a, False, True,"
    ],
    [
        "v, j = unique(a, False, False, True)",
        "v, j = unique(a,"
    ],
    [
        "msg = base_msg.format('return_index and return_inverse', dt)",
        "msg = base_msg.format('return_index"
    ],
    [
        "msg = base_msg.format('return_index and return_counts', dt)",
        "msg = base_msg.format('return_index and return_counts',"
    ],
    [
        "msg = base_msg.format('return_inverse and return_counts', dt)",
        "msg = base_msg.format('return_inverse"
    ],
    [
        "dt = [('', 'i'), ('', 'i')]",
        "dt = [('', 'i'), ('',"
    ],
    [
        "msg = \"Unique failed on list of lists\"",
        "msg = \"Unique failed on list of"
    ],
    [
        "msg = 'Non-bitwise-equal booleans test failed'",
        "msg = 'Non-bitwise-equal"
    ],
    [
        "result = np.array([[False, True], [True, True]], dtype=bool)",
        "result = np.array([[False, True], [True, True]],"
    ],
    [
        "msg = 'Negative zero equality test failed'",
        "msg = 'Negative zero"
    ],
    [
        "uniq, inv = unique(x, return_inverse=True, axis=axis)",
        "uniq, inv = unique(x,"
    ],
    [
        "msg = 'Unique returned different results when asked for index'",
        "msg = 'Unique returned different results"
    ],
    [
        "fmt = \"sort order incorrect for integer type '%s'\"",
        "fmt = \"sort order incorrect for integer type"
    ],
    [
        "for actual, expected in zip(res_unique_array_api, res_unique):",
        "for actual, expected"
    ],
    [
        "ma, angle, average, bartlett, blackman, corrcoef, cov,",
        "ma, angle, average, bartlett, blackman, corrcoef,"
    ],
    [
        "delete, diff, digitize, extract, flipud, gradient, hamming, hanning,",
        "delete, diff, digitize, extract, flipud, gradient, hamming,"
    ],
    [
        "'x, axis, expected_avg, weights, expected_wavg, expected_wsum',",
        "'x, axis, expected_avg, weights, expected_wavg,"
    ],
    [
        "wavg = np.average(x, axis=axis, weights=weights, keepdims=True)",
        "wavg = np.average(x, axis=axis, weights=weights,"
    ],
    [
        "wavg, wsum = np.average(x, axis=axis, weights=weights, returned=True,",
        "wavg, wsum = np.average(x,"
    ],
    [
        "match=\"Axis must be specified when shapes of a \"",
        "match=\"Axis must be specified when shapes of"
    ],
    [
        "match=\"Shape of weights must be consistent with \"",
        "match=\"Shape of weights must be consistent with"
    ],
    [
        "\"shape of a along specified axis\"):",
        "\"shape of a along specified"
    ],
    [
        "match=\"Shape of weights must be consistent with \"",
        "match=\"Shape of weights must be"
    ],
    [
        "\"shape of a along specified axis\"):",
        "\"shape of a"
    ],
    [
        "for at, wt, rt in typs:",
        "for at, wt, rt"
    ],
    [
        "output += [V[m] for V, C in zip(values, cond) if C[m]] or [default]",
        "output += [V[m] for V, C in zip(values, cond)"
    ],
    [
        "conditions = [np.array(True), np.array([False, True, False])]",
        "conditions = [np.array(True), np.array([False, True,"
    ],
    [
        "x = [True, True, False, False]",
        "x = [True, True,"
    ],
    [
        "[False, True], [True, True], [False, False]])",
        "[False, True], [True, True],"
    ],
    [
        "msg = 'Delete failed for obj: %r' % indices",
        "msg = 'Delete failed for obj:"
    ],
    [
        "attr_names = ('a', 'b', 'c', 'd')",
        "attr_names = ('a', 'b', 'c',"
    ],
    [
        "return (getattr(self, name) for name in attr_names)",
        "return (getattr(self, name) for name in"
    ],
    [
        "with pytest.raises(ValueError, match=r\"unexpected character\\(s\\) in `trim`\"):",
        "with pytest.raises(ValueError, match=r\"unexpected character\\(s\\)"
    ],
    [
        "assert_raises_regex(ValueError, \"Cannot insert from an empty array\",",
        "assert_raises_regex(ValueError, \"Cannot insert from an empty"
    ],
    [
        "return y * math.floor(x) + z",
        "return y * math.floor(x)"
    ],
    [
        "([(), ('a', 'b', 'c'), ('d',)], [('d', 'e')]))",
        "([(), ('a', 'b', 'c'), ('d',)],"
    ],
    [
        "assert_equal(nfb._parse_gufunc_signature('( x , y )->(  )'),",
        "assert_equal(nfb._parse_gufunc_signature('( x , y"
    ],
    [
        "'(  ), ( a,  b,c )  ,(  d)   ->   (d  ,  e)'),",
        "'( ), ( a, b,c ) ,( d)"
    ],
    [
        "([(), ('a', 'b', 'c'), ('d',)], [('d', 'e')]))",
        "([(), ('a', 'b', 'c'), ('d',)],"
    ],
    [
        "f = vectorize(lambda x: (x, x), signature='()->(),()')",
        "f = vectorize(lambda x: (x, x),"
    ],
    [
        "with assert_raises_regex(TypeError, 'wrong number of positional'):",
        "with assert_raises_regex(TypeError, 'wrong"
    ],
    [
        "ValueError, 'does not have enough dimensions'):",
        "ValueError, 'does not have"
    ],
    [
        "ValueError, 'inconsistent size for core dimension'):",
        "ValueError, 'inconsistent size for"
    ],
    [
        "with assert_raises_regex(TypeError, 'wrong number of positional'):",
        "with assert_raises_regex(TypeError, 'wrong number"
    ],
    [
        "ValueError, 'inconsistent size for core dimension'):",
        "ValueError, 'inconsistent size for"
    ],
    [
        "f = vectorize(lambda x: x, signature='()->(),()')",
        "f = vectorize(lambda"
    ],
    [
        "with assert_raises_regex(ValueError, 'wrong number of outputs'):",
        "with assert_raises_regex(ValueError, 'wrong"
    ],
    [
        "f = vectorize(lambda x: (x, x), signature='()->()')",
        "f = vectorize(lambda x:"
    ],
    [
        "with assert_raises_regex(ValueError, 'wrong number of outputs'):",
        "with assert_raises_regex(ValueError, 'wrong"
    ],
    [
        "f = np.vectorize(lambda x: x, signature='()->()')",
        "f = np.vectorize(lambda"
    ],
    [
        "f = np.vectorize(lambda x: x, signature='()->()', otypes='i')",
        "f = np.vectorize(lambda x:"
    ],
    [
        "f = np.vectorize(lambda x: x, signature='(n)->(n)', otypes='i')",
        "f = np.vectorize(lambda x: x,"
    ],
    [
        "f = np.vectorize(lambda x: x, signature='(n)->(n)')",
        "f = np.vectorize(lambda x: x,"
    ],
    [
        "f = np.vectorize(lambda x: [x], signature='()->(n)', otypes='i')",
        "f = np.vectorize(lambda x: [x], signature='()->(n)',"
    ],
    [
        "mult = np.vectorize(lambda x, y: x * y)",
        "mult = np.vectorize(lambda x, y:"
    ],
    [
        "reason=(\"Functions are immortalized if a thread is \"",
        "reason=(\"Functions are immortalized if"
    ],
    [
        "\"dtype\", \"O\" + np.typecodes[\"AllInteger\"] + np.typecodes[\"Float\"]",
        "\"dtype\", \"O\" +"
    ],
    [
        "def test_hanning(self, dtype: str, M: int) -> None:",
        "def test_hanning(self, dtype: str,"
    ],
    [
        "def test_hamming(self, dtype: str, M: int) -> None:",
        "def test_hamming(self, dtype: str, M:"
    ],
    [
        "def test_bartlett(self, dtype: str, M: int) -> None:",
        "def test_bartlett(self, dtype: str,"
    ],
    [
        "def test_blackman(self, dtype: str, M: int) -> None:",
        "def test_blackman(self, dtype: str, M: int) ->"
    ],
    [
        "def test_kaiser(self, dtype: str, M: int) -> None:",
        "def test_kaiser(self, dtype: str, M:"
    ],
    [
        "q = x[:, None, None] + y[None, :, None] + z[None, None, :]",
        "q = x[:, None, None] + y[None, :, None] +"
    ],
    [
        "x = ['widget', 'ham', 'foo', 'bar', 'foo', 'ham']",
        "x = ['widget', 'ham', 'foo', 'bar',"
    ],
    [
        "assert_(np.all(unique(x) == ['bar', 'foo', 'ham', 'widget']))",
        "assert_(np.all(unique(x) == ['bar',"
    ],
    [
        "[X, Y] = meshgrid(x, y, indexing='ij')",
        "[X, Y] = meshgrid(x,"
    ],
    [
        "X, Y = np.meshgrid(x, y, copy=True)",
        "X, Y ="
    ],
    [
        "X, Y = np.meshgrid(x, y, sparse=True)",
        "X, Y = np.meshgrid(x, y,"
    ],
    [
        "x, y = np.meshgrid(X, Y, sparse=False, copy=True)",
        "x, y = np.meshgrid(X,"
    ],
    [
        "\"\"\" scale function used by the below tests \"\"\"",
        "\"\"\" scale function used by the"
    ],
    [
        "\"\"\" test that nans are propagated \"\"\"",
        "\"\"\" test that nans are"
    ],
    [
        "\"\"\" Test that interp between opposite infs gives nan \"\"\"",
        "\"\"\" Test that interp between opposite infs gives"
    ],
    [
        "\"\"\" Test that interp where both axes have a bound at inf gives nan \"\"\"",
        "\"\"\" Test that interp where both axes have"
    ],
    [
        "\"\"\" Test interp where the x axis has a bound at inf \"\"\"",
        "\"\"\" Test interp where the x axis has"
    ],
    [
        "\"\"\" Test interp where the f axis has a bound at inf \"\"\"",
        "\"\"\" Test interp where the f axis"
    ],
    [
        "weights = np.ones_like(arr) if weighted else None",
        "weights = np.ones_like(arr) if weighted else"
    ],
    [
        "actual = function(arr, quantile, method=method, weights=weights)",
        "actual = function(arr, quantile,"
    ],
    [
        "TYPE_CODES = np.typecodes[\"AllInteger\"] + np.typecodes[\"Float\"] + \"O\"",
        "TYPE_CODES = np.typecodes[\"AllInteger\"] +"
    ],
    [
        "out_dtype = int if with_weights else float",
        "out_dtype = int if with_weights"
    ],
    [
        "weights = np.ones_like(x) if with_weights else None",
        "weights = np.ones_like(x) if with_weights"
    ],
    [
        "r = percentile(x, p, out=y, weights=weights)",
        "r = percentile(x, p,"
    ],
    [
        "weights = np.ones_like(x) if with_weights else None",
        "weights = np.ones_like(x) if with_weights else"
    ],
    [
        "weights = np.ones_like(x) if with_weights else None",
        "weights = np.ones_like(x) if with_weights"
    ],
    [
        "result = np.percentile(d, q, axis=axis, keepdims=True, out=out)",
        "result = np.percentile(d, q, axis=axis, keepdims=True,"
    ],
    [
        "with pytest.raises(ValueError, match=\"Percentiles must be in\"):",
        "with pytest.raises(ValueError, match=\"Percentiles must be"
    ],
    [
        "with pytest.raises(ValueError, match=\"Percentiles must be in\"):",
        "with pytest.raises(ValueError, match=\"Percentiles must"
    ],
    [
        "with pytest.raises(ValueError, match=\"Percentiles must be in\"):",
        "with pytest.raises(ValueError, match=\"Percentiles"
    ],
    [
        "return (x >= y) - alpha",
        "return (x >="
    ],
    [
        "if weights and method not in methods_supporting_weights:",
        "if weights and method"
    ],
    [
        "x = np.quantile(y, alpha, method=method, weights=w)",
        "x = np.quantile(y,"
    ],
    [
        "elif int(n * alpha) == n * alpha and not weights:",
        "elif int(n * alpha) == n *"
    ],
    [
        "if weights and method not in methods_supporting_weights:",
        "if weights and method not in"
    ],
    [
        "q = np.quantile(y, alpha, method=method, weights=w)",
        "q = np.quantile(y,"
    ],
    [
        "assert_allclose(np.quantile(c + y, alpha, method=method, weights=w),",
        "assert_allclose(np.quantile(c + y,"
    ],
    [
        "assert_allclose(np.quantile(c * y, alpha, method=method, weights=w),",
        "assert_allclose(np.quantile(c * y,"
    ],
    [
        "n * alpha == int(n * alpha)",
        "n * alpha =="
    ],
    [
        "if n * alpha == int(n * alpha):",
        "if n * alpha =="
    ],
    [
        "if n * alpha == int(n * alpha):",
        "if n * alpha == int(n *"
    ],
    [
        "qw = np.quantile(y, alpha, method=method, weights=w)",
        "qw = np.quantile(y, alpha,"
    ],
    [
        "qw = np.quantile(y, alpha, method=method, weights=w)",
        "qw = np.quantile(y, alpha, method=method,"
    ],
    [
        "qw = np.quantile(y, alpha, method=method, weights=w)",
        "qw = np.quantile(y, alpha, method=method,"
    ],
    [
        "q = np.quantile(np.repeat(y, w), alpha, method=method)",
        "q = np.quantile(np.repeat(y, w), alpha,"
    ],
    [
        "y[i, :, j], alpha, method=method, weights=w",
        "y[i, :, j], alpha, method=method,"
    ],
    [
        "y[i, :, j], alpha, method=method, weights=w",
        "y[i, :, j], alpha, method=method,"
    ],
    [
        "y[i, :, j], alpha, method=method, weights=w[i, :, j]",
        "y[i, :, j], alpha,"
    ],
    [
        "with pytest.raises(ValueError, match=\"Weights must be non-negative\"):",
        "with pytest.raises(ValueError, match=\"Weights must be"
    ],
    [
        "msg = \"Only method 'inverted_cdf' supports weights\"",
        "msg = \"Only method 'inverted_cdf' supports"
    ],
    [
        "assert a <= nfb._lerp(a, b, t) <= b",
        "assert a <= nfb._lerp(a, b,"
    ],
    [
        "assert b <= nfb._lerp(a, b, t) <= a",
        "assert b <= nfb._lerp(a, b, t) <="
    ],
    [
        "\"\"\"Check that we return subclasses, even if a NaN scalar.\"\"\"",
        "\"\"\"Check that we return subclasses, even if a"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work correctly\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "result = np.median(d, axis=axis, keepdims=True, out=out)",
        "result = np.median(d,"
    ],
    [
        "\"\"\"Tests for the array padding functions.",
        "\"\"\"Tests for the"
    ],
    [
        "from numpy.testing import assert_array_equal, assert_allclose, assert_equal",
        "from numpy.testing import assert_array_equal,"
    ],
    [
        "\"\"\"Test casting for a single value.\"\"\"",
        "\"\"\"Test casting for a single"
    ],
    [
        "\"\"\"Test proper casting for two different values.\"\"\"",
        "\"\"\"Test proper casting for two different"
    ],
    [
        "expected = ((None, None), (None, None), (None, None))",
        "expected = ((None, None), (None, None), (None,"
    ],
    [
        "\"\"\"Test if `x` already matching desired output are passed through.\"\"\"",
        "\"\"\"Test if `x` already matching desired output are"
    ],
    [
        "with pytest.raises(ValueError, match=\"more dimensions than allowed\"):",
        "with pytest.raises(ValueError, match=\"more dimensions"
    ],
    [
        "with pytest.raises(ValueError, match=\"could not be broadcast\"):",
        "with pytest.raises(ValueError, match=\"could not"
    ],
    [
        "with pytest.raises(ValueError, match=\"could not be broadcast\"):",
        "with pytest.raises(ValueError, match=\"could not be"
    ],
    [
        "\"\"\" Test that appended and prepended values are equal \"\"\"",
        "\"\"\" Test that appended and prepended values are"
    ],
    [
        "match = \"index can't contain negative values\"",
        "match = \"index can't contain"
    ],
    [
        "\"ignore:invalid value encountered in( scalar)? divide:RuntimeWarning\"",
        "\"ignore:invalid value encountered"
    ],
    [
        "\"\"\"Ensure that end values are exact.\"\"\"",
        "\"\"\"Ensure that end values are"
    ],
    [
        "Check correct behavior of unsigned dtypes if there is a negative",
        "Check correct behavior of unsigned dtypes if there"
    ],
    [
        "difference between the edge to pad and `end_values`. Check both cases",
        "difference between the edge to pad"
    ],
    [
        "to be independent of implementation. Test behavior for all other dtypes",
        "to be independent of implementation. Test behavior for all"
    ],
    [
        "\"\"\"Check how padding behaves on arrays with an empty dimension.\"\"\"",
        "\"\"\"Check how padding behaves on arrays with"
    ],
    [
        "Check wrapping on each side individually if the wrapped area is longer",
        "Check wrapping on each side individually if the wrapped area is"
    ],
    [
        "Assert that 'wrap' pads only with multiples of the original area if",
        "Assert that 'wrap' pads only with multiples of"
    ],
    [
        "the pad width is larger than the original array.",
        "the pad width is larger than"
    ],
    [
        "match = \"operands could not be broadcast together\"",
        "match = \"operands could not be broadcast"
    ],
    [
        "match = (\"input operand has more dimensions than allowed by the axis \"",
        "match = (\"input operand has more dimensions"
    ],
    [
        "match = \"index can't contain negative values\"",
        "match = \"index can't contain"
    ],
    [
        "match = \"`pad_width` must be of integral type.\"",
        "match = \"`pad_width` must"
    ],
    [
        "\"\"\"Test behavior of pad's kwargs for the given mode.\"\"\"",
        "\"\"\"Test behavior of pad's kwargs for the given"
    ],
    [
        "match = \"unsupported keyword arguments for mode '{}'\".format(mode)",
        "match = \"unsupported keyword arguments for mode"
    ],
    [
        "match = \"mode '{}' is not supported\".format(mode)",
        "match = \"mode '{}' is"
    ],
    [
        "\"\"\"Test if C and F order is preserved for all pad modes.\"\"\"",
        "\"\"\"Test if C and F order is preserved for"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method, *inputs,"
    ],
    [
        "for x in inputs + out:",
        "for x in"
    ],
    [
        "if not isinstance(x, self._HANDLED_TYPES + (ArrayLike,)):",
        "if not isinstance(x,"
    ],
    [
        "inputs = tuple(x.value if isinstance(x, ArrayLike) else x",
        "inputs = tuple(x.value if isinstance(x, ArrayLike)"
    ],
    [
        "x.value if isinstance(x, ArrayLike) else x",
        "x.value if isinstance(x, ArrayLike) else"
    ],
    [
        "return tuple(type(self)(x) for x in result)",
        "return tuple(type(self)(x) for"
    ],
    [
        "return tuple(ArrayLike(r) for r in result)",
        "return tuple(ArrayLike(r) for r"
    ],
    [
        "for result_item, expected_item in zip(result, expected):",
        "for result_item, expected_item"
    ],
    [
        "\"\"\"Object that opts out of __array_ufunc__.\"\"\"",
        "\"\"\"Object that opts out of"
    ],
    [
        "err_msg = 'failed for operator {}'.format(op)",
        "err_msg = 'failed"
    ],
    [
        "err_msg = 'failed for operator {}'.format(op)",
        "err_msg = 'failed"
    ],
    [
        "from numpy.testing import assert_array_equal, assert_equal, assert_raises",
        "from numpy.testing import"
    ],
    [
        "from tempfile import mkdtemp, mkstemp, NamedTemporaryFile",
        "from tempfile import mkdtemp,"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import assert_, assert_equal,"
    ],
    [
        "'''Stub to replace urlopen for testing.'''",
        "'''Stub to replace"
    ],
    [
        "raise URLError('Name or service not known')",
        "raise URLError('Name or service"
    ],
    [
        "magic_line = b'three is the magic number'",
        "magic_line = b'three is the"
    ],
    [
        "fd, path = mkstemp(suffix='.txt', prefix='dstmp_', dir=filedir, text=True)",
        "fd, path = mkstemp(suffix='.txt', prefix='dstmp_',"
    ],
    [
        "fd, path = mkstemp(suffix='.txt', prefix='dstmp_', dir=filedir)",
        "fd, path ="
    ],
    [
        "scheme, netloc, upath, pms, qry, frg = urlparse(valid_httpurl())",
        "scheme, netloc, upath, pms,"
    ],
    [
        "scheme, netloc, upath, pms, qry, frg = urlparse(invalid_httpurl())",
        "scheme, netloc, upath, pms, qry,"
    ],
    [
        "scheme, netloc, upath, pms, qry, frg = urlparse(valid_httpurl())",
        "scheme, netloc, upath, pms, qry, frg"
    ],
    [
        "scheme, netloc, upath, pms, qry, frg = urlparse(localfile)",
        "scheme, netloc, upath, pms, qry,"
    ],
    [
        "inarrays = [np.zeros(s) for s in input_shapes]",
        "inarrays = [np.zeros(s) for s in"
    ],
    [
        "outshapes = [a.shape for a in outarrays]",
        "outshapes = [a.shape for a"
    ],
    [
        "inarrays = [np.zeros(s) for s in input_shapes]",
        "inarrays = [np.zeros(s) for s in"
    ],
    [
        "with assert_raises_regex(TypeError, 'got an unexpected keyword'):",
        "with assert_raises_regex(TypeError, 'got an"
    ],
    [
        "for input_array, shape, expected in data:",
        "for input_array, shape,"
    ],
    [
        "with pytest.raises(ValueError, match='cannot contain negative values'):",
        "with pytest.raises(ValueError, match='cannot"
    ],
    [
        "match='must provide window_shape for all dimensions of `x`'):",
        "match='must provide window_shape for all dimensions of"
    ],
    [
        "match='Must provide matching length window_shape and axis'):",
        "match='Must provide matching length window_shape"
    ],
    [
        "match='window shape cannot be larger than input array'):",
        "match='window shape cannot be larger than"
    ],
    [
        "self.info = getattr(obj, 'info', '') + ' finalized'",
        "self.info = getattr(obj, 'info', '') +"
    ],
    [
        "a_view, b_view = broadcast_arrays(a, b, subok=True)",
        "a_view, b_view = broadcast_arrays(a,"
    ],
    [
        "for array_is_broadcast, result in zip(is_broadcast, results):",
        "for array_is_broadcast, result in zip(is_broadcast,"
    ],
    [
        "for array_is_broadcast, result in zip(is_broadcast, results):",
        "for array_is_broadcast, result in zip(is_broadcast,"
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int)])])",
        "dtype=[('a', int), ('b', [('ba', float),"
    ],
    [
        "self.data = (w, x, y, z)",
        "self.data = (w, x,"
    ],
    [
        "(w, x, y, z) = self.data",
        "(w, x, y,"
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int)])])",
        "dtype=[('a', int), ('b', [('ba', float),"
    ],
    [
        "test = rename_fields(a, {'a': 'A', 'bb': 'BB'})",
        "test = rename_fields(a, {'a': 'A', 'bb':"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', [('ba', float), ('bb', int)])])",
        "ndtype = np.dtype([('a', int), ('b', [('ba', float), ('bb',"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', [])])",
        "ndtype = np.dtype([('a', int),"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', [('ba', float), ('bb', int)])])",
        "ndtype = np.dtype([('a', int), ('b', [('ba', float), ('bb',"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', [])])",
        "ndtype = np.dtype([('a', int), ('b',"
    ],
    [
        "assert_equal(test, {'A': [], 'B': [], 'BA': ['B', ], 'BB': ['B']})",
        "assert_equal(test, {'A': [], 'B': [],"
    ],
    [
        "control = {'A': [], 'B': [], 'BA': ['B'], 'BB': ['B'],",
        "control = {'A': [], 'B': [], 'BA': ['B'],"
    ],
    [
        "'BBA': ['B', 'BB'], 'BBB': ['B', 'BB']}",
        "'BBA': ['B', 'BB'], 'BBB':"
    ],
    [
        "point = np.dtype([('x', int), ('y', int)])",
        "point = np.dtype([('x', int), ('y',"
    ],
    [
        "triangle = np.dtype([('a', point), ('b', point), ('c', point)])",
        "triangle = np.dtype([('a', point),"
    ],
    [
        "return np.dtype([('x{}'.format(i), dt) for i, dt in enumerate(dts)])",
        "return np.dtype([('x{}'.format(i), dt) for i, dt in"
    ],
    [
        "test_dtype_args = [('x', float), ('y', float)]",
        "test_dtype_args = [('x', float),"
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int), ('bc', [])])])",
        "dtype=[('a', int), ('b', [('ba', float), ('bb',"
    ],
    [
        "self.data = (w, x, y, z)",
        "self.data = (w, x,"
    ],
    [
        "(_, x, _, z) = self.data",
        "(_, x, _,"
    ],
    [
        "dtype=[('a', int), ('ba', float), ('bb', int)])",
        "dtype=[('a', int), ('ba',"
    ],
    [
        "(_, x, y, _) = self.data",
        "(_, x, y, _)"
    ],
    [
        "(_, x, _, z) = self.data",
        "(_, x, _, z)"
    ],
    [
        "(w, x, _, _) = self.data",
        "(w, x, _, _)"
    ],
    [
        "('a', int), ('ba', float), ('bb', int)])",
        "('a', int), ('ba', float),"
    ],
    [
        "('b', [('ba', float), ('bb', int), ('bc', [])])])]",
        "('b', [('ba', float), ('bb', int),"
    ],
    [
        "(_, x, _, _) = self.data",
        "(_, x, _,"
    ],
    [
        "test = merge_arrays((x, mx), usemask=True, asrecarray=True)",
        "test = merge_arrays((x, mx),"
    ],
    [
        "(_, x, y, z) = self.data",
        "(_, x, y, z) ="
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int)])])",
        "dtype=[('a', int), ('b', [('ba', float), ('bb',"
    ],
    [
        "self.data = (w, x, y, z)",
        "self.data = (w, x, y,"
    ],
    [
        "(_, x, _, _) = self.data",
        "(_, x, _, _) ="
    ],
    [
        "(_, x, _, _) = self.data",
        "(_, x, _,"
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int)])])",
        "dtype=[('a', int), ('b', [('ba', float),"
    ],
    [
        "self.data = (w, x, y, z)",
        "self.data = (w,"
    ],
    [
        "(_, x, _, _) = self.data",
        "(_, x, _,"
    ],
    [
        "(_, x, y, _) = self.data",
        "(_, x, y,"
    ],
    [
        "(_, x, _, z) = self.data",
        "(_, x, _,"
    ],
    [
        "(_, x, _, z) = self.data",
        "(_, x, _,"
    ],
    [
        "(_, _, _, z) = self.data",
        "(_, _, _, z) ="
    ],
    [
        "adtype = [('A', int), ('B', bool), ('C', float)]",
        "adtype = [('A', int),"
    ],
    [
        "bdtype = [('A', int), ('B', float), ('C', float)]",
        "bdtype = [('A', int), ('B', float),"
    ],
    [
        "adtype = [(('a', 'A'), int), (('b', 'B'), bool), (('c', 'C'), float)]",
        "adtype = [(('a', 'A'), int), (('b',"
    ],
    [
        "bdtype = [(('a', 'A'), int), (('b', 'B'), bool), (('c', 'C'), float)]",
        "bdtype = [(('a', 'A'), int), (('b',"
    ],
    [
        "dtype=[('a', int), ('b', int), ('c', int)])",
        "dtype=[('a', int), ('b',"
    ],
    [
        "dtype=[('a', int), ('b', int), ('d', int)])",
        "dtype=[('a', int), ('b', int), ('d',"
    ],
    [
        "test = join_by('a', a, b, jointype='inner')",
        "test = join_by('a', a, b,"
    ],
    [
        "test = join_by(('a', 'b'), a, b, 'outer')",
        "test = join_by(('a', 'b'),"
    ],
    [
        "test = join_by(('a', 'b'), a, b, 'leftouter')",
        "test = join_by(('a', 'b'), a,"
    ],
    [
        "dtype=[('a', int), ('b', int), ('c', int), ('d', int)])",
        "dtype=[('a', int), ('b', int), ('c', int),"
    ],
    [
        "j = join_by(['c', 'b'], a, b, jointype='inner', usemask=False)",
        "j = join_by(['c', 'b'], a,"
    ],
    [
        "assert_raises(ValueError, join_by, ['a', 'b', 'b'], a, b)",
        "assert_raises(ValueError, join_by, ['a', 'b', 'b'],"
    ],
    [
        "dtype=[('a', int), ('b', int), ('c', int)])",
        "dtype=[('a', int), ('b',"
    ],
    [
        "dtype=[('a', int), ('b', int), ('d', int)])",
        "dtype=[('a', int), ('b',"
    ],
    [
        "dtype=[('k', int), ('a', int), ('b', int), ('c', int)])",
        "dtype=[('k', int), ('a', int),"
    ],
    [
        "dtype=[('k', int), ('a', int), ('b', int), ('c', int)])",
        "dtype=[('k', int), ('a', int), ('b', int), ('c',"
    ],
    [
        "Test append_fields with arrays containing objects",
        "Test append_fields with"
    ],
    [
        "\"Test append_fields when the base array contains objects\"",
        "\"Test append_fields when the base array contains"
    ],
    [
        "test = append_fields(x, 'C', data=y, usemask=False)",
        "test = append_fields(x, 'C',"
    ],
    [
        "dtype=[('A', object), ('B', float), ('C', int)])",
        "dtype=[('A', object), ('B',"
    ],
    [
        "IDS = [k.__name__ for k in NANFUNCS]",
        "IDS = [k.__name__ for k in"
    ],
    [
        "\"\"\"Construct a signature and replace all default parameter-values.\"\"\"",
        "\"\"\"Construct a signature and replace all default"
    ],
    [
        "\"\"\"Validate that all nan functions are actually tested.\"\"\"",
        "\"\"\"Validate that all nan functions are"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "tgt = [rf(d) for d in _rdat]",
        "tgt = [rf(d) for d in"
    ],
    [
        "for f, fcmp in zip(self.nanfuncs, [np.greater, np.less]):",
        "for f, fcmp in zip(self.nanfuncs,"
    ],
    [
        "\"attempt to get argm.. of an empty sequence\",",
        "\"attempt to get argm.. of an"
    ],
    [
        "nanfunc_ids = [i.__name__ for i in nanfuncs]",
        "nanfunc_ids = [i.__name__ for i"
    ],
    [
        "def test_nanfunc(self, mat, dtype, nanfunc, func):",
        "def test_nanfunc(self, mat, dtype, nanfunc,"
    ],
    [
        "def test_nanfunc_q(self, mat, dtype, nanfunc, func):",
        "def test_nanfunc_q(self, mat, dtype,"
    ],
    [
        "def test_nanfunc_ddof(self, mat, dtype, nanfunc, func):",
        "def test_nanfunc_ddof(self, mat,"
    ],
    [
        "err_msg = \"ddof and correction can't be provided simultaneously.\"",
        "err_msg = \"ddof and correction can't be provided"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in zip(self.nanfuncs,"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "if nf in {np.nanstd, np.nanvar} and c in 'FDG':",
        "if nf in {np.nanstd, np.nanvar} and c"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "if nf in {np.nanstd, np.nanvar} and c in 'FDG':",
        "if nf in {np.nanstd, np.nanvar} and"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "assert_(res is tgt, \"res %s, tgt %s\" % (res, tgt))",
        "assert_(res is tgt, \"res %s, tgt"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "tgt = [rf(d) for d in _rdat]",
        "tgt = [rf(d) for d in"
    ],
    [
        "for f, g in zip(self.nanfuncs, self.stdfuncs):",
        "for f, g"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "for dtype in [np.bool, np.int_, np.object_]:",
        "for dtype in [np.bool, np.int_,"
    ],
    [
        "for dtype in [np.bool, np.int_, np.object_]:",
        "for dtype in"
    ],
    [
        "for nf, rf in zip(nanfuncs, stdfuncs):",
        "for nf, rf"
    ],
    [
        "tgt = [rf(d, ddof=ddof) for d in _rdat]",
        "tgt = [rf(d, ddof=ddof) for d in"
    ],
    [
        "dsize = [len(d) for d in _rdat]",
        "dsize = [len(d) for d"
    ],
    [
        "for nf, rf in zip(nanfuncs, stdfuncs):",
        "for nf, rf"
    ],
    [
        "tgt = [ddof >= d for d in dsize]",
        "tgt = [ddof >= d for d in"
    ],
    [
        "for f, f_std in zip(self.nanfuncs, self.stdfuncs):",
        "for f, f_std in"
    ],
    [
        "dtype_reference = dtype if f is np.nanmean else ar.real.dtype",
        "dtype_reference = dtype if f is"
    ],
    [
        "\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \"ps\", \"fs\", \"as\"",
        "\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \"ps\", \"fs\","
    ],
    [
        "tgt = np.median(mat, axis=axis, out=None, overwrite_input=False)",
        "tgt = np.median(mat, axis=axis,"
    ],
    [
        "res = np.nanmedian(mat, axis=axis, out=None, overwrite_input=False)",
        "res = np.nanmedian(mat,"
    ],
    [
        "result = np.nanmedian(d, axis=axis, keepdims=True, out=out)",
        "result = np.nanmedian(d,"
    ],
    [
        "tgt = [np.median(d) for d in _rdat]",
        "tgt = [np.median(d) for d in"
    ],
    [
        "a = np.array([[inf,  np.nan], [np.nan, np.nan]])",
        "a = np.array([[inf,"
    ],
    [
        "a = np.array([[inf, inf], [inf, inf]])",
        "a = np.array([[inf,"
    ],
    [
        "([np.nan] * i) + [inf] * j)",
        "([np.nan] * i) + [inf] *"
    ],
    [
        "([np.nan] * i) + [-inf] * j)",
        "([np.nan] * i) + [-inf] *"
    ],
    [
        "result = np.nanpercentile(d, q, axis=axis, keepdims=True, out=out)",
        "result = np.nanpercentile(d, q, axis=axis, keepdims=True,"
    ],
    [
        "w_args = {\"weights\": np.ones_like(mat), \"method\": \"inverted_cdf\"}",
        "w_args = {\"weights\": np.ones_like(mat),"
    ],
    [
        "out = np.empty_like(tgt) if use_out else None",
        "out = np.empty_like(tgt) if use_out"
    ],
    [
        "out = np.empty_like(tgt) if use_out else None",
        "out = np.empty_like(tgt) if"
    ],
    [
        "val = np.percentile(mat, perc, axis=axis, keepdims=keepdim)",
        "val = np.percentile(mat, perc, axis=axis,"
    ],
    [
        "x, p, axis=axis, weights=weights, out=out, method=\"inverted_cdf\")",
        "x, p, axis=axis,"
    ],
    [
        "w_args = {\"weights\": np.ones_like(ar), \"method\": \"inverted_cdf\"}",
        "w_args = {\"weights\":"
    ],
    [
        "for out in [None, np.empty(arr.shape, dtype=np.bool)]:",
        "for out in"
    ],
    [
        "\"\"\" Test that _replace_nan returns the original array if there are no",
        "\"\"\" Test that _replace_nan returns the"
    ],
    [
        "Tests specific to `np.loadtxt` added during the move of loadtxt to be backed",
        "Tests specific to `np.loadtxt` added during the move of loadtxt to"
    ],
    [
        "These tests complement those found in `test_io.py`.",
        "These tests complement those"
    ],
    [
        "from numpy.testing import assert_array_equal, HAS_REFCOUNT, IS_PYPY",
        "from numpy.testing import assert_array_equal, HAS_REFCOUNT,"
    ],
    [
        "\"\"\"Test that both 'e' and 'E' are parsed correctly.\"\"\"",
        "\"\"\"Test that both 'e' and"
    ],
    [
        "@pytest.mark.parametrize(\"comment\", [\"..\", \"//\", \"@-\", \"this is a comment:\"])",
        "@pytest.mark.parametrize(\"comment\", [\"..\", \"//\", \"@-\", \"this is"
    ],
    [
        "Fixture providing heterogeneous input data with a structured dtype, along",
        "Fixture providing heterogeneous input data with"
    ],
    [
        "a = np.loadtxt(data, dtype=dtype, delimiter=\";\", skiprows=skiprows)",
        "a = np.loadtxt(data,"
    ],
    [
        "a, b, c, d = np.loadtxt(data, dtype=dtype, delimiter=\";\", unpack=True)",
        "a, b, c, d = np.loadtxt(data,"
    ],
    [
        "point = np.dtype([('x', float), ('y', float)])",
        "point = np.dtype([('x', float), ('y',"
    ],
    [
        "\"\"\"skiprows and max_rows should raise for negative parameters.\"\"\"",
        "\"\"\"skiprows and max_rows should raise for"
    ],
    [
        "with pytest.raises(ValueError, match=\"argument must be nonnegative\"):",
        "with pytest.raises(ValueError, match=\"argument must"
    ],
    [
        "with pytest.raises(TypeError, match=\"argument must be an integer\"):",
        "with pytest.raises(TypeError, match=\"argument must be an"
    ],
    [
        "with pytest.raises(ValueError, match=\"Illegal value of ndmin keyword\"):",
        "with pytest.raises(ValueError, match=\"Illegal value of"
    ],
    [
        "res = np.loadtxt(txt, dtype=np.dtype([]), delimiter=\",\", usecols=[])",
        "res = np.loadtxt(txt, dtype=np.dtype([]),"
    ],
    [
        "expected = np.array([['CAT', 'dog'], ['Î‘Î’Î“', 'Î´ÎµÎ¶'], ['ABC', 'def']])",
        "expected = np.array([['CAT', 'dog'], ['Î‘Î’Î“', 'Î´ÎµÎ¶'],"
    ],
    [
        "res = np.loadtxt(txt, dtype=dt, delimiter=\",\", converters=conv)",
        "res = np.loadtxt(txt, dtype=dt, delimiter=\",\","
    ],
    [
        "With the 'bytes' encoding, tokens are encoded prior to being",
        "With the 'bytes' encoding, tokens are encoded"
    ],
    [
        "passed to the converter. This means that the output of the converter may",
        "passed to the converter. This means that the output of"
    ],
    [
        "be bytes instead of unicode as expected by `read_rows`.",
        "be bytes instead of unicode as"
    ],
    [
        "This test checks that outputs from the above scenario are properly decoded",
        "This test checks that outputs from the above"
    ],
    [
        "expected = np.array([['ABC', 'DEF'], ['RST', 'XYZ']])",
        "expected = np.array([['ABC', 'DEF'], ['RST',"
    ],
    [
        "The given dtype is just 'S' or 'U' with no length. In these cases, the",
        "The given dtype is just 'S' or 'U'"
    ],
    [
        "length of the resulting dtype is determined by the longest string found",
        "length of the resulting dtype is determined by"
    ],
    [
        "Python built-in `float` function. In a naive version of the float parser,",
        "Python built-in `float` function. In a naive version of the float"
    ],
    [
        "these strings resulted in values that were off by an ULP or two.",
        "these strings resulted in values that were"
    ],
    [
        "expected = np.array([float(s) for s in strings])",
        "expected = np.array([float(s) for s"
    ],
    [
        "for sign in [\"++\", \"+-\", \"--\", \"-+\"]:",
        "for sign in [\"++\", \"+-\","
    ],
    [
        "res = np.loadtxt(gen(), dtype=\"i, d\", delimiter=\" \")",
        "res = np.loadtxt(gen(), dtype=\"i, d\","
    ],
    [
        "TypeError, match=r\"non-string returned while reading data\"):",
        "TypeError, match=r\"non-string returned"
    ],
    [
        "\"\"\"Test exception when a character cannot be encoded as 'S'.\"\"\"",
        "\"\"\"Test exception when a character cannot"
    ],
    [
        "\"converters must be a dictionary mapping columns to converter \"",
        "\"converters must be a dictionary mapping columns to converter"
    ],
    [
        "with pytest.raises(TypeError, match=\"keys of the converters dict\"):",
        "with pytest.raises(TypeError, match=\"keys of the converters"
    ],
    [
        "with pytest.raises(TypeError, match=\"keys of the converters dict\"):",
        "with pytest.raises(TypeError, match=\"keys of the"
    ],
    [
        "with pytest.raises(ValueError, match=\"converter specified for column\"):",
        "with pytest.raises(ValueError, match=\"converter specified"
    ],
    [
        "match=\"values of the converters dictionary must be callable\"):",
        "match=\"values of the converters dictionary must be"
    ],
    [
        "res = np.loadtxt(txt, dtype=dtype, delimiter=\",\", quotechar=q)",
        "res = np.loadtxt(txt,"
    ],
    [
        "res = np.loadtxt(txt, dtype=dtype, delimiter=None, quotechar=q)",
        "res = np.loadtxt(txt,"
    ],
    [
        "\"\"\"Support for quoted fields is disabled by default.\"\"\"",
        "\"\"\"Support for quoted fields is disabled"
    ],
    [
        "res = np.loadtxt(txt, dtype=dtype, delimiter=\",\", quotechar='\"')",
        "res = np.loadtxt(txt, dtype=dtype, delimiter=\",\","
    ],
    [
        "msg = r\".*must be a single unicode character or None\"",
        "msg = r\".*must be a"
    ],
    [
        "\"when multiple comments or a multi-character comment is given, \"",
        "\"when multiple comments or a multi-character comment is"
    ],
    [
        "res = np.loadtxt(data, dtype=dtype, delimiter=\";\", quotechar=\"'\")",
        "res = np.loadtxt(data, dtype=dtype,"
    ],
    [
        "txt = StringIO('\"Hello, my name is \"\"Monty\"\"!\"')",
        "txt = StringIO('\"Hello, my"
    ],
    [
        "\"\"\"Check that a UserWarning is emitted when no data is read from input.\"\"\"",
        "\"\"\"Check that a UserWarning is emitted when no data"
    ],
    [
        "with pytest.warns(UserWarning, match=\"input contained no data\"):",
        "with pytest.warns(UserWarning, match=\"input contained no"
    ],
    [
        "with pytest.warns(UserWarning, match=\"input contained no data\"):",
        "with pytest.warns(UserWarning, match=\"input"
    ],
    [
        "with pytest.warns(UserWarning, match=\"input contained no data\"):",
        "with pytest.warns(UserWarning, match=\"input contained no"
    ],
    [
        "res = np.loadtxt(txt, dtype=dtype, delimiter=\",\", quotechar='\"')",
        "res = np.loadtxt(txt,"
    ],
    [
        "pytest.skip(\"half assignment currently uses Python float converter\")",
        "pytest.skip(\"half assignment currently uses Python float"
    ],
    [
        "pytest.xfail(\"clongdouble assignment is buggy (uses `complex`?).\")",
        "pytest.xfail(\"clongdouble assignment is buggy (uses"
    ],
    [
        "msg = \"Found an unquoted embedded newline within a single line\"",
        "msg = \"Found an unquoted embedded newline within a single"
    ],
    [
        "data = [row.replace(\"\\n\", newline) for row in data]",
        "data = [row.replace(\"\\n\", newline) for row in"
    ],
    [
        "res = np.loadtxt(data, dtype=object, delimiter=\",\", quotechar='\"')",
        "res = np.loadtxt(data, dtype=object,"
    ],
    [
        "match=\"error reading from object, expected an iterable\"):",
        "match=\"error reading from object,"
    ],
    [
        "with pytest.raises(TypeError, match=\"internal error: dtype must\"):",
        "with pytest.raises(TypeError, match=\"internal error: dtype"
    ],
    [
        "with pytest.raises(TypeError, match=\"encoding must be a unicode\"):",
        "with pytest.raises(TypeError, match=\"encoding must"
    ],
    [
        "TypeError, match=\"Comment characters.*cannot include the delimiter\"",
        "TypeError, match=\"Comment characters.*cannot include"
    ],
    [
        "msg = \"control character.*cannot be a newline\"",
        "msg = \"control character.*cannot"
    ],
    [
        "\"\"\"Check that the correct unit (e.g. month, day, second) is discovered from",
        "\"\"\"Check that the correct unit (e.g. month, day, second)"
    ],
    [
        "the data when a user specifies a unitless datetime.\"\"\"",
        "the data when a user specifies a"
    ],
    [
        "data = [generic_data] * nrows + [long_datum]",
        "data = [generic_data] *"
    ],
    [
        "with pytest.raises(TypeError, match=\"Text reading control character must\"):",
        "with pytest.raises(TypeError, match=\"Text reading control"
    ],
    [
        "with pytest.raises(TypeError, match=\"Text reading control character must\"):",
        "with pytest.raises(TypeError, match=\"Text reading control character"
    ],
    [
        "with pytest.raises(ValueError, match=\"comments cannot be an empty string\"):",
        "with pytest.raises(ValueError, match=\"comments cannot be an empty"
    ],
    [
        "with pytest.raises(ValueError, match=\"comments cannot be an empty string\"):",
        "with pytest.raises(ValueError, match=\"comments cannot be an empty"
    ],
    [
        "\"\"\"Byte control characters (comments, delimiter) are supported.\"\"\"",
        "\"\"\"Byte control characters (comments, delimiter)"
    ],
    [
        "res = np.loadtxt(txt, dtype=str, delimiter=\" \", max_rows=nmax)",
        "res = np.loadtxt(txt, dtype=str,"
    ],
    [
        "res = np.loadtxt(fname, dtype=str, delimiter=\" \", max_rows=nmax)",
        "res = np.loadtxt(fname, dtype=str, delimiter=\" \","
    ],
    [
        "r''' Test the .npy file format.",
        "r''' Test the"
    ],
    [
        ">>> for arr in basic_arrays + record_arrays:",
        ">>> for arr in basic_arrays"
    ],
    [
        "for arr in basic_arrays + record_arrays:",
        "for arr in basic_arrays"
    ],
    [
        "for arr in basic_arrays + record_arrays:",
        "for arr in basic_arrays +"
    ],
    [
        "for i, arr in enumerate(basic_arrays + record_arrays):",
        "for i, arr in enumerate(basic_arrays"
    ],
    [
        "@pytest.mark.xfail(IS_WASM, reason=\"Emscripten NODEFS has a buggy dup\")",
        "@pytest.mark.xfail(IS_WASM, reason=\"Emscripten NODEFS has a"
    ],
    [
        "for magic in bad_version_magic + malformed_magic:",
        "for magic in bad_version_magic"
    ],
    [
        "pytest.skip(\"Unknown if Windows has sparse filesystems\")",
        "pytest.skip(\"Unknown if Windows"
    ],
    [
        "for is_fortran_array, dtype_space, expected_header_length in [",
        "for is_fortran_array, dtype_space,"
    ],
    [
        "'descr': np.dtype([(' ' * dtype_space, int)])",
        "'descr': np.dtype([(' ' * dtype_space,"
    ],
    [
        "float, np.dtype({'names': ['c'], 'formats': [np.dtype(int, metadata={})]})",
        "float, np.dtype({'names': ['c'],"
    ],
    [
        "from numpy import histogram, histogramdd, histogram_bin_edges",
        "from numpy import"
    ],
    [
        "a, b = histogram(v, bins, density=True)",
        "a, b = histogram(v,"
    ],
    [
        "a, b = histogram(v, bins, density=False)",
        "a, b = histogram(v, bins,"
    ],
    [
        "a, b = histogram(v, bins, density=True)",
        "a, b = histogram(v,"
    ],
    [
        "rec = sup.record(RuntimeWarning, 'Converting input from .*')",
        "rec = sup.record(RuntimeWarning, 'Converting"
    ],
    [
        "hist, edges = np.histogram([True, True, False])",
        "hist, edges = np.histogram([True,"
    ],
    [
        "nwa, nwb = histogram(v, weights=w, density=True)",
        "nwa, nwb = histogram(v, weights=w,"
    ],
    [
        "with assert_raises_regex(ValueError, \"max must be larger than\"):",
        "with assert_raises_regex(ValueError, \"max must"
    ],
    [
        "for x, left, right in zip(arr, left_edges, right_edges):",
        "for x, left, right in zip(arr, left_edges,"
    ],
    [
        "with pytest.raises(ValueError, match=\"Too many bins for data range\"):",
        "with pytest.raises(ValueError, match=\"Too many bins"
    ],
    [
        "@pytest.mark.skip(reason=\"Bad memory reports lead to OOM in ci testing\")",
        "@pytest.mark.skip(reason=\"Bad memory reports lead to"
    ],
    [
        "hist = np.histogramdd(sample=sample, bins=(xbins, ybins, zbins))",
        "hist = np.histogramdd(sample=sample,"
    ],
    [
        "Provide test coverage when using provided estimators for optimal number of",
        "Provide test coverage when using provided estimators for"
    ],
    [
        "estimator_list = ['fd', 'scott', 'rice', 'sturges',",
        "estimator_list = ['fd', 'scott',"
    ],
    [
        "Straightforward testing with a mixture of linspace data (for",
        "Straightforward testing with a mixture of linspace"
    ],
    [
        "consistency). All test values have been precomputed and the values",
        "consistency). All test values have been"
    ],
    [
        "Smaller datasets have the potential to cause issues with the data",
        "Smaller datasets have the potential to cause issues with the"
    ],
    [
        "adaptive methods, especially the FD method. All bin numbers have been",
        "adaptive methods, especially the FD method. All bin"
    ],
    [
        "Check a Value Error is thrown when an unknown string is passed in",
        "Check a Value Error is thrown when an unknown string is"
    ],
    [
        "check_list = ['mad', 'freeman', 'histograms', 'IQR']",
        "check_list = ['mad', 'freeman', 'histograms',"
    ],
    [
        "Check that methods handle no variance in data",
        "Check that methods handle no"
    ],
    [
        "Check the FD, Scott and Doane with outliers.",
        "Check the FD, Scott and Doane"
    ],
    [
        "The FD estimates a smaller binwidth since it's less affected by",
        "The FD estimates a smaller binwidth since"
    ],
    [
        "outliers. Since the range is so (artificially) large, this means more",
        "outliers. Since the range is so (artificially) large, this"
    ],
    [
        "bins, most of which will be empty, but the data of interest usually is",
        "bins, most of which will be empty, but the data"
    ],
    [
        "unaffected. The Scott estimator is more affected and returns fewer bins,",
        "unaffected. The Scott estimator is more"
    ],
    [
        "despite most of the variance being in one area of the data. The Doane",
        "despite most of the variance being in one area of the"
    ],
    [
        "estimator lies somewhere between the other two.",
        "estimator lies somewhere between"
    ],
    [
        "\"\"\"Verify that Scott's rule and Stone's rule converges for normally distributed data\"\"\"",
        "\"\"\"Verify that Scott's rule and Stone's rule"
    ],
    [
        "return a / (a + b)",
        "return a / (a +"
    ],
    [
        "Straightforward testing with a mixture of linspace data (for",
        "Straightforward testing with a mixture"
    ],
    [
        "completely ignored. All test values have been precomputed and",
        "completely ignored. All test values have been"
    ],
    [
        "Check that weighted data raises a TypeError",
        "Check that weighted data raises"
    ],
    [
        "estimator_list = ['fd', 'scott', 'rice', 'sturges', 'auto']",
        "estimator_list = ['fd', 'scott',"
    ],
    [
        "H, edges = histogramdd(x, bins=ed, density=True)",
        "H, edges = histogramdd(x,"
    ],
    [
        "\"\"\" Test that adjacent entries in an edge array can be equal \"\"\"",
        "\"\"\" Test that adjacent entries in an edge array can be equal"
    ],
    [
        "hist, edges = histogramdd((x, y), bins=(x_edges, y_edges))",
        "hist, edges = histogramdd((x, y),"
    ],
    [
        "\"\"\" Test that if an edge array is input, its type is preserved \"\"\"",
        "\"\"\" Test that if an edge array"
    ],
    [
        "hist, edges = histogramdd((x, y), bins=(x_edges, y_edges))",
        "hist, edges = histogramdd((x, y),"
    ],
    [
        "hist, edges = histogramdd((x, y), bins=(x_edges, y_edges))",
        "hist, edges = histogramdd((x, y), bins=(x_edges,"
    ],
    [
        "hist, edges = histogramdd((y, x), bins=(y_edges, x_edges))",
        "hist, edges = histogramdd((y, x), bins=(y_edges,"
    ],
    [
        "hist, edges = histogramdd((y, x), bins=(y_edges, x_edges), density=True)",
        "hist, edges = histogramdd((y, x),"
    ],
    [
        "hist, edges = histogram(v, bins, density=True)",
        "hist, edges = histogram(v, bins,"
    ],
    [
        "hist_dd, edges_dd = histogramdd((v,), (bins,), density=True)",
        "hist_dd, edges_dd = histogramdd((v,), (bins,),"
    ],
    [
        "assert_equal(q * v + r, u)",
        "assert_equal(q * v +"
    ],
    [
        "msg = \"Wrong type, should be complex\"",
        "msg = \"Wrong type,"
    ],
    [
        "msg = \"Wrong type, should be float\"",
        "msg = \"Wrong type,"
    ],
    [
        "msg = \"Wrong type, should be complex\"",
        "msg = \"Wrong type, should"
    ],
    [
        "msg = \"Wrong type, should be float\"",
        "msg = \"Wrong type, should be"
    ],
    [
        "from numpy._core import integer, empty, arange, asarray, roll",
        "from numpy._core import integer,"
    ],
    [
        "__all__ = ['fftshift', 'ifftshift', 'fftfreq', 'rfftfreq']",
        "__all__ = ['fftshift', 'ifftshift', 'fftfreq',"
    ],
    [
        "Shift the zero-frequency component to the center of the spectrum.",
        "Shift the zero-frequency component to the center"
    ],
    [
        "This function swaps half-spaces for all axes listed (defaults to all).",
        "This function swaps half-spaces for all axes listed (defaults to"
    ],
    [
        "axes : int or shape tuple, optional",
        "axes : int or shape tuple,"
    ],
    [
        "Axes over which to shift.  Default is None, which shifts all axes.",
        "Axes over which to shift. Default is"
    ],
    [
        "ifftshift : The inverse of `fftshift`.",
        "ifftshift : The"
    ],
    [
        "Shift the zero-frequency component only along the second axis:",
        "Shift the zero-frequency component only along the second"
    ],
    [
        "The inverse of `fftshift`. Although identical for even-length `x`, the",
        "The inverse of `fftshift`. Although identical for even-length `x`,"
    ],
    [
        "functions differ by one sample for odd-length `x`.",
        "functions differ by one sample for odd-length"
    ],
    [
        "axes : int or shape tuple, optional",
        "axes : int or shape tuple,"
    ],
    [
        "Axes over which to calculate.  Defaults to None, which shifts all axes.",
        "Axes over which to calculate. Defaults to"
    ],
    [
        "fftshift : Shift zero-frequency component to the center of the spectrum.",
        "fftshift : Shift zero-frequency component to the"
    ],
    [
        "Return the Discrete Fourier Transform sample frequencies.",
        "Return the Discrete Fourier Transform sample"
    ],
    [
        "The returned float array `f` contains the frequency bin centers in cycles",
        "The returned float array `f` contains the frequency"
    ],
    [
        "per unit of the sample spacing (with zero at the start).  For instance, if",
        "per unit of the sample spacing (with zero at the start). For instance,"
    ],
    [
        "the sample spacing is in seconds, then the frequency unit is cycles/second.",
        "the sample spacing is in seconds, then the frequency"
    ],
    [
        "Given a window length `n` and a sample spacing `d`::",
        "Given a window length `n`"
    ],
    [
        "The device on which to place the created array. Default: ``None``.",
        "The device on which to place the created array."
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be ``\"cpu\"``"
    ],
    [
        "Array of length `n` containing the sample frequencies.",
        "Array of length `n` containing"
    ],
    [
        "raise ValueError(\"n should be an integer\")",
        "raise ValueError(\"n should"
    ],
    [
        "Return the Discrete Fourier Transform sample frequencies",
        "Return the Discrete Fourier Transform"
    ],
    [
        "The returned float array `f` contains the frequency bin centers in cycles",
        "The returned float array `f` contains the"
    ],
    [
        "per unit of the sample spacing (with zero at the start).  For instance, if",
        "per unit of the sample spacing (with"
    ],
    [
        "the sample spacing is in seconds, then the frequency unit is cycles/second.",
        "the sample spacing is in seconds, then the"
    ],
    [
        "Given a window length `n` and a sample spacing `d`::",
        "Given a window length `n` and a"
    ],
    [
        "the Nyquist frequency component is considered to be positive.",
        "the Nyquist frequency component is considered to be"
    ],
    [
        "The device on which to place the created array. Default: ``None``.",
        "The device on which to place the created array."
    ],
    [
        "For Array-API interoperability only, so must be ``\"cpu\"`` if passed.",
        "For Array-API interoperability only, so must be"
    ],
    [
        "raise ValueError(\"n should be an integer\")",
        "raise ValueError(\"n should be"
    ],
    [
        "The SciPy module `scipy.fft` is a more comprehensive superset",
        "The SciPy module `scipy.fft` is a"
    ],
    [
        "of ``numpy.fft``, which includes only a basic set of routines.",
        "of ``numpy.fft``, which includes only a basic"
    ],
    [
        "fftn      Discrete Fourier transform in N-dimensions.",
        "fftn Discrete Fourier"
    ],
    [
        "ifftn     Inverse discrete Fourier transform in N dimensions.",
        "ifftn Inverse discrete Fourier transform in N"
    ],
    [
        "irfft     Inverse real discrete Fourier transform.",
        "irfft Inverse real"
    ],
    [
        "rfftn     Real discrete Fourier transform in N dimensions.",
        "rfftn Real discrete Fourier transform in N"
    ],
    [
        "irfftn    Inverse real discrete Fourier transform in N dimensions.",
        "irfftn Inverse real discrete Fourier transform in N"
    ],
    [
        "ihfft     Inverse Hermitian discrete Fourier transform.",
        "ihfft Inverse Hermitian discrete"
    ],
    [
        "fftfreq   Discrete Fourier Transform sample frequencies.",
        "fftfreq Discrete Fourier Transform"
    ],
    [
        "rfftfreq  DFT sample frequencies (for usage with rfft, irfft).",
        "rfftfreq DFT sample frequencies (for usage with rfft,"
    ],
    [
        "fftshift  Shift zero-frequency component to center of spectrum.",
        "fftshift Shift zero-frequency component to center of"
    ],
    [
        "Fourier analysis is fundamentally a method for expressing a function as a",
        "Fourier analysis is fundamentally a method for"
    ],
    [
        "sum of periodic components, and for recovering the function from those",
        "sum of periodic components, and for recovering the"
    ],
    [
        "components.  When both the function and its Fourier transform are",
        "components. When both the function and its"
    ],
    [
        "replaced with discretized counterparts, it is called the discrete Fourier",
        "replaced with discretized counterparts, it is called"
    ],
    [
        "transform (DFT).  The DFT has become a mainstay of numerical computing in",
        "transform (DFT). The DFT has become a mainstay of numerical"
    ],
    [
        "part because of a very fast algorithm for computing it, called the Fast",
        "part because of a very fast algorithm for computing it, called"
    ],
    [
        "to light in its current form by Cooley and Tukey [CT]_.  Press et al. [NR]_",
        "to light in its current form by Cooley and Tukey [CT]_. Press"
    ],
    [
        "provide an accessible introduction to Fourier analysis and its",
        "provide an accessible introduction to Fourier"
    ],
    [
        "Because the discrete Fourier transform separates its input into",
        "Because the discrete Fourier transform separates its"
    ],
    [
        "components that contribute at discrete frequencies, it has a great number",
        "components that contribute at discrete frequencies,"
    ],
    [
        "of applications in digital signal processing, e.g., for filtering, and in",
        "of applications in digital signal processing, e.g., for filtering, and"
    ],
    [
        "this context the discretized input to the transform is customarily",
        "this context the discretized input to the"
    ],
    [
        "referred to as a *signal*, which exists in the *time domain*.  The output",
        "referred to as a *signal*, which exists"
    ],
    [
        "is called a *spectrum* or *transform* and exists in the *frequency",
        "is called a *spectrum* or *transform* and"
    ],
    [
        "There are many ways to define the DFT, varying in the sign of the",
        "There are many ways to define the DFT, varying in"
    ],
    [
        "exponent, normalization, etc.  In this implementation, the DFT is defined",
        "exponent, normalization, etc. In this implementation,"
    ],
    [
        "The DFT is in general defined for complex inputs and outputs, and a",
        "The DFT is in general defined for complex inputs"
    ],
    [
        "single-frequency component at linear frequency :math:`f` is",
        "single-frequency component at linear frequency"
    ],
    [
        "The values in the result follow so-called \"standard\" order: If ``A =",
        "The values in the result follow so-called \"standard\""
    ],
    [
        "negative-frequency terms, in order of decreasingly negative frequency.",
        "negative-frequency terms, in order of"
    ],
    [
        "negative Nyquist frequency, and is also purely real for real input.  For",
        "negative Nyquist frequency, and is also purely real for real input."
    ],
    [
        "The routine ``np.fft.fftfreq(n)`` returns an array giving the frequencies",
        "The routine ``np.fft.fftfreq(n)`` returns an"
    ],
    [
        "of corresponding elements in the output.  The routine",
        "of corresponding elements in the output."
    ],
    [
        "``np.fft.fftshift(A)`` shifts transforms and their frequencies to put the",
        "``np.fft.fftshift(A)`` shifts transforms and their frequencies to"
    ],
    [
        "zero-frequency components in the middle, and ``np.fft.ifftshift(A)`` undoes",
        "zero-frequency components in the middle, and ``np.fft.ifftshift(A)``"
    ],
    [
        "When the input `a` is a time-domain signal and ``A = fft(a)``, ``np.abs(A)``",
        "When the input `a` is a time-domain signal"
    ],
    [
        "The phase spectrum is obtained by ``np.angle(A)``.",
        "The phase spectrum is obtained by"
    ],
    [
        "The inverse DFT is defined as",
        "The inverse DFT is defined"
    ],
    [
        "It differs from the forward transform by the sign of the exponential",
        "It differs from the forward transform by the sign of"
    ],
    [
        "The argument ``norm`` indicates which direction of the pair of direct/inverse",
        "The argument ``norm`` indicates which direction"
    ],
    [
        "transforms is scaled and with what normalization factor.",
        "transforms is scaled and with what"
    ],
    [
        "The default normalization (``\"backward\"``) has the direct (forward) transforms",
        "The default normalization (``\"backward\"``) has the direct"
    ],
    [
        "possible to obtain unitary transforms by setting the keyword argument ``norm``",
        "possible to obtain unitary transforms by setting the keyword argument"
    ],
    [
        "to ``\"ortho\"`` so that both direct and inverse transforms are scaled by",
        "to ``\"ortho\"`` so that both direct and inverse transforms are"
    ],
    [
        "transforms unscaled (i.e. exactly opposite to the default ``\"backward\"``).",
        "transforms unscaled (i.e. exactly opposite to the"
    ],
    [
        "`None` is an alias of the default option ``\"backward\"`` for backward",
        "`None` is an alias of the default"
    ],
    [
        "When the input is purely real, its transform is Hermitian, i.e., the",
        "When the input is purely real,"
    ],
    [
        "component at frequency :math:`f_k` is the complex conjugate of the",
        "component at frequency :math:`f_k` is the complex"
    ],
    [
        "component at frequency :math:`-f_k`, which means that for real",
        "component at frequency :math:`-f_k`, which means that"
    ],
    [
        "inputs there is no information in the negative frequency components that",
        "inputs there is no information in the"
    ],
    [
        "is not already available from the positive frequency components.",
        "is not already available from the positive"
    ],
    [
        "The family of `rfft` functions is",
        "The family of"
    ],
    [
        "designed to operate on real inputs, and exploits this symmetry by",
        "designed to operate on real inputs, and exploits this"
    ],
    [
        "computing only the positive frequency components, up to and including the",
        "computing only the positive frequency components, up to and"
    ],
    [
        "output points.  The inverses of this family assumes the same symmetry of",
        "output points. The inverses of this"
    ],
    [
        "Correspondingly, when the spectrum is purely real, the signal is",
        "Correspondingly, when the spectrum is purely real,"
    ],
    [
        "Hermitian.  The `hfft` family of functions exploits this symmetry by",
        "Hermitian. The `hfft` family of"
    ],
    [
        "In higher dimensions, FFTs are used, e.g., for image analysis and",
        "In higher dimensions, FFTs are used, e.g., for image analysis"
    ],
    [
        "filtering.  The computational efficiency of the FFT means that it can",
        "filtering. The computational efficiency of the FFT"
    ],
    [
        "also be a faster way to compute large convolutions, using the property",
        "also be a faster way to compute large convolutions, using the"
    ],
    [
        "that a convolution in the time domain is equivalent to a point-by-point",
        "that a convolution in the time domain"
    ],
    [
        "In two dimensions, the DFT is defined as",
        "In two dimensions, the DFT is"
    ],
    [
        "which extends in the obvious way to higher dimensions, and the inverses",
        "which extends in the obvious way"
    ],
    [
        "in higher dimensions also extend in the same way.",
        "in higher dimensions also extend in the same"
    ],
    [
        "machine calculation of complex Fourier series,\" *Math. Comput.*",
        "machine calculation of complex"
    ],
    [
        ".. [NR] Press, W., Teukolsky, S., Vetterline, W.T., and Flannery, B.P.,",
        ".. [NR] Press, W., Teukolsky, S., Vetterline, W.T., and"
    ],
    [
        "For examples, see the various functions.",
        "For examples, see"
    ],
    [
        "f\"module 'numpy.fft.helper' has no attribute {attr_name}\")",
        "f\"module 'numpy.fft.helper' has"
    ],
    [
        "\"The numpy.fft.helper has been made private and renamed to \"",
        "\"The numpy.fft.helper has been made private and renamed to"
    ],
    [
        "\"numpy.fft._helper. All four functions exported by it (i.e. fftshift, \"",
        "\"numpy.fft._helper. All four functions exported"
    ],
    [
        "\"ifftshift, fftfreq, rfftfreq) are available from numpy.fft. \"",
        "\"ifftshift, fftfreq, rfftfreq) are available from"
    ],
    [
        "r = transform of purely real data",
        "r = transform of purely"
    ],
    [
        "__all__ = ['fft', 'ifft', 'rfft', 'irfft', 'hfft', 'ihfft', 'rfftn',",
        "__all__ = ['fft', 'ifft', 'rfft', 'irfft', 'hfft', 'ihfft',"
    ],
    [
        "from numpy._core import (asarray, empty_like, result_type,",
        "from numpy._core import (asarray,"
    ],
    [
        "from . import _pocketfft_umath as pfu",
        "from . import _pocketfft_umath"
    ],
    [
        "def _raw_fft(a, n, axis, is_real, is_forward, norm, out=None):",
        "def _raw_fft(a, n, axis, is_real, is_forward, norm,"
    ],
    [
        "raise ValueError(f\"Invalid number of FFT data points ({n}) specified.\")",
        "raise ValueError(f\"Invalid number of FFT data points ({n})"
    ],
    [
        "if norm is None or norm == \"backward\":",
        "if norm is None or norm"
    ],
    [
        "raise ValueError(f'Invalid norm value {norm}; should be \"backward\",'",
        "raise ValueError(f'Invalid norm value"
    ],
    [
        "ufunc = pfu.fft if is_forward else pfu.ifft",
        "ufunc = pfu.fft if is_forward else"
    ],
    [
        "elif ((shape := getattr(out, \"shape\", None)) is not None",
        "elif ((shape := getattr(out, \"shape\", None))"
    ],
    [
        "and (len(shape) != a.ndim or shape[axis] != n_out)):",
        "and (len(shape) != a.ndim or"
    ],
    [
        "raise ValueError(\"output array has wrong shape.\")",
        "raise ValueError(\"output array"
    ],
    [
        "return ufunc(a, fct, axes=[(axis,), (), (axis,)], out=out)",
        "return ufunc(a, fct, axes=[(axis,), (),"
    ],
    [
        "_SWAP_DIRECTION_MAP = {\"backward\": \"forward\", None: \"forward\",",
        "_SWAP_DIRECTION_MAP = {\"backward\":"
    ],
    [
        "raise ValueError(f'Invalid norm value {norm}; should be \"backward\", '",
        "raise ValueError(f'Invalid norm value {norm}; should be"
    ],
    [
        "def _fft_dispatcher(a, n=None, axis=None, norm=None, out=None):",
        "def _fft_dispatcher(a, n=None, axis=None, norm=None,"
    ],
    [
        "Compute the one-dimensional discrete Fourier Transform.",
        "Compute the one-dimensional"
    ],
    [
        "This function computes the one-dimensional *n*-point discrete Fourier",
        "This function computes the one-dimensional *n*-point discrete"
    ],
    [
        "Transform (DFT) with the efficient Fast Fourier Transform (FFT)",
        "Transform (DFT) with the efficient"
    ],
    [
        "Length of the transformed axis of the output.",
        "Length of the transformed axis of"
    ],
    [
        "If `n` is smaller than the length of the input, the input is cropped.",
        "If `n` is smaller than the length of the input, the input is"
    ],
    [
        "If it is larger, the input is padded with zeros.  If `n` is not given,",
        "If it is larger, the input is padded with zeros. If"
    ],
    [
        "the length of the input along the axis specified by `axis` is used.",
        "the length of the input along the axis specified by"
    ],
    [
        "Axis over which to compute the FFT.  If not given, the last axis is",
        "Axis over which to compute the FFT. If"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`). Default is"
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in this array. It should"
    ],
    [
        "of the appropriate shape and dtype.",
        "of the appropriate shape"
    ],
    [
        "The truncated or zero-padded input, transformed along the axis",
        "The truncated or zero-padded input, transformed along"
    ],
    [
        "indicated by `axis`, or the last one if `axis` is not specified.",
        "indicated by `axis`, or the last"
    ],
    [
        "If `axis` is not a valid axis of `a`.",
        "If `axis` is not a valid axis"
    ],
    [
        "numpy.fft : for definition of the DFT and conventions used.",
        "numpy.fft : for definition of the"
    ],
    [
        "ifft : The inverse of `fft`.",
        "ifft : The"
    ],
    [
        "rfftn : The *n*-dimensional FFT of real input.",
        "rfftn : The *n*-dimensional FFT of real"
    ],
    [
        "fftfreq : Frequency bins for given FFT parameters.",
        "fftfreq : Frequency bins for given"
    ],
    [
        "FFT (Fast Fourier Transform) refers to a way the discrete Fourier",
        "FFT (Fast Fourier Transform) refers to a way"
    ],
    [
        "Transform (DFT) can be calculated efficiently, by using symmetries in the",
        "Transform (DFT) can be calculated efficiently, by using"
    ],
    [
        "the transform is therefore most efficient for these sizes.",
        "the transform is therefore most efficient for these"
    ],
    [
        "The DFT is defined, with the conventions used in this implementation, in",
        "The DFT is defined, with the conventions"
    ],
    [
        "the documentation for the `numpy.fft` module.",
        "the documentation for"
    ],
    [
        "machine calculation of complex Fourier series,\" *Math. Comput.*",
        "machine calculation of complex"
    ],
    [
        "In this example, real input has an FFT which is Hermitian, i.e., symmetric",
        "In this example, real input has an"
    ],
    [
        "in the real part and anti-symmetric in the imaginary part, as described in",
        "in the real part and anti-symmetric in the imaginary part, as described"
    ],
    [
        "output = _raw_fft(a, n, axis, False, True, norm, out)",
        "output = _raw_fft(a, n, axis, False, True, norm,"
    ],
    [
        "Compute the one-dimensional inverse discrete Fourier Transform.",
        "Compute the one-dimensional inverse discrete"
    ],
    [
        "This function computes the inverse of the one-dimensional *n*-point",
        "This function computes the inverse of"
    ],
    [
        "discrete Fourier transform computed by `fft`.  In other words,",
        "discrete Fourier transform computed by `fft`."
    ],
    [
        "``ifft(fft(a)) == a`` to within numerical accuracy.",
        "``ifft(fft(a)) == a`` to within numerical"
    ],
    [
        "For a general description of the algorithm and definitions,",
        "For a general description of the"
    ],
    [
        "The input should be ordered in the same way as is returned by `fft`,",
        "The input should be ordered in the same way"
    ],
    [
        "increasing order starting from the most negative frequency.",
        "increasing order starting from"
    ],
    [
        "the values at the positive and negative Nyquist frequencies, as the two",
        "the values at the positive and negative Nyquist"
    ],
    [
        "are aliased together. See `numpy.fft` for details.",
        "are aliased together. See `numpy.fft`"
    ],
    [
        "Length of the transformed axis of the output.",
        "Length of the transformed"
    ],
    [
        "If `n` is smaller than the length of the input, the input is cropped.",
        "If `n` is smaller than the length of the input,"
    ],
    [
        "If it is larger, the input is padded with zeros.  If `n` is not given,",
        "If it is larger, the input is padded with zeros. If `n` is not"
    ],
    [
        "the length of the input along the axis specified by `axis` is used.",
        "the length of the input along the axis specified by `axis` is"
    ],
    [
        "Axis over which to compute the inverse DFT.  If not given, the last",
        "Axis over which to compute the inverse"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`). Default"
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values were"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in this array. It"
    ],
    [
        "of the appropriate shape and dtype.",
        "of the appropriate shape"
    ],
    [
        "The truncated or zero-padded input, transformed along the axis",
        "The truncated or zero-padded input,"
    ],
    [
        "indicated by `axis`, or the last one if `axis` is not specified.",
        "indicated by `axis`, or the last one"
    ],
    [
        "If `axis` is not a valid axis of `a`.",
        "If `axis` is not a valid"
    ],
    [
        "numpy.fft : An introduction, with definitions and general explanations.",
        "numpy.fft : An introduction, with"
    ],
    [
        "fft : The one-dimensional (forward) FFT, of which `ifft` is the inverse",
        "fft : The one-dimensional (forward) FFT, of which `ifft` is the"
    ],
    [
        "ifftn : The n-dimensional inverse FFT.",
        "ifftn : The n-dimensional"
    ],
    [
        "If the input parameter `n` is larger than the size of the input, the input",
        "If the input parameter `n` is larger than the size of the input, the"
    ],
    [
        "is padded by appending zeros at the end.  Even though this is the common",
        "is padded by appending zeros at the"
    ],
    [
        "approach, it might lead to surprising results.  If a different padding is",
        "approach, it might lead to surprising results. If a"
    ],
    [
        "desired, it must be performed before calling `ifft`.",
        "desired, it must be"
    ],
    [
        "Create and plot a band-limited signal with random phases:",
        "Create and plot a band-limited signal with random"
    ],
    [
        "output = _raw_fft(a, n, axis, False, False, norm, out=out)",
        "output = _raw_fft(a, n, axis,"
    ],
    [
        "Compute the one-dimensional discrete Fourier Transform for real input.",
        "Compute the one-dimensional discrete Fourier Transform for"
    ],
    [
        "This function computes the one-dimensional *n*-point discrete Fourier",
        "This function computes the one-dimensional *n*-point discrete"
    ],
    [
        "Transform (DFT) of a real-valued array by means of an efficient algorithm",
        "Transform (DFT) of a real-valued array by means of an efficient"
    ],
    [
        "called the Fast Fourier Transform (FFT).",
        "called the Fast"
    ],
    [
        "Number of points along transformation axis in the input to use.",
        "Number of points along transformation axis in"
    ],
    [
        "If `n` is smaller than the length of the input, the input is cropped.",
        "If `n` is smaller than the length of the input, the input is"
    ],
    [
        "If it is larger, the input is padded with zeros. If `n` is not given,",
        "If it is larger, the input is padded with"
    ],
    [
        "the length of the input along the axis specified by `axis` is used.",
        "the length of the input along the axis specified by `axis` is"
    ],
    [
        "Axis over which to compute the FFT. If not given, the last axis is",
        "Axis over which to compute the FFT. If not"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\", \"ortho\", \"forward\"},"
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`). Default"
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values were"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in this array."
    ],
    [
        "of the appropriate shape and dtype.",
        "of the appropriate"
    ],
    [
        "The truncated or zero-padded input, transformed along the axis",
        "The truncated or zero-padded input, transformed along"
    ],
    [
        "indicated by `axis`, or the last one if `axis` is not specified.",
        "indicated by `axis`, or the last one if `axis` is"
    ],
    [
        "If `axis` is not a valid axis of `a`.",
        "If `axis` is not a"
    ],
    [
        "numpy.fft : For definition of the DFT and conventions used.",
        "numpy.fft : For definition of the DFT"
    ],
    [
        "irfft : The inverse of `rfft`.",
        "irfft : The inverse of"
    ],
    [
        "fft : The one-dimensional FFT of general (complex) input.",
        "fft : The one-dimensional FFT of general"
    ],
    [
        "rfftn : The *n*-dimensional FFT of real input.",
        "rfftn : The *n*-dimensional FFT of"
    ],
    [
        "When the DFT is computed for purely real input, the output is",
        "When the DFT is computed for"
    ],
    [
        "Hermitian-symmetric, i.e. the negative frequency terms are just the complex",
        "Hermitian-symmetric, i.e. the negative frequency terms are just"
    ],
    [
        "conjugates of the corresponding positive-frequency terms, and the",
        "conjugates of the corresponding positive-frequency"
    ],
    [
        "negative-frequency terms are therefore redundant.  This function does not",
        "negative-frequency terms are therefore redundant. This function"
    ],
    [
        "compute the negative frequency terms, and the length of the transformed",
        "compute the negative frequency terms, and"
    ],
    [
        "If the input `a` contains an imaginary part, it is silently discarded.",
        "If the input `a` contains an imaginary part, it"
    ],
    [
        "Notice how the final element of the `fft` output is the complex conjugate",
        "Notice how the final element of the"
    ],
    [
        "of the second element, for real input. For `rfft`, this symmetry is",
        "of the second element, for real input. For"
    ],
    [
        "exploited to compute only the non-negative frequency terms.",
        "exploited to compute only the non-negative frequency"
    ],
    [
        "output = _raw_fft(a, n, axis, True, True, norm, out=out)",
        "output = _raw_fft(a, n, axis, True, True,"
    ],
    [
        "This function computes the inverse of the one-dimensional *n*-point",
        "This function computes the inverse of the"
    ],
    [
        "discrete Fourier Transform of real input computed by `rfft`.",
        "discrete Fourier Transform of real input computed"
    ],
    [
        "In other words, ``irfft(rfft(a), len(a)) == a`` to within numerical",
        "In other words, ``irfft(rfft(a), len(a)) == a`` to"
    ],
    [
        "accuracy. (See Notes below for why ``len(a)`` is necessary here.)",
        "accuracy. (See Notes below for why ``len(a)`` is"
    ],
    [
        "The input is expected to be in the form returned by `rfft`, i.e. the",
        "The input is expected to be in the form returned by"
    ],
    [
        "real zero-frequency term followed by the complex positive frequency terms",
        "real zero-frequency term followed by the"
    ],
    [
        "in order of increasing frequency.  Since the discrete Fourier Transform of",
        "in order of increasing frequency. Since the discrete Fourier"
    ],
    [
        "real input is Hermitian-symmetric, the negative frequency terms are taken",
        "real input is Hermitian-symmetric, the negative frequency terms are"
    ],
    [
        "to be the complex conjugates of the corresponding positive frequency terms.",
        "to be the complex conjugates of the corresponding"
    ],
    [
        "Length of the transformed axis of the output.",
        "Length of the transformed axis"
    ],
    [
        "input is longer than this, it is cropped.  If it is shorter than this,",
        "input is longer than this, it is cropped. If it is shorter"
    ],
    [
        "it is padded with zeros.  If `n` is not given, it is taken to be",
        "it is padded with zeros. If `n` is not"
    ],
    [
        "Axis over which to compute the inverse FFT. If not given, the last",
        "Axis over which to compute the inverse FFT. If not given, the"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\", \"ortho\", \"forward\"},"
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`)."
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the forward/backward"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed"
    ],
    [
        "of the appropriate shape and dtype.",
        "of the appropriate"
    ],
    [
        "The truncated or zero-padded input, transformed along the axis",
        "The truncated or zero-padded input, transformed along the"
    ],
    [
        "indicated by `axis`, or the last one if `axis` is not specified.",
        "indicated by `axis`, or the last one"
    ],
    [
        "The length of the transformed axis is `n`, or, if `n` is not given,",
        "The length of the transformed axis is `n`, or, if"
    ],
    [
        "input. To get an odd number of output points, `n` must be specified.",
        "input. To get an odd number of output"
    ],
    [
        "If `axis` is not a valid axis of `a`.",
        "If `axis` is not a valid"
    ],
    [
        "numpy.fft : For definition of the DFT and conventions used.",
        "numpy.fft : For definition of the DFT and conventions"
    ],
    [
        "rfft : The one-dimensional FFT of real input, of which `irfft` is inverse.",
        "rfft : The one-dimensional FFT of real input, of which"
    ],
    [
        "irfftn : The inverse of the *n*-dimensional FFT of real input.",
        "irfftn : The inverse of the *n*-dimensional FFT of real"
    ],
    [
        "Returns the real valued `n`-point inverse discrete Fourier transform",
        "Returns the real valued `n`-point inverse"
    ],
    [
        "of `a`, where `a` contains the non-negative frequency terms of a",
        "of `a`, where `a` contains the non-negative"
    ],
    [
        "Hermitian-symmetric sequence. `n` is the length of the result, not the",
        "Hermitian-symmetric sequence. `n` is the length of the result,"
    ],
    [
        "If you specify an `n` such that `a` must be zero-padded or truncated, the",
        "If you specify an `n` such that"
    ],
    [
        "extra/removed values will be added/removed at high frequencies. One can",
        "extra/removed values will be added/removed at high frequencies. One"
    ],
    [
        "thus resample a series to `m` points via Fourier interpolation by:",
        "thus resample a series to `m` points via Fourier interpolation"
    ],
    [
        "The correct interpretation of the hermitian input depends on the length of",
        "The correct interpretation of the hermitian input depends on the"
    ],
    [
        "the original data, as given by `n`. This is because each input shape could",
        "the original data, as given by `n`. This is because each input"
    ],
    [
        "correspond to either an odd or even length signal. By default, `irfft`",
        "correspond to either an odd or even length signal. By default,"
    ],
    [
        "assumes an even output length which puts the last entry at the Nyquist",
        "assumes an even output length which puts the last"
    ],
    [
        "frequency; aliasing with its symmetric counterpart. By Hermitian symmetry,",
        "frequency; aliasing with its symmetric counterpart. By Hermitian"
    ],
    [
        "the value is thus treated as purely real. To avoid losing information, the",
        "the value is thus treated as purely real. To avoid"
    ],
    [
        "correct length of the real input **must** be given.",
        "correct length of the real input **must**"
    ],
    [
        "Notice how the last term in the input to the ordinary `ifft` is the",
        "Notice how the last term in the input to the ordinary `ifft` is"
    ],
    [
        "complex conjugate of the second term, and the output has zero imaginary",
        "complex conjugate of the second term, and"
    ],
    [
        "part everywhere.  When calling `irfft`, the negative frequencies are not",
        "part everywhere. When calling `irfft`,"
    ],
    [
        "specified, and the output array is purely real.",
        "specified, and the output array"
    ],
    [
        "output = _raw_fft(a, n, axis, True, False, norm, out=out)",
        "output = _raw_fft(a, n, axis, True, False, norm,"
    ],
    [
        "Compute the FFT of a signal that has Hermitian symmetry, i.e., a real",
        "Compute the FFT of a signal that has"
    ],
    [
        "Length of the transformed axis of the output. For `n` output",
        "Length of the transformed axis of the output. For `n`"
    ],
    [
        "longer than this, it is cropped.  If it is shorter than this, it is",
        "longer than this, it is cropped. If it is shorter than this, it"
    ],
    [
        "where ``m`` is the length of the input along the axis specified by",
        "where ``m`` is the length of the input along"
    ],
    [
        "Axis over which to compute the FFT. If not given, the last",
        "Axis over which to compute the FFT. If not given,"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`)."
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the forward/backward"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what normalization"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values were"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed"
    ],
    [
        "of the appropriate shape and dtype.",
        "of the appropriate"
    ],
    [
        "The truncated or zero-padded input, transformed along the axis",
        "The truncated or zero-padded input,"
    ],
    [
        "indicated by `axis`, or the last one if `axis` is not specified.",
        "indicated by `axis`, or the last one if `axis` is"
    ],
    [
        "The length of the transformed axis is `n`, or, if `n` is not given,",
        "The length of the transformed axis is"
    ],
    [
        "the input. To get an odd number of output points, `n` must be",
        "the input. To get an odd number"
    ],
    [
        "If `axis` is not a valid axis of `a`.",
        "If `axis` is not a valid axis of"
    ],
    [
        "rfft : Compute the one-dimensional FFT for real input.",
        "rfft : Compute the one-dimensional FFT"
    ],
    [
        "ihfft : The inverse of `hfft`.",
        "ihfft : The inverse"
    ],
    [
        "`hfft`/`ihfft` are a pair analogous to `rfft`/`irfft`, but for the",
        "`hfft`/`ihfft` are a pair analogous to"
    ],
    [
        "opposite case: here the signal has Hermitian symmetry in the time",
        "opposite case: here the signal has"
    ],
    [
        "domain and is real in the frequency domain. So here it's `hfft` for",
        "domain and is real in the frequency domain."
    ],
    [
        "which you must supply the length of the result if it is to be odd.",
        "which you must supply the length of the result if it is to be"
    ],
    [
        "The correct interpretation of the hermitian input depends on the length of",
        "The correct interpretation of the hermitian input depends"
    ],
    [
        "the original data, as given by `n`. This is because each input shape could",
        "the original data, as given by `n`. This is because each input"
    ],
    [
        "correspond to either an odd or even length signal. By default, `hfft`",
        "correspond to either an odd or even length signal. By"
    ],
    [
        "assumes an even output length which puts the last entry at the Nyquist",
        "assumes an even output length which puts the last entry at"
    ],
    [
        "frequency; aliasing with its symmetric counterpart. By Hermitian symmetry,",
        "frequency; aliasing with its symmetric counterpart. By"
    ],
    [
        "the value is thus treated as purely real. To avoid losing information, the",
        "the value is thus treated as purely real. To avoid losing information,"
    ],
    [
        "shape of the full signal **must** be given.",
        "shape of the full signal"
    ],
    [
        "output = irfft(conjugate(a), n, axis, norm=new_norm, out=None)",
        "output = irfft(conjugate(a), n, axis,"
    ],
    [
        "Compute the inverse FFT of a signal that has Hermitian symmetry.",
        "Compute the inverse FFT of a signal that has Hermitian"
    ],
    [
        "Length of the inverse FFT, the number of points along",
        "Length of the inverse FFT, the number of points"
    ],
    [
        "transformation axis in the input to use.  If `n` is smaller than",
        "transformation axis in the input to"
    ],
    [
        "the length of the input, the input is cropped.  If it is larger,",
        "the length of the input, the input is cropped. If it is"
    ],
    [
        "the input is padded with zeros. If `n` is not given, the length of",
        "the input is padded with zeros. If `n` is"
    ],
    [
        "the input along the axis specified by `axis` is used.",
        "the input along the axis"
    ],
    [
        "Axis over which to compute the inverse FFT. If not given, the last",
        "Axis over which to compute the inverse FFT."
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\", \"ortho\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`)."
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the forward/backward pair"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed"
    ],
    [
        "of the appropriate shape and dtype.",
        "of the appropriate"
    ],
    [
        "The truncated or zero-padded input, transformed along the axis",
        "The truncated or zero-padded input,"
    ],
    [
        "indicated by `axis`, or the last one if `axis` is not specified.",
        "indicated by `axis`, or the last one if"
    ],
    [
        "`hfft`/`ihfft` are a pair analogous to `rfft`/`irfft`, but for the",
        "`hfft`/`ihfft` are a pair analogous"
    ],
    [
        "opposite case: here the signal has Hermitian symmetry in the time",
        "opposite case: here the signal has Hermitian symmetry in"
    ],
    [
        "domain and is real in the frequency domain. So here it's `hfft` for",
        "domain and is real in the frequency domain. So here"
    ],
    [
        "which you must supply the length of the result if it is to be odd:",
        "which you must supply the length of the result if"
    ],
    [
        "out = rfft(a, n, axis, norm=new_norm, out=out)",
        "out = rfft(a, n, axis, norm=new_norm,"
    ],
    [
        "msg = (\"`axes` should not be `None` if `s` is not `None` \"",
        "msg = (\"`axes` should not be `None` if `s` is not `None`"
    ],
    [
        "\"this will raise an error and `s[i]` will correspond to \"",
        "\"this will raise an error and `s[i]` will"
    ],
    [
        "\"the size along the transformed axis specified by \"",
        "\"the size along the transformed axis"
    ],
    [
        "\"`axes[i]`. To retain current behaviour, pass a sequence \"",
        "\"`axes[i]`. To retain current behaviour, pass a"
    ],
    [
        "raise ValueError(\"Shape and axes have different lengths.\")",
        "raise ValueError(\"Shape and axes"
    ],
    [
        "msg = (\"Passing an array containing `None` values to `s` is \"",
        "msg = (\"Passing an array containing `None` values to"
    ],
    [
        "\"a future version of NumPy. To use the default behaviour \"",
        "\"a future version of NumPy. To use the default behaviour"
    ],
    [
        "\"the default for its `n` parameter. To use the default \"",
        "\"the default for its `n` parameter. To use the default"
    ],
    [
        "\"behaviour for every axis, the `s` argument can be omitted.\")",
        "\"behaviour for every axis, the `s` argument can"
    ],
    [
        "def _raw_fftnd(a, s=None, axes=None, function=fft, norm=None, out=None):",
        "def _raw_fftnd(a, s=None, axes=None,"
    ],
    [
        "s, axes = _cook_nd_args(a, s, axes)",
        "s, axes = _cook_nd_args(a, s,"
    ],
    [
        "a = function(a, n=s[ii], axis=axes[ii], norm=norm, out=out)",
        "a = function(a, n=s[ii], axis=axes[ii],"
    ],
    [
        "def _fftn_dispatcher(a, s=None, axes=None, norm=None, out=None):",
        "def _fftn_dispatcher(a, s=None, axes=None, norm=None,"
    ],
    [
        "def fftn(a, s=None, axes=None, norm=None, out=None):",
        "def fftn(a, s=None,"
    ],
    [
        "Compute the N-dimensional discrete Fourier Transform.",
        "Compute the N-dimensional"
    ],
    [
        "This function computes the *N*-dimensional discrete Fourier Transform over",
        "This function computes the *N*-dimensional"
    ],
    [
        "any number of axes in an *M*-dimensional array by means of the Fast Fourier",
        "any number of axes in an *M*-dimensional"
    ],
    [
        "s : sequence of ints, optional",
        "s : sequence"
    ],
    [
        "Shape (length of each transformed axis) of the output",
        "Shape (length of each transformed axis) of the"
    ],
    [
        "This corresponds to ``n`` for ``fft(x, n)``.",
        "This corresponds to ``n`` for ``fft(x,"
    ],
    [
        "Along any axis, if the given shape is smaller than that of the input,",
        "Along any axis, if the given shape is smaller than that of the"
    ],
    [
        "the input is cropped. If it is larger, the input is padded with zeros.",
        "the input is cropped. If it is larger,"
    ],
    [
        "If `s` is not given, the shape of the input along the axes specified",
        "If `s` is not given, the shape of the input along"
    ],
    [
        "If `s` is not ``None``, `axes` must not be ``None`` either.",
        "If `s` is not ``None``, `axes` must"
    ],
    [
        "`s` must contain only ``int`` s, not ``None`` values. ``None``",
        "`s` must contain only ``int`` s, not ``None``"
    ],
    [
        "values currently mean that the default value for ``n`` is used",
        "values currently mean that the default value for"
    ],
    [
        "axes : sequence of ints, optional",
        "axes : sequence"
    ],
    [
        "Axes over which to compute the FFT.  If not given, the last ``len(s)``",
        "Axes over which to compute the FFT."
    ],
    [
        "axes are used, or all axes if `s` is also not specified.",
        "axes are used, or all axes if `s` is also not"
    ],
    [
        "Repeated indices in `axes` means that the transform over that axis is",
        "Repeated indices in `axes` means that the"
    ],
    [
        "If `s` is specified, the corresponding `axes` to be transformed",
        "If `s` is specified, the corresponding `axes` to be"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\", \"ortho\", \"forward\"},"
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`)."
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the forward/backward"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values were"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed"
    ],
    [
        "of the appropriate shape and dtype for all axes (and hence is",
        "of the appropriate shape and dtype for all"
    ],
    [
        "incompatible with passing in all but the trivial ``s``).",
        "incompatible with passing in all"
    ],
    [
        "The truncated or zero-padded input, transformed along the axes",
        "The truncated or zero-padded input, transformed"
    ],
    [
        "indicated by `axes`, or by a combination of `s` and `a`,",
        "indicated by `axes`, or by a combination of `s`"
    ],
    [
        "as explained in the parameters section above.",
        "as explained in the"
    ],
    [
        "If `s` and `axes` have different length.",
        "If `s` and `axes` have"
    ],
    [
        "If an element of `axes` is larger than than the number of axes of `a`.",
        "If an element of `axes` is larger than than the number"
    ],
    [
        "numpy.fft : Overall view of discrete Fourier transforms, with definitions",
        "numpy.fft : Overall view of discrete Fourier"
    ],
    [
        "ifftn : The inverse of `fftn`, the inverse *n*-dimensional FFT.",
        "ifftn : The inverse of `fftn`, the inverse"
    ],
    [
        "fft : The one-dimensional FFT, with definitions and conventions used.",
        "fft : The one-dimensional FFT, with definitions and conventions"
    ],
    [
        "rfftn : The *n*-dimensional FFT of real input.",
        "rfftn : The *n*-dimensional FFT"
    ],
    [
        "fftshift : Shifts zero-frequency terms to centre of array",
        "fftshift : Shifts zero-frequency terms to centre"
    ],
    [
        "The output, analogously to `fft`, contains the term for zero frequency in",
        "The output, analogously to `fft`, contains"
    ],
    [
        "the low-order corner of all axes, the positive frequency terms in the",
        "the low-order corner of all axes, the positive frequency terms in"
    ],
    [
        "first half of all axes, the term for the Nyquist frequency in the middle",
        "first half of all axes, the term for the Nyquist frequency"
    ],
    [
        "of all axes and the negative frequency terms in the second half of all",
        "of all axes and the negative frequency terms"
    ],
    [
        "axes, in order of decreasingly negative frequency.",
        "axes, in order of decreasingly"
    ],
    [
        "See `numpy.fft` for details, definitions and conventions used.",
        "See `numpy.fft` for details, definitions"
    ],
    [
        "return _raw_fftnd(a, s, axes, fft, norm, out=out)",
        "return _raw_fftnd(a, s, axes, fft,"
    ],
    [
        "def ifftn(a, s=None, axes=None, norm=None, out=None):",
        "def ifftn(a, s=None, axes=None, norm=None,"
    ],
    [
        "Compute the N-dimensional inverse discrete Fourier Transform.",
        "Compute the N-dimensional inverse discrete"
    ],
    [
        "This function computes the inverse of the N-dimensional discrete",
        "This function computes the inverse of"
    ],
    [
        "Fourier Transform over any number of axes in an M-dimensional array by",
        "Fourier Transform over any number of axes in"
    ],
    [
        "means of the Fast Fourier Transform (FFT).  In other words,",
        "means of the Fast Fourier Transform (FFT)."
    ],
    [
        "``ifftn(fftn(a)) == a`` to within numerical accuracy.",
        "``ifftn(fftn(a)) == a`` to within"
    ],
    [
        "For a description of the definitions and conventions used, see `numpy.fft`.",
        "For a description of the definitions and conventions used, see"
    ],
    [
        "The input, analogously to `ifft`, should be ordered in the same way as is",
        "The input, analogously to `ifft`, should be ordered in the same way"
    ],
    [
        "returned by `fftn`, i.e. it should have the term for zero frequency",
        "returned by `fftn`, i.e. it should have the term for"
    ],
    [
        "in all axes in the low-order corner, the positive frequency terms in the",
        "in all axes in the low-order corner, the positive frequency terms"
    ],
    [
        "first half of all axes, the term for the Nyquist frequency in the middle",
        "first half of all axes, the term for"
    ],
    [
        "of all axes and the negative frequency terms in the second half of all",
        "of all axes and the negative frequency"
    ],
    [
        "axes, in order of decreasingly negative frequency.",
        "axes, in order of decreasingly"
    ],
    [
        "s : sequence of ints, optional",
        "s : sequence of"
    ],
    [
        "Shape (length of each transformed axis) of the output",
        "Shape (length of each transformed axis) of"
    ],
    [
        "This corresponds to ``n`` for ``ifft(x, n)``.",
        "This corresponds to ``n`` for ``ifft(x,"
    ],
    [
        "Along any axis, if the given shape is smaller than that of the input,",
        "Along any axis, if the given shape is smaller than that of the"
    ],
    [
        "the input is cropped. If it is larger, the input is padded with zeros.",
        "the input is cropped. If it is larger,"
    ],
    [
        "If `s` is not given, the shape of the input along the axes specified",
        "If `s` is not given, the shape of the"
    ],
    [
        "by `axes` is used. See notes for issue on `ifft` zero padding.",
        "by `axes` is used. See notes"
    ],
    [
        "If `s` is not ``None``, `axes` must not be ``None`` either.",
        "If `s` is not ``None``, `axes` must"
    ],
    [
        "`s` must contain only ``int`` s, not ``None`` values. ``None``",
        "`s` must contain only ``int``"
    ],
    [
        "values currently mean that the default value for ``n`` is used",
        "values currently mean that the default value"
    ],
    [
        "axes : sequence of ints, optional",
        "axes : sequence of ints,"
    ],
    [
        "Axes over which to compute the IFFT.  If not given, the last ``len(s)``",
        "Axes over which to compute the IFFT. If not given,"
    ],
    [
        "axes are used, or all axes if `s` is also not specified.",
        "axes are used, or all axes if"
    ],
    [
        "Repeated indices in `axes` means that the inverse transform over that",
        "Repeated indices in `axes` means that the inverse transform over"
    ],
    [
        "If `s` is specified, the corresponding `axes` to be transformed",
        "If `s` is specified, the corresponding"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\", \"ortho\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`). Default is"
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what normalization"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in this array. It should"
    ],
    [
        "of the appropriate shape and dtype for all axes (and hence is",
        "of the appropriate shape and dtype for"
    ],
    [
        "incompatible with passing in all but the trivial ``s``).",
        "incompatible with passing in all but"
    ],
    [
        "The truncated or zero-padded input, transformed along the axes",
        "The truncated or zero-padded input, transformed"
    ],
    [
        "indicated by `axes`, or by a combination of `s` or `a`,",
        "indicated by `axes`, or by a"
    ],
    [
        "as explained in the parameters section above.",
        "as explained in the"
    ],
    [
        "If `s` and `axes` have different length.",
        "If `s` and `axes` have different"
    ],
    [
        "If an element of `axes` is larger than than the number of axes of `a`.",
        "If an element of `axes` is larger than than the number of axes of"
    ],
    [
        "numpy.fft : Overall view of discrete Fourier transforms, with definitions",
        "numpy.fft : Overall view of discrete Fourier"
    ],
    [
        "fftn : The forward *n*-dimensional FFT, of which `ifftn` is the inverse.",
        "fftn : The forward *n*-dimensional FFT, of"
    ],
    [
        "ifft : The one-dimensional inverse FFT.",
        "ifft : The one-dimensional inverse"
    ],
    [
        "ifftshift : Undoes `fftshift`, shifts zero-frequency terms to beginning",
        "ifftshift : Undoes `fftshift`, shifts zero-frequency terms to"
    ],
    [
        "See `numpy.fft` for definitions and conventions used.",
        "See `numpy.fft` for definitions and conventions"
    ],
    [
        "Zero-padding, analogously with `ifft`, is performed by appending zeros to",
        "Zero-padding, analogously with `ifft`, is performed"
    ],
    [
        "the input along the specified dimension.  Although this is the common",
        "the input along the specified dimension. Although this is the"
    ],
    [
        "approach, it might lead to surprising results.  If another form of zero",
        "approach, it might lead to surprising results. If"
    ],
    [
        "padding is desired, it must be performed before `ifftn` is called.",
        "padding is desired, it must be performed before `ifftn`"
    ],
    [
        "Create and plot an image with band-limited frequency content:",
        "Create and plot an image with"
    ],
    [
        "return _raw_fftnd(a, s, axes, ifft, norm, out=out)",
        "return _raw_fftnd(a, s, axes, ifft, norm,"
    ],
    [
        "This function computes the *n*-dimensional discrete Fourier Transform",
        "This function computes the"
    ],
    [
        "over any axes in an *M*-dimensional array by means of the",
        "over any axes in an *M*-dimensional array by means of"
    ],
    [
        "Fast Fourier Transform (FFT).  By default, the transform is computed over",
        "Fast Fourier Transform (FFT). By default, the"
    ],
    [
        "s : sequence of ints, optional",
        "s : sequence"
    ],
    [
        "Shape (length of each transformed axis) of the output",
        "Shape (length of each transformed axis)"
    ],
    [
        "This corresponds to ``n`` for ``fft(x, n)``.",
        "This corresponds to ``n`` for"
    ],
    [
        "Along each axis, if the given shape is smaller than that of the input,",
        "Along each axis, if the given shape is smaller than that of the"
    ],
    [
        "the input is cropped. If it is larger, the input is padded with zeros.",
        "the input is cropped. If it is larger, the input is"
    ],
    [
        "If `s` is not given, the shape of the input along the axes specified",
        "If `s` is not given, the shape"
    ],
    [
        "If `s` is not ``None``, `axes` must not be ``None`` either.",
        "If `s` is not ``None``, `axes` must not"
    ],
    [
        "`s` must contain only ``int`` s, not ``None`` values. ``None``",
        "`s` must contain only ``int`` s,"
    ],
    [
        "values currently mean that the default value for ``n`` is used",
        "values currently mean that the default value for"
    ],
    [
        "axes : sequence of ints, optional",
        "axes : sequence of"
    ],
    [
        "Axes over which to compute the FFT.  If not given, the last two",
        "Axes over which to compute the FFT. If"
    ],
    [
        "axes are used.  A repeated index in `axes` means the transform over",
        "axes are used. A repeated index in `axes` means"
    ],
    [
        "that axis is performed multiple times.  A one-element sequence means",
        "that axis is performed multiple times. A one-element"
    ],
    [
        "If `s` is specified, the corresponding `axes` to be transformed",
        "If `s` is specified, the corresponding `axes` to"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\", \"ortho\", \"forward\"},"
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`). Default"
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the forward/backward"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what normalization"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values were"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in this"
    ],
    [
        "of the appropriate shape and dtype for all axes (and hence only the",
        "of the appropriate shape and dtype for all axes"
    ],
    [
        "last axis can have ``s`` not equal to the shape at that axis).",
        "last axis can have ``s`` not equal to the shape"
    ],
    [
        "The truncated or zero-padded input, transformed along the axes",
        "The truncated or zero-padded input, transformed"
    ],
    [
        "indicated by `axes`, or the last two axes if `axes` is not given.",
        "indicated by `axes`, or the last two axes if `axes` is"
    ],
    [
        "If `s` and `axes` have different length, or `axes` not given and",
        "If `s` and `axes` have different length, or `axes`"
    ],
    [
        "If an element of `axes` is larger than than the number of axes of `a`.",
        "If an element of `axes` is larger than than the number"
    ],
    [
        "numpy.fft : Overall view of discrete Fourier transforms, with definitions",
        "numpy.fft : Overall view of discrete Fourier transforms, with"
    ],
    [
        "fftshift : Shifts zero-frequency terms to the center of the array.",
        "fftshift : Shifts zero-frequency terms to the center of the"
    ],
    [
        "For two-dimensional input, swaps first and third quadrants, and second",
        "For two-dimensional input, swaps first and"
    ],
    [
        "The output, analogously to `fft`, contains the term for zero frequency in",
        "The output, analogously to `fft`, contains the"
    ],
    [
        "the low-order corner of the transformed axes, the positive frequency terms",
        "the low-order corner of the transformed axes, the positive"
    ],
    [
        "in the first half of these axes, the term for the Nyquist frequency in the",
        "in the first half of these axes, the term for"
    ],
    [
        "middle of the axes and the negative frequency terms in the second half of",
        "middle of the axes and the negative frequency terms in"
    ],
    [
        "the axes, in order of decreasingly negative frequency.",
        "the axes, in order"
    ],
    [
        "See `fftn` for details and a plotting example, and `numpy.fft` for",
        "See `fftn` for details and a plotting example, and"
    ],
    [
        "return _raw_fftnd(a, s, axes, fft, norm, out=out)",
        "return _raw_fftnd(a, s, axes,"
    ],
    [
        "Transform over any number of axes in an M-dimensional array by means of",
        "Transform over any number of axes in an M-dimensional array by"
    ],
    [
        "to within numerical accuracy.  By default, the inverse transform is",
        "to within numerical accuracy. By default, the"
    ],
    [
        "computed over the last two axes of the input array.",
        "computed over the last two axes of the input"
    ],
    [
        "The input, analogously to `ifft`, should be ordered in the same way as is",
        "The input, analogously to `ifft`, should be"
    ],
    [
        "in the low-order corner of the two axes, the positive frequency terms in",
        "in the low-order corner of the two axes, the positive frequency"
    ],
    [
        "the first half of these axes, the term for the Nyquist frequency in the",
        "the first half of these axes, the term for the Nyquist frequency"
    ],
    [
        "middle of the axes and the negative frequency terms in the second half of",
        "middle of the axes and the negative frequency"
    ],
    [
        "both axes, in order of decreasingly negative frequency.",
        "both axes, in order of"
    ],
    [
        "s : sequence of ints, optional",
        "s : sequence of"
    ],
    [
        "Along each axis, if the given shape is smaller than that of the input,",
        "Along each axis, if the given shape"
    ],
    [
        "the input is cropped. If it is larger, the input is padded with zeros.",
        "the input is cropped. If it is larger, the input is"
    ],
    [
        "If `s` is not given, the shape of the input along the axes specified",
        "If `s` is not given, the shape"
    ],
    [
        "by `axes` is used.  See notes for issue on `ifft` zero padding.",
        "by `axes` is used. See notes for"
    ],
    [
        "If `s` is not ``None``, `axes` must not be ``None`` either.",
        "If `s` is not ``None``, `axes`"
    ],
    [
        "`s` must contain only ``int`` s, not ``None`` values. ``None``",
        "`s` must contain only ``int`` s, not"
    ],
    [
        "values currently mean that the default value for ``n`` is used",
        "values currently mean that the default"
    ],
    [
        "axes : sequence of ints, optional",
        "axes : sequence of ints,"
    ],
    [
        "Axes over which to compute the FFT.  If not given, the last two",
        "Axes over which to compute the FFT. If"
    ],
    [
        "axes are used.  A repeated index in `axes` means the transform over",
        "axes are used. A repeated index in `axes`"
    ],
    [
        "that axis is performed multiple times.  A one-element sequence means",
        "that axis is performed multiple"
    ],
    [
        "If `s` is specified, the corresponding `axes` to be transformed",
        "If `s` is specified, the corresponding `axes`"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`)."
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\""
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in this array."
    ],
    [
        "of the appropriate shape and dtype for all axes (and hence is",
        "of the appropriate shape and dtype"
    ],
    [
        "incompatible with passing in all but the trivial ``s``).",
        "incompatible with passing in all"
    ],
    [
        "The truncated or zero-padded input, transformed along the axes",
        "The truncated or zero-padded input, transformed along the"
    ],
    [
        "indicated by `axes`, or the last two axes if `axes` is not given.",
        "indicated by `axes`, or the last two axes if `axes` is"
    ],
    [
        "If `s` and `axes` have different length, or `axes` not given and",
        "If `s` and `axes` have different length, or"
    ],
    [
        "If an element of `axes` is larger than than the number of axes of `a`.",
        "If an element of `axes` is larger than"
    ],
    [
        "numpy.fft : Overall view of discrete Fourier transforms, with definitions",
        "numpy.fft : Overall view of discrete"
    ],
    [
        "ifftn : The inverse of the *n*-dimensional FFT.",
        "ifftn : The inverse"
    ],
    [
        "ifft : The one-dimensional inverse FFT.",
        "ifft : The"
    ],
    [
        "See `ifftn` for details and a plotting example, and `numpy.fft` for",
        "See `ifftn` for details and a plotting example, and"
    ],
    [
        "Zero-padding, analogously with `ifft`, is performed by appending zeros to",
        "Zero-padding, analogously with `ifft`, is performed by appending zeros"
    ],
    [
        "the input along the specified dimension.  Although this is the common",
        "the input along the specified dimension. Although this"
    ],
    [
        "approach, it might lead to surprising results.  If another form of zero",
        "approach, it might lead to surprising results."
    ],
    [
        "return _raw_fftnd(a, s, axes, ifft, norm, out=None)",
        "return _raw_fftnd(a, s, axes, ifft,"
    ],
    [
        "def rfftn(a, s=None, axes=None, norm=None, out=None):",
        "def rfftn(a, s=None,"
    ],
    [
        "Compute the N-dimensional discrete Fourier Transform for real input.",
        "Compute the N-dimensional discrete Fourier Transform"
    ],
    [
        "This function computes the N-dimensional discrete Fourier Transform over",
        "This function computes the N-dimensional discrete Fourier"
    ],
    [
        "any number of axes in an M-dimensional real array by means of the Fast",
        "any number of axes in an M-dimensional real array by means"
    ],
    [
        "Fourier Transform (FFT).  By default, all axes are transformed, with the",
        "Fourier Transform (FFT). By default, all axes are"
    ],
    [
        "real transform performed over the last axis, while the remaining",
        "real transform performed over the"
    ],
    [
        "Input array, taken to be real.",
        "Input array, taken to"
    ],
    [
        "s : sequence of ints, optional",
        "s : sequence of"
    ],
    [
        "Shape (length along each transformed axis) to use from the input.",
        "Shape (length along each transformed axis) to"
    ],
    [
        "The final element of `s` corresponds to `n` for ``rfft(x, n)``, while",
        "The final element of `s` corresponds to `n` for"
    ],
    [
        "for the remaining axes, it corresponds to `n` for ``fft(x, n)``.",
        "for the remaining axes, it corresponds to `n`"
    ],
    [
        "Along any axis, if the given shape is smaller than that of the input,",
        "Along any axis, if the given shape is smaller than that of the"
    ],
    [
        "the input is cropped. If it is larger, the input is padded with zeros.",
        "the input is cropped. If it is larger, the"
    ],
    [
        "If `s` is not given, the shape of the input along the axes specified",
        "If `s` is not given, the shape of the input"
    ],
    [
        "If `s` is not ``None``, `axes` must not be ``None`` either.",
        "If `s` is not ``None``, `axes` must not be ``None``"
    ],
    [
        "`s` must contain only ``int`` s, not ``None`` values. ``None``",
        "`s` must contain only ``int`` s, not ``None``"
    ],
    [
        "values currently mean that the default value for ``n`` is used",
        "values currently mean that the default value for"
    ],
    [
        "axes : sequence of ints, optional",
        "axes : sequence of"
    ],
    [
        "Axes over which to compute the FFT.  If not given, the last ``len(s)``",
        "Axes over which to compute the FFT. If not given,"
    ],
    [
        "axes are used, or all axes if `s` is also not specified.",
        "axes are used, or all axes if `s` is"
    ],
    [
        "If `s` is specified, the corresponding `axes` to be transformed",
        "If `s` is specified, the corresponding `axes` to be"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\", \"ortho\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`)."
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the forward/backward"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values were"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in"
    ],
    [
        "of the appropriate shape and dtype for all axes (and hence is",
        "of the appropriate shape and dtype for"
    ],
    [
        "incompatible with passing in all but the trivial ``s``).",
        "incompatible with passing in all but"
    ],
    [
        "The truncated or zero-padded input, transformed along the axes",
        "The truncated or zero-padded input,"
    ],
    [
        "indicated by `axes`, or by a combination of `s` and `a`,",
        "indicated by `axes`, or by a combination"
    ],
    [
        "as explained in the parameters section above.",
        "as explained in the parameters"
    ],
    [
        "while the remaining transformed axes will have lengths according to",
        "while the remaining transformed axes will have lengths according"
    ],
    [
        "`s`, or unchanged from the input.",
        "`s`, or unchanged from"
    ],
    [
        "If `s` and `axes` have different length.",
        "If `s` and `axes`"
    ],
    [
        "If an element of `axes` is larger than than the number of axes of `a`.",
        "If an element of `axes` is larger than"
    ],
    [
        "irfftn : The inverse of `rfftn`, i.e. the inverse of the n-dimensional FFT",
        "irfftn : The inverse of `rfftn`, i.e. the inverse"
    ],
    [
        "fft : The one-dimensional FFT, with definitions and conventions used.",
        "fft : The one-dimensional FFT, with"
    ],
    [
        "rfft : The one-dimensional FFT of real input.",
        "rfft : The one-dimensional FFT"
    ],
    [
        "The transform for real input is performed over the last transformation",
        "The transform for real input is performed over the last"
    ],
    [
        "axis, as by `rfft`, then the transform over the remaining axes is",
        "axis, as by `rfft`, then the transform"
    ],
    [
        "performed as by `fftn`.  The order of the output is as for `rfft` for the",
        "performed as by `fftn`. The order of the output is as for `rfft`"
    ],
    [
        "final transformation axis, and as for `fftn` for the remaining",
        "final transformation axis, and as for `fftn` for"
    ],
    [
        "See `fft` for details, definitions and conventions used.",
        "See `fft` for details, definitions and conventions"
    ],
    [
        "s, axes = _cook_nd_args(a, s, axes)",
        "s, axes = _cook_nd_args(a, s,"
    ],
    [
        "a = fft(a, s[ii], axes[ii], norm, out=out)",
        "a = fft(a, s[ii],"
    ],
    [
        "Input array, taken to be real.",
        "Input array, taken to be"
    ],
    [
        "s : sequence of ints, optional",
        "s : sequence of"
    ],
    [
        "If `s` is not ``None``, `axes` must not be ``None`` either.",
        "If `s` is not ``None``, `axes` must not be ``None``"
    ],
    [
        "`s` must contain only ``int`` s, not ``None`` values. ``None``",
        "`s` must contain only ``int`` s,"
    ],
    [
        "values currently mean that the default value for ``n`` is used",
        "values currently mean that the default value for ``n`` is"
    ],
    [
        "axes : sequence of ints, optional",
        "axes : sequence of"
    ],
    [
        "If `s` is specified, the corresponding `axes` to be transformed",
        "If `s` is specified, the"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\", \"ortho\", \"forward\"},"
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`). Default is"
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the forward/backward pair of"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what normalization"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in this array."
    ],
    [
        "of the appropriate shape and dtype for the last inverse transform.",
        "of the appropriate shape and dtype"
    ],
    [
        "incompatible with passing in all but the trivial ``s``).",
        "incompatible with passing in all"
    ],
    [
        "rfftn : Compute the N-dimensional discrete Fourier Transform for real",
        "rfftn : Compute the N-dimensional discrete"
    ],
    [
        "This is really just `rfftn` with different default behavior.",
        "This is really just `rfftn` with different"
    ],
    [
        "return rfftn(a, s, axes, norm, out=out)",
        "return rfftn(a, s, axes,"
    ],
    [
        "def irfftn(a, s=None, axes=None, norm=None, out=None):",
        "def irfftn(a, s=None, axes=None,"
    ],
    [
        "This function computes the inverse of the N-dimensional discrete",
        "This function computes the inverse"
    ],
    [
        "Fourier Transform for real input over any number of axes in an",
        "Fourier Transform for real input over any number of axes"
    ],
    [
        "M-dimensional array by means of the Fast Fourier Transform (FFT).  In",
        "M-dimensional array by means of the Fast"
    ],
    [
        "other words, ``irfftn(rfftn(a), a.shape) == a`` to within numerical",
        "other words, ``irfftn(rfftn(a), a.shape) == a`` to within"
    ],
    [
        "accuracy. (The ``a.shape`` is necessary like ``len(a)`` is for `irfft`,",
        "accuracy. (The ``a.shape`` is necessary"
    ],
    [
        "The input should be ordered in the same way as is returned by `rfftn`,",
        "The input should be ordered in the same"
    ],
    [
        "i.e. as for `irfft` for the final transformation axis, and as for `ifftn`",
        "i.e. as for `irfft` for the final transformation axis,"
    ],
    [
        "s : sequence of ints, optional",
        "s : sequence of ints,"
    ],
    [
        "Shape (length of each transformed axis) of the output",
        "Shape (length of each transformed axis)"
    ],
    [
        "number of input points used along this axis, except for the last axis,",
        "number of input points used along this axis, except"
    ],
    [
        "Along any axis, if the shape indicated by `s` is smaller than that of",
        "Along any axis, if the shape indicated by `s` is smaller"
    ],
    [
        "the input, the input is cropped.  If it is larger, the input is padded",
        "the input, the input is cropped. If it is larger, the input is"
    ],
    [
        "If `s` is not given, the shape of the input along the axes",
        "If `s` is not given, the shape of the input"
    ],
    [
        "specified by axes is used. Except for the last axis which is taken to",
        "specified by axes is used. Except for"
    ],
    [
        "If `s` is not ``None``, `axes` must not be ``None`` either.",
        "If `s` is not ``None``, `axes`"
    ],
    [
        "`s` must contain only ``int`` s, not ``None`` values. ``None``",
        "`s` must contain only ``int`` s, not ``None``"
    ],
    [
        "values currently mean that the default value for ``n`` is used",
        "values currently mean that the default value for ``n`` is"
    ],
    [
        "axes : sequence of ints, optional",
        "axes : sequence"
    ],
    [
        "Axes over which to compute the inverse FFT. If not given, the last",
        "Axes over which to compute the inverse FFT. If"
    ],
    [
        "`len(s)` axes are used, or all axes if `s` is also not specified.",
        "`len(s)` axes are used, or all axes if `s`"
    ],
    [
        "Repeated indices in `axes` means that the inverse transform over that",
        "Repeated indices in `axes` means that"
    ],
    [
        "If `s` is specified, the corresponding `axes` to be transformed",
        "If `s` is specified, the corresponding"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`). Default is"
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\" values"
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed"
    ],
    [
        "of the appropriate shape and dtype for the last transformation.",
        "of the appropriate shape and dtype for the last"
    ],
    [
        "The truncated or zero-padded input, transformed along the axes",
        "The truncated or zero-padded input, transformed along the"
    ],
    [
        "indicated by `axes`, or by a combination of `s` or `a`,",
        "indicated by `axes`, or by a"
    ],
    [
        "as explained in the parameters section above.",
        "as explained in the parameters section"
    ],
    [
        "The length of each transformed axis is as given by the corresponding",
        "The length of each transformed axis is as given by"
    ],
    [
        "element of `s`, or the length of the input in every axis except for the",
        "element of `s`, or the length of the input in every"
    ],
    [
        "last one if `s` is not given.  In the final transformed axis the length",
        "last one if `s` is not given. In the final"
    ],
    [
        "length of the final transformed axis of the input.  To get an odd",
        "length of the final transformed axis of"
    ],
    [
        "number of output points in the final axis, `s` must be specified.",
        "number of output points in the final"
    ],
    [
        "If `s` and `axes` have different length.",
        "If `s` and `axes` have different"
    ],
    [
        "If an element of `axes` is larger than than the number of axes of `a`.",
        "If an element of `axes` is larger than"
    ],
    [
        "rfftn : The forward n-dimensional FFT of real input,",
        "rfftn : The forward n-dimensional FFT of"
    ],
    [
        "of which `ifftn` is the inverse.",
        "of which `ifftn`"
    ],
    [
        "fft : The one-dimensional FFT, with definitions and conventions used.",
        "fft : The one-dimensional FFT, with definitions and conventions"
    ],
    [
        "irfft : The inverse of the one-dimensional FFT of real input.",
        "irfft : The inverse of the one-dimensional"
    ],
    [
        "See `fft` for definitions and conventions used.",
        "See `fft` for definitions"
    ],
    [
        "See `rfft` for definitions and conventions used for real input.",
        "See `rfft` for definitions and conventions used for real"
    ],
    [
        "The correct interpretation of the hermitian input depends on the shape of",
        "The correct interpretation of the hermitian input depends on"
    ],
    [
        "the original data, as given by `s`. This is because each input shape could",
        "the original data, as given by `s`. This is because"
    ],
    [
        "correspond to either an odd or even length signal. By default, `irfftn`",
        "correspond to either an odd or even"
    ],
    [
        "assumes an even output length which puts the last entry at the Nyquist",
        "assumes an even output length which puts the"
    ],
    [
        "frequency; aliasing with its symmetric counterpart. When performing the",
        "frequency; aliasing with its symmetric counterpart."
    ],
    [
        "final complex to real transform, the last value is thus treated as purely",
        "final complex to real transform, the last value"
    ],
    [
        "real. To avoid losing information, the correct shape of the real input",
        "real. To avoid losing information, the correct shape of the"
    ],
    [
        "a = ifft(a, s[ii], axes[ii], norm)",
        "a = ifft(a, s[ii], axes[ii],"
    ],
    [
        "s : sequence of ints, optional",
        "s : sequence"
    ],
    [
        "Shape of the real output to the inverse FFT.",
        "Shape of the real output to the"
    ],
    [
        "If `s` is not ``None``, `axes` must not be ``None`` either.",
        "If `s` is not ``None``, `axes`"
    ],
    [
        "`s` must contain only ``int`` s, not ``None`` values. ``None``",
        "`s` must contain only ``int``"
    ],
    [
        "values currently mean that the default value for ``n`` is used",
        "values currently mean that the default value for"
    ],
    [
        "axes : sequence of ints, optional",
        "axes : sequence"
    ],
    [
        "The axes over which to compute the inverse fft.",
        "The axes over which to"
    ],
    [
        "If `s` is specified, the corresponding `axes` to be transformed",
        "If `s` is specified, the corresponding `axes` to"
    ],
    [
        "norm : {\"backward\", \"ortho\", \"forward\"}, optional",
        "norm : {\"backward\","
    ],
    [
        "Normalization mode (see `numpy.fft`). Default is \"backward\".",
        "Normalization mode (see `numpy.fft`)."
    ],
    [
        "Indicates which direction of the forward/backward pair of transforms",
        "Indicates which direction of the forward/backward pair of"
    ],
    [
        "is scaled and with what normalization factor.",
        "is scaled and with what"
    ],
    [
        "The \"backward\", \"forward\" values were added.",
        "The \"backward\", \"forward\""
    ],
    [
        "If provided, the result will be placed in this array. It should be",
        "If provided, the result will be placed in this array. It"
    ],
    [
        "of the appropriate shape and dtype for the last transformation.",
        "of the appropriate shape and dtype for the last"
    ],
    [
        "rfft : The one-dimensional FFT for real input.",
        "rfft : The one-dimensional FFT for real"
    ],
    [
        "irfft : The inverse of the one-dimensional FFT of real input.",
        "irfft : The inverse of the one-dimensional"
    ],
    [
        "irfftn : Compute the inverse of the N-dimensional FFT of real input.",
        "irfftn : Compute the inverse of the"
    ],
    [
        "This is really `irfftn` with different defaults.",
        "This is really `irfftn` with different"
    ],
    [
        "return irfftn(a, s, axes, norm, out=None)",
        "return irfftn(a, s,"
    ],
    [
        "with pytest.raises(TypeError, match=\"must be of ArrayType\"):",
        "with pytest.raises(TypeError, match=\"must"
    ],
    [
        "match='Invalid number of FFT data points'):",
        "match='Invalid number of FFT data"
    ],
    [
        "for norm in [None, 'backward', 'ortho', 'forward']:",
        "for norm in [None, 'backward', 'ortho',"
    ],
    [
        "with pytest.warns(match='`axes` should not be `None` if `s`'):",
        "with pytest.warns(match='`axes` should not be"
    ],
    [
        "with pytest.warns(match='`axes` should not be `None` if `s`'):",
        "with pytest.warns(match='`axes` should not be `None` if"
    ],
    [
        "with pytest.warns(match='array containing `None` values to `s`'):",
        "with pytest.warns(match='array containing `None` values"
    ],
    [
        "for norm in [None, 'backward', 'ortho', 'forward']:",
        "for norm in [None, 'backward', 'ortho',"
    ],
    [
        "'Function returned wrong value in multithreaded context')",
        "'Function returned wrong value in multithreaded"
    ],
    [
        "from numpy._core import asarray, concatenate, arange, take",
        "from numpy._core import asarray, concatenate,"
    ],
    [
        "Ufuncs are, generally speaking, mathematical functions or operations that are",
        "Ufuncs are, generally speaking, mathematical functions or operations that"
    ],
    [
        "applied element-by-element to the contents of an array. That is, the result",
        "applied element-by-element to the contents of an"
    ],
    [
        "in each output array element only depends on the value in the corresponding",
        "in each output array element only depends on"
    ],
    [
        "input array (or arrays) and on no other array elements. NumPy comes with a",
        "input array (or arrays) and on no other array elements. NumPy comes with"
    ],
    [
        "large suite of ufuncs, and scipy extends that suite substantially. The simplest",
        "large suite of ufuncs, and scipy extends that suite"
    ],
    [
        "example is the addition operator: ::",
        "example is the addition"
    ],
    [
        "The ufunc module lists all the available ufuncs in numpy. Documentation on",
        "The ufunc module lists all the available ufuncs in"
    ],
    [
        "the specific ufuncs may be found in those modules. This documentation is",
        "the specific ufuncs may be found in those modules. This"
    ],
    [
        "intended to address the more general aspects of ufuncs common to most of",
        "intended to address the more general aspects"
    ],
    [
        "them. All of the ufuncs that make use of Python operators (e.g., +, -, etc.)",
        "them. All of the ufuncs that make use of Python operators"
    ],
    [
        "have equivalent functions defined (e.g. add() for +)",
        "have equivalent functions defined (e.g."
    ],
    [
        "What happens when a binary operator (e.g., +,-,\\\\*,/, etc) deals with arrays of",
        "What happens when a binary operator (e.g., +,-,\\\\*,/, etc) deals with arrays"
    ],
    [
        "two different types? What is the type of the result? Typically, the result is",
        "two different types? What is the type of the result? Typically, the result"
    ],
    [
        "the higher of the two types. For example: ::",
        "the higher of the two types. For example:"
    ],
    [
        "There are some less obvious cases generally involving mixes of types",
        "There are some less obvious cases generally"
    ],
    [
        "(e.g. uints, ints and floats) where equal bit sizes for each are not",
        "(e.g. uints, ints and floats) where equal bit sizes for each"
    ],
    [
        "capable of saving all the information in a different type of equivalent",
        "capable of saving all the information"
    ],
    [
        "Generally, the result is the higher type of larger size than both",
        "Generally, the result is the higher type of larger size than"
    ],
    [
        "Finally, the type coercion behavior when expressions involve Python",
        "Finally, the type coercion behavior when"
    ],
    [
        "scalars is different than that seen for arrays. Since Python has a",
        "scalars is different than that seen for arrays."
    ],
    [
        "array does not coerce to the higher type but instead, the type of the",
        "array does not coerce to the higher type"
    ],
    [
        "array prevails. So the rules for Python scalars combined with arrays is",
        "array prevails. So the rules for Python"
    ],
    [
        "that the result will be that of the array equivalent the Python scalar",
        "that the result will be that of the array equivalent the Python"
    ],
    [
        "if the Python scalar is of a higher 'kind' than the array (e.g., float",
        "if the Python scalar is of a higher 'kind' than the"
    ],
    [
        "vs. int), otherwise the resultant type will be that of the array.",
        "vs. int), otherwise the resultant type will be that of the"
    ],
    [
        "**.reduce(arr)** applies the binary operator to elements of the array in",
        "**.reduce(arr)** applies the binary operator to elements of the"
    ],
    [
        "For multidimensional arrays, the first dimension is reduced by default: ::",
        "For multidimensional arrays, the first dimension is reduced by"
    ],
    [
        "The axis keyword can be used to specify different axes to reduce: ::",
        "The axis keyword can be used to specify different axes to reduce:"
    ],
    [
        "**.accumulate(arr)** applies the binary operator and generates an",
        "**.accumulate(arr)** applies the binary"
    ],
    [
        "equivalently shaped array that includes the accumulated amount for each",
        "equivalently shaped array that includes the accumulated"
    ],
    [
        "element of the array. A couple examples: ::",
        "element of the array."
    ],
    [
        "The behavior for multidimensional arrays is the same as for .reduce(),",
        "The behavior for multidimensional arrays is the same as for"
    ],
    [
        "as is the use of the axis keyword).",
        "as is the use of the"
    ],
    [
        "**.reduceat(arr,indices)** allows one to apply reduce to selected parts",
        "**.reduceat(arr,indices)** allows one to apply reduce"
    ],
    [
        "of an array. It is a difficult method to understand. See the documentation",
        "of an array. It is a difficult method to understand."
    ],
    [
        "the concatenation of the two input shapes.: ::",
        "the concatenation of the two input"
    ],
    [
        "All ufuncs accept an optional output array. The array must be of the expected",
        "All ufuncs accept an optional output array. The array must be"
    ],
    [
        "output shape. Beware that if the type of the output array is of a different",
        "output shape. Beware that if the type of the output"
    ],
    [
        "(and lower) type than the output result, the results may be silently truncated",
        "(and lower) type than the output result, the results"
    ],
    [
        "or otherwise corrupted in the downcast to the lower type. This usage is useful",
        "or otherwise corrupted in the downcast to the"
    ],
    [
        "when one wants to avoid creating large temporary arrays and instead allows one",
        "when one wants to avoid creating large temporary arrays and instead"
    ],
    [
        "to reuse the same array memory repeatedly (at the expense of not being able to",
        "to reuse the same array memory repeatedly (at the"
    ],
    [
        "use more convenient operator notation in expressions). Note that when the",
        "use more convenient operator notation in expressions). Note that when"
    ],
    [
        "output argument is used, the ufunc still returns a reference to the result.",
        "output argument is used, the ufunc still returns a reference"
    ],
    [
        "Invariably people try to use the python 'and' and 'or' as logical operators",
        "Invariably people try to use the python"
    ],
    [
        "(and quite understandably). But these operators do not behave as normal",
        "(and quite understandably). But these operators do not"
    ],
    [
        "operators since Python treats these quite differently. They cannot be",
        "operators since Python treats these quite differently. They cannot"
    ],
    [
        "overloaded with array equivalents. Thus using 'and' or 'or' with an array",
        "overloaded with array equivalents. Thus using 'and'"
    ],
    [
        "results in an error. There are two alternatives:",
        "results in an error. There"
    ],
    [
        "the arguments to these operators are not boolean arrays, the result is",
        "the arguments to these operators are not boolean arrays, the result"
    ],
    [
        "likely incorrect. On the other hand, most usages of logical_and and",
        "likely incorrect. On the other hand, most usages"
    ],
    [
        "logical_or are with boolean arrays. As long as one is careful, this is",
        "logical_or are with boolean arrays. As long as one is"
    ],
    [
        "a convenient way to apply these operators.",
        "a convenient way to"
    ],
    [
        "Pickling helper function that returns a bit generator object",
        "Pickling helper function that returns"
    ],
    [
        "BitGenerator class or string containing the name of the BitGenerator",
        "BitGenerator class or string containing the"
    ],
    [
        "str(bit_generator) + ' is not a known BitGenerator module.'",
        "str(bit_generator) + ' is not a known BitGenerator"
    ],
    [
        "Pickling helper function that returns a Generator object",
        "Pickling helper function that returns a Generator"
    ],
    [
        "String containing the core BitGenerator's name or a",
        "String containing the core BitGenerator's name or"
    ],
    [
        "Callable function that takes bit_generator_name as its only argument",
        "Callable function that takes bit_generator_name as its only"
    ],
    [
        "and returns an instantized bit generator.",
        "and returns an instantized"
    ],
    [
        "Generator using the named core BitGenerator",
        "Generator using the"
    ],
    [
        "Pickling helper function that returns a legacy RandomState-like object",
        "Pickling helper function that returns a legacy RandomState-like"
    ],
    [
        "String containing the core BitGenerator's name",
        "String containing the core BitGenerator's"
    ],
    [
        "Callable function that takes bit_generator_name as its only argument",
        "Callable function that takes bit_generator_name as its"
    ],
    [
        "and returns an instantized bit generator.",
        "and returns an instantized bit"
    ],
    [
        "Legacy RandomState using the named core BitGenerator",
        "Legacy RandomState using the"
    ],
    [
        "Use ``default_rng()`` to create a `Generator` and call its methods.",
        "Use ``default_rng()`` to create a"
    ],
    [
        "Generator       Class implementing all of the random number distributions",
        "Generator Class implementing all of"
    ],
    [
        "BitGenerator Streams that work with Generator",
        "BitGenerator Streams that"
    ],
    [
        "Getting entropy to initialize a BitGenerator",
        "Getting entropy to initialize"
    ],
    [
        "various aliases to the global `RandomState` methods are left alone and do not",
        "various aliases to the global `RandomState` methods are left alone and"
    ],
    [
        "permutation          Randomly permute a sequence / generate a random sequence.",
        "permutation Randomly permute a sequence / generate"
    ],
    [
        "shuffle              Randomly permute a sequence in place.",
        "shuffle Randomly permute a sequence"
    ],
    [
        "ranf                 Uniformly distributed floating point numbers.",
        "ranf Uniformly distributed floating point"
    ],
    [
        "random_integers      Uniformly distributed integers in a given range.",
        "random_integers Uniformly distributed integers"
    ],
    [
        "randint              Uniformly distributed integers in a given range",
        "randint Uniformly distributed integers in"
    ],
    [
        "seed                 Seed the legacy random number generator.",
        "seed Seed the legacy random number"
    ],
    [
        "zipf                 Zipf's distribution over ranked data.",
        "zipf Zipf's distribution"
    ],
    [
        "dirichlet            Multivariate generalization of Beta distribution.",
        "dirichlet Multivariate generalization"
    ],
    [
        "multinomial          Multivariate generalization of the binomial distribution.",
        "multinomial Multivariate generalization of the"
    ],
    [
        "multivariate_normal  Multivariate generalization of the normal distribution.",
        "multivariate_normal Multivariate generalization of the normal"
    ],
    [
        "get_state            Get tuple representing internal state of generator.",
        "get_state Get tuple representing internal state"
    ],
    [
        "This function exists solely to assist (un)pickling.",
        "This function exists solely to assist"
    ],
    [
        "Note that the state of the RandomState returned here is irrelevant, as this",
        "Note that the state of the RandomState returned here is"
    ],
    [
        "function's entire purpose is to return a newly allocated RandomState whose",
        "function's entire purpose is to return a newly"
    ],
    [
        "state pickle can set.  Consequently the RandomState returned by this function",
        "state pickle can set. Consequently the RandomState returned"
    ],
    [
        "raise AssertionError(\"No error should have been raised, \"",
        "raise AssertionError(\"No error should"
    ],
    [
        "\"but one was with the following \"",
        "\"but one was with the"
    ],
    [
        "raise AssertionError(\"No error should have been raised, \"",
        "raise AssertionError(\"No error should have been raised,"
    ],
    [
        "\"but one was with the following \"",
        "\"but one was with the"
    ],
    [
        "scalar = random.integers(lbnd, ubnd, size=size, endpoint=endpoint,",
        "scalar = random.integers(lbnd, ubnd, size=size,"
    ],
    [
        "array = random.integers([lbnd] * size, [ubnd] *",
        "array = random.integers([lbnd] *"
    ],
    [
        "actual = random.integers(lbnd, ubnd, endpoint=endpoint, dtype=dt)",
        "actual = random.integers(lbnd,"
    ],
    [
        "dt = np.bool if dt is bool else dt",
        "dt = np.bool if dt is bool"
    ],
    [
        "sample = self.rfunc(lbnd, ubnd, endpoint=endpoint, dtype=dt)",
        "sample = self.rfunc(lbnd,"
    ],
    [
        "sample = self.rfunc(lbnd, ubnd, endpoint=endpoint, dtype=dt)",
        "sample = self.rfunc(lbnd, ubnd,"
    ],
    [
        "dt = np.bool if dt is bool else dt",
        "dt = np.bool if dt is bool"
    ],
    [
        "sample = self.rfunc([lbnd], [ubnd], endpoint=endpoint, dtype=dt)",
        "sample = self.rfunc([lbnd], [ubnd],"
    ],
    [
        "desired = np.array(['a', 'a', 'c', 'c'])",
        "desired = np.array(['a',"
    ],
    [
        "for conv in [lambda x: np.array([]),",
        "for conv in [lambda x:"
    ],
    [
        "lambda x: [(i, i) for i in x],",
        "lambda x: [(i, i) for i in"
    ],
    [
        "lambda x: np.asarray([[i, i] for i in x]),",
        "lambda x: np.asarray([[i, i] for i"
    ],
    [
        "lambda x: (np.asarray([(i, i) for i in x],",
        "lambda x: (np.asarray([(i, i)"
    ],
    [
        "lambda x: np.asarray([(i, i) for i in x],",
        "lambda x: np.asarray([(i, i)"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "actual = random.multivariate_normal(mean, cov, size, method=method)",
        "actual = random.multivariate_normal(mean,"
    ],
    [
        "with pytest.raises(TypeError, match=\"must not be complex\"):",
        "with pytest.raises(TypeError, match=\"must not"
    ],
    [
        "s = random.multivariate_normal(mean, cov, size=(n_s,), method=method)",
        "s = random.multivariate_normal(mean, cov, size=(n_s,),"
    ],
    [
        "assert_(np.all(r > -np.pi) and np.all(r <= np.pi))",
        "assert_(np.all(r > -np.pi) and np.all(r <="
    ],
    [
        "n_shape = () if isinstance(n, int) else n.shape",
        "n_shape = () if isinstance(n, int) else"
    ],
    [
        "out = func(low, high, endpoint=endpoint, dtype=dt)",
        "out = func(low, high,"
    ],
    [
        "msg = 'low > high' if endpoint else 'low >= high'",
        "msg = 'low > high' if"
    ],
    [
        "ctor, (bit_gen, ), _ = rg.__reduce__()",
        "ctor, (bit_gen, ), _ ="
    ],
    [
        "\"\"\"Ensures that the singleton bitgen is restored after a test\"\"\"",
        "\"\"\"Ensures that the singleton bitgen is restored"
    ],
    [
        "raise AssertionError(\"No error should have been raised, \"",
        "raise AssertionError(\"No error should have"
    ],
    [
        "\"but one was with the following \"",
        "\"but one was with the following"
    ],
    [
        "op_dtype = \"long\" if dt is int else \"bool\"",
        "op_dtype = \"long\" if dt is"
    ],
    [
        "desired = np.array(['c', 'd', 'c', 'd'])",
        "desired = np.array(['c', 'd', 'c',"
    ],
    [
        "for conv in [lambda x: np.array([]),",
        "for conv in [lambda"
    ],
    [
        "lambda x: [(i, i) for i in x],",
        "lambda x: [(i, i) for i in"
    ],
    [
        "lambda x: np.asarray([[i, i] for i in x]),",
        "lambda x: np.asarray([[i, i] for i in"
    ],
    [
        "lambda x: (np.asarray([(i, i) for i in x],",
        "lambda x: (np.asarray([(i, i) for i in"
    ],
    [
        "lambda x: np.asarray([(i, i) for i in x],",
        "lambda x: np.asarray([(i, i)"
    ],
    [
        "from numpy.testing import (assert_equal, assert_allclose, assert_array_equal,",
        "from numpy.testing import (assert_equal,"
    ],
    [
        "\"\"\" Test spawning new generators and bit_generators directly.",
        "\"\"\" Test spawning new generators and bit_generators"
    ],
    [
        "assert [c.spawn_key for c in new_ss] == expected_keys",
        "assert [c.spawn_key for c"
    ],
    [
        "assert [bg.seed_seq.spawn_key for bg in new_bgs] == expected_keys",
        "assert [bg.seed_seq.spawn_key for bg in new_bgs] =="
    ],
    [
        "found_keys = [rng.bit_generator.seed_seq.spawn_key for rng in new_rngs]",
        "found_keys = [rng.bit_generator.seed_seq.spawn_key for rng"
    ],
    [
        "return {'seed': seed, 'data': np.array(data, dtype=cls.dtype)}",
        "return {'seed': seed, 'data':"
    ],
    [
        "from Cython.Compiler.Version import version as cython_version",
        "from Cython.Compiler.Version import"
    ],
    [
        "reason='Editable install cannot find .pxd headers'",
        "reason='Editable install cannot"
    ],
    [
        "build_dir = tmp_path / 'random' / '_examples' / 'cython'",
        "build_dir = tmp_path / 'random' / '_examples'"
    ],
    [
        "g = glob.glob(str(target_dir / \"*\" / \"extending.pyx.c\"))",
        "g = glob.glob(str(target_dir / \"*\" /"
    ],
    [
        "txt_to_find = 'NumPy API declarations from \"numpy/__init__'",
        "txt_to_find = 'NumPy API declarations from"
    ],
    [
        "assert False, (\"Could not find '{}' in C file, \"",
        "assert False, (\"Could not find '{}' in C"
    ],
    [
        "@pytest.mark.skipif(numba is None or cffi is None,",
        "@pytest.mark.skipif(numba is None or"
    ],
    [
        "from numpy.testing import assert_equal, assert_, assert_array_equal",
        "from numpy.testing import assert_equal, assert_,"
    ],
    [
        "pytest.skip(f'Advance is not supported by {bitgen_name}')",
        "pytest.skip(f'Advance is not"
    ],
    [
        "pytest.skip(f'Jump is not supported by {bitgen_name}')",
        "pytest.skip(f'Jump is not supported by"
    ],
    [
        "pytest.skip(f'Vector seeding is not supported by {bitgen_name}')",
        "pytest.skip(f'Vector seeding is not supported by"
    ],
    [
        "assert_(np.all(r > -np.pi) and np.all(r <= np.pi))",
        "assert_(np.all(r > -np.pi) and np.all(r"
    ],
    [
        "probs = np.array(counts, dtype=dt) / sum(counts)",
        "probs = np.array(counts, dtype=dt) /"
    ],
    [
        "\"\"\" Check that SeedSequence generates data the same as the C++ reference.",
        "\"\"\" Check that SeedSequence generates data the same as"
    ],
    [
        "\"\"\" Ensure that the implicit zero-padding does not cause problems.",
        "\"\"\" Ensure that the implicit zero-padding"
    ],
    [
        "assert_(np.all(r > -np.pi) and np.all(r <= np.pi))",
        "assert_(np.all(r > -np.pi) and"
    ],
    [
        "probs = np.array(counts, dtype=dt) / sum(counts)",
        "probs = np.array(counts, dtype=dt) /"
    ],
    [
        "raise AssertionError(\"No error should have been raised, \"",
        "raise AssertionError(\"No error should"
    ],
    [
        "\"but one was with the following \"",
        "\"but one was with the"
    ],
    [
        "desired = np.array(['c', 'd', 'c', 'd'])",
        "desired = np.array(['c', 'd',"
    ],
    [
        "for conv in [lambda x: np.array([]),",
        "for conv in"
    ],
    [
        "lambda x: [(i, i) for i in x],",
        "lambda x: [(i, i) for i"
    ],
    [
        "lambda x: np.asarray([[i, i] for i in x]),",
        "lambda x: np.asarray([[i, i]"
    ],
    [
        "lambda x: (np.asarray([(i, i) for i in x],",
        "lambda x: (np.asarray([(i, i) for i"
    ],
    [
        "lambda x: np.asarray([(i, i) for i in x],",
        "lambda x: np.asarray([(i, i)"
    ],
    [
        "match=\"you are shuffling a 'dict' object\") as rec:",
        "match=\"you are shuffling a"
    ],
    [
        "item_ids = {id(i) for i in items}",
        "item_ids = {id(i) for i"
    ],
    [
        "assert all(id(i) in item_ids for i in arr)",
        "assert all(id(i) in item_ids for i"
    ],
    [
        "if use_array_like and not isinstance(random, np.random.Generator):",
        "if use_array_like and not isinstance(random,"
    ],
    [
        "assert all(id(i) in item_ids for i in arr)",
        "assert all(id(i) in item_ids"
    ],
    [
        "assert_(np.all(r > -np.pi) and np.all(r <= np.pi))",
        "assert_(np.all(r > -np.pi) and np.all(r <="
    ],
    [
        "probs = np.array(counts, dtype=dt) / sum(counts)",
        "probs = np.array(counts, dtype=dt) /"
    ],
    [
        "Parse distributions.h located in inc_dir for CFFI, filling in the ffi.cdef",
        "Parse distributions.h located in inc_dir for CFFI,"
    ],
    [
        "be filled in when loading the library.",
        "be filled in when"
    ],
    [
        "with open(os.path.join(inc_dir, 'random', 'bitgen.h')) as fid:",
        "with open(os.path.join(inc_dir, 'random', 'bitgen.h'))"
    ],
    [
        "with open(os.path.join(inc_dir, 'random', 'distributions.h')) as fid:",
        "with open(os.path.join(inc_dir, 'random',"
    ],
    [
        "Use cffi to access any of the underlying C functions from distributions.h",
        "Use cffi to access any of the underlying C"
    ],
    [
        "mask = delta = ub - lb",
        "mask = delta = ub"
    ],
    [
        "Building the required library in this example requires a source distribution",
        "Building the required library in this example requires a"
    ],
    [
        "of NumPy or clone of the NumPy git repository since distributions.c is not",
        "of NumPy or clone of the NumPy git"
    ],
    [
        "gcc -shared -o libdistributions.so -fPIC distributions.c \\",
        "gcc -shared -o libdistributions.so"
    ],
    [
        "rem PYTHON_HOME and PYTHON_VERSION are setup dependent, this is an example",
        "rem PYTHON_HOME and PYTHON_VERSION are setup dependent,"
    ],
    [
        "raise RuntimeError('Required DLL/so file was not found.')",
        "raise RuntimeError('Required DLL/so file was not"
    ],
    [
        "\"\"\"Sub-package containing the matrix class and related functions.",
        "\"\"\"Sub-package containing the matrix class and related"
    ],
    [
        "raise ValueError(\"Rows not the same size.\")",
        "raise ValueError(\"Rows not"
    ],
    [
        "Interpret the input as a matrix.",
        "Interpret the input as"
    ],
    [
        "Unlike `matrix`, `asmatrix` does not make a copy if the input is already",
        "Unlike `matrix`, `asmatrix` does not make a copy if the input"
    ],
    [
        "a matrix or an ndarray.  Equivalent to ``matrix(data, copy=False)``.",
        "a matrix or an ndarray."
    ],
    [
        "Returns a matrix from an array-like object, or from a string of data.",
        "Returns a matrix from an array-like object, or from a"
    ],
    [
        "through operations.  It has certain special operators, such as ``*``",
        "through operations. It has certain special operators, such as"
    ],
    [
        "(matrix multiplication) and ``**`` (matrix power).",
        "(matrix multiplication) and ``**`` (matrix"
    ],
    [
        ".. note:: It is no longer recommended to use this class, even for linear",
        ".. note:: It is no longer recommended to"
    ],
    [
        "algebra. Instead use regular arrays. The class may be removed",
        "algebra. Instead use regular arrays. The"
    ],
    [
        "If `data` is a string, it is interpreted as a matrix with commas",
        "If `data` is a string, it is"
    ],
    [
        "or spaces separating columns, and semicolons separating rows.",
        "or spaces separating columns,"
    ],
    [
        "If `data` is already an `ndarray`, then this flag determines",
        "If `data` is already an"
    ],
    [
        "whether the data is copied (the default), or whether a view is",
        "whether the data is copied (the default), or whether a view"
    ],
    [
        "warnings.warn('the matrix subclass is not the recommended way to '",
        "warnings.warn('the matrix subclass is not"
    ],
    [
        "'represent matrices or deal with linear algebra (see '",
        "'represent matrices or deal with linear algebra"
    ],
    [
        "'Please adjust your code to use regular ndarray.',",
        "'Please adjust your code to use"
    ],
    [
        "copy = None if not copy else True",
        "copy = None if"
    ],
    [
        "raise ValueError(\"shape too large to be a matrix.\")",
        "raise ValueError(\"shape too large to be"
    ],
    [
        "if isscalar(other) or not hasattr(other, '__rmul__'):",
        "if isscalar(other) or not"
    ],
    [
        "\"\"\"A convenience function for operations that need to preserve axis",
        "\"\"\"A convenience function for operations that need to preserve"
    ],
    [
        "\"\"\"A convenience function for operations that want to collapse",
        "\"\"\"A convenience function for operations"
    ],
    [
        "to a scalar like _align, but are using keepdims=True",
        "to a scalar like _align, but are"
    ],
    [
        "Return the matrix as a (possibly nested) list.",
        "Return the matrix as a (possibly"
    ],
    [
        "Returns the sum of the matrix elements, along the given axis.",
        "Returns the sum of the matrix elements, along the given"
    ],
    [
        "Refer to `numpy.sum` for full documentation.",
        "Refer to `numpy.sum`"
    ],
    [
        "This is the same as `ndarray.sum`, except that where an `ndarray` would",
        "This is the same as `ndarray.sum`, except that where"
    ],
    [
        "be returned, a `matrix` object is returned instead.",
        "be returned, a `matrix` object"
    ],
    [
        "return N.ndarray.sum(self, axis, dtype, out, keepdims=True)._collapse(axis)",
        "return N.ndarray.sum(self, axis, dtype, out,"
    ],
    [
        "Refer to `numpy.squeeze` for more documentation.",
        "Refer to `numpy.squeeze` for"
    ],
    [
        "axis : None or int or tuple of ints, optional",
        "axis : None or int or tuple of ints,"
    ],
    [
        "Selects a subset of the axes of length one in the shape.",
        "Selects a subset of the axes of length"
    ],
    [
        "If an axis is selected with shape entry greater than one,",
        "If an axis is selected with shape entry"
    ],
    [
        "If `m` has a single column then that column is returned",
        "If `m` has a single column then that"
    ],
    [
        "as the single row of a matrix.  Otherwise `m` is returned.",
        "as the single row of a matrix. Otherwise `m`"
    ],
    [
        "The returned matrix is always either `m` itself or a view into `m`.",
        "The returned matrix is always either `m` itself"
    ],
    [
        "Supplying an axis keyword argument will not affect the returned matrix",
        "Supplying an axis keyword argument will not"
    ],
    [
        "but it may cause an error to be raised.",
        "but it may cause an"
    ],
    [
        "Return a flattened copy of the matrix.",
        "Return a flattened copy"
    ],
    [
        "All `N` elements of the matrix are placed into a single row.",
        "All `N` elements of the matrix are placed into a"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F',"
    ],
    [
        "'C' means to flatten in row-major (C-style) order. 'F' means to",
        "'C' means to flatten in row-major (C-style)"
    ],
    [
        "flatten in column-major (Fortran-style) order. 'A' means to",
        "flatten in column-major (Fortran-style) order. 'A'"
    ],
    [
        "flatten in column-major order if `m` is Fortran *contiguous* in",
        "flatten in column-major order if `m` is Fortran *contiguous*"
    ],
    [
        "memory, row-major order otherwise. 'K' means to flatten `m` in",
        "memory, row-major order otherwise. 'K' means to flatten"
    ],
    [
        "the order the elements occur in memory. The default is 'C'.",
        "the order the elements occur in"
    ],
    [
        "is the number of elements in the original matrix.",
        "is the number of elements in the"
    ],
    [
        "ravel : Return a flattened array.",
        "ravel : Return"
    ],
    [
        "Returns the average of the matrix elements along the given axis.",
        "Returns the average of the matrix"
    ],
    [
        "Refer to `numpy.mean` for full documentation.",
        "Refer to `numpy.mean` for"
    ],
    [
        "Same as `ndarray.mean` except that, where that returns an `ndarray`,",
        "Same as `ndarray.mean` except that, where that returns"
    ],
    [
        "return N.ndarray.mean(self, axis, dtype, out, keepdims=True)._collapse(axis)",
        "return N.ndarray.mean(self, axis, dtype,"
    ],
    [
        "Return the standard deviation of the array elements along the given axis.",
        "Return the standard deviation of the array elements along"
    ],
    [
        "Refer to `numpy.std` for full documentation.",
        "Refer to `numpy.std`"
    ],
    [
        "This is the same as `ndarray.std`, except that where an `ndarray` would",
        "This is the same as `ndarray.std`, except that where an `ndarray`"
    ],
    [
        "be returned, a `matrix` object is returned instead.",
        "be returned, a `matrix`"
    ],
    [
        "return N.ndarray.std(self, axis, dtype, out, ddof,",
        "return N.ndarray.std(self, axis,"
    ],
    [
        "Returns the variance of the matrix elements, along the given axis.",
        "Returns the variance of the matrix elements, along the given"
    ],
    [
        "Refer to `numpy.var` for full documentation.",
        "Refer to `numpy.var` for"
    ],
    [
        "This is the same as `ndarray.var`, except that where an `ndarray` would",
        "This is the same as `ndarray.var`, except that where"
    ],
    [
        "be returned, a `matrix` object is returned instead.",
        "be returned, a `matrix` object is"
    ],
    [
        "return N.ndarray.var(self, axis, dtype, out, ddof,",
        "return N.ndarray.var(self, axis, dtype, out,"
    ],
    [
        "Return the product of the array elements over the given axis.",
        "Return the product of the array"
    ],
    [
        "Refer to `prod` for full documentation.",
        "Refer to `prod` for"
    ],
    [
        "Same as `ndarray.prod`, except, where that returns an `ndarray`, this",
        "Same as `ndarray.prod`, except, where that"
    ],
    [
        "return N.ndarray.prod(self, axis, dtype, out, keepdims=True)._collapse(axis)",
        "return N.ndarray.prod(self, axis, dtype, out,"
    ],
    [
        "Test whether any array element along a given axis evaluates to True.",
        "Test whether any array element along"
    ],
    [
        "Refer to `numpy.any` for full documentation.",
        "Refer to `numpy.any` for full"
    ],
    [
        "Axis along which logical OR is performed",
        "Axis along which logical"
    ],
    [
        "Output to existing array instead of creating new one, must have",
        "Output to existing array instead of creating"
    ],
    [
        "Returns a single bool if `axis` is ``None``; otherwise,",
        "Returns a single bool if"
    ],
    [
        "Test whether all matrix elements along a given axis evaluate to True.",
        "Test whether all matrix elements along a given"
    ],
    [
        "This is the same as `ndarray.all`, but it returns a `matrix` object.",
        "This is the same as `ndarray.all`, but"
    ],
    [
        "Return the maximum value along an axis.",
        "Return the maximum value along"
    ],
    [
        "This is the same as `ndarray.max`, but returns a `matrix` object",
        "This is the same as `ndarray.max`, but returns a"
    ],
    [
        "where `ndarray.max` would return an ndarray.",
        "where `ndarray.max` would return"
    ],
    [
        "Indexes of the maximum values along an axis.",
        "Indexes of the maximum values along an"
    ],
    [
        "Return the indexes of the first occurrences of the maximum values",
        "Return the indexes of the first"
    ],
    [
        "along the specified axis.  If axis is None, the index is for the",
        "along the specified axis. If axis is None, the index"
    ],
    [
        "This is the same as `ndarray.argmax`, but returns a `matrix` object",
        "This is the same as `ndarray.argmax`, but returns a"
    ],
    [
        "where `ndarray.argmax` would return an `ndarray`.",
        "where `ndarray.argmax` would return"
    ],
    [
        "Return the minimum value along an axis.",
        "Return the minimum value"
    ],
    [
        "This is the same as `ndarray.min`, but returns a `matrix` object",
        "This is the same as `ndarray.min`, but"
    ],
    [
        "where `ndarray.min` would return an ndarray.",
        "where `ndarray.min` would"
    ],
    [
        "Indexes of the minimum values along an axis.",
        "Indexes of the minimum values"
    ],
    [
        "Return the indexes of the first occurrences of the minimum values",
        "Return the indexes of the first occurrences of the"
    ],
    [
        "along the specified axis.  If axis is None, the index is for the",
        "along the specified axis. If axis is"
    ],
    [
        "This is the same as `ndarray.argmin`, but returns a `matrix` object",
        "This is the same as `ndarray.argmin`, but returns a"
    ],
    [
        "where `ndarray.argmin` would return an `ndarray`.",
        "where `ndarray.argmin` would"
    ],
    [
        "Peak-to-peak (maximum - minimum) value along the given axis.",
        "Peak-to-peak (maximum - minimum) value along the given"
    ],
    [
        "Refer to `numpy.ptp` for full documentation.",
        "Refer to `numpy.ptp` for full"
    ],
    [
        "Same as `ndarray.ptp`, except, where that would return an `ndarray` object,",
        "Same as `ndarray.ptp`, except, where that would return an `ndarray`"
    ],
    [
        "Returns the (multiplicative) inverse of invertible `self`.",
        "Returns the (multiplicative) inverse"
    ],
    [
        "If `self` is non-singular, `ret` is such that ``ret * self`` ==",
        "If `self` is non-singular, `ret` is such that ``ret *"
    ],
    [
        "from numpy.linalg import inv as func",
        "from numpy.linalg import inv"
    ],
    [
        "from numpy.linalg import pinv as func",
        "from numpy.linalg import pinv"
    ],
    [
        "Return `self` as an `ndarray` object.",
        "Return `self` as an"
    ],
    [
        "Return `self` as a flattened `ndarray`.",
        "Return `self` as"
    ],
    [
        "Refer to `numpy.ravel` for more documentation.",
        "Refer to `numpy.ravel` for more"
    ],
    [
        "order : {'C', 'F', 'A', 'K'}, optional",
        "order : {'C', 'F',"
    ],
    [
        "The elements of `m` are read using this index order. 'C' means to",
        "The elements of `m` are read using this index"
    ],
    [
        "index the elements in C-like order, with the last axis index",
        "index the elements in C-like order,"
    ],
    [
        "changing fastest, back to the first axis index changing slowest.",
        "changing fastest, back to the first axis"
    ],
    [
        "'F' means to index the elements in Fortran-like index order, with",
        "'F' means to index the elements in Fortran-like index"
    ],
    [
        "the first index changing fastest, and the last index changing",
        "the first index changing fastest, and"
    ],
    [
        "slowest. Note that the 'C' and 'F' options take no account of the",
        "slowest. Note that the 'C' and 'F' options take no account of"
    ],
    [
        "memory layout of the underlying array, and only refer to the order",
        "memory layout of the underlying array, and only"
    ],
    [
        "of axis indexing.  'A' means to read the elements in Fortran-like",
        "of axis indexing. 'A' means to read the"
    ],
    [
        "index order if `m` is Fortran *contiguous* in memory, C-like order",
        "index order if `m` is Fortran"
    ],
    [
        "otherwise.  'K' means to read the elements in the order they occur",
        "otherwise. 'K' means to read the"
    ],
    [
        "in memory, except for reversing the data when strides are negative.",
        "in memory, except for reversing the"
    ],
    [
        "By default, 'C' index order is used.",
        "By default, 'C' index"
    ],
    [
        "is the number of elements in the original matrix.",
        "is the number of elements"
    ],
    [
        "A copy is made only if necessary.",
        "A copy is made"
    ],
    [
        "matrix.flatten : returns a similar output matrix but always a copy",
        "matrix.flatten : returns a similar output matrix"
    ],
    [
        "matrix.flat : a flat iterator on the array.",
        "matrix.flat : a flat iterator on the"
    ],
    [
        "numpy.ravel : related function which returns an ndarray",
        "numpy.ravel : related function which returns"
    ],
    [
        "Returns the transpose of the matrix.",
        "Returns the transpose of the"
    ],
    [
        "Does *not* conjugate!  For the complex conjugate transpose, use ``.H``.",
        "Does *not* conjugate! For the complex conjugate"
    ],
    [
        "The (non-conjugated) transpose of the matrix.",
        "The (non-conjugated) transpose"
    ],
    [
        "Returns the (complex) conjugate transpose of `self`.",
        "Returns the (complex) conjugate"
    ],
    [
        "Equivalent to ``np.transpose(self)`` if `self` is real-valued.",
        "Equivalent to ``np.transpose(self)`` if `self`"
    ],
    [
        "raise NameError(f\"name {col!r} is not defined\") from None",
        "raise NameError(f\"name {col!r} is"
    ],
    [
        "Build a matrix object from a string, nested sequence, or array.",
        "Build a matrix object from a string,"
    ],
    [
        "Input data. If a string, variables in the current scope may be",
        "Input data. If a string, variables in the current"
    ],
    [
        "A dictionary that replaces local operands in current frame.",
        "A dictionary that replaces local"
    ],
    [
        "Ignored if `obj` is not a string or `gdict` is None.",
        "Ignored if `obj` is not a string"
    ],
    [
        "A dictionary that replaces global operands in current frame.",
        "A dictionary that replaces global operands in"
    ],
    [
        "Ignored if `obj` is not a string.",
        "Ignored if `obj` is not"
    ],
    [
        "A generalization of this function for N-d arrays, that returns normal",
        "A generalization of this function for N-d"
    ],
    [
        "All the following expressions construct the same block matrix:",
        "All the following expressions construct the same"
    ],
    [
        "\"\"\" Test functions for linalg module using the matrix class.\"\"\"",
        "\"\"\" Test functions for linalg module using"
    ],
    [
        "LinalgCase, apply_tag, TestQR as _TestQR, LinalgTestCase,",
        "LinalgCase, apply_tag, TestQR"
    ],
    [
        "SolveCases, InvCases, EigvalsCases, EigCases, SVDCases, CondCases,",
        "SolveCases, InvCases, EigvalsCases,"
    ],
    [
        "from numpy import matrix, asmatrix, bmat",
        "from numpy import matrix, asmatrix,"
    ],
    [
        "C = bmat([[A, A], [A, A]])",
        "C = bmat([[A, A],"
    ],
    [
        "np.all(bmat(\"A,A;A,A\", ldict={'A': A}, gdict={'A': B}) == Aresult))",
        "np.all(bmat(\"A,A;A,A\", ldict={'A': A}, gdict={'A':"
    ],
    [
        "assert_(np.allclose((mA + mA).A, (A + A)))",
        "assert_(np.allclose((mA + mA).A,"
    ],
    [
        "\"\"\"Test raising a matrix to an integer power works as expected.\"\"\"",
        "\"\"\"Test raising a matrix to an integer power works"
    ],
    [
        "'''Check that 'not implemented' operations produce a failure.'''",
        "'''Check that 'not implemented' operations produce"
    ],
    [
        "'argmin', 'choose', 'dump', 'dumps', 'fill', 'getfield',",
        "'argmin', 'choose', 'dump', 'dumps',"
    ],
    [
        "'take', 'tofile', 'tolist', 'tobytes', 'all', 'any',",
        "'take', 'tofile', 'tolist', 'tobytes', 'all',"
    ],
    [
        "'sum', 'argmax', 'argmin', 'min', 'max', 'mean', 'var', 'ptp',",
        "'sum', 'argmax', 'argmin', 'min',"
    ],
    [
        "if attrib.startswith('_') or attrib in excluded_methods:",
        "if attrib.startswith('_') or attrib"
    ],
    [
        "assert_(type(b) is matrix, \"%s\" % attrib)",
        "assert_(type(b) is matrix, \"%s\""
    ],
    [
        "\"\"\"Tests of interaction of matrix with other parts of numpy.",
        "\"\"\"Tests of interaction of matrix with other parts of"
    ],
    [
        "Note that tests with MaskedArray and linalg are done in separate files.",
        "Note that tests with MaskedArray and linalg are"
    ],
    [
        "from numpy.testing import (assert_, assert_equal, assert_raises,",
        "from numpy.testing import"
    ],
    [
        "for dt in np.typecodes['AllInteger'] + np.typecodes['AllFloat'] + '?':",
        "for dt in np.typecodes['AllInteger'] +"
    ],
    [
        "i = np.nditer([a, b, None], [],",
        "i = np.nditer([a, b, None],"
    ],
    [
        "assert_raises(RuntimeError, np.nditer, [a, b, None], [],",
        "assert_raises(RuntimeError, np.nditer, [a, b, None],"
    ],
    [
        "i = np.nditer([a, b, None], [],",
        "i = np.nditer([a,"
    ],
    [
        "for like_function in np.zeros_like, np.ones_like, np.empty_like:",
        "for like_function in np.zeros_like, np.ones_like,"
    ],
    [
        "assert_raises_regex(ValueError, 'shape too large to be a matrix',",
        "assert_raises_regex(ValueError, 'shape too large to be a"
    ],
    [
        "for f in (np.nanargmin, np.nanargmax, np.nansum, np.nanprod,",
        "for f in (np.nanargmin, np.nanargmax,"
    ],
    [
        "actual = np.r_['a, b; c, d']",
        "actual = np.r_['a,"
    ],
    [
        "expected = np.bmat([[a, b], [c, d]])",
        "expected = np.bmat([[a,"
    ],
    [
        "from numpy.ma.testutils import (assert_, assert_equal, assert_raises,",
        "from numpy.ma.testutils import"
    ],
    [
        "from numpy.ma.core import (masked_array, masked_values, masked, allequal,",
        "from numpy.ma.core import (masked_array,"
    ],
    [
        "a = masked_array(iterator, dtype=[('a', float), ('b', float)])",
        "a = masked_array(iterator, dtype=[('a',"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_array_equal",
        "from numpy.testing import assert_,"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import"
    ],
    [
        "This module provides a number of objects (mostly functions) useful for",
        "This module provides a number of"
    ],
    [
        "dealing with Laguerre series, including a `Laguerre` class that",
        "dealing with Laguerre series, including a `Laguerre` class"
    ],
    [
        "encapsulates the usual arithmetic operations.  (General information",
        "encapsulates the usual arithmetic operations. (General"
    ],
    [
        "on how this module represents and works with such polynomials is in the",
        "on how this module represents and works with such polynomials"
    ],
    [
        "docstring for its \"parent\" sub-package, `numpy.polynomial`).",
        "docstring for its \"parent\""
    ],
    [
        "from . import polyutils as pu",
        "from . import polyutils as"
    ],
    [
        "'lagzero', 'lagone', 'lagx', 'lagdomain', 'lagline', 'lagadd',",
        "'lagzero', 'lagone', 'lagx',"
    ],
    [
        "'lagsub', 'lagmulx', 'lagmul', 'lagdiv', 'lagpow', 'lagval', 'lagder',",
        "'lagsub', 'lagmulx', 'lagmul', 'lagdiv',"
    ],
    [
        "Convert a polynomial to a Laguerre series.",
        "Convert a polynomial to a"
    ],
    [
        "Convert an array representing the coefficients of a polynomial (relative",
        "Convert an array representing the coefficients"
    ],
    [
        "to the \"standard\" basis) ordered from lowest degree to highest, to an",
        "to the \"standard\" basis) ordered from lowest degree"
    ],
    [
        "array of the coefficients of the equivalent Laguerre series, ordered",
        "array of the coefficients of the equivalent Laguerre series,"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do conversions"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert method of a class"
    ],
    [
        "Convert a Laguerre series to a polynomial.",
        "Convert a Laguerre series to"
    ],
    [
        "Convert an array representing the coefficients of a Laguerre series,",
        "Convert an array representing the coefficients of a Laguerre"
    ],
    [
        "ordered from lowest degree to highest, to an array of the coefficients",
        "ordered from lowest degree to highest,"
    ],
    [
        "of the equivalent polynomial (relative to the \"standard\" basis) ordered",
        "of the equivalent polynomial (relative to the"
    ],
    [
        "from lowest order term to highest.",
        "from lowest order term"
    ],
    [
        "(relative to the \"standard\" basis) ordered from lowest order term",
        "(relative to the \"standard\" basis) ordered"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do conversions"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert method of"
    ],
    [
        "from .polynomial import polyadd, polysub, polymulx",
        "from .polynomial import polyadd, polysub,"
    ],
    [
        "Laguerre series whose graph is a straight line.",
        "Laguerre series whose graph"
    ],
    [
        "The specified line is given by ``off + scl*x``.",
        "The specified line is given"
    ],
    [
        "This module's representation of the Laguerre series for",
        "This module's representation of the Laguerre series"
    ],
    [
        ">>> from numpy.polynomial.laguerre import lagline, lagval",
        ">>> from numpy.polynomial.laguerre import"
    ],
    [
        "Generate a Laguerre series with given roots.",
        "Generate a Laguerre series"
    ],
    [
        "The function returns the coefficients of the polynomial",
        "The function returns the coefficients of"
    ],
    [
        "in Laguerre form, where the :math:`r_n` are the roots specified in `roots`.",
        "in Laguerre form, where the :math:`r_n` are the roots specified"
    ],
    [
        "If a zero has multiplicity n, then it must appear in `roots` n times.",
        "If a zero has multiplicity n, then it must"
    ],
    [
        "roots can appear in any order.",
        "roots can appear"
    ],
    [
        "If the returned coefficients are `c`, then",
        "If the returned coefficients"
    ],
    [
        "real array, if some of the roots are complex, then `out` is complex",
        "real array, if some of the roots are complex, then `out` is"
    ],
    [
        "even if all the coefficients in the result are real (see Examples",
        "even if all the coefficients in the result are real"
    ],
    [
        ">>> from numpy.polynomial.laguerre import lagfromroots, lagval",
        ">>> from numpy.polynomial.laguerre"
    ],
    [
        "Add one Laguerre series to another.",
        "Add one Laguerre"
    ],
    [
        "are sequences of coefficients ordered from lowest order term to",
        "are sequences of coefficients ordered"
    ],
    [
        "Array representing the Laguerre series of their sum.",
        "Array representing the Laguerre"
    ],
    [
        "Unlike multiplication, division, etc., the sum of two Laguerre series",
        "Unlike multiplication, division, etc., the sum of two Laguerre"
    ],
    [
        "is a Laguerre series (without having to \"reproject\" the result onto",
        "is a Laguerre series (without having to \"reproject\" the result"
    ],
    [
        "the basis set) so addition, just like that of \"standard\" polynomials,",
        "the basis set) so addition, just like that of"
    ],
    [
        "Subtract one Laguerre series from another.",
        "Subtract one Laguerre series from"
    ],
    [
        "sequences of coefficients are from lowest order term to highest, i.e.,",
        "sequences of coefficients are from lowest order"
    ],
    [
        "Of Laguerre series coefficients representing their difference.",
        "Of Laguerre series coefficients representing their"
    ],
    [
        "Unlike multiplication, division, etc., the difference of two Laguerre",
        "Unlike multiplication, division, etc., the"
    ],
    [
        "series is a Laguerre series (without having to \"reproject\" the result",
        "series is a Laguerre series (without"
    ],
    [
        "onto the basis set) so subtraction, just like that of \"standard\"",
        "onto the basis set) so subtraction,"
    ],
    [
        "\"\"\"Multiply a Laguerre series by x.",
        "\"\"\"Multiply a Laguerre series"
    ],
    [
        "Multiply the Laguerre series `c` by x, where x is the independent",
        "Multiply the Laguerre series `c` by x, where x is the"
    ],
    [
        "Array representing the result of the multiplication.",
        "Array representing the result of"
    ],
    [
        "The multiplication uses the recursion relationship for Laguerre",
        "The multiplication uses the recursion relationship"
    ],
    [
        "Multiply one Laguerre series by another.",
        "Multiply one Laguerre series"
    ],
    [
        "are sequences of coefficients, from lowest order \"term\" to highest,",
        "are sequences of coefficients, from lowest order"
    ],
    [
        "Of Laguerre series coefficients representing their product.",
        "Of Laguerre series coefficients representing"
    ],
    [
        "In general, the (polynomial) product of two C-series results in terms",
        "In general, the (polynomial) product of two"
    ],
    [
        "that are not in the Laguerre polynomial basis set.  Thus, to express",
        "that are not in the Laguerre polynomial basis set."
    ],
    [
        "the product as a Laguerre series, it is necessary to \"reproject\" the",
        "the product as a Laguerre series, it is necessary"
    ],
    [
        "product onto said basis set, which may produce \"unintuitive\" (but",
        "product onto said basis set, which may produce"
    ],
    [
        "correct) results; see Examples section below.",
        "correct) results; see Examples"
    ],
    [
        "Divide one Laguerre series by another.",
        "Divide one Laguerre"
    ],
    [
        "Returns the quotient-with-remainder of two Laguerre series",
        "Returns the quotient-with-remainder of two"
    ],
    [
        "Of Laguerre series coefficients representing the quotient and",
        "Of Laguerre series coefficients representing the quotient"
    ],
    [
        "In general, the (polynomial) division of one Laguerre series by another",
        "In general, the (polynomial) division of"
    ],
    [
        "results in quotient and remainder terms that are not in the Laguerre",
        "results in quotient and remainder terms"
    ],
    [
        "polynomial basis set.  Thus, to express these results as a Laguerre",
        "polynomial basis set. Thus, to express these results"
    ],
    [
        "series, it is necessary to \"reproject\" the results onto the Laguerre",
        "series, it is necessary to \"reproject\" the"
    ],
    [
        "basis set, which may produce \"unintuitive\" (but correct) results; see",
        "basis set, which may produce \"unintuitive\" (but correct) results;"
    ],
    [
        "\"\"\"Raise a Laguerre series to a power.",
        "\"\"\"Raise a Laguerre series"
    ],
    [
        "Returns the Laguerre series `c` raised to the power `pow`. The",
        "Returns the Laguerre series `c` raised to"
    ],
    [
        "argument `c` is a sequence of coefficients ordered from low to high.",
        "argument `c` is a sequence of coefficients"
    ],
    [
        "Power to which the series will be raised",
        "Power to which the"
    ],
    [
        "Maximum power allowed. This is mainly to limit growth of the series",
        "Maximum power allowed. This is mainly to limit"
    ],
    [
        "Returns the Laguerre series coefficients `c` differentiated `m` times",
        "Returns the Laguerre series coefficients `c`"
    ],
    [
        "along `axis`.  At each iteration the result is multiplied by `scl` (the",
        "along `axis`. At each iteration the result is multiplied by"
    ],
    [
        "scaling factor is for use in a linear change of variable). The argument",
        "scaling factor is for use in a"
    ],
    [
        "`c` is an array of coefficients from low to high degree along each",
        "`c` is an array of coefficients from low to high degree"
    ],
    [
        "Array of Laguerre series coefficients. If `c` is multidimensional",
        "Array of Laguerre series coefficients. If"
    ],
    [
        "the different axis correspond to different variables with the",
        "the different axis correspond to different"
    ],
    [
        "degree in each axis given by the corresponding index.",
        "degree in each axis given by"
    ],
    [
        "Each differentiation is multiplied by `scl`.  The end result is",
        "Each differentiation is multiplied by `scl`. The end result"
    ],
    [
        "multiplication by ``scl**m``.  This is for use in a linear change of",
        "multiplication by ``scl**m``. This is for use in a linear"
    ],
    [
        "In general, the result of differentiating a Laguerre series does not",
        "In general, the result of differentiating"
    ],
    [
        "resemble the same operation on a power series. Thus the result of this",
        "resemble the same operation on a power series. Thus"
    ],
    [
        "function may be \"unintuitive,\" albeit correct; see Examples section",
        "function may be \"unintuitive,\" albeit correct; see Examples"
    ],
    [
        "cnt = pu._as_int(m, \"the order of derivation\")",
        "cnt = pu._as_int(m, \"the order"
    ],
    [
        "raise ValueError(\"The order of derivation must be non-negative\")",
        "raise ValueError(\"The order of derivation must"
    ],
    [
        "Returns the Laguerre series coefficients `c` integrated `m` times from",
        "Returns the Laguerre series coefficients `c` integrated `m`"
    ],
    [
        "`lbnd` along `axis`. At each iteration the resulting series is",
        "`lbnd` along `axis`. At each"
    ],
    [
        "**multiplied** by `scl` and an integration constant, `k`, is added.",
        "**multiplied** by `scl` and an integration"
    ],
    [
        "The scaling factor is for use in a linear change of variable.  (\"Buyer",
        "The scaling factor is for use in a linear change of"
    ],
    [
        "beware\": note that, depending on what one is doing, one may want `scl`",
        "beware\": note that, depending on what one is doing, one may"
    ],
    [
        "to be the reciprocal of what one might expect; for more information,",
        "to be the reciprocal of what one might expect; for more"
    ],
    [
        "see the Notes section below.)  The argument `c` is an array of",
        "see the Notes section below.) The argument `c` is an array"
    ],
    [
        "Array of Laguerre series coefficients. If `c` is multidimensional",
        "Array of Laguerre series coefficients. If `c` is"
    ],
    [
        "the different axis correspond to different variables with the",
        "the different axis correspond to"
    ],
    [
        "degree in each axis given by the corresponding index.",
        "degree in each axis given by"
    ],
    [
        "k : {[], list, scalar}, optional",
        "k : {[], list,"
    ],
    [
        "Integration constant(s).  The value of the first integral at",
        "Integration constant(s). The value of the"
    ],
    [
        "``lbnd`` is the first value in the list, the value of the second",
        "``lbnd`` is the first value in the list,"
    ],
    [
        "integral at ``lbnd`` is the second value, etc.  If ``k == []`` (the",
        "integral at ``lbnd`` is the second value, etc. If ``k =="
    ],
    [
        "scalar can be given instead of a list.",
        "scalar can be given instead"
    ],
    [
        "Following each integration the result is *multiplied* by `scl`",
        "Following each integration the result is *multiplied*"
    ],
    [
        "Laguerre series coefficients of the integral.",
        "Laguerre series coefficients of the"
    ],
    [
        "Note that the result of each integration is *multiplied* by `scl`.",
        "Note that the result of each"
    ],
    [
        "Why is this important to note?  Say one is making a linear change of",
        "Why is this important to note? Say one"
    ],
    [
        "variable :math:`u = ax + b` in an integral relative to `x`.  Then",
        "variable :math:`u = ax + b` in"
    ],
    [
        ":math:`dx = du/a`, so one will need to set `scl` equal to",
        ":math:`dx = du/a`, so one will need to set `scl` equal"
    ],
    [
        "Also note that, in general, the result of integrating a C-series needs",
        "Also note that, in general, the result"
    ],
    [
        "to be \"reprojected\" onto the C-series basis set.  Thus, typically,",
        "to be \"reprojected\" onto the C-series"
    ],
    [
        "the result of this function is \"unintuitive,\" albeit correct; see",
        "the result of this function"
    ],
    [
        "cnt = pu._as_int(m, \"the order of integration\")",
        "cnt = pu._as_int(m, \"the order"
    ],
    [
        "raise ValueError(\"The order of integration must be non-negative\")",
        "raise ValueError(\"The order of integration must"
    ],
    [
        "raise ValueError(\"lbnd must be a scalar.\")",
        "raise ValueError(\"lbnd must be"
    ],
    [
        "raise ValueError(\"scl must be a scalar.\")",
        "raise ValueError(\"scl must"
    ],
    [
        "Evaluate a Laguerre series at points x.",
        "Evaluate a Laguerre series at"
    ],
    [
        "The parameter `x` is converted to an array only if it is a tuple or a",
        "The parameter `x` is converted to an array only if it is a"
    ],
    [
        "list, otherwise it is treated as a scalar. In either case, either `x`",
        "list, otherwise it is treated as a scalar. In either case, either"
    ],
    [
        "or its elements must support multiplication and addition both with",
        "or its elements must support multiplication and"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the elements of"
    ],
    [
        "`c` is multidimensional, then the shape of the result depends on the",
        "`c` is multidimensional, then the shape of the result depends on"
    ],
    [
        "Trailing zeros in the coefficients will be used in the evaluation, so",
        "Trailing zeros in the coefficients will be used in the evaluation,"
    ],
    [
        "they should be avoided if efficiency is a concern.",
        "they should be avoided if efficiency is a"
    ],
    [
        "If `x` is a list or tuple, it is converted to an ndarray, otherwise",
        "If `x` is a list or tuple, it"
    ],
    [
        "it is left unchanged and treated as a scalar. In either case, `x`",
        "it is left unchanged and treated as a"
    ],
    [
        "or its elements must support addition and multiplication with",
        "or its elements must support addition and multiplication"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the elements of"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients"
    ],
    [
        "degree n are contained in c[n]. If `c` is multidimensional the",
        "degree n are contained in c[n]. If"
    ],
    [
        "remaining indices enumerate multiple polynomials. In the two",
        "remaining indices enumerate multiple polynomials. In"
    ],
    [
        "dimensional case the coefficients may be thought of as stored in",
        "dimensional case the coefficients may be thought of as"
    ],
    [
        "If True, the shape of the coefficient array is extended with ones",
        "If True, the shape of the coefficient array is"
    ],
    [
        "for this action. The result is that every column of coefficients in",
        "for this action. The result is that every column"
    ],
    [
        "`c` is evaluated for every element of `x`. If False, `x` is broadcast",
        "`c` is evaluated for every element of `x`."
    ],
    [
        "over the columns of `c` for the evaluation.  This keyword is useful",
        "over the columns of `c` for the evaluation."
    ],
    [
        "when `c` is multidimensional. The default value is True.",
        "when `c` is multidimensional. The default value is"
    ],
    [
        "The shape of the return value is described above.",
        "The shape of the return value is"
    ],
    [
        "The evaluation uses Clenshaw recursion, aka synthetic division.",
        "The evaluation uses Clenshaw"
    ],
    [
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * L_i(x) * L_j(y)",
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} *"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted to"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars and they",
        "tuples or a lists, otherwise they are treated as a scalars and"
    ],
    [
        "must have the same shape after conversion. In either case, either `x`",
        "must have the same shape after conversion. In either case, either"
    ],
    [
        "and `y` or their elements must support multiplication and addition both",
        "and `y` or their elements must support"
    ],
    [
        "with themselves and with the elements of `c`.",
        "with themselves and with the elements of"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like,"
    ],
    [
        "The two dimensional series is evaluated at the points ``(x, y)``,",
        "The two dimensional series is evaluated at the points"
    ],
    [
        "where `x` and `y` must have the same shape. If `x` or `y` is a list",
        "where `x` and `y` must have the same shape. If `x` or `y` is a"
    ],
    [
        "or tuple, it is first converted to an ndarray, otherwise it is left",
        "or tuple, it is first converted to an ndarray, otherwise"
    ],
    [
        "unchanged and if it isn't an ndarray it is treated as a scalar.",
        "unchanged and if it isn't an ndarray it is treated as a"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term",
        "Array of coefficients ordered so that the coefficient"
    ],
    [
        "of multi-degree i,j is contained in ``c[i,j]``. If `c` has",
        "of multi-degree i,j is contained in ``c[i,j]``. If"
    ],
    [
        "dimension greater than two the remaining indices enumerate multiple",
        "dimension greater than two the remaining indices"
    ],
    [
        "The values of the two dimensional polynomial at points formed with",
        "The values of the two dimensional polynomial at points formed"
    ],
    [
        "pairs of corresponding values from `x` and `y`.",
        "pairs of corresponding values from `x` and"
    ],
    [
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j} * L_i(a) * L_j(b)",
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j}"
    ],
    [
        "where the points ``(a, b)`` consist of all pairs formed by taking",
        "where the points ``(a, b)`` consist of all pairs formed by"
    ],
    [
        "`a` from `x` and `b` from `y`. The resulting points form a grid with",
        "`a` from `x` and `b` from `y`. The"
    ],
    [
        "`x` in the first dimension and `y` in the second.",
        "`x` in the first dimension"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted to arrays only"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars. In either",
        "tuples or a lists, otherwise they are treated as a"
    ],
    [
        "case, either `x` and `y` or their elements must support multiplication",
        "case, either `x` and `y` or their elements must support"
    ],
    [
        "and addition both with themselves and with the elements of `c`.",
        "and addition both with themselves and with the elements of"
    ],
    [
        "If `c` has fewer than two dimensions, ones are implicitly appended to",
        "If `c` has fewer than two dimensions, ones are implicitly appended"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y :"
    ],
    [
        "The two dimensional series is evaluated at the points in the",
        "The two dimensional series is evaluated at the"
    ],
    [
        "Cartesian product of `x` and `y`.  If `x` or `y` is a list or",
        "Cartesian product of `x` and `y`. If `x` or `y` is"
    ],
    [
        "tuple, it is first converted to an ndarray, otherwise it is left",
        "tuple, it is first converted to an ndarray, otherwise it is"
    ],
    [
        "unchanged and, if it isn't an ndarray, it is treated as a scalar.",
        "unchanged and, if it isn't an ndarray, it is treated"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that the coefficient"
    ],
    [
        "multi-degree i,j is contained in ``c[i,j]``. If `c` has dimension",
        "multi-degree i,j is contained in ``c[i,j]``. If `c` has"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining"
    ],
    [
        "The values of the two dimensional Chebyshev series at points in the",
        "The values of the two dimensional Chebyshev series at"
    ],
    [
        "Cartesian product of `x` and `y`.",
        "Cartesian product of"
    ],
    [
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * L_i(x) * L_j(y) * L_k(z)",
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * L_i(x) * L_j(y)"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if",
        "The parameters `x`, `y`, and `z`"
    ],
    [
        "they are tuples or a lists, otherwise they are treated as a scalars and",
        "they are tuples or a lists, otherwise they"
    ],
    [
        "they must have the same shape after conversion. In either case, either",
        "they must have the same shape after conversion. In"
    ],
    [
        "`x`, `y`, and `z` or their elements must support multiplication and",
        "`x`, `y`, and `z` or their elements must"
    ],
    [
        "addition both with themselves and with the elements of `c`.",
        "addition both with themselves and with the elements"
    ],
    [
        "x, y, z : array_like, compatible object",
        "x, y, z :"
    ],
    [
        "The three dimensional series is evaluated at the points",
        "The three dimensional series is evaluated"
    ],
    [
        "``(x, y, z)``, where `x`, `y`, and `z` must have the same shape.  If",
        "``(x, y, z)``, where `x`, `y`, and `z` must"
    ],
    [
        "any of `x`, `y`, or `z` is a list or tuple, it is first converted",
        "any of `x`, `y`, or `z` is a list or tuple, it"
    ],
    [
        "to an ndarray, otherwise it is left unchanged and if it isn't an",
        "to an ndarray, otherwise it is left unchanged and if it isn't"
    ],
    [
        "ndarray it is  treated as a scalar.",
        "ndarray it is treated as"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that the coefficient"
    ],
    [
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension",
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c`"
    ],
    [
        "The values of the multidimensional polynomial on points formed with",
        "The values of the multidimensional polynomial on"
    ],
    [
        "triples of corresponding values from `x`, `y`, and `z`.",
        "triples of corresponding values from `x`,"
    ],
    [
        "return pu._valnd(lagval, c, x, y, z)",
        "return pu._valnd(lagval, c,"
    ],
    [
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * L_i(a) * L_j(b) * L_k(c)",
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * L_i(a) *"
    ],
    [
        "where the points ``(a, b, c)`` consist of all triples formed by taking",
        "where the points ``(a, b, c)`` consist of all triples"
    ],
    [
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form",
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting points"
    ],
    [
        "a grid with `x` in the first dimension, `y` in the second, and `z` in",
        "a grid with `x` in the first dimension, `y` in"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if they",
        "The parameters `x`, `y`, and `z` are converted"
    ],
    [
        "are tuples or a lists, otherwise they are treated as a scalars. In",
        "are tuples or a lists, otherwise they are"
    ],
    [
        "either case, either `x`, `y`, and `z` or their elements must support",
        "either case, either `x`, `y`, and `z` or their elements"
    ],
    [
        "multiplication and addition both with themselves and with the elements",
        "multiplication and addition both with themselves and with"
    ],
    [
        "If `c` has fewer than three dimensions, ones are implicitly appended to",
        "If `c` has fewer than three"
    ],
    [
        "x, y, z : array_like, compatible objects",
        "x, y, z : array_like, compatible"
    ],
    [
        "The three dimensional series is evaluated at the points in the",
        "The three dimensional series is evaluated at the points"
    ],
    [
        "Cartesian product of `x`, `y`, and `z`.  If `x`, `y`, or `z` is a",
        "Cartesian product of `x`, `y`, and `z`. If"
    ],
    [
        "list or tuple, it is first converted to an ndarray, otherwise it is",
        "list or tuple, it is first converted"
    ],
    [
        "left unchanged and, if it isn't an ndarray, it is treated as a",
        "left unchanged and, if it isn't an"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional"
    ],
    [
        "return pu._gridnd(lagval, c, x, y, z)",
        "return pu._gridnd(lagval, c, x, y,"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degree `deg` and sample points",
        "Returns the pseudo-Vandermonde matrix of degree `deg`"
    ],
    [
        "`x`. The pseudo-Vandermonde matrix is defined by",
        "`x`. The pseudo-Vandermonde matrix is defined"
    ],
    [
        ".. math:: V[..., i] = L_i(x)",
        ".. math:: V[..., i] ="
    ],
    [
        "`x` and the last index is the degree of the Laguerre polynomial.",
        "`x` and the last index is the"
    ],
    [
        "array ``V = lagvander(x, n)``, then ``np.dot(V, c)`` and",
        "array ``V = lagvander(x, n)``, then"
    ],
    [
        "``lagval(x, c)`` are the same up to roundoff. This equivalence is",
        "``lagval(x, c)`` are the same up to roundoff. This equivalence"
    ],
    [
        "useful both for least squares fitting and for the evaluation of a large",
        "useful both for least squares fitting and for the evaluation of a"
    ],
    [
        "number of Laguerre series of the same degree and sample points.",
        "number of Laguerre series of the same degree and"
    ],
    [
        "depending on whether any of the elements are complex. If `x` is",
        "depending on whether any of the elements are complex."
    ],
    [
        "The pseudo-Vandermonde matrix. The shape of the returned matrix is",
        "The pseudo-Vandermonde matrix. The shape of the returned matrix"
    ],
    [
        "corresponding Laguerre polynomial.  The dtype will be the same as",
        "corresponding Laguerre polynomial. The dtype will be the same"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of"
    ],
    [
        "points ``(x, y)``. The pseudo-Vandermonde matrix is defined by",
        "points ``(x, y)``. The pseudo-Vandermonde"
    ],
    [
        "`V` index the points ``(x, y)`` and the last index encodes the degrees of",
        "`V` index the points ``(x, y)`` and the last index encodes the"
    ],
    [
        "up to roundoff. This equivalence is useful both for least squares",
        "up to roundoff. This equivalence is useful both"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same degrees and"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes",
        "Arrays of point coordinates, all of the same shape."
    ],
    [
        "whether any of the elements are complex. Scalars are converted to",
        "whether any of the elements are complex. Scalars"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg].",
        "List of maximum degrees of the form [x_deg,"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix"
    ],
    [
        "as the converted `x` and `y`.",
        "as the converted"
    ],
    [
        "return pu._vander_nd_flat((lagvander, lagvander), (x, y), deg)",
        "return pu._vander_nd_flat((lagvander, lagvander),"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and"
    ],
    [
        "points ``(x, y, z)``. If `l`, `m`, `n` are the given degrees in `x`, `y`, `z`,",
        "points ``(x, y, z)``. If `l`, `m`, `n` are the given degrees"
    ],
    [
        "then The pseudo-Vandermonde matrix is defined by",
        "then The pseudo-Vandermonde matrix"
    ],
    [
        "indices of `V` index the points ``(x, y, z)`` and the last index encodes",
        "indices of `V` index the points ``(x, y, z)`` and the"
    ],
    [
        "the degrees of the Laguerre polynomials.",
        "the degrees of the Laguerre"
    ],
    [
        "same up to roundoff. This equivalence is useful both for least squares",
        "same up to roundoff. This equivalence"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same degrees and"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes will",
        "Arrays of point coordinates, all of the"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg, z_deg].",
        "List of maximum degrees of the form [x_deg, y_deg,"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is"
    ],
    [
        "be the same as the converted `x`, `y`, and `z`.",
        "be the same as the converted `x`, `y`, and"
    ],
    [
        "return pu._vander_nd_flat((lagvander, lagvander, lagvander), (x, y, z), deg)",
        "return pu._vander_nd_flat((lagvander, lagvander, lagvander), (x, y, z),"
    ],
    [
        "def lagfit(x, y, deg, rcond=None, full=False, w=None):",
        "def lagfit(x, y, deg, rcond=None, full=False,"
    ],
    [
        "Least squares fit of Laguerre series to data.",
        "Least squares fit of Laguerre series to"
    ],
    [
        "Return the coefficients of a Laguerre series of degree `deg` that is the",
        "Return the coefficients of a Laguerre series of degree `deg` that is"
    ],
    [
        "least squares fit to the data values `y` given at points `x`. If `y` is",
        "least squares fit to the data values `y` given at points"
    ],
    [
        "fits are done, one for each column of `y`, and the resulting",
        "fits are done, one for each column of `y`, and"
    ],
    [
        "The fitted polynomial(s) are in the form",
        "The fitted polynomial(s) are in"
    ],
    [
        "x-coordinates of the M sample points ``(x[i], y[i])``.",
        "x-coordinates of the M sample points"
    ],
    [
        "y : array_like, shape (M,) or (M, K)",
        "y : array_like, shape (M,) or"
    ],
    [
        "y-coordinates of the sample points. Several data sets of sample",
        "y-coordinates of the sample points. Several data"
    ],
    [
        "points sharing the same x-coordinates can be fitted at once by",
        "points sharing the same x-coordinates can be fitted"
    ],
    [
        "Degree(s) of the fitting polynomials. If `deg` is a single integer",
        "Degree(s) of the fitting polynomials. If `deg` is a single"
    ],
    [
        "all terms up to and including the `deg`'th term are included in the",
        "all terms up to and including the `deg`'th term are included in"
    ],
    [
        "degrees of the terms to include may be used instead.",
        "degrees of the terms to include"
    ],
    [
        "Relative condition number of the fit. Singular values smaller than",
        "Relative condition number of the"
    ],
    [
        "this relative to the largest singular value will be ignored. The",
        "this relative to the largest singular value will be ignored."
    ],
    [
        "default value is len(x)*eps, where eps is the relative precision of",
        "default value is len(x)*eps, where eps"
    ],
    [
        "Switch determining nature of return value. When it is False (the",
        "Switch determining nature of return value. When it is False"
    ],
    [
        "default) just the coefficients are returned, when True diagnostic",
        "default) just the coefficients are"
    ],
    [
        "information from the singular value decomposition is also returned.",
        "information from the singular value"
    ],
    [
        "w : array_like, shape (`M`,), optional",
        "w : array_like, shape (`M`,),"
    ],
    [
        "Weights. If not None, the weight ``w[i]`` applies to the unsquared",
        "Weights. If not None, the weight ``w[i]`` applies to"
    ],
    [
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are",
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally"
    ],
    [
        "chosen so that the errors of the products ``w[i]*y[i]`` all have the",
        "chosen so that the errors of the products"
    ],
    [
        "same variance.  When using inverse-variance weighting, use",
        "same variance. When using inverse-variance"
    ],
    [
        "coef : ndarray, shape (M,) or (M, K)",
        "coef : ndarray, shape (M,) or (M,"
    ],
    [
        "the coefficients for the data in column *k*  of `y` are in column",
        "the coefficients for the data in column *k*"
    ],
    [
        "[residuals, rank, singular_values, rcond] : list",
        "[residuals, rank, singular_values, rcond]"
    ],
    [
        "These values are only returned if ``full == True``",
        "These values are only returned if ``full =="
    ],
    [
        "- residuals -- sum of squared residuals of the least squares fit",
        "- residuals -- sum of squared residuals of"
    ],
    [
        "- rank -- the numerical rank of the scaled Vandermonde matrix",
        "- rank -- the numerical rank of the scaled"
    ],
    [
        "- singular_values -- singular values of the scaled Vandermonde matrix",
        "- singular_values -- singular values of the"
    ],
    [
        "- rcond -- value of `rcond`.",
        "- rcond -- value"
    ],
    [
        "The rank of the coefficient matrix in the least-squares fit is",
        "The rank of the coefficient matrix in"
    ],
    [
        "deficient. The warning is only raised if ``full == False``.  The",
        "deficient. The warning is only raised if ``full =="
    ],
    [
        "warnings can be turned off by",
        "warnings can be turned off"
    ],
    [
        "lagval : Evaluates a Laguerre series.",
        "lagval : Evaluates"
    ],
    [
        "lagvander : pseudo Vandermonde matrix of Laguerre series.",
        "lagvander : pseudo Vandermonde matrix"
    ],
    [
        "numpy.linalg.lstsq : Computes a least-squares fit from the matrix.",
        "numpy.linalg.lstsq : Computes a least-squares fit from the"
    ],
    [
        "The solution is the coefficients of the Laguerre series ``p`` that",
        "The solution is the coefficients of the Laguerre"
    ],
    [
        "minimizes the sum of the weighted squared errors",
        "minimizes the sum of the"
    ],
    [
        "where the :math:`w_j` are the weights. This problem is solved by",
        "where the :math:`w_j` are the weights."
    ],
    [
        "setting up as the (typically) overdetermined matrix equation",
        "setting up as the (typically) overdetermined"
    ],
    [
        ".. math:: V(x) * c = w * y,",
        ".. math:: V(x) * c = w"
    ],
    [
        "where ``V`` is the weighted pseudo Vandermonde matrix of `x`, ``c`` are the",
        "where ``V`` is the weighted pseudo Vandermonde matrix"
    ],
    [
        "coefficients to be solved for, `w` are the weights, and `y` are the",
        "coefficients to be solved for, `w` are the"
    ],
    [
        "observed values.  This equation is then solved using the singular value",
        "observed values. This equation is then solved using the singular"
    ],
    [
        "If some of the singular values of `V` are so small that they are",
        "If some of the singular values of"
    ],
    [
        "neglected, then a `~exceptions.RankWarning` will be issued. This means that",
        "neglected, then a `~exceptions.RankWarning` will be"
    ],
    [
        "the coefficient values may be poorly determined. Using a lower order fit",
        "the coefficient values may be poorly determined. Using a lower order"
    ],
    [
        "will usually get rid of the warning.  The `rcond` parameter can also be",
        "will usually get rid of the warning. The `rcond` parameter can also"
    ],
    [
        "set to a value smaller than its default, but the resulting fit may be",
        "set to a value smaller than its default, but the resulting fit"
    ],
    [
        "spurious and have large contributions from roundoff error.",
        "spurious and have large contributions from"
    ],
    [
        "Fits using Laguerre series are probably most useful when the data can",
        "Fits using Laguerre series are probably most"
    ],
    [
        "be approximated by ``sqrt(w(x)) * p(x)``, where ``w(x)`` is the Laguerre",
        "be approximated by ``sqrt(w(x)) * p(x)``, where ``w(x)`` is the"
    ],
    [
        "weight. In that case the weight ``sqrt(w(x[i]))`` should be used",
        "weight. In that case the weight ``sqrt(w(x[i]))``"
    ],
    [
        "together with data values ``y[i]/sqrt(w(x[i]))``. The weight function is",
        "together with data values ``y[i]/sqrt(w(x[i]))``."
    ],
    [
        ">>> from numpy.polynomial.laguerre import lagfit, lagval",
        ">>> from numpy.polynomial.laguerre import lagfit,"
    ],
    [
        "return pu._fit(lagvander, x, y, deg, rcond, full, w)",
        "return pu._fit(lagvander, x, y, deg, rcond, full,"
    ],
    [
        "Return the companion matrix of c.",
        "Return the companion matrix of"
    ],
    [
        "The usual companion matrix of the Laguerre polynomials is already",
        "The usual companion matrix of"
    ],
    [
        "symmetric when `c` is a basis Laguerre polynomial, so no scaling is",
        "symmetric when `c` is a basis Laguerre polynomial, so no"
    ],
    [
        "Companion matrix of dimensions (deg, deg).",
        "Companion matrix of dimensions (deg,"
    ],
    [
        "Compute the roots of a Laguerre series.",
        "Compute the roots of a"
    ],
    [
        "Return the roots (a.k.a. \"zeros\") of the polynomial",
        "Return the roots (a.k.a. \"zeros\") of"
    ],
    [
        ".. math:: p(x) = \\\\sum_i c[i] * L_i(x).",
        ".. math:: p(x) ="
    ],
    [
        "Array of the roots of the series. If all the roots are real,",
        "Array of the roots of the series. If all the roots"
    ],
    [
        "then `out` is also real, otherwise it is complex.",
        "then `out` is also real,"
    ],
    [
        "The root estimates are obtained as the eigenvalues of the companion",
        "The root estimates are obtained as the eigenvalues"
    ],
    [
        "matrix, Roots far from the origin of the complex plane may have large",
        "matrix, Roots far from the origin of the complex plane"
    ],
    [
        "errors due to the numerical instability of the series for such",
        "errors due to the numerical instability of the series for"
    ],
    [
        "errors as the value of the series near such points is relatively",
        "errors as the value of the series near such points is"
    ],
    [
        "insensitive to errors in the roots. Isolated roots near the origin can",
        "insensitive to errors in the roots. Isolated roots near the"
    ],
    [
        "be improved by a few iterations of Newton's method.",
        "be improved by a few"
    ],
    [
        "The Laguerre series basis polynomials aren't powers of `x` so the",
        "The Laguerre series basis polynomials aren't powers of `x`"
    ],
    [
        "results of this function may seem unintuitive.",
        "results of this function may seem"
    ],
    [
        ">>> from numpy.polynomial.laguerre import lagroots, lagfromroots",
        ">>> from numpy.polynomial.laguerre import lagroots,"
    ],
    [
        "Computes the sample points and weights for Gauss-Laguerre quadrature.",
        "Computes the sample points and weights for Gauss-Laguerre"
    ],
    [
        "These sample points and weights will correctly integrate polynomials of",
        "These sample points and weights"
    ],
    [
        "with the weight function :math:`f(x) = \\\\exp(-x)`.",
        "with the weight function :math:`f(x) ="
    ],
    [
        "be problematic. The weights are determined by using the fact that",
        "be problematic. The weights are determined"
    ],
    [
        "where :math:`c` is a constant independent of :math:`k` and :math:`x_k`",
        "where :math:`c` is a constant independent of :math:`k` and"
    ],
    [
        "is the k'th root of :math:`L_n`, and then scaling the results to get",
        "is the k'th root of :math:`L_n`, and"
    ],
    [
        "raise ValueError(\"deg must be a positive integer\")",
        "raise ValueError(\"deg must be a positive"
    ],
    [
        "\"\"\"Weight function of the Laguerre polynomials.",
        "\"\"\"Weight function of the"
    ],
    [
        "The weight function is :math:`exp(-x)` and the interval of integration",
        "The weight function is :math:`exp(-x)` and the interval of"
    ],
    [
        "normalized, with respect to this weight function.",
        "normalized, with respect to this weight"
    ],
    [
        "Values at which the weight function will be computed.",
        "Values at which the weight function"
    ],
    [
        "The Laguerre class provides the standard Python numerical methods",
        "The Laguerre class provides the"
    ],
    [
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as the",
        "'+', '-', '*', '//', '%', 'divmod', '**', and"
    ],
    [
        "Laguerre coefficients in order of increasing degree, i.e,",
        "Laguerre coefficients in order"
    ],
    [
        "Symbol used to represent the independent variable in string",
        "Symbol used to represent the independent variable in"
    ],
    [
        "representations of the polynomial expression, e.g. for printing.",
        "representations of the polynomial"
    ],
    [
        "The symbol must be a valid Python identifier. Default value is 'x'.",
        "The symbol must be a valid Python identifier. Default"
    ],
    [
        "Abstract base class for the various polynomial Classes.",
        "Abstract base class for the various polynomial"
    ],
    [
        "The ABCPolyBase class provides the methods needed to implement the common API",
        "The ABCPolyBase class provides the methods needed to implement the common"
    ],
    [
        "for the various polynomial classes. It operates as a mixin, but uses the",
        "for the various polynomial classes. It operates as a"
    ],
    [
        "from . import polyutils as pu",
        "from . import"
    ],
    [
        "\"\"\"An abstract base class for immutable series classes.",
        "\"\"\"An abstract base class"
    ],
    [
        "ABCPolyBase provides the standard Python numerical methods",
        "ABCPolyBase provides the standard Python numerical"
    ],
    [
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' along with the",
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' along"
    ],
    [
        "Series coefficients in order of increasing degree, i.e.,",
        "Series coefficients in order of increasing degree,"
    ],
    [
        "``P_i`` is the basis polynomials of degree ``i``.",
        "``P_i`` is the basis polynomials of"
    ],
    [
        "The default value is the derived class domain.",
        "The default value is"
    ],
    [
        "Window, see domain for its use. The default value is the",
        "Window, see domain for its use. The default value"
    ],
    [
        "Symbol used to represent the independent variable in string",
        "Symbol used to represent the independent variable"
    ],
    [
        "representations of the polynomial expression, e.g. for printing.",
        "representations of the polynomial expression,"
    ],
    [
        "The symbol must be a valid Python identifier. Default value is 'x'.",
        "The symbol must be a valid Python"
    ],
    [
        "Series coefficients in order of increasing degree.",
        "Series coefficients in order"
    ],
    [
        "Domain that is mapped to window.",
        "Domain that is"
    ],
    [
        "Window that domain is mapped to.",
        "Window that domain is mapped"
    ],
    [
        "Maximum power allowed, i.e., the largest number ``n`` such that",
        "Maximum power allowed, i.e., the largest number ``n`` such"
    ],
    [
        "``p(x)**n`` is allowed. This is to limit runaway polynomial size.",
        "``p(x)**n`` is allowed. This is"
    ],
    [
        "_use_unicode = not os.name == 'nt'",
        "_use_unicode = not"
    ],
    [
        "def _int(c, m, k, lbnd, scl):",
        "def _int(c, m, k,"
    ],
    [
        "def _fit(x, y, deg, rcond, full):",
        "def _fit(x, y, deg,"
    ],
    [
        "The other class must have the ``coef`` attribute.",
        "The other class must have the"
    ],
    [
        "True if the coefficients are the same, False otherwise.",
        "True if the coefficients are the same,"
    ],
    [
        "The other class must have the ``domain`` attribute.",
        "The other class must have the"
    ],
    [
        "True if the domains are the same, False otherwise.",
        "True if the domains are"
    ],
    [
        "The other class must have the ``window`` attribute.",
        "The other class must have the ``window``"
    ],
    [
        "True if the windows are the same, False otherwise.",
        "True if the windows are the same, False"
    ],
    [
        "True if other is same class as self",
        "True if other is same"
    ],
    [
        "The `other` argument is checked to see if it is of the same",
        "The `other` argument is checked to see"
    ],
    [
        "class as self with identical domain and window. If so,",
        "class as self with identical domain"
    ],
    [
        "return its coefficients, otherwise return `other`.",
        "return its coefficients, otherwise"
    ],
    [
        "The coefficients of`other` if it is a compatible instance,",
        "The coefficients of`other` if it"
    ],
    [
        "When `other` is an incompatible instance of ABCPolyBase.",
        "When `other` is an incompatible instance"
    ],
    [
        "def __init__(self, coef, domain=None, window=None, symbol='x'):",
        "def __init__(self, coef, domain=None, window=None,"
    ],
    [
        "raise ValueError(\"Domain has wrong number of elements.\")",
        "raise ValueError(\"Domain has wrong"
    ],
    [
        "raise ValueError(\"Window has wrong number of elements.\")",
        "raise ValueError(\"Window has wrong number"
    ],
    [
        "\"Symbol string must be a valid Python identifier\"",
        "\"Symbol string must be a"
    ],
    [
        "raise TypeError(\"Symbol must be a non-empty string\")",
        "raise TypeError(\"Symbol must be a non-empty"
    ],
    [
        "if fmt_str not in ('ascii', 'unicode'):",
        "if fmt_str not in ('ascii',"
    ],
    [
        "f\"Unsupported format string '{fmt_str}' passed to \"",
        "f\"Unsupported format string '{fmt_str}'"
    ],
    [
        "Generate the full string representation of the polynomial, using",
        "Generate the full string representation of the polynomial,"
    ],
    [
        "``term_method`` to generate each polynomial term.",
        "``term_method`` to generate each polynomial"
    ],
    [
        "scaled_symbol = '(' + scaled_symbol + ')'",
        "scaled_symbol = '(' +"
    ],
    [
        "next_term = \"+ \" + pu.format_float(coef, parens=True)",
        "next_term = \"+ \""
    ],
    [
        "next_term = \"- \" + pu.format_float(-coef, parens=True)",
        "next_term = \"- \" +"
    ],
    [
        "String representation of single polynomial term using unicode",
        "String representation of single"
    ],
    [
        "\"Subclasses must define either a basis_name, or override \"",
        "\"Subclasses must define either a"
    ],
    [
        "String representation of a single polynomial term using ** and _ to",
        "String representation of a single polynomial"
    ],
    [
        "\"Subclasses must define either a basis_name, or override \"",
        "\"Subclasses must define either a basis_name, or"
    ],
    [
        "\"Subclasses must define either a basis name, or override \"",
        "\"Subclasses must define either a basis name, or override"
    ],
    [
        "def _format_term(self, scalar_format: Callable, off: float, scale: float):",
        "def _format_term(self, scalar_format: Callable, off: float, scale:"
    ],
    [
        "\"\"\" Format a single term in the expansion \"\"\"",
        "\"\"\" Format a single term in the"
    ],
    [
        "coef_str = f\" + {self._repr_latex_scalar(c, parens=True)}\"",
        "coef_str = f\" +"
    ],
    [
        "coef_str = f\" - {self._repr_latex_scalar(-c, parens=True)}\"",
        "coef_str = f\""
    ],
    [
        "if not isinstance(other, numbers.Number) or isinstance(other, bool):",
        "if not isinstance(other, numbers.Number) or"
    ],
    [
        "f\"unsupported types for true division: \"",
        "f\"unsupported types for"
    ],
    [
        "quo = self.__class__(quo, self.domain, self.window, self.symbol)",
        "quo = self.__class__(quo,"
    ],
    [
        "rem = self.__class__(rem, self.domain, self.window, self.symbol)",
        "rem = self.__class__(rem,"
    ],
    [
        "res = self.__class__(coef, self.domain, self.window, self.symbol)",
        "res = self.__class__(coef, self.domain,"
    ],
    [
        "quo = self.__class__(quo, self.domain, self.window, self.symbol)",
        "quo = self.__class__(quo,"
    ],
    [
        "rem = self.__class__(rem, self.domain, self.window, self.symbol)",
        "rem = self.__class__(rem,"
    ],
    [
        "Degree of the series, one less than the number of coefficients.",
        "Degree of the series, one less"
    ],
    [
        "Note that this method does not check for non-zero coefficients.",
        "Note that this method does not check for non-zero"
    ],
    [
        "You must trim the polynomial to remove any trailing zeroes:",
        "You must trim the polynomial to"
    ],
    [
        "\"\"\"Truncate series to the given degree.",
        "\"\"\"Truncate series to"
    ],
    [
        "Reduce the degree of the series to `deg` by discarding the",
        "Reduce the degree of the series to `deg`"
    ],
    [
        "high order terms. If `deg` is greater than the current degree a",
        "high order terms. If `deg` is greater than the current"
    ],
    [
        "copy of the current series is returned. This can be useful in least",
        "copy of the current series is returned. This can be"
    ],
    [
        "squares where the coefficients of the high degree terms may be very",
        "squares where the coefficients of the high degree"
    ],
    [
        "The series is reduced to degree `deg` by discarding the high",
        "The series is reduced to degree `deg`"
    ],
    [
        "order terms. The value of `deg` must be a non-negative integer.",
        "order terms. The value of `deg` must be"
    ],
    [
        "New instance of series with reduced degree.",
        "New instance of series with reduced"
    ],
    [
        "Remove trailing coefficients until a coefficient is reached whose",
        "Remove trailing coefficients until a coefficient"
    ],
    [
        "absolute value greater than `tol` or the beginning of the series is",
        "absolute value greater than `tol` or"
    ],
    [
        "reached. If all the coefficients would be removed the series is set",
        "reached. If all the coefficients would be removed"
    ],
    [
        "coefficients.  The current instance remains unchanged.",
        "coefficients. The current instance"
    ],
    [
        "All trailing coefficients less than `tol` will be removed.",
        "All trailing coefficients less than `tol` will"
    ],
    [
        "New instance of series with trimmed coefficients.",
        "New instance of series"
    ],
    [
        "Reduce the series to length `size` by discarding the high",
        "Reduce the series to length"
    ],
    [
        "degree terms. The value of `size` must be a positive integer. This",
        "degree terms. The value of `size` must be a positive integer."
    ],
    [
        "can be useful in least squares where the coefficients of the",
        "can be useful in least squares where the coefficients of"
    ],
    [
        "high degree terms may be very small.",
        "high degree terms may"
    ],
    [
        "The series is reduced to length `size` by discarding the high",
        "The series is reduced to length `size` by discarding the"
    ],
    [
        "degree terms. The value of `size` must be a positive integer.",
        "degree terms. The value of `size` must be a"
    ],
    [
        "New instance of series with truncated coefficients.",
        "New instance of series with"
    ],
    [
        "raise ValueError(\"size must be a positive integer\")",
        "raise ValueError(\"size must be"
    ],
    [
        "\"\"\"Convert series to a different kind and/or domain and/or window.",
        "\"\"\"Convert series to a different kind and/or domain and/or"
    ],
    [
        "The domain of the converted series. If the value is None,",
        "The domain of the converted series. If the value is"
    ],
    [
        "the default domain of `kind` is used.",
        "the default domain of `kind` is"
    ],
    [
        "The polynomial series type class to which the current instance",
        "The polynomial series type class"
    ],
    [
        "should be converted. If kind is None, then the class of the",
        "should be converted. If kind is None, then the"
    ],
    [
        "The window of the converted series. If the value is None,",
        "The window of the converted series. If"
    ],
    [
        "the default window of `kind` is used.",
        "the default window of `kind` is"
    ],
    [
        "The returned class can be of different type than the current",
        "The returned class can be of different type"
    ],
    [
        "instance and/or have a different domain and/or different",
        "instance and/or have a"
    ],
    [
        "Conversion between domains and class types can result in",
        "Conversion between domains and class types"
    ],
    [
        "The returned values define a linear map ``off + scl*x`` that is",
        "The returned values define a linear map ``off + scl*x``"
    ],
    [
        "applied to the input arguments before the series is evaluated. The",
        "applied to the input arguments before the"
    ],
    [
        "map depends on the ``domain`` and ``window``; if the current",
        "map depends on the ``domain``"
    ],
    [
        "``domain`` is equal to the ``window`` the resulting map is the",
        "``domain`` is equal to the ``window`` the resulting map is"
    ],
    [
        "identity.  If the coefficients of the series instance are to be",
        "identity. If the coefficients of the"
    ],
    [
        "used by themselves outside this class, then the linear function",
        "used by themselves outside this"
    ],
    [
        "must be substituted for the ``x`` in the standard representation of",
        "must be substituted for the ``x`` in"
    ],
    [
        "off, scl : float or complex",
        "off, scl : float"
    ],
    [
        "The mapping function is defined by ``off + scl*x``.",
        "The mapping function is defined by ``off"
    ],
    [
        "Return a series instance that is the definite integral of the",
        "Return a series instance that is the"
    ],
    [
        "The number of integrations to perform.",
        "The number of integrations to"
    ],
    [
        "Integration constants. The first constant is applied to the",
        "Integration constants. The first constant is applied"
    ],
    [
        "first integration, the second to the second, and so on. The",
        "first integration, the second to the"
    ],
    [
        "list of values must less than or equal to `m` in length and any",
        "list of values must less than or equal"
    ],
    [
        "missing values are set to zero.",
        "missing values are set"
    ],
    [
        "The lower bound of the definite integral.",
        "The lower bound of the definite"
    ],
    [
        "A new series representing the integral. The domain is the same",
        "A new series representing the integral. The domain is"
    ],
    [
        "as the domain of the integrated series.",
        "as the domain of the"
    ],
    [
        "lbnd = off + scl * lbnd",
        "lbnd = off +"
    ],
    [
        "Return a series instance of that is the derivative of the current",
        "Return a series instance of that is the derivative of"
    ],
    [
        "Find the derivative of order `m`.",
        "Find the derivative"
    ],
    [
        "A new series representing the derivative. The domain is the same",
        "A new series representing the derivative. The domain is the"
    ],
    [
        "as the domain of the differentiated series.",
        "as the domain of the differentiated"
    ],
    [
        "\"\"\"Return the roots of the series polynomial.",
        "\"\"\"Return the roots of"
    ],
    [
        "Compute the roots for the series. Note that the accuracy of the",
        "Compute the roots for the series."
    ],
    [
        "roots decreases the further outside the `domain` they lie.",
        "roots decreases the further outside the"
    ],
    [
        "Array containing the roots of the series.",
        "Array containing the roots of the"
    ],
    [
        "\"\"\"Return x, y values at equally spaced points in domain.",
        "\"\"\"Return x, y values at equally spaced points"
    ],
    [
        "Returns the x, y values at `n` linearly spaced points across the",
        "Returns the x, y values at `n` linearly spaced points"
    ],
    [
        "domain.  Here y is the value of the polynomial at the points x. By",
        "domain. Here y is the value of"
    ],
    [
        "default the domain is the same as that of the series instance.",
        "default the domain is the same as"
    ],
    [
        "This method is intended mostly as a plotting aid.",
        "This method is intended mostly"
    ],
    [
        "If not None, the specified domain is used instead of that of",
        "If not None, the specified domain is"
    ],
    [
        "the calling instance. It should be of the form ``[beg,end]``.",
        "the calling instance. It should be of"
    ],
    [
        "The default is None which case the class domain is used.",
        "The default is None which case the class"
    ],
    [
        "y is the series evaluated at element of x.",
        "y is the series evaluated at element of"
    ],
    [
        "def fit(cls, x, y, deg, domain=None, rcond=None, full=False, w=None,",
        "def fit(cls, x, y, deg, domain=None, rcond=None, full=False,"
    ],
    [
        "Return a series instance that is the least squares fit to the data",
        "Return a series instance that is the least squares"
    ],
    [
        "`y` sampled at `x`. The domain of the returned instance can be",
        "`y` sampled at `x`. The domain"
    ],
    [
        "specified and this will often result in a superior fit with less",
        "specified and this will often result in a superior fit"
    ],
    [
        "x-coordinates of the M sample points ``(x[i], y[i])``.",
        "x-coordinates of the M sample"
    ],
    [
        "y-coordinates of the M sample points ``(x[i], y[i])``.",
        "y-coordinates of the M sample points"
    ],
    [
        "Degree(s) of the fitting polynomials. If `deg` is a single integer",
        "Degree(s) of the fitting polynomials. If"
    ],
    [
        "all terms up to and including the `deg`'th term are included in the",
        "all terms up to and including the `deg`'th term are included in"
    ],
    [
        "degrees of the terms to include may be used instead.",
        "degrees of the terms to include"
    ],
    [
        "domain : {None, [beg, end], []}, optional",
        "domain : {None, [beg, end], []},"
    ],
    [
        "Domain to use for the returned series. If ``None``,",
        "Domain to use for the returned series. If"
    ],
    [
        "then a minimal domain that covers the points `x` is chosen.  If",
        "then a minimal domain that covers the"
    ],
    [
        "``[]`` the class domain is used. The default value was the",
        "``[]`` the class domain is used. The default value"
    ],
    [
        "Relative condition number of the fit. Singular values smaller",
        "Relative condition number of the fit. Singular"
    ],
    [
        "than this relative to the largest singular value will be",
        "than this relative to the largest"
    ],
    [
        "ignored. The default value is ``len(x)*eps``, where eps is the",
        "ignored. The default value is ``len(x)*eps``,"
    ],
    [
        "Switch determining nature of return value. When it is False",
        "Switch determining nature of return"
    ],
    [
        "(the default) just the coefficients are returned, when True",
        "(the default) just the coefficients are"
    ],
    [
        "diagnostic information from the singular value decomposition is",
        "diagnostic information from the singular value"
    ],
    [
        "w : array_like, shape (M,), optional",
        "w : array_like,"
    ],
    [
        "Weights. If not None, the weight ``w[i]`` applies to the unsquared",
        "Weights. If not None, the weight ``w[i]`` applies to"
    ],
    [
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are",
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally"
    ],
    [
        "chosen so that the errors of the products ``w[i]*y[i]`` all have",
        "chosen so that the errors of"
    ],
    [
        "the same variance.  When using inverse-variance weighting, use",
        "the same variance. When using inverse-variance"
    ],
    [
        "Window to use for the returned series. The default",
        "Window to use for the returned"
    ],
    [
        "value is the default class domain",
        "value is the"
    ],
    [
        "Symbol representing the independent variable. Default is 'x'.",
        "Symbol representing the independent variable."
    ],
    [
        "A series that represents the least squares fit to the data and",
        "A series that represents the least"
    ],
    [
        "has the domain and window specified in the call. If the",
        "has the domain and window specified in"
    ],
    [
        "coefficients for the unscaled and unshifted basis polynomials are",
        "coefficients for the unscaled and unshifted"
    ],
    [
        "[resid, rank, sv, rcond] : list",
        "[resid, rank, sv, rcond]"
    ],
    [
        "These values are only returned if ``full == True``",
        "These values are only returned"
    ],
    [
        "- resid -- sum of squared residuals of the least squares fit",
        "- resid -- sum of squared residuals"
    ],
    [
        "- rank -- the numerical rank of the scaled Vandermonde matrix",
        "- rank -- the numerical rank of the scaled"
    ],
    [
        "- sv -- singular values of the scaled Vandermonde matrix",
        "- sv -- singular values of the scaled"
    ],
    [
        "- rcond -- value of `rcond`.",
        "- rcond --"
    ],
    [
        "res = cls._fit(xnew, y, deg, w=w, rcond=rcond, full=full)",
        "res = cls._fit(xnew, y,"
    ],
    [
        "def fromroots(cls, roots, domain=[], window=None, symbol='x'):",
        "def fromroots(cls, roots, domain=[],"
    ],
    [
        "\"\"\"Return series instance that has the specified roots.",
        "\"\"\"Return series instance that has"
    ],
    [
        "Returns a series representing the product",
        "Returns a series"
    ],
    [
        "domain : {[], None, array_like}, optional",
        "domain : {[], None,"
    ],
    [
        "Domain for the resulting series. If None the domain is the",
        "Domain for the resulting series. If None the domain is"
    ],
    [
        "interval from the smallest root to the largest. If [] the",
        "interval from the smallest root to the"
    ],
    [
        "domain is the class domain. The default is [].",
        "domain is the class domain. The default is"
    ],
    [
        "Window for the returned series. If None the class window is",
        "Window for the returned series. If None the"
    ],
    [
        "Symbol representing the independent variable. Default is 'x'.",
        "Symbol representing the independent variable. Default"
    ],
    [
        "rnew = off + scl * roots",
        "rnew = off + scl"
    ],
    [
        "If ``p`` is the returned series, then ``p(x) == x`` for all",
        "If ``p`` is the returned series,"
    ],
    [
        "If given, the array must be of the form ``[beg, end]``, where",
        "If given, the array must be of"
    ],
    [
        "``beg`` and ``end`` are the endpoints of the domain. If None is",
        "``beg`` and ``end`` are the endpoints of"
    ],
    [
        "given then the class domain is used. The default is None.",
        "given then the class domain is used. The default"
    ],
    [
        "If given, the resulting array must be if the form",
        "If given, the resulting array must be if the"
    ],
    [
        "``[beg, end]``, where ``beg`` and ``end`` are the endpoints of",
        "``[beg, end]``, where ``beg`` and ``end`` are the endpoints"
    ],
    [
        "the window. If None is given then the class window is used. The",
        "the window. If None is given then the"
    ],
    [
        "Symbol representing the independent variable. Default is 'x'.",
        "Symbol representing the independent"
    ],
    [
        "def basis(cls, deg, domain=None, window=None, symbol='x'):",
        "def basis(cls, deg,"
    ],
    [
        "\"\"\"Series basis polynomial of degree `deg`.",
        "\"\"\"Series basis polynomial of"
    ],
    [
        "Returns the series representing the basis polynomial of degree `deg`.",
        "Returns the series representing the"
    ],
    [
        "If given, the array must be of the form ``[beg, end]``, where",
        "If given, the array must be"
    ],
    [
        "``beg`` and ``end`` are the endpoints of the domain. If None is",
        "``beg`` and ``end`` are the endpoints of the domain."
    ],
    [
        "given then the class domain is used. The default is None.",
        "given then the class domain is"
    ],
    [
        "If given, the resulting array must be if the form",
        "If given, the resulting array must"
    ],
    [
        "``[beg, end]``, where ``beg`` and ``end`` are the endpoints of",
        "``[beg, end]``, where ``beg`` and ``end`` are the endpoints"
    ],
    [
        "the window. If None is given then the class window is used. The",
        "the window. If None is given then the"
    ],
    [
        "Symbol representing the independent variable. Default is 'x'.",
        "Symbol representing the independent variable."
    ],
    [
        "A series with the coefficient of the `deg` term set to one and",
        "A series with the coefficient of the `deg` term set to"
    ],
    [
        "raise ValueError(\"deg must be non-negative integer\")",
        "raise ValueError(\"deg must be"
    ],
    [
        "\"\"\"Convert series to series of this class.",
        "\"\"\"Convert series to series"
    ],
    [
        "The `series` is expected to be an instance of some polynomial",
        "The `series` is expected to be an instance of"
    ],
    [
        "series of one of the types supported by by the numpy.polynomial",
        "series of one of the types supported by by"
    ],
    [
        "module, but could be some other class that supports the convert",
        "module, but could be some other class"
    ],
    [
        "The series instance to be converted.",
        "The series instance to be"
    ],
    [
        "If given, the array must be of the form ``[beg, end]``, where",
        "If given, the array must be of"
    ],
    [
        "``beg`` and ``end`` are the endpoints of the domain. If None is",
        "``beg`` and ``end`` are the endpoints"
    ],
    [
        "given then the class domain is used. The default is None.",
        "given then the class domain is used."
    ],
    [
        "If given, the resulting array must be if the form",
        "If given, the resulting array"
    ],
    [
        "``[beg, end]``, where ``beg`` and ``end`` are the endpoints of",
        "``[beg, end]``, where ``beg`` and ``end`` are the endpoints"
    ],
    [
        "the window. If None is given then the class window is used. The",
        "the window. If None is given then"
    ],
    [
        "A series of the same kind as the calling class and equal to",
        "A series of the same kind as the calling class"
    ],
    [
        "Utility classes and functions for the polynomial modules.",
        "Utility classes and functions for the polynomial"
    ],
    [
        "This module provides: error and warning objects; a polynomial base class;",
        "This module provides: error and warning objects; a polynomial"
    ],
    [
        "and some routines used in both the `polynomial` and `chebyshev` modules.",
        "and some routines used in both the `polynomial`"
    ],
    [
        "getdomain    return the domain appropriate for a given set of abscissae.",
        "getdomain return the domain appropriate for a"
    ],
    [
        "mapparms     parameters of the linear map between domains.",
        "mapparms parameters of the linear map"
    ],
    [
        "'as_series', 'trimseq', 'trimcoef', 'getdomain', 'mapdomain', 'mapparms',",
        "'as_series', 'trimseq', 'trimcoef', 'getdomain',"
    ],
    [
        "Subsequence with trailing zeros removed. If the resulting sequence",
        "Subsequence with trailing zeros removed. If"
    ],
    [
        "would be empty, return the first element. The returned sequence may",
        "would be empty, return the first"
    ],
    [
        "or may not be a view.",
        "or may not"
    ],
    [
        "Do not lose the type info if the sequence contains unknown objects.",
        "Do not lose the type info if the"
    ],
    [
        "The returned list contains array(s) of dtype double, complex double, or",
        "The returned list contains array(s) of dtype double, complex double,"
    ],
    [
        "of size ``N`` (i.e., is \"parsed by row\"); and a higher dimensional array",
        "of size ``N`` (i.e., is \"parsed by"
    ],
    [
        "When True, trailing zeros are removed from the inputs.",
        "When True, trailing zeros are"
    ],
    [
        "When False, the inputs are passed through intact.",
        "When False, the inputs are passed"
    ],
    [
        "least one of the resulting arrays is empty.",
        "least one of the resulting"
    ],
    [
        ">>> from numpy.polynomial import polyutils as pu",
        ">>> from numpy.polynomial import polyutils"
    ],
    [
        "arrays = [trimseq(a) for a in arrays]",
        "arrays = [trimseq(a) for a"
    ],
    [
        "raise ValueError(\"Coefficient arrays have no common type\") from e",
        "raise ValueError(\"Coefficient arrays have no common"
    ],
    [
        "ret = [np.array(a, copy=True, dtype=dtype) for a in arrays]",
        "ret = [np.array(a, copy=True, dtype=dtype) for a in"
    ],
    [
        "Remove \"small\" \"trailing\" coefficients from a polynomial.",
        "Remove \"small\" \"trailing\" coefficients from a"
    ],
    [
        "\"Small\" means \"small in absolute value\" and is controlled by the",
        "\"Small\" means \"small in absolute value\" and is"
    ],
    [
        "parameter `tol`; \"trailing\" means highest order coefficient(s), e.g., in",
        "parameter `tol`; \"trailing\" means highest order coefficient(s), e.g.,"
    ],
    [
        "Trailing (i.e., highest order) elements with absolute value less",
        "Trailing (i.e., highest order) elements with"
    ],
    [
        "than or equal to `tol` (default value is zero) are removed.",
        "than or equal to `tol` (default value is zero) are"
    ],
    [
        "would be empty, a series containing a single zero is returned.",
        "would be empty, a series containing a single zero"
    ],
    [
        ">>> from numpy.polynomial import polyutils as pu",
        ">>> from numpy.polynomial import polyutils as"
    ],
    [
        "Return a domain suitable for given abscissae.",
        "Return a domain suitable for given"
    ],
    [
        "Find a domain suitable for a polynomial or Chebyshev series",
        "Find a domain suitable for a polynomial or"
    ],
    [
        "the two returned points are the lower left and upper right corners",
        "the two returned points are the"
    ],
    [
        "of the smallest rectangle (aligned with the axes) in the complex",
        "of the smallest rectangle (aligned with the axes) in the"
    ],
    [
        "plane containing the points `x`. If the inputs are real, then the",
        "plane containing the points `x`. If the inputs are"
    ],
    [
        "two points are the ends of the smallest interval containing the",
        "two points are the ends of the"
    ],
    [
        ">>> from numpy.polynomial import polyutils as pu",
        ">>> from numpy.polynomial import polyutils as"
    ],
    [
        "Return the parameters of the linear map ``offset + scale*x`` that maps",
        "Return the parameters of the linear map ``offset + scale*x`` that"
    ],
    [
        "The map ``L(x) = offset + scale*x`` maps the first domain to the",
        "The map ``L(x) = offset + scale*x`` maps the first domain"
    ],
    [
        "Also works for complex numbers, and thus can be used to calculate the",
        "Also works for complex numbers, and thus can be used to calculate"
    ],
    [
        "parameters required to map any line in the complex plane to any other",
        "parameters required to map any line in the complex"
    ],
    [
        ">>> from numpy.polynomial import polyutils as pu",
        ">>> from numpy.polynomial import"
    ],
    [
        "Apply linear map to input points.",
        "Apply linear map to"
    ],
    [
        "The linear map ``offset + scale*x`` that maps the domain `old` to",
        "The linear map ``offset + scale*x`` that maps the domain"
    ],
    [
        "the domain `new` is applied to the points `x`.",
        "the domain `new` is applied"
    ],
    [
        "Points to be mapped. If `x` is a subtype of ndarray the subtype",
        "Points to be mapped. If `x` is"
    ],
    [
        "The two domains that determine the map.  Each must (successfully)",
        "The two domains that determine the"
    ],
    [
        "Array of points of the same shape as `x`, after application of the",
        "Array of points of the same shape as `x`, after"
    ],
    [
        "linear map between the two domains.",
        "linear map between"
    ],
    [
        ">>> from numpy.polynomial import polyutils as pu",
        ">>> from numpy.polynomial import polyutils"
    ],
    [
        ">>> x_out = pu.mapdomain(x, old_domain, new_domain); x_out",
        ">>> x_out = pu.mapdomain(x, old_domain,"
    ],
    [
        ">>> x - pu.mapdomain(x_out, new_domain, old_domain)",
        ">>> x - pu.mapdomain(x_out, new_domain,"
    ],
    [
        "Also works for complex numbers (and thus can be used to map any line in",
        "Also works for complex numbers (and thus can be used to map any line"
    ],
    [
        "the complex plane to any other line therein).",
        "the complex plane to any other line"
    ],
    [
        ">>> new_z = pu.mapdomain(z, old, new); new_z",
        ">>> new_z = pu.mapdomain(z,"
    ],
    [
        "if type(x) not in (int, float, complex) and not isinstance(x, np.generic):",
        "if type(x) not in (int, float, complex)"
    ],
    [
        "return off + scl * x",
        "return off + scl"
    ],
    [
        "A generalization of the Vandermonde matrix for N dimensions",
        "A generalization of the Vandermonde matrix for N"
    ],
    [
        "N &= \\texttt{len(points)} = \\texttt{len(degrees)} = \\texttt{len(vander\\_fs)} \\\\",
        "N &= \\texttt{len(points)} = \\texttt{len(degrees)} ="
    ],
    [
        "Expanding the one-dimensional :math:`V_k` functions gives:",
        "Expanding the one-dimensional :math:`V_k` functions"
    ],
    [
        "where :math:`B_{k,m}` is the m'th basis of the polynomial construction used along",
        "where :math:`B_{k,m}` is the m'th basis of the polynomial"
    ],
    [
        "dimension :math:`k`. For a regular polynomial, :math:`B_{k, m}(x) = P_m(x) = x^m`.",
        "dimension :math:`k`. For a regular polynomial, :math:`B_{k,"
    ],
    [
        "vander_fs : Sequence[function(array_like, int) -> ndarray]",
        "vander_fs : Sequence[function(array_like,"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes",
        "Arrays of point coordinates, all of the"
    ],
    [
        "whether any of the elements are complex. Scalars are converted to",
        "whether any of the elements are complex. Scalars"
    ],
    [
        "This must be the same length as `vander_fs`.",
        "This must be the same length"
    ],
    [
        "The maximum degree (inclusive) to use for each axis.",
        "The maximum degree (inclusive) to use"
    ],
    [
        "This must be the same length as `vander_fs`.",
        "This must be the"
    ],
    [
        "f\"Expected {n_dims} dimensions of sample points, got {len(points)}\")",
        "f\"Expected {n_dims} dimensions of sample"
    ],
    [
        "f\"Expected {n_dims} dimensions of degrees, got {len(degrees)}\")",
        "f\"Expected {n_dims} dimensions of degrees,"
    ],
    [
        "raise ValueError(\"Unable to guess a dtype or shape when no points are given\")",
        "raise ValueError(\"Unable to guess a dtype or shape when no points are"
    ],
    [
        "Like `_vander_nd`, but flattens the last ``len(degrees)`` axes into a single axis",
        "Like `_vander_nd`, but flattens the last ``len(degrees)`` axes"
    ],
    [
        "Used to implement the public ``<type>vander<n>d`` functions.",
        "Used to implement the public ``<type>vander<n>d``"
    ],
    [
        "Helper function used to implement the ``<type>fromroots`` functions.",
        "Helper function used to implement the ``<type>fromroots``"
    ],
    [
        "line_f : function(float, float) -> ndarray",
        "line_f : function(float, float) ->"
    ],
    [
        "The ``<type>line`` function, such as ``polyline``",
        "The ``<type>line`` function, such"
    ],
    [
        "mul_f : function(array_like, array_like) -> ndarray",
        "mul_f : function(array_like, array_like) ->"
    ],
    [
        "The ``<type>mul`` function, such as ``polymul``",
        "The ``<type>mul`` function, such"
    ],
    [
        "See the ``<type>fromroots`` functions for more detail",
        "See the ``<type>fromroots`` functions for"
    ],
    [
        "tmp = [mul_f(p[i], p[i + m]) for i in range(m)]",
        "tmp = [mul_f(p[i], p[i + m]) for i"
    ],
    [
        "Helper function used to implement the ``<type>val<n>d`` functions.",
        "Helper function used to"
    ],
    [
        "val_f : function(array_like, array_like, tensor: bool) -> array_like",
        "val_f : function(array_like, array_like, tensor: bool) ->"
    ],
    [
        "The ``<type>val`` function, such as ``polyval``",
        "The ``<type>val`` function, such as"
    ],
    [
        "See the ``<type>val<n>d`` functions for more detail",
        "See the ``<type>val<n>d`` functions for"
    ],
    [
        "args = [np.asanyarray(a) for a in args]",
        "args = [np.asanyarray(a) for a"
    ],
    [
        "raise ValueError('x, y, z are incompatible')",
        "raise ValueError('x, y, z are"
    ],
    [
        "Helper function used to implement the ``<type>grid<n>d`` functions.",
        "Helper function used to implement the ``<type>grid<n>d``"
    ],
    [
        "val_f : function(array_like, array_like, tensor: bool) -> array_like",
        "val_f : function(array_like, array_like, tensor:"
    ],
    [
        "The ``<type>val`` function, such as ``polyval``",
        "The ``<type>val`` function, such"
    ],
    [
        "See the ``<type>grid<n>d`` functions for more detail",
        "See the ``<type>grid<n>d`` functions"
    ],
    [
        "Helper function used to implement the ``<type>div`` functions.",
        "Helper function used to implement"
    ],
    [
        "For some polynomial types, a more efficient approach may be possible.",
        "For some polynomial types, a more efficient"
    ],
    [
        "mul_f : function(array_like, array_like) -> array_like",
        "mul_f : function(array_like,"
    ],
    [
        "The ``<type>mul`` function, such as ``polymul``",
        "The ``<type>mul`` function,"
    ],
    [
        "See the ``<type>div`` functions for more detail",
        "See the ``<type>div`` functions"
    ],
    [
        "\"\"\" Helper function used to implement the ``<type>add`` functions. \"\"\"",
        "\"\"\" Helper function used to implement"
    ],
    [
        "\"\"\" Helper function used to implement the ``<type>sub`` functions. \"\"\"",
        "\"\"\" Helper function used to implement the"
    ],
    [
        "def _fit(vander_f, x, y, deg, rcond=None, full=False, w=None):",
        "def _fit(vander_f, x, y, deg,"
    ],
    [
        "Helper function used to implement the ``<type>fit`` functions.",
        "Helper function used to implement the"
    ],
    [
        "vander_f : function(array_like, int) -> ndarray",
        "vander_f : function(array_like, int) ->"
    ],
    [
        "See the ``<type>fit`` functions for more detail",
        "See the ``<type>fit`` functions"
    ],
    [
        "raise TypeError(\"expected non-empty vector for x\")",
        "raise TypeError(\"expected non-empty vector"
    ],
    [
        "raise TypeError(\"expected x and y to have same length\")",
        "raise TypeError(\"expected x and y"
    ],
    [
        "raise TypeError(\"expected x and w to have same length\")",
        "raise TypeError(\"expected x and w to have same"
    ],
    [
        "c, resids, rank, s = np.linalg.lstsq(lhs.T / scl, rhs.T, rcond)",
        "c, resids, rank, s = np.linalg.lstsq(lhs.T / scl,"
    ],
    [
        "if rank != order and not full:",
        "if rank != order and"
    ],
    [
        "msg = \"The fit may be poorly conditioned\"",
        "msg = \"The fit may be"
    ],
    [
        "return c, [resids, rank, s, rcond]",
        "return c, [resids, rank, s,"
    ],
    [
        "Helper function used to implement the ``<type>pow`` functions.",
        "Helper function used to implement the"
    ],
    [
        "mul_f : function(array_like, array_like) -> ndarray",
        "mul_f : function(array_like, array_like)"
    ],
    [
        "The ``<type>mul`` function, such as ``polymul``",
        "The ``<type>mul`` function, such as"
    ],
    [
        "See the ``<type>pow`` functions for more detail",
        "See the ``<type>pow`` functions"
    ],
    [
        "raise ValueError(\"Power must be a non-negative integer.\")",
        "raise ValueError(\"Power must be a"
    ],
    [
        "elif maxpower is not None and power > maxpower:",
        "elif maxpower is not None and"
    ],
    [
        "Like `operator.index`, but emits a custom exception when passed an",
        "Like `operator.index`, but emits a custom"
    ],
    [
        "Value to interpret as an integer",
        "Value to interpret as an"
    ],
    [
        "description to include in any error message",
        "description to include in any error"
    ],
    [
        "TypeError : if x is a float or non-numeric",
        "TypeError : if x is a"
    ],
    [
        "raise TypeError(f\"{desc} must be an integer, received {x}\") from e",
        "raise TypeError(f\"{desc} must be an integer, received {x}\") from"
    ],
    [
        "s = '(' + s + ')'",
        "s = '(' + s +"
    ],
    [
        "A sub-package for efficiently dealing with polynomials.",
        "A sub-package for efficiently"
    ],
    [
        "Within the documentation for this sub-package, a \"finite power series,\"",
        "Within the documentation for this"
    ],
    [
        "i.e., a polynomial (also referred to simply as a \"series\") is represented",
        "i.e., a polynomial (also referred to"
    ],
    [
        "applicable to the specific module in question, e.g., `polynomial` (which",
        "applicable to the specific module"
    ],
    [
        "\"wraps\" the \"standard\" basis) or `chebyshev`.  For optimal performance,",
        "\"wraps\" the \"standard\" basis) or `chebyshev`. For optimal"
    ],
    [
        "all operations on polynomials, including evaluation at an argument, are",
        "all operations on polynomials, including evaluation"
    ],
    [
        "implemented as operations on the coefficients.  Additional (module-specific)",
        "implemented as operations on the coefficients. Additional"
    ],
    [
        "information can be found in the docstring for the module of interest.",
        "information can be found in the docstring for the module"
    ],
    [
        "This package provides *convenience classes* for each of six different kinds",
        "This package provides *convenience classes* for each of six different"
    ],
    [
        "These *convenience classes* provide a consistent interface for creating,",
        "These *convenience classes* provide a"
    ],
    [
        "manipulating, and fitting data with polynomials of different bases.",
        "manipulating, and fitting data with polynomials of different"
    ],
    [
        "The convenience classes are the preferred interface for the `~numpy.polynomial`",
        "The convenience classes are the preferred interface for the"
    ],
    [
        "package, and are available from the ``numpy.polynomial`` namespace.",
        "package, and are available"
    ],
    [
        "This eliminates the need to navigate to the corresponding submodules, e.g.",
        "This eliminates the need to navigate to the corresponding submodules,"
    ],
    [
        "The classes provide a more consistent and concise interface than the",
        "The classes provide a more consistent and"
    ],
    [
        "type-specific functions defined in the submodules for each type of polynomial.",
        "type-specific functions defined in the submodules for each type of"
    ],
    [
        "by arrays ``xdata`` and ``ydata``, the",
        "by arrays ``xdata`` and ``ydata``,"
    ],
    [
        "is preferred over the `chebyshev.chebfit` function from the",
        "is preferred over the `chebyshev.chebfit`"
    ],
    [
        "The following lists the various constants and methods common to all of",
        "The following lists the various constants and"
    ],
    [
        "the classes representing the various kinds of polynomials. In the following,",
        "the classes representing the various kinds of polynomials. In the"
    ],
    [
        "the term ``Poly`` represents any one of the convenience classes (e.g.",
        "the term ``Poly`` represents any one"
    ],
    [
        "while the lowercase ``p`` represents an **instance** of a polynomial class.",
        "while the lowercase ``p`` represents an"
    ],
    [
        "- ``Poly.basis_name`` -- String used to represent the basis",
        "- ``Poly.basis_name`` -- String used to represent"
    ],
    [
        "- ``Poly.maxpower``   -- Maximum value ``n`` such that ``p**n`` is allowed",
        "- ``Poly.maxpower`` -- Maximum value ``n`` such that"
    ],
    [
        "- ``Poly.nickname``   -- String used in printing",
        "- ``Poly.nickname`` -- String"
    ],
    [
        "- ``Poly.basis(degree)``    -- Basis polynomial of given degree",
        "- ``Poly.basis(degree)`` -- Basis polynomial of given"
    ],
    [
        "- ``Poly.identity()``       -- ``p`` where ``p(x) = x`` for all ``x``",
        "- ``Poly.identity()`` -- ``p`` where ``p(x) = x`` for"
    ],
    [
        "- ``Poly.fit(x, y, deg)``   -- ``p`` of degree ``deg`` with coefficients",
        "- ``Poly.fit(x, y, deg)`` -- ``p`` of degree"
    ],
    [
        "determined by the least-squares fit to the data ``x``, ``y``",
        "determined by the least-squares fit to the data"
    ],
    [
        "- ``Poly.fromroots(roots)`` -- ``p`` with specified roots",
        "- ``Poly.fromroots(roots)`` -- ``p`` with specified"
    ],
    [
        "- ``p.copy()``              -- Create a copy of ``p``",
        "- ``p.copy()`` -- Create a copy of"
    ],
    [
        "Methods for converting a polynomial instance of one kind to another.",
        "Methods for converting a polynomial instance of"
    ],
    [
        "- ``p.cast(Poly)``    -- Convert ``p`` to instance of kind ``Poly``",
        "- ``p.cast(Poly)`` -- Convert ``p`` to instance of kind"
    ],
    [
        "- ``p.convert(Poly)`` -- Convert ``p`` to instance of kind ``Poly`` or map",
        "- ``p.convert(Poly)`` -- Convert ``p`` to instance of"
    ],
    [
        "- ``p.deriv()`` -- Take the derivative of ``p``",
        "- ``p.deriv()`` -- Take the"
    ],
    [
        "- ``p.linspace()`` -- Return ``x, p(x)`` at equally-spaced points in ``domain``",
        "- ``p.linspace()`` -- Return ``x, p(x)`` at equally-spaced points"
    ],
    [
        "- ``p.mapparms()`` -- Return the parameters for the linear mapping between",
        "- ``p.mapparms()`` -- Return the parameters for the linear"
    ],
    [
        "- ``p.roots()``    -- Return the roots of ``p``.",
        "- ``p.roots()`` -- Return"
    ],
    [
        "- ``p.trim()``     -- Remove trailing coefficients.",
        "- ``p.trim()`` -- Remove trailing"
    ],
    [
        "- ``p.cutdeg(degree)`` -- Truncate ``p`` to given degree",
        "- ``p.cutdeg(degree)`` -- Truncate ``p`` to given"
    ],
    [
        "- ``p.truncate(size)`` -- Truncate ``p`` to given size",
        "- ``p.truncate(size)`` -- Truncate ``p`` to given"
    ],
    [
        "Set the default format for the string representation of polynomials.",
        "Set the default format for"
    ],
    [
        "Values for ``style`` must be valid inputs to ``__format__``, i.e. 'ascii'",
        "Values for ``style`` must be valid inputs to ``__format__``,"
    ],
    [
        "Format string for default printing style. Must be either 'ascii' or",
        "Format string for default printing style. Must"
    ],
    [
        "The default format depends on the platform: 'unicode' is used on",
        "The default format depends on the platform:"
    ],
    [
        "Unix-based systems and 'ascii' on Windows. This determination is based on",
        "Unix-based systems and 'ascii' on Windows."
    ],
    [
        "default font support for the unicode superscript and subscript ranges.",
        "default font support for the unicode superscript and"
    ],
    [
        "if style not in ('unicode', 'ascii'):",
        "if style not in"
    ],
    [
        "f\"Unsupported format string '{style}'. Valid options are 'ascii' \"",
        "f\"Unsupported format string '{style}'. Valid options"
    ],
    [
        "This module provides a number of objects (mostly functions) useful for",
        "This module provides a number of objects (mostly"
    ],
    [
        "dealing with Hermite_e series, including a `HermiteE` class that",
        "dealing with Hermite_e series, including a `HermiteE`"
    ],
    [
        "encapsulates the usual arithmetic operations.  (General information",
        "encapsulates the usual arithmetic"
    ],
    [
        "on how this module represents and works with such polynomials is in the",
        "on how this module represents and works with such polynomials"
    ],
    [
        "docstring for its \"parent\" sub-package, `numpy.polynomial`).",
        "docstring for its \"parent\""
    ],
    [
        "from . import polyutils as pu",
        "from . import polyutils"
    ],
    [
        "Convert a polynomial to a Hermite series.",
        "Convert a polynomial to"
    ],
    [
        "Convert an array representing the coefficients of a polynomial (relative",
        "Convert an array representing the"
    ],
    [
        "to the \"standard\" basis) ordered from lowest degree to highest, to an",
        "to the \"standard\" basis) ordered from lowest degree to highest, to"
    ],
    [
        "array of the coefficients of the equivalent Hermite series, ordered",
        "array of the coefficients of"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do conversions between"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert method"
    ],
    [
        "Convert a Hermite series to a polynomial.",
        "Convert a Hermite series to"
    ],
    [
        "Convert an array representing the coefficients of a Hermite series,",
        "Convert an array representing the coefficients of"
    ],
    [
        "ordered from lowest degree to highest, to an array of the coefficients",
        "ordered from lowest degree to highest,"
    ],
    [
        "of the equivalent polynomial (relative to the \"standard\" basis) ordered",
        "of the equivalent polynomial (relative to the"
    ],
    [
        "from lowest order term to highest.",
        "from lowest order"
    ],
    [
        "(relative to the \"standard\" basis) ordered from lowest order term",
        "(relative to the \"standard\" basis) ordered from"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do conversions"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert"
    ],
    [
        "from .polynomial import polyadd, polysub, polymulx",
        "from .polynomial import"
    ],
    [
        "Hermite series whose graph is a straight line.",
        "Hermite series whose graph is a"
    ],
    [
        "The specified line is given by ``off + scl*x``.",
        "The specified line is given by"
    ],
    [
        "This module's representation of the Hermite series for",
        "This module's representation of the"
    ],
    [
        ">>> from numpy.polynomial.hermite_e import hermeline, hermeval",
        ">>> from numpy.polynomial.hermite_e import"
    ],
    [
        "Generate a HermiteE series with given roots.",
        "Generate a HermiteE series"
    ],
    [
        "The function returns the coefficients of the polynomial",
        "The function returns the coefficients of the"
    ],
    [
        "in HermiteE form, where the :math:`r_n` are the roots specified in `roots`.",
        "in HermiteE form, where the :math:`r_n`"
    ],
    [
        "If a zero has multiplicity n, then it must appear in `roots` n times.",
        "If a zero has multiplicity n, then it"
    ],
    [
        "roots can appear in any order.",
        "roots can appear in"
    ],
    [
        "If the returned coefficients are `c`, then",
        "If the returned coefficients"
    ],
    [
        "real array, if some of the roots are complex, then `out` is complex",
        "real array, if some of the roots are complex, then `out` is"
    ],
    [
        "even if all the coefficients in the result are real (see Examples",
        "even if all the coefficients in the result are real"
    ],
    [
        ">>> from numpy.polynomial.hermite_e import hermefromroots, hermeval",
        ">>> from numpy.polynomial.hermite_e"
    ],
    [
        "Add one Hermite series to another.",
        "Add one Hermite series to"
    ],
    [
        "are sequences of coefficients ordered from lowest order term to",
        "are sequences of coefficients ordered from"
    ],
    [
        "Array representing the Hermite series of their sum.",
        "Array representing the Hermite series"
    ],
    [
        "Unlike multiplication, division, etc., the sum of two Hermite series",
        "Unlike multiplication, division, etc., the sum of"
    ],
    [
        "is a Hermite series (without having to \"reproject\" the result onto",
        "is a Hermite series (without having to \"reproject\""
    ],
    [
        "the basis set) so addition, just like that of \"standard\" polynomials,",
        "the basis set) so addition, just"
    ],
    [
        "Subtract one Hermite series from another.",
        "Subtract one Hermite"
    ],
    [
        "sequences of coefficients are from lowest order term to highest, i.e.,",
        "sequences of coefficients are from lowest order term to"
    ],
    [
        "Of Hermite series coefficients representing their difference.",
        "Of Hermite series coefficients representing their"
    ],
    [
        "Unlike multiplication, division, etc., the difference of two Hermite",
        "Unlike multiplication, division, etc., the"
    ],
    [
        "series is a Hermite series (without having to \"reproject\" the result",
        "series is a Hermite series (without having to"
    ],
    [
        "onto the basis set) so subtraction, just like that of \"standard\"",
        "onto the basis set) so subtraction, just like that of"
    ],
    [
        "\"\"\"Multiply a Hermite series by x.",
        "\"\"\"Multiply a Hermite series by"
    ],
    [
        "Multiply the Hermite series `c` by x, where x is the independent",
        "Multiply the Hermite series `c` by x,"
    ],
    [
        "Array representing the result of the multiplication.",
        "Array representing the result of the"
    ],
    [
        "The multiplication uses the recursion relationship for Hermite",
        "The multiplication uses the recursion"
    ],
    [
        "Multiply one Hermite series by another.",
        "Multiply one Hermite series"
    ],
    [
        "are sequences of coefficients, from lowest order \"term\" to highest,",
        "are sequences of coefficients, from"
    ],
    [
        "Of Hermite series coefficients representing their product.",
        "Of Hermite series coefficients representing"
    ],
    [
        "In general, the (polynomial) product of two C-series results in terms",
        "In general, the (polynomial) product of"
    ],
    [
        "that are not in the Hermite polynomial basis set.  Thus, to express",
        "that are not in the Hermite polynomial basis set. Thus, to"
    ],
    [
        "the product as a Hermite series, it is necessary to \"reproject\" the",
        "the product as a Hermite series, it is necessary to \"reproject\""
    ],
    [
        "product onto said basis set, which may produce \"unintuitive\" (but",
        "product onto said basis set, which"
    ],
    [
        "correct) results; see Examples section below.",
        "correct) results; see"
    ],
    [
        "Divide one Hermite series by another.",
        "Divide one Hermite series by"
    ],
    [
        "Returns the quotient-with-remainder of two Hermite series",
        "Returns the quotient-with-remainder of two"
    ],
    [
        "Of Hermite series coefficients representing the quotient and",
        "Of Hermite series coefficients representing the"
    ],
    [
        "In general, the (polynomial) division of one Hermite series by another",
        "In general, the (polynomial) division of"
    ],
    [
        "results in quotient and remainder terms that are not in the Hermite",
        "results in quotient and remainder terms that are not in the"
    ],
    [
        "polynomial basis set.  Thus, to express these results as a Hermite",
        "polynomial basis set. Thus, to express"
    ],
    [
        "series, it is necessary to \"reproject\" the results onto the Hermite",
        "series, it is necessary to \"reproject\""
    ],
    [
        "basis set, which may produce \"unintuitive\" (but correct) results; see",
        "basis set, which may produce \"unintuitive\" (but correct)"
    ],
    [
        "\"\"\"Raise a Hermite series to a power.",
        "\"\"\"Raise a Hermite series to a"
    ],
    [
        "Returns the Hermite series `c` raised to the power `pow`. The",
        "Returns the Hermite series `c` raised to the power `pow`."
    ],
    [
        "argument `c` is a sequence of coefficients ordered from low to high.",
        "argument `c` is a sequence of coefficients ordered from low to"
    ],
    [
        "Power to which the series will be raised",
        "Power to which the series will be"
    ],
    [
        "Maximum power allowed. This is mainly to limit growth of the series",
        "Maximum power allowed. This is mainly to limit"
    ],
    [
        "Returns the series coefficients `c` differentiated `m` times along",
        "Returns the series coefficients `c` differentiated `m`"
    ],
    [
        "`axis`.  At each iteration the result is multiplied by `scl` (the",
        "`axis`. At each iteration the result is"
    ],
    [
        "scaling factor is for use in a linear change of variable). The argument",
        "scaling factor is for use in a linear change of variable)."
    ],
    [
        "`c` is an array of coefficients from low to high degree along each",
        "`c` is an array of coefficients from low to high"
    ],
    [
        "Array of Hermite_e series coefficients. If `c` is multidimensional",
        "Array of Hermite_e series coefficients."
    ],
    [
        "the different axis correspond to different variables with the",
        "the different axis correspond to different"
    ],
    [
        "degree in each axis given by the corresponding index.",
        "degree in each axis given by the"
    ],
    [
        "Each differentiation is multiplied by `scl`.  The end result is",
        "Each differentiation is multiplied by `scl`. The end"
    ],
    [
        "multiplication by ``scl**m``.  This is for use in a linear change of",
        "multiplication by ``scl**m``. This is for use in"
    ],
    [
        "In general, the result of differentiating a Hermite series does not",
        "In general, the result of differentiating a Hermite series does"
    ],
    [
        "resemble the same operation on a power series. Thus the result of this",
        "resemble the same operation on a power series. Thus the result of"
    ],
    [
        "function may be \"unintuitive,\" albeit correct; see Examples section",
        "function may be \"unintuitive,\" albeit correct; see"
    ],
    [
        "cnt = pu._as_int(m, \"the order of derivation\")",
        "cnt = pu._as_int(m, \"the"
    ],
    [
        "raise ValueError(\"The order of derivation must be non-negative\")",
        "raise ValueError(\"The order of derivation must"
    ],
    [
        "Returns the Hermite_e series coefficients `c` integrated `m` times from",
        "Returns the Hermite_e series coefficients"
    ],
    [
        "`lbnd` along `axis`. At each iteration the resulting series is",
        "`lbnd` along `axis`. At each iteration the resulting series"
    ],
    [
        "**multiplied** by `scl` and an integration constant, `k`, is added.",
        "**multiplied** by `scl` and an integration constant, `k`,"
    ],
    [
        "The scaling factor is for use in a linear change of variable.  (\"Buyer",
        "The scaling factor is for use in a linear"
    ],
    [
        "beware\": note that, depending on what one is doing, one may want `scl`",
        "beware\": note that, depending on what one is doing, one may want"
    ],
    [
        "to be the reciprocal of what one might expect; for more information,",
        "to be the reciprocal of what one might expect; for"
    ],
    [
        "see the Notes section below.)  The argument `c` is an array of",
        "see the Notes section below.) The"
    ],
    [
        "Array of Hermite_e series coefficients. If c is multidimensional",
        "Array of Hermite_e series coefficients."
    ],
    [
        "the different axis correspond to different variables with the",
        "the different axis correspond to different variables with"
    ],
    [
        "degree in each axis given by the corresponding index.",
        "degree in each axis given by the corresponding"
    ],
    [
        "k : {[], list, scalar}, optional",
        "k : {[], list, scalar},"
    ],
    [
        "Integration constant(s).  The value of the first integral at",
        "Integration constant(s). The value of"
    ],
    [
        "``lbnd`` is the first value in the list, the value of the second",
        "``lbnd`` is the first value in the list,"
    ],
    [
        "integral at ``lbnd`` is the second value, etc.  If ``k == []`` (the",
        "integral at ``lbnd`` is the second value, etc. If ``k"
    ],
    [
        "scalar can be given instead of a list.",
        "scalar can be given"
    ],
    [
        "Following each integration the result is *multiplied* by `scl`",
        "Following each integration the result is *multiplied* by"
    ],
    [
        "Hermite_e series coefficients of the integral.",
        "Hermite_e series coefficients of the"
    ],
    [
        "Note that the result of each integration is *multiplied* by `scl`.",
        "Note that the result of each integration is"
    ],
    [
        "Why is this important to note?  Say one is making a linear change of",
        "Why is this important to note? Say one is making a linear"
    ],
    [
        "variable :math:`u = ax + b` in an integral relative to `x`.  Then",
        "variable :math:`u = ax + b` in an integral relative to"
    ],
    [
        ":math:`dx = du/a`, so one will need to set `scl` equal to",
        ":math:`dx = du/a`, so one will"
    ],
    [
        "Also note that, in general, the result of integrating a C-series needs",
        "Also note that, in general, the result of integrating a C-series"
    ],
    [
        "to be \"reprojected\" onto the C-series basis set.  Thus, typically,",
        "to be \"reprojected\" onto the C-series basis"
    ],
    [
        "the result of this function is \"unintuitive,\" albeit correct; see",
        "the result of this function"
    ],
    [
        "cnt = pu._as_int(m, \"the order of integration\")",
        "cnt = pu._as_int(m, \"the order"
    ],
    [
        "raise ValueError(\"The order of integration must be non-negative\")",
        "raise ValueError(\"The order of integration must"
    ],
    [
        "raise ValueError(\"lbnd must be a scalar.\")",
        "raise ValueError(\"lbnd must be"
    ],
    [
        "raise ValueError(\"scl must be a scalar.\")",
        "raise ValueError(\"scl must be a"
    ],
    [
        "Evaluate an HermiteE series at points x.",
        "Evaluate an HermiteE series at"
    ],
    [
        "The parameter `x` is converted to an array only if it is a tuple or a",
        "The parameter `x` is converted to an array only if it is"
    ],
    [
        "list, otherwise it is treated as a scalar. In either case, either `x`",
        "list, otherwise it is treated as a scalar."
    ],
    [
        "or its elements must support multiplication and addition both with",
        "or its elements must support multiplication and"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the"
    ],
    [
        "`c` is multidimensional, then the shape of the result depends on the",
        "`c` is multidimensional, then the shape of the"
    ],
    [
        "Trailing zeros in the coefficients will be used in the evaluation, so",
        "Trailing zeros in the coefficients will be used in the"
    ],
    [
        "they should be avoided if efficiency is a concern.",
        "they should be avoided if efficiency"
    ],
    [
        "If `x` is a list or tuple, it is converted to an ndarray, otherwise",
        "If `x` is a list or tuple, it"
    ],
    [
        "it is left unchanged and treated as a scalar. In either case, `x`",
        "it is left unchanged and treated as a scalar. In either case,"
    ],
    [
        "or its elements must support addition and multiplication with",
        "or its elements must support"
    ],
    [
        "with themselves and with the elements of `c`.",
        "with themselves and with the"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that"
    ],
    [
        "degree n are contained in c[n]. If `c` is multidimensional the",
        "degree n are contained in c[n]. If `c` is"
    ],
    [
        "remaining indices enumerate multiple polynomials. In the two",
        "remaining indices enumerate multiple polynomials. In the"
    ],
    [
        "dimensional case the coefficients may be thought of as stored in",
        "dimensional case the coefficients may be thought"
    ],
    [
        "If True, the shape of the coefficient array is extended with ones",
        "If True, the shape of the coefficient array"
    ],
    [
        "for this action. The result is that every column of coefficients in",
        "for this action. The result is that every column of"
    ],
    [
        "`c` is evaluated for every element of `x`. If False, `x` is broadcast",
        "`c` is evaluated for every element of `x`. If False, `x`"
    ],
    [
        "over the columns of `c` for the evaluation.  This keyword is useful",
        "over the columns of `c` for"
    ],
    [
        "when `c` is multidimensional. The default value is True.",
        "when `c` is multidimensional. The"
    ],
    [
        "The shape of the return value is described above.",
        "The shape of the return value"
    ],
    [
        "The evaluation uses Clenshaw recursion, aka synthetic division.",
        "The evaluation uses Clenshaw"
    ],
    [
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * He_i(x) * He_j(y)",
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * He_i(x) *"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted to arrays"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars and they",
        "tuples or a lists, otherwise they are treated as a scalars and"
    ],
    [
        "must have the same shape after conversion. In either case, either `x`",
        "must have the same shape after conversion. In either case, either"
    ],
    [
        "and `y` or their elements must support multiplication and addition both",
        "and `y` or their elements must support multiplication and addition"
    ],
    [
        "with themselves and with the elements of `c`.",
        "with themselves and with the"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like, compatible"
    ],
    [
        "The two dimensional series is evaluated at the points ``(x, y)``,",
        "The two dimensional series is evaluated at the"
    ],
    [
        "where `x` and `y` must have the same shape. If `x` or `y` is a list",
        "where `x` and `y` must have the same shape. If `x`"
    ],
    [
        "or tuple, it is first converted to an ndarray, otherwise it is left",
        "or tuple, it is first converted to an ndarray,"
    ],
    [
        "unchanged and if it isn't an ndarray it is treated as a scalar.",
        "unchanged and if it isn't an ndarray it is"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term",
        "Array of coefficients ordered so that the coefficient of"
    ],
    [
        "of multi-degree i,j is contained in ``c[i,j]``. If `c` has",
        "of multi-degree i,j is contained in"
    ],
    [
        "dimension greater than two the remaining indices enumerate multiple",
        "dimension greater than two the remaining indices enumerate"
    ],
    [
        "The values of the two dimensional polynomial at points formed with",
        "The values of the two dimensional polynomial"
    ],
    [
        "pairs of corresponding values from `x` and `y`.",
        "pairs of corresponding values from"
    ],
    [
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j} * H_i(a) * H_j(b)",
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j} * H_i(a)"
    ],
    [
        "where the points ``(a, b)`` consist of all pairs formed by taking",
        "where the points ``(a, b)`` consist of"
    ],
    [
        "`a` from `x` and `b` from `y`. The resulting points form a grid with",
        "`a` from `x` and `b` from `y`. The resulting points"
    ],
    [
        "`x` in the first dimension and `y` in the second.",
        "`x` in the first dimension and `y`"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars. In either",
        "tuples or a lists, otherwise they are"
    ],
    [
        "case, either `x` and `y` or their elements must support multiplication",
        "case, either `x` and `y` or their elements"
    ],
    [
        "and addition both with themselves and with the elements of `c`.",
        "and addition both with themselves and"
    ],
    [
        "If `c` has fewer than two dimensions, ones are implicitly appended to",
        "If `c` has fewer than two dimensions, ones are"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like,"
    ],
    [
        "The two dimensional series is evaluated at the points in the",
        "The two dimensional series is evaluated at the"
    ],
    [
        "Cartesian product of `x` and `y`.  If `x` or `y` is a list or",
        "Cartesian product of `x` and `y`. If `x` or `y`"
    ],
    [
        "tuple, it is first converted to an ndarray, otherwise it is left",
        "tuple, it is first converted to an ndarray, otherwise"
    ],
    [
        "unchanged and, if it isn't an ndarray, it is treated as a scalar.",
        "unchanged and, if it isn't an ndarray, it is treated as a"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in ``c[i,j]``. If `c`"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices enumerate"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional polynomial at points in the"
    ],
    [
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * He_i(x) * He_j(y) * He_k(z)",
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * He_i(x)"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if",
        "The parameters `x`, `y`, and `z` are converted to arrays"
    ],
    [
        "they are tuples or a lists, otherwise they are treated as a scalars and",
        "they are tuples or a lists, otherwise"
    ],
    [
        "they must have the same shape after conversion. In either case, either",
        "they must have the same shape after conversion. In either"
    ],
    [
        "`x`, `y`, and `z` or their elements must support multiplication and",
        "`x`, `y`, and `z` or their elements must support"
    ],
    [
        "addition both with themselves and with the elements of `c`.",
        "addition both with themselves and with the elements"
    ],
    [
        "x, y, z : array_like, compatible object",
        "x, y, z :"
    ],
    [
        "The three dimensional series is evaluated at the points",
        "The three dimensional series is evaluated at the"
    ],
    [
        "`(x, y, z)`, where `x`, `y`, and `z` must have the same shape.  If",
        "`(x, y, z)`, where `x`, `y`, and `z`"
    ],
    [
        "any of `x`, `y`, or `z` is a list or tuple, it is first converted",
        "any of `x`, `y`, or `z` is a list or tuple, it is"
    ],
    [
        "to an ndarray, otherwise it is left unchanged and if it isn't an",
        "to an ndarray, otherwise it is left unchanged"
    ],
    [
        "ndarray it is  treated as a scalar.",
        "ndarray it is treated as a"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that"
    ],
    [
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension",
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c`"
    ],
    [
        "The values of the multidimensional polynomial on points formed with",
        "The values of the multidimensional polynomial on"
    ],
    [
        "triples of corresponding values from `x`, `y`, and `z`.",
        "triples of corresponding values from `x`, `y`,"
    ],
    [
        "return pu._valnd(hermeval, c, x, y, z)",
        "return pu._valnd(hermeval, c, x, y,"
    ],
    [
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * He_i(a) * He_j(b) * He_k(c)",
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * He_i(a) * He_j(b)"
    ],
    [
        "where the points ``(a, b, c)`` consist of all triples formed by taking",
        "where the points ``(a, b, c)`` consist of all"
    ],
    [
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form",
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting points"
    ],
    [
        "a grid with `x` in the first dimension, `y` in the second, and `z` in",
        "a grid with `x` in the first dimension, `y` in"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if they",
        "The parameters `x`, `y`, and `z` are"
    ],
    [
        "are tuples or a lists, otherwise they are treated as a scalars. In",
        "are tuples or a lists, otherwise they are"
    ],
    [
        "either case, either `x`, `y`, and `z` or their elements must support",
        "either case, either `x`, `y`, and `z` or their elements"
    ],
    [
        "multiplication and addition both with themselves and with the elements",
        "multiplication and addition both with"
    ],
    [
        "If `c` has fewer than three dimensions, ones are implicitly appended to",
        "If `c` has fewer than three dimensions, ones are"
    ],
    [
        "x, y, z : array_like, compatible objects",
        "x, y, z :"
    ],
    [
        "The three dimensional series is evaluated at the points in the",
        "The three dimensional series is evaluated at the points in"
    ],
    [
        "Cartesian product of `x`, `y`, and `z`.  If `x`, `y`, or `z` is a",
        "Cartesian product of `x`, `y`, and `z`. If `x`, `y`, or `z` is"
    ],
    [
        "list or tuple, it is first converted to an ndarray, otherwise it is",
        "list or tuple, it is first converted to an ndarray, otherwise it"
    ],
    [
        "left unchanged and, if it isn't an ndarray, it is treated as a",
        "left unchanged and, if it isn't an ndarray, it is treated"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in ``c[i,j]``. If"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices enumerate multiple"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional polynomial at points in the"
    ],
    [
        "return pu._gridnd(hermeval, c, x, y, z)",
        "return pu._gridnd(hermeval, c, x,"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degree `deg` and sample points",
        "Returns the pseudo-Vandermonde matrix of degree `deg`"
    ],
    [
        "`x`. The pseudo-Vandermonde matrix is defined by",
        "`x`. The pseudo-Vandermonde matrix is"
    ],
    [
        ".. math:: V[..., i] = He_i(x),",
        ".. math:: V[..., i]"
    ],
    [
        "`x` and the last index is the degree of the HermiteE polynomial.",
        "`x` and the last index is the degree of the HermiteE"
    ],
    [
        "array ``V = hermevander(x, n)``, then ``np.dot(V, c)`` and",
        "array ``V = hermevander(x, n)``, then ``np.dot(V,"
    ],
    [
        "``hermeval(x, c)`` are the same up to roundoff. This equivalence is",
        "``hermeval(x, c)`` are the same up to roundoff."
    ],
    [
        "useful both for least squares fitting and for the evaluation of a large",
        "useful both for least squares fitting and for the"
    ],
    [
        "number of HermiteE series of the same degree and sample points.",
        "number of HermiteE series of the same"
    ],
    [
        "depending on whether any of the elements are complex. If `x` is",
        "depending on whether any of the elements are complex. If `x`"
    ],
    [
        "The pseudo-Vandermonde matrix. The shape of the returned matrix is",
        "The pseudo-Vandermonde matrix. The shape of"
    ],
    [
        "corresponding HermiteE polynomial.  The dtype will be the same as",
        "corresponding HermiteE polynomial. The dtype will be the"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg`"
    ],
    [
        "points ``(x, y)``. The pseudo-Vandermonde matrix is defined by",
        "points ``(x, y)``. The pseudo-Vandermonde matrix"
    ],
    [
        "`V` index the points ``(x, y)`` and the last index encodes the degrees of",
        "`V` index the points ``(x, y)`` and"
    ],
    [
        "up to roundoff. This equivalence is useful both for least squares",
        "up to roundoff. This equivalence is useful both"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same degrees and"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes",
        "Arrays of point coordinates, all of the same shape."
    ],
    [
        "whether any of the elements are complex. Scalars are converted to",
        "whether any of the elements are complex. Scalars are"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg].",
        "List of maximum degrees of"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is ``x.shape"
    ],
    [
        "as the converted `x` and `y`.",
        "as the converted `x`"
    ],
    [
        "return pu._vander_nd_flat((hermevander, hermevander), (x, y), deg)",
        "return pu._vander_nd_flat((hermevander, hermevander), (x, y),"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and"
    ],
    [
        "points ``(x, y, z)``. If `l`, `m`, `n` are the given degrees in `x`, `y`, `z`,",
        "points ``(x, y, z)``. If `l`, `m`, `n`"
    ],
    [
        "then Hehe pseudo-Vandermonde matrix is defined by",
        "then Hehe pseudo-Vandermonde matrix is"
    ],
    [
        "indices of `V` index the points ``(x, y, z)`` and the last index encodes",
        "indices of `V` index the points ``(x, y, z)`` and the last"
    ],
    [
        "the degrees of the HermiteE polynomials.",
        "the degrees of the"
    ],
    [
        "same up to roundoff. This equivalence is useful both for least squares",
        "same up to roundoff. This equivalence is useful"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same degrees and sample"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes will",
        "Arrays of point coordinates, all of the"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg, z_deg].",
        "List of maximum degrees of the form [x_deg, y_deg,"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is ``x.shape"
    ],
    [
        "be the same as the converted `x`, `y`, and `z`.",
        "be the same as the converted `x`, `y`,"
    ],
    [
        "return pu._vander_nd_flat((hermevander, hermevander, hermevander), (x, y, z), deg)",
        "return pu._vander_nd_flat((hermevander, hermevander, hermevander), (x,"
    ],
    [
        "def hermefit(x, y, deg, rcond=None, full=False, w=None):",
        "def hermefit(x, y, deg,"
    ],
    [
        "Least squares fit of Hermite series to data.",
        "Least squares fit of"
    ],
    [
        "Return the coefficients of a HermiteE series of degree `deg` that is",
        "Return the coefficients of a HermiteE series of degree"
    ],
    [
        "the least squares fit to the data values `y` given at points `x`. If",
        "the least squares fit to the data"
    ],
    [
        "multiple fits are done, one for each column of `y`, and the resulting",
        "multiple fits are done, one for each column of"
    ],
    [
        "The fitted polynomial(s) are in the form",
        "The fitted polynomial(s) are in"
    ],
    [
        "x-coordinates of the M sample points ``(x[i], y[i])``.",
        "x-coordinates of the M sample"
    ],
    [
        "y : array_like, shape (M,) or (M, K)",
        "y : array_like, shape"
    ],
    [
        "y-coordinates of the sample points. Several data sets of sample",
        "y-coordinates of the sample points. Several data sets of"
    ],
    [
        "points sharing the same x-coordinates can be fitted at once by",
        "points sharing the same x-coordinates can be fitted at once"
    ],
    [
        "Degree(s) of the fitting polynomials. If `deg` is a single integer",
        "Degree(s) of the fitting polynomials. If"
    ],
    [
        "all terms up to and including the `deg`'th term are included in the",
        "all terms up to and including the"
    ],
    [
        "degrees of the terms to include may be used instead.",
        "degrees of the terms to include may be used"
    ],
    [
        "Relative condition number of the fit. Singular values smaller than",
        "Relative condition number of the fit. Singular"
    ],
    [
        "this relative to the largest singular value will be ignored. The",
        "this relative to the largest singular value"
    ],
    [
        "default value is len(x)*eps, where eps is the relative precision of",
        "default value is len(x)*eps, where eps is the"
    ],
    [
        "Switch determining nature of return value. When it is False (the",
        "Switch determining nature of return value. When it is"
    ],
    [
        "default) just the coefficients are returned, when True diagnostic",
        "default) just the coefficients are"
    ],
    [
        "information from the singular value decomposition is also returned.",
        "information from the singular value decomposition"
    ],
    [
        "w : array_like, shape (`M`,), optional",
        "w : array_like, shape (`M`,),"
    ],
    [
        "Weights. If not None, the weight ``w[i]`` applies to the unsquared",
        "Weights. If not None, the weight ``w[i]`` applies"
    ],
    [
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are",
        "residual ``y[i] - y_hat[i]`` at ``x[i]``."
    ],
    [
        "chosen so that the errors of the products ``w[i]*y[i]`` all have the",
        "chosen so that the errors of the products"
    ],
    [
        "same variance.  When using inverse-variance weighting, use",
        "same variance. When using inverse-variance weighting,"
    ],
    [
        "coef : ndarray, shape (M,) or (M, K)",
        "coef : ndarray, shape (M,)"
    ],
    [
        "the coefficients for the data in column k  of `y` are in column",
        "the coefficients for the data in column k of `y` are"
    ],
    [
        "[residuals, rank, singular_values, rcond] : list",
        "[residuals, rank, singular_values, rcond] :"
    ],
    [
        "These values are only returned if ``full == True``",
        "These values are only returned if ``full"
    ],
    [
        "- residuals -- sum of squared residuals of the least squares fit",
        "- residuals -- sum of squared residuals of the least squares"
    ],
    [
        "- rank -- the numerical rank of the scaled Vandermonde matrix",
        "- rank -- the numerical rank of"
    ],
    [
        "- singular_values -- singular values of the scaled Vandermonde matrix",
        "- singular_values -- singular values"
    ],
    [
        "- rcond -- value of `rcond`.",
        "- rcond -- value of"
    ],
    [
        "The rank of the coefficient matrix in the least-squares fit is",
        "The rank of the coefficient matrix in the"
    ],
    [
        "deficient. The warning is only raised if ``full = False``.  The",
        "deficient. The warning is only raised if"
    ],
    [
        "warnings can be turned off by",
        "warnings can be"
    ],
    [
        "hermeval : Evaluates a Hermite series.",
        "hermeval : Evaluates a Hermite"
    ],
    [
        "hermevander : pseudo Vandermonde matrix of Hermite series.",
        "hermevander : pseudo Vandermonde matrix of Hermite"
    ],
    [
        "numpy.linalg.lstsq : Computes a least-squares fit from the matrix.",
        "numpy.linalg.lstsq : Computes a least-squares"
    ],
    [
        "The solution is the coefficients of the HermiteE series `p` that",
        "The solution is the coefficients of"
    ],
    [
        "minimizes the sum of the weighted squared errors",
        "minimizes the sum of the"
    ],
    [
        "where the :math:`w_j` are the weights. This problem is solved by",
        "where the :math:`w_j` are the weights. This problem"
    ],
    [
        "setting up the (typically) overdetermined matrix equation",
        "setting up the (typically) overdetermined"
    ],
    [
        ".. math:: V(x) * c = w * y,",
        ".. math:: V(x) * c = w"
    ],
    [
        "where `V` is the pseudo Vandermonde matrix of `x`, the elements of `c`",
        "where `V` is the pseudo Vandermonde matrix of `x`, the elements of"
    ],
    [
        "are the coefficients to be solved for, and the elements of `y` are the",
        "are the coefficients to be solved for, and the elements"
    ],
    [
        "observed values.  This equation is then solved using the singular value",
        "observed values. This equation is then solved using"
    ],
    [
        "If some of the singular values of `V` are so small that they are",
        "If some of the singular values of `V` are so"
    ],
    [
        "neglected, then a `~exceptions.RankWarning` will be issued. This means that",
        "neglected, then a `~exceptions.RankWarning` will"
    ],
    [
        "the coefficient values may be poorly determined. Using a lower order fit",
        "the coefficient values may be poorly"
    ],
    [
        "will usually get rid of the warning.  The `rcond` parameter can also be",
        "will usually get rid of the warning. The `rcond`"
    ],
    [
        "set to a value smaller than its default, but the resulting fit may be",
        "set to a value smaller than its default, but the"
    ],
    [
        "spurious and have large contributions from roundoff error.",
        "spurious and have large contributions from"
    ],
    [
        "Fits using HermiteE series are probably most useful when the data can",
        "Fits using HermiteE series are probably most useful when the data"
    ],
    [
        "be approximated by ``sqrt(w(x)) * p(x)``, where ``w(x)`` is the HermiteE",
        "be approximated by ``sqrt(w(x)) * p(x)``, where ``w(x)`` is"
    ],
    [
        "weight. In that case the weight ``sqrt(w(x[i]))`` should be used",
        "weight. In that case the weight ``sqrt(w(x[i]))`` should"
    ],
    [
        "together with data values ``y[i]/sqrt(w(x[i]))``. The weight function is",
        "together with data values ``y[i]/sqrt(w(x[i]))``. The"
    ],
    [
        ">>> from numpy.polynomial.hermite_e import hermefit, hermeval",
        ">>> from numpy.polynomial.hermite_e"
    ],
    [
        "return pu._fit(hermevander, x, y, deg, rcond, full, w)",
        "return pu._fit(hermevander, x, y, deg, rcond, full,"
    ],
    [
        "Return the scaled companion matrix of c.",
        "Return the scaled companion matrix of"
    ],
    [
        "The basis polynomials are scaled so that the companion matrix is",
        "The basis polynomials are scaled so that the"
    ],
    [
        "symmetric when `c` is an HermiteE basis polynomial. This provides",
        "symmetric when `c` is an"
    ],
    [
        "better eigenvalue estimates than the unscaled case and for basis",
        "better eigenvalue estimates than the unscaled case and for"
    ],
    [
        "polynomials the eigenvalues are guaranteed to be real if",
        "polynomials the eigenvalues are guaranteed to be real"
    ],
    [
        "`numpy.linalg.eigvalsh` is used to obtain them.",
        "`numpy.linalg.eigvalsh` is used to obtain"
    ],
    [
        "Scaled companion matrix of dimensions (deg, deg).",
        "Scaled companion matrix of dimensions (deg,"
    ],
    [
        "Compute the roots of a HermiteE series.",
        "Compute the roots of"
    ],
    [
        "Return the roots (a.k.a. \"zeros\") of the polynomial",
        "Return the roots (a.k.a. \"zeros\") of"
    ],
    [
        ".. math:: p(x) = \\\\sum_i c[i] * He_i(x).",
        ".. math:: p(x) = \\\\sum_i"
    ],
    [
        "Array of the roots of the series. If all the roots are real,",
        "Array of the roots of the series. If all the roots are"
    ],
    [
        "then `out` is also real, otherwise it is complex.",
        "then `out` is also real, otherwise it is"
    ],
    [
        "The root estimates are obtained as the eigenvalues of the companion",
        "The root estimates are obtained as the eigenvalues of the"
    ],
    [
        "matrix, Roots far from the origin of the complex plane may have large",
        "matrix, Roots far from the origin of the complex plane"
    ],
    [
        "errors due to the numerical instability of the series for such",
        "errors due to the numerical instability of"
    ],
    [
        "errors as the value of the series near such points is relatively",
        "errors as the value of the"
    ],
    [
        "insensitive to errors in the roots. Isolated roots near the origin can",
        "insensitive to errors in the roots. Isolated roots near the origin"
    ],
    [
        "be improved by a few iterations of Newton's method.",
        "be improved by a few iterations"
    ],
    [
        "The HermiteE series basis polynomials aren't powers of `x` so the",
        "The HermiteE series basis polynomials aren't powers of `x` so"
    ],
    [
        "results of this function may seem unintuitive.",
        "results of this function"
    ],
    [
        ">>> from numpy.polynomial.hermite_e import hermeroots, hermefromroots",
        ">>> from numpy.polynomial.hermite_e import hermeroots,"
    ],
    [
        "Compute the value of the normalized HermiteE polynomial of degree ``n``",
        "Compute the value of the normalized HermiteE"
    ],
    [
        "Points at which to evaluate the function",
        "Points at which to"
    ],
    [
        "Degree of the normalized HermiteE function to be evaluated.",
        "Degree of the normalized HermiteE function to be"
    ],
    [
        "The shape of the return value is described above.",
        "The shape of the return value"
    ],
    [
        "This function is needed for finding the Gauss points and integration",
        "This function is needed for finding the Gauss points and"
    ],
    [
        "weights for high degrees. The values of the standard HermiteE functions",
        "weights for high degrees. The values of the standard HermiteE"
    ],
    [
        "Computes the sample points and weights for Gauss-HermiteE quadrature.",
        "Computes the sample points and"
    ],
    [
        "These sample points and weights will correctly integrate polynomials of",
        "These sample points and weights will correctly"
    ],
    [
        "be problematic. The weights are determined by using the fact that",
        "be problematic. The weights are determined by using"
    ],
    [
        "where :math:`c` is a constant independent of :math:`k` and :math:`x_k`",
        "where :math:`c` is a constant independent of :math:`k` and"
    ],
    [
        "is the k'th root of :math:`He_n`, and then scaling the results to get",
        "is the k'th root of :math:`He_n`, and then scaling"
    ],
    [
        "raise ValueError(\"deg must be a positive integer\")",
        "raise ValueError(\"deg must be"
    ],
    [
        "\"\"\"Weight function of the Hermite_e polynomials.",
        "\"\"\"Weight function of the"
    ],
    [
        "integration is :math:`[-\\\\inf, \\\\inf]`. the HermiteE polynomials are",
        "integration is :math:`[-\\\\inf, \\\\inf]`. the HermiteE polynomials"
    ],
    [
        "orthogonal, but not normalized, with respect to this weight function.",
        "orthogonal, but not normalized, with respect to this weight"
    ],
    [
        "Values at which the weight function will be computed.",
        "Values at which the weight function will be"
    ],
    [
        "The HermiteE class provides the standard Python numerical methods",
        "The HermiteE class provides the standard"
    ],
    [
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as the",
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well"
    ],
    [
        "HermiteE coefficients in order of increasing degree, i.e,",
        "HermiteE coefficients in order of increasing degree,"
    ],
    [
        "Symbol used to represent the independent variable in string",
        "Symbol used to represent the"
    ],
    [
        "representations of the polynomial expression, e.g. for printing.",
        "representations of the polynomial"
    ],
    [
        "The symbol must be a valid Python identifier. Default value is 'x'.",
        "The symbol must be a valid Python identifier."
    ],
    [
        "This module provides a number of objects (mostly functions) useful for",
        "This module provides a number of"
    ],
    [
        "dealing with Chebyshev series, including a `Chebyshev` class that",
        "dealing with Chebyshev series, including a `Chebyshev`"
    ],
    [
        "encapsulates the usual arithmetic operations.  (General information",
        "encapsulates the usual arithmetic operations."
    ],
    [
        "on how this module represents and works with such polynomials is in the",
        "on how this module represents and works with such"
    ],
    [
        "docstring for its \"parent\" sub-package, `numpy.polynomial`).",
        "docstring for its \"parent\" sub-package,"
    ],
    [
        "The implementations of multiplication, division, integration, and",
        "The implementations of multiplication,"
    ],
    [
        "These identities allow a Chebyshev series to be expressed as a finite,",
        "These identities allow a Chebyshev series to be"
    ],
    [
        "symmetric Laurent series.  In this module, this sort of Laurent series",
        "symmetric Laurent series. In this module, this sort"
    ],
    [
        "is referred to as a \"z-series.\"",
        "is referred to"
    ],
    [
        "from . import polyutils as pu",
        "from . import"
    ],
    [
        "'chebzero', 'chebone', 'chebx', 'chebdomain', 'chebline', 'chebadd',",
        "'chebzero', 'chebone', 'chebx',"
    ],
    [
        "'chebsub', 'chebmulx', 'chebmul', 'chebdiv', 'chebpow', 'chebval',",
        "'chebsub', 'chebmulx', 'chebmul',"
    ],
    [
        "Convert a Chebyshev series to the equivalent z-series. The result is",
        "Convert a Chebyshev series to the"
    ],
    [
        "never an empty array. The dtype of the return is the same as that of",
        "never an empty array. The dtype of the"
    ],
    [
        "the input. No checks are run on the arguments as this routine is for",
        "the input. No checks are run on the arguments as this routine"
    ],
    [
        "Chebyshev coefficients, ordered from low to high",
        "Chebyshev coefficients, ordered from low"
    ],
    [
        "Odd length symmetric z-series, ordered from  low to high.",
        "Odd length symmetric z-series, ordered"
    ],
    [
        "\"\"\"Convert z-series to a Chebyshev series.",
        "\"\"\"Convert z-series to a"
    ],
    [
        "Convert a z series to the equivalent Chebyshev series. The result is",
        "Convert a z series to the equivalent Chebyshev series. The result"
    ],
    [
        "never an empty array. The dtype of the return is the same as that of",
        "never an empty array. The dtype of the return is the same"
    ],
    [
        "the input. No checks are run on the arguments as this routine is for",
        "the input. No checks are run on the arguments as"
    ],
    [
        "Odd length symmetric z-series, ordered from  low to high.",
        "Odd length symmetric z-series, ordered"
    ],
    [
        "Chebyshev coefficients, ordered from  low to high.",
        "Chebyshev coefficients, ordered from low"
    ],
    [
        "Multiply two z-series to produce a z-series.",
        "Multiply two z-series to"
    ],
    [
        "This is simply convolution. If symmetric/anti-symmetric z-series are",
        "This is simply convolution. If symmetric/anti-symmetric"
    ],
    [
        "denoted by S/A then the following rules apply:",
        "denoted by S/A then the following"
    ],
    [
        "\"\"\"Divide the first z-series by the second.",
        "\"\"\"Divide the first z-series by the"
    ],
    [
        "same symmetry, which is sufficient for present purposes.",
        "same symmetry, which is sufficient for present"
    ],
    [
        "This is not the same as polynomial division on account of the desired form",
        "This is not the same as polynomial division on account of"
    ],
    [
        "of the remainder. If symmetric/anti-symmetric z-series are denoted by S/A",
        "of the remainder. If symmetric/anti-symmetric z-series are denoted"
    ],
    [
        "The restriction to types of the same symmetry could be fixed but seems like",
        "The restriction to types of the same symmetry could be fixed but"
    ],
    [
        "unneeded generality. There is no natural form for the remainder in the case",
        "unneeded generality. There is no natural form"
    ],
    [
        "The derivative is with respect to x, not z. This is achieved using the",
        "The derivative is with respect to x, not z."
    ],
    [
        "chain rule and the value of dx/dz given in the module notes.",
        "chain rule and the value of dx/dz"
    ],
    [
        "The zseries for x (ns) has been multiplied by two in order to avoid",
        "The zseries for x (ns) has been"
    ],
    [
        "using floats that are incompatible with Decimal and likely other",
        "using floats that are incompatible with Decimal and"
    ],
    [
        "specialized scalar types. This scaling has been compensated by",
        "specialized scalar types. This scaling has been compensated"
    ],
    [
        "multiplying the value of zs by two also so that the two cancels in the",
        "multiplying the value of zs by two also so"
    ],
    [
        "The integral is with respect to x, not z. This is achieved by a change",
        "The integral is with respect to x, not"
    ],
    [
        "of variable using dx/dz given in the module notes.",
        "of variable using dx/dz given in the module"
    ],
    [
        "The zseries for x (ns) has been multiplied by two in order to avoid",
        "The zseries for x (ns) has been multiplied by two"
    ],
    [
        "using floats that are incompatible with Decimal and likely other",
        "using floats that are incompatible"
    ],
    [
        "specialized scalar types. This scaling has been compensated by",
        "specialized scalar types. This scaling"
    ],
    [
        "dividing the resulting zs by two.",
        "dividing the resulting zs by"
    ],
    [
        "Convert a polynomial to a Chebyshev series.",
        "Convert a polynomial to a Chebyshev"
    ],
    [
        "Convert an array representing the coefficients of a polynomial (relative",
        "Convert an array representing the coefficients of"
    ],
    [
        "to the \"standard\" basis) ordered from lowest degree to highest, to an",
        "to the \"standard\" basis) ordered from lowest degree to highest,"
    ],
    [
        "array of the coefficients of the equivalent Chebyshev series, ordered",
        "array of the coefficients of"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do conversions between"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert method"
    ],
    [
        ">>> from numpy import polynomial as P",
        ">>> from numpy import polynomial"
    ],
    [
        "Convert a Chebyshev series to a polynomial.",
        "Convert a Chebyshev series to a"
    ],
    [
        "Convert an array representing the coefficients of a Chebyshev series,",
        "Convert an array representing the"
    ],
    [
        "ordered from lowest degree to highest, to an array of the coefficients",
        "ordered from lowest degree to highest, to an array of"
    ],
    [
        "of the equivalent polynomial (relative to the \"standard\" basis) ordered",
        "of the equivalent polynomial (relative to the"
    ],
    [
        "from lowest order term to highest.",
        "from lowest order term"
    ],
    [
        "(relative to the \"standard\" basis) ordered from lowest order term",
        "(relative to the \"standard\" basis) ordered from"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert"
    ],
    [
        ">>> from numpy import polynomial as P",
        ">>> from numpy import polynomial as"
    ],
    [
        "from .polynomial import polyadd, polysub, polymulx",
        "from .polynomial import"
    ],
    [
        "Chebyshev series whose graph is a straight line.",
        "Chebyshev series whose graph is a"
    ],
    [
        "The specified line is given by ``off + scl*x``.",
        "The specified line is given"
    ],
    [
        "This module's representation of the Chebyshev series for",
        "This module's representation of the Chebyshev"
    ],
    [
        "Generate a Chebyshev series with given roots.",
        "Generate a Chebyshev series"
    ],
    [
        "The function returns the coefficients of the polynomial",
        "The function returns the"
    ],
    [
        "in Chebyshev form, where the :math:`r_n` are the roots specified in",
        "in Chebyshev form, where the :math:`r_n`"
    ],
    [
        "`roots`.  If a zero has multiplicity n, then it must appear in `roots`",
        "`roots`. If a zero has multiplicity n, then it must appear in"
    ],
    [
        "The roots can appear in any order.",
        "The roots can appear in"
    ],
    [
        "If the returned coefficients are `c`, then",
        "If the returned coefficients are"
    ],
    [
        "real array, if some of the roots are complex, then `out` is complex",
        "real array, if some of the roots are complex, then"
    ],
    [
        "even if all the coefficients in the result are real (see Examples",
        "even if all the coefficients in"
    ],
    [
        "Add one Chebyshev series to another.",
        "Add one Chebyshev series"
    ],
    [
        "are sequences of coefficients ordered from lowest order term to",
        "are sequences of coefficients ordered from"
    ],
    [
        "Array representing the Chebyshev series of their sum.",
        "Array representing the Chebyshev"
    ],
    [
        "Unlike multiplication, division, etc., the sum of two Chebyshev series",
        "Unlike multiplication, division, etc., the sum of two Chebyshev"
    ],
    [
        "is a Chebyshev series (without having to \"reproject\" the result onto",
        "is a Chebyshev series (without having to \"reproject\""
    ],
    [
        "the basis set) so addition, just like that of \"standard\" polynomials,",
        "the basis set) so addition, just like that"
    ],
    [
        ">>> from numpy.polynomial import chebyshev as C",
        ">>> from numpy.polynomial import chebyshev as"
    ],
    [
        "Subtract one Chebyshev series from another.",
        "Subtract one Chebyshev series"
    ],
    [
        "sequences of coefficients are from lowest order term to highest, i.e.,",
        "sequences of coefficients are from lowest order term to highest,"
    ],
    [
        "Of Chebyshev series coefficients representing their difference.",
        "Of Chebyshev series coefficients representing their"
    ],
    [
        "Unlike multiplication, division, etc., the difference of two Chebyshev",
        "Unlike multiplication, division, etc., the"
    ],
    [
        "series is a Chebyshev series (without having to \"reproject\" the result",
        "series is a Chebyshev series (without having"
    ],
    [
        "onto the basis set) so subtraction, just like that of \"standard\"",
        "onto the basis set) so subtraction, just"
    ],
    [
        ">>> from numpy.polynomial import chebyshev as C",
        ">>> from numpy.polynomial import chebyshev"
    ],
    [
        "\"\"\"Multiply a Chebyshev series by x.",
        "\"\"\"Multiply a Chebyshev series by"
    ],
    [
        "Multiply the polynomial `c` by x, where x is the independent",
        "Multiply the polynomial `c` by x, where x is the"
    ],
    [
        "Array representing the result of the multiplication.",
        "Array representing the result"
    ],
    [
        ">>> from numpy.polynomial import chebyshev as C",
        ">>> from numpy.polynomial import chebyshev"
    ],
    [
        "Multiply one Chebyshev series by another.",
        "Multiply one Chebyshev series by"
    ],
    [
        "are sequences of coefficients, from lowest order \"term\" to highest,",
        "are sequences of coefficients, from"
    ],
    [
        "Of Chebyshev series coefficients representing their product.",
        "Of Chebyshev series coefficients representing"
    ],
    [
        "In general, the (polynomial) product of two C-series results in terms",
        "In general, the (polynomial) product of two"
    ],
    [
        "that are not in the Chebyshev polynomial basis set.  Thus, to express",
        "that are not in the Chebyshev polynomial basis set. Thus,"
    ],
    [
        "the product as a C-series, it is typically necessary to \"reproject\"",
        "the product as a C-series, it is typically"
    ],
    [
        "the product onto said basis set, which typically produces",
        "the product onto said basis set, which"
    ],
    [
        "\"unintuitive live\" (but correct) results; see Examples section below.",
        "\"unintuitive live\" (but correct) results; see"
    ],
    [
        ">>> from numpy.polynomial import chebyshev as C",
        ">>> from numpy.polynomial import chebyshev as"
    ],
    [
        "Divide one Chebyshev series by another.",
        "Divide one Chebyshev series by"
    ],
    [
        "Returns the quotient-with-remainder of two Chebyshev series",
        "Returns the quotient-with-remainder of two"
    ],
    [
        "Of Chebyshev series coefficients representing the quotient and",
        "Of Chebyshev series coefficients representing"
    ],
    [
        "In general, the (polynomial) division of one C-series by another",
        "In general, the (polynomial) division of one"
    ],
    [
        "results in quotient and remainder terms that are not in the Chebyshev",
        "results in quotient and remainder terms that"
    ],
    [
        "polynomial basis set.  Thus, to express these results as C-series, it",
        "polynomial basis set. Thus, to express these"
    ],
    [
        "is typically necessary to \"reproject\" the results onto said basis",
        "is typically necessary to \"reproject\" the results onto"
    ],
    [
        "set, which typically produces \"unintuitive\" (but correct) results;",
        "set, which typically produces \"unintuitive\" (but"
    ],
    [
        ">>> from numpy.polynomial import chebyshev as C",
        ">>> from numpy.polynomial import chebyshev as"
    ],
    [
        "\"\"\"Raise a Chebyshev series to a power.",
        "\"\"\"Raise a Chebyshev series"
    ],
    [
        "Returns the Chebyshev series `c` raised to the power `pow`. The",
        "Returns the Chebyshev series `c` raised"
    ],
    [
        "argument `c` is a sequence of coefficients ordered from low to high.",
        "argument `c` is a sequence of coefficients ordered"
    ],
    [
        "Power to which the series will be raised",
        "Power to which the series will"
    ],
    [
        "Maximum power allowed. This is mainly to limit growth of the series",
        "Maximum power allowed. This is mainly to limit growth"
    ],
    [
        ">>> from numpy.polynomial import chebyshev as C",
        ">>> from numpy.polynomial import chebyshev as"
    ],
    [
        "raise ValueError(\"Power must be a non-negative integer.\")",
        "raise ValueError(\"Power must be"
    ],
    [
        "elif maxpower is not None and power > maxpower:",
        "elif maxpower is not None and power"
    ],
    [
        "Returns the Chebyshev series coefficients `c` differentiated `m` times",
        "Returns the Chebyshev series coefficients"
    ],
    [
        "along `axis`.  At each iteration the result is multiplied by `scl` (the",
        "along `axis`. At each iteration the result is multiplied by"
    ],
    [
        "scaling factor is for use in a linear change of variable). The argument",
        "scaling factor is for use in a linear change of"
    ],
    [
        "`c` is an array of coefficients from low to high degree along each",
        "`c` is an array of coefficients from low"
    ],
    [
        "Array of Chebyshev series coefficients. If c is multidimensional",
        "Array of Chebyshev series coefficients. If c"
    ],
    [
        "the different axis correspond to different variables with the",
        "the different axis correspond to different variables with"
    ],
    [
        "degree in each axis given by the corresponding index.",
        "degree in each axis given"
    ],
    [
        "Each differentiation is multiplied by `scl`.  The end result is",
        "Each differentiation is multiplied by `scl`. The end"
    ],
    [
        "multiplication by ``scl**m``.  This is for use in a linear change of",
        "multiplication by ``scl**m``. This is for"
    ],
    [
        "In general, the result of differentiating a C-series needs to be",
        "In general, the result of differentiating a C-series needs to"
    ],
    [
        "\"reprojected\" onto the C-series basis set. Thus, typically, the",
        "\"reprojected\" onto the C-series basis"
    ],
    [
        "result of this function is \"unintuitive,\" albeit correct; see Examples",
        "result of this function is \"unintuitive,\" albeit"
    ],
    [
        ">>> from numpy.polynomial import chebyshev as C",
        ">>> from numpy.polynomial import chebyshev"
    ],
    [
        "cnt = pu._as_int(m, \"the order of derivation\")",
        "cnt = pu._as_int(m, \"the"
    ],
    [
        "raise ValueError(\"The order of derivation must be non-negative\")",
        "raise ValueError(\"The order of derivation must be"
    ],
    [
        "Returns the Chebyshev series coefficients `c` integrated `m` times from",
        "Returns the Chebyshev series coefficients `c`"
    ],
    [
        "`lbnd` along `axis`. At each iteration the resulting series is",
        "`lbnd` along `axis`. At each iteration the resulting"
    ],
    [
        "**multiplied** by `scl` and an integration constant, `k`, is added.",
        "**multiplied** by `scl` and an integration"
    ],
    [
        "The scaling factor is for use in a linear change of variable.  (\"Buyer",
        "The scaling factor is for use in a linear"
    ],
    [
        "beware\": note that, depending on what one is doing, one may want `scl`",
        "beware\": note that, depending on what one is doing, one may want"
    ],
    [
        "to be the reciprocal of what one might expect; for more information,",
        "to be the reciprocal of what"
    ],
    [
        "see the Notes section below.)  The argument `c` is an array of",
        "see the Notes section below.) The argument `c` is an"
    ],
    [
        "Array of Chebyshev series coefficients. If c is multidimensional",
        "Array of Chebyshev series coefficients. If c"
    ],
    [
        "the different axis correspond to different variables with the",
        "the different axis correspond to"
    ],
    [
        "degree in each axis given by the corresponding index.",
        "degree in each axis given by the corresponding"
    ],
    [
        "k : {[], list, scalar}, optional",
        "k : {[],"
    ],
    [
        "Integration constant(s).  The value of the first integral at zero",
        "Integration constant(s). The value of"
    ],
    [
        "is the first value in the list, the value of the second integral",
        "is the first value in the list, the value"
    ],
    [
        "at zero is the second value, etc.  If ``k == []`` (the default),",
        "at zero is the second value, etc. If"
    ],
    [
        "be given instead of a list.",
        "be given instead of a"
    ],
    [
        "Following each integration the result is *multiplied* by `scl`",
        "Following each integration the result is"
    ],
    [
        "Note that the result of each integration is *multiplied* by `scl`.",
        "Note that the result of each"
    ],
    [
        "Why is this important to note?  Say one is making a linear change of",
        "Why is this important to note? Say one is making a linear"
    ],
    [
        "variable :math:`u = ax + b` in an integral relative to `x`.  Then",
        "variable :math:`u = ax + b` in an integral relative to"
    ],
    [
        ":math:`dx = du/a`, so one will need to set `scl` equal to",
        ":math:`dx = du/a`, so one will need to set `scl` equal"
    ],
    [
        "Also note that, in general, the result of integrating a C-series needs",
        "Also note that, in general, the result of integrating a C-series"
    ],
    [
        "to be \"reprojected\" onto the C-series basis set.  Thus, typically,",
        "to be \"reprojected\" onto the"
    ],
    [
        "the result of this function is \"unintuitive,\" albeit correct; see",
        "the result of this function is"
    ],
    [
        ">>> from numpy.polynomial import chebyshev as C",
        ">>> from numpy.polynomial import chebyshev"
    ],
    [
        "cnt = pu._as_int(m, \"the order of integration\")",
        "cnt = pu._as_int(m, \"the order"
    ],
    [
        "raise ValueError(\"The order of integration must be non-negative\")",
        "raise ValueError(\"The order of"
    ],
    [
        "raise ValueError(\"lbnd must be a scalar.\")",
        "raise ValueError(\"lbnd must be"
    ],
    [
        "raise ValueError(\"scl must be a scalar.\")",
        "raise ValueError(\"scl must be"
    ],
    [
        "Evaluate a Chebyshev series at points x.",
        "Evaluate a Chebyshev series at points"
    ],
    [
        "The parameter `x` is converted to an array only if it is a tuple or a",
        "The parameter `x` is converted to an array only if it is a tuple or"
    ],
    [
        "list, otherwise it is treated as a scalar. In either case, either `x`",
        "list, otherwise it is treated as a scalar. In either case,"
    ],
    [
        "or its elements must support multiplication and addition both with",
        "or its elements must support multiplication and addition both"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the elements of"
    ],
    [
        "`c` is multidimensional, then the shape of the result depends on the",
        "`c` is multidimensional, then the shape"
    ],
    [
        "Trailing zeros in the coefficients will be used in the evaluation, so",
        "Trailing zeros in the coefficients will be used in the evaluation,"
    ],
    [
        "they should be avoided if efficiency is a concern.",
        "they should be avoided if efficiency is"
    ],
    [
        "If `x` is a list or tuple, it is converted to an ndarray, otherwise",
        "If `x` is a list or tuple, it is"
    ],
    [
        "it is left unchanged and treated as a scalar. In either case, `x`",
        "it is left unchanged and treated as a"
    ],
    [
        "or its elements must support addition and multiplication with",
        "or its elements must support addition and multiplication"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the elements"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the"
    ],
    [
        "degree n are contained in c[n]. If `c` is multidimensional the",
        "degree n are contained in c[n]. If `c` is"
    ],
    [
        "remaining indices enumerate multiple polynomials. In the two",
        "remaining indices enumerate multiple polynomials."
    ],
    [
        "dimensional case the coefficients may be thought of as stored in",
        "dimensional case the coefficients may be thought of as"
    ],
    [
        "If True, the shape of the coefficient array is extended with ones",
        "If True, the shape of the coefficient array is extended"
    ],
    [
        "for this action. The result is that every column of coefficients in",
        "for this action. The result is that every column of coefficients"
    ],
    [
        "`c` is evaluated for every element of `x`. If False, `x` is broadcast",
        "`c` is evaluated for every element of `x`."
    ],
    [
        "over the columns of `c` for the evaluation.  This keyword is useful",
        "over the columns of `c` for the evaluation. This"
    ],
    [
        "when `c` is multidimensional. The default value is True.",
        "when `c` is multidimensional. The"
    ],
    [
        "The shape of the return value is described above.",
        "The shape of the return value is described"
    ],
    [
        "The evaluation uses Clenshaw recursion, aka synthetic division.",
        "The evaluation uses Clenshaw recursion,"
    ],
    [
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * T_i(x) * T_j(y)",
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * T_i(x) *"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted to arrays"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars and they",
        "tuples or a lists, otherwise they are treated as a scalars and"
    ],
    [
        "must have the same shape after conversion. In either case, either `x`",
        "must have the same shape after"
    ],
    [
        "and `y` or their elements must support multiplication and addition both",
        "and `y` or their elements must support multiplication and addition"
    ],
    [
        "with themselves and with the elements of `c`.",
        "with themselves and with the"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like, compatible"
    ],
    [
        "The two dimensional series is evaluated at the points ``(x, y)``,",
        "The two dimensional series is evaluated"
    ],
    [
        "where `x` and `y` must have the same shape. If `x` or `y` is a list",
        "where `x` and `y` must have the same shape. If `x` or `y` is"
    ],
    [
        "or tuple, it is first converted to an ndarray, otherwise it is left",
        "or tuple, it is first converted to an"
    ],
    [
        "unchanged and if it isn't an ndarray it is treated as a scalar.",
        "unchanged and if it isn't an ndarray"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term",
        "Array of coefficients ordered so that"
    ],
    [
        "of multi-degree i,j is contained in ``c[i,j]``. If `c` has",
        "of multi-degree i,j is contained in ``c[i,j]``. If `c`"
    ],
    [
        "The values of the two dimensional Chebyshev series at points formed",
        "The values of the two dimensional Chebyshev series at"
    ],
    [
        "from pairs of corresponding values from `x` and `y`.",
        "from pairs of corresponding values from `x` and"
    ],
    [
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j} * T_i(a) * T_j(b),",
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j}"
    ],
    [
        "where the points `(a, b)` consist of all pairs formed by taking",
        "where the points `(a, b)` consist of"
    ],
    [
        "`a` from `x` and `b` from `y`. The resulting points form a grid with",
        "`a` from `x` and `b` from `y`. The resulting points"
    ],
    [
        "`x` in the first dimension and `y` in the second.",
        "`x` in the first dimension and `y`"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars. In either",
        "tuples or a lists, otherwise they are treated as a scalars."
    ],
    [
        "case, either `x` and `y` or their elements must support multiplication",
        "case, either `x` and `y` or their elements"
    ],
    [
        "and addition both with themselves and with the elements of `c`.",
        "and addition both with themselves and with the"
    ],
    [
        "If `c` has fewer than two dimensions, ones are implicitly appended to",
        "If `c` has fewer than two dimensions, ones are implicitly"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y :"
    ],
    [
        "The two dimensional series is evaluated at the points in the",
        "The two dimensional series is evaluated at the points"
    ],
    [
        "Cartesian product of `x` and `y`.  If `x` or `y` is a list or",
        "Cartesian product of `x` and `y`. If `x`"
    ],
    [
        "tuple, it is first converted to an ndarray, otherwise it is left",
        "tuple, it is first converted to an ndarray, otherwise it is"
    ],
    [
        "unchanged and, if it isn't an ndarray, it is treated as a scalar.",
        "unchanged and, if it isn't an ndarray, it is treated as a"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that"
    ],
    [
        "multi-degree i,j is contained in ``c[i,j]``. If `c` has dimension",
        "multi-degree i,j is contained in ``c[i,j]``. If `c` has"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices"
    ],
    [
        "The values of the two dimensional Chebyshev series at points in the",
        "The values of the two dimensional"
    ],
    [
        "Cartesian product of `x` and `y`.",
        "Cartesian product of `x` and"
    ],
    [
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * T_i(x) * T_j(y) * T_k(z)",
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k}"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if",
        "The parameters `x`, `y`, and `z` are converted to arrays"
    ],
    [
        "they are tuples or a lists, otherwise they are treated as a scalars and",
        "they are tuples or a lists, otherwise they"
    ],
    [
        "they must have the same shape after conversion. In either case, either",
        "they must have the same shape"
    ],
    [
        "`x`, `y`, and `z` or their elements must support multiplication and",
        "`x`, `y`, and `z` or their elements must support"
    ],
    [
        "addition both with themselves and with the elements of `c`.",
        "addition both with themselves and with the elements"
    ],
    [
        "x, y, z : array_like, compatible object",
        "x, y, z :"
    ],
    [
        "The three dimensional series is evaluated at the points",
        "The three dimensional series is evaluated"
    ],
    [
        "``(x, y, z)``, where `x`, `y`, and `z` must have the same shape.  If",
        "``(x, y, z)``, where `x`, `y`, and `z` must have"
    ],
    [
        "any of `x`, `y`, or `z` is a list or tuple, it is first converted",
        "any of `x`, `y`, or `z` is a list or tuple, it is"
    ],
    [
        "to an ndarray, otherwise it is left unchanged and if it isn't an",
        "to an ndarray, otherwise it is left"
    ],
    [
        "ndarray it is  treated as a scalar.",
        "ndarray it is treated"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that the coefficient of"
    ],
    [
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension",
        "multi-degree i,j,k is contained in"
    ],
    [
        "The values of the multidimensional polynomial on points formed with",
        "The values of the multidimensional polynomial on points"
    ],
    [
        "triples of corresponding values from `x`, `y`, and `z`.",
        "triples of corresponding values from `x`, `y`, and"
    ],
    [
        "return pu._valnd(chebval, c, x, y, z)",
        "return pu._valnd(chebval, c,"
    ],
    [
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * T_i(a) * T_j(b) * T_k(c)",
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} *"
    ],
    [
        "where the points ``(a, b, c)`` consist of all triples formed by taking",
        "where the points ``(a, b, c)`` consist of all triples formed by"
    ],
    [
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form",
        "`a` from `x`, `b` from `y`, and `c`"
    ],
    [
        "a grid with `x` in the first dimension, `y` in the second, and `z` in",
        "a grid with `x` in the first dimension, `y` in the"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if they",
        "The parameters `x`, `y`, and `z` are converted to arrays only"
    ],
    [
        "are tuples or a lists, otherwise they are treated as a scalars. In",
        "are tuples or a lists, otherwise they are treated as a"
    ],
    [
        "either case, either `x`, `y`, and `z` or their elements must support",
        "either case, either `x`, `y`, and `z` or their"
    ],
    [
        "multiplication and addition both with themselves and with the elements",
        "multiplication and addition both with themselves and with"
    ],
    [
        "If `c` has fewer than three dimensions, ones are implicitly appended to",
        "If `c` has fewer than three dimensions, ones are implicitly appended"
    ],
    [
        "x, y, z : array_like, compatible objects",
        "x, y, z : array_like,"
    ],
    [
        "The three dimensional series is evaluated at the points in the",
        "The three dimensional series is evaluated at the points in"
    ],
    [
        "Cartesian product of `x`, `y`, and `z`.  If `x`, `y`, or `z` is a",
        "Cartesian product of `x`, `y`, and `z`."
    ],
    [
        "list or tuple, it is first converted to an ndarray, otherwise it is",
        "list or tuple, it is first converted to an ndarray, otherwise it"
    ],
    [
        "left unchanged and, if it isn't an ndarray, it is treated as a",
        "left unchanged and, if it isn't an ndarray, it is"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients for terms"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in ``c[i,j]``. If"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices enumerate multiple"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional polynomial at points in"
    ],
    [
        "return pu._gridnd(chebval, c, x, y, z)",
        "return pu._gridnd(chebval, c, x, y,"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degree `deg` and sample points",
        "Returns the pseudo-Vandermonde matrix of degree `deg`"
    ],
    [
        "`x`. The pseudo-Vandermonde matrix is defined by",
        "`x`. The pseudo-Vandermonde matrix"
    ],
    [
        ".. math:: V[..., i] = T_i(x),",
        ".. math:: V[..., i] ="
    ],
    [
        "`x` and the last index is the degree of the Chebyshev polynomial.",
        "`x` and the last index is"
    ],
    [
        "matrix ``V = chebvander(x, n)``, then ``np.dot(V, c)`` and",
        "matrix ``V = chebvander(x, n)``, then ``np.dot(V, c)``"
    ],
    [
        "``chebval(x, c)`` are the same up to roundoff.  This equivalence is",
        "``chebval(x, c)`` are the same up to roundoff. This"
    ],
    [
        "useful both for least squares fitting and for the evaluation of a large",
        "useful both for least squares fitting and for the evaluation"
    ],
    [
        "number of Chebyshev series of the same degree and sample points.",
        "number of Chebyshev series of the"
    ],
    [
        "depending on whether any of the elements are complex. If `x` is",
        "depending on whether any of the"
    ],
    [
        "The pseudo Vandermonde matrix. The shape of the returned matrix is",
        "The pseudo Vandermonde matrix. The shape of"
    ],
    [
        "corresponding Chebyshev polynomial.  The dtype will be the same as",
        "corresponding Chebyshev polynomial. The dtype will"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees"
    ],
    [
        "points ``(x, y)``. The pseudo-Vandermonde matrix is defined by",
        "points ``(x, y)``. The pseudo-Vandermonde"
    ],
    [
        "`V` index the points ``(x, y)`` and the last index encodes the degrees of",
        "`V` index the points ``(x, y)`` and"
    ],
    [
        "up to roundoff. This equivalence is useful both for least squares",
        "up to roundoff. This equivalence is useful both for"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes",
        "Arrays of point coordinates, all of the"
    ],
    [
        "whether any of the elements are complex. Scalars are converted to",
        "whether any of the elements are complex. Scalars are"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg].",
        "List of maximum degrees of the"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix"
    ],
    [
        "as the converted `x` and `y`.",
        "as the converted `x`"
    ],
    [
        "return pu._vander_nd_flat((chebvander, chebvander), (x, y), deg)",
        "return pu._vander_nd_flat((chebvander, chebvander), (x, y),"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg`"
    ],
    [
        "points ``(x, y, z)``. If `l`, `m`, `n` are the given degrees in `x`, `y`, `z`,",
        "points ``(x, y, z)``. If `l`, `m`, `n` are the given degrees in `x`,"
    ],
    [
        "then The pseudo-Vandermonde matrix is defined by",
        "then The pseudo-Vandermonde matrix"
    ],
    [
        "indices of `V` index the points ``(x, y, z)`` and the last index encodes",
        "indices of `V` index the points ``(x, y, z)`` and the last index"
    ],
    [
        "the degrees of the Chebyshev polynomials.",
        "the degrees of"
    ],
    [
        "same up to roundoff. This equivalence is useful both for least squares",
        "same up to roundoff. This equivalence is useful"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same degrees and sample"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes will",
        "Arrays of point coordinates, all of the same shape. The"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg, z_deg].",
        "List of maximum degrees of the form [x_deg,"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is"
    ],
    [
        "be the same as the converted `x`, `y`, and `z`.",
        "be the same as the converted `x`, `y`, and"
    ],
    [
        "return pu._vander_nd_flat((chebvander, chebvander, chebvander), (x, y, z), deg)",
        "return pu._vander_nd_flat((chebvander, chebvander, chebvander), (x, y,"
    ],
    [
        "def chebfit(x, y, deg, rcond=None, full=False, w=None):",
        "def chebfit(x, y, deg,"
    ],
    [
        "Least squares fit of Chebyshev series to data.",
        "Least squares fit of Chebyshev"
    ],
    [
        "Return the coefficients of a Chebyshev series of degree `deg` that is the",
        "Return the coefficients of a Chebyshev series of degree `deg` that"
    ],
    [
        "least squares fit to the data values `y` given at points `x`. If `y` is",
        "least squares fit to the data values `y` given at points `x`."
    ],
    [
        "fits are done, one for each column of `y`, and the resulting",
        "fits are done, one for each"
    ],
    [
        "The fitted polynomial(s) are in the form",
        "The fitted polynomial(s) are"
    ],
    [
        "x-coordinates of the M sample points ``(x[i], y[i])``.",
        "x-coordinates of the M sample"
    ],
    [
        "y : array_like, shape (M,) or (M, K)",
        "y : array_like, shape (M,) or (M,"
    ],
    [
        "y-coordinates of the sample points. Several data sets of sample",
        "y-coordinates of the sample points."
    ],
    [
        "points sharing the same x-coordinates can be fitted at once by",
        "points sharing the same x-coordinates can be"
    ],
    [
        "Degree(s) of the fitting polynomials. If `deg` is a single integer,",
        "Degree(s) of the fitting polynomials. If `deg`"
    ],
    [
        "all terms up to and including the `deg`'th term are included in the",
        "all terms up to and including the `deg`'th term are"
    ],
    [
        "degrees of the terms to include may be used instead.",
        "degrees of the terms to include may be"
    ],
    [
        "Relative condition number of the fit. Singular values smaller than",
        "Relative condition number of the fit."
    ],
    [
        "this relative to the largest singular value will be ignored. The",
        "this relative to the largest singular value will be ignored."
    ],
    [
        "default value is ``len(x)*eps``, where eps is the relative precision of",
        "default value is ``len(x)*eps``, where eps is the relative"
    ],
    [
        "Switch determining nature of return value. When it is False (the",
        "Switch determining nature of return value. When it is False"
    ],
    [
        "default) just the coefficients are returned, when True diagnostic",
        "default) just the coefficients are"
    ],
    [
        "information from the singular value decomposition is also returned.",
        "information from the singular value"
    ],
    [
        "w : array_like, shape (`M`,), optional",
        "w : array_like, shape"
    ],
    [
        "Weights. If not None, the weight ``w[i]`` applies to the unsquared",
        "Weights. If not None, the weight ``w[i]`` applies"
    ],
    [
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are",
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights"
    ],
    [
        "chosen so that the errors of the products ``w[i]*y[i]`` all have the",
        "chosen so that the errors of"
    ],
    [
        "same variance.  When using inverse-variance weighting, use",
        "same variance. When using"
    ],
    [
        "coef : ndarray, shape (M,) or (M, K)",
        "coef : ndarray, shape (M,) or (M,"
    ],
    [
        "the coefficients for the data in column k  of `y` are in column",
        "the coefficients for the data in column k"
    ],
    [
        "[residuals, rank, singular_values, rcond] : list",
        "[residuals, rank, singular_values, rcond]"
    ],
    [
        "These values are only returned if ``full == True``",
        "These values are only returned if"
    ],
    [
        "- residuals -- sum of squared residuals of the least squares fit",
        "- residuals -- sum of squared residuals of the least squares"
    ],
    [
        "- rank -- the numerical rank of the scaled Vandermonde matrix",
        "- rank -- the numerical rank of the scaled"
    ],
    [
        "- singular_values -- singular values of the scaled Vandermonde matrix",
        "- singular_values -- singular values of the"
    ],
    [
        "- rcond -- value of `rcond`.",
        "- rcond --"
    ],
    [
        "The rank of the coefficient matrix in the least-squares fit is",
        "The rank of the coefficient matrix in"
    ],
    [
        "deficient. The warning is only raised if ``full == False``.  The",
        "deficient. The warning is only raised if"
    ],
    [
        "warnings can be turned off by",
        "warnings can be turned off"
    ],
    [
        "chebval : Evaluates a Chebyshev series.",
        "chebval : Evaluates a"
    ],
    [
        "chebvander : Vandermonde matrix of Chebyshev series.",
        "chebvander : Vandermonde matrix of Chebyshev"
    ],
    [
        "numpy.linalg.lstsq : Computes a least-squares fit from the matrix.",
        "numpy.linalg.lstsq : Computes a least-squares"
    ],
    [
        "The solution is the coefficients of the Chebyshev series `p` that",
        "The solution is the coefficients of the Chebyshev series"
    ],
    [
        "minimizes the sum of the weighted squared errors",
        "minimizes the sum of the"
    ],
    [
        "where :math:`w_j` are the weights. This problem is solved by setting up",
        "where :math:`w_j` are the weights. This problem is solved by"
    ],
    [
        "as the (typically) overdetermined matrix equation",
        "as the (typically)"
    ],
    [
        ".. math:: V(x) * c = w * y,",
        ".. math:: V(x) * c = w"
    ],
    [
        "where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the",
        "where `V` is the weighted pseudo Vandermonde matrix"
    ],
    [
        "coefficients to be solved for, `w` are the weights, and `y` are the",
        "coefficients to be solved for, `w` are the weights, and `y` are"
    ],
    [
        "observed values.  This equation is then solved using the singular value",
        "observed values. This equation is then"
    ],
    [
        "If some of the singular values of `V` are so small that they are",
        "If some of the singular values of `V` are"
    ],
    [
        "neglected, then a `~exceptions.RankWarning` will be issued. This means that",
        "neglected, then a `~exceptions.RankWarning` will"
    ],
    [
        "the coefficient values may be poorly determined. Using a lower order fit",
        "the coefficient values may be poorly determined. Using a lower"
    ],
    [
        "will usually get rid of the warning.  The `rcond` parameter can also be",
        "will usually get rid of the warning. The"
    ],
    [
        "set to a value smaller than its default, but the resulting fit may be",
        "set to a value smaller than its default, but the"
    ],
    [
        "spurious and have large contributions from roundoff error.",
        "spurious and have large"
    ],
    [
        "Fits using Chebyshev series are usually better conditioned than fits",
        "Fits using Chebyshev series are"
    ],
    [
        "using power series, but much can depend on the distribution of the",
        "using power series, but much can depend on the distribution of"
    ],
    [
        "sample points and the smoothness of the data. If the quality of the fit",
        "sample points and the smoothness of the data. If the quality"
    ],
    [
        "is inadequate splines may be a good alternative.",
        "is inadequate splines may be"
    ],
    [
        "return pu._fit(chebvander, x, y, deg, rcond, full, w)",
        "return pu._fit(chebvander, x, y, deg, rcond,"
    ],
    [
        "\"\"\"Return the scaled companion matrix of c.",
        "\"\"\"Return the scaled companion"
    ],
    [
        "The basis polynomials are scaled so that the companion matrix is",
        "The basis polynomials are scaled so that"
    ],
    [
        "symmetric when `c` is a Chebyshev basis polynomial. This provides",
        "symmetric when `c` is a Chebyshev"
    ],
    [
        "better eigenvalue estimates than the unscaled case and for basis",
        "better eigenvalue estimates than the unscaled case and for"
    ],
    [
        "polynomials the eigenvalues are guaranteed to be real if",
        "polynomials the eigenvalues are guaranteed to be"
    ],
    [
        "`numpy.linalg.eigvalsh` is used to obtain them.",
        "`numpy.linalg.eigvalsh` is used"
    ],
    [
        "Scaled companion matrix of dimensions (deg, deg).",
        "Scaled companion matrix of"
    ],
    [
        "Compute the roots of a Chebyshev series.",
        "Compute the roots of"
    ],
    [
        "Return the roots (a.k.a. \"zeros\") of the polynomial",
        "Return the roots (a.k.a. \"zeros\")"
    ],
    [
        ".. math:: p(x) = \\\\sum_i c[i] * T_i(x).",
        ".. math:: p(x) = \\\\sum_i c[i] *"
    ],
    [
        "Array of the roots of the series. If all the roots are real,",
        "Array of the roots of the series."
    ],
    [
        "then `out` is also real, otherwise it is complex.",
        "then `out` is also real, otherwise"
    ],
    [
        "The root estimates are obtained as the eigenvalues of the companion",
        "The root estimates are obtained as"
    ],
    [
        "matrix, Roots far from the origin of the complex plane may have large",
        "matrix, Roots far from the origin of the complex plane"
    ],
    [
        "errors due to the numerical instability of the series for such",
        "errors due to the numerical instability of the series for"
    ],
    [
        "errors as the value of the series near such points is relatively",
        "errors as the value of the series near such"
    ],
    [
        "insensitive to errors in the roots. Isolated roots near the origin can",
        "insensitive to errors in the roots. Isolated roots near"
    ],
    [
        "be improved by a few iterations of Newton's method.",
        "be improved by a few iterations of Newton's"
    ],
    [
        "The Chebyshev series basis polynomials aren't powers of `x` so the",
        "The Chebyshev series basis polynomials aren't"
    ],
    [
        "results of this function may seem unintuitive.",
        "results of this function"
    ],
    [
        "\"\"\"Interpolate a function at the Chebyshev points of the first kind.",
        "\"\"\"Interpolate a function at the Chebyshev points of the first"
    ],
    [
        "Returns the Chebyshev series that interpolates `func` at the Chebyshev",
        "Returns the Chebyshev series that"
    ],
    [
        "series tends to a minmax approximation to `func` with increasing `deg`",
        "series tends to a minmax approximation"
    ],
    [
        "if the function is continuous in the interval.",
        "if the function is continuous in"
    ],
    [
        "The function to be approximated. It must be a function of a single",
        "The function to be approximated. It must be"
    ],
    [
        "variable of the form ``f(x, a, b, c...)``, where ``a, b, c...`` are",
        "variable of the form ``f(x, a, b, c...)``, where ``a, b, c...``"
    ],
    [
        "extra arguments passed in the `args` parameter.",
        "extra arguments passed in the `args`"
    ],
    [
        "Extra arguments to be used in the function call. Default is no extra",
        "Extra arguments to be used in the function call. Default is no"
    ],
    [
        "Chebyshev coefficients of the interpolating series ordered from low to",
        "Chebyshev coefficients of the interpolating"
    ],
    [
        "The Chebyshev polynomials used in the interpolation are orthogonal when",
        "The Chebyshev polynomials used in"
    ],
    [
        "sampled at the Chebyshev points of the first kind. If it is desired to",
        "sampled at the Chebyshev points of the first kind. If it"
    ],
    [
        "constrain some of the coefficients they can simply be set to the desired",
        "constrain some of the coefficients they can simply be set to"
    ],
    [
        "value after the interpolation, no new interpolation or fit is needed. This",
        "value after the interpolation, no new interpolation or fit is needed."
    ],
    [
        "is especially useful if it is known apriori that some of coefficients are",
        "is especially useful if it is known"
    ],
    [
        "zero. For instance, if the function is even then the coefficients of the",
        "zero. For instance, if the function is even then the coefficients"
    ],
    [
        "terms of odd degree in the result can be set to zero.",
        "terms of odd degree in the"
    ],
    [
        "raise TypeError(\"deg must be an int\")",
        "raise TypeError(\"deg must be an"
    ],
    [
        "Computes the sample points and weights for Gauss-Chebyshev quadrature.",
        "Computes the sample points and"
    ],
    [
        "These sample points and weights will correctly integrate polynomials of",
        "These sample points and weights will correctly integrate polynomials"
    ],
    [
        "be problematic. For Gauss-Chebyshev there are closed form solutions for",
        "be problematic. For Gauss-Chebyshev there are"
    ],
    [
        "the sample points and weights. If n = `deg`, then",
        "the sample points and weights. If n = `deg`,"
    ],
    [
        ".. math:: w_i = \\\\pi / n",
        ".. math:: w_i = \\\\pi /"
    ],
    [
        "raise ValueError(\"deg must be a positive integer\")",
        "raise ValueError(\"deg must be a"
    ],
    [
        "w = np.ones(ideg) * (np.pi / ideg)",
        "w = np.ones(ideg) * (np.pi"
    ],
    [
        "The weight function of the Chebyshev polynomials.",
        "The weight function of the Chebyshev"
    ],
    [
        "orthogonal, but not normalized, with respect to this weight function.",
        "orthogonal, but not normalized, with respect to this weight"
    ],
    [
        "Values at which the weight function will be computed.",
        "Values at which the weight function will"
    ],
    [
        "Chebyshev points of the first kind.",
        "Chebyshev points of the"
    ],
    [
        "The Chebyshev points of the first kind are the points ``cos(x)``,",
        "The Chebyshev points of the first kind"
    ],
    [
        "The Chebyshev points of the first kind.",
        "The Chebyshev points of the first"
    ],
    [
        "Chebyshev points of the second kind.",
        "Chebyshev points of the"
    ],
    [
        "The Chebyshev points of the second kind are the points ``cos(x)``,",
        "The Chebyshev points of the second kind"
    ],
    [
        "The Chebyshev points of the second kind.",
        "The Chebyshev points of the second"
    ],
    [
        "The Chebyshev class provides the standard Python numerical methods",
        "The Chebyshev class provides the standard Python"
    ],
    [
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as the",
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as"
    ],
    [
        "Chebyshev coefficients in order of increasing degree, i.e.,",
        "Chebyshev coefficients in order of increasing"
    ],
    [
        "Symbol used to represent the independent variable in string",
        "Symbol used to represent the independent"
    ],
    [
        "representations of the polynomial expression, e.g. for printing.",
        "representations of the polynomial expression, e.g."
    ],
    [
        "The symbol must be a valid Python identifier. Default value is 'x'.",
        "The symbol must be a valid Python identifier."
    ],
    [
        "def interpolate(cls, func, deg, domain=None, args=()):",
        "def interpolate(cls, func, deg,"
    ],
    [
        "\"\"\"Interpolate a function at the Chebyshev points of the first kind.",
        "\"\"\"Interpolate a function at the Chebyshev points"
    ],
    [
        "Returns the series that interpolates `func` at the Chebyshev points of",
        "Returns the series that interpolates `func` at"
    ],
    [
        "the first kind scaled and shifted to the `domain`. The resulting series",
        "the first kind scaled and shifted to the `domain`. The"
    ],
    [
        "tends to a minmax approximation of `func` when the function is",
        "tends to a minmax approximation of"
    ],
    [
        "The function to be interpolated. It must be a function of a single",
        "The function to be interpolated. It must be a function of a"
    ],
    [
        "variable of the form ``f(x, a, b, c...)``, where ``a, b, c...`` are",
        "variable of the form ``f(x, a, b, c...)``, where ``a, b, c...``"
    ],
    [
        "extra arguments passed in the `args` parameter.",
        "extra arguments passed in the `args`"
    ],
    [
        "domain : {None, [beg, end]}, optional",
        "domain : {None, [beg, end]},"
    ],
    [
        "Domain over which `func` is interpolated. The default is None, in",
        "Domain over which `func` is interpolated. The default is None,"
    ],
    [
        "Extra arguments to be used in the function call. Default is no",
        "Extra arguments to be used in"
    ],
    [
        "xfunc = lambda x: func(pu.mapdomain(x, cls.window, domain), *args)",
        "xfunc = lambda x: func(pu.mapdomain(x,"
    ],
    [
        "This module provides a number of objects (mostly functions) useful for",
        "This module provides a number of objects (mostly"
    ],
    [
        "dealing with polynomials, including a `Polynomial` class that",
        "dealing with polynomials, including a `Polynomial`"
    ],
    [
        "encapsulates the usual arithmetic operations.  (General information",
        "encapsulates the usual arithmetic operations. (General"
    ],
    [
        "on how this module represents and works with polynomial objects is in",
        "on how this module represents and"
    ],
    [
        "the docstring for its \"parent\" sub-package, `numpy.polynomial`).",
        "the docstring for its"
    ],
    [
        "'polyzero', 'polyone', 'polyx', 'polydomain', 'polyline', 'polyadd',",
        "'polyzero', 'polyone', 'polyx', 'polydomain',"
    ],
    [
        "'polysub', 'polymulx', 'polymul', 'polydiv', 'polypow', 'polyval',",
        "'polysub', 'polymulx', 'polymul', 'polydiv',"
    ],
    [
        "from . import polyutils as pu",
        "from . import polyutils"
    ],
    [
        "Returns an array representing a linear polynomial.",
        "Returns an array representing"
    ],
    [
        "The \"y-intercept\" and \"slope\" of the line, respectively.",
        "The \"y-intercept\" and \"slope\" of the"
    ],
    [
        "This module's representation of the linear polynomial ``off +",
        "This module's representation of the linear polynomial"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial as"
    ],
    [
        "Generate a monic polynomial with given roots.",
        "Generate a monic polynomial"
    ],
    [
        "Return the coefficients of the polynomial",
        "Return the coefficients"
    ],
    [
        "where the :math:`r_n` are the roots specified in `roots`.  If a zero has",
        "where the :math:`r_n` are the roots specified in `roots`. If a"
    ],
    [
        "multiplicity n, then it must appear in `roots` n times. For instance,",
        "multiplicity n, then it must appear in `roots` n"
    ],
    [
        "If the returned coefficients are `c`, then",
        "If the returned coefficients are"
    ],
    [
        "real, then `out` is also real, otherwise it is complex.  (see",
        "real, then `out` is also real,"
    ],
    [
        "The coefficients are determined by multiplying together linear factors",
        "The coefficients are determined by multiplying together"
    ],
    [
        "of the form ``(x - r_i)``, i.e.",
        "of the form ``(x - r_i)``,"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial as"
    ],
    [
        "sequences of coefficients from lowest order term to highest, i.e.,",
        "sequences of coefficients from lowest order term to highest,"
    ],
    [
        "The coefficient array representing their sum.",
        "The coefficient array representing their"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import"
    ],
    [
        "are sequences of coefficients from lowest order term to highest, i.e.,",
        "are sequences of coefficients from lowest"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial as"
    ],
    [
        "Multiply the polynomial `c` by x, where x is the independent",
        "Multiply the polynomial `c` by x,"
    ],
    [
        "Array representing the result of the multiplication.",
        "Array representing the result of"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import"
    ],
    [
        "sequences of coefficients, from lowest order term to highest, e.g.,",
        "sequences of coefficients, from lowest order term to highest,"
    ],
    [
        "\"standard\" basis, and ordered from lowest order term to highest.",
        "\"standard\" basis, and ordered from lowest order term"
    ],
    [
        "Of the coefficients of their product.",
        "Of the coefficients of"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial"
    ],
    [
        "The arguments are sequences of coefficients, from lowest order term",
        "The arguments are sequences of coefficients, from lowest order"
    ],
    [
        "Of coefficient series representing the quotient and remainder.",
        "Of coefficient series representing the quotient and"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial"
    ],
    [
        "\"\"\"Raise a polynomial to a power.",
        "\"\"\"Raise a polynomial"
    ],
    [
        "Returns the polynomial `c` raised to the power `pow`. The argument",
        "Returns the polynomial `c` raised to the"
    ],
    [
        "`c` is a sequence of coefficients ordered from low to high. i.e.,",
        "`c` is a sequence of coefficients ordered"
    ],
    [
        "Power to which the series will be raised",
        "Power to which the series"
    ],
    [
        "Maximum power allowed. This is mainly to limit growth of the series",
        "Maximum power allowed. This is mainly to limit growth of the"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import"
    ],
    [
        "Returns the polynomial coefficients `c` differentiated `m` times along",
        "Returns the polynomial coefficients `c` differentiated `m`"
    ],
    [
        "`axis`.  At each iteration the result is multiplied by `scl` (the",
        "`axis`. At each iteration the result is multiplied"
    ],
    [
        "scaling factor is for use in a linear change of variable).  The",
        "scaling factor is for use in a linear change"
    ],
    [
        "argument `c` is an array of coefficients from low to high degree along",
        "argument `c` is an array of coefficients from low to high degree"
    ],
    [
        "Array of polynomial coefficients. If c is multidimensional the",
        "Array of polynomial coefficients. If"
    ],
    [
        "different axis correspond to different variables with the degree",
        "different axis correspond to different variables"
    ],
    [
        "in each axis given by the corresponding index.",
        "in each axis given by"
    ],
    [
        "Each differentiation is multiplied by `scl`.  The end result is",
        "Each differentiation is multiplied by `scl`. The end"
    ],
    [
        "multiplication by ``scl**m``.  This is for use in a linear change",
        "multiplication by ``scl**m``. This is for"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import"
    ],
    [
        "cnt = pu._as_int(m, \"the order of derivation\")",
        "cnt = pu._as_int(m, \"the order of"
    ],
    [
        "raise ValueError(\"The order of derivation must be non-negative\")",
        "raise ValueError(\"The order of derivation"
    ],
    [
        "Returns the polynomial coefficients `c` integrated `m` times from",
        "Returns the polynomial coefficients `c` integrated `m` times"
    ],
    [
        "`lbnd` along `axis`.  At each iteration the resulting series is",
        "`lbnd` along `axis`. At each iteration"
    ],
    [
        "**multiplied** by `scl` and an integration constant, `k`, is added.",
        "**multiplied** by `scl` and an integration"
    ],
    [
        "The scaling factor is for use in a linear change of variable.  (\"Buyer",
        "The scaling factor is for use in a"
    ],
    [
        "beware\": note that, depending on what one is doing, one may want `scl`",
        "beware\": note that, depending on what one"
    ],
    [
        "to be the reciprocal of what one might expect; for more information,",
        "to be the reciprocal of what one might"
    ],
    [
        "see the Notes section below.) The argument `c` is an array of",
        "see the Notes section below.) The argument"
    ],
    [
        "k : {[], list, scalar}, optional",
        "k : {[], list,"
    ],
    [
        "Integration constant(s).  The value of the first integral at zero",
        "Integration constant(s). The value of the first integral"
    ],
    [
        "is the first value in the list, the value of the second integral",
        "is the first value in the list, the value"
    ],
    [
        "at zero is the second value, etc.  If ``k == []`` (the default),",
        "at zero is the second value, etc. If ``k == []`` (the"
    ],
    [
        "be given instead of a list.",
        "be given instead"
    ],
    [
        "Following each integration the result is *multiplied* by `scl`",
        "Following each integration the result is *multiplied*"
    ],
    [
        "Note that the result of each integration is *multiplied* by `scl`.  Why",
        "Note that the result of each"
    ],
    [
        "is this important to note?  Say one is making a linear change of",
        "is this important to note? Say one is making a"
    ],
    [
        "variable :math:`u = ax + b` in an integral relative to `x`. Then",
        "variable :math:`u = ax + b` in an integral relative to `x`."
    ],
    [
        ":math:`dx = du/a`, so one will need to set `scl` equal to",
        ":math:`dx = du/a`, so one will"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial"
    ],
    [
        "cnt = pu._as_int(m, \"the order of integration\")",
        "cnt = pu._as_int(m, \"the"
    ],
    [
        "raise ValueError(\"The order of integration must be non-negative\")",
        "raise ValueError(\"The order of integration must be"
    ],
    [
        "raise ValueError(\"lbnd must be a scalar.\")",
        "raise ValueError(\"lbnd must be"
    ],
    [
        "raise ValueError(\"scl must be a scalar.\")",
        "raise ValueError(\"scl must be a"
    ],
    [
        "Evaluate a polynomial at points x.",
        "Evaluate a polynomial at"
    ],
    [
        "The parameter `x` is converted to an array only if it is a tuple or a",
        "The parameter `x` is converted to an array only"
    ],
    [
        "list, otherwise it is treated as a scalar. In either case, either `x`",
        "list, otherwise it is treated as a scalar."
    ],
    [
        "or its elements must support multiplication and addition both with",
        "or its elements must support multiplication"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the elements"
    ],
    [
        "`c` is multidimensional, then the shape of the result depends on the",
        "`c` is multidimensional, then the shape of the result depends on"
    ],
    [
        "Trailing zeros in the coefficients will be used in the evaluation, so",
        "Trailing zeros in the coefficients will be used"
    ],
    [
        "they should be avoided if efficiency is a concern.",
        "they should be avoided if efficiency is a"
    ],
    [
        "If `x` is a list or tuple, it is converted to an ndarray, otherwise",
        "If `x` is a list or tuple,"
    ],
    [
        "it is left unchanged and treated as a scalar. In either case, `x`",
        "it is left unchanged and treated as a scalar. In either"
    ],
    [
        "or its elements must support addition and multiplication with",
        "or its elements must support addition and"
    ],
    [
        "with themselves and with the elements of `c`.",
        "with themselves and with the"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients for"
    ],
    [
        "degree n are contained in c[n]. If `c` is multidimensional the",
        "degree n are contained in c[n]. If `c`"
    ],
    [
        "remaining indices enumerate multiple polynomials. In the two",
        "remaining indices enumerate multiple polynomials."
    ],
    [
        "dimensional case the coefficients may be thought of as stored in",
        "dimensional case the coefficients may be"
    ],
    [
        "If True, the shape of the coefficient array is extended with ones",
        "If True, the shape of the coefficient array is extended with"
    ],
    [
        "for this action. The result is that every column of coefficients in",
        "for this action. The result is"
    ],
    [
        "`c` is evaluated for every element of `x`. If False, `x` is broadcast",
        "`c` is evaluated for every element of `x`. If False, `x`"
    ],
    [
        "over the columns of `c` for the evaluation.  This keyword is useful",
        "over the columns of `c` for the evaluation. This"
    ],
    [
        "when `c` is multidimensional. The default value is True.",
        "when `c` is multidimensional. The default value"
    ],
    [
        "The shape of the returned array is described above.",
        "The shape of the returned array"
    ],
    [
        "Evaluate a polynomial specified by its roots at points x.",
        "Evaluate a polynomial specified by"
    ],
    [
        "If `r` is of length ``N``, this function returns the value",
        "If `r` is of length ``N``, this"
    ],
    [
        "The parameter `x` is converted to an array only if it is a tuple or a",
        "The parameter `x` is converted to an array only if it is a"
    ],
    [
        "list, otherwise it is treated as a scalar. In either case, either `x`",
        "list, otherwise it is treated as a scalar. In either case, either"
    ],
    [
        "or its elements must support multiplication and addition both with",
        "or its elements must support multiplication"
    ],
    [
        "themselves and with the elements of `r`.",
        "themselves and with the elements of"
    ],
    [
        "is multidimensional, then the shape of the result depends on the value of",
        "is multidimensional, then the shape of the result depends on the"
    ],
    [
        "that is, each polynomial is evaluated at every value of `x`. If `tensor` is",
        "that is, each polynomial is evaluated at every value of `x`. If `tensor`"
    ],
    [
        "evaluated only for the corresponding broadcast value of `x`. Note that",
        "evaluated only for the corresponding broadcast value"
    ],
    [
        "If `x` is a list or tuple, it is converted to an ndarray, otherwise",
        "If `x` is a list or tuple,"
    ],
    [
        "it is left unchanged and treated as a scalar. In either case, `x`",
        "it is left unchanged and treated as a scalar."
    ],
    [
        "or its elements must support addition and multiplication with",
        "or its elements must support addition and multiplication"
    ],
    [
        "with themselves and with the elements of `r`.",
        "with themselves and with the elements"
    ],
    [
        "Array of roots. If `r` is multidimensional the first index is the",
        "Array of roots. If `r` is multidimensional the first"
    ],
    [
        "root index, while the remaining indices enumerate multiple",
        "root index, while the remaining"
    ],
    [
        "polynomials. For instance, in the two dimensional case the roots",
        "polynomials. For instance, in the two"
    ],
    [
        "of each polynomial may be thought of as stored in the columns of `r`.",
        "of each polynomial may be thought of as stored in the columns"
    ],
    [
        "If True, the shape of the roots array is extended with ones on the",
        "If True, the shape of the roots array is extended with"
    ],
    [
        "action. The result is that every column of coefficients in `r` is",
        "action. The result is that every column of coefficients"
    ],
    [
        "evaluated for every element of `x`. If False, `x` is broadcast over the",
        "evaluated for every element of `x`. If False, `x` is broadcast over"
    ],
    [
        "columns of `r` for the evaluation.  This keyword is useful when `r` is",
        "columns of `r` for the evaluation. This keyword is useful when `r`"
    ],
    [
        "multidimensional. The default value is True.",
        "multidimensional. The default"
    ],
    [
        "The shape of the returned array is described above.",
        "The shape of the returned array is described"
    ],
    [
        "raise ValueError(\"x.ndim must be < r.ndim when tensor == False\")",
        "raise ValueError(\"x.ndim must be < r.ndim when"
    ],
    [
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * x^i * y^j",
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * x^i *"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted to arrays only if they"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars and they",
        "tuples or a lists, otherwise they are treated as"
    ],
    [
        "must have the same shape after conversion. In either case, either `x`",
        "must have the same shape after conversion. In"
    ],
    [
        "and `y` or their elements must support multiplication and addition both",
        "and `y` or their elements must support multiplication and addition"
    ],
    [
        "with themselves and with the elements of `c`.",
        "with themselves and with the elements"
    ],
    [
        "If `c` has fewer than two dimensions, ones are implicitly appended to",
        "If `c` has fewer than two"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like,"
    ],
    [
        "The two dimensional series is evaluated at the points ``(x, y)``,",
        "The two dimensional series is evaluated at"
    ],
    [
        "where `x` and `y` must have the same shape. If `x` or `y` is a list",
        "where `x` and `y` must have the same shape. If `x` or `y` is a"
    ],
    [
        "or tuple, it is first converted to an ndarray, otherwise it is left",
        "or tuple, it is first converted to an ndarray,"
    ],
    [
        "unchanged and, if it isn't an ndarray, it is treated as a scalar.",
        "unchanged and, if it isn't an ndarray, it is"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term",
        "Array of coefficients ordered so that"
    ],
    [
        "of multi-degree i,j is contained in ``c[i,j]``. If `c` has",
        "of multi-degree i,j is contained"
    ],
    [
        "dimension greater than two the remaining indices enumerate multiple",
        "dimension greater than two the remaining indices"
    ],
    [
        "The values of the two dimensional polynomial at points formed with",
        "The values of the two dimensional polynomial at"
    ],
    [
        "pairs of corresponding values from `x` and `y`.",
        "pairs of corresponding values from"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial"
    ],
    [
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j} * a^i * b^j",
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j} *"
    ],
    [
        "where the points ``(a, b)`` consist of all pairs formed by taking",
        "where the points ``(a, b)`` consist of all pairs"
    ],
    [
        "`a` from `x` and `b` from `y`. The resulting points form a grid with",
        "`a` from `x` and `b` from `y`. The resulting points form a grid"
    ],
    [
        "`x` in the first dimension and `y` in the second.",
        "`x` in the first dimension and `y`"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars. In either",
        "tuples or a lists, otherwise they are treated as"
    ],
    [
        "case, either `x` and `y` or their elements must support multiplication",
        "case, either `x` and `y` or their elements must"
    ],
    [
        "and addition both with themselves and with the elements of `c`.",
        "and addition both with themselves and with the"
    ],
    [
        "If `c` has fewer than two dimensions, ones are implicitly appended to",
        "If `c` has fewer than two dimensions, ones"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like, compatible"
    ],
    [
        "The two dimensional series is evaluated at the points in the",
        "The two dimensional series is evaluated"
    ],
    [
        "Cartesian product of `x` and `y`.  If `x` or `y` is a list or",
        "Cartesian product of `x` and `y`. If `x` or `y`"
    ],
    [
        "tuple, it is first converted to an ndarray, otherwise it is left",
        "tuple, it is first converted to"
    ],
    [
        "unchanged and, if it isn't an ndarray, it is treated as a scalar.",
        "unchanged and, if it isn't an ndarray, it is"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in ``c[i,j]``. If `c`"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional polynomial at points in the"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial as"
    ],
    [
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * x^i * y^j * z^k",
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * x^i *"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if",
        "The parameters `x`, `y`, and `z` are converted"
    ],
    [
        "they are tuples or a lists, otherwise they are treated as a scalars and",
        "they are tuples or a lists, otherwise they"
    ],
    [
        "they must have the same shape after conversion. In either case, either",
        "they must have the same shape after"
    ],
    [
        "`x`, `y`, and `z` or their elements must support multiplication and",
        "`x`, `y`, and `z` or their elements must support multiplication"
    ],
    [
        "addition both with themselves and with the elements of `c`.",
        "addition both with themselves and with the elements"
    ],
    [
        "x, y, z : array_like, compatible object",
        "x, y, z : array_like, compatible"
    ],
    [
        "The three dimensional series is evaluated at the points",
        "The three dimensional series is evaluated at the"
    ],
    [
        "``(x, y, z)``, where `x`, `y`, and `z` must have the same shape.  If",
        "``(x, y, z)``, where `x`, `y`, and"
    ],
    [
        "any of `x`, `y`, or `z` is a list or tuple, it is first converted",
        "any of `x`, `y`, or `z` is a list or tuple, it is"
    ],
    [
        "to an ndarray, otherwise it is left unchanged and if it isn't an",
        "to an ndarray, otherwise it is left"
    ],
    [
        "ndarray it is  treated as a scalar.",
        "ndarray it is treated"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that"
    ],
    [
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension",
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c`"
    ],
    [
        "The values of the multidimensional polynomial on points formed with",
        "The values of the multidimensional polynomial on points formed"
    ],
    [
        "triples of corresponding values from `x`, `y`, and `z`.",
        "triples of corresponding values from `x`,"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import"
    ],
    [
        "return pu._valnd(polyval, c, x, y, z)",
        "return pu._valnd(polyval, c,"
    ],
    [
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * a^i * b^j * c^k",
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * a^i"
    ],
    [
        "where the points ``(a, b, c)`` consist of all triples formed by taking",
        "where the points ``(a, b, c)`` consist of all"
    ],
    [
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form",
        "`a` from `x`, `b` from `y`, and `c` from `z`."
    ],
    [
        "a grid with `x` in the first dimension, `y` in the second, and `z` in",
        "a grid with `x` in the first dimension, `y`"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if they",
        "The parameters `x`, `y`, and `z` are converted to arrays only"
    ],
    [
        "are tuples or a lists, otherwise they are treated as a scalars. In",
        "are tuples or a lists, otherwise they are"
    ],
    [
        "either case, either `x`, `y`, and `z` or their elements must support",
        "either case, either `x`, `y`, and `z` or their"
    ],
    [
        "multiplication and addition both with themselves and with the elements",
        "multiplication and addition both with"
    ],
    [
        "If `c` has fewer than three dimensions, ones are implicitly appended to",
        "If `c` has fewer than three dimensions, ones are implicitly"
    ],
    [
        "x, y, z : array_like, compatible objects",
        "x, y, z : array_like, compatible"
    ],
    [
        "The three dimensional series is evaluated at the points in the",
        "The three dimensional series is evaluated"
    ],
    [
        "Cartesian product of `x`, `y`, and `z`.  If `x`, `y`, or `z` is a",
        "Cartesian product of `x`, `y`, and `z`. If `x`, `y`, or `z`"
    ],
    [
        "list or tuple, it is first converted to an ndarray, otherwise it is",
        "list or tuple, it is first converted to an"
    ],
    [
        "left unchanged and, if it isn't an ndarray, it is treated as a",
        "left unchanged and, if it isn't an ndarray, it"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in ``c[i,j]``. If"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional polynomial at points in"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial"
    ],
    [
        "return pu._gridnd(polyval, c, x, y, z)",
        "return pu._gridnd(polyval, c, x, y,"
    ],
    [
        "Returns the Vandermonde matrix of degree `deg` and sample points",
        "Returns the Vandermonde matrix of"
    ],
    [
        "`x`. The Vandermonde matrix is defined by",
        "`x`. The Vandermonde matrix"
    ],
    [
        ".. math:: V[..., i] = x^i,",
        ".. math:: V[..., i]"
    ],
    [
        "`x` and the last index is the power of `x`.",
        "`x` and the last index is the"
    ],
    [
        "matrix ``V = polyvander(x, n)``, then ``np.dot(V, c)`` and",
        "matrix ``V = polyvander(x, n)``, then"
    ],
    [
        "``polyval(x, c)`` are the same up to roundoff. This equivalence is",
        "``polyval(x, c)`` are the same up to roundoff. This"
    ],
    [
        "useful both for least squares fitting and for the evaluation of a large",
        "useful both for least squares fitting and for the evaluation"
    ],
    [
        "number of polynomials of the same degree and sample points.",
        "number of polynomials of the same degree and"
    ],
    [
        "depending on whether any of the elements are complex. If `x` is",
        "depending on whether any of the elements"
    ],
    [
        "The Vandermonde matrix. The shape of the returned matrix is",
        "The Vandermonde matrix. The shape of the returned matrix"
    ],
    [
        "The dtype will be the same as the converted `x`.",
        "The dtype will be the same as the"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial as"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of"
    ],
    [
        "points ``(x, y)``. The pseudo-Vandermonde matrix is defined by",
        "points ``(x, y)``. The pseudo-Vandermonde matrix is defined"
    ],
    [
        "`V` index the points ``(x, y)`` and the last index encodes the powers of",
        "`V` index the points ``(x, y)`` and"
    ],
    [
        "up to roundoff. This equivalence is useful both for least squares",
        "up to roundoff. This equivalence is"
    ],
    [
        "of the same degrees and sample points.",
        "of the same degrees"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes",
        "Arrays of point coordinates, all of the same shape."
    ],
    [
        "whether any of the elements are complex. Scalars are converted to",
        "whether any of the elements are complex. Scalars are converted"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg].",
        "List of maximum degrees of"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is"
    ],
    [
        "as the converted `x` and `y`.",
        "as the converted `x`"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial as"
    ],
    [
        "return pu._vander_nd_flat((polyvander, polyvander), (x, y), deg)",
        "return pu._vander_nd_flat((polyvander, polyvander), (x,"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and"
    ],
    [
        "points ``(x, y, z)``. If `l`, `m`, `n` are the given degrees in `x`, `y`, `z`,",
        "points ``(x, y, z)``. If `l`, `m`, `n`"
    ],
    [
        "then The pseudo-Vandermonde matrix is defined by",
        "then The pseudo-Vandermonde matrix"
    ],
    [
        "indices of `V` index the points ``(x, y, z)`` and the last index encodes",
        "indices of `V` index the points ``(x, y, z)`` and"
    ],
    [
        "the powers of `x`, `y`, and `z`.",
        "the powers of `x`,"
    ],
    [
        "same up to roundoff. This equivalence is useful both for least squares",
        "same up to roundoff. This equivalence is useful"
    ],
    [
        "of the same degrees and sample points.",
        "of the same degrees and"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes will",
        "Arrays of point coordinates, all of the same"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg, z_deg].",
        "List of maximum degrees of"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is ``x.shape + (order,)``,"
    ],
    [
        "be the same as the converted `x`, `y`, and `z`.",
        "be the same as the"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import polynomial as"
    ],
    [
        ">>> deg = [l, m, n]",
        ">>> deg = [l, m,"
    ],
    [
        "return pu._vander_nd_flat((polyvander, polyvander, polyvander), (x, y, z), deg)",
        "return pu._vander_nd_flat((polyvander, polyvander, polyvander), (x, y,"
    ],
    [
        "def polyfit(x, y, deg, rcond=None, full=False, w=None):",
        "def polyfit(x, y, deg,"
    ],
    [
        "Least-squares fit of a polynomial to data.",
        "Least-squares fit of a"
    ],
    [
        "Return the coefficients of a polynomial of degree `deg` that is the",
        "Return the coefficients of a polynomial"
    ],
    [
        "least squares fit to the data values `y` given at points `x`. If `y` is",
        "least squares fit to the data values `y` given at points"
    ],
    [
        "fits are done, one for each column of `y`, and the resulting",
        "fits are done, one for each column of"
    ],
    [
        "The fitted polynomial(s) are in the form",
        "The fitted polynomial(s) are in the"
    ],
    [
        "x-coordinates of the `M` sample (data) points ``(x[i], y[i])``.",
        "x-coordinates of the `M` sample (data) points"
    ],
    [
        "y : array_like, shape (`M`,) or (`M`, `K`)",
        "y : array_like, shape (`M`,) or"
    ],
    [
        "y-coordinates of the sample points.  Several sets of sample points",
        "y-coordinates of the sample points."
    ],
    [
        "sharing the same x-coordinates can be (independently) fit with one",
        "sharing the same x-coordinates can be (independently)"
    ],
    [
        "Degree(s) of the fitting polynomials. If `deg` is a single integer",
        "Degree(s) of the fitting polynomials. If `deg`"
    ],
    [
        "all terms up to and including the `deg`'th term are included in the",
        "all terms up to and including the `deg`'th term are included"
    ],
    [
        "degrees of the terms to include may be used instead.",
        "degrees of the terms to"
    ],
    [
        "Relative condition number of the fit.  Singular values smaller",
        "Relative condition number of the fit. Singular"
    ],
    [
        "than `rcond`, relative to the largest singular value, will be",
        "than `rcond`, relative to the largest"
    ],
    [
        "ignored.  The default value is ``len(x)*eps``, where `eps` is the",
        "ignored. The default value is ``len(x)*eps``,"
    ],
    [
        "Switch determining the nature of the return value.  When ``False``",
        "Switch determining the nature of"
    ],
    [
        "(the default) just the coefficients are returned; when ``True``,",
        "(the default) just the coefficients"
    ],
    [
        "diagnostic information from the singular value decomposition (used",
        "diagnostic information from the singular"
    ],
    [
        "to solve the fit's matrix equation) is also returned.",
        "to solve the fit's matrix equation) is also"
    ],
    [
        "w : array_like, shape (`M`,), optional",
        "w : array_like,"
    ],
    [
        "Weights. If not None, the weight ``w[i]`` applies to the unsquared",
        "Weights. If not None, the weight ``w[i]`` applies to the"
    ],
    [
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are",
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the"
    ],
    [
        "chosen so that the errors of the products ``w[i]*y[i]`` all have the",
        "chosen so that the errors of the products"
    ],
    [
        "same variance.  When using inverse-variance weighting, use",
        "same variance. When using"
    ],
    [
        "the coefficients in column `k` of `coef` represent the polynomial",
        "the coefficients in column `k` of `coef` represent the"
    ],
    [
        "fit to the data in `y`'s `k`-th column.",
        "fit to the data in"
    ],
    [
        "[residuals, rank, singular_values, rcond] : list",
        "[residuals, rank, singular_values,"
    ],
    [
        "These values are only returned if ``full == True``",
        "These values are only returned if"
    ],
    [
        "- residuals -- sum of squared residuals of the least squares fit",
        "- residuals -- sum of squared residuals of"
    ],
    [
        "- rank -- the numerical rank of the scaled Vandermonde matrix",
        "- rank -- the numerical rank of the"
    ],
    [
        "- singular_values -- singular values of the scaled Vandermonde matrix",
        "- singular_values -- singular values"
    ],
    [
        "- rcond -- value of `rcond`.",
        "- rcond -- value"
    ],
    [
        "Raised if the matrix in the least-squares fit is rank deficient.",
        "Raised if the matrix in the least-squares fit"
    ],
    [
        "The warning is only raised if ``full == False``.  The warnings can",
        "The warning is only raised if ``full == False``."
    ],
    [
        "polyvander : Vandermonde matrix for powers.",
        "polyvander : Vandermonde matrix for"
    ],
    [
        "numpy.linalg.lstsq : Computes a least-squares fit from the matrix.",
        "numpy.linalg.lstsq : Computes a least-squares fit"
    ],
    [
        "The solution is the coefficients of the polynomial `p` that minimizes",
        "The solution is the coefficients of the polynomial `p`"
    ],
    [
        "the sum of the weighted squared errors",
        "the sum of the weighted squared"
    ],
    [
        "where the :math:`w_j` are the weights. This problem is solved by",
        "where the :math:`w_j` are the weights. This problem"
    ],
    [
        "setting up the (typically) over-determined matrix equation:",
        "setting up the (typically) over-determined"
    ],
    [
        ".. math:: V(x) * c = w * y,",
        ".. math:: V(x) * c ="
    ],
    [
        "where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the",
        "where `V` is the weighted pseudo Vandermonde"
    ],
    [
        "coefficients to be solved for, `w` are the weights, and `y` are the",
        "coefficients to be solved for, `w` are the weights, and `y`"
    ],
    [
        "observed values.  This equation is then solved using the singular value",
        "observed values. This equation is then solved using"
    ],
    [
        "If some of the singular values of `V` are so small that they are",
        "If some of the singular values of"
    ],
    [
        "neglected (and `full` == ``False``), a `~exceptions.RankWarning` will be",
        "neglected (and `full` == ``False``), a"
    ],
    [
        "raised.  This means that the coefficient values may be poorly determined.",
        "raised. This means that the coefficient"
    ],
    [
        "Fitting to a lower order polynomial will usually get rid of the warning",
        "Fitting to a lower order polynomial will usually get"
    ],
    [
        "(but may not be what you want, of course; if you have independent",
        "(but may not be what you want, of course;"
    ],
    [
        "reason(s) for choosing the degree which isn't working, you may have to:",
        "reason(s) for choosing the degree which isn't working, you"
    ],
    [
        "a) reconsider those reasons, and/or b) reconsider the quality of your",
        "a) reconsider those reasons, and/or b) reconsider"
    ],
    [
        "data).  The `rcond` parameter can also be set to a value smaller than",
        "data). The `rcond` parameter can also be"
    ],
    [
        "its default, but the resulting fit may be spurious and have large",
        "its default, but the resulting fit may"
    ],
    [
        "Polynomial fits using double precision tend to \"fail\" at about",
        "Polynomial fits using double precision tend"
    ],
    [
        "generally better conditioned, but much can still depend on the",
        "generally better conditioned, but much can still"
    ],
    [
        "distribution of the sample points and the smoothness of the data.  If",
        "distribution of the sample points and"
    ],
    [
        "the quality of the fit is inadequate, splines may be a good",
        "the quality of the fit is inadequate, splines"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import"
    ],
    [
        "Same thing without the added noise",
        "Same thing without the added"
    ],
    [
        "return pu._fit(polyvander, x, y, deg, rcond, full, w)",
        "return pu._fit(polyvander, x, y, deg, rcond, full,"
    ],
    [
        "Return the companion matrix of c.",
        "Return the companion matrix"
    ],
    [
        "The companion matrix for power series cannot be made symmetric by",
        "The companion matrix for power series"
    ],
    [
        "scaling the basis, so this function differs from those for the",
        "scaling the basis, so this function differs"
    ],
    [
        "Companion matrix of dimensions (deg, deg).",
        "Companion matrix of dimensions"
    ],
    [
        ">>> from numpy.polynomial import polynomial as P",
        ">>> from numpy.polynomial import"
    ],
    [
        "Compute the roots of a polynomial.",
        "Compute the roots"
    ],
    [
        "Return the roots (a.k.a. \"zeros\") of the polynomial",
        "Return the roots (a.k.a. \"zeros\") of the"
    ],
    [
        ".. math:: p(x) = \\\\sum_i c[i] * x^i.",
        ".. math:: p(x) = \\\\sum_i c[i] *"
    ],
    [
        "Array of the roots of the polynomial. If all the roots are real,",
        "Array of the roots of the polynomial. If all"
    ],
    [
        "then `out` is also real, otherwise it is complex.",
        "then `out` is also real,"
    ],
    [
        "The root estimates are obtained as the eigenvalues of the companion",
        "The root estimates are obtained as the eigenvalues"
    ],
    [
        "matrix, Roots far from the origin of the complex plane may have large",
        "matrix, Roots far from the origin of the"
    ],
    [
        "errors due to the numerical instability of the power series for such",
        "errors due to the numerical instability of the power series"
    ],
    [
        "errors as the value of the series near such points is relatively",
        "errors as the value of the series near"
    ],
    [
        "insensitive to errors in the roots. Isolated roots near the origin can",
        "insensitive to errors in the roots. Isolated roots near the origin"
    ],
    [
        "be improved by a few iterations of Newton's method.",
        "be improved by a few iterations of"
    ],
    [
        "The Polynomial class provides the standard Python numerical methods",
        "The Polynomial class provides the standard Python"
    ],
    [
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as the",
        "'+', '-', '*', '//', '%', 'divmod', '**',"
    ],
    [
        "Polynomial coefficients in order of increasing degree, i.e.,",
        "Polynomial coefficients in order of increasing"
    ],
    [
        "Symbol used to represent the independent variable in string",
        "Symbol used to represent the independent variable"
    ],
    [
        "representations of the polynomial expression, e.g. for printing.",
        "representations of the polynomial"
    ],
    [
        "The symbol must be a valid Python identifier. Default value is 'x'.",
        "The symbol must be a valid Python identifier. Default"
    ],
    [
        "This module provides a number of objects (mostly functions) useful for",
        "This module provides a number of objects (mostly functions) useful"
    ],
    [
        "dealing with Legendre series, including a `Legendre` class that",
        "dealing with Legendre series, including"
    ],
    [
        "encapsulates the usual arithmetic operations.  (General information",
        "encapsulates the usual arithmetic operations."
    ],
    [
        "on how this module represents and works with such polynomials is in the",
        "on how this module represents and works with such polynomials"
    ],
    [
        "docstring for its \"parent\" sub-package, `numpy.polynomial`).",
        "docstring for its"
    ],
    [
        "from . import polyutils as pu",
        "from . import polyutils"
    ],
    [
        "'legzero', 'legone', 'legx', 'legdomain', 'legline', 'legadd',",
        "'legzero', 'legone', 'legx', 'legdomain', 'legline',"
    ],
    [
        "'legsub', 'legmulx', 'legmul', 'legdiv', 'legpow', 'legval', 'legder',",
        "'legsub', 'legmulx', 'legmul', 'legdiv',"
    ],
    [
        "Convert a polynomial to a Legendre series.",
        "Convert a polynomial to a Legendre"
    ],
    [
        "Convert an array representing the coefficients of a polynomial (relative",
        "Convert an array representing the coefficients"
    ],
    [
        "to the \"standard\" basis) ordered from lowest degree to highest, to an",
        "to the \"standard\" basis) ordered from lowest degree to highest,"
    ],
    [
        "array of the coefficients of the equivalent Legendre series, ordered",
        "array of the coefficients of the"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do conversions between polynomial basis"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert method of a"
    ],
    [
        ">>> from numpy import polynomial as P",
        ">>> from numpy import polynomial"
    ],
    [
        "Convert a Legendre series to a polynomial.",
        "Convert a Legendre series"
    ],
    [
        "Convert an array representing the coefficients of a Legendre series,",
        "Convert an array representing the coefficients"
    ],
    [
        "ordered from lowest degree to highest, to an array of the coefficients",
        "ordered from lowest degree to highest, to"
    ],
    [
        "of the equivalent polynomial (relative to the \"standard\" basis) ordered",
        "of the equivalent polynomial (relative"
    ],
    [
        "from lowest order term to highest.",
        "from lowest order term"
    ],
    [
        "(relative to the \"standard\" basis) ordered from lowest order term",
        "(relative to the \"standard\" basis) ordered from lowest order"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do conversions between polynomial basis"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert method of"
    ],
    [
        ">>> from numpy import polynomial as P",
        ">>> from numpy import polynomial as"
    ],
    [
        "from .polynomial import polyadd, polysub, polymulx",
        "from .polynomial import polyadd, polysub,"
    ],
    [
        "Legendre series whose graph is a straight line.",
        "Legendre series whose graph"
    ],
    [
        "The specified line is given by ``off + scl*x``.",
        "The specified line is given by ``off"
    ],
    [
        "This module's representation of the Legendre series for",
        "This module's representation of the Legendre series"
    ],
    [
        "Generate a Legendre series with given roots.",
        "Generate a Legendre series with"
    ],
    [
        "The function returns the coefficients of the polynomial",
        "The function returns the"
    ],
    [
        "in Legendre form, where the :math:`r_n` are the roots specified in `roots`.",
        "in Legendre form, where the :math:`r_n` are the roots specified"
    ],
    [
        "If a zero has multiplicity n, then it must appear in `roots` n times.",
        "If a zero has multiplicity n, then it must appear in `roots`"
    ],
    [
        "roots can appear in any order.",
        "roots can appear in"
    ],
    [
        "If the returned coefficients are `c`, then",
        "If the returned coefficients are"
    ],
    [
        "real array, if some of the roots are complex, then `out` is complex",
        "real array, if some of the roots are complex, then `out` is"
    ],
    [
        "even if all the coefficients in the result are real (see Examples",
        "even if all the coefficients in the result are real"
    ],
    [
        "Add one Legendre series to another.",
        "Add one Legendre"
    ],
    [
        "are sequences of coefficients ordered from lowest order term to",
        "are sequences of coefficients ordered"
    ],
    [
        "Array representing the Legendre series of their sum.",
        "Array representing the Legendre"
    ],
    [
        "Unlike multiplication, division, etc., the sum of two Legendre series",
        "Unlike multiplication, division, etc., the sum of two Legendre"
    ],
    [
        "is a Legendre series (without having to \"reproject\" the result onto",
        "is a Legendre series (without having to \"reproject\" the"
    ],
    [
        "the basis set) so addition, just like that of \"standard\" polynomials,",
        "the basis set) so addition, just"
    ],
    [
        ">>> from numpy.polynomial import legendre as L",
        ">>> from numpy.polynomial import"
    ],
    [
        "Subtract one Legendre series from another.",
        "Subtract one Legendre series from"
    ],
    [
        "sequences of coefficients are from lowest order term to highest, i.e.,",
        "sequences of coefficients are from lowest order term to highest,"
    ],
    [
        "Of Legendre series coefficients representing their difference.",
        "Of Legendre series coefficients"
    ],
    [
        "Unlike multiplication, division, etc., the difference of two Legendre",
        "Unlike multiplication, division, etc., the difference"
    ],
    [
        "series is a Legendre series (without having to \"reproject\" the result",
        "series is a Legendre series (without having to \"reproject\" the"
    ],
    [
        "onto the basis set) so subtraction, just like that of \"standard\"",
        "onto the basis set) so subtraction, just like that"
    ],
    [
        ">>> from numpy.polynomial import legendre as L",
        ">>> from numpy.polynomial import"
    ],
    [
        "\"\"\"Multiply a Legendre series by x.",
        "\"\"\"Multiply a Legendre series"
    ],
    [
        "Multiply the Legendre series `c` by x, where x is the independent",
        "Multiply the Legendre series `c` by x,"
    ],
    [
        "Array representing the result of the multiplication.",
        "Array representing the result of the"
    ],
    [
        "The multiplication uses the recursion relationship for Legendre",
        "The multiplication uses the recursion relationship"
    ],
    [
        ">>> from numpy.polynomial import legendre as L",
        ">>> from numpy.polynomial import"
    ],
    [
        "prd[j] = (c[i] * j) / s",
        "prd[j] = (c[i] * j) /"
    ],
    [
        "prd[k] += (c[i] * i) / s",
        "prd[k] += (c[i] * i) /"
    ],
    [
        "Multiply one Legendre series by another.",
        "Multiply one Legendre"
    ],
    [
        "are sequences of coefficients, from lowest order \"term\" to highest,",
        "are sequences of coefficients, from lowest"
    ],
    [
        "Of Legendre series coefficients representing their product.",
        "Of Legendre series coefficients representing"
    ],
    [
        "In general, the (polynomial) product of two C-series results in terms",
        "In general, the (polynomial) product of two C-series results in"
    ],
    [
        "that are not in the Legendre polynomial basis set.  Thus, to express",
        "that are not in the Legendre polynomial basis set. Thus,"
    ],
    [
        "the product as a Legendre series, it is necessary to \"reproject\" the",
        "the product as a Legendre series, it is necessary to \"reproject\""
    ],
    [
        "product onto said basis set, which may produce \"unintuitive\" (but",
        "product onto said basis set, which may produce \"unintuitive\""
    ],
    [
        "correct) results; see Examples section below.",
        "correct) results; see"
    ],
    [
        ">>> from numpy.polynomial import legendre as L",
        ">>> from numpy.polynomial import"
    ],
    [
        "Divide one Legendre series by another.",
        "Divide one Legendre series by"
    ],
    [
        "Returns the quotient-with-remainder of two Legendre series",
        "Returns the quotient-with-remainder of two"
    ],
    [
        "Of Legendre series coefficients representing the quotient and",
        "Of Legendre series coefficients representing"
    ],
    [
        "In general, the (polynomial) division of one Legendre series by another",
        "In general, the (polynomial) division of one Legendre"
    ],
    [
        "results in quotient and remainder terms that are not in the Legendre",
        "results in quotient and remainder terms that are not in"
    ],
    [
        "polynomial basis set.  Thus, to express these results as a Legendre",
        "polynomial basis set. Thus, to express these results as"
    ],
    [
        "series, it is necessary to \"reproject\" the results onto the Legendre",
        "series, it is necessary to \"reproject\" the results onto the"
    ],
    [
        "basis set, which may produce \"unintuitive\" (but correct) results; see",
        "basis set, which may produce \"unintuitive\" (but correct) results;"
    ],
    [
        ">>> from numpy.polynomial import legendre as L",
        ">>> from numpy.polynomial import legendre"
    ],
    [
        "\"\"\"Raise a Legendre series to a power.",
        "\"\"\"Raise a Legendre series to a"
    ],
    [
        "Returns the Legendre series `c` raised to the power `pow`. The",
        "Returns the Legendre series `c` raised to the power"
    ],
    [
        "argument `c` is a sequence of coefficients ordered from low to high.",
        "argument `c` is a sequence of coefficients ordered from low"
    ],
    [
        "Power to which the series will be raised",
        "Power to which the series"
    ],
    [
        "Maximum power allowed. This is mainly to limit growth of the series",
        "Maximum power allowed. This is mainly to limit growth of"
    ],
    [
        "Returns the Legendre series coefficients `c` differentiated `m` times",
        "Returns the Legendre series coefficients `c` differentiated"
    ],
    [
        "along `axis`.  At each iteration the result is multiplied by `scl` (the",
        "along `axis`. At each iteration the"
    ],
    [
        "scaling factor is for use in a linear change of variable). The argument",
        "scaling factor is for use in a linear change of variable)."
    ],
    [
        "`c` is an array of coefficients from low to high degree along each",
        "`c` is an array of coefficients from"
    ],
    [
        "Array of Legendre series coefficients. If c is multidimensional the",
        "Array of Legendre series coefficients. If c is"
    ],
    [
        "different axis correspond to different variables with the degree in",
        "different axis correspond to different variables with the"
    ],
    [
        "each axis given by the corresponding index.",
        "each axis given by the"
    ],
    [
        "Each differentiation is multiplied by `scl`.  The end result is",
        "Each differentiation is multiplied by `scl`. The"
    ],
    [
        "multiplication by ``scl**m``.  This is for use in a linear change of",
        "multiplication by ``scl**m``. This is for use"
    ],
    [
        "In general, the result of differentiating a Legendre series does not",
        "In general, the result of differentiating a Legendre series does"
    ],
    [
        "resemble the same operation on a power series. Thus the result of this",
        "resemble the same operation on a power series. Thus the result of"
    ],
    [
        "function may be \"unintuitive,\" albeit correct; see Examples section",
        "function may be \"unintuitive,\" albeit correct; see Examples"
    ],
    [
        ">>> from numpy.polynomial import legendre as L",
        ">>> from numpy.polynomial import legendre as"
    ],
    [
        "cnt = pu._as_int(m, \"the order of derivation\")",
        "cnt = pu._as_int(m, \"the order"
    ],
    [
        "raise ValueError(\"The order of derivation must be non-negative\")",
        "raise ValueError(\"The order of"
    ],
    [
        "Returns the Legendre series coefficients `c` integrated `m` times from",
        "Returns the Legendre series coefficients"
    ],
    [
        "`lbnd` along `axis`. At each iteration the resulting series is",
        "`lbnd` along `axis`. At each"
    ],
    [
        "**multiplied** by `scl` and an integration constant, `k`, is added.",
        "**multiplied** by `scl` and an integration constant, `k`,"
    ],
    [
        "The scaling factor is for use in a linear change of variable.  (\"Buyer",
        "The scaling factor is for use in a"
    ],
    [
        "beware\": note that, depending on what one is doing, one may want `scl`",
        "beware\": note that, depending on what one is"
    ],
    [
        "to be the reciprocal of what one might expect; for more information,",
        "to be the reciprocal of what one might expect;"
    ],
    [
        "see the Notes section below.)  The argument `c` is an array of",
        "see the Notes section below.) The"
    ],
    [
        "Array of Legendre series coefficients. If c is multidimensional the",
        "Array of Legendre series coefficients. If"
    ],
    [
        "different axis correspond to different variables with the degree in",
        "different axis correspond to different variables with the"
    ],
    [
        "each axis given by the corresponding index.",
        "each axis given by"
    ],
    [
        "k : {[], list, scalar}, optional",
        "k : {[], list, scalar},"
    ],
    [
        "Integration constant(s).  The value of the first integral at",
        "Integration constant(s). The value of"
    ],
    [
        "``lbnd`` is the first value in the list, the value of the second",
        "``lbnd`` is the first value in the list, the"
    ],
    [
        "integral at ``lbnd`` is the second value, etc.  If ``k == []`` (the",
        "integral at ``lbnd`` is the second value,"
    ],
    [
        "scalar can be given instead of a list.",
        "scalar can be given instead of"
    ],
    [
        "Following each integration the result is *multiplied* by `scl`",
        "Following each integration the result is *multiplied*"
    ],
    [
        "Legendre series coefficient array of the integral.",
        "Legendre series coefficient array"
    ],
    [
        "Note that the result of each integration is *multiplied* by `scl`.",
        "Note that the result of each integration is *multiplied*"
    ],
    [
        "Why is this important to note?  Say one is making a linear change of",
        "Why is this important to note? Say one is"
    ],
    [
        "variable :math:`u = ax + b` in an integral relative to `x`.  Then",
        "variable :math:`u = ax + b` in an integral relative"
    ],
    [
        ":math:`dx = du/a`, so one will need to set `scl` equal to",
        ":math:`dx = du/a`, so one will need to"
    ],
    [
        "Also note that, in general, the result of integrating a C-series needs",
        "Also note that, in general, the result of"
    ],
    [
        "to be \"reprojected\" onto the C-series basis set.  Thus, typically,",
        "to be \"reprojected\" onto the C-series basis set."
    ],
    [
        "the result of this function is \"unintuitive,\" albeit correct; see",
        "the result of this function"
    ],
    [
        ">>> from numpy.polynomial import legendre as L",
        ">>> from numpy.polynomial import legendre"
    ],
    [
        "cnt = pu._as_int(m, \"the order of integration\")",
        "cnt = pu._as_int(m, \"the order"
    ],
    [
        "raise ValueError(\"The order of integration must be non-negative\")",
        "raise ValueError(\"The order of integration must"
    ],
    [
        "raise ValueError(\"lbnd must be a scalar.\")",
        "raise ValueError(\"lbnd must be"
    ],
    [
        "raise ValueError(\"scl must be a scalar.\")",
        "raise ValueError(\"scl must be"
    ],
    [
        "Evaluate a Legendre series at points x.",
        "Evaluate a Legendre series at"
    ],
    [
        "The parameter `x` is converted to an array only if it is a tuple or a",
        "The parameter `x` is converted to an array only if it is a tuple or"
    ],
    [
        "list, otherwise it is treated as a scalar. In either case, either `x`",
        "list, otherwise it is treated as a scalar. In either case,"
    ],
    [
        "or its elements must support multiplication and addition both with",
        "or its elements must support multiplication and addition both"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the elements"
    ],
    [
        "`c` is multidimensional, then the shape of the result depends on the",
        "`c` is multidimensional, then the shape of the"
    ],
    [
        "Trailing zeros in the coefficients will be used in the evaluation, so",
        "Trailing zeros in the coefficients will be used in"
    ],
    [
        "they should be avoided if efficiency is a concern.",
        "they should be avoided if"
    ],
    [
        "If `x` is a list or tuple, it is converted to an ndarray, otherwise",
        "If `x` is a list or tuple,"
    ],
    [
        "it is left unchanged and treated as a scalar. In either case, `x`",
        "it is left unchanged and treated as a scalar. In"
    ],
    [
        "or its elements must support addition and multiplication with",
        "or its elements must support"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the"
    ],
    [
        "degree n are contained in c[n]. If `c` is multidimensional the",
        "degree n are contained in c[n]. If `c` is multidimensional"
    ],
    [
        "remaining indices enumerate multiple polynomials. In the two",
        "remaining indices enumerate multiple polynomials. In"
    ],
    [
        "dimensional case the coefficients may be thought of as stored in",
        "dimensional case the coefficients may be thought of as stored"
    ],
    [
        "If True, the shape of the coefficient array is extended with ones",
        "If True, the shape of the coefficient array is extended"
    ],
    [
        "for this action. The result is that every column of coefficients in",
        "for this action. The result is that every column"
    ],
    [
        "`c` is evaluated for every element of `x`. If False, `x` is broadcast",
        "`c` is evaluated for every element of `x`."
    ],
    [
        "over the columns of `c` for the evaluation.  This keyword is useful",
        "over the columns of `c` for the"
    ],
    [
        "when `c` is multidimensional. The default value is True.",
        "when `c` is multidimensional. The default"
    ],
    [
        "The shape of the return value is described above.",
        "The shape of the return"
    ],
    [
        "The evaluation uses Clenshaw recursion, aka synthetic division.",
        "The evaluation uses Clenshaw recursion,"
    ],
    [
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * L_i(x) * L_j(y)",
        ".. math:: p(x,y) = \\\\sum_{i,j}"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted to arrays"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars and they",
        "tuples or a lists, otherwise they are treated as"
    ],
    [
        "must have the same shape after conversion. In either case, either `x`",
        "must have the same shape after"
    ],
    [
        "and `y` or their elements must support multiplication and addition both",
        "and `y` or their elements must support multiplication"
    ],
    [
        "with themselves and with the elements of `c`.",
        "with themselves and with"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like,"
    ],
    [
        "The two dimensional series is evaluated at the points ``(x, y)``,",
        "The two dimensional series is evaluated at the points ``(x,"
    ],
    [
        "where `x` and `y` must have the same shape. If `x` or `y` is a list",
        "where `x` and `y` must have the same shape. If `x`"
    ],
    [
        "or tuple, it is first converted to an ndarray, otherwise it is left",
        "or tuple, it is first converted to an ndarray, otherwise"
    ],
    [
        "unchanged and if it isn't an ndarray it is treated as a scalar.",
        "unchanged and if it isn't an ndarray it is treated as a"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term",
        "Array of coefficients ordered so that the"
    ],
    [
        "of multi-degree i,j is contained in ``c[i,j]``. If `c` has",
        "of multi-degree i,j is contained in"
    ],
    [
        "dimension greater than two the remaining indices enumerate multiple",
        "dimension greater than two the remaining"
    ],
    [
        "The values of the two dimensional Legendre series at points formed",
        "The values of the two dimensional Legendre series at"
    ],
    [
        "from pairs of corresponding values from `x` and `y`.",
        "from pairs of corresponding values from `x`"
    ],
    [
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j} * L_i(a) * L_j(b)",
        ".. math:: p(a,b) = \\\\sum_{i,j}"
    ],
    [
        "where the points ``(a, b)`` consist of all pairs formed by taking",
        "where the points ``(a, b)`` consist of all"
    ],
    [
        "`a` from `x` and `b` from `y`. The resulting points form a grid with",
        "`a` from `x` and `b` from `y`. The resulting points form a"
    ],
    [
        "`x` in the first dimension and `y` in the second.",
        "`x` in the first dimension and `y` in"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted to arrays"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars. In either",
        "tuples or a lists, otherwise they are treated as a scalars. In"
    ],
    [
        "case, either `x` and `y` or their elements must support multiplication",
        "case, either `x` and `y` or"
    ],
    [
        "and addition both with themselves and with the elements of `c`.",
        "and addition both with themselves and with the"
    ],
    [
        "If `c` has fewer than two dimensions, ones are implicitly appended to",
        "If `c` has fewer than two"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like,"
    ],
    [
        "The two dimensional series is evaluated at the points in the",
        "The two dimensional series is evaluated at the points"
    ],
    [
        "Cartesian product of `x` and `y`.  If `x` or `y` is a list or",
        "Cartesian product of `x` and `y`. If `x` or `y` is a"
    ],
    [
        "tuple, it is first converted to an ndarray, otherwise it is left",
        "tuple, it is first converted to an"
    ],
    [
        "unchanged and, if it isn't an ndarray, it is treated as a scalar.",
        "unchanged and, if it isn't an ndarray, it is"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that"
    ],
    [
        "multi-degree i,j is contained in ``c[i,j]``. If `c` has dimension",
        "multi-degree i,j is contained in ``c[i,j]``. If `c` has"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices enumerate multiple sets"
    ],
    [
        "The values of the two dimensional Chebyshev series at points in the",
        "The values of the two dimensional Chebyshev series at"
    ],
    [
        "Cartesian product of `x` and `y`.",
        "Cartesian product of"
    ],
    [
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * L_i(x) * L_j(y) * L_k(z)",
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * L_i(x) * L_j(y) *"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if",
        "The parameters `x`, `y`, and `z`"
    ],
    [
        "they are tuples or a lists, otherwise they are treated as a scalars and",
        "they are tuples or a lists, otherwise they are treated"
    ],
    [
        "they must have the same shape after conversion. In either case, either",
        "they must have the same shape"
    ],
    [
        "`x`, `y`, and `z` or their elements must support multiplication and",
        "`x`, `y`, and `z` or their"
    ],
    [
        "addition both with themselves and with the elements of `c`.",
        "addition both with themselves and"
    ],
    [
        "x, y, z : array_like, compatible object",
        "x, y, z : array_like,"
    ],
    [
        "The three dimensional series is evaluated at the points",
        "The three dimensional series is"
    ],
    [
        "``(x, y, z)``, where `x`, `y`, and `z` must have the same shape.  If",
        "``(x, y, z)``, where `x`, `y`, and `z` must have the same"
    ],
    [
        "any of `x`, `y`, or `z` is a list or tuple, it is first converted",
        "any of `x`, `y`, or `z` is a list"
    ],
    [
        "to an ndarray, otherwise it is left unchanged and if it isn't an",
        "to an ndarray, otherwise it is left unchanged"
    ],
    [
        "ndarray it is  treated as a scalar.",
        "ndarray it is treated as a"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that the"
    ],
    [
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension",
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c`"
    ],
    [
        "The values of the multidimensional polynomial on points formed with",
        "The values of the multidimensional polynomial on"
    ],
    [
        "triples of corresponding values from `x`, `y`, and `z`.",
        "triples of corresponding values from `x`, `y`,"
    ],
    [
        "return pu._valnd(legval, c, x, y, z)",
        "return pu._valnd(legval, c, x,"
    ],
    [
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * L_i(a) * L_j(b) * L_k(c)",
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} *"
    ],
    [
        "where the points ``(a, b, c)`` consist of all triples formed by taking",
        "where the points ``(a, b, c)`` consist of"
    ],
    [
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form",
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting"
    ],
    [
        "a grid with `x` in the first dimension, `y` in the second, and `z` in",
        "a grid with `x` in the first dimension, `y` in the second, and `z`"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if they",
        "The parameters `x`, `y`, and `z` are converted to arrays only if"
    ],
    [
        "are tuples or a lists, otherwise they are treated as a scalars. In",
        "are tuples or a lists, otherwise they are"
    ],
    [
        "either case, either `x`, `y`, and `z` or their elements must support",
        "either case, either `x`, `y`, and"
    ],
    [
        "multiplication and addition both with themselves and with the elements",
        "multiplication and addition both with themselves and"
    ],
    [
        "If `c` has fewer than three dimensions, ones are implicitly appended to",
        "If `c` has fewer than three dimensions,"
    ],
    [
        "x, y, z : array_like, compatible objects",
        "x, y, z :"
    ],
    [
        "The three dimensional series is evaluated at the points in the",
        "The three dimensional series is evaluated at"
    ],
    [
        "Cartesian product of `x`, `y`, and `z`.  If `x`, `y`, or `z` is a",
        "Cartesian product of `x`, `y`, and `z`. If `x`, `y`, or `z` is"
    ],
    [
        "list or tuple, it is first converted to an ndarray, otherwise it is",
        "list or tuple, it is first converted to an"
    ],
    [
        "left unchanged and, if it isn't an ndarray, it is treated as a",
        "left unchanged and, if it isn't an ndarray, it is treated as"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in ``c[i,j]``. If `c`"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices enumerate"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional polynomial at points in"
    ],
    [
        "return pu._gridnd(legval, c, x, y, z)",
        "return pu._gridnd(legval, c,"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degree `deg` and sample points",
        "Returns the pseudo-Vandermonde matrix of degree `deg` and sample"
    ],
    [
        "`x`. The pseudo-Vandermonde matrix is defined by",
        "`x`. The pseudo-Vandermonde matrix is"
    ],
    [
        ".. math:: V[..., i] = L_i(x)",
        ".. math:: V[..., i]"
    ],
    [
        "`x` and the last index is the degree of the Legendre polynomial.",
        "`x` and the last index is the degree"
    ],
    [
        "array ``V = legvander(x, n)``, then ``np.dot(V, c)`` and",
        "array ``V = legvander(x, n)``, then ``np.dot(V, c)``"
    ],
    [
        "``legval(x, c)`` are the same up to roundoff. This equivalence is",
        "``legval(x, c)`` are the same up to roundoff. This"
    ],
    [
        "useful both for least squares fitting and for the evaluation of a large",
        "useful both for least squares fitting and for the evaluation of a"
    ],
    [
        "number of Legendre series of the same degree and sample points.",
        "number of Legendre series of the"
    ],
    [
        "depending on whether any of the elements are complex. If `x` is",
        "depending on whether any of the elements are complex. If `x`"
    ],
    [
        "The pseudo-Vandermonde matrix. The shape of the returned matrix is",
        "The pseudo-Vandermonde matrix. The shape of the"
    ],
    [
        "corresponding Legendre polynomial.  The dtype will be the same as",
        "corresponding Legendre polynomial. The dtype will be"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and"
    ],
    [
        "points ``(x, y)``. The pseudo-Vandermonde matrix is defined by",
        "points ``(x, y)``. The pseudo-Vandermonde matrix is"
    ],
    [
        "`V` index the points ``(x, y)`` and the last index encodes the degrees of",
        "`V` index the points ``(x, y)`` and the last index encodes"
    ],
    [
        "up to roundoff. This equivalence is useful both for least squares",
        "up to roundoff. This equivalence is useful both for"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same degrees and sample"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes",
        "Arrays of point coordinates, all of the same"
    ],
    [
        "whether any of the elements are complex. Scalars are converted to",
        "whether any of the elements are complex."
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg].",
        "List of maximum degrees of"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is ``x.shape + (order,)``,"
    ],
    [
        "as the converted `x` and `y`.",
        "as the converted"
    ],
    [
        "return pu._vander_nd_flat((legvander, legvander), (x, y), deg)",
        "return pu._vander_nd_flat((legvander, legvander), (x, y),"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and"
    ],
    [
        "points ``(x, y, z)``. If `l`, `m`, `n` are the given degrees in `x`, `y`, `z`,",
        "points ``(x, y, z)``. If `l`, `m`, `n`"
    ],
    [
        "then The pseudo-Vandermonde matrix is defined by",
        "then The pseudo-Vandermonde matrix is defined"
    ],
    [
        "indices of `V` index the points ``(x, y, z)`` and the last index encodes",
        "indices of `V` index the points ``(x, y,"
    ],
    [
        "the degrees of the Legendre polynomials.",
        "the degrees of"
    ],
    [
        "same up to roundoff. This equivalence is useful both for least squares",
        "same up to roundoff. This equivalence is useful both for least"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same degrees and sample"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes will",
        "Arrays of point coordinates, all of"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg, z_deg].",
        "List of maximum degrees of"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is ``x.shape"
    ],
    [
        "be the same as the converted `x`, `y`, and `z`.",
        "be the same as the converted `x`, `y`, and"
    ],
    [
        "return pu._vander_nd_flat((legvander, legvander, legvander), (x, y, z), deg)",
        "return pu._vander_nd_flat((legvander, legvander, legvander),"
    ],
    [
        "def legfit(x, y, deg, rcond=None, full=False, w=None):",
        "def legfit(x, y, deg, rcond=None, full=False,"
    ],
    [
        "Least squares fit of Legendre series to data.",
        "Least squares fit of Legendre"
    ],
    [
        "Return the coefficients of a Legendre series of degree `deg` that is the",
        "Return the coefficients of a Legendre series of degree `deg` that is"
    ],
    [
        "least squares fit to the data values `y` given at points `x`. If `y` is",
        "least squares fit to the data values `y` given at points `x`. If"
    ],
    [
        "fits are done, one for each column of `y`, and the resulting",
        "fits are done, one for each column of `y`,"
    ],
    [
        "The fitted polynomial(s) are in the form",
        "The fitted polynomial(s) are in"
    ],
    [
        "x-coordinates of the M sample points ``(x[i], y[i])``.",
        "x-coordinates of the M sample points"
    ],
    [
        "y : array_like, shape (M,) or (M, K)",
        "y : array_like, shape (M,) or"
    ],
    [
        "y-coordinates of the sample points. Several data sets of sample",
        "y-coordinates of the sample points. Several data"
    ],
    [
        "points sharing the same x-coordinates can be fitted at once by",
        "points sharing the same x-coordinates can"
    ],
    [
        "Degree(s) of the fitting polynomials. If `deg` is a single integer",
        "Degree(s) of the fitting polynomials. If `deg` is"
    ],
    [
        "all terms up to and including the `deg`'th term are included in the",
        "all terms up to and including the `deg`'th term"
    ],
    [
        "degrees of the terms to include may be used instead.",
        "degrees of the terms to include may be used"
    ],
    [
        "Relative condition number of the fit. Singular values smaller than",
        "Relative condition number of the fit."
    ],
    [
        "this relative to the largest singular value will be ignored. The",
        "this relative to the largest singular value will be"
    ],
    [
        "default value is len(x)*eps, where eps is the relative precision of",
        "default value is len(x)*eps, where eps"
    ],
    [
        "Switch determining nature of return value. When it is False (the",
        "Switch determining nature of return value. When it is False"
    ],
    [
        "default) just the coefficients are returned, when True diagnostic",
        "default) just the coefficients are returned, when True"
    ],
    [
        "information from the singular value decomposition is also returned.",
        "information from the singular value decomposition is also"
    ],
    [
        "w : array_like, shape (`M`,), optional",
        "w : array_like,"
    ],
    [
        "Weights. If not None, the weight ``w[i]`` applies to the unsquared",
        "Weights. If not None, the weight ``w[i]``"
    ],
    [
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are",
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights"
    ],
    [
        "chosen so that the errors of the products ``w[i]*y[i]`` all have the",
        "chosen so that the errors of the products ``w[i]*y[i]`` all"
    ],
    [
        "same variance.  When using inverse-variance weighting, use",
        "same variance. When using inverse-variance weighting,"
    ],
    [
        "coef : ndarray, shape (M,) or (M, K)",
        "coef : ndarray, shape (M,) or"
    ],
    [
        "Legendre coefficients ordered from low to high. If `y` was",
        "Legendre coefficients ordered from low to high. If `y`"
    ],
    [
        "column `k`. If `deg` is specified as a list, coefficients for",
        "column `k`. If `deg` is specified as"
    ],
    [
        "terms not included in the fit are set equal to zero in the",
        "terms not included in the fit are set equal"
    ],
    [
        "[residuals, rank, singular_values, rcond] : list",
        "[residuals, rank, singular_values, rcond] :"
    ],
    [
        "These values are only returned if ``full == True``",
        "These values are only returned if ``full =="
    ],
    [
        "- residuals -- sum of squared residuals of the least squares fit",
        "- residuals -- sum of squared"
    ],
    [
        "- rank -- the numerical rank of the scaled Vandermonde matrix",
        "- rank -- the numerical rank"
    ],
    [
        "- singular_values -- singular values of the scaled Vandermonde matrix",
        "- singular_values -- singular values of the"
    ],
    [
        "- rcond -- value of `rcond`.",
        "- rcond -- value"
    ],
    [
        "The rank of the coefficient matrix in the least-squares fit is",
        "The rank of the coefficient matrix in"
    ],
    [
        "deficient. The warning is only raised if ``full == False``.  The",
        "deficient. The warning is only raised"
    ],
    [
        "warnings can be turned off by",
        "warnings can be turned off"
    ],
    [
        "legval : Evaluates a Legendre series.",
        "legval : Evaluates"
    ],
    [
        "legvander : Vandermonde matrix of Legendre series.",
        "legvander : Vandermonde matrix of"
    ],
    [
        "numpy.linalg.lstsq : Computes a least-squares fit from the matrix.",
        "numpy.linalg.lstsq : Computes a least-squares fit from the"
    ],
    [
        "The solution is the coefficients of the Legendre series `p` that",
        "The solution is the coefficients of"
    ],
    [
        "minimizes the sum of the weighted squared errors",
        "minimizes the sum of the"
    ],
    [
        "where :math:`w_j` are the weights. This problem is solved by setting up",
        "where :math:`w_j` are the weights. This problem is solved by setting"
    ],
    [
        "as the (typically) overdetermined matrix equation",
        "as the (typically)"
    ],
    [
        ".. math:: V(x) * c = w * y,",
        ".. math:: V(x) * c = w"
    ],
    [
        "where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the",
        "where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are"
    ],
    [
        "coefficients to be solved for, `w` are the weights, and `y` are the",
        "coefficients to be solved for, `w` are"
    ],
    [
        "observed values.  This equation is then solved using the singular value",
        "observed values. This equation is then solved using the singular"
    ],
    [
        "If some of the singular values of `V` are so small that they are",
        "If some of the singular values of `V` are so small that they"
    ],
    [
        "neglected, then a `~exceptions.RankWarning` will be issued. This means that",
        "neglected, then a `~exceptions.RankWarning` will"
    ],
    [
        "the coefficient values may be poorly determined. Using a lower order fit",
        "the coefficient values may be poorly determined. Using a"
    ],
    [
        "will usually get rid of the warning.  The `rcond` parameter can also be",
        "will usually get rid of the warning. The `rcond` parameter can also"
    ],
    [
        "set to a value smaller than its default, but the resulting fit may be",
        "set to a value smaller than its default, but the"
    ],
    [
        "spurious and have large contributions from roundoff error.",
        "spurious and have large contributions"
    ],
    [
        "Fits using Legendre series are usually better conditioned than fits",
        "Fits using Legendre series are usually"
    ],
    [
        "using power series, but much can depend on the distribution of the",
        "using power series, but much can depend on the"
    ],
    [
        "sample points and the smoothness of the data. If the quality of the fit",
        "sample points and the smoothness of the data. If"
    ],
    [
        "is inadequate splines may be a good alternative.",
        "is inadequate splines may"
    ],
    [
        "return pu._fit(legvander, x, y, deg, rcond, full, w)",
        "return pu._fit(legvander, x, y, deg, rcond, full,"
    ],
    [
        "\"\"\"Return the scaled companion matrix of c.",
        "\"\"\"Return the scaled companion matrix"
    ],
    [
        "The basis polynomials are scaled so that the companion matrix is",
        "The basis polynomials are scaled so"
    ],
    [
        "symmetric when `c` is an Legendre basis polynomial. This provides",
        "symmetric when `c` is an Legendre basis polynomial."
    ],
    [
        "better eigenvalue estimates than the unscaled case and for basis",
        "better eigenvalue estimates than the unscaled case and for"
    ],
    [
        "polynomials the eigenvalues are guaranteed to be real if",
        "polynomials the eigenvalues are guaranteed"
    ],
    [
        "`numpy.linalg.eigvalsh` is used to obtain them.",
        "`numpy.linalg.eigvalsh` is used to obtain"
    ],
    [
        "Scaled companion matrix of dimensions (deg, deg).",
        "Scaled companion matrix of"
    ],
    [
        "Compute the roots of a Legendre series.",
        "Compute the roots of"
    ],
    [
        "Return the roots (a.k.a. \"zeros\") of the polynomial",
        "Return the roots (a.k.a."
    ],
    [
        ".. math:: p(x) = \\\\sum_i c[i] * L_i(x).",
        ".. math:: p(x) = \\\\sum_i c[i]"
    ],
    [
        "Array of the roots of the series. If all the roots are real,",
        "Array of the roots of the series."
    ],
    [
        "then `out` is also real, otherwise it is complex.",
        "then `out` is also real, otherwise"
    ],
    [
        "The root estimates are obtained as the eigenvalues of the companion",
        "The root estimates are obtained as"
    ],
    [
        "matrix, Roots far from the origin of the complex plane may have large",
        "matrix, Roots far from the origin of the complex plane may"
    ],
    [
        "errors due to the numerical instability of the series for such values.",
        "errors due to the numerical instability"
    ],
    [
        "the value of the series near such points is relatively insensitive to",
        "the value of the series near"
    ],
    [
        "errors in the roots. Isolated roots near the origin can be improved by",
        "errors in the roots. Isolated roots near the origin can"
    ],
    [
        "a few iterations of Newton's method.",
        "a few iterations"
    ],
    [
        "The Legendre series basis polynomials aren't powers of ``x`` so the",
        "The Legendre series basis polynomials aren't powers"
    ],
    [
        "results of this function may seem unintuitive.",
        "results of this function may seem"
    ],
    [
        "Computes the sample points and weights for Gauss-Legendre quadrature.",
        "Computes the sample points and weights"
    ],
    [
        "These sample points and weights will correctly integrate polynomials of",
        "These sample points and weights will correctly"
    ],
    [
        "be problematic. The weights are determined by using the fact that",
        "be problematic. The weights are determined"
    ],
    [
        "where :math:`c` is a constant independent of :math:`k` and :math:`x_k`",
        "where :math:`c` is a constant independent of :math:`k`"
    ],
    [
        "is the k'th root of :math:`L_n`, and then scaling the results to get",
        "is the k'th root of :math:`L_n`, and then scaling the results"
    ],
    [
        "raise ValueError(\"deg must be a positive integer\")",
        "raise ValueError(\"deg must be a positive"
    ],
    [
        "Weight function of the Legendre polynomials.",
        "Weight function of"
    ],
    [
        "normalized, with respect to this weight function.",
        "normalized, with respect to this"
    ],
    [
        "Values at which the weight function will be computed.",
        "Values at which the weight"
    ],
    [
        "The Legendre class provides the standard Python numerical methods",
        "The Legendre class provides the standard Python numerical"
    ],
    [
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as the",
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as"
    ],
    [
        "Legendre coefficients in order of increasing degree, i.e.,",
        "Legendre coefficients in order of increasing degree,"
    ],
    [
        "Symbol used to represent the independent variable in string",
        "Symbol used to represent the independent variable in"
    ],
    [
        "representations of the polynomial expression, e.g. for printing.",
        "representations of the polynomial expression, e.g. for"
    ],
    [
        "The symbol must be a valid Python identifier. Default value is 'x'.",
        "The symbol must be a valid"
    ],
    [
        "This module provides a number of objects (mostly functions) useful for",
        "This module provides a number of objects (mostly functions) useful"
    ],
    [
        "dealing with Hermite series, including a `Hermite` class that",
        "dealing with Hermite series, including a"
    ],
    [
        "encapsulates the usual arithmetic operations.  (General information",
        "encapsulates the usual arithmetic operations."
    ],
    [
        "on how this module represents and works with such polynomials is in the",
        "on how this module represents and works with such polynomials is in"
    ],
    [
        "docstring for its \"parent\" sub-package, `numpy.polynomial`).",
        "docstring for its"
    ],
    [
        "from . import polyutils as pu",
        "from . import polyutils as"
    ],
    [
        "'hermzero', 'hermone', 'hermx', 'hermdomain', 'hermline', 'hermadd',",
        "'hermzero', 'hermone', 'hermx', 'hermdomain', 'hermline',"
    ],
    [
        "'hermsub', 'hermmulx', 'hermmul', 'hermdiv', 'hermpow', 'hermval',",
        "'hermsub', 'hermmulx', 'hermmul',"
    ],
    [
        "Convert a polynomial to a Hermite series.",
        "Convert a polynomial to a"
    ],
    [
        "Convert an array representing the coefficients of a polynomial (relative",
        "Convert an array representing the coefficients of a polynomial"
    ],
    [
        "to the \"standard\" basis) ordered from lowest degree to highest, to an",
        "to the \"standard\" basis) ordered from lowest degree to"
    ],
    [
        "array of the coefficients of the equivalent Hermite series, ordered",
        "array of the coefficients of the equivalent Hermite"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert method of a"
    ],
    [
        "Convert a Hermite series to a polynomial.",
        "Convert a Hermite series to"
    ],
    [
        "Convert an array representing the coefficients of a Hermite series,",
        "Convert an array representing the"
    ],
    [
        "ordered from lowest degree to highest, to an array of the coefficients",
        "ordered from lowest degree to highest,"
    ],
    [
        "of the equivalent polynomial (relative to the \"standard\" basis) ordered",
        "of the equivalent polynomial (relative"
    ],
    [
        "from lowest order term to highest.",
        "from lowest order term to"
    ],
    [
        "(relative to the \"standard\" basis) ordered from lowest order term",
        "(relative to the \"standard\" basis) ordered from lowest order"
    ],
    [
        "The easy way to do conversions between polynomial basis sets",
        "The easy way to do conversions between polynomial basis"
    ],
    [
        "is to use the convert method of a class instance.",
        "is to use the convert method"
    ],
    [
        "from .polynomial import polyadd, polysub, polymulx",
        "from .polynomial import"
    ],
    [
        "Hermite series whose graph is a straight line.",
        "Hermite series whose graph is a straight"
    ],
    [
        "The specified line is given by ``off + scl*x``.",
        "The specified line is given by"
    ],
    [
        "This module's representation of the Hermite series for",
        "This module's representation of"
    ],
    [
        ">>> from numpy.polynomial.hermite import hermline, hermval",
        ">>> from numpy.polynomial.hermite import"
    ],
    [
        "Generate a Hermite series with given roots.",
        "Generate a Hermite series"
    ],
    [
        "The function returns the coefficients of the polynomial",
        "The function returns the coefficients of"
    ],
    [
        "in Hermite form, where the :math:`r_n` are the roots specified in `roots`.",
        "in Hermite form, where the :math:`r_n`"
    ],
    [
        "If a zero has multiplicity n, then it must appear in `roots` n times.",
        "If a zero has multiplicity n, then it must appear in"
    ],
    [
        "roots can appear in any order.",
        "roots can appear"
    ],
    [
        "If the returned coefficients are `c`, then",
        "If the returned coefficients are"
    ],
    [
        "real array, if some of the roots are complex, then `out` is complex",
        "real array, if some of the roots are"
    ],
    [
        "even if all the coefficients in the result are real (see Examples",
        "even if all the coefficients in the result are real (see"
    ],
    [
        ">>> from numpy.polynomial.hermite import hermfromroots, hermval",
        ">>> from numpy.polynomial.hermite"
    ],
    [
        "Add one Hermite series to another.",
        "Add one Hermite series"
    ],
    [
        "are sequences of coefficients ordered from lowest order term to",
        "are sequences of coefficients ordered from lowest order"
    ],
    [
        "Array representing the Hermite series of their sum.",
        "Array representing the Hermite series"
    ],
    [
        "Unlike multiplication, division, etc., the sum of two Hermite series",
        "Unlike multiplication, division, etc., the sum of"
    ],
    [
        "is a Hermite series (without having to \"reproject\" the result onto",
        "is a Hermite series (without having to \"reproject\" the result"
    ],
    [
        "the basis set) so addition, just like that of \"standard\" polynomials,",
        "the basis set) so addition, just like that of"
    ],
    [
        "Subtract one Hermite series from another.",
        "Subtract one Hermite"
    ],
    [
        "sequences of coefficients are from lowest order term to highest, i.e.,",
        "sequences of coefficients are from lowest order term to highest,"
    ],
    [
        "Of Hermite series coefficients representing their difference.",
        "Of Hermite series coefficients"
    ],
    [
        "Unlike multiplication, division, etc., the difference of two Hermite",
        "Unlike multiplication, division, etc., the"
    ],
    [
        "series is a Hermite series (without having to \"reproject\" the result",
        "series is a Hermite series (without having to \"reproject\""
    ],
    [
        "onto the basis set) so subtraction, just like that of \"standard\"",
        "onto the basis set) so subtraction,"
    ],
    [
        "\"\"\"Multiply a Hermite series by x.",
        "\"\"\"Multiply a Hermite series"
    ],
    [
        "Multiply the Hermite series `c` by x, where x is the independent",
        "Multiply the Hermite series `c` by x, where x"
    ],
    [
        "Array representing the result of the multiplication.",
        "Array representing the result of"
    ],
    [
        "The multiplication uses the recursion relationship for Hermite",
        "The multiplication uses the"
    ],
    [
        "Multiply one Hermite series by another.",
        "Multiply one Hermite series"
    ],
    [
        "are sequences of coefficients, from lowest order \"term\" to highest,",
        "are sequences of coefficients, from lowest order"
    ],
    [
        "Of Hermite series coefficients representing their product.",
        "Of Hermite series coefficients"
    ],
    [
        "In general, the (polynomial) product of two C-series results in terms",
        "In general, the (polynomial) product of two C-series results"
    ],
    [
        "that are not in the Hermite polynomial basis set.  Thus, to express",
        "that are not in the Hermite polynomial"
    ],
    [
        "the product as a Hermite series, it is necessary to \"reproject\" the",
        "the product as a Hermite series,"
    ],
    [
        "product onto said basis set, which may produce \"unintuitive\" (but",
        "product onto said basis set, which may produce \"unintuitive\""
    ],
    [
        "correct) results; see Examples section below.",
        "correct) results; see Examples"
    ],
    [
        "Divide one Hermite series by another.",
        "Divide one Hermite series"
    ],
    [
        "Returns the quotient-with-remainder of two Hermite series",
        "Returns the quotient-with-remainder of"
    ],
    [
        "Of Hermite series coefficients representing the quotient and",
        "Of Hermite series coefficients representing the"
    ],
    [
        "In general, the (polynomial) division of one Hermite series by another",
        "In general, the (polynomial) division of"
    ],
    [
        "results in quotient and remainder terms that are not in the Hermite",
        "results in quotient and remainder terms that are not"
    ],
    [
        "polynomial basis set.  Thus, to express these results as a Hermite",
        "polynomial basis set. Thus, to express these results as"
    ],
    [
        "series, it is necessary to \"reproject\" the results onto the Hermite",
        "series, it is necessary to \"reproject\" the"
    ],
    [
        "basis set, which may produce \"unintuitive\" (but correct) results; see",
        "basis set, which may produce \"unintuitive\""
    ],
    [
        "\"\"\"Raise a Hermite series to a power.",
        "\"\"\"Raise a Hermite series to a"
    ],
    [
        "Returns the Hermite series `c` raised to the power `pow`. The",
        "Returns the Hermite series `c` raised"
    ],
    [
        "argument `c` is a sequence of coefficients ordered from low to high.",
        "argument `c` is a sequence of coefficients ordered from low to"
    ],
    [
        "Power to which the series will be raised",
        "Power to which the series will be"
    ],
    [
        "Maximum power allowed. This is mainly to limit growth of the series",
        "Maximum power allowed. This is mainly to limit growth of the"
    ],
    [
        "Returns the Hermite series coefficients `c` differentiated `m` times",
        "Returns the Hermite series coefficients"
    ],
    [
        "along `axis`.  At each iteration the result is multiplied by `scl` (the",
        "along `axis`. At each iteration the"
    ],
    [
        "scaling factor is for use in a linear change of variable). The argument",
        "scaling factor is for use in a linear change"
    ],
    [
        "`c` is an array of coefficients from low to high degree along each",
        "`c` is an array of coefficients from low to"
    ],
    [
        "Array of Hermite series coefficients. If `c` is multidimensional the",
        "Array of Hermite series coefficients."
    ],
    [
        "different axis correspond to different variables with the degree in",
        "different axis correspond to different variables with the"
    ],
    [
        "each axis given by the corresponding index.",
        "each axis given by"
    ],
    [
        "Each differentiation is multiplied by `scl`.  The end result is",
        "Each differentiation is multiplied by `scl`. The end result"
    ],
    [
        "multiplication by ``scl**m``.  This is for use in a linear change of",
        "multiplication by ``scl**m``. This is for use in"
    ],
    [
        "In general, the result of differentiating a Hermite series does not",
        "In general, the result of differentiating a Hermite"
    ],
    [
        "resemble the same operation on a power series. Thus the result of this",
        "resemble the same operation on a power series. Thus the"
    ],
    [
        "function may be \"unintuitive,\" albeit correct; see Examples section",
        "function may be \"unintuitive,\" albeit correct; see"
    ],
    [
        "cnt = pu._as_int(m, \"the order of derivation\")",
        "cnt = pu._as_int(m, \"the order of"
    ],
    [
        "raise ValueError(\"The order of derivation must be non-negative\")",
        "raise ValueError(\"The order of"
    ],
    [
        "Returns the Hermite series coefficients `c` integrated `m` times from",
        "Returns the Hermite series coefficients `c` integrated `m`"
    ],
    [
        "`lbnd` along `axis`. At each iteration the resulting series is",
        "`lbnd` along `axis`. At each iteration the resulting"
    ],
    [
        "**multiplied** by `scl` and an integration constant, `k`, is added.",
        "**multiplied** by `scl` and an integration constant,"
    ],
    [
        "The scaling factor is for use in a linear change of variable.  (\"Buyer",
        "The scaling factor is for use in a"
    ],
    [
        "beware\": note that, depending on what one is doing, one may want `scl`",
        "beware\": note that, depending on what one"
    ],
    [
        "to be the reciprocal of what one might expect; for more information,",
        "to be the reciprocal of what one might expect; for"
    ],
    [
        "see the Notes section below.)  The argument `c` is an array of",
        "see the Notes section below.) The argument `c`"
    ],
    [
        "Array of Hermite series coefficients. If c is multidimensional the",
        "Array of Hermite series coefficients. If c"
    ],
    [
        "different axis correspond to different variables with the degree in",
        "different axis correspond to different variables with the"
    ],
    [
        "each axis given by the corresponding index.",
        "each axis given by"
    ],
    [
        "k : {[], list, scalar}, optional",
        "k : {[],"
    ],
    [
        "Integration constant(s).  The value of the first integral at",
        "Integration constant(s). The value of the first integral"
    ],
    [
        "``lbnd`` is the first value in the list, the value of the second",
        "``lbnd`` is the first value in the"
    ],
    [
        "integral at ``lbnd`` is the second value, etc.  If ``k == []`` (the",
        "integral at ``lbnd`` is the second value, etc. If ``k"
    ],
    [
        "scalar can be given instead of a list.",
        "scalar can be given instead of"
    ],
    [
        "Following each integration the result is *multiplied* by `scl`",
        "Following each integration the result is *multiplied* by"
    ],
    [
        "Hermite series coefficients of the integral.",
        "Hermite series coefficients of the"
    ],
    [
        "Note that the result of each integration is *multiplied* by `scl`.",
        "Note that the result of each integration is *multiplied*"
    ],
    [
        "Why is this important to note?  Say one is making a linear change of",
        "Why is this important to note? Say one is making a"
    ],
    [
        "variable :math:`u = ax + b` in an integral relative to `x`.  Then",
        "variable :math:`u = ax + b` in an integral relative to `x`."
    ],
    [
        ":math:`dx = du/a`, so one will need to set `scl` equal to",
        ":math:`dx = du/a`, so one will need to set `scl` equal"
    ],
    [
        "Also note that, in general, the result of integrating a C-series needs",
        "Also note that, in general, the"
    ],
    [
        "to be \"reprojected\" onto the C-series basis set.  Thus, typically,",
        "to be \"reprojected\" onto the C-series basis"
    ],
    [
        "the result of this function is \"unintuitive,\" albeit correct; see",
        "the result of this function"
    ],
    [
        "cnt = pu._as_int(m, \"the order of integration\")",
        "cnt = pu._as_int(m, \"the order"
    ],
    [
        "raise ValueError(\"The order of integration must be non-negative\")",
        "raise ValueError(\"The order of"
    ],
    [
        "raise ValueError(\"lbnd must be a scalar.\")",
        "raise ValueError(\"lbnd must"
    ],
    [
        "raise ValueError(\"scl must be a scalar.\")",
        "raise ValueError(\"scl must be"
    ],
    [
        "Evaluate an Hermite series at points x.",
        "Evaluate an Hermite series at points"
    ],
    [
        "The parameter `x` is converted to an array only if it is a tuple or a",
        "The parameter `x` is converted to an array only if it"
    ],
    [
        "list, otherwise it is treated as a scalar. In either case, either `x`",
        "list, otherwise it is treated as a scalar. In either"
    ],
    [
        "or its elements must support multiplication and addition both with",
        "or its elements must support multiplication and"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the elements of"
    ],
    [
        "`c` is multidimensional, then the shape of the result depends on the",
        "`c` is multidimensional, then the shape"
    ],
    [
        "Trailing zeros in the coefficients will be used in the evaluation, so",
        "Trailing zeros in the coefficients will be used"
    ],
    [
        "they should be avoided if efficiency is a concern.",
        "they should be avoided if efficiency is a"
    ],
    [
        "If `x` is a list or tuple, it is converted to an ndarray, otherwise",
        "If `x` is a list or tuple,"
    ],
    [
        "it is left unchanged and treated as a scalar. In either case, `x`",
        "it is left unchanged and treated as a scalar. In"
    ],
    [
        "or its elements must support addition and multiplication with",
        "or its elements must support"
    ],
    [
        "themselves and with the elements of `c`.",
        "themselves and with the"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients"
    ],
    [
        "degree n are contained in c[n]. If `c` is multidimensional the",
        "degree n are contained in c[n]."
    ],
    [
        "remaining indices enumerate multiple polynomials. In the two",
        "remaining indices enumerate multiple polynomials. In"
    ],
    [
        "dimensional case the coefficients may be thought of as stored in",
        "dimensional case the coefficients may be thought of as stored"
    ],
    [
        "If True, the shape of the coefficient array is extended with ones",
        "If True, the shape of the coefficient array is extended"
    ],
    [
        "for this action. The result is that every column of coefficients in",
        "for this action. The result is that every"
    ],
    [
        "`c` is evaluated for every element of `x`. If False, `x` is broadcast",
        "`c` is evaluated for every element of `x`. If"
    ],
    [
        "over the columns of `c` for the evaluation.  This keyword is useful",
        "over the columns of `c` for"
    ],
    [
        "when `c` is multidimensional. The default value is True.",
        "when `c` is multidimensional. The default value is"
    ],
    [
        "The shape of the return value is described above.",
        "The shape of the return value is described"
    ],
    [
        "The evaluation uses Clenshaw recursion, aka synthetic division.",
        "The evaluation uses Clenshaw recursion, aka"
    ],
    [
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * H_i(x) * H_j(y)",
        ".. math:: p(x,y) = \\\\sum_{i,j} c_{i,j} * H_i(x)"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars and they",
        "tuples or a lists, otherwise they are treated"
    ],
    [
        "must have the same shape after conversion. In either case, either `x`",
        "must have the same shape after conversion. In either"
    ],
    [
        "and `y` or their elements must support multiplication and addition both",
        "and `y` or their elements must support"
    ],
    [
        "with themselves and with the elements of `c`.",
        "with themselves and with"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like, compatible"
    ],
    [
        "The two dimensional series is evaluated at the points ``(x, y)``,",
        "The two dimensional series is evaluated at the points"
    ],
    [
        "where `x` and `y` must have the same shape. If `x` or `y` is a list",
        "where `x` and `y` must have the same shape."
    ],
    [
        "or tuple, it is first converted to an ndarray, otherwise it is left",
        "or tuple, it is first converted to an ndarray, otherwise"
    ],
    [
        "unchanged and if it isn't an ndarray it is treated as a scalar.",
        "unchanged and if it isn't an ndarray it"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term",
        "Array of coefficients ordered so that the coefficient"
    ],
    [
        "of multi-degree i,j is contained in ``c[i,j]``. If `c` has",
        "of multi-degree i,j is contained"
    ],
    [
        "dimension greater than two the remaining indices enumerate multiple",
        "dimension greater than two the remaining indices enumerate"
    ],
    [
        "The values of the two dimensional polynomial at points formed with",
        "The values of the two dimensional polynomial at points formed"
    ],
    [
        "pairs of corresponding values from `x` and `y`.",
        "pairs of corresponding values"
    ],
    [
        ".. math:: p(a,b) = \\\\sum_{i,j} c_{i,j} * H_i(a) * H_j(b)",
        ".. math:: p(a,b) = \\\\sum_{i,j}"
    ],
    [
        "where the points ``(a, b)`` consist of all pairs formed by taking",
        "where the points ``(a, b)`` consist of"
    ],
    [
        "`a` from `x` and `b` from `y`. The resulting points form a grid with",
        "`a` from `x` and `b` from `y`. The resulting points"
    ],
    [
        "`x` in the first dimension and `y` in the second.",
        "`x` in the first dimension and `y` in the"
    ],
    [
        "The parameters `x` and `y` are converted to arrays only if they are",
        "The parameters `x` and `y` are converted to arrays"
    ],
    [
        "tuples or a lists, otherwise they are treated as a scalars. In either",
        "tuples or a lists, otherwise they are"
    ],
    [
        "case, either `x` and `y` or their elements must support multiplication",
        "case, either `x` and `y` or their"
    ],
    [
        "and addition both with themselves and with the elements of `c`.",
        "and addition both with themselves and with the elements"
    ],
    [
        "If `c` has fewer than two dimensions, ones are implicitly appended to",
        "If `c` has fewer than two dimensions, ones are implicitly appended"
    ],
    [
        "x, y : array_like, compatible objects",
        "x, y : array_like,"
    ],
    [
        "The two dimensional series is evaluated at the points in the",
        "The two dimensional series is evaluated at the points"
    ],
    [
        "Cartesian product of `x` and `y`.  If `x` or `y` is a list or",
        "Cartesian product of `x` and `y`. If `x` or"
    ],
    [
        "tuple, it is first converted to an ndarray, otherwise it is left",
        "tuple, it is first converted to an ndarray, otherwise"
    ],
    [
        "unchanged and, if it isn't an ndarray, it is treated as a scalar.",
        "unchanged and, if it isn't an ndarray, it is"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients for terms"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in ``c[i,j]``. If"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining indices enumerate"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional"
    ],
    [
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * H_i(x) * H_j(y) * H_k(z)",
        ".. math:: p(x,y,z) = \\\\sum_{i,j,k} c_{i,j,k} * H_i(x) * H_j(y)"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if",
        "The parameters `x`, `y`, and `z` are converted"
    ],
    [
        "they are tuples or a lists, otherwise they are treated as a scalars and",
        "they are tuples or a lists, otherwise they are treated as a"
    ],
    [
        "they must have the same shape after conversion. In either case, either",
        "they must have the same shape"
    ],
    [
        "`x`, `y`, and `z` or their elements must support multiplication and",
        "`x`, `y`, and `z` or their elements must support"
    ],
    [
        "addition both with themselves and with the elements of `c`.",
        "addition both with themselves and with the elements of"
    ],
    [
        "x, y, z : array_like, compatible object",
        "x, y, z :"
    ],
    [
        "The three dimensional series is evaluated at the points",
        "The three dimensional series is"
    ],
    [
        "``(x, y, z)``, where `x`, `y`, and `z` must have the same shape.  If",
        "``(x, y, z)``, where `x`, `y`, and `z` must"
    ],
    [
        "any of `x`, `y`, or `z` is a list or tuple, it is first converted",
        "any of `x`, `y`, or `z` is a list or tuple, it is first"
    ],
    [
        "to an ndarray, otherwise it is left unchanged and if it isn't an",
        "to an ndarray, otherwise it is left unchanged"
    ],
    [
        "ndarray it is  treated as a scalar.",
        "ndarray it is treated as a"
    ],
    [
        "Array of coefficients ordered so that the coefficient of the term of",
        "Array of coefficients ordered so that the coefficient of"
    ],
    [
        "multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension",
        "multi-degree i,j,k is contained in ``c[i,j,k]``."
    ],
    [
        "The values of the multidimensional polynomial on points formed with",
        "The values of the multidimensional polynomial"
    ],
    [
        "triples of corresponding values from `x`, `y`, and `z`.",
        "triples of corresponding values from"
    ],
    [
        "return pu._valnd(hermval, c, x, y, z)",
        "return pu._valnd(hermval, c, x,"
    ],
    [
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * H_i(a) * H_j(b) * H_k(c)",
        ".. math:: p(a,b,c) = \\\\sum_{i,j,k} c_{i,j,k} * H_i(a)"
    ],
    [
        "where the points ``(a, b, c)`` consist of all triples formed by taking",
        "where the points ``(a, b, c)`` consist of"
    ],
    [
        "`a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form",
        "`a` from `x`, `b` from `y`, and `c` from `z`. The"
    ],
    [
        "a grid with `x` in the first dimension, `y` in the second, and `z` in",
        "a grid with `x` in the first dimension, `y` in the second, and"
    ],
    [
        "The parameters `x`, `y`, and `z` are converted to arrays only if they",
        "The parameters `x`, `y`, and `z` are converted to arrays only"
    ],
    [
        "are tuples or a lists, otherwise they are treated as a scalars. In",
        "are tuples or a lists, otherwise they are treated as a"
    ],
    [
        "either case, either `x`, `y`, and `z` or their elements must support",
        "either case, either `x`, `y`, and"
    ],
    [
        "multiplication and addition both with themselves and with the elements",
        "multiplication and addition both with themselves and with the"
    ],
    [
        "If `c` has fewer than three dimensions, ones are implicitly appended to",
        "If `c` has fewer than three dimensions, ones are implicitly"
    ],
    [
        "x, y, z : array_like, compatible objects",
        "x, y, z : array_like, compatible"
    ],
    [
        "The three dimensional series is evaluated at the points in the",
        "The three dimensional series is evaluated at the points in"
    ],
    [
        "Cartesian product of `x`, `y`, and `z`.  If `x`, `y`, or `z` is a",
        "Cartesian product of `x`, `y`, and `z`. If `x`, `y`,"
    ],
    [
        "list or tuple, it is first converted to an ndarray, otherwise it is",
        "list or tuple, it is first converted to an ndarray, otherwise"
    ],
    [
        "left unchanged and, if it isn't an ndarray, it is treated as a",
        "left unchanged and, if it isn't an ndarray, it is treated"
    ],
    [
        "Array of coefficients ordered so that the coefficients for terms of",
        "Array of coefficients ordered so that the coefficients for"
    ],
    [
        "degree i,j are contained in ``c[i,j]``. If `c` has dimension",
        "degree i,j are contained in ``c[i,j]``. If"
    ],
    [
        "greater than two the remaining indices enumerate multiple sets of",
        "greater than two the remaining"
    ],
    [
        "The values of the two dimensional polynomial at points in the Cartesian",
        "The values of the two dimensional polynomial"
    ],
    [
        "return pu._gridnd(hermval, c, x, y, z)",
        "return pu._gridnd(hermval, c,"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degree `deg` and sample points",
        "Returns the pseudo-Vandermonde matrix of degree `deg`"
    ],
    [
        "`x`. The pseudo-Vandermonde matrix is defined by",
        "`x`. The pseudo-Vandermonde matrix is"
    ],
    [
        ".. math:: V[..., i] = H_i(x),",
        ".. math:: V[..., i]"
    ],
    [
        "`x` and the last index is the degree of the Hermite polynomial.",
        "`x` and the last index is the degree of the"
    ],
    [
        "array ``V = hermvander(x, n)``, then ``np.dot(V, c)`` and",
        "array ``V = hermvander(x, n)``, then ``np.dot(V,"
    ],
    [
        "``hermval(x, c)`` are the same up to roundoff. This equivalence is",
        "``hermval(x, c)`` are the same up to roundoff. This"
    ],
    [
        "useful both for least squares fitting and for the evaluation of a large",
        "useful both for least squares fitting and for the evaluation of a"
    ],
    [
        "number of Hermite series of the same degree and sample points.",
        "number of Hermite series of the same degree"
    ],
    [
        "depending on whether any of the elements are complex. If `x` is",
        "depending on whether any of the elements"
    ],
    [
        "The pseudo-Vandermonde matrix. The shape of the returned matrix is",
        "The pseudo-Vandermonde matrix. The shape of the returned"
    ],
    [
        "corresponding Hermite polynomial.  The dtype will be the same as",
        "corresponding Hermite polynomial. The dtype will be"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg`"
    ],
    [
        "points ``(x, y)``. The pseudo-Vandermonde matrix is defined by",
        "points ``(x, y)``. The pseudo-Vandermonde"
    ],
    [
        "`V` index the points ``(x, y)`` and the last index encodes the degrees of",
        "`V` index the points ``(x, y)`` and the last index"
    ],
    [
        "up to roundoff. This equivalence is useful both for least squares",
        "up to roundoff. This equivalence is useful"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same degrees and sample"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes",
        "Arrays of point coordinates, all of the same shape. The"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg].",
        "List of maximum degrees of the form [x_deg,"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is ``x.shape + (order,)``,"
    ],
    [
        "as the converted `x` and `y`.",
        "as the converted `x` and"
    ],
    [
        "return pu._vander_nd_flat((hermvander, hermvander), (x, y), deg)",
        "return pu._vander_nd_flat((hermvander, hermvander), (x,"
    ],
    [
        "Returns the pseudo-Vandermonde matrix of degrees `deg` and sample",
        "Returns the pseudo-Vandermonde matrix of degrees `deg`"
    ],
    [
        "points ``(x, y, z)``. If `l`, `m`, `n` are the given degrees in `x`, `y`, `z`,",
        "points ``(x, y, z)``. If `l`, `m`, `n` are"
    ],
    [
        "then The pseudo-Vandermonde matrix is defined by",
        "then The pseudo-Vandermonde matrix is defined"
    ],
    [
        "indices of `V` index the points ``(x, y, z)`` and the last index encodes",
        "indices of `V` index the points ``(x,"
    ],
    [
        "the degrees of the Hermite polynomials.",
        "the degrees of the Hermite"
    ],
    [
        "same up to roundoff. This equivalence is useful both for least squares",
        "same up to roundoff. This equivalence is useful"
    ],
    [
        "series of the same degrees and sample points.",
        "series of the same"
    ],
    [
        "Arrays of point coordinates, all of the same shape. The dtypes will",
        "Arrays of point coordinates, all of"
    ],
    [
        "List of maximum degrees of the form [x_deg, y_deg, z_deg].",
        "List of maximum degrees of the form [x_deg, y_deg,"
    ],
    [
        "The shape of the returned matrix is ``x.shape + (order,)``, where",
        "The shape of the returned matrix is ``x.shape + (order,)``,"
    ],
    [
        "be the same as the converted `x`, `y`, and `z`.",
        "be the same as the"
    ],
    [
        "return pu._vander_nd_flat((hermvander, hermvander, hermvander), (x, y, z), deg)",
        "return pu._vander_nd_flat((hermvander, hermvander, hermvander),"
    ],
    [
        "def hermfit(x, y, deg, rcond=None, full=False, w=None):",
        "def hermfit(x, y, deg,"
    ],
    [
        "Least squares fit of Hermite series to data.",
        "Least squares fit of Hermite series"
    ],
    [
        "Return the coefficients of a Hermite series of degree `deg` that is the",
        "Return the coefficients of a Hermite series of degree `deg`"
    ],
    [
        "least squares fit to the data values `y` given at points `x`. If `y` is",
        "least squares fit to the data values `y` given at points `x`. If"
    ],
    [
        "fits are done, one for each column of `y`, and the resulting",
        "fits are done, one for each column of `y`, and the"
    ],
    [
        "The fitted polynomial(s) are in the form",
        "The fitted polynomial(s) are in"
    ],
    [
        "x-coordinates of the M sample points ``(x[i], y[i])``.",
        "x-coordinates of the M sample"
    ],
    [
        "y : array_like, shape (M,) or (M, K)",
        "y : array_like, shape (M,) or"
    ],
    [
        "y-coordinates of the sample points. Several data sets of sample",
        "y-coordinates of the sample points. Several data sets"
    ],
    [
        "points sharing the same x-coordinates can be fitted at once by",
        "points sharing the same x-coordinates can be"
    ],
    [
        "Degree(s) of the fitting polynomials. If `deg` is a single integer",
        "Degree(s) of the fitting polynomials. If `deg` is"
    ],
    [
        "all terms up to and including the `deg`'th term are included in the",
        "all terms up to and including the"
    ],
    [
        "degrees of the terms to include may be used instead.",
        "degrees of the terms to include may be"
    ],
    [
        "Relative condition number of the fit. Singular values smaller than",
        "Relative condition number of the"
    ],
    [
        "this relative to the largest singular value will be ignored. The",
        "this relative to the largest singular"
    ],
    [
        "default value is len(x)*eps, where eps is the relative precision of",
        "default value is len(x)*eps, where eps"
    ],
    [
        "Switch determining nature of return value. When it is False (the",
        "Switch determining nature of return value. When it"
    ],
    [
        "default) just the coefficients are returned, when True diagnostic",
        "default) just the coefficients are returned, when True"
    ],
    [
        "information from the singular value decomposition is also returned.",
        "information from the singular value decomposition is"
    ],
    [
        "w : array_like, shape (`M`,), optional",
        "w : array_like,"
    ],
    [
        "Weights. If not None, the weight ``w[i]`` applies to the unsquared",
        "Weights. If not None, the weight ``w[i]`` applies to the"
    ],
    [
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are",
        "residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the"
    ],
    [
        "chosen so that the errors of the products ``w[i]*y[i]`` all have the",
        "chosen so that the errors of the products"
    ],
    [
        "same variance.  When using inverse-variance weighting, use",
        "same variance. When using inverse-variance"
    ],
    [
        "coef : ndarray, shape (M,) or (M, K)",
        "coef : ndarray, shape (M,) or (M,"
    ],
    [
        "the coefficients for the data in column k  of `y` are in column",
        "the coefficients for the data in column k of `y` are"
    ],
    [
        "[residuals, rank, singular_values, rcond] : list",
        "[residuals, rank, singular_values, rcond] :"
    ],
    [
        "These values are only returned if ``full == True``",
        "These values are only returned"
    ],
    [
        "- residuals -- sum of squared residuals of the least squares fit",
        "- residuals -- sum of squared residuals of the least"
    ],
    [
        "- rank -- the numerical rank of the scaled Vandermonde matrix",
        "- rank -- the numerical rank of the scaled"
    ],
    [
        "- singular_values -- singular values of the scaled Vandermonde matrix",
        "- singular_values -- singular values of the"
    ],
    [
        "- rcond -- value of `rcond`.",
        "- rcond -- value"
    ],
    [
        "The rank of the coefficient matrix in the least-squares fit is",
        "The rank of the coefficient matrix in the least-squares fit"
    ],
    [
        "deficient. The warning is only raised if ``full == False``.  The",
        "deficient. The warning is only raised"
    ],
    [
        "warnings can be turned off by",
        "warnings can be"
    ],
    [
        "hermval : Evaluates a Hermite series.",
        "hermval : Evaluates"
    ],
    [
        "hermvander : Vandermonde matrix of Hermite series.",
        "hermvander : Vandermonde matrix of Hermite"
    ],
    [
        "numpy.linalg.lstsq : Computes a least-squares fit from the matrix.",
        "numpy.linalg.lstsq : Computes a least-squares"
    ],
    [
        "The solution is the coefficients of the Hermite series `p` that",
        "The solution is the coefficients of the"
    ],
    [
        "minimizes the sum of the weighted squared errors",
        "minimizes the sum of the weighted"
    ],
    [
        "where the :math:`w_j` are the weights. This problem is solved by",
        "where the :math:`w_j` are the weights. This"
    ],
    [
        "setting up the (typically) overdetermined matrix equation",
        "setting up the (typically) overdetermined"
    ],
    [
        ".. math:: V(x) * c = w * y,",
        ".. math:: V(x) * c"
    ],
    [
        "where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the",
        "where `V` is the weighted pseudo Vandermonde matrix of `x`,"
    ],
    [
        "coefficients to be solved for, `w` are the weights, `y` are the",
        "coefficients to be solved for, `w`"
    ],
    [
        "observed values.  This equation is then solved using the singular value",
        "observed values. This equation is then solved using"
    ],
    [
        "If some of the singular values of `V` are so small that they are",
        "If some of the singular values of `V` are so small that they"
    ],
    [
        "neglected, then a `~exceptions.RankWarning` will be issued. This means that",
        "neglected, then a `~exceptions.RankWarning` will"
    ],
    [
        "the coefficient values may be poorly determined. Using a lower order fit",
        "the coefficient values may be poorly"
    ],
    [
        "will usually get rid of the warning.  The `rcond` parameter can also be",
        "will usually get rid of the warning."
    ],
    [
        "set to a value smaller than its default, but the resulting fit may be",
        "set to a value smaller than its default,"
    ],
    [
        "spurious and have large contributions from roundoff error.",
        "spurious and have large contributions from roundoff"
    ],
    [
        "Fits using Hermite series are probably most useful when the data can be",
        "Fits using Hermite series are probably most useful when the data can"
    ],
    [
        "approximated by ``sqrt(w(x)) * p(x)``, where ``w(x)`` is the Hermite",
        "approximated by ``sqrt(w(x)) * p(x)``, where ``w(x)``"
    ],
    [
        "weight. In that case the weight ``sqrt(w(x[i]))`` should be used",
        "weight. In that case the weight ``sqrt(w(x[i]))`` should be"
    ],
    [
        "together with data values ``y[i]/sqrt(w(x[i]))``. The weight function is",
        "together with data values ``y[i]/sqrt(w(x[i]))``. The"
    ],
    [
        ">>> from numpy.polynomial.hermite import hermfit, hermval",
        ">>> from numpy.polynomial.hermite import"
    ],
    [
        "return pu._fit(hermvander, x, y, deg, rcond, full, w)",
        "return pu._fit(hermvander, x, y, deg, rcond,"
    ],
    [
        "\"\"\"Return the scaled companion matrix of c.",
        "\"\"\"Return the scaled companion matrix"
    ],
    [
        "The basis polynomials are scaled so that the companion matrix is",
        "The basis polynomials are scaled so that the companion"
    ],
    [
        "symmetric when `c` is an Hermite basis polynomial. This provides",
        "symmetric when `c` is an Hermite basis polynomial."
    ],
    [
        "better eigenvalue estimates than the unscaled case and for basis",
        "better eigenvalue estimates than the unscaled case and for"
    ],
    [
        "polynomials the eigenvalues are guaranteed to be real if",
        "polynomials the eigenvalues are guaranteed to be"
    ],
    [
        "`numpy.linalg.eigvalsh` is used to obtain them.",
        "`numpy.linalg.eigvalsh` is used to obtain"
    ],
    [
        "Scaled companion matrix of dimensions (deg, deg).",
        "Scaled companion matrix of"
    ],
    [
        "Compute the roots of a Hermite series.",
        "Compute the roots of"
    ],
    [
        "Return the roots (a.k.a. \"zeros\") of the polynomial",
        "Return the roots (a.k.a. \"zeros\")"
    ],
    [
        ".. math:: p(x) = \\\\sum_i c[i] * H_i(x).",
        ".. math:: p(x) ="
    ],
    [
        "Array of the roots of the series. If all the roots are real,",
        "Array of the roots of the series."
    ],
    [
        "then `out` is also real, otherwise it is complex.",
        "then `out` is also real,"
    ],
    [
        "The root estimates are obtained as the eigenvalues of the companion",
        "The root estimates are obtained as the eigenvalues"
    ],
    [
        "matrix, Roots far from the origin of the complex plane may have large",
        "matrix, Roots far from the origin of the complex plane"
    ],
    [
        "errors due to the numerical instability of the series for such",
        "errors due to the numerical instability of the series for"
    ],
    [
        "errors as the value of the series near such points is relatively",
        "errors as the value of the series near such points"
    ],
    [
        "insensitive to errors in the roots. Isolated roots near the origin can",
        "insensitive to errors in the roots."
    ],
    [
        "be improved by a few iterations of Newton's method.",
        "be improved by a few iterations of"
    ],
    [
        "The Hermite series basis polynomials aren't powers of `x` so the",
        "The Hermite series basis polynomials aren't"
    ],
    [
        "results of this function may seem unintuitive.",
        "results of this function may seem"
    ],
    [
        ">>> from numpy.polynomial.hermite import hermroots, hermfromroots",
        ">>> from numpy.polynomial.hermite import"
    ],
    [
        "Compute the value of the normalized Hermite polynomial of degree ``n``",
        "Compute the value of the normalized"
    ],
    [
        "Points at which to evaluate the function",
        "Points at which to evaluate the"
    ],
    [
        "Degree of the normalized Hermite function to be evaluated.",
        "Degree of the normalized Hermite function to"
    ],
    [
        "The shape of the return value is described above.",
        "The shape of the return value is"
    ],
    [
        "This function is needed for finding the Gauss points and integration",
        "This function is needed for finding the Gauss points"
    ],
    [
        "weights for high degrees. The values of the standard Hermite functions",
        "weights for high degrees. The values"
    ],
    [
        "Computes the sample points and weights for Gauss-Hermite quadrature.",
        "Computes the sample points and weights for"
    ],
    [
        "These sample points and weights will correctly integrate polynomials of",
        "These sample points and weights"
    ],
    [
        "be problematic. The weights are determined by using the fact that",
        "be problematic. The weights are determined by using the fact"
    ],
    [
        "where :math:`c` is a constant independent of :math:`k` and :math:`x_k`",
        "where :math:`c` is a constant"
    ],
    [
        "is the k'th root of :math:`H_n`, and then scaling the results to get",
        "is the k'th root of :math:`H_n`, and then scaling the"
    ],
    [
        "raise ValueError(\"deg must be a positive integer\")",
        "raise ValueError(\"deg must be a"
    ],
    [
        "Weight function of the Hermite polynomials.",
        "Weight function of the"
    ],
    [
        "integration is :math:`[-\\\\inf, \\\\inf]`. the Hermite polynomials are",
        "integration is :math:`[-\\\\inf, \\\\inf]`. the"
    ],
    [
        "orthogonal, but not normalized, with respect to this weight function.",
        "orthogonal, but not normalized, with respect to"
    ],
    [
        "Values at which the weight function will be computed.",
        "Values at which the weight"
    ],
    [
        "The Hermite class provides the standard Python numerical methods",
        "The Hermite class provides the"
    ],
    [
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as the",
        "'+', '-', '*', '//', '%', 'divmod', '**', and '()' as well as"
    ],
    [
        "Hermite coefficients in order of increasing degree, i.e,",
        "Hermite coefficients in order of increasing"
    ],
    [
        "Symbol used to represent the independent variable in string",
        "Symbol used to represent the independent variable"
    ],
    [
        "representations of the polynomial expression, e.g. for printing.",
        "representations of the polynomial expression, e.g. for"
    ],
    [
        "The symbol must be a valid Python identifier. Default value is 'x'.",
        "The symbol must be a valid"
    ],
    [
        "y = [polyval(x, c) for c in Tlist]",
        "y = [polyval(x, c) for"
    ],
    [
        "vv = np.dot(v.T * w, v)",
        "vv = np.dot(v.T *"
    ],
    [
        "vv = vd[:, None] * vv * vd",
        "vv = vd[:, None] * vv"
    ],
    [
        "y = [polyval(x, c) for c in Helist]",
        "y = [polyval(x, c) for c"
    ],
    [
        "vv = np.dot(v.T * w, v)",
        "vv = np.dot(v.T *"
    ],
    [
        "vv = vd[:, None] * vv * vd",
        "vv = vd[:, None] * vv"
    ],
    [
        "p = poly.Polynomial([f, f], domain=[zero, one], window=[zero, one])",
        "p = poly.Polynomial([f, f],"
    ],
    [
        "tgt[ii, jj, :] = poly.polyvalfromroots(x[jj], r[:, ii])",
        "tgt[ii, jj, :] = poly.polyvalfromroots(x[jj], r[:,"
    ],
    [
        "y = [polyval(x, c) for c in Llist]",
        "y = [polyval(x, c)"
    ],
    [
        "vv = np.dot(v.T * w, v)",
        "vv = np.dot(v.T *"
    ],
    [
        "vv = vd[:, None] * vv * vd",
        "vv = vd[:, None] * vv"
    ],
    [
        "y = [polyval(x, c) for c in Llist]",
        "y = [polyval(x, c) for c in"
    ],
    [
        "vv = np.dot(v.T * w, v)",
        "vv = np.dot(v.T"
    ],
    [
        "vv = vd[:, None] * vv * vd",
        "vv = vd[:, None] * vv"
    ],
    [
        "from numpy._core import array, arange, printoptions",
        "from numpy._core import array, arange,"
    ],
    [
        "\"\"\"Test both numpy and built-in complex.\"\"\"",
        "\"\"\"Test both numpy"
    ],
    [
        "Test coef fallback for object arrays of non-numeric coefficients.",
        "Test coef fallback for object"
    ],
    [
        "\"\"\"Test the latex repr used by Jupyter\"\"\"",
        "\"\"\"Test the latex repr used"
    ],
    [
        "obj._repr_latex_scalar = lambda x, parens=False: str(x)",
        "obj._repr_latex_scalar = lambda x, parens=False:"
    ],
    [
        "Test the output is properly configured via printoptions.",
        "Test the output is properly"
    ],
    [
        "The exponential notation is enabled automatically when the values",
        "The exponential notation is enabled automatically"
    ],
    [
        "are too small or too large.",
        "are too small"
    ],
    [
        "assert str(p).replace('\\n', ' ') == s",
        "assert str(p).replace('\\n', ' ') =="
    ],
    [
        "assert str(p) == 'nan + inf x'",
        "assert str(p) == 'nan + inf"
    ],
    [
        "assert p._repr_latex_() == r'$x \\mapsto \\text{nan} + \\text{inf}\\,x$'",
        "assert p._repr_latex_() == r'$x"
    ],
    [
        "assert str(p) == 'NAN + INF x'",
        "assert str(p) == 'NAN + INF"
    ],
    [
        "y = [polyval(x, c) for c in Hlist]",
        "y = [polyval(x, c)"
    ],
    [
        "vv = np.dot(v.T * w, v)",
        "vv = np.dot(v.T"
    ],
    [
        "vv = vd[:, None] * vv * vd",
        "vv = vd[:, None] * vv *"
    ],
    [
        "\"\"\"Test inter-conversion of different polynomial classes.",
        "\"\"\"Test inter-conversion of different polynomial"
    ],
    [
        "This tests the convert and cast methods of all the polynomial classes.",
        "This tests the convert and cast methods of all the"
    ],
    [
        "Polynomial, Legendre, Chebyshev, Laguerre, Hermite, HermiteE)",
        "Polynomial, Legendre, Chebyshev, Laguerre,"
    ],
    [
        "classids = tuple(cls.__name__ for cls in classes)",
        "classids = tuple(cls.__name__ for cls in"
    ],
    [
        "if not issubclass(stype, Number) or issubclass(stype, bool):",
        "if not issubclass(stype, Number) or"
    ],
    [
        "Tests related to the ``symbol`` attribute of the ABCPolyBase class.",
        "Tests related to the ``symbol`` attribute"
    ],
    [
        "from numpy.testing import assert_equal, assert_raises, assert_",
        "from numpy.testing import"
    ],
    [
        "Test polynomial creation with symbol kwarg.",
        "Test polynomial creation with"
    ],
    [
        "Values for symbol that should pass input validation.",
        "Values for symbol that"
    ],
    [
        "Ensure symbol is preserved for numeric operations on polynomials with",
        "Ensure symbol is preserved for"
    ],
    [
        "ops = (p.__add__, p.__sub__, p.__mul__, p.__floordiv__, p.__mod__)",
        "ops = (p.__add__, p.__sub__, p.__mul__, p.__floordiv__,"
    ],
    [
        "Test other methods for manipulating/creating polynomial objects.",
        "Test other methods for"
    ],
    [
        "\"\"\"Import a file directly, avoiding importing scipy\"\"\"",
        "\"\"\"Import a file directly, avoiding importing"
    ],
    [
        "res = run(['gcc', '-v'], check=True, text=True, capture_output=True)",
        "res = run(['gcc', '-v'], check=True,"
    ],
    [
        "\"\"\"Process tempita templated file and write out the result.",
        "\"\"\"Process tempita templated file and write out the"
    ],
    [
        "The template file is expected to end in `.c.in` or `.pyx.in`:",
        "The template file is expected to end"
    ],
    [
        "help=\"An ignored input - may be useful to add a \"",
        "help=\"An ignored input - may be useful to add"
    ],
    [
        "line for line in data if line.startswith('version =')",
        "line for line in data"
    ],
    [
        "parser.add_argument('--write', help=\"Save version to this file\")",
        "parser.add_argument('--write', help=\"Save version to"
    ],
    [
        "help='Output path is relative to MESON_DIST_ROOT',",
        "help='Output path is"
    ],
    [
        "Module to expose more detailed version info for the installed `numpy`",
        "Module to expose more detailed version"
    ],
    [
        "release = 'dev' not in version and '+' not in version",
        "release = 'dev' not in version"
    ],
    [
        "\"\"\"Process tempita templated file and write out the result.",
        "\"\"\"Process tempita templated file and write out"
    ],
    [
        "The template file is expected to end in `.src`",
        "The template file is expected"
    ],
    [
        "help=\"An ignored input - may be useful to add a \"",
        "help=\"An ignored input - may be useful"
    ],
    [
        "Helper for looping over sequences, particular in templates.",
        "Helper for looping over sequences,"
    ],
    [
        "Often in a loop in a template it's handy to know what's next up,",
        "Often in a loop in a template"
    ],
    [
        "previously up, if this is the first or last item in the sequence, etc.",
        "previously up, if this is the first or last"
    ],
    [
        "These can be awkward to manage in a normal Python loop, but using the",
        "These can be awkward to manage in a normal Python"
    ],
    [
        "looper you can get a better sense of the context.  Use like::",
        "looper you can get a better sense of the"
    ],
    [
        ">>> for loop, item in looper(['a', 'b', 'c']):",
        ">>> for loop, item"
    ],
    [
        "Helper for looping (particularly in templates)",
        "Helper for looping"
    ],
    [
        "return '<%s for %r>' % (",
        "return '<%s for"
    ],
    [
        "return '<loop pos=%r at %r>' % (",
        "return '<loop pos=%r at %r>'"
    ],
    [
        "Returns true if this item is the start of a new group,",
        "Returns true if this item is"
    ],
    [
        "where groups mean that some attribute has changed.  The getter",
        "where groups mean that some attribute has changed. The"
    ],
    [
        "can be None (the item itself changes), an attribute name like",
        "can be None (the item itself changes), an"
    ],
    [
        "``'.attr'``, a function, or a dict key or list index.",
        "``'.attr'``, a function, or a dict key or"
    ],
    [
        "Returns true if this item is the end of a new group,",
        "Returns true if this item is the end of a new"
    ],
    [
        "where groups mean that some attribute has changed.  The getter",
        "where groups mean that some attribute"
    ],
    [
        "can be None (the item itself changes), an attribute name like",
        "can be None (the item itself changes),"
    ],
    [
        "``'.attr'``, a function, or a dict key or list index.",
        "``'.attr'``, a function, or a dict key or list"
    ],
    [
        "return getattr(item, getter)() != getattr(other, getter)()",
        "return getattr(item, getter)() !="
    ],
    [
        "return getattr(item, getter) != getattr(other, getter)",
        "return getattr(item, getter) != getattr(other,"
    ],
    [
        "This implements a small templating language.  This language implements",
        "This implements a small templating"
    ],
    [
        "if/elif/else, for/continue/break, expressions, and blocks of Python",
        "if/elif/else, for/continue/break, expressions, and"
    ],
    [
        "You use this with the ``Template`` class or the ``sub`` shortcut.",
        "You use this with the ``Template``"
    ],
    [
        "The ``Template`` class takes the template string and the name of",
        "The ``Template`` class takes the template string and the name"
    ],
    [
        "the template (for errors) and a default namespace.  Then (like",
        "the template (for errors) and a default namespace. Then"
    ],
    [
        "``string.Template``) you can call the ``tmpl.substitute(**kw)``",
        "``string.Template``) you can call"
    ],
    [
        "method to make a substitution (or ``tmpl.substitute(a_dict)``).",
        "method to make a"
    ],
    [
        "``sub(content, **kw)`` substitutes the template immediately.  You",
        "``sub(content, **kw)`` substitutes the template"
    ],
    [
        "can use ``__name='tmpl.html'`` to set the name of the template.",
        "can use ``__name='tmpl.html'`` to set the name of the"
    ],
    [
        "If there are syntax errors ``TemplateError`` will be raised.",
        "If there are syntax errors ``TemplateError`` will"
    ],
    [
        "__all__ = [\"TemplateError\", \"Template\", \"sub\", \"bunch\"]",
        "__all__ = [\"TemplateError\", \"Template\","
    ],
    [
        "\"\"\"Exception raised while parsing a template\"\"\"",
        "\"\"\"Exception raised while"
    ],
    [
        "msg += \" in %s\" % self.name",
        "msg += \" in %s\""
    ],
    [
        "if name is None and stacklevel is not None:",
        "if name is None and"
    ],
    [
        "return \"<%s %s name=%r>\" % (",
        "return \"<%s %s name=%r>\" %"
    ],
    [
        "raise TypeError(\"You can only give positional *or* keyword arguments\")",
        "raise TypeError(\"You can only give"
    ],
    [
        "raise TypeError(\"You can only give one positional argument\")",
        "raise TypeError(\"You can only give one positional"
    ],
    [
        "\"If you pass in a single argument, you must pass in a \"",
        "\"If you pass in a single argument, you must pass in"
    ],
    [
        "\"dictionary-like object (with a .items() method); you gave %r\"",
        "\"dictionary-like object (with a .items() method); you"
    ],
    [
        "result = self._interpret_inherit(result, defs, inherit, ns)",
        "result = self._interpret_inherit(result,"
    ],
    [
        "def _interpret_inherit(self, body, defs, inherit_template, ns):",
        "def _interpret_inherit(self, body, defs, inherit_template,"
    ],
    [
        "\"You cannot use inheritance without passing in get_template\",",
        "\"You cannot use inheritance without passing in"
    ],
    [
        "def _interpret_codes(self, codes, ns, out, defs):",
        "def _interpret_codes(self, codes, ns, out,"
    ],
    [
        "def _interpret_code(self, code, ns, out, defs):",
        "def _interpret_code(self, code, ns, out,"
    ],
    [
        "self._interpret_for(vars, expr, content, ns, out, defs)",
        "self._interpret_for(vars, expr, content,"
    ],
    [
        "self, name, signature, body=parts, ns=ns, pos=pos",
        "self, name, signature, body=parts, ns=ns,"
    ],
    [
        "def _interpret_for(self, vars, expr, content, ns, out, defs):",
        "def _interpret_for(self, vars, expr,"
    ],
    [
        "\"Need %i items to unpack (got %i items)\"",
        "\"Need %i items to unpack (got %i"
    ],
    [
        "for name, value in zip(vars, item):",
        "for name, value"
    ],
    [
        "def _interpret_if(self, parts, ns, out, defs):",
        "def _interpret_if(self, parts, ns,"
    ],
    [
        "raise SyntaxError(\"invalid syntax in expression: %s\" % code)",
        "raise SyntaxError(\"invalid syntax in expression: %s\""
    ],
    [
        "\"Cannot decode bytes value %r into unicode \"",
        "\"Cannot decode bytes value %r into unicode"
    ],
    [
        "e.reason + \" in string %r\" % value,",
        "e.reason + \" in string"
    ],
    [
        "elif not self._unicode and isinstance(value, str):",
        "elif not self._unicode and"
    ],
    [
        "\"Cannot encode unicode value %r into bytes \"",
        "\"Cannot encode unicode value %r into bytes"
    ],
    [
        "msg += \" in file %s\" % self.name",
        "msg += \" in"
    ],
    [
        "\" \".join([\"%s=%r\" % (k, v) for k, v in sorted(self.items())]),",
        "\" \".join([\"%s=%r\" % (k, v) for"
    ],
    [
        "self, template, func_name, func_signature, body, ns, pos, bound_self=None",
        "self, template, func_name, func_signature, body, ns,"
    ],
    [
        "return \"<tempita function %s(%s) at %s:%s>\" % (",
        "return \"<tempita function %s(%s) at"
    ],
    [
        "sig_args, var_args, var_kw, defaults = self._func_signature",
        "sig_args, var_args, var_kw, defaults ="
    ],
    [
        "if not var_kw and name not in sig_args:",
        "if not var_kw and name not"
    ],
    [
        "raise TypeError(\"Unexpected argument %s\" % name)",
        "raise TypeError(\"Unexpected argument"
    ],
    [
        "\"Extra position arguments: %s\" % \", \".join([repr(v) for v in args])",
        "\"Extra position arguments: %s\" % \", \".join([repr(v) for v"
    ],
    [
        "raise TypeError(\"Missing argument: %s\" % name)",
        "raise TypeError(\"Missing argument: %s\""
    ],
    [
        "return \"<%s %s>\" % (self.__class__.__name__, self.__name)",
        "return \"<%s %s>\" %"
    ],
    [
        "return \"<%s around %r>\" % (self.__class__.__name__, self.__template_obj)",
        "return \"<%s around %r>\" %"
    ],
    [
        "pos = find_position(s, match.end(), last, last_pos)",
        "pos = find_position(s, match.end(), last,"
    ],
    [
        "statement_re = re.compile(r\"^(?:if |elif |for |def |inherit |default |py:)\")",
        "statement_re = re.compile(r\"^(?:if |elif |for"
    ],
    [
        "single_statements = [\"else\", \"endif\", \"endfor\", \"enddef\", \"continue\", \"break\"]",
        "single_statements = [\"else\", \"endif\", \"endfor\", \"enddef\", \"continue\","
    ],
    [
        "Takes a lexed set of tokens, and removes whitespace when there is",
        "Takes a lexed set of tokens, and removes whitespace when there"
    ],
    [
        "a directive on a line by itself:",
        "a directive on a"
    ],
    [
        ">>> tokens = lex('{{if x}}\\nx\\n{{endif}}\\ny', trim_whitespace=False)",
        ">>> tokens = lex('{{if"
    ],
    [
        "if not statement_re.search(item) and item not in single_statements:",
        "if not statement_re.search(item) and item not in"
    ],
    [
        "if not isinstance(next_chunk, basestring_) or not isinstance(prev, basestring_):",
        "if not isinstance(next_chunk, basestring_) or not"
    ],
    [
        "prev_ok = not prev or trail_whitespace_re.search(prev)",
        "prev_ok = not"
    ],
    [
        "\"\"\"Given a string and index, return (line, column)\"\"\"",
        "\"\"\"Given a string and index, return (line,"
    ],
    [
        "column = index - string.rfind(\"\\n\", last_index, index)",
        "column = index - string.rfind(\"\\n\", last_index,"
    ],
    [
        "Parses a string into a kind of AST",
        "Parses a string into"
    ],
    [
        ">>> parse('{{for x, y in z:}}{{continue}}{{endfor}}')",
        ">>> parse('{{for x,"
    ],
    [
        ">>> parse('{{if x}}{{for x in y}}{{endif}}{{endfor}}')",
        ">>> parse('{{if x}}{{for"
    ],
    [
        "tokens = lex(s, name=name, line_offset=line_offset, delimiters=delimiters)",
        "tokens = lex(s,"
    ],
    [
        "\"Multi-line py blocks must start with a newline\",",
        "\"Multi-line py blocks must"
    ],
    [
        "raise TemplateError(\"continue outside of for loop\", position=pos, name=name)",
        "raise TemplateError(\"continue outside of for"
    ],
    [
        "elif expr.startswith(\"elif \") or expr == \"else\":",
        "elif expr.startswith(\"elif \") or expr =="
    ],
    [
        "elif expr in (\"if\", \"elif\", \"for\"):",
        "elif expr in (\"if\","
    ],
    [
        "raise TemplateError(\"%s with no expression\" % expr, position=pos, name=name)",
        "raise TemplateError(\"%s with no expression\" %"
    ],
    [
        "elif expr in (\"endif\", \"endfor\", \"enddef\"):",
        "elif expr in (\"endif\","
    ],
    [
        "raise TemplateError(\"Unexpected %s\" % expr, position=pos, name=name)",
        "raise TemplateError(\"Unexpected %s\" %"
    ],
    [
        "next_chunk, tokens = parse_one_cond(tokens, name, context)",
        "next_chunk, tokens ="
    ],
    [
        "part = (\"else\", pos, None, content)",
        "part = (\"else\", pos,"
    ],
    [
        "next_chunk, tokens = parse_expr(tokens, name, context)",
        "next_chunk, tokens ="
    ],
    [
        "raise TemplateError('Bad for (no \"in\") in %r' % first, position=pos, name=name)",
        "raise TemplateError('Bad for (no \"in\") in %r' % first,"
    ],
    [
        "\"You cannot have () in the variable section of a for loop (%r)\" % vars,",
        "\"You cannot have () in the variable section of a for loop (%r)\""
    ],
    [
        "vars = tuple(v.strip() for v in first[: match.start()].split(\",\") if v.strip())",
        "vars = tuple(v.strip() for v in first[: match.start()].split(\",\") if"
    ],
    [
        "next_chunk, tokens = parse_expr(tokens, name, context)",
        "next_chunk, tokens ="
    ],
    [
        "\"Expression must be {{default var=value}}; no = found in %r\" % first,",
        "\"Expression must be {{default var=value}}; no = found in"
    ],
    [
        "\"{{default x, y = ...}} is not supported\", position=pos, name=name",
        "\"{{default x, y = ...}} is not supported\", position=pos,"
    ],
    [
        "\"Not a valid variable name for {{default}}: %r\" % var,",
        "\"Not a valid variable name"
    ],
    [
        "sig = ((), None, None, {})",
        "sig = ((),"
    ],
    [
        "\"Function definition doesn't end with ): %s\" % first,",
        "\"Function definition doesn't end with ): %s\" %"
    ],
    [
        "next_chunk, tokens = parse_expr(tokens, name, context)",
        "next_chunk, tokens = parse_expr(tokens,"
    ],
    [
        "tok_type, tok_string, (srow, scol), (erow, ecol), line = next(tokens)",
        "tok_type, tok_string, (srow, scol), (erow, ecol),"
    ],
    [
        "return tok_type, tok_string, (srow, scol), (erow, ecol)",
        "return tok_type, tok_string, (srow,"
    ],
    [
        "if tok_type == tokenize.OP and (tok_string == \"*\" or tok_string == \"**\"):",
        "if tok_type == tokenize.OP and (tok_string == \"*\""
    ],
    [
        "\"Invalid signature: (%s)\" % sig_text, position=pos, name=name",
        "\"Invalid signature: (%s)\" % sig_text, position=pos,"
    ],
    [
        "if tok_type == tokenize.ENDMARKER or (",
        "if tok_type =="
    ],
    [
        "tok_type == tokenize.OP and tok_string == \",\"",
        "tok_type == tokenize.OP and tok_string =="
    ],
    [
        "\"Invalid signature: (%s)\" % sig_text, position=pos, name=name",
        "\"Invalid signature: (%s)\" % sig_text,"
    ],
    [
        "if tok_type == tokenize.OP and tok_string == \"=\":",
        "if tok_type == tokenize.OP and tok_string =="
    ],
    [
        "tok_type, tok_string, s, e = get_token(True)",
        "tok_type, tok_string, s, e ="
    ],
    [
        "if tok_type == tokenize.ENDMARKER and nest_count:",
        "if tok_type == tokenize.ENDMARKER and"
    ],
    [
        "\"Invalid signature: (%s)\" % sig_text, position=pos, name=name",
        "\"Invalid signature: (%s)\" % sig_text, position=pos,"
    ],
    [
        "or (tok_type == tokenize.OP and tok_string == \",\")",
        "or (tok_type == tokenize.OP"
    ],
    [
        "if nest_count and tok_type == tokenize.OP and tok_string == nest_type:",
        "if nest_count and tok_type == tokenize.OP and tok_string"
    ],
    [
        "nest_count and tok_type == tokenize.OP and tok_string == unnest_type",
        "nest_count and tok_type == tokenize.OP and tok_string =="
    ],
    [
        "and tok_string in (\"(\", \"[\", \"{\")",
        "and tok_string in (\"(\", \"[\","
    ],
    [
        "unnest_type = {\"(\": \")\", \"[\": \"]\", \"{\": \"}\"}[nest_type]",
        "unnest_type = {\"(\": \")\", \"[\": \"]\", \"{\":"
    ],
    [
        "Use py:arg=value to set a Python value; otherwise all values are",
        "Use py:arg=value to set a Python value; otherwise"
    ],
    [
        "help=\"File to write output to (default stdout)\",",
        "help=\"File to write output to"
    ],
    [
        "help=\"Put the environment in as top-level variables\",",
        "help=\"Put the environment in as top-level"
    ],
    [
        "print(\"You must give a template filename\")",
        "print(\"You must give a template"
    ],
    [
        "This file is used by asv_compare.conf.json.tpl.",
        "This file is used by"
    ],
    [
        "if \"no such option\" in output:",
        "if \"no such option\""
    ],
    [
        "UFUNCS = [obj for obj in np._core.umath.__dict__.values() if",
        "UFUNCS = [obj for obj in"
    ],
    [
        "UFUNCS_UNARY = [uf for uf in UFUNCS if \"O->O\" in uf.types]",
        "UFUNCS_UNARY = [uf for uf in"
    ],
    [
        "if ufunc_insig + dtype not in ufunc.types:",
        "if ufunc_insig + dtype"
    ],
    [
        "test = [sig for sig in ufunc.types if sig.startswith(st_sig)]",
        "test = [sig for sig in ufunc.types if"
    ],
    [
        "param_names = ['ufunc', 'stride_in', 'stride_out', 'dtype']",
        "param_names = ['ufunc', 'stride_in',"
    ],
    [
        "def setup(self, ufunc, stride_in, stride_out, dtype):",
        "def setup(self, ufunc, stride_in, stride_out,"
    ],
    [
        "if ufunc_insig + dtype not in ufunc.types:",
        "if ufunc_insig + dtype not in"
    ],
    [
        "test = [sig for sig in ufunc.types if sig.startswith(ufunc_insig)]",
        "test = [sig for sig in"
    ],
    [
        "def time_unary(self, ufunc, stride_in, stride_out, dtype):",
        "def time_unary(self, ufunc, stride_in,"
    ],
    [
        "params = [[uf for uf in UFUNCS_UNARY",
        "params = [[uf for uf"
    ],
    [
        "if uf not in (np.invert, np.bitwise_count)],",
        "if uf not in (np.invert,"
    ],
    [
        "def setup(self, ufunc, stride_in, stride_out, dtype):",
        "def setup(self, ufunc,"
    ],
    [
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L', 'q', 'Q']",
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L',"
    ],
    [
        "[getattr(np, uf) for uf in (",
        "[getattr(np, uf) for"
    ],
    [
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L', 'q', 'Q']",
        "['b', 'B', 'h', 'H', 'i',"
    ],
    [
        "[getattr(np, uf) for uf in (",
        "[getattr(np, uf) for"
    ],
    [
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L', 'q', 'Q']",
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L',"
    ],
    [
        "def mandelbrot_set(self, xmin, xmax, ymin, ymax, width, height, maxiter):",
        "def mandelbrot_set(self, xmin, xmax, ymin, ymax,"
    ],
    [
        "self.W = self.W - self.alpha * dw",
        "self.W = self.W -"
    ],
    [
        "param_names = ['size', 'ndims', 'ind', 'ndtype']",
        "param_names = ['size', 'ndims', 'ind',"
    ],
    [
        "def setup(self, size, ndims, ind, ndtype):",
        "def setup(self, size,"
    ],
    [
        "def time_meshgrid(self, size, ndims, ind, ndtype):",
        "def time_meshgrid(self, size,"
    ],
    [
        "func = {'inplace': num_inplace, 'normal': num_update}[update]",
        "func = {'inplace': num_inplace, 'normal':"
    ],
    [
        "A magical feature score for each feature in each dataset",
        "A magical feature score for each"
    ],
    [
        "If arrays are column-wise zscore-d before computation it",
        "If arrays are column-wise zscore-d before"
    ],
    [
        "results in characterizing each column in each array with",
        "results in characterizing each column"
    ],
    [
        "sum of maximal correlations of that column with columns",
        "sum of maximal correlations of"
    ],
    [
        "Arrays must agree only on the first dimension.",
        "Arrays must agree only on the"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func, types, args,"
    ],
    [
        "Returns an array that's in descending order.",
        "Returns an array that's in descending"
    ],
    [
        "raise SkipNotImplemented(\"Cannot construct arange for this size.\")",
        "raise SkipNotImplemented(\"Cannot construct arange for"
    ],
    [
        "Returns an array that has the same value everywhere.",
        "Returns an array that has the same value"
    ],
    [
        "Returns an array with blocks that are all sorted.",
        "Returns an array with blocks that are"
    ],
    [
        "This benchmark tests sorting performance with several",
        "This benchmark tests sorting"
    ],
    [
        "different types of arrays that are likely to appear in",
        "different types of arrays that are likely to"
    ],
    [
        "info = \"NumPy CPU features: \" + (info if info else 'nothing enabled')",
        "info = \"NumPy CPU features: \" +"
    ],
    [
        "if not ppid or ppid == os.getpid():",
        "if not ppid or ppid =="
    ],
    [
        "\"\"\" Test overhead of linalg methods for small arrays \"\"\"",
        "\"\"\" Test overhead of linalg"
    ],
    [
        "params = [float(x) for x in items]",
        "params = [float(x) for x in"
    ],
    [
        "CACHE_ROOT = Path(__file__).resolve().parent.parent / 'env' / 'numpy_benchdata'",
        "CACHE_ROOT = Path(__file__).resolve().parent.parent / 'env'"
    ],
    [
        "Generates a cached random array that covers several scenarios that",
        "Generates a cached random array that covers several scenarios"
    ],
    [
        "may affect the benchmark for fairness and to stabilize the benchmark.",
        "may affect the benchmark for fairness and to stabilize"
    ],
    [
        "Input number, to avoid memory overload",
        "Input number, to avoid memory"
    ],
    [
        "and to provide unique data for each operand.",
        "and to provide unique data"
    ],
    [
        "Spreading zeros along with generated data.",
        "Spreading zeros along with"
    ],
    [
        "Avoid spreading fp special cases nan/inf.",
        "Avoid spreading fp special cases"
    ],
    [
        "Spreading subnormal numbers along with generated data.",
        "Spreading subnormal numbers along with"
    ],
    [
        "params = [['ravel', 'transpose', 'compressed', 'conjugate'],",
        "params = [['ravel', 'transpose', 'compressed',"
    ],
    [
        "self.small = np.ma.array(data, mask=(data <= prop_mask))",
        "self.small = np.ma.array(data, mask=(data <="
    ],
    [
        "self.large = np.ma.array(data, mask=(data <= prop_mask))",
        "self.large = np.ma.array(data, mask=(data <="
    ],
    [
        "self.small = np.ma.array(data, mask=(data <= prop_mask))",
        "self.small = np.ma.array(data, mask=(data <="
    ],
    [
        "self.large = np.ma.array(data, mask=(data <= prop_mask))",
        "self.large = np.ma.array(data, mask=(data"
    ],
    [
        "['==', '!=', '<', '<=', '>', '>=']]",
        "['==', '!=', '<', '<=', '>',"
    ],
    [
        "param_names = ['shape', 'dtype', 'contig', 'operator']",
        "param_names = ['shape', 'dtype', 'contig',"
    ],
    [
        "def setup(self, shape, dtype, contig, operator):",
        "def setup(self, shape,"
    ],
    [
        "def time_compare_identical(self, shape, dtype, contig, operator):",
        "def time_compare_identical(self, shape, dtype,"
    ],
    [
        "def time_compare_different(self, shape, dtype, contig, operator):",
        "def time_compare_different(self, shape, dtype, contig,"
    ],
    [
        "res = n + n + n + n + n + n + n + n + n + n",
        "res = n + n + n + n + n + n + n + n + n"
    ],
    [
        "res = n * n * n * n * n * n * n * n * n * n",
        "res = n * n * n * n * n * n"
    ],
    [
        "res = [str(x) for x in self.a]",
        "res = [str(x) for x"
    ],
    [
        "[np.full(shape=[s // n_chunk for s, n_chunk in zip(shape, n_chunks)],",
        "[np.full(shape=[s // n_chunk for s, n_chunk in"
    ],
    [
        "\"\"\"Benchmarks for Kronecker product of two arrays\"\"\"",
        "\"\"\"Benchmarks for Kronecker product of two"
    ],
    [
        "ufuncs = ['abs', 'absolute', 'add', 'arccos', 'arccosh', 'arcsin', 'arcsinh',",
        "ufuncs = ['abs', 'absolute', 'add', 'arccos', 'arccosh', 'arcsin',"
    ],
    [
        "'bitwise_or', 'bitwise_xor', 'cbrt', 'ceil', 'conj', 'conjugate',",
        "'bitwise_or', 'bitwise_xor', 'cbrt',"
    ],
    [
        "'floor_divide', 'fmax', 'fmin', 'fmod', 'frexp', 'gcd', 'greater',",
        "'floor_divide', 'fmax', 'fmin', 'fmod',"
    ],
    [
        "'isinf', 'isnan', 'isnat', 'lcm', 'ldexp', 'left_shift', 'less',",
        "'isinf', 'isnan', 'isnat', 'lcm',"
    ],
    [
        "'logical_xor', 'matmul', 'matvec', 'maximum', 'minimum', 'mod',",
        "'logical_xor', 'matmul', 'matvec', 'maximum', 'minimum',"
    ],
    [
        "'modf', 'multiply', 'negative', 'nextafter', 'not_equal', 'positive',",
        "'modf', 'multiply', 'negative', 'nextafter', 'not_equal',"
    ],
    [
        "'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',",
        "'sinh', 'spacing', 'sqrt', 'square',"
    ],
    [
        "raise ValueError(f\"Bench target `np.{name}` is not a ufunc\")",
        "raise ValueError(f\"Bench target `np.{name}` is not"
    ],
    [
        "all_ufuncs = (getattr(np, name, None) for name in dir(np))",
        "all_ufuncs = (getattr(np, name, None) for"
    ],
    [
        "all_ufuncs = set(filter(lambda f: isinstance(f, np.ufunc), all_ufuncs))",
        "all_ufuncs = set(filter(lambda f:"
    ],
    [
        "bench_ufuncs = {getattr(np, name, None) for name in ufuncs}",
        "bench_ufuncs = {getattr(np, name, None) for name in"
    ],
    [
        "missing_ufunc_names = [f.__name__ for f in missing_ufuncs]",
        "missing_ufunc_names = [f.__name__ for f"
    ],
    [
        "\"Missing benchmarks for ufuncs %r\" % missing_ufunc_names)",
        "\"Missing benchmarks for ufuncs"
    ],
    [
        "\"\"\" Benchmark for the methods which do not take any arguments",
        "\"\"\" Benchmark for the methods which do not take"
    ],
    [
        "\"\"\" Benchmark for the shift methods",
        "\"\"\" Benchmark for the shift"
    ],
    [
        "\"\"\" Benchmark for the methods which take an argument",
        "\"\"\" Benchmark for the methods which take"
    ],
    [
        "params = [['__add__', '__eq__', '__ge__', '__gt__', '__le__',",
        "params = [['__add__', '__eq__', '__ge__',"
    ],
    [
        "\"\"\" Benchmark for the methods which take an argument",
        "\"\"\" Benchmark for the methods"
    ],
    [
        "\"\"\" Benchmark for the methods which take an argument",
        "\"\"\" Benchmark for the methods"
    ],
    [
        "\"Skipping test for converting to the same dtype\")",
        "\"Skipping test for converting to the"
    ],
    [
        "\"\"\"  Benchmark for a selection of ufuncs on a small arrays and scalars",
        "\"\"\" Benchmark for a selection of ufuncs on a"
    ],
    [
        "Since the arrays and scalars are small, we are benchmarking the overhead",
        "Since the arrays and scalars are small, we are"
    ],
    [
        "[repr(a) for a in self.args] +",
        "[repr(a) for a in self.args]"
    ],
    [
        "['{}={}'.format(k, repr(v)) for k, v in self.kwargs.items()]",
        "['{}={}'.format(k, repr(v)) for k, v in"
    ],
    [
        "from os.path import join as pjoin",
        "from os.path import"
    ],
    [
        "param_names = ['dtype', 'indexes', 'sel', 'op']",
        "param_names = ['dtype',"
    ],
    [
        "def setup(self, dtype, indexes, sel, op):",
        "def setup(self, dtype, indexes,"
    ],
    [
        "code = code % (sel, op)",
        "code = code % (sel,"
    ],
    [
        "def time_op(self, dtype, indexes, sel, op):",
        "def time_op(self, dtype,"
    ],
    [
        "from .common import Benchmark, get_squares, get_squares_",
        "from .common import Benchmark, get_squares,"
    ],
    [
        "from io import SEEK_SET, StringIO, BytesIO",
        "from io import SEEK_SET,"
    ],
    [
        "for date, value in zip(dates, values):",
        "for date, value in zip(dates,"
    ],
    [
        "date_line += (str(date) + ',' + str(value) + '\\n')",
        "date_line += (str(date) + ','"
    ],
    [
        "self.xarg = [x.astype(ndtype) for x in self.xarg]",
        "self.xarg = [x.astype(ndtype) for x in"
    ],
    [
        "When benchmarking the pad function it is useful to cover scenarios where",
        "When benchmarking the pad function it is"
    ],
    [
        "the ratio between the size of the input array and the output array differs",
        "the ratio between the size of the input array and the output array"
    ],
    [
        "significantly (original area vs. padded area). This allows to evaluate for",
        "significantly (original area vs. padded area)."
    ],
    [
        "which scenario a padding algorithm is optimized. Furthermore involving",
        "which scenario a padding algorithm is optimized."
    ],
    [
        "large range of array sizes ensures that the effects of CPU-bound caching is",
        "large range of array sizes ensures that the effects"
    ],
    [
        "The table below shows the sizes of the arrays involved in this benchmark:",
        "The table below shows the sizes of the arrays involved in this"
    ],
    [
        "[\"constant\", \"edge\", \"linear_ramp\", \"mean\", \"reflect\", \"wrap\"],",
        "[\"constant\", \"edge\", \"linear_ramp\", \"mean\","
    ],
    [
        "\"\"\"Benchmark for np.unique with np.nan values.\"\"\"",
        "\"\"\"Benchmark for np.unique with"
    ],
    [
        "self.l_view = [memoryview(a) for a in self.l]",
        "self.l_view = [memoryview(a) for a"
    ],
    [
        "self.x = np.arange(numaxes * size).reshape(numaxes, size)",
        "self.x = np.arange(numaxes *"
    ],
    [
        "Pytest configuration and fixtures for the Numpy test suite.",
        "Pytest configuration and fixtures for"
    ],
    [
        "build_path = os.path.join(root_path, \"doc\", \"build\", \"doxygen\")",
        "build_path = os.path.join(root_path,"
    ],
    [
        "Fetch all Doxygen sub-config files and gather it with the main config file.",
        "Fetch all Doxygen sub-config files and gather it"
    ],
    [
        "for dpath, _, files in os.walk(root_path):",
        "for dpath, _,"
    ],
    [
        "Post-processes HTML and Latex files output by Sphinx.",
        "Post-processes HTML and Latex"
    ],
    [
        "Remove unnecessary section titles from the LaTeX file.",
        "Remove unnecessary section titles"
    ],
    [
        "\"\"\" Rename numpy types to use the canonical names to make sphinx behave \"\"\"",
        "\"\"\" Rename numpy types to use the canonical names to make sphinx behave"
    ],
    [
        "warnings.filterwarnings(\"ignore\", \"In the future.*NumPy scalar\", FutureWarning)",
        "warnings.filterwarnings(\"ignore\", \"In the future.*NumPy"
    ],
    [
        "('breathe', 'skip generating C/C++ API from comment blocks.'),",
        "('breathe', 'skip generating C/C++ API from comment"
    ],
    [
        "ext_exist = importlib.util.find_spec(ext) is not None",
        "ext_exist = importlib.util.find_spec(ext) is not"
    ],
    [
        "print(f\"Unable to find Sphinx extension '{ext}', {warn}.\")",
        "print(f\"Unable to find Sphinx"
    ],
    [
        "Uses a default text if the directive does not have contents. If it does,",
        "Uses a default text if the directive does not"
    ],
    [
        "the default text is concatenated to the contents.",
        "the default text is concatenated"
    ],
    [
        "See also the same implementation in SciPy's conf.py.",
        "See also the same implementation in SciPy's"
    ],
    [
        "text = (f\"This {obj} is considered legacy and will no longer receive \"",
        "text = (f\"This {obj} is considered legacy and will no longer"
    ],
    [
        "\"updates. This could also mean it will be removed in future \"",
        "\"updates. This could also mean it will be removed in future"
    ],
    [
        "html_title = \"%s v%s Manual\" % (project, version)",
        "html_title = \"%s v%s Manual\""
    ],
    [
        "_stdauthor = 'Written by the NumPy community'",
        "_stdauthor = 'Written by the NumPy"
    ],
    [
        "% In the parameters section, place a newline after the Parameters",
        "% In the parameters section, place a newline after"
    ],
    [
        "% so we check rather sphinxpackagefootnote.sty (which exists",
        "% so we check rather sphinxpackagefootnote.sty (which"
    ],
    [
        "% but expdlist old LaTeX package requires fixes:",
        "% but expdlist old LaTeX package requires"
    ],
    [
        "% now a hack because Sphinx inserts \\leavevmode after term node",
        "% now a hack because Sphinx inserts \\leavevmode after"
    ],
    [
        "% Make Examples/etc section headers smaller and more compact",
        "% Make Examples/etc section headers smaller and"
    ],
    [
        "(\"index\", 'numpy', 'NumPy Documentation', _stdauthor, 'NumPy',",
        "(\"index\", 'numpy', 'NumPy"
    ],
    [
        "\"NumPy: array processing for numbers, strings, records, and objects.\",",
        "\"NumPy: array processing for numbers, strings, records, and"
    ],
    [
        "'test($|_)', '(some|all)true', 'bitwise_not', 'cumproduct', 'pkgload', 'generic\\\\.'",
        "'test($|_)', '(some|all)true', 'bitwise_not', 'cumproduct', 'pkgload',"
    ],
    [
        "print(\"NOTE: linkcode extension not found -- no links to source generated\")",
        "print(\"NOTE: linkcode extension not found -- no"
    ],
    [
        "Determine the URL corresponding to Python object",
        "Determine the URL corresponding to"
    ],
    [
        "if isinstance(obj, type) and obj.__module__ == 'numpy':",
        "if isinstance(obj, type) and obj.__module__"
    ],
    [
        "if module is not None and not module.__name__.startswith(\"numpy\"):",
        "if module is not None"
    ],
    [
        "breathe_projects = {'numpy': os.path.join(\"..\", \"build\", \"doxygen\", \"xml\")}",
        "breathe_projects = {'numpy': os.path.join(\"..\","
    ],
    [
        "try_examples_global_button_text = \"Try it in your browser!\"",
        "try_examples_global_button_text = \"Try it in"
    ],
    [
        "\"NumPy's interactive examples are experimental and may not always work\"",
        "\"NumPy's interactive examples are experimental and may not"
    ],
    [
        "\" as expected, with high load times especially on low-resource platforms,\"",
        "\" as expected, with high load times"
    ],
    [
        "\" and the version of NumPy might not be in sync with the one you are\"",
        "\" and the version of NumPy might not be in sync with"
    ],
    [
        "\" browsing the documentation for. If you encounter any issues, please\"",
        "\" browsing the documentation for. If you encounter any issues,"
    ],
    [
        "description=\"a minimal example package (fortran version)\",",
        "description=\"a minimal example package"
    ],
    [
        "Generate CPU features tables from CCompilerOpt",
        "Generate CPU features"
    ],
    [
        "def __init__(self, arch, cc, *args, **kwargs):",
        "def __init__(self, arch,"
    ],
    [
        "if not i and not e:",
        "if not i"
    ],
    [
        "if f in notavl or i in inotavl.get(f, {}):",
        "if f in notavl or i in inotavl.get(f,"
    ],
    [
        "fstyle_implies = lambda origin, ft: fstyle(ft)",
        "fstyle_implies = lambda"
    ],
    [
        "for f, implies, gather in serialized_features:",
        "for f, implies, gather in"
    ],
    [
        "implies = ' '.join([fstyle_implies(f, i) for i in implies])",
        "implies = ' '.join([fstyle_implies(f, i) for i in"
    ],
    [
        "gather = ' '.join([fstyle_implies(f, i) for i in gather])",
        "gather = ' '.join([fstyle_implies(f, i)"
    ],
    [
        "rows = [(name, implies) for name, implies, _ in rows]",
        "rows = [(name, implies) for name, implies,"
    ],
    [
        "cls_len = [max(len(c[i]) for c in rows) for i in range(fld_len)]",
        "cls_len = [max(len(c[i]) for c in rows) for"
    ],
    [
        "cformat = ' '.join('{:<%d}' % i for i in cls_len)",
        "cformat = ' '.join('{:<%d}' % i for"
    ],
    [
        "border = cformat.format(*['=' * i for i in cls_len])",
        "border = cformat.format(*['=' * i for i"
    ],
    [
        "rows = [cformat.format(*row) for row in rows]",
        "rows = [cformat.format(*row) for row"
    ],
    [
        "rows = [border, cformat.format(*field_names), border] + rows",
        "rows = [border, cformat.format(*field_names), border]"
    ],
    [
        "rows = [(' ' * tab_size) + r for r in rows]",
        "rows = [(' ' * tab_size)"
    ],
    [
        "tab = ' ' * tab_size",
        "tab = '"
    ],
    [
        "tab = ' ' * tab_size",
        "tab = ' '"
    ],
    [
        "with open(path.join(gen_path, 'cpu_features.inc'), 'w') as fd:",
        "with open(path.join(gen_path, 'cpu_features.inc'), 'w')"
    ],
    [
        "title = \"On \" + pretty_names.get(arch, arch)",
        "title = \"On \" +"
    ],
    [
        "with open(path.join(gen_path, 'compilers-diff.inc'), 'w') as fd:",
        "with open(path.join(gen_path, 'compilers-diff.inc'),"
    ],
    [
        "rel = table.loc[:, ['RandomState']].values @ np.ones(",
        "rel = table.loc[:, ['RandomState']].values"
    ],
    [
        "title = 'NumPy Enhancement Proposals Documentation'",
        "title = 'NumPy Enhancement Proposals"
    ],
    [
        "author, 'NumPyEnhancementProposals', 'One line description of project.',",
        "author, 'NumPyEnhancementProposals', 'One line description"
    ],
    [
        "Scan the directory of nep files and extract their metadata.  The",
        "Scan the directory of nep files and extract their"
    ],
    [
        "metadata is passed to Jinja for filling out the toctrees for various NEP",
        "metadata is passed to Jinja for filling"
    ],
    [
        "sources = [s for s in sources if s not in ignore]",
        "sources = [s for s in"
    ],
    [
        "tags = [re.match(meta_re, line) for line in lines]",
        "tags = [re.match(meta_re, line) for"
    ],
    [
        "tags = [match.groups() for match in tags if match is not None]",
        "tags = [match.groups() for match in"
    ],
    [
        "raise RuntimeError(\"Unable to find NEP title.\")",
        "raise RuntimeError(\"Unable to"
    ],
    [
        "if not tags['Title'].startswith(f'NEP {nr} â€” '):",
        "if not tags['Title'].startswith(f'NEP {nr}"
    ],
    [
        "f'Title for NEP {nr} does not start with \"NEP {nr} â€” \" '",
        "f'Title for NEP {nr} does not start"
    ],
    [
        "'(note that â€” here is a special, elongated dash). Got: '",
        "'(note that â€” here is a"
    ],
    [
        "if tags['Status'] in ('Accepted', 'Rejected', 'Withdrawn'):",
        "if tags['Status'] in ('Accepted',"
    ],
    [
        "f'NEP {nr} is Accepted/Rejected/Withdrawn but '",
        "f'NEP {nr} is Accepted/Rejected/Withdrawn but"
    ],
    [
        "f'NEP {nr} has been Superseded, but has no Replaced-By tag'",
        "f'NEP {nr} has been Superseded, but"
    ],
    [
        "f'NEP {nr} is superseded by {replaced_by}, but that NEP has '",
        "f'NEP {nr} is superseded by {replaced_by}, but that NEP"
    ],
    [
        "f'NEP {nr} is superseded by {replaced_by}, but that NEP has a '",
        "f'NEP {nr} is superseded by {replaced_by}, but that NEP"
    ],
    [
        "f'NEP {nr} replaces NEP {nr_replaced}, but that NEP '",
        "f'NEP {nr} replaces NEP {nr_replaced}, but"
    ],
    [
        "'has not been set to Superseded'",
        "'has not been set to"
    ],
    [
        "\"\"\"Handle :Replaces: as integer or list of integers\"\"\"",
        "\"\"\"Handle :Replaces: as integer or list of"
    ],
    [
        "replaced_neps = [int(s) for s in replaces]",
        "replaced_neps = [int(s) for"
    ]
]