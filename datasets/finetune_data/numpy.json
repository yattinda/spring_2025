[
    [
        "This paver file is intended to help with the release process as much as",
        "This paver file is intended to help with the"
    ],
    [
        "possible. It relies on virtualenv to generate 'bootstrap' environments as",
        "possible. It relies on virtualenv to generate 'bootstrap' environments"
    ],
    [
        "independent from the user system as possible (e.g. to make sure the sphinx doc",
        "independent from the user system as possible (e.g. to make"
    ],
    [
        "is built against the built numpy, not an installed one).",
        "is built against the built"
    ],
    [
        "Assumes you have git and the binaries/tarballs in installers/::",
        "Assumes you have git and the binaries/tarballs"
    ],
    [
        "This automatically put the checksum into README.rst, and writes the Changelog.",
        "This automatically put the checksum into"
    ],
    [
        "- the script is messy, lots of global variables",
        "- the script is messy, lots of global"
    ],
    [
        "- make it more easily customizable (through command line args)",
        "- make it more easily customizable"
    ],
    [
        "- missing targets: install & test, sdist test, debian packaging",
        "- missing targets: install & test, sdist test,"
    ],
    [
        "- fix bdist_mpkg: we build the same source twice -> how to make sure we use",
        "- fix bdist_mpkg: we build the same source twice -> how"
    ],
    [
        "the same underlying python for egg install in venv and for bdist_mpkg",
        "the same underlying python for egg install in venv and for"
    ],
    [
        "meson_import_dir = curdir.parent / 'vendored-meson' / 'meson' / 'mesonbuild'",
        "meson_import_dir = curdir.parent / 'vendored-meson' / 'meson' /"
    ],
    [
        "'The `vendored-meson/meson` git submodule does not exist! '",
        "'The `vendored-meson/meson` git submodule does"
    ],
    [
        "'Run `git submodule update --init` to fix this problem.'",
        "'Run `git submodule update --init` to fix this"
    ],
    [
        "title = re.sub(r\"\\s+\", \" \", pull.title.strip())",
        "title = re.sub(r\"\\s+\", \" \","
    ],
    [
        "parser = ArgumentParser(description=\"Generate author/pr lists for release\")",
        "parser = ArgumentParser(description=\"Generate author/pr lists"
    ],
    [
        "count = [(x, result.count(x), repo) for x in u]",
        "count = [(x, result.count(x), repo) for x"
    ],
    [
        "def run_ruff(self, fix: bool) -> tuple[int, str]:",
        "def run_ruff(self, fix: bool)"
    ],
    [
        "were accepted before. For instance, '\\(' was previously accepted but must now",
        "were accepted before. For instance, '\\(' was previously accepted"
    ],
    [
        "be written as '\\\\(' or r'\\('.",
        "be written as '\\\\('"
    ],
    [
        "self.array[i, j] = i + j",
        "self.array[i, j] = i +"
    ],
    [
        "\"Test Farray size constructor, negative nrows\"",
        "\"Test Farray size"
    ],
    [
        "\"Test Farray size constructor, negative ncols\"",
        "\"Test Farray size constructor,"
    ],
    [
        "self.array[i, j] = i * j",
        "self.array[i, j] = i *"
    ],
    [
        "self.assertTrue(self.array[i, j] == i * j)",
        "self.assertTrue(self.array[i, j] == i *"
    ],
    [
        "\"Test Farray __setitem__ method, negative row\"",
        "\"Test Farray __setitem__ method,"
    ],
    [
        "\"Test Farray __setitem__ method, negative col\"",
        "\"Test Farray __setitem__"
    ],
    [
        "\"Test Farray __setitem__ method, out-of-range row\"",
        "\"Test Farray __setitem__ method,"
    ],
    [
        "\"Test Farray __setitem__ method, out-of-range col\"",
        "\"Test Farray __setitem__ method, out-of-range"
    ],
    [
        "\"Test Farray __getitem__ method, negative row\"",
        "\"Test Farray __getitem__ method, negative"
    ],
    [
        "\"Test Farray __getitem__ method, negative col\"",
        "\"Test Farray __getitem__ method, negative"
    ],
    [
        "\"Test Farray __getitem__ method, out-of-range row\"",
        "\"Test Farray __getitem__ method, out-of-range"
    ],
    [
        "\"Test Farray __getitem__ method, out-of-range col\"",
        "\"Test Farray __getitem__"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test norm function with bad list\"",
        "\"Test norm function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test norm function with wrong dimensions\"",
        "\"Test norm function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test norm function with wrong size\"",
        "\"Test norm function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test max function with bad list\"",
        "\"Test max function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test max function with wrong dimensions\"",
        "\"Test max function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test min function with bad list\"",
        "\"Test min function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test min function with wrong dimensions\"",
        "\"Test min function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test scale function with wrong type\"",
        "\"Test scale function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test scale function with wrong dimensions\"",
        "\"Test scale function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test scale function with wrong size\"",
        "\"Test scale function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test ceil function with wrong type\"",
        "\"Test ceil function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test ceil function with wrong dimensions\"",
        "\"Test ceil function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "description = \"Functions that work on arrays\",",
        "description = \"Functions that work"
    ],
    [
        "py_modules = [\"Array\", \"Farray\", \"Vector\", \"Matrix\", \"Tensor\",",
        "py_modules = [\"Array\", \"Farray\", \"Vector\", \"Matrix\","
    ],
    [
        "ext_modules = [_Array, _Farray, _Vector, _Matrix, _Tensor,",
        "ext_modules = [_Array, _Farray, _Vector, _Matrix,"
    ],
    [
        "\"Test norm function with bad list\"",
        "\"Test norm function"
    ],
    [
        "\"Test norm function with wrong dimensions\"",
        "\"Test norm function"
    ],
    [
        "\"Test norm function with wrong size\"",
        "\"Test norm function"
    ],
    [
        "\"Test max function with bad list\"",
        "\"Test max function with bad"
    ],
    [
        "\"Test max function with wrong dimensions\"",
        "\"Test max function"
    ],
    [
        "\"Test min function with bad list\"",
        "\"Test min function"
    ],
    [
        "\"Test min function with wrong dimensions\"",
        "\"Test min function with wrong"
    ],
    [
        "\"Test scale function with wrong type\"",
        "\"Test scale function"
    ],
    [
        "\"Test scale function with wrong dimensions\"",
        "\"Test scale function"
    ],
    [
        "\"Test scale function with wrong size\"",
        "\"Test scale function with wrong"
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function with wrong"
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function"
    ],
    [
        "\"Test ceil function with wrong type\"",
        "\"Test ceil function with wrong"
    ],
    [
        "\"Test ceil function with wrong dimensions\"",
        "\"Test ceil function with"
    ],
    [
        "\"Test Fortran matrix initialized from reshaped NumPy fortranarray\"",
        "\"Test Fortran matrix initialized from reshaped NumPy"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test Fortran matrix initialized from nested list fortranarray\"",
        "\"Test Fortran matrix initialized from"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test length function with bad list\"",
        "\"Test length function with bad"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test length function with wrong size\"",
        "\"Test length function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test length function with wrong dimensions\"",
        "\"Test length function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test prod function with bad list\"",
        "\"Test prod function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test prod function with wrong dimensions\"",
        "\"Test prod function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test sum function with bad list\"",
        "\"Test sum function with bad"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test sum function with wrong dimensions\"",
        "\"Test sum function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test reverse function with wrong dimensions\"",
        "\"Test reverse function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test reverse function with wrong size\"",
        "\"Test reverse function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test reverse function with wrong type\"",
        "\"Test reverse function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test ones function with wrong dimensions\"",
        "\"Test ones function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test ones function with wrong type\"",
        "\"Test ones function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test zeros function with wrong dimensions\"",
        "\"Test zeros function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test zeros function with wrong type\"",
        "\"Test zeros function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test twos function with non-integer dimension\"",
        "\"Test twos function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test threes function with non-integer dimension\"",
        "\"Test threes function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test det function with bad list\"",
        "\"Test det function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test det function with wrong dimensions\"",
        "\"Test det function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test det function with wrong size\"",
        "\"Test det function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test max function with bad list\"",
        "\"Test max function with bad"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test max function with wrong dimensions\"",
        "\"Test max function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test min function with bad list\"",
        "\"Test min function with bad"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "matrix = [[\"nine\", \"eight\"], [\"seven\", \"six\"]]",
        "matrix = [[\"nine\","
    ],
    [
        "\"Test min function with wrong dimensions\"",
        "\"Test min function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test scale function with wrong dimensions\"",
        "\"Test scale function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test scale function with wrong size\"",
        "\"Test scale function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test scale function with wrong type\"",
        "\"Test scale function with wrong"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test floor function with wrong dimensions\"",
        "\"Test floor function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test floor function with wrong type\"",
        "\"Test floor function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "\"Test ceil function with wrong dimensions\"",
        "\"Test ceil function with"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "\"Test ceil function with wrong dimensions\"",
        "\"Test ceil function"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end='"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \", end=' ',"
    ],
    [
        "\"Test Process function with non-contiguous array, which should raise an error\"",
        "\"Test Process function with non-contiguous array, which should raise"
    ],
    [
        "print(self.typeStr, \"... \", end=' ', file=sys.stderr)",
        "print(self.typeStr, \"... \","
    ],
    [
        "print(\"The following files were not found by towncrier:\")",
        "print(\"The following files were not found by"
    ],
    [
        "description='Upload files to a remote repo, replacing existing content'",
        "description='Upload files to a remote repo, replacing"
    ],
    [
        "parser.add_argument('dir', help='directory of which content will be uploaded')",
        "parser.add_argument('dir', help='directory of which content"
    ],
    [
        "parser.add_argument('remote', help='remote to which content will be pushed')",
        "parser.add_argument('remote', help='remote to which"
    ],
    [
        "help='hereby acknowledge that remote repo content will be overwritten'",
        "help='hereby acknowledge that remote repo content will be"
    ],
    [
        "count = len([name for name in os.listdir(args.dir)",
        "count = len([name for name in"
    ],
    [
        "print(f\"Expected {args.count} top-directory files to upload, got {count}\")",
        "print(f\"Expected {args.count} top-directory files"
    ],
    [
        "pipe = None if stdout else subprocess.DEVNULL",
        "pipe = None if"
    ],
    [
        "print(\"\\n! Error executing: `%s;` aborting\" % ' '.join(cmd))",
        "print(\"\\n! Error executing: `%s;`"
    ],
    [
        "print('- committing new content: \"%s\"' % args.message)",
        "print('- committing new content: \"%s\"'"
    ],
    [
        "run(['git', 'commit', '--allow-empty', '-m', args.message], stdout=False)",
        "run(['git', 'commit', '--allow-empty',"
    ],
    [
        "print('- uploading as %s <%s>' % (args.committer, args.email))",
        "print('- uploading as %s <%s>' %"
    ],
    [
        "print('\\n!! No `--force` argument specified; aborting')",
        "print('\\n!! No `--force`"
    ],
    [
        "print('!! Before enabling that flag, make sure you know what it does\\n')",
        "print('!! Before enabling that flag, make sure you know"
    ],
    [
        "for i, (c, t) in enumerate(HtmlFormatter.wrap(self, source, outfile)):",
        "for i, (c, t)"
    ],
    [
        "with open(os.path.join(root, self.clean_path(path)), \"w\") as fd:",
        "with open(os.path.join(root, self.clean_path(path)), \"w\") as"
    ],
    [
        "with open(os.path.join(root, 'index.html'), 'w') as fd:",
        "with open(os.path.join(root, 'index.html'),"
    ],
    [
        "help='Destination directory for output (default: %(default)s)')",
        "help='Destination directory for output (default:"
    ],
    [
        "help='Regex pattern to match against source file paths '",
        "help='Regex pattern to match against source"
    ],
    [
        "\"If option not provided, both will be generated.\")",
        "\"If option not provided, both will"
    ],
    [
        "help=\"Compile flag needed when using the NumPy headers.\",",
        "help=\"Compile flag needed when using"
    ],
    [
        "help=(\"Print the pkgconfig directory in which `numpy.pc` is stored \"",
        "help=(\"Print the pkgconfig directory in which `numpy.pc` is stored"
    ],
    [
        "_path = Path(get_include()) / '..' / 'lib' / 'pkgconfig'",
        "_path = Path(get_include()) / '..'"
    ],
    [
        "\"The matrix subclass is not the recommended way to represent \"",
        "\"The matrix subclass is not the recommended way to"
    ],
    [
        "\"matrices or deal with linear algebra (see \"",
        "\"matrices or deal with linear algebra (see"
    ],
    [
        "\"Please adjust your code to use regular ndarray. \",",
        "\"Please adjust your code to"
    ],
    [
        "deps = ['-MMD', '-MF', obj + '.d']",
        "deps = ['-MMD', '-MF',"
    ],
    [
        "self.spawn(self.compiler_so + cc_args + [src, '-o', obj] + deps +",
        "self.spawn(self.compiler_so + cc_args + [src,"
    ],
    [
        "with open(obj + '.d', 'a') as f:",
        "with open(obj + '.d', 'a') as"
    ],
    [
        "__all__ = ['FormatError', 'PkgNotFound', 'LibraryInfo', 'VariableSet',",
        "__all__ = ['FormatError',"
    ],
    [
        "from threading import local as tlocal",
        "from threading import local"
    ],
    [
        "assert apath[len(pd)] in [os.sep], repr((path, apath[len(pd)]))",
        "assert apath[len(pd)] in [os.sep],"
    ],
    [
        "return all(is_string(item) for item in lst)",
        "return all(is_string(item) for"
    ],
    [
        "return is_string(s) and ('*' in s or '?' in s)",
        "return is_string(s) and ('*' in s or"
    ],
    [
        "return any(fortran_ext_match(source) for source in sources)",
        "return any(fortran_ext_match(source) for source"
    ],
    [
        "dirs = [_m for _m in sorted_glob(subpackage_path) if os.path.isdir(_m)]",
        "dirs = [_m for _m in sorted_glob(subpackage_path)"
    ],
    [
        "self.warn('Subpackage %r configuration returned as %r' % \\",
        "self.warn('Subpackage %r configuration returned as %r'"
    ],
    [
        "from distutils.log import Log as old_Log",
        "from distutils.log import Log as"
    ],
    [
        "from numpy.distutils.misc_util import (red_text, default_text, cyan_text,",
        "from numpy.distutils.misc_util import (red_text,"
    ],
    [
        "__doc__ = \"\"\"This module generates a DEF file from the symbols in",
        "__doc__ = \"\"\"This module generates a DEF"
    ],
    [
        "an MSVC-compiled DLL import library.  It correctly discriminates between",
        "an MSVC-compiled DLL import library. It correctly discriminates"
    ],
    [
        "data and functions.  The data is collected from the output of the program",
        "data and functions. The data is collected from"
    ],
    [
        "libname.lib defaults to python<py_ver>.lib and output.def defaults to stdout",
        "libname.lib defaults to python<py_ver>.lib and"
    ],
    [
        "os.path.join(library_root, d) for d in _lib_dirs)",
        "os.path.join(library_root, d) for"
    ],
    [
        "os.path.join(library_root, d) for d in _include_dirs)",
        "os.path.join(library_root, d) for d in"
    ],
    [
        "default_src_dirs = ['.', '/usr/local/src', '/opt/src', '/sw/src']",
        "default_src_dirs = ['.', '/usr/local/src',"
    ],
    [
        "if os.path.join(sys.prefix, 'lib') not in default_lib_dirs:",
        "if os.path.join(sys.prefix, 'lib') not"
    ],
    [
        "default_lib_dirs = [_m for _m in default_lib_dirs if os.path.isdir(_m)]",
        "default_lib_dirs = [_m for _m"
    ],
    [
        "default_runtime_dirs = [_m for _m in default_runtime_dirs if os.path.isdir(_m)]",
        "default_runtime_dirs = [_m for _m in default_runtime_dirs"
    ],
    [
        "default_include_dirs = [_m for _m in default_include_dirs if os.path.isdir(_m)]",
        "default_include_dirs = [_m for _m"
    ],
    [
        "default_src_dirs = [_m for _m in default_src_dirs if os.path.isdir(_m)]",
        "default_src_dirs = [_m for _m"
    ],
    [
        "opt = self.get_option_single(self.section + '_libs', 'libraries')",
        "opt = self.get_option_single(self.section + '_libs',"
    ],
    [
        "log.info('  %s not found' % (ver_param['name']))",
        "log.info(' %s not found'"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d"
    ],
    [
        "p = self.combine_paths(d, ['libdjbfft.a', 'libdjbfft' + so_ext])",
        "p = self.combine_paths(d, ['libdjbfft.a', 'libdjbfft'"
    ],
    [
        "info = {'libraries': ['djbfft'], 'library_dirs': [d]}",
        "info = {'libraries': ['djbfft'], 'library_dirs':"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d in dirs"
    ],
    [
        "atlas_libs = self.get_libs(opt, self._lib_names + self._lib_atlas)",
        "atlas_libs = self.get_libs(opt,"
    ],
    [
        "h = (self.combine_paths(lib_dirs + include_dirs, 'cblas.h') or [None])",
        "h = (self.combine_paths(lib_dirs + include_dirs,"
    ],
    [
        "Could not find lapack library within the ATLAS installation.",
        "Could not find lapack library"
    ],
    [
        "int main(int argc, const char *argv[])",
        "int main(int argc, const char"
    ],
    [
        "info[key] = info.get(key, []) + blas_info[key]",
        "info[key] = info.get(key,"
    ],
    [
        "info[key] = info.get(key, ()) + blas_info[key]",
        "info[key] = info.get(key,"
    ],
    [
        "info[key] = info.get(key, '') + blas_info[key]",
        "info[key] = info.get(key, '') +"
    ],
    [
        "libraries = [lib.strip().lower() for lib in libraries]",
        "libraries = [lib.strip().lower() for lib in"
    ],
    [
        "return [d for d in dirs if os.path.isdir(d)]",
        "return [d for d in dirs if"
    ],
    [
        "srotmg zdrot cdotu daxpy drotm idamax scopy sscal zdscal crotg",
        "srotmg zdrot cdotu daxpy drotm idamax"
    ],
    [
        "from setuptools import setup as old_setup",
        "from setuptools import setup"
    ],
    [
        "from distutils.core import setup as old_setup",
        "from distutils.core import"
    ],
    [
        "from numpy.distutils.command import config, config_compiler, \\",
        "from numpy.distutils.command import config,"
    ],
    [
        "build, build_py, build_ext, build_clib, build_src, build_scripts, \\",
        "build, build_py, build_ext, build_clib, build_src, build_scripts,"
    ],
    [
        "sdist, install_data, install_headers, install, bdist_rpm, \\",
        "sdist, install_data, install_headers, install, bdist_rpm,"
    ],
    [
        "raise ValueError('No replicates found for <%s>' % (r))",
        "raise ValueError('No replicates found for"
    ],
    [
        "if r not in names and not thelist.startswith('_'):",
        "if r not in names and"
    ],
    [
        "rule = [i.replace('@comma@', ',') for i in thelist.split(',')]",
        "rule = [i.replace('@comma@', ',') for i in"
    ],
    [
        "print(\"Mismatch in number of replacements (base <%s=%s>)\"",
        "print(\"Mismatch in number of replacements (base"
    ],
    [
        "newstr += template_re.sub(namerepl, substr) + '\\n\\n'",
        "newstr += template_re.sub(namerepl, substr)"
    ],
    [
        "return [] if msvcr is None else [msvcr]",
        "return [] if msvcr"
    ],
    [
        "if hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix:",
        "if hasattr(sys, 'base_prefix') and sys.base_prefix"
    ],
    [
        "elif hasattr(sys, 'real_prefix') and sys.real_prefix != sys.prefix:",
        "elif hasattr(sys, 'real_prefix') and"
    ],
    [
        "filename = pat % (major_version, minor_version)",
        "filename = pat % (major_version,"
    ],
    [
        "log.debug('Skip building import library: \"%s\" exists', out_file)",
        "log.debug('Skip building import library: \"%s\""
    ],
    [
        "cmd = ['dlltool', '-d', def_file, '-l', out_file]",
        "cmd = ['dlltool', '-d',"
    ],
    [
        "\"Discrepancy between linked msvcr \" \\",
        "\"Discrepancy between linked"
    ],
    [
        "\"(%d) and the one about to be embedded \" \\",
        "\"(%d) and the one about to be"
    ],
    [
        "return root + exext + \".manifest\"",
        "return root + exext"
    ],
    [
        "from distutils.msvccompiler import MSVCCompiler as _MSVCCompiler",
        "from distutils.msvccompiler import"
    ],
    [
        "flags = kwargs.pop(\"extra_postargs\", []) + flags",
        "flags = kwargs.pop(\"extra_postargs\", []) +"
    ],
    [
        "if not isinstance(arg, str) and hasattr(arg, '__iter__'):",
        "if not isinstance(arg, str)"
    ],
    [
        "return '('+ ' '.join(ret) + ')'",
        "return '('+ ' '.join(ret)"
    ],
    [
        "start = \"CCompilerOpt.%s[%d] : \" % (stack.function, stack.lineno)",
        "start = \"CCompilerOpt.%s[%d] : \" % (stack.function,"
    ],
    [
        "self.dist_fatal(\"'$' must stuck in the begin of policy name\")",
        "self.dist_fatal(\"'$' must stuck in the begin of policy"
    ],
    [
        "\"'%s' is an invalid policy name, available policies are\" % token,",
        "\"'%s' is an invalid policy name,"
    ],
    [
        "def _parse_token_group(self, token, has_baseline, final_targets, extra_flags):",
        "def _parse_token_group(self, token,"
    ],
    [
        "self.dist_fatal(\"invalid target name in multi-target\", targets)",
        "self.dist_fatal(\"invalid target name in multi-target\","
    ],
    [
        "\"policy 'keep_sort' is on, dispatch-able targets\", final_targets, \"\\n\"",
        "\"policy 'keep_sort' is on, dispatch-able targets\","
    ],
    [
        "\"are 'not' sorted depend on the highest interest but\"",
        "\"are 'not' sorted depend on the highest interest"
    ],
    [
        "\"as specified in the dispatch-able source or the extra group\"",
        "\"as specified in the dispatch-able source or"
    ],
    [
        "self.dist_log(\"debug mode is detected, policy 'maxopt' is skipped.\")",
        "self.dist_log(\"debug mode is detected, policy 'maxopt'"
    ],
    [
        "self.dist_log(\"optimization is disabled, policy 'maxopt' is skipped.\")",
        "self.dist_log(\"optimization is disabled, policy 'maxopt'"
    ],
    [
        "\"current compiler doesn't support optimization flags, \"",
        "\"current compiler doesn't support optimization flags,"
    ],
    [
        "class CCompilerOpt(_Config, _Distutils, _Cache, _CCompiler, _Feature, _Parse):",
        "class CCompilerOpt(_Config, _Distutils, _Cache, _CCompiler, _Feature,"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import assert_, assert_equal,"
    ],
    [
        "from numpy.distutils.system_info import system_info, ConfigParser, mkl_info",
        "from numpy.distutils.system_info import system_info,"
    ],
    [
        "info = {'libraries': libs, 'library_dirs': lib_dirs}",
        "info = {'libraries':"
    ],
    [
        "HAS_MKL = \"mkl_rt\" in mkl_info().calc_libraries_info().get(\"libraries\", [])",
        "HAS_MKL = \"mkl_rt\" in"
    ],
    [
        "@pytest.mark.xfail(HAS_MKL, reason=(\"`[DEFAULT]` override doesn't work if \"",
        "@pytest.mark.xfail(HAS_MKL, reason=(\"`[DEFAULT]` override doesn't work if"
    ],
    [
        "\"numpy is built with MKL support\"))",
        "\"numpy is built"
    ],
    [
        "is_standalone = __name__ == '__main__' and __package__ is None",
        "is_standalone = __name__ == '__main__'"
    ],
    [
        "line = next(line for line in clean_out.splitlines())",
        "line = next(line for"
    ],
    [
        "from os.path import join, sep, dirname",
        "from os.path import"
    ],
    [
        "n = lambda path: path.replace('/', sep)",
        "n = lambda path: path.replace('/',"
    ],
    [
        "assert_(join(local_path, 'command', 'build_src.py') in ls, repr(ls))",
        "assert_(join(local_path, 'command', 'build_src.py') in"
    ],
    [
        "reason=\"`get_info` .ini lookup method incompatible with editable install\"",
        "reason=\"`get_info` .ini lookup method incompatible with editable"
    ],
    [
        "flag_vars = fc.flag_vars.clone(lambda *args, **kwargs: None)",
        "flag_vars = fc.flag_vars.clone(lambda *args, **kwargs:"
    ],
    [
        "pytest.skip('Unable to run with non-native parser')",
        "pytest.skip('Unable to run with"
    ],
    [
        "from numpy.testing import tempdir, assert_, assert_warns, IS_WASM",
        "from numpy.testing import tempdir, assert_,"
    ],
    [
        "nag_version_strings = [('nagfor', 'NAG Fortran Compiler Release '",
        "nag_version_strings = [('nagfor', 'NAG Fortran Compiler Release"
    ],
    [
        "('nagfor', 'NAG Fortran Compiler Release '",
        "('nagfor', 'NAG Fortran Compiler"
    ],
    [
        "('nagfor', 'NAG Fortran Compiler Release '",
        "('nagfor', 'NAG Fortran"
    ],
    [
        "('nagfor', 'NAG Fortran Compiler Release '",
        "('nagfor', 'NAG Fortran Compiler"
    ],
    [
        "for comp, vs, version in nag_version_strings:",
        "for comp, vs,"
    ],
    [
        "is_standalone = __name__ == '__main__' and __package__ is None",
        "is_standalone = __name__ == '__main__' and __package__ is"
    ],
    [
        "def __init__(self, trap_files=\"\", trap_flags=\"\", *args, **kwargs):",
        "def __init__(self, trap_files=\"\", trap_flags=\"\","
    ],
    [
        "from subprocess import Popen, PIPE, STDOUT",
        "from subprocess import Popen,"
    ],
    [
        "p = Popen(newcmd, stderr=STDOUT, stdout=PIPE, cwd=d)",
        "p = Popen(newcmd, stderr=STDOUT, stdout=PIPE,"
    ],
    [
        "description = 'DIGITAL or Compaq Visual Fortran Compiler'",
        "description = 'DIGITAL or Compaq Visual"
    ],
    [
        "version_pattern = (r'(DIGITAL|Compaq) Visual Fortran Optimizing Compiler'",
        "version_pattern = (r'(DIGITAL|Compaq) Visual"
    ],
    [
        "print('Ignoring \"%s\" (I think it is msvccompiler.py bug)' % (e))",
        "print('Ignoring \"%s\" (I think it is msvccompiler.py bug)' %"
    ],
    [
        "f + '.f', '-o', f + '.o']",
        "f + '.f', '-o', f +"
    ],
    [
        "description = 'Intel Fortran Compiler for Itanium apps'",
        "description = 'Intel Fortran Compiler"
    ],
    [
        "f + '.f', '/o', f + '.o']",
        "f + '.f', '/o',"
    ],
    [
        "opt = ['/nologo', '/MD', '/nbs', '/names:lowercase',",
        "opt = ['/nologo',"
    ],
    [
        "description = 'Intel Visual Fortran Compiler for Itanium apps'",
        "description = 'Intel Visual Fortran Compiler for Itanium"
    ],
    [
        "return ['-g', '-u', '-nan', '-C=all', '-thread_safe',",
        "return ['-g', '-u', '-nan', '-C=all',"
    ],
    [
        "return ['-g', '-nan', '-C=all', '-u', '-thread_safe']",
        "return ['-g', '-nan', '-C=all',"
    ],
    [
        "from os.path import join, dirname, normpath",
        "from os.path import join, dirname,"
    ],
    [
        "description = 'Portland Group Fortran Compiler'",
        "description = 'Portland Group"
    ],
    [
        "description = 'Portland Group Fortran LLVM Compiler'",
        "description = 'Portland Group Fortran"
    ],
    [
        "description = 'IBM XL Fortran Compiler'",
        "description = 'IBM"
    ],
    [
        "if version is None and sys.platform.startswith('aix'):",
        "if version is"
    ],
    [
        "if version is None and os.path.isdir(xlf_dir):",
        "if version is None"
    ],
    [
        "l = [d for d in l if os.path.isfile(os.path.join(xlf_dir, d, 'xlf.cfg'))]",
        "l = [d for d in"
    ],
    [
        "for key in list(self.executables.keys()) + \\",
        "for key in"
    ],
    [
        "for l in pretty_printer.generate_help(\"%s instance properties:\" \\",
        "for l in pretty_printer.generate_help(\"%s instance"
    ],
    [
        "def _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts):",
        "def _compile(self, obj, src, ext, cc_args,"
    ],
    [
        "from os.path import join, dirname, normpath",
        "from os.path import join, dirname,"
    ],
    [
        "version_pattern =  r'MIPSpro Compilers: Version (?P<version>[^\\s*,]*)'",
        "version_pattern = r'MIPSpro"
    ],
    [
        "hook, envvar, confvar, convert, append = conf_desc",
        "hook, envvar, confvar, convert,"
    ],
    [
        "convert = lambda x : x",
        "convert = lambda x :"
    ],
    [
        "print('  hook   : %s' % (convert(v),))",
        "print(' hook : %s' %"
    ],
    [
        "print('  config : %s' % (convert(v),))",
        "print(' config : %s'"
    ],
    [
        "f\"'EnvironmentConfig' object has no attribute '{name}'\"",
        "f\"'EnvironmentConfig' object has"
    ],
    [
        "hook, envvar, confvar, convert, append = conf_desc",
        "hook, envvar, confvar, convert, append"
    ],
    [
        "if confvar is not None and self._conf:",
        "if confvar is not"
    ],
    [
        "version_pattern =  r'PathScale\\(TM\\) Compiler Suite: Version (?P<version>[\\d.]+)'",
        "version_pattern = r'PathScale\\(TM\\) Compiler Suite: Version"
    ],
    [
        "description = 'Absoft Corp Fortran Compiler'",
        "description = 'Absoft Corp Fortran"
    ],
    [
        "from distutils.command.build import build as old_build",
        "from distutils.command.build import build as"
    ],
    [
        "sub_commands = [('config_cc',     lambda *args: True),",
        "sub_commands = [('config_cc', lambda *args:"
    ],
    [
        "\"turn all warnings into errors (-Werror)\"),",
        "\"turn all warnings into errors"
    ],
    [
        "\"specify a list of enabled baseline CPU optimizations\"),",
        "\"specify a list of enabled baseline CPU"
    ],
    [
        "\"specify a list of dispatched CPU optimizations\"),",
        "\"specify a list of"
    ],
    [
        "\"specify a list of CPU optimizations to be tested against NumPy SIMD interface\"),",
        "\"specify a list of CPU optimizations to be tested against NumPy SIMD"
    ],
    [
        "('help-fcompiler', None, \"list available Fortran compilers\",",
        "('help-fcompiler', None, \"list available Fortran"
    ],
    [
        "from distutils.command.config import config as old_config",
        "from distutils.command.config import config as"
    ],
    [
        "('fcompiler=', None, \"specify the Fortran compiler type\"),",
        "('fcompiler=', None, \"specify the Fortran compiler"
    ],
    [
        "Could not initialize compiler instance: do you have Visual Studio",
        "Could not initialize compiler instance: do you"
    ],
    [
        "installed?  If you are trying to build with MinGW, please use \"python setup.py",
        "installed? If you are trying to build with MinGW, please use"
    ],
    [
        "Original exception was: %s, and the Compiler class was %s",
        "Original exception was: %s, and the Compiler class was"
    ],
    [
        "raise CompileError('%s compiler is not set' % (lang,))",
        "raise CompileError('%s compiler is not"
    ],
    [
        "def _compile (self, body, headers, include_dirs, lang):",
        "def _compile (self, body, headers,"
    ],
    [
        "for d in self.fcompiler.library_dirs or []:",
        "for d in self.fcompiler.library_dirs"
    ],
    [
        "for libname in self.fcompiler.libraries or []:",
        "for libname in self.fcompiler.libraries"
    ],
    [
        "for libdir in library_dirs or []:",
        "for libdir in"
    ],
    [
        "libfile = os.path.join(libdir, '%s.lib' % (libname))",
        "libfile = os.path.join(libdir,"
    ],
    [
        "libfile = os.path.join(libdir, 'lib%s.a' % (libname))",
        "libfile = os.path.join(libdir, 'lib%s.a' %"
    ],
    [
        "log.warn('could not find library %r in directories %s' \\",
        "log.warn('could not find library %r in directories"
    ],
    [
        "def check_header(self, header, include_dirs=None, library_dirs=None, lang='c'):",
        "def check_header(self, header,"
    ],
    [
        "\"/* we need a dummy line to make distutils happy */\",",
        "\"/* we need a dummy line"
    ],
    [
        "from distutils.command.install_headers import install_headers as old_install_headers",
        "from distutils.command.install_headers import install_headers"
    ],
    [
        "from distutils.command.build_py import build_py as old_build_py",
        "from distutils.command.build_py import build_py"
    ],
    [
        "if build_src.py_modules_dict and self.packages is None:",
        "if build_src.py_modules_dict and"
    ],
    [
        "new_py_modules = [_m for _m in self.py_modules if is_string(_m)]",
        "new_py_modules = [_m for _m in"
    ],
    [
        "def generate_a_pyrex_source(self, base, ext_name, source, extension):",
        "def generate_a_pyrex_source(self, base, ext_name, source,"
    ],
    [
        "from setuptools.command.sdist import sdist as old_sdist",
        "from setuptools.command.sdist import sdist"
    ],
    [
        "from distutils.command.sdist import sdist as old_sdist",
        "from distutils.command.sdist import"
    ],
    [
        "from setuptools.command.bdist_rpm import bdist_rpm as old_bdist_rpm",
        "from setuptools.command.bdist_rpm import"
    ],
    [
        "from distutils.command.bdist_rpm import bdist_rpm as old_bdist_rpm",
        "from distutils.command.bdist_rpm import bdist_rpm"
    ],
    [
        "description = \"Command to install installable C libraries\"",
        "description = \"Command to"
    ],
    [
        "for kw in ['inline', '__inline__', '__inline']:",
        "for kw in"
    ],
    [
        "st = cmd.try_compile(body % {'inline': kw}, None, None)",
        "st = cmd.try_compile(body % {'inline':"
    ],
    [
        "from setuptools.command.egg_info import egg_info as _egg_info",
        "from setuptools.command.egg_info import"
    ],
    [
        "`build_src` is being run, this may lead to missing",
        "`build_src` is being run, this may lead"
    ],
    [
        "files in your sdist!  You want to use distutils.sdist",
        "files in your sdist! You want"
    ],
    [
        "from distutils.command.install_data import install_data as old_install_data",
        "from distutils.command.install_data import install_data"
    ],
    [
        "f\"module 'numpy.core.umath' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.umath' has"
    ],
    [
        "f\"module 'numpy.core.fromnumeric' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.fromnumeric' has no attribute"
    ],
    [
        "f\"module 'numpy.core._dtype' has no attribute {attr_name}\")",
        "f\"module 'numpy.core._dtype' has"
    ],
    [
        "f\"module 'numpy.core._internal' has no attribute {attr_name}\")",
        "f\"module 'numpy.core._internal' has no"
    ],
    [
        "f\"module 'numpy.core.multiarray' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.multiarray' has"
    ],
    [
        "f\"module 'numpy.core.records' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.records' has no attribute"
    ],
    [
        "f\"module 'numpy.core.overrides' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.overrides' has no"
    ],
    [
        "f\"module 'numpy.core.getlimits' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.getlimits' has no attribute"
    ],
    [
        "f\"module 'numpy.core._dtype_ctypes' has no attribute {attr_name}\")",
        "f\"module 'numpy.core._dtype_ctypes' has no attribute"
    ],
    [
        "f\"module 'numpy.core.defchararray' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.defchararray' has no"
    ],
    [
        "f\"module 'numpy.core.shape_base' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.shape_base' has"
    ],
    [
        "f\"module 'numpy.core.numeric' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.numeric' has no"
    ],
    [
        "f\"module 'numpy.core.function_base' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.function_base' has no"
    ],
    [
        "f\"module 'numpy.core.einsumfunc' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.einsumfunc' has"
    ],
    [
        "f\"module 'numpy.core.numerictypes' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.numerictypes' has no"
    ],
    [
        "def _raise_warning(attr: str, submodule: str | None = None) -> None:",
        "def _raise_warning(attr: str, submodule: str | None = None)"
    ],
    [
        "f\"{old_module} is deprecated and has been renamed to {new_module}. \"",
        "f\"{old_module} is deprecated and has"
    ],
    [
        "\"The numpy._core namespace contains private NumPy internals and its \"",
        "\"The numpy._core namespace contains private NumPy internals"
    ],
    [
        "\"use is discouraged, as NumPy internals can change without warning in \"",
        "\"use is discouraged, as NumPy internals can change"
    ],
    [
        "\"any release. In practice, most real-world usage of numpy.core is to \"",
        "\"any release. In practice, most real-world"
    ],
    [
        "\"access functionality in the public NumPy API. If that is the case, \"",
        "\"access functionality in the public NumPy API. If that"
    ],
    [
        "\"use the public NumPy API. If not, you are using NumPy internals. \"",
        "\"use the public NumPy API. If not, you"
    ],
    [
        "\"If you would still like to access an internal attribute, \"",
        "\"If you would still like to"
    ],
    [
        "f\"module 'numpy.core.arrayprint' has no attribute {attr_name}\")",
        "f\"module 'numpy.core.arrayprint' has no"
    ],
    [
        "If you are a user of the module, the easiest solution will be to",
        "If you are a user of the module, the easiest solution will"
    ],
    [
        "return dot(_multi_dot(arrays, order, i, order[i, j]),",
        "return dot(_multi_dot(arrays, order, i, order[i,"
    ],
    [
        "f\"module 'numpy.linalg.linalg' has no attribute {attr_name}\")",
        "f\"module 'numpy.linalg.linalg' has"
    ],
    [
        "\"The numpy.linalg.linalg has been made private and renamed to \"",
        "\"The numpy.linalg.linalg has been made"
    ],
    [
        "\"numpy.linalg._linalg. All public functions exported by it are \"",
        "\"numpy.linalg._linalg. All public functions exported"
    ],
    [
        "f\"available from numpy.linalg. Please use numpy.linalg.{attr_name} \"",
        "f\"available from numpy.linalg. Please"
    ],
    [
        "u, s, vh = linalg.svd(x, compute_uv=True, hermitian=self.hermitian)",
        "u, s, vh = linalg.svd(x, compute_uv=True,"
    ],
    [
        "u, s, vh = linalg.svd(x, compute_uv=True, hermitian=self.hermitian)",
        "u, s, vh = linalg.svd(x, compute_uv=True,"
    ],
    [
        "u, s, vt = linalg.svd(a, False, hermitian=True)",
        "u, s, vt = linalg.svd(a,"
    ],
    [
        "assert_allclose(a, matmul(np.asarray(u) * np.asarray(s)[..., None, :],",
        "assert_allclose(a, matmul(np.asarray(u) * np.asarray(s)[..., None,"
    ],
    [
        "for A, p in itertools.product(As, p_pos):",
        "for A, p in itertools.product(As,"
    ],
    [
        "for A, p in itertools.product(As, p_neg):",
        "for A, p"
    ],
    [
        "ValueError, match=r\"`rtol` and `rcond` can't be both set.\"",
        "ValueError, match=r\"`rtol` and `rcond`"
    ],
    [
        "u, s, vt = linalg.svd(a, False)",
        "u, s, vt = linalg.svd(a,"
    ],
    [
        "if rank == n and m > n:",
        "if rank == n and m"
    ],
    [
        "x, residuals, rank, s = linalg.lstsq(a, b)",
        "x, residuals, rank, s ="
    ],
    [
        "x, residuals, rank, s = linalg.lstsq(a, b, rcond=None)",
        "x, residuals, rank, s ="
    ],
    [
        "a = np.arange(m * n).reshape(m, n)",
        "a = np.arange(m *"
    ],
    [
        "x, residuals, rank, s = linalg.lstsq(a, b, rcond=None)",
        "x, residuals, rank, s = linalg.lstsq(a, b,"
    ],
    [
        "r = b - np.dot(a, x)",
        "r = b"
    ],
    [
        "@pytest.mark.parametrize('dt', [np.dtype(c) for c in '?bBhHiIqQefdgFDGO'])",
        "@pytest.mark.parametrize('dt', [np.dtype(c) for"
    ],
    [
        "dtnoinv = [object, np.dtype('e'), np.dtype('g'), np.dtype('G')]",
        "dtnoinv = [object, np.dtype('e'),"
    ],
    [
        "mmul = matmul if mat.dtype != object else dot",
        "mmul = matmul if mat.dtype != object"
    ],
    [
        "mmul = matmul if mat.dtype != object else dot",
        "mmul = matmul if mat.dtype != object else"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "for v in (a, b, c,):",
        "for v in (a,"
    ],
    [
        "for v in (array(a, dtype=self.dt), array(b, dtype=self.dt),",
        "for v in (array(a, dtype=self.dt), array(b,"
    ],
    [
        "k_index = nd - (row_axis + col_axis)",
        "k_index = nd -"
    ],
    [
        "found = norm(A, ord=None, axis=None, keepdims=True)",
        "found = norm(A,"
    ],
    [
        "found = norm(A, ord=order, axis=k, keepdims=True)",
        "found = norm(A,"
    ],
    [
        "found = norm(A, ord=order, axis=k, keepdims=True)",
        "found = norm(A, ord=order,"
    ],
    [
        "ValueError, \"`tol` and `rtol` can\\'t be both set.\"",
        "ValueError, \"`tol` and `rtol` can\\'t"
    ],
    [
        "ValueError, \"Input arrays must be one-dimensional\"",
        "ValueError, \"Input arrays must"
    ],
    [
        "for routine in (linalg.inv, linalg.det, linalg.pinv):",
        "for routine in (linalg.inv, linalg.det,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "reason=\"skipping test that uses fork because there are multiple threads\")",
        "reason=\"skipping test that uses fork because there are"
    ],
    [
        "reason=\"Cannot safely use fork in tests on the free-threaded build\")",
        "reason=\"Cannot safely use fork in tests"
    ],
    [
        "from plex import Scanner, Str, Lexicon, Opt, Bol, State, AnyChar, TEXT, IGNORE",
        "from plex import Scanner, Str, Lexicon, Opt, Bol, State,"
    ],
    [
        "from plex.traditional import re as Re",
        "from plex.traditional import re"
    ],
    [
        "from io import BytesIO as UStringIO",
        "from io import"
    ],
    [
        "from io import StringIO as UStringIO",
        "from io import"
    ],
    [
        "return {'E': 'EPSILON', 'P': 'PRECISION', 'S': 'SAFEMINIMUM',",
        "return {'E': 'EPSILON', 'P': 'PRECISION',"
    ],
    [
        "source = re.sub(r'^\\s+extern.*? dlamch_.*?;$(?m)', '', source)",
        "source = re.sub(r'^\\s+extern.*? dlamch_.*?;$(?m)', '',"
    ],
    [
        "f\"attributes of {self!r} are not writeable\")",
        "f\"attributes of {self!r}"
    ],
    [
        "def assert_array_compare(self, comparison, x, y, err_msg='', header='',",
        "def assert_array_compare(self, comparison, x, y,"
    ],
    [
        "MaskType, MaskedArray, absolute, add, all, allclose, allequal, alltrue,",
        "MaskType, MaskedArray, absolute, add, all, allclose,"
    ],
    [
        "concatenate, conjugate, cos, cosh, count, divide, equal, exp, filled,",
        "concatenate, conjugate, cos, cosh, count,"
    ],
    [
        "getmask, greater, greater_equal, inner, isMaskedArray, less,",
        "getmask, greater, greater_equal, inner, isMaskedArray,"
    ],
    [
        "multiply, nomask, nonzero, not_equal, ones, outer, product, put, ravel,",
        "multiply, nomask, nonzero, not_equal, ones, outer, product, put,"
    ],
    [
        "repeat, resize, shape, sin, sinh, sometrue, sort, sqrt, subtract, sum,",
        "repeat, resize, shape, sin, sinh, sometrue, sort, sqrt,"
    ],
    [
        "take, tan, tanh, transpose, where, zeros,",
        "take, tan, tanh, transpose, where,"
    ],
    [
        "assert_equal(xm.size, reduce(lambda x, y: x * y, s))",
        "assert_equal(xm.size, reduce(lambda x, y: x *"
    ],
    [
        "assert_equal(xm.size, reduce(lambda x, y: x * y, s))",
        "assert_equal(xm.size, reduce(lambda x, y: x"
    ],
    [
        "assert_(eq(x + y, xm + ym))",
        "assert_(eq(x + y, xm +"
    ],
    [
        "assert_(eq(x - y, xm - ym))",
        "assert_(eq(x - y, xm"
    ],
    [
        "assert_(eq(x * y, xm * ym))",
        "assert_(eq(x * y, xm *"
    ],
    [
        "assert_(eq(x / y, xm / ym))",
        "assert_(eq(x / y, xm /"
    ],
    [
        "assert_(eq(x ** y, xm ** ym))",
        "assert_(eq(x ** y, xm"
    ],
    [
        "assert_(eq(np.concatenate((x, y, x)), concatenate((x, ym, x))))",
        "assert_(eq(np.concatenate((x, y, x)), concatenate((x, ym,"
    ],
    [
        "assert_(eq(minimum(x, y), where(less(x, y), x, y)))",
        "assert_(eq(minimum(x, y), where(less(x,"
    ],
    [
        "assert_(eq(maximum(x, y), where(greater(x, y), x, y)))",
        "assert_(eq(maximum(x, y), where(greater(x, y), x,"
    ],
    [
        "assert_(not [m for m in dir(np.ndarray)",
        "assert_(not [m for"
    ],
    [
        "if m not in dir(MaskedArray) and",
        "if m not in"
    ],
    [
        "self.d = (x, X, XX, m, mx, mX, mXX)",
        "self.d = (x, X, XX, m, mx,"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX, mXX,) ="
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX, mXX,)"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX, mXX,)"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX,"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX,"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX,"
    ],
    [
        "(x, X, XX, m, mx, mX, mXX,) = self.d",
        "(x, X, XX, m, mx, mX, mXX,) ="
    ],
    [
        "assert_(x is np.array(x, dtype=descr, copy=None, subok=True))",
        "assert_(x is np.array(x, dtype=descr, copy=None,"
    ],
    [
        "mxcsub = masked_array(xcsub, mask=[True, False, True, False, False])",
        "mxcsub = masked_array(xcsub, mask=[True, False,"
    ],
    [
        "mxsub = masked_array(xsub, mask=[True, False, True, False, False])",
        "mxsub = masked_array(xsub, mask=[True, False,"
    ],
    [
        "mxcsub = masked_array(xcsub, mask=[True, False, True, False, False])",
        "mxcsub = masked_array(xcsub, mask=[True, False, True, False,"
    ],
    [
        "sup.filter(DeprecationWarning, \"bias and ddof have no effect\")",
        "sup.filter(DeprecationWarning, \"bias and ddof have no"
    ],
    [
        "ret += fieldsep.join(repr(name) for name in names)",
        "ret += fieldsep.join(repr(name) for name in"
    ],
    [
        "ret += \"], 'formats'%s[\" % colon",
        "ret += \"],"
    ],
    [
        "_construction_repr(fld_dtype, short=True) for fld_dtype in fld_dtypes)",
        "_construction_repr(fld_dtype, short=True) for fld_dtype"
    ],
    [
        "ret += \"], 'offsets'%s[\" % colon",
        "ret += \"], 'offsets'%s[\" %"
    ],
    [
        "ret += fieldsep.join(\"%d\" % offset for offset in offsets)",
        "ret += fieldsep.join(\"%d\" % offset for offset"
    ],
    [
        "if any(title is not None for title in titles):",
        "if any(title is not None"
    ],
    [
        "ret += \"], 'titles'%s[\" % colon",
        "ret += \"], 'titles'%s[\""
    ],
    [
        "ret += fieldsep.join(repr(title) for title in titles)",
        "ret += fieldsep.join(repr(title) for title"
    ],
    [
        "ret += \"], 'itemsize'%s%d\" % (colon, dtype.itemsize)",
        "ret += \"], 'itemsize'%s%d\""
    ],
    [
        "ret += \", 'aligned'%sTrue}\" % colon",
        "ret += \", 'aligned'%sTrue}\""
    ],
    [
        "return - (-offset // alignment) * alignment",
        "return - (-offset //"
    ],
    [
        "raise ValueError('Can only find greatest common divisor of '",
        "raise ValueError('Can only find greatest common divisor"
    ],
    [
        "f'finite arguments, found \"{a}\" and \"{b}\"')",
        "f'finite arguments, found"
    ],
    [
        "a, b = b, a % b",
        "a, b = b, a %"
    ],
    [
        "return a // _gcd(a, b) * b",
        "return a // _gcd(a,"
    ],
    [
        "def array_ufunc_errmsg_formatter(dummy, ufunc, method, *inputs, **kwargs):",
        "def array_ufunc_errmsg_formatter(dummy, ufunc, method,"
    ],
    [
        "return (\"no implementation found for '{}' on types that implement \"",
        "return (\"no implementation found for '{}' on"
    ],
    [
        "maxlen = max(len(name) for name in names)",
        "maxlen = max(len(name) for"
    ],
    [
        "fmt = '%% %ds: %%s' % maxlen",
        "fmt = '%% %ds:"
    ],
    [
        "rows = [fmt % (name, getattr(self, name)) for name in names]",
        "rows = [fmt % (name, getattr(self,"
    ],
    [
        "valid_filemodes = [\"r\", \"c\", \"r+\", \"w+\"]",
        "valid_filemodes = [\"r\", \"c\","
    ],
    [
        "raise RuntimeError('implementation and dispatcher for %s have '",
        "raise RuntimeError('implementation and dispatcher"
    ],
    [
        "if dispatcher_spec.defaults != (None,) * len(dispatcher_spec.defaults):",
        "if dispatcher_spec.defaults !="
    ],
    [
        "raise RuntimeError('dispatcher functions can only use None for '",
        "raise RuntimeError('dispatcher functions can only use"
    ],
    [
        "def __init__(self, ftype, *, eps, epsneg, huge, tiny,",
        "def __init__(self, ftype, *, eps, epsneg, huge,"
    ],
    [
        "return fmt % {'dtype': self.dtype, 'min': self.min, 'max': self.max}",
        "return fmt % {'dtype': self.dtype, 'min': self.min, 'max':"
    ],
    [
        "return \"%s(min=%s, max=%s, dtype=%s)\" % (self.__class__.__name__,",
        "return \"%s(min=%s, max=%s, dtype=%s)\""
    ],
    [
        "from . import numeric as _nx",
        "from . import"
    ],
    [
        "from .multiarray import array, asanyarray, normalize_axis_index",
        "from .multiarray import array,"
    ],
    [
        "from . import fromnumeric as _from_nx",
        "from . import fromnumeric"
    ],
    [
        "from . import numerictypes as nt",
        "from . import numerictypes"
    ],
    [
        "ALLOW_THREADS, BUFSIZE, CLIP, MAXDIMS, MAY_SHARE_BOUNDS, MAY_SHARE_EXACT,",
        "ALLOW_THREADS, BUFSIZE, CLIP,"
    ],
    [
        "RAISE, WRAP, arange, array, asarray, asanyarray, ascontiguousarray,",
        "RAISE, WRAP, arange, array,"
    ],
    [
        "asfortranarray, broadcast, can_cast, concatenate, copyto, dot, dtype,",
        "asfortranarray, broadcast, can_cast, concatenate, copyto,"
    ],
    [
        "empty, empty_like, flatiter, frombuffer, from_dlpack, fromfile, fromiter,",
        "empty, empty_like, flatiter, frombuffer, from_dlpack,"
    ],
    [
        "fromstring, inner, lexsort, matmul, may_share_memory, min_scalar_type,",
        "fromstring, inner, lexsort, matmul, may_share_memory,"
    ],
    [
        "ndarray, nditer, nested_iters, promote_types, putmask, result_type,",
        "ndarray, nditer, nested_iters, promote_types,"
    ],
    [
        "shares_memory, vdot, where, zeros, normalize_axis_index, vecdot",
        "shares_memory, vdot, where, zeros,"
    ],
    [
        "from .umath import (multiply, invert, sin, PINF, NAN)",
        "from .umath import (multiply, invert, sin, PINF,"
    ],
    [
        "'newaxis', 'ndarray', 'flatiter', 'nditer', 'nested_iters', 'ufunc',",
        "'newaxis', 'ndarray', 'flatiter',"
    ],
    [
        "'asfortranarray', 'zeros', 'count_nonzero', 'empty', 'broadcast', 'dtype',",
        "'asfortranarray', 'zeros', 'count_nonzero',"
    ],
    [
        "'correlate', 'convolve', 'inner', 'dot', 'outer', 'vdot', 'roll',",
        "'correlate', 'convolve', 'inner', 'dot',"
    ],
    [
        "'flatnonzero', 'inf', 'nan', 'False_', 'True_', 'bitwise_not',",
        "'flatnonzero', 'inf', 'nan', 'False_',"
    ],
    [
        "a, dtype=None, order=None, subok=None, shape=None, *, device=None",
        "a, dtype=None, order=None, subok=None, shape=None,"
    ],
    [
        "a, dtype=None, order='K', subok=True, shape=None, *, device=None",
        "a, dtype=None, order='K', subok=True, shape=None, *,"
    ],
    [
        "from . import numeric as _nx",
        "from . import"
    ],
    [
        "from .numeric import result_type, nan, asanyarray, ndim",
        "from .numeric import result_type, nan,"
    ],
    [
        "def _linspace_dispatcher(start, stop, num=None, endpoint=None, retstep=None,",
        "def _linspace_dispatcher(start, stop, num=None,"
    ],
    [
        "\"ufunc {!r} cannot use operands with types {!r} and {!r}\"",
        "\"ufunc {!r} cannot use operands with types {!r}"
    ],
    [
        "def __init__(self, ufunc, casting, from_, to):",
        "def __init__(self, ufunc, casting,"
    ],
    [
        "def __init__(self, ufunc, casting, from_, to, i):",
        "def __init__(self, ufunc, casting, from_, to,"
    ],
    [
        "\"Cannot cast ufunc {!r} output {}from {!r} to {!r} with casting \"",
        "\"Cannot cast ufunc {!r} output {}from {!r}"
    ],
    [
        "units = ['bytes', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB']",
        "units = ['bytes', 'KiB', 'MiB', 'GiB',"
    ],
    [
        "\"Unable to allocate {} for an array with shape {} and data type {}\"",
        "\"Unable to allocate {} for an array with shape"
    ],
    [
        "ScalarType = [int, float, complex, bool, bytes, str, memoryview]",
        "ScalarType = [int, float, complex, bool, bytes, str,"
    ],
    [
        "def _get_formatdict(data, *, precision, floatmode, suppress, sign, legacy,",
        "def _get_formatdict(data, *, precision,"
    ],
    [
        "data, precision, floatmode, suppress, sign, legacy=legacy),",
        "data, precision, floatmode,"
    ],
    [
        "data, precision, floatmode, suppress, sign, legacy=legacy),",
        "data, precision, floatmode,"
    ],
    [
        "data, precision, floatmode, suppress, sign, legacy=legacy),",
        "data, precision, floatmode,"
    ],
    [
        "data, precision, floatmode, suppress, sign, legacy=legacy),",
        "data, precision, floatmode,"
    ],
    [
        "fkeys = [k for k in formatter.keys() if formatter[k] is not None]",
        "fkeys = [k for k in formatter.keys() if formatter[k] is"
    ],
    [
        "def __init__(self, data, precision, floatmode, suppress_small, sign=False,",
        "def __init__(self, data, precision, floatmode, suppress_small,"
    ],
    [
        "sign = '+' if sign else '-'",
        "sign = '+' if"
    ],
    [
        "if data.shape != () and sign == '-':",
        "if data.shape != () and"
    ],
    [
        "frac_strs, _, exp_strs = zip(*(s.partition('e') for s in strs))",
        "frac_strs, _, exp_strs = zip(*(s.partition('e')"
    ],
    [
        "int_part, frac_part = zip(*(s.split('.') for s in frac_strs))",
        "int_part, frac_part = zip(*(s.split('.') for"
    ],
    [
        "self.precision = max(len(s) for s in frac_part)",
        "self.precision = max(len(s) for s in"
    ],
    [
        "self.pad_left = max(len(s) for s in int_part)",
        "self.pad_left = max(len(s) for"
    ],
    [
        "int_part, frac_part = zip(*(s.split('.') for s in strs))",
        "int_part, frac_part = zip(*(s.split('.') for"
    ],
    [
        "self.pad_left = max(len(s) for s in int_part)",
        "self.pad_left = max(len(s) for"
    ],
    [
        "self.pad_right = max(len(s) for s in frac_part)",
        "self.pad_right = max(len(s) for"
    ],
    [
        "if self.sign == ' ' and not any(np.signbit(finite_vals)):",
        "if self.sign == ' ' and"
    ],
    [
        "sign = '+' if self.sign == '+' else ''",
        "sign = '+' if self.sign"
    ],
    [
        "def __init__(self, x, precision, floatmode, suppress_small,",
        "def __init__(self, x,"
    ],
    [
        "sign = '+' if sign else '-'",
        "sign = '+' if"
    ],
    [
        "i = i[:sp] + 'j' + i[sp:]",
        "i = i[:sp] + 'j' +"
    ],
    [
        "def __init__(self, x, unit=None, timezone=None, casting='same_kind',",
        "def __init__(self, x,"
    ],
    [
        "self.summary_insert = \"...\" if a.size > self.threshold else \"\"",
        "self.summary_insert = \"...\" if a.size >"
    ],
    [
        "+ [self.format_array(a_) for a_ in a[-self.edge_items:]]",
        "+ [self.format_array(a_) for"
    ],
    [
        "formatted = [self.format_array(a_) for a_ in a]",
        "formatted = [self.format_array(a_) for a_ in"
    ],
    [
        "return \"[\" + \", \".join(formatted) + \"]\"",
        "return \"[\" + \", \".join(formatted) +"
    ],
    [
        "arr.shape == () and not arr.dtype.names):",
        "arr.shape == () and not"
    ],
    [
        "return prefix + lst + \")\"",
        "return prefix +"
    ],
    [
        "arr_str = prefix + lst + \",\"",
        "arr_str = prefix + lst +"
    ],
    [
        "extra_str = \", \".join(extras) + \")\"",
        "extra_str = \","
    ],
    [
        "spacer = '\\n' + ' ' * len(prefix)",
        "spacer = '\\n' + ' ' *"
    ],
    [
        "spacer = '\\n' + ' ' * len(prefix)",
        "spacer = '\\n' + ' '"
    ],
    [
        "return arr_str + spacer + extra_str",
        "return arr_str +"
    ],
    [
        "a.shape == () and not a.dtype.names):",
        "a.shape == () and not"
    ],
    [
        "byteorder = {'little': '<', 'big': '>'}[sys.byteorder]",
        "byteorder = {'little':"
    ],
    [
        "\"Normalize a description adding the platform byteorder.\"",
        "\"Normalize a description adding the platform"
    ],
    [
        "raise ValueError(\"Expected a str or list and got %s\" %",
        "raise ValueError(\"Expected a str or list"
    ],
    [
        "from hypothesis.extra import numpy as hynp",
        "from hypothesis.extra import"
    ],
    [
        "types = [np.bool, np.byte, np.ubyte, np.short, np.ushort, np.intc, np.uintc,",
        "types = [np.bool, np.byte, np.ubyte, np.short, np.ushort,"
    ],
    [
        "objecty_things = [object(), None, np.array(None, dtype=object)]",
        "objecty_things = [object(), None, np.array(None,"
    ],
    [
        "\"error with types (%d/'%c' + %d/'%c')\" %",
        "\"error with types (%d/'%c' +"
    ],
    [
        "comp_ops = {operator.ge, operator.gt, operator.le, operator.lt}",
        "comp_ops = {operator.ge,"
    ],
    [
        "pytest.xfail(\"complex comp ufuncs use sort-order, scalars do not.\")",
        "pytest.xfail(\"complex comp ufuncs use"
    ],
    [
        "if sctype == np.clongdouble and op in [operator.mod, operator.floordiv]:",
        "if sctype == np.clongdouble and op"
    ],
    [
        "lambda min, max: max + max,",
        "lambda min, max: max +"
    ],
    [
        "lambda min, max: min - max,",
        "lambda min, max: min"
    ],
    [
        "lambda min, max: max * max], ids=[\"+\", \"-\", \"*\"])",
        "lambda min, max: max * max], ids=[\"+\","
    ],
    [
        "lambda val, zero: val // zero,",
        "lambda val, zero:"
    ],
    [
        "lambda val, zero: val % zero, ], ids=[\"//\", \"%\"])",
        "lambda val, zero: val % zero,"
    ],
    [
        "def test_subclass_deferral(sctype, __op__, __rop__, op, cmp):",
        "def test_subclass_deferral(sctype, __op__, __rop__, op,"
    ],
    [
        "ta = np.array(a if np.issubdtype(t, np.number) else a_str, dtype=t)",
        "ta = np.array(a if np.issubdtype(t, np.number)"
    ],
    [
        "for mode in ('raise', 'clip', 'wrap'):",
        "for mode in"
    ],
    [
        "from numpy.testing import IS_WASM, IS_PYPY, NOGIL_BUILD, IS_EDITABLE",
        "from numpy.testing import IS_WASM, IS_PYPY,"
    ],
    [
        "from Cython.Compiler.Version import version as cython_version",
        "from Cython.Compiler.Version import"
    ],
    [
        "pytestmark = pytest.mark.skipif(cython is None, reason=\"requires cython\")",
        "pytestmark = pytest.mark.skipif(cython is None,"
    ],
    [
        "\"Editable install doesn't support tests with a compile step\",",
        "\"Editable install doesn't support tests with a"
    ],
    [
        "\"Py_LIMITED_API is incompatible with Py_DEBUG, Py_TRACE_REFS, \"",
        "\"Py_LIMITED_API is incompatible with"
    ],
    [
        "reason=\"Py_GIL_DISABLED builds do not currently support the limited API\",",
        "reason=\"Py_GIL_DISABLED builds do not currently"
    ],
    [
        "@pytest.mark.skipif(IS_PYPY, reason=\"no support for limited API in PyPy\")",
        "@pytest.mark.skipif(IS_PYPY, reason=\"no support for"
    ],
    [
        "is_cmp = name.strip(\"_\") in [\"eq\", \"ne\", \"le\", \"lt\", \"ge\", \"gt\"]",
        "is_cmp = name.strip(\"_\") in [\"eq\","
    ],
    [
        "or isinstance(other, (str, bytes, numbers.Number, np.bool))",
        "or isinstance(other, (str, bytes, numbers.Number,"
    ],
    [
        "or isinstance(other, np.ndarray) and not other.shape",
        "or isinstance(other, np.ndarray) and not"
    ],
    [
        "if name in [\"__sub__\", \"__rsub__\", \"__add__\", \"__radd__\"]:",
        "if name in [\"__sub__\","
    ],
    [
        "raise TypeError(\"boolean value of NA is ambiguous\")",
        "raise TypeError(\"boolean value of NA is"
    ],
    [
        "elif other is True or other is pd_NA:",
        "elif other is True or"
    ],
    [
        "elif other is False or other is pd_NA:",
        "elif other is False"
    ],
    [
        "if other is False or other is True or other is pd_NA:",
        "if other is False or other is True or other is"
    ],
    [
        "_HANDLED_TYPES = (np.ndarray, numbers.Number, str, np.bool)",
        "_HANDLED_TYPES = (np.ndarray, numbers.Number,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc,"
    ],
    [
        "raise ValueError(f\"ufunc method '{method}' not supported for NA\")",
        "raise ValueError(f\"ufunc method '{method}' not supported"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_array_equal",
        "from numpy.testing import assert_, assert_equal,"
    ],
    [
        "charmax = max(ord(c) for c in arr)",
        "charmax = max(ord(c) for c in"
    ],
    [
        "ua = np.zeros((), dtype='U%s' % self.ulen)",
        "ua = np.zeros((), dtype='U%s' %"
    ],
    [
        "from hypothesis.extra import numpy as hynp",
        "from hypothesis.extra import numpy"
    ],
    [
        "fmt = {'all': lambda x: x.to_string()}",
        "fmt = {'all': lambda"
    ],
    [
        "assert_equal(str(dc), \"[zero one two many many]\")",
        "assert_equal(str(dc), \"[zero one two many"
    ],
    [
        "assert_equal(repr(arr_no_fields), 'array([(), (), (), ()], dtype=[])')",
        "assert_equal(repr(arr_no_fields), 'array([(), (), (), ()],"
    ],
    [
        "cvals = [complex(rp, ip) for rp in rvals for ip in rvals]",
        "cvals = [complex(rp, ip) for rp in"
    ],
    [
        "actual = [str(np.array([c], dt)) for c in cvals for dt in dtypes]",
        "actual = [str(np.array([c], dt)) for c in cvals for dt"
    ],
    [
        "for res, val in zip(actual, wanted):",
        "for res, val in zip(actual,"
    ],
    [
        "( 'NaT',) ( 'NaT',) ( 'NaT',)]\"\"\")",
        "( 'NaT',) ("
    ],
    [
        "a = np.array([[None, MultiLine()], [MultiLine(), None]])",
        "a = np.array([[None, MultiLine()],"
    ],
    [
        "a = np.array([[None, MultiLineLong()], [MultiLineLong(), None]])",
        "a = np.array([[None, MultiLineLong()],"
    ],
    [
        "pytest.skip(allow_module_level=True, reason=\"no threading support in wasm\")",
        "pytest.skip(allow_module_level=True, reason=\"no threading"
    ],
    [
        "pytest.skip(\"Couldn't spawn enough threads to run the test\")",
        "pytest.skip(\"Couldn't spawn enough threads to"
    ],
    [
        "from numpy.testing import assert_, assert_equal, IS_MUSL",
        "from numpy.testing import assert_, assert_equal,"
    ],
    [
        "_REF = {np.inf: 'inf', -np.inf: '-inf', np.nan: 'nan'}",
        "_REF = {np.inf: 'inf', -np.inf: '-inf',"
    ],
    [
        "err_msg='print failed for type%s' % tp)",
        "err_msg='print failed for type%s'"
    ],
    [
        "from numpy.testing import assert_, assert_equal, IS_WASM",
        "from numpy.testing import"
    ],
    [
        "\"Did not raise floating point %s error\" % strmatch)",
        "\"Did not raise floating point %s error\" %"
    ],
    [
        "\"Did not raise floating point %s error\" % strmatch)",
        "\"Did not raise floating point %s error\""
    ],
    [
        "reason=\"fp exceptions don't work in wasm.\")",
        "reason=\"fp exceptions don't"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b:"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b: a"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b: a /"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b:"
    ],
    [
        "assert_raises_fpe('underflow', lambda a, b: a / b,",
        "assert_raises_fpe('underflow', lambda a, b: a"
    ],
    [
        "assert_raises_fpe('overflow', lambda a, b: a + b,",
        "assert_raises_fpe('overflow', lambda a, b: a +"
    ],
    [
        "assert_raises_fpe('overflow', lambda a, b: a - b,",
        "assert_raises_fpe('overflow', lambda a, b: a -"
    ],
    [
        "def test_subscript_tup(self, cls: type[np.ndarray], arg_len: int) -> None:",
        "def test_subscript_tup(self, cls: type[np.ndarray], arg_len: int)"
    ],
    [
        "'assigning arr[%s] = arr[%s]' % (dstidx, srcidx))",
        "'assigning arr[%s] = arr[%s]'"
    ],
    [
        "assert_(X_simplified is None, (A, U, b, X_simplified))",
        "assert_(X_simplified is None, (A, U, b,"
    ],
    [
        "assert_(not any(sum(w) == b for w in itertools.product(*ranges)))",
        "assert_(not any(sum(w) == b"
    ],
    [
        "assert_(X_simplified is not None, (A, U, b, X_simplified))",
        "assert_(X_simplified is not None, (A,"
    ],
    [
        "assert_(sum(a * x for a, x in zip(A, X)) == b)",
        "assert_(sum(a * x for a, x in"
    ],
    [
        "err_msg = \"    \" + \"\\n    \".join([",
        "err_msg = \" \""
    ],
    [
        "easy_answer = np.may_share_memory(a, b, max_work=get_max_work(a, b))",
        "easy_answer = np.may_share_memory(a,"
    ],
    [
        "exists = (X is not None)",
        "exists = (X is"
    ],
    [
        "ranges = tuple(range(n) for n in a.shape)",
        "ranges = tuple(range(n) for n in"
    ],
    [
        "offset = sum(s * w for s, w in zip(a.strides, v))",
        "offset = sum(s * w for s, w"
    ],
    [
        "if manual_expected is not None and expected != manual_expected:",
        "if manual_expected is not None and expected !="
    ],
    [
        "from numpy.testing import extbuild, IS_WASM, IS_EDITABLE",
        "from numpy.testing import extbuild, IS_WASM,"
    ],
    [
        "from numpy.testing import assert_, assert_raises, IS_WASM",
        "from numpy.testing import assert_, assert_raises,"
    ],
    [
        "arm_softfloat = False if hosttype is None else hosttype.endswith('gnueabi')",
        "arm_softfloat = False if hosttype is"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't"
    ],
    [
        "from numpy.testing import extbuild, assert_warns, IS_WASM, IS_EDITABLE",
        "from numpy.testing import extbuild,"
    ],
    [
        "from numpy._core._simd import targets, clear_floatstatus, get_floatstatus",
        "from numpy._core._simd import targets, clear_floatstatus,"
    ],
    [
        "b = np.array([[ True, False, True],",
        "b = np.array([[ True,"
    ],
    [
        "ind = np.array([False, True, True], dtype=bool)",
        "ind = np.array([False, True, True],"
    ],
    [
        "from numpy._core import _umath_tests as ncu_tests, sctypes",
        "from numpy._core import _umath_tests"
    ],
    [
        "UFUNCS = [obj for obj in np._core.umath.__dict__.values()",
        "UFUNCS = [obj for obj"
    ],
    [
        "uf for uf in UFUNCS_UNARY if 'f->f' in uf.types",
        "uf for uf in UFUNCS_UNARY if 'f->f' in"
    ],
    [
        "return platform.processor() == 'powerpc' or \\",
        "return platform.processor() =="
    ],
    [
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)], d.max(),",
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)],"
    ],
    [
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)], d.max(),",
        "assert_(np.all(d < rtol), (np.argmax(d),"
    ],
    [
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)], d.max(),",
        "assert_(np.all(d < rtol), (np.argmax(d),"
    ],
    [
        "assert_(np.all(d < rtol), (np.argmax(d), x[np.argmax(d)], d.max(),",
        "assert_(np.all(d < rtol),"
    ],
    [
        "pytest.skip(\"Trig functions of np.clongdouble values known \"",
        "pytest.skip(\"Trig functions of np.clongdouble"
    ],
    [
        "for func in (np.arcsinh, np.arcsinh, np.arcsin, np.arctanh, np.arctan):",
        "for func in (np.arcsinh, np.arcsinh,"
    ],
    [
        "for x in nans + fins:",
        "for x in nans"
    ],
    [
        "for y in nans + fins:",
        "for y in"
    ],
    [
        "assert_equal(x < y, False, err_msg=\"%r < %r\" % (x, y))",
        "assert_equal(x < y, False, err_msg=\"%r <"
    ],
    [
        "assert_equal(x > y, False, err_msg=\"%r > %r\" % (x, y))",
        "assert_equal(x > y, False, err_msg=\"%r >"
    ],
    [
        "assert_equal(x <= y, False, err_msg=\"%r <= %r\" % (x, y))",
        "assert_equal(x <= y, False, err_msg=\"%r"
    ],
    [
        "assert_equal(x >= y, False, err_msg=\"%r >= %r\" % (x, y))",
        "assert_equal(x >= y, False, err_msg=\"%r >= %r\" % (x,"
    ],
    [
        "assert_equal(x == y, False, err_msg=\"%r == %r\" % (x, y))",
        "assert_equal(x == y, False, err_msg=\"%r =="
    ],
    [
        "@pytest.mark.skipif(IS_PYPY, reason=\"PyPy does not modify tp_doc\")",
        "@pytest.mark.skipif(IS_PYPY, reason=\"PyPy does not modify"
    ],
    [
        "from numpy.random import rand, randint, randn",
        "from numpy.random import"
    ],
    [
        "from hypothesis import given, strategies as st",
        "from hypothesis import given, strategies as"
    ],
    [
        "from hypothesis.extra import numpy as hynp",
        "from hypothesis.extra import numpy"
    ],
    [
        "match=\"You cannot specify 'newshape' and 'shape' \"",
        "match=\"You cannot specify 'newshape' and 'shape'"
    ],
    [
        "assert not np.shares_memory(np.reshape(arr, shape, copy=True), arr)",
        "assert not np.shares_memory(np.reshape(arr,"
    ],
    [
        "err_msg = \"Unable to avoid creating a copy while reshaping.\"",
        "err_msg = \"Unable to avoid creating a copy while"
    ],
    [
        "std_b = np.std(B, axis=axis, keepdims=True, mean=mean_b)",
        "std_b = np.std(B, axis=axis,"
    ],
    [
        "var_b = np.var(B, axis=axis, keepdims=True, mean=mean_b)",
        "var_b = np.var(B, axis=axis,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception support\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm"
    ],
    [
        "def assert_raises_fpe(self, fpeerr, flop, x, y):",
        "def assert_raises_fpe(self, fpeerr,"
    ],
    [
        "\"Type %s did not raise fpe error '%s'.\" % (ftype, fpeerr))",
        "\"Type %s did not raise fpe error '%s'.\" %"
    ],
    [
        "\"Type %s raised wrong fpe error '%s'.\" % (ftype, exc))",
        "\"Type %s raised wrong fpe error '%s'.\" % (ftype,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception support\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp"
    ],
    [
        "if 'bsd' in sys.platform and typecode in 'gG':",
        "if 'bsd' in sys.platform and typecode in"
    ],
    [
        "pytest.skip(reason=\"Fallback impl for (c)longdouble may not raise \"",
        "pytest.skip(reason=\"Fallback impl for (c)longdouble"
    ],
    [
        "\"FPE errors as expected on BSD OSes, \"",
        "\"FPE errors as expected on BSD OSes,"
    ],
    [
        "lambda a, b: a / b, ft_tiny, ft_max)",
        "lambda a, b: a"
    ],
    [
        "lambda a, b: a * b, ft_tiny, ft_tiny)",
        "lambda a, b: a * b, ft_tiny,"
    ],
    [
        "lambda a, b: a + b, ft_max, ft_max * ft_eps)",
        "lambda a, b: a +"
    ],
    [
        "lambda a, b: a - b, -ft_max, ft_max * ft_eps)",
        "lambda a, b: a - b, -ft_max,"
    ],
    [
        "invalid, lambda a, b: a / b, ftype(np.inf), ftype(np.inf)",
        "invalid, lambda a, b: a / b, ftype(np.inf),"
    ],
    [
        "invalid, lambda a, b: a - b, ftype(np.inf), ftype(np.inf)",
        "invalid, lambda a, b: a - b,"
    ],
    [
        "invalid, lambda a, b: a + b, ftype(np.inf), ftype(-np.inf)",
        "invalid, lambda a, b: a"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm fp exception support\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"no wasm"
    ],
    [
        "invalid_types = \"BHILQP\" + \"FDG\" + \"mM\" + \"f\" + \"V\"",
        "invalid_types = \"BHILQP\" + \"FDG\" + \"mM\" + \"f\""
    ],
    [
        "promote_types = lambda a, b: np.promote_types(b, a)",
        "promote_types = lambda a, b: np.promote_types(b,"
    ],
    [
        "dz = like_function(d, order='C', dtype=dtype, **fill_kwarg)",
        "dz = like_function(d, order='C', dtype=dtype,"
    ],
    [
        "dz = like_function(d, order='F', dtype=dtype, **fill_kwarg)",
        "dz = like_function(d, order='F',"
    ],
    [
        "dz = like_function(d, order='A', dtype=dtype, **fill_kwarg)",
        "dz = like_function(d, order='A', dtype=dtype,"
    ],
    [
        "sz = like_function(d, dtype=dtype, shape=s, order=o,",
        "sz = like_function(d, dtype=dtype,"
    ],
    [
        "if o == 'C' or (o == 'A' and d.flags.c_contiguous):",
        "if o == 'C' or (o == 'A' and"
    ],
    [
        "elif o == 'F' or (o == 'A' and d.flags.f_contiguous):",
        "elif o == 'F' or (o"
    ],
    [
        "kwargs = {'fill_value': ''} if likefunc == np.full_like else {}",
        "kwargs = {'fill_value': ''} if likefunc"
    ],
    [
        "assert_(res.shape == self.tgtshape[(i, j)], str((i, j)))",
        "assert_(res.shape == self.tgtshape[(i, j)], str((i,"
    ],
    [
        "for source, destination, expected in [",
        "for source, destination, expected"
    ],
    [
        "for source, destination, expected in [",
        "for source, destination, expected"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same number',",
        "assert_raises_regex(ValueError, 'must have"
    ],
    [
        "assert_raises_regex(ValueError, 'must have the same number',",
        "assert_raises_regex(ValueError, 'must have"
    ],
    [
        "assert \"At least one array has zero dimension\" in str(exc.value)",
        "assert \"At least one array has zero"
    ],
    [
        "for arr in np.indices(dims, dtype=dtype, sparse=True):",
        "for arr in np.indices(dims, dtype=dtype,"
    ],
    [
        "for idtype, fdtype, flag in itertools.product(id, fd, self.flag_names):",
        "for idtype, fdtype, flag in itertools.product(id,"
    ],
    [
        "assert_raises(ValueError, np.require, a, None, ['C', 'F'])",
        "assert_raises(ValueError, np.require, a, None, ['C',"
    ],
    [
        "for a, ia in zip(arrs, mit.iters):",
        "for a, ia in zip(arrs,"
    ],
    [
        "return np.ndarray.sum(self, axis, dtype, out, keepdims=True)",
        "return np.ndarray.sum(self, axis, dtype, out,"
    ],
    [
        "with pytest.raises(TypeError, match=\"Input should be a NumPy array\"):",
        "with pytest.raises(TypeError, match=\"Input should be"
    ],
    [
        "logspace, linspace, geomspace, dtype, array, arange, isnan,",
        "logspace, linspace, geomspace, dtype, array, arange,"
    ],
    [
        "[logspace(start, stop, num=num, base=_base) for _base in base],",
        "[logspace(start, stop, num=num, base=_base) for _base"
    ],
    [
        "for _stop, _base in zip(stop, base)],",
        "for _stop, _base in zip(stop,"
    ],
    [
        "from pytz import timezone as tz",
        "from pytz import timezone as"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of"
    ],
    [
        "for unit in ['Y', 'M', 'W', 'D',",
        "for unit in ['Y', 'M',"
    ],
    [
        "for larger_unit, smaller_unit in zip(larger_units, smaller_units):",
        "for larger_unit, smaller_unit in"
    ],
    [
        "\"s\", \"ms\", \"us\", \"ns\", \"ps\", \"fs\", \"as\"])",
        "\"s\", \"ms\", \"us\", \"ns\", \"ps\", \"fs\","
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones available for \""
    ],
    [
        "(\"Y\"), (\"M\"), (\"W\"), (\"D\"), (\"h\"), (\"m\"),",
        "(\"Y\"), (\"M\"), (\"W\"),"
    ],
    [
        "\"Verify that datetime dtype __setstate__ can handle bad arguments\"",
        "\"Verify that datetime dtype __setstate__ can handle bad"
    ],
    [
        "\"Error roundtripping unit %s\" % unit)",
        "\"Error roundtripping unit %s\" %"
    ],
    [
        "\"Error roundtripping unit %s\" % unit)",
        "\"Error roundtripping unit %s\""
    ],
    [
        "for tda, tdb, tdzero, tdone, tdmone in \\",
        "for tda, tdb, tdzero,"
    ],
    [
        "for dta, dtb, dtc, dtnat, tda, tdb, tdc in \\",
        "for dta, dtb, dtc, dtnat,"
    ],
    [
        "for dta, dtb, dtc, dtd, dte, dtnat, tda, tdb, tdc in \\",
        "for dta, dtb, dtc, dtd, dte, dtnat,"
    ],
    [
        "for dta, tda, tdb, tdc in \\",
        "for dta, tda, tdb, tdc"
    ],
    [
        "sup.filter(RuntimeWarning, \"invalid value encountered in multiply\")",
        "sup.filter(RuntimeWarning, \"invalid value encountered"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"does not work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"does not work in"
    ],
    [
        "for dta, tda, tdb, tdc, tdd in \\",
        "for dta, tda, tdb,"
    ],
    [
        "for op in [np.equal, np.less, np.less_equal,",
        "for op in [np.equal, np.less,"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones available for"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of timezones available for"
    ],
    [
        "for unit in ['ms', 'us', 'ns']:",
        "for unit in ['ms', 'us',"
    ],
    [
        "err_msg='Datetime conversion error for unit %s' % unit)",
        "err_msg='Datetime conversion error for"
    ],
    [
        "for us in ['us', 'μs', b'us']:",
        "for us in"
    ],
    [
        "@pytest.mark.skipif(not _has_pytz, reason=\"The pytz module is not available.\")",
        "@pytest.mark.skipif(not _has_pytz, reason=\"The pytz module is not"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "\"'remainder' cannot use operands with types\"):",
        "\"'remainder' cannot use operands with"
    ],
    [
        "msg = r\"the resolved dtypes are not compatible\"",
        "msg = r\"the resolved dtypes"
    ],
    [
        "msg = \"no explicit representation of timezones available for \" \\",
        "msg = \"no explicit representation of"
    ],
    [
        "for unit in ['Y', 'M', 'W', 'D',",
        "for unit in ['Y', 'M',"
    ],
    [
        "@pytest.mark.parametrize('unit', ['Y', 'M', 'W', 'D', 'h', 'm', 's', 'ms',",
        "@pytest.mark.parametrize('unit', ['Y', 'M', 'W', 'D',"
    ],
    [
        "from numpy.testing import assert_array_equal, IS_WASM, IS_EDITABLE",
        "from numpy.testing import assert_array_equal,"
    ],
    [
        "from Cython.Compiler.Version import version as cython_version",
        "from Cython.Compiler.Version import version as"
    ],
    [
        "pytestmark = pytest.mark.skipif(cython is None, reason=\"requires cython\")",
        "pytestmark = pytest.mark.skipif(cython is None, reason=\"requires"
    ],
    [
        "\"Editable install doesn't support tests with a compile step\",",
        "\"Editable install doesn't support tests"
    ],
    [
        "for x, y in zip(bcast.iters, checks.get_multiiter_iters(bcast))",
        "for x, y"
    ],
    [
        "assert checks.get_npyiter_size(it) == it.itersize == np.prod(arr.shape)",
        "assert checks.get_npyiter_size(it) =="
    ],
    [
        "assert checks.npyiter_has_index(it) == it.has_index == False",
        "assert checks.npyiter_has_index(it) =="
    ],
    [
        "assert checks.npyiter_has_index(it) == it.has_index == True",
        "assert checks.npyiter_has_index(it) == it.has_index =="
    ],
    [
        "assert checks.get_npyiter_size(it) == it.itersize == np.prod(arr.shape)",
        "assert checks.get_npyiter_size(it) == it.itersize =="
    ],
    [
        "assert checks.npyiter_has_multi_index(it) == it.has_multi_index == True",
        "assert checks.npyiter_has_multi_index(it) == it.has_multi_index"
    ],
    [
        "x is y for x, y in zip(checks.get_npyiter_operands(it), it.operands)",
        "x is y for x,"
    ],
    [
        "for x, y in zip(checks.get_npyiter_itviews(it), it.itviews)",
        "for x, y in"
    ],
    [
        "arr = np.array(['abcd', 'b', 'c'], dtype='T')",
        "arr = np.array(['abcd', 'b', 'c'],"
    ],
    [
        "xfail_complex_tests = (not sys.platform.startswith('linux') or functions_seem_flaky)",
        "xfail_complex_tests = (not"
    ],
    [
        "msgform = \"cexp(inf, inf) is (%f, %f), expected (+-inf, nan)\"",
        "msgform = \"cexp(inf, inf) is"
    ],
    [
        "if not np.isinf(z.real) or not np.isnan(z.imag):",
        "if not np.isinf(z.real)"
    ],
    [
        "msgform = \"cexp(-inf, nan) is (%f, %f), expected (+-inf, nan)\"",
        "msgform = \"cexp(-inf, nan) is (%f, %f), expected"
    ],
    [
        "if not np.isinf(z.real) or not np.isnan(z.imag):",
        "if not np.isinf(z.real) or"
    ],
    [
        "msgform = \"csqrt(-inf, nan) is (%f, %f), expected (nan, +-inf)\"",
        "msgform = \"csqrt(-inf, nan) is (%f,"
    ],
    [
        "n_r = [x[i] ** y[i] for i in lx]",
        "n_r = [x[i] ** y[i] for i in"
    ],
    [
        "assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' % i)",
        "assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n'"
    ],
    [
        "assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n' % i)",
        "assert_almost_equal(n_r[i], p_r[i], err_msg='Loop %d\\n'"
    ],
    [
        "assert len(xa) == len(x) == len(y)",
        "assert len(xa) =="
    ],
    [
        "for xi, yi in zip(x, y):",
        "for xi, yi"
    ],
    [
        "reason=\"Complex arithmetic with signed zero fails on most platforms\")",
        "reason=\"Complex arithmetic with signed zero"
    ],
    [
        "match=\"error raised inside the core-loop: non-finite factor!\"):",
        "match=\"error raised inside the"
    ],
    [
        "match=\"the resolved dtypes are not compatible\"):",
        "match=\"the resolved dtypes are"
    ],
    [
        "_vec_string([['abc', 'def']], np.int_, 'find', (['a', 'd', 'j'],))",
        "_vec_string([['abc', 'def']], np.int_, 'find', (['a', 'd',"
    ],
    [
        "[[True, True, False], [True, True, True]])",
        "[[True, True, False],"
    ],
    [
        "[[False, False, True], [False, False, False]])",
        "[[False, False, True], [False, False,"
    ],
    [
        "[[False, False, True], [True, False, True]])",
        "[[False, False, True], [True, False,"
    ],
    [
        "[[True, True, True], [False, True, False]])",
        "[[True, True, True], [False, True,"
    ],
    [
        "[[False, False, False], [True, False, True]])",
        "[[False, False, False], [True,"
    ],
    [
        "[[True, True, False], [False, True, False]])",
        "[[True, True, False], [False, True,"
    ],
    [
        "self.A = np.array([[' abc ', ''],",
        "self.A = np.array([[' abc"
    ],
    [
        "assert_array_equal(self.A.isalnum(), [[False, False], [True, True], [False, True]])",
        "assert_array_equal(self.A.isalnum(), [[False, False], [True, True],"
    ],
    [
        "assert_array_equal(self.A.isalpha(), [[False, False], [False, True], [False, True]])",
        "assert_array_equal(self.A.isalpha(), [[False, False], [False, True],"
    ],
    [
        "assert_array_equal(self.A.isdigit(), [[False, False], [True, False], [False, False]])",
        "assert_array_equal(self.A.isdigit(), [[False, False], [True,"
    ],
    [
        "assert_array_equal(self.A.islower(), [[True, False], [False, False], [False, False]])",
        "assert_array_equal(self.A.islower(), [[True, False], [False,"
    ],
    [
        "assert_array_equal(self.A.isspace(), [[False, False], [False, False], [False, False]])",
        "assert_array_equal(self.A.isspace(), [[False, False], [False, False], [False,"
    ],
    [
        "assert_array_equal(self.A.istitle(), [[False, False], [False, False], [False, False]])",
        "assert_array_equal(self.A.istitle(), [[False, False], [False, False], [False,"
    ],
    [
        "assert_array_equal(self.A.isupper(), [[False, False], [False, False], [False, True]])",
        "assert_array_equal(self.A.isupper(), [[False, False], [False,"
    ],
    [
        "self.A = np.array([[' abc ', ''],",
        "self.A = np.array([[' abc ',"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b' abc"
    ],
    [
        "tgt = [[b'   FOO    ', b'        FOO         '],",
        "tgt = [[b' FOO"
    ],
    [
        "[b'      FOO      ', b'  FOO   ']]",
        "[b' FOO ',"
    ],
    [
        "tgt = np.array([[' ,a,b,c, ', ''],",
        "tgt = np.array([['"
    ],
    [
        "[False, True], [False, False], [False, False]])",
        "[False, True], [False, False],"
    ],
    [
        "tgt = [[b'FOO       ', b'FOO                 '],",
        "tgt = [[b'FOO ', b'FOO"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b' abc"
    ],
    [
        "tgt = [[(b' abc ', b'', b''), (b'', b'', b'')],",
        "tgt = [[(b' abc ', b'',"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b' abc"
    ],
    [
        "[[False, True], [False, False], [False, False]])",
        "[[False, True], [False, False],"
    ],
    [
        "tgt = [[b'       FOO', b'                 FOO'],",
        "tgt = [[b' FOO', b'"
    ],
    [
        "tgt = [[(b'', b'', b' abc '), (b'', b'', b'')],",
        "tgt = [[(b'', b'', b' abc"
    ],
    [
        "tgt = [[[b' abc '], [b'']],",
        "tgt = [[[b' abc '],"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b' abc"
    ],
    [
        "tgt = [[b' abc ', b''],",
        "tgt = [[b'"
    ],
    [
        "tgt = [[b' ABC ', b''],",
        "tgt = [[b' ABC"
    ],
    [
        "tgt = [[b' Abc ', b''],",
        "tgt = [[b'"
    ],
    [
        "tgt = [[b' ABC ', b''],",
        "tgt = [[b'"
    ],
    [
        "[False, False], [True, False], [False, False]])",
        "[False, False], [True,"
    ],
    [
        "[False, False], [True, False], [False, False]])",
        "[False, False], [True, False], [False,"
    ],
    [
        "arr = np.array([['abc ', 'def '], ['geh ', 'ijk ']],",
        "arr = np.array([['abc ', 'def"
    ],
    [
        "A = np.array([[' abc ', ''],",
        "A = np.array([[' abc ',"
    ],
    [
        "s = \"\\tone level of indentation\\n\\t\\ttwo levels of indentation\"",
        "s = \"\\tone level of indentation\\n\\t\\ttwo levels of"
    ],
    [
        "\"  one level of indentation\\n    two levels of indentation\"",
        "\" one level of indentation\\n two levels"
    ],
    [
        "f\"{t.__name__} is not instance of Real\")",
        "f\"{t.__name__} is not instance"
    ],
    [
        "f\"{t.__name__} is not subclass of Real\")",
        "f\"{t.__name__} is not subclass of"
    ],
    [
        "f\"{t.__name__} is not instance of Complex\")",
        "f\"{t.__name__} is not instance of"
    ],
    [
        "f\"{t.__name__} is not subclass of Complex\")",
        "f\"{t.__name__} is not subclass of"
    ],
    [
        "f\"{t.__name__} is not instance of Integral\")",
        "f\"{t.__name__} is not instance of"
    ],
    [
        "f\"{t.__name__} is not subclass of Integral\")",
        "f\"{t.__name__} is not subclass of"
    ],
    [
        "f\"{t.__name__} is not instance of Integral\")",
        "f\"{t.__name__} is not"
    ],
    [
        "f\"{t.__name__} is not subclass of Integral\")",
        "f\"{t.__name__} is not"
    ],
    [
        "UNARY_UFUNCS = [obj for obj in np._core.umath.__dict__.values()",
        "UNARY_UFUNCS = [obj for"
    ],
    [
        "UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if \"O->O\" in uf.types]",
        "UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if \"O->O\" in"
    ],
    [
        "@pytest.mark.skipif(IS_PYPY, reason=\"'is' check does not work on PyPy\")",
        "@pytest.mark.skipif(IS_PYPY, reason=\"'is' check does"
    ],
    [
        "expected = np.einsum('...i,ij,...j', vec.conj(), mat, vec)",
        "expected = np.einsum('...i,ij,...j', vec.conj(),"
    ],
    [
        "with pytest.raises(TypeError, match=r\"\\*: 'float' and 'NoneType'\"):",
        "with pytest.raises(TypeError, match=r\"\\*:"
    ],
    [
        "msg = \"extend & broadcast loop dimensions\"",
        "msg = \"extend & broadcast"
    ],
    [
        "msg = \"type cast on one argument\"",
        "msg = \"type cast on"
    ],
    [
        "msg = \"incontiguous memory layout of array\"",
        "msg = \"incontiguous memory layout of"
    ],
    [
        "msg = \"output argument with type cast\"",
        "msg = \"output argument with"
    ],
    [
        "msg = \"output argument with incontiguous layout\"",
        "msg = \"output argument with"
    ],
    [
        "assert_raises(TypeError, mm, a, b, axes=[None, None, None])",
        "assert_raises(TypeError, mm, a, b, axes=[None,"
    ],
    [
        "d = np.vecdot(a, b, keepdims=True, out=out)",
        "d = np.vecdot(a, b, keepdims=True,"
    ],
    [
        "np.array([x or None for x in a], dtype=object))",
        "np.array([x or None for x in"
    ],
    [
        "np.array([x or True for x in a], dtype=object))",
        "np.array([x or True for x in a],"
    ],
    [
        "np.array([x or \"blah\" for x in a], dtype=object))",
        "np.array([x or \"blah\" for x in"
    ],
    [
        "np.array([x and None for x in a], dtype=object))",
        "np.array([x and None for"
    ],
    [
        "np.array([x and True for x in a], dtype=object))",
        "np.array([x and True for x"
    ],
    [
        "np.array([x and \"blah\" for x in a], dtype=object))",
        "np.array([x and \"blah\" for x in a],"
    ],
    [
        "np.array([not x for x in a], dtype=object))",
        "np.array([not x for x in"
    ],
    [
        "a = np.array(['a', 'b', 'c'], dtype=object)",
        "a = np.array(['a', 'b', 'c'],"
    ],
    [
        "a = np.array([True, False, True], dtype=object)",
        "a = np.array([True,"
    ],
    [
        "for a in [[], np.array([], dtype=object)]:",
        "for a in"
    ],
    [
        "from hypothesis.extra import numpy as hynp",
        "from hypothesis.extra import"
    ],
    [
        "\"two equivalent types do not hash to the same value !\")",
        "\"two equivalent types do not hash to the"
    ],
    [
        "\"two different types hash to the same value !\")",
        "\"two different types hash to"
    ],
    [
        "d = {\"names\": names, \"formats\": formats, \"titles\": titles, \"offsets\": offsets}",
        "d = {\"names\": names, \"formats\":"
    ],
    [
        "refcounts = {k: sys.getrefcount(i) for k, i in d.items()}",
        "refcounts = {k: sys.getrefcount(i) for"
    ],
    [
        "refcounts_new = {k: sys.getrefcount(i) for k, i in d.items()}",
        "refcounts_new = {k: sys.getrefcount(i) for"
    ],
    [
        "with pytest.raises(ValueError, match=\"must replace all names at once\"):",
        "with pytest.raises(ValueError, match=\"must replace all"
    ],
    [
        "def test_structured_object_item_setting(self, dt, pat, count, singleton):",
        "def test_structured_object_item_setting(self, dt,"
    ],
    [
        "def test_structured_object_take_and_repeat(self, dt, pat, count, singleton):",
        "def test_structured_object_take_and_repeat(self, dt,"
    ],
    [
        "'titles': ['Red pixel', 'Green pixel', 'Blue pixel']})",
        "'titles': ['Red pixel', 'Green pixel', 'Blue"
    ],
    [
        "dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],",
        "dt = np.dtype({'names': ['rgba',"
    ],
    [
        "\" 'titles': ['Color', 'Red pixel', \"",
        "\" 'titles': ['Color', 'Red"
    ],
    [
        "\" 'titles': ['Red pixel', 'Blue pixel'],\"",
        "\" 'titles': ['Red"
    ],
    [
        "'titles': ['Red pixel', 'Green pixel', 'Blue pixel']},",
        "'titles': ['Red pixel', 'Green pixel',"
    ],
    [
        "dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],",
        "dt = np.dtype({'names': ['rgba', 'r',"
    ],
    [
        "\" 'titles': ['Color', 'Red pixel', \"",
        "\" 'titles': ['Color', 'Red pixel',"
    ],
    [
        "\"'titles': ['Red pixel', 'Blue pixel'], \"",
        "\"'titles': ['Red pixel',"
    ],
    [
        "attr = [\"subdtype\", \"descr\", \"str\", \"name\", \"base\", \"shape\",",
        "attr = [\"subdtype\", \"descr\","
    ],
    [
        "from ctypes import c_longlong, c_double, c_float, c_int, cast, pointer, POINTER",
        "from ctypes import c_longlong, c_double, c_float, c_int,"
    ],
    [
        "UNARY_UFUNCS = [obj for obj in np._core.umath.__dict__.values() if",
        "UNARY_UFUNCS = [obj for obj in np._core.umath.__dict__.values()"
    ],
    [
        "UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if \"O->O\" in uf.types]",
        "UNARY_OBJECT_UFUNCS = [uf for uf in UNARY_UFUNCS if"
    ],
    [
        "files = list(filter(lambda f: f.endswith('.csv'), files))",
        "files = list(filter(lambda f:"
    ],
    [
        "for ftype in np._core.sctypes['float'] + np._core.sctypes['complex']:",
        "for ftype in np._core.sctypes['float'] +"
    ],
    [
        "from numpy.testing._private.utils import get_stringdtype_dtype as get_dtype",
        "from numpy.testing._private.utils import get_stringdtype_dtype as"
    ],
    [
        "params=[\"unset\", None, pd_NA, np.nan, float(\"nan\"), \"__nan__\"],",
        "params=[\"unset\", None, pd_NA,"
    ],
    [
        "ids=[\"unset\", \"None\", \"pandas.NA\", \"np.nan\", \"float('nan')\", \"string nan\"],",
        "ids=[\"unset\", \"None\", \"pandas.NA\", \"np.nan\", \"float('nan')\", \"string"
    ],
    [
        "assert not hasattr(dt, \"na_object\") and dt.coerce is True",
        "assert not hasattr(dt, \"na_object\") and dt.coerce"
    ],
    [
        "assert dt.na_object is None and dt.coerce is True",
        "assert dt.na_object is None and dt.coerce is"
    ],
    [
        "assert not hasattr(dt, \"na_object\") and dt.coerce is False",
        "assert not hasattr(dt, \"na_object\")"
    ],
    [
        "assert dt.na_object is None and dt.coerce is False",
        "assert dt.na_object is None and dt.coerce"
    ],
    [
        "if not hasattr(dtype, \"na_object\") and dtype.coerce:",
        "if not hasattr(dtype, \"na_object\") and"
    ],
    [
        "pytest.skip(\"does not have an na object\")",
        "pytest.skip(\"does not have"
    ],
    [
        "assert str(arr) == \"[\" + \" \".join([repr(s) for s in string_list]) + \"]\"",
        "assert str(arr) == \"[\" + \" \".join([repr(s) for"
    ],
    [
        "strings = [s_medium, s_empty, s_short, s_medium, s_long]",
        "strings = [s_medium, s_empty, s_short, s_medium,"
    ],
    [
        "for s in [a[i], s_medium + s_short, s_short, s_empty, s_long]:",
        "for s in [a[i], s_medium + s_short, s_short,"
    ],
    [
        "arr = np.array([\"a\", \"b\", \"c\"], dtype=StringDType())",
        "arr = np.array([\"a\", \"b\", \"c\"],"
    ],
    [
        "assert str(arr) == \"[\" + \" \".join([\"'\" + str(d) + \"'\" for d in data]) + \"]\"",
        "assert str(arr) == \"[\" + \" \".join([\"'\" + str(d)"
    ],
    [
        "str_vals = [str(d) for d in data]",
        "str_vals = [str(d) for"
    ],
    [
        "[\"A¢☃€ 😊\", \" A☃€¢😊\", \"☃€😊 A¢\", \"😊☃A¢ €\"],",
        "[\"A¢☃€ 😊\", \" A☃€¢😊\", \"☃€😊 A¢\","
    ],
    [
        "[\"A¢☃€ 😊\", \" A☃€¢😊\", \"☃€😊 A¢\", \"😊☃A¢ €\"],",
        "[\"A¢☃€ 😊\", \" A☃€¢😊\", \"☃€😊"
    ],
    [
        "if na_object is None and None in strings:",
        "if na_object is None and None"
    ],
    [
        "match=\"Cannot compare null that is not a nan-like value\",",
        "match=\"Cannot compare null that is"
    ],
    [
        "elif na_object is pd_NA or na_object != '':",
        "elif na_object is pd_NA or na_object !="
    ],
    [
        "if na_object is None and None in strings:",
        "if na_object is None and None"
    ],
    [
        "match=\"Cannot compare null that is not a nan-like value\",",
        "match=\"Cannot compare null that is not a nan-like"
    ],
    [
        "[\"A¢☃€ 😊\", \" A☃€¢😊\", \"☃€😊 A¢\", \"😊☃A¢ €\"],",
        "[\"A¢☃€ 😊\", \" A☃€¢😊\","
    ],
    [
        "[\"A¢☃€ 😊\", \"\", \" \", \" \"],",
        "[\"A¢☃€ 😊\", \"\", \""
    ],
    [
        "if na_object is not pd_NA and na_object == 'unset':",
        "if na_object is not pd_NA"
    ],
    [
        "strings_with_na = np.array(strings + [na_object], dtype=dtype)",
        "strings_with_na = np.array(strings + [na_object],"
    ],
    [
        "res = np.where([True, False, True, False, True, False], a, b)",
        "res = np.where([True, False, True, False, True, False], a,"
    ],
    [
        "for b in [rop, np.array(rop, dtype=\"T\")]:",
        "for b in [rop,"
    ],
    [
        "sarr_cat = np.array(string_list + string_list, dtype=\"T\")",
        "sarr_cat = np.array(string_list"
    ],
    [
        "with pytest.raises(ValueError, match=\"Unable to avoid copy\"):",
        "with pytest.raises(ValueError, match=\"Unable to"
    ],
    [
        "[\"left\", \"right\", \"leftovers\", \"righty\", \"up\", \"down\"],",
        "[\"left\", \"right\", \"leftovers\", \"righty\","
    ],
    [
        "[\"A¢☃€ 😊\", \" A☃€¢😊\", \"☃€😊 A¢\", \"😊☃A¢ €\"],",
        "[\"A¢☃€ 😊\", \" A☃€¢😊\","
    ],
    [
        "ufunc = getattr(np, ufunc_name + \"imum\")",
        "ufunc = getattr(np,"
    ],
    [
        "arr = np.array(['y', 'y', 'z'], dtype=\"T\")",
        "arr = np.array(['y', 'y', 'z'],"
    ],
    [
        "[\"🚜\", \"🙃\", \"😾\", \"😹\", \"🚠\", \"🚌\"],",
        "[\"🚜\", \"🙃\", \"😾\", \"😹\", \"🚠\","
    ],
    [
        "[\"🥦\", \"¨\", \"⨯\", \"∰ \", \"⨌ \", \"⎶ \"],",
        "[\"🥦\", \"¨\", \"⨯\", \"∰ \", \"⨌ \", \"⎶"
    ],
    [
        "is_nan = isinstance(dtype.na_object, float) and np.isnan(dtype.na_object)",
        "is_nan = isinstance(dtype.na_object,"
    ],
    [
        "if is_nan or bool_errors or is_str:",
        "if is_nan or bool_errors"
    ],
    [
        "values = [\"a\", \"this is a long string\", \"c\"]",
        "values = [\"a\", \"this is a long"
    ],
    [
        "lresult = np.array([\"hello\" + s for s in string_list], dtype=StringDType())",
        "lresult = np.array([\"hello\" + s for"
    ],
    [
        "rresult = np.array([s + \"hello\" for s in string_list], dtype=StringDType())",
        "rresult = np.array([s + \"hello\" for s in string_list],"
    ],
    [
        "for op in [\"hello\", np.str_(\"hello\"), np.array([\"hello\"])]:",
        "for op in [\"hello\", np.str_(\"hello\"),"
    ],
    [
        "np.add(arr, \"add\", signature=(\"U\", \"U\", None), casting=\"unsafe\")",
        "np.add(arr, \"add\", signature=(\"U\","
    ],
    [
        "with pytest.raises(TypeError, match=\".*did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\".*did not contain"
    ],
    [
        "with pytest.raises(TypeError, match=\".*did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\".*did not"
    ],
    [
        "with pytest.raises(TypeError, match=\".*did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\".*did not contain a"
    ],
    [
        "with pytest.raises(TypeError, match=\"the resolved dtypes are not\"):",
        "with pytest.raises(TypeError, match=\"the resolved"
    ],
    [
        "assert res == val * np.prod(repeats)",
        "assert res =="
    ],
    [
        "def test_ufunc_multiply(dtype, string_list, other, other_dtype, use_out):",
        "def test_ufunc_multiply(dtype, string_list,"
    ],
    [
        "from numpy.testing import assert_array_equal, assert_raises, IS_PYPY",
        "from numpy.testing import"
    ],
    [
        "with pytest.raises(TypeError, match=\"did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\"did not contain"
    ],
    [
        "with pytest.raises(TypeError, match=\"did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\"did not contain a"
    ],
    [
        "def test_string_comparisons(op, ufunc, sym, dtypes, aligned):",
        "def test_string_comparisons(op, ufunc, sym,"
    ],
    [
        "arr = np.array([np.nan, np.inf, -np.inf, fi.max, fi.min], dtype=float_dt)",
        "arr = np.array([np.nan, np.inf, -np.inf,"
    ],
    [
        "expected = [\"nan\", \"inf\", \"-inf\", str(fi.max), str(fi.min)]",
        "expected = [\"nan\", \"inf\", \"-inf\", str(fi.max),"
    ],
    [
        "pytest.skip(\"python failed to create huge string\")",
        "pytest.skip(\"python failed to create huge"
    ],
    [
        "raise AssertionError(\"Ops should raise before any large allocation.\")",
        "raise AssertionError(\"Ops should raise"
    ],
    [
        "a = np.array([\"A\" * very_large], dtype=str_dt)",
        "a = np.array([\"A\" *"
    ],
    [
        "raise AssertionError(\"Ops should raise before any large allocation.\")",
        "raise AssertionError(\"Ops should raise before any large"
    ],
    [
        "([\"abc\", \"def\"], [\"hello\", \"world\"], [\"abchello\", \"defworld\"]),",
        "([\"abc\", \"def\"], [\"hello\", \"world\"], [\"abchello\","
    ],
    [
        "def test_find(self, a, sub, start, end, out, dt):",
        "def test_find(self, a, sub, start, end, out,"
    ],
    [
        "if \"😊\" in a and dt == \"S\":",
        "if \"😊\" in a and dt"
    ],
    [
        "pytest.skip(\"Bytes dtype does not support non-ascii input\")",
        "pytest.skip(\"Bytes dtype does not support"
    ],
    [
        "def test_rfind(self, a, sub, start, end, out, dt):",
        "def test_rfind(self, a, sub, start, end,"
    ],
    [
        "if \"😊\" in a and dt == \"S\":",
        "if \"😊\" in a and dt"
    ],
    [
        "pytest.skip(\"Bytes dtype does not support non-ascii input\")",
        "pytest.skip(\"Bytes dtype does not support non-ascii"
    ],
    [
        "def test_count(self, a, sub, start, end, out, dt):",
        "def test_count(self, a, sub,"
    ],
    [
        "if \"😊\" in a and dt == \"S\":",
        "if \"😊\" in a and dt"
    ],
    [
        "pytest.skip(\"Bytes dtype does not support non-ascii input\")",
        "pytest.skip(\"Bytes dtype does not support"
    ],
    [
        "def test_startswith(self, a, prefix, start, end, out, dt):",
        "def test_startswith(self, a, prefix, start, end, out,"
    ],
    [
        "def test_endswith(self, a, suffix, start, end, out, dt):",
        "def test_endswith(self, a, suffix,"
    ],
    [
        "(\"   hello   \", None, \"hello   \"),",
        "(\" hello \", None, \"hello"
    ],
    [
        "(\" \\t\\n\\r\\f\\vabc \\t\\n\\r\\f\\v\", None, \"abc \\t\\n\\r\\f\\v\"),",
        "(\" \\t\\n\\r\\f\\vabc \\t\\n\\r\\f\\v\","
    ],
    [
        "([\"   hello   \", \"hello\"], None, [\"hello   \", \"hello\"]),",
        "([\" hello \", \"hello\"], None, [\"hello"
    ],
    [
        "([\"ba\", \"ac\", \"baa\", \"bba\"], \"b\", [\"a\", \"ac\", \"aa\", \"a\"]),",
        "([\"ba\", \"ac\", \"baa\", \"bba\"], \"b\", [\"a\", \"ac\", \"aa\","
    ],
    [
        "def test_lstrip(self, a, chars, out, dt):",
        "def test_lstrip(self, a, chars, out,"
    ],
    [
        "(\"   hello   \", None, \"   hello\"),",
        "(\" hello \","
    ],
    [
        "(\" \\t\\n\\r\\f\\vabc \\t\\n\\r\\f\\v\", None, \" \\t\\n\\r\\f\\vabc\"),",
        "(\" \\t\\n\\r\\f\\vabc \\t\\n\\r\\f\\v\", None,"
    ],
    [
        "([\"   hello   \", \"hello\"], None, [\"   hello\", \"hello\"]),",
        "([\" hello \", \"hello\"],"
    ],
    [
        "([\"ab\", \"ac\", \"aab\", \"abb\"], \"b\", [\"a\", \"ac\", \"aa\", \"a\"]),",
        "([\"ab\", \"ac\", \"aab\", \"abb\"], \"b\", [\"a\", \"ac\", \"aa\","
    ],
    [
        "def test_rstrip(self, a, chars, out, dt):",
        "def test_rstrip(self, a,"
    ],
    [
        "([\"   hello   \", \"hello\"], None, [\"hello\", \"hello\"]),",
        "([\" hello \", \"hello\"], None,"
    ],
    [
        "([\"bab\", \"ac\", \"baab\", \"bbabb\"], \"b\", [\"a\", \"ac\", \"aa\", \"a\"]),",
        "([\"bab\", \"ac\", \"baab\", \"bbabb\"], \"b\", [\"a\", \"ac\","
    ],
    [
        "def test_strip(self, a, chars, out, dt):",
        "def test_strip(self, a, chars, out,"
    ],
    [
        "def test_replace(self, buf, old, new, count, res, dt):",
        "def test_replace(self, buf, old, new, count, res,"
    ],
    [
        "if \"😊\" in buf and dt == \"S\":",
        "if \"😊\" in buf and"
    ],
    [
        "pytest.skip(\"Bytes dtype does not support non-ascii input\")",
        "pytest.skip(\"Bytes dtype does not"
    ],
    [
        "def test_index(self, buf, sub, start, end, res, dt):",
        "def test_index(self, buf, sub, start,"
    ],
    [
        "def test_index_raises(self, buf, sub, start, end, dt):",
        "def test_index_raises(self, buf, sub,"
    ],
    [
        "def test_rindex(self, buf, sub, start, end, res, dt):",
        "def test_rindex(self, buf, sub, start,"
    ],
    [
        "def test_rindex_raises(self, buf, sub, start, end, dt):",
        "def test_rindex_raises(self, buf, sub,"
    ],
    [
        "def test_expandtabs(self, buf, tabsize, res, dt):",
        "def test_expandtabs(self, buf, tabsize,"
    ],
    [
        "with pytest.raises(OverflowError, match=\"new string is too long\"):",
        "with pytest.raises(OverflowError, match=\"new string is"
    ],
    [
        "FILL_ERROR = \"The fill character must be exactly one character long\"",
        "FILL_ERROR = \"The fill character must be"
    ],
    [
        "def test_center(self, buf, width, fillchar, res, dt):",
        "def test_center(self, buf, width,"
    ],
    [
        "def test_ljust(self, buf, width, fillchar, res, dt):",
        "def test_ljust(self, buf, width, fillchar,"
    ],
    [
        "def test_rjust(self, buf, width, fillchar, res, dt):",
        "def test_rjust(self, buf, width,"
    ],
    [
        "def test_zfill(self, buf, width, res, dt):",
        "def test_zfill(self, buf,"
    ],
    [
        "(\"this is the partition method\", \"ti\", \"this is the par\",",
        "(\"this is the partition method\", \"ti\","
    ],
    [
        "(\"this is the partition method\", \"ti\", \"this is the parti\",",
        "(\"this is the partition method\", \"ti\", \"this"
    ],
    [
        "bcast_args = tuple(np.broadcast_to(arg, buf.shape) for arg in args)",
        "bcast_args = tuple(np.broadcast_to(arg, buf.shape)"
    ],
    [
        "for s, arg in zip(buf, zip(*bcast_args))],",
        "for s, arg"
    ],
    [
        "with pytest.raises(TypeError, match=\"did not contain a loop\"):",
        "with pytest.raises(TypeError, match=\"did not contain a"
    ],
    [
        "np.strings.slice(np.array(['foo', 'bar'], dtype=dt), np.array(['foo', 'bar'], dtype=dt))",
        "np.strings.slice(np.array(['foo', 'bar'], dtype=dt),"
    ],
    [
        "def test_replace_unicode(self, buf, old, new, count, res, dt):",
        "def test_replace_unicode(self, buf, old,"
    ],
    [
        "def test_index_unicode(self, buf, sub, start, end, res, dt):",
        "def test_index_unicode(self, buf, sub,"
    ],
    [
        "def test_center(self, buf, width, fillchar, res, dt):",
        "def test_center(self, buf, width,"
    ],
    [
        "def test_ljust(self, buf, width, fillchar, res, dt):",
        "def test_ljust(self, buf, width, fillchar, res,"
    ],
    [
        "def test_rjust(self, buf, width, fillchar, res, dt):",
        "def test_rjust(self, buf, width, fillchar, res,"
    ],
    [
        "def test_strip_functions_unicode(self, source, strip, method, dt):",
        "def test_strip_functions_unicode(self, source, strip,"
    ],
    [
        "buf = np.array([\"Приве́т नमस्ते שָׁלוֹם\", \"😀😃😄😁😆😅🤣😂🙂🙃\"],",
        "buf = np.array([\"Приве́т नमस्ते שָׁלוֹם\","
    ],
    [
        "bcast_args = tuple(np.broadcast_to(arg, buf.shape) for arg in args)",
        "bcast_args = tuple(np.broadcast_to(arg, buf.shape) for"
    ],
    [
        "for s, arg in zip(buf, zip(*bcast_args))],",
        "for s, arg in zip(buf,"
    ],
    [
        "with pytest.raises(ValueError, match=\"'ascii' codec can't encode\"):",
        "with pytest.raises(ValueError, match=\"'ascii'"
    ],
    [
        "with pytest.raises(ValueError, match=\"'ascii' codec can't encode\"):",
        "with pytest.raises(ValueError, match=\"'ascii' codec can't"
    ],
    [
        "with pytest.raises(ValueError, match=\"'ascii' codec can't encode\"):",
        "with pytest.raises(ValueError, match=\"'ascii' codec can't"
    ],
    [
        "\"Output indices do not map to the correct dimensions. Expected: \"",
        "\"Output indices do not map to"
    ],
    [
        "assert_raises(CustomException, np.einsum, \"ij, j\", a, b)",
        "assert_raises(CustomException, np.einsum, \"ij, j\", a,"
    ],
    [
        "assert_raises(CustomException, np.einsum, \"ij, jh\", a, a)",
        "assert_raises(CustomException, np.einsum, \"ij, jh\", a,"
    ],
    [
        "a = np.arange(n * n, dtype=dtype).reshape(n, n)",
        "a = np.arange(n * n, dtype=dtype).reshape(n,"
    ],
    [
        "assert_equal(np.einsum(\"...i, ...i\", a, b, optimize=do_opt), np.inner(a, b))",
        "assert_equal(np.einsum(\"...i, ...i\", a, b,"
    ],
    [
        "assert_equal(np.einsum(\"ijk, jil -> kl\", a, b),",
        "assert_equal(np.einsum(\"ijk, jil -> kl\","
    ],
    [
        "c = np.array([True, True, False, True, True, False, True, True])",
        "c = np.array([True, True, False, True, True, False, True,"
    ],
    [
        "assert_equal(np.einsum(\"i,i\", a, a, optimize=do_opt), np.dot(a, a))",
        "assert_equal(np.einsum(\"i,i\", a, a,"
    ],
    [
        "b = np.einsum(\"i->\", a, dtype=dtype, casting='unsafe')",
        "b = np.einsum(\"i->\","
    ],
    [
        "ref = np.einsum('ijk,j->ijk', A, B, optimize=False)",
        "ref = np.einsum('ijk,j->ijk', A,"
    ],
    [
        "ref = np.einsum('ik,kj->ij', A, B, optimize=False)",
        "ref = np.einsum('ik,kj->ij',"
    ],
    [
        "ref = np.einsum('ijkl,k->ijl', a, v, optimize=False)",
        "ref = np.einsum('ijkl,k->ijl', a, v,"
    ],
    [
        "ref = np.einsum('...lmn,...lmno->...o', A, B, optimize=False)",
        "ref = np.einsum('...lmn,...lmno->...o', A, B,"
    ],
    [
        "es = np.einsum('cl, cpx->lpx',  A,  B)",
        "es = np.einsum('cl, cpx->lpx', A,"
    ],
    [
        "es = np.einsum('cl, cpxy->lpxy',  A, B)",
        "es = np.einsum('cl,"
    ],
    [
        "assert np.einsum('i,i->', arr, arr) == (arr * arr).sum()",
        "assert np.einsum('i,i->', arr, arr)"
    ],
    [
        "assert res == np.einsum('i->', scalar * arr)",
        "assert res == np.einsum('i->',"
    ],
    [
        "assert res == np.einsum('i->', scalar * arr)",
        "assert res == np.einsum('i->', scalar *"
    ],
    [
        "res = np.einsum('i,i,i->', arr, arr, arr)",
        "res = np.einsum('i,i,i->',"
    ],
    [
        "assert_array_equal(res, (arr * arr * arr).sum())",
        "assert_array_equal(res, (arr * arr"
    ],
    [
        "res = np.einsum('i,i,i,i->', arr, arr, arr, arr)",
        "res = np.einsum('i,i,i,i->', arr, arr, arr,"
    ],
    [
        "assert_array_equal(res, (arr * arr * arr * arr).sum())",
        "assert_array_equal(res, (arr * arr *"
    ],
    [
        "res = np.einsum('...ij,...jk->...ik', a, a, out=out)",
        "res = np.einsum('...ij,...jk->...ik', a, a,"
    ],
    [
        "res = np.einsum('...ij,...jk->...ik', a, a, out=a)",
        "res = np.einsum('...ij,...jk->...ik',"
    ],
    [
        "dims = [global_size_dict[x] for x in term]",
        "dims = [global_size_dict[x] for x"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='a', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a, b,"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='f', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a,"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='c', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a, b,"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, order='k', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a,"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, b, optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a, b,"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', a, c, order='a', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', a, c, order='a',"
    ],
    [
        "tmp = np.einsum('...ft,mf->...mt', d, c, order='a', optimize=opt)",
        "tmp = np.einsum('...ft,mf->...mt', d, c, order='a',"
    ],
    [
        "dims = [size_dict[x] for x in term]",
        "dims = [size_dict[x] for x in"
    ],
    [
        "c = np.einsum('ij,jk->ik', a, b, out=b)",
        "c = np.einsum('ij,jk->ik', a,"
    ],
    [
        "o = type(\"o\", (object,), {\"__array__\": custom__array__})()",
        "o = type(\"o\","
    ],
    [
        "[True, True, True, True, True, True, False, False],",
        "[True, True, True, True,"
    ],
    [
        "l = [True] * pad + [True, True, True, True]",
        "l = [True] * pad + [True, True,"
    ],
    [
        "def check_copy_result(x, y, ccontig, fcontig, strides=False):",
        "def check_copy_result(x, y, ccontig, fcontig,"
    ],
    [
        "assert_equal(_get_implementing_args([a, b, c]), [b, c, a])",
        "assert_equal(_get_implementing_args([a, b, c]), [b, c,"
    ],
    [
        "assert_equal(_get_implementing_args([a, c, b]), [c, b, a])",
        "assert_equal(_get_implementing_args([a, c, b]), [c,"
    ],
    [
        "relevant_args = [t() for t in types]",
        "relevant_args = [t() for"
    ],
    [
        "with pytest.raises(TypeError, match=\"args must be a tuple\"):",
        "with pytest.raises(TypeError, match=\"args must be a"
    ],
    [
        "with pytest.raises(TypeError, match=\"kwargs must be a dict\"):",
        "with pytest.raises(TypeError, match=\"kwargs must be a"
    ],
    [
        "with pytest.raises(TypeError, match=\"args must be a tuple\"):",
        "with pytest.raises(TypeError, match=\"args must be a"
    ],
    [
        "with pytest.raises(TypeError, match=\"kwargs must be a dict\"):",
        "with pytest.raises(TypeError, match=\"kwargs must"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func, types,"
    ],
    [
        "return (self, func, types, args, kwargs)",
        "return (self, func, types,"
    ],
    [
        "(obj, func, types, args, kwargs) = dispatched_one_arg(original)",
        "(obj, func, types, args, kwargs)"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func, types, args,"
    ],
    [
        "def __array_function__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_function__(self, ufunc, method,"
    ],
    [
        "TypeError, \"no implementation found for 'my.func'\"):",
        "TypeError, \"no implementation"
    ],
    [
        "pytest.skip(\"Python version is not using __qualname__ for \"",
        "pytest.skip(\"Python version is not"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func,"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func, types, args,"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func,"
    ],
    [
        "result = super().__array_function__(func, types, args, kwargs)",
        "result = super().__array_function__(func, types,"
    ],
    [
        "if enable_value_error and 'value_error' in kwargs:",
        "if enable_value_error and"
    ],
    [
        "getattr(np, func_name) for func_name, *_ in self.__class__._array_tests",
        "getattr(np, func_name) for func_name, *_"
    ],
    [
        "def test_array_like(self, function, args, kwargs, numpy_ref):",
        "def test_array_like(self, function, args,"
    ],
    [
        "like_args = tuple(a() if callable(a) else a for a in args)",
        "like_args = tuple(a() if callable(a) else a for a"
    ],
    [
        "np_args = tuple(a() if callable(a) else a for a in args)",
        "np_args = tuple(a() if callable(a) else"
    ],
    [
        "def test_no_array_function_like(self, function, args, kwargs, ref):",
        "def test_no_array_function_like(self, function, args, kwargs,"
    ],
    [
        "like_args = tuple(a() if callable(a) else a for a in args)",
        "like_args = tuple(a() if callable(a) else a for a in"
    ],
    [
        "'The `like` argument must be an array-like that implements'):",
        "'The `like` argument must be an array-like"
    ],
    [
        "like_args = tuple(a() if callable(a) else a for a in args)",
        "like_args = tuple(a() if callable(a) else a for a"
    ],
    [
        "np_args = tuple(a() if callable(a) else a for a in args)",
        "np_args = tuple(a() if callable(a) else a for a in"
    ],
    [
        "like_args = tuple(a() if callable(a) else a for a in args)",
        "like_args = tuple(a() if callable(a) else a for"
    ],
    [
        "like_args_exp = tuple(a() if callable(a) else a for a in args)",
        "like_args_exp = tuple(a() if callable(a) else a"
    ],
    [
        "int_types = [np.byte, np.short, np.intc, np.long, np.longlong]",
        "int_types = [np.byte, np.short,"
    ],
    [
        "uint_types = [np.ubyte, np.ushort, np.uintc, np.ulong, np.ulonglong]",
        "uint_types = [np.ubyte, np.ushort,"
    ],
    [
        "float_types = [np.half, np.single, np.double, np.longdouble]",
        "float_types = [np.half, np.single,"
    ],
    [
        "assert_raises(IndexError, lambda x: x[np.array([], int)], a)",
        "assert_raises(IndexError, lambda x: x[np.array([], int)],"
    ],
    [
        "assert_raises(IndexError, lambda x: x[np.array([], int)], b)",
        "assert_raises(IndexError, lambda x: x[np.array([],"
    ],
    [
        "assert_raises(IndexError, lambda x: x[np.array([], int)], a)",
        "assert_raises(IndexError, lambda x:"
    ],
    [
        "v = np.array([True, False, True, False], dtype=np.bool)",
        "v = np.array([True, False,"
    ],
    [
        "raise OSError('Can not tell or seek')",
        "raise OSError('Can not tell or"
    ],
    [
        "err_msg = \"%d %s\" % (size, mode)",
        "err_msg = \"%d %s\" % (size,"
    ],
    [
        "assert_raises_regex(ValueError, \"Cannot read into object array\",",
        "assert_raises_regex(ValueError, \"Cannot read into object"
    ],
    [
        "assert_raises_regex(ValueError, \"Cannot read into object array\",",
        "assert_raises_regex(ValueError, \"Cannot read"
    ],
    [
        "\"'offset' argument only permitted for binary files\",",
        "\"'offset' argument only permitted for binary"
    ],
    [
        "for dup, exc in ((dup_str, TypeError), (dup_bigint, OSError)):",
        "for dup, exc in"
    ],
    [
        "def _check_from(self, s, value, filename, **kw):",
        "def _check_from(self, s, value, filename,"
    ],
    [
        "sz = sum(np.dtype(b).itemsize for a, b in dt)",
        "sz = sum(np.dtype(b).itemsize for a, b"
    ],
    [
        "[('a', 'b'), ('b', 'i'), ('sub', np.dtype('b,i')), ('c', 'i')],",
        "[('a', 'b'), ('b', 'i'), ('sub', np.dtype('b,i')), ('c',"
    ],
    [
        "[('a', 'b'), ('b', 'i'), ('c', 'b'), ('d', 'b'),",
        "[('a', 'b'), ('b', 'i'), ('c', 'b'), ('d',"
    ],
    [
        "for c_integer in {ctypes.c_int, ctypes.c_long, ctypes.c_longlong}:",
        "for c_integer in"
    ],
    [
        "assert_(arr_ref() is not None, \"ctypes pointer did not hold onto a reference\")",
        "assert_(arr_ref() is not None, \"ctypes pointer did not hold"
    ],
    [
        "assert_(arr_ref() is None, \"unknowable whether ctypes pointer holds a reference\")",
        "assert_(arr_ref() is None, \"unknowable whether ctypes pointer holds a"
    ],
    [
        "assert_(arr_ref() is not None, \"ctypes pointer did not hold onto a reference\")",
        "assert_(arr_ref() is not None, \"ctypes pointer did not"
    ],
    [
        "assert_(arr_ref() is None, \"unknowable whether ctypes pointer holds a reference\")",
        "assert_(arr_ref() is None, \"unknowable whether ctypes pointer"
    ],
    [
        "reason=\"increments self in dealloc; ignore since deprecated path.\")",
        "reason=\"increments self in dealloc; ignore"
    ],
    [
        "match=rf\"arange\\(\\) not supported for inputs .* {DType_name}\"):",
        "match=rf\"arange\\(\\) not supported for"
    ],
    [
        "match=rf\"arange\\(\\) not supported for inputs .* {DType_name}\"):",
        "match=rf\"arange\\(\\) not supported for inputs .*"
    ],
    [
        "for scalar_type in [type, dict, list, tuple]:",
        "for scalar_type in [type, dict,"
    ],
    [
        "memmap, sum, average, prod, ndarray, isscalar, add, subtract, multiply)",
        "memmap, sum, average, prod, ndarray, isscalar, add,"
    ],
    [
        "from numpy import arange, allclose, asarray",
        "from numpy import arange, allclose,"
    ],
    [
        "sup.filter(FutureWarning, \"np.average currently does not preserve\")",
        "sup.filter(FutureWarning, \"np.average currently does"
    ],
    [
        "for unary_op in [sum, average, prod]:",
        "for unary_op in [sum,"
    ],
    [
        "for binary_op in [add, subtract, multiply]:",
        "for binary_op in"
    ],
    [
        "fp = memmap(self.tmpfp, shape=size, mode='w+', offset=offset)",
        "fp = memmap(self.tmpfp, shape=size, mode='w+',"
    ],
    [
        "fp = memmap(self.tmpfp, shape=size, mode='w+', offset=offset)",
        "fp = memmap(self.tmpfp, shape=size, mode='w+',"
    ],
    [
        "from numpy import array, arange, nditer, all",
        "from numpy import array, arange,"
    ],
    [
        "i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a, None], [], [['readonly'], ['writeonly',"
    ],
    [
        "i = nditer([a.T, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a.T, None],"
    ],
    [
        "i = nditer([a.T, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a.T, None],"
    ],
    [
        "raise AssertionError('Should have raised a broadcast error')",
        "raise AssertionError('Should have raised"
    ],
    [
        "raise AssertionError('Should have raised a broadcast error')",
        "raise AssertionError('Should have raised a broadcast"
    ],
    [
        "('Message \"%s\" doesn\\'t contain remapped operand shape'",
        "('Message \"%s\" doesn\\'t contain"
    ],
    [
        "raise AssertionError('Should have raised a broadcast error')",
        "raise AssertionError('Should have raised"
    ],
    [
        "assert_raises(ValueError, nditer, [a], ['bad flag'], [['readonly']])",
        "assert_raises(ValueError, nditer, [a], ['bad"
    ],
    [
        "assert_raises(ValueError, nditer, [a], [], [['readonly', 'bad flag']])",
        "assert_raises(ValueError, nditer, [a], [],"
    ],
    [
        "assert_raises(ValueError, nditer, [a], [], [['readonly']], order='G')",
        "assert_raises(ValueError, nditer, [a],"
    ],
    [
        "assert_raises(ValueError, nditer, [a], [], [['readonly']], casting='noon')",
        "assert_raises(ValueError, nditer, [a], [],"
    ],
    [
        "assert_raises(ValueError, nditer, a, [], [['readonly', 'writeonly']])",
        "assert_raises(ValueError, nditer, a, [], [['readonly',"
    ],
    [
        "assert_raises(ValueError, nditer, a, [], [['readonly', 'readwrite']])",
        "assert_raises(ValueError, nditer, a, [],"
    ],
    [
        "assert_raises(ValueError, nditer, a, [], [['writeonly', 'readwrite']])",
        "assert_raises(ValueError, nditer, a, [], [['writeonly',"
    ],
    [
        "i = nditer([a, b, c], [], ['readwrite'])",
        "i = nditer([a, b,"
    ],
    [
        "it = np.nditer(a, [], [['readwrite', 'updateifcopy']],",
        "it = np.nditer(a,"
    ],
    [
        "it = np.nditer(a, [], [['readwrite', 'updateifcopy']],",
        "it = np.nditer(a,"
    ],
    [
        "i = nditer(au, [], [['readwrite', 'updateifcopy']],",
        "i = nditer(au,"
    ],
    [
        "with nditer(au, [], [['readwrite', 'updateifcopy', 'nbo']],",
        "with nditer(au, [],"
    ],
    [
        "with nditer(a, [], [['readwrite', 'updateifcopy', 'aligned']]) as i:",
        "with nditer(a, [], [['readwrite', 'updateifcopy', 'aligned']])"
    ],
    [
        "i = nditer(a, [], [['readonly', 'copy']],",
        "i = nditer(a, [],"
    ],
    [
        "i = nditer(a, [], [['readonly', 'copy']],",
        "i = nditer(a, [], [['readonly',"
    ],
    [
        "vals = [x_[()] for x_ in i]",
        "vals = [x_[()] for x_"
    ],
    [
        "vals = [x_[()] for x_ in i]",
        "vals = [x_[()] for x_ in"
    ],
    [
        "i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],",
        "i = nditer(a, ['refs_ok',"
    ],
    [
        "i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],",
        "i = nditer(a,"
    ],
    [
        "i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],",
        "i = nditer(a, ['refs_ok',"
    ],
    [
        "i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],",
        "i = nditer(a, ['refs_ok',"
    ],
    [
        "for flag in ['readonly', 'writeonly', 'readwrite']:",
        "for flag in"
    ],
    [
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['readwrite']]) as i:",
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'],"
    ],
    [
        "i = nditer([a, b], ['copy_if_overlap'], [['readonly', 'overlap_assume_elementwise'],",
        "i = nditer([a, b], ['copy_if_overlap'], [['readonly',"
    ],
    [
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['readwrite']]) as i:",
        "with nditer([a, b], ['copy_if_overlap'],"
    ],
    [
        "i = nditer([a, b], ['copy_if_overlap'], [['readonly'], ['writeonly']])",
        "i = nditer([a, b], ['copy_if_overlap'], [['readonly'],"
    ],
    [
        "with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['writeonly']]) as i:",
        "with nditer([a, b], ['copy_if_overlap'],"
    ],
    [
        "i = nditer([a, b, c], ['copy_if_overlap'],",
        "i = nditer([a,"
    ],
    [
        "i = nditer([a, b, c], ['copy_if_overlap'],",
        "i = nditer([a, b,"
    ],
    [
        "i = nditer([a, b, c], ['copy_if_overlap'],",
        "i = nditer([a, b,"
    ],
    [
        "assert_(all([x == y for (x, y) in i]))",
        "assert_(all([x == y for (x, y)"
    ],
    [
        "assert_(all([x == y for (x, y) in i]))",
        "assert_(all([x == y for (x,"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for x in"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()]"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()]"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for x"
    ],
    [
        "assert_equal([x[()] for x in i], [x[()] for x in j])",
        "assert_equal([x[()] for x in i], [x[()] for x in"
    ],
    [
        "assert_equal([x[()] for x in j], a.ravel(order='F'))",
        "assert_equal([x[()] for x"
    ],
    [
        "assert_equal([x[()] for x in j], a.ravel(order='F'))",
        "assert_equal([x[()] for x"
    ],
    [
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],",
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\","
    ],
    [
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],",
        "it = np.nditer((arr,), [\"buffered\","
    ],
    [
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],",
        "it = np.nditer((arr,), [\"buffered\", \"external_loop\","
    ],
    [
        "i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a, None], [], [['readonly'], ['writeonly',"
    ],
    [
        "i = nditer([a, None], ['buffered', 'delay_bufalloc'],",
        "i = nditer([a, None],"
    ],
    [
        "i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a, None], [], [['readonly'], ['writeonly',"
    ],
    [
        "i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],",
        "i = nditer([a, None], [], [['readonly'],"
    ],
    [
        "i = nditer([None, a], [], [['writeonly', 'allocate'], ['readonly']],",
        "i = nditer([None, a], [], [['writeonly',"
    ],
    [
        "i = nditer([a, a, None], [],",
        "i = nditer([a, a, None],"
    ],
    [
        "i = nditer([a, b, None], [],",
        "i = nditer([a, b, None],"
    ],
    [
        "i = nditer([a, b, None], [],",
        "i = nditer([a, b,"
    ],
    [
        "i = nditer(a, flags, order='F', buffersize=buffersize)",
        "i = nditer(a, flags, order='F',"
    ],
    [
        "i = nditer(a, ['ranged'], ['readonly'], order='F',",
        "i = nditer(a, ['ranged'],"
    ],
    [
        "assert_equal([x[()] for x in i], a_fort)",
        "assert_equal([x[()] for x"
    ],
    [
        "i = nditer(a, ['ranged', 'buffered'], ['readonly'], order='F',",
        "i = nditer(a, ['ranged',"
    ],
    [
        "assert_equal([x[()] for x in i], a_fort)",
        "assert_equal([x[()] for x in i],"
    ],
    [
        "i = nditer(a, ['ranged', 'buffered', 'external_loop'],",
        "i = nditer(a, ['ranged', 'buffered',"
    ],
    [
        "i = nditer([a, b], ['buffered', 'delay_bufalloc', 'multi_index', 'reduce_ok'],",
        "i = nditer([a, b], ['buffered', 'delay_bufalloc', 'multi_index',"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a,"
    ],
    [
        "vals = [np.array(x) for x in i]",
        "vals = [np.array(x) for x"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a,"
    ],
    [
        "vals = [x.copy() for x in i]",
        "vals = [x.copy() for x"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered', 'refs_ok'],"
    ],
    [
        "i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],",
        "i = nditer(a, ['buffered',"
    ],
    [
        "for intent in [\"readwrite\", \"readonly\", \"writeonly\"]:",
        "for intent in [\"readwrite\", \"readonly\","
    ],
    [
        "nditer((simple_arr, a), ['buffered', 'refs_ok'], [intent, intent],",
        "nditer((simple_arr, a), ['buffered', 'refs_ok'], [intent,"
    ],
    [
        "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"PyPy seems to not hit this.\")",
        "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"PyPy seems to not"
    ],
    [
        "\"numeric\": (\"integral\", \"real floating\", \"complex floating\"),",
        "\"numeric\": (\"integral\", \"real floating\", \"complex"
    ],
    [
        "dt = np.dtype([('x', int), ('y', np.object_), ('z', 'O')])",
        "dt = np.dtype([('x', int),"
    ],
    [
        "dt = np.dtype([('x', int), ('y', np.object_)])",
        "dt = np.dtype([('x', int),"
    ],
    [
        "x = np.char.array((\"x\", \"x \", \"x  \"))",
        "x = np.char.array((\"x\", \"x"
    ],
    [
        "if isinstance(result, np.ndarray) and result.dtype.names is not None:",
        "if isinstance(result, np.ndarray) and result.dtype.names is"
    ],
    [
        "raise AssertionError(\"compress with an out which cannot be \"",
        "raise AssertionError(\"compress with an out which cannot"
    ],
    [
        "\"safely casted should not return \"",
        "\"safely casted should"
    ],
    [
        "msg = 'unicode offset: %d chars' % i",
        "msg = 'unicode offset: %d chars' %"
    ],
    [
        "dt = np.dtype([('foo', float), ('bar', float)])",
        "dt = np.dtype([('foo',"
    ],
    [
        "for dtype in [np.dtype('<' + t) for t in np.typecodes['Complex']]:",
        "for dtype in [np.dtype('<' + t)"
    ],
    [
        "dtspec = [(('a', 'a'), 'i'), ('b', 'i')]",
        "dtspec = [(('a', 'a'), 'i'), ('b',"
    ],
    [
        "dtypes = [x for x in np._core.sctypeDict.values()",
        "dtypes = [x for x"
    ],
    [
        "for name in ('eps', 'epsneg', 'max', 'min', 'resolution', 'tiny'):",
        "for name in ('eps', 'epsneg', 'max',"
    ],
    [
        "for tp in [np.csingle, np.cdouble, np.clongdouble]:",
        "for tp in [np.csingle,"
    ],
    [
        "for tp in [np.csingle, np.cdouble, np.clongdouble]:",
        "for tp in"
    ],
    [
        "for tp in [np.csingle, np.cdouble, np.clongdouble]:",
        "for tp in [np.csingle, np.cdouble,"
    ],
    [
        "for tostr, dtype in [(asunicode, \"U\"), (asbytes, \"S\")]:",
        "for tostr, dtype in [(asunicode, \"U\"),"
    ],
    [
        "arr = np.array([[a, b], [a, b]], order='F')",
        "arr = np.array([[a, b], [a, b]],"
    ],
    [
        "for f in [op.lt, op.le, op.gt, op.ge]:",
        "for f in [op.lt, op.le,"
    ],
    [
        "for axis in chain(range(-a.ndim, a.ndim), [None]):",
        "for axis in"
    ],
    [
        "([('a', 'O'), ('b', 'O')], [('c', 'O'), ('d', 'O')]))",
        "([('a', 'O'), ('b', 'O')],"
    ],
    [
        "s = 'Some long field name'",
        "s = 'Some"
    ],
    [
        "with pytest.raises(TypeError, match=r\"Unable to convert dtype.*\"):",
        "with pytest.raises(TypeError, match=r\"Unable to"
    ],
    [
        "assert str(f) == \"<ufunc 'cassé (vectorized)'>\"",
        "assert str(f) == \"<ufunc 'cassé"
    ],
    [
        "f\"Unexpected types order of ufunc in {operation}\"",
        "f\"Unexpected types order of"
    ],
    [
        "f\"for {order}. Possible fix: Use signed before unsigned\"",
        "f\"for {order}. Possible fix: Use"
    ],
    [
        "with pytest.raises(TypeError, match=\"not an acceptable base type\"):",
        "with pytest.raises(TypeError, match=\"not an acceptable"
    ],
    [
        "with pytest.raises(TypeError, match=\"not an acceptable base type\"):",
        "with pytest.raises(TypeError, match=\"not an"
    ],
    [
        "match=\"Only None and strings are allowed as the Array API version\"",
        "match=\"Only None and strings are allowed as the"
    ],
    [
        "expected[:] = [s.replace(b\"E\", b\"D\") for s in test_strings]",
        "expected[:] = [s.replace(b\"E\", b\"D\")"
    ],
    [
        "/* By default do not export API in an .so (was never the case on windows) */",
        "/* By default do not export API in an .so (was"
    ],
    [
        "if (numpy == NULL && PyErr_ExceptionMatches(PyExc_ModuleNotFoundError)) {",
        "if (numpy == NULL && PyErr_ExceptionMatches(PyExc_ModuleNotFoundError))"
    ],
    [
        "PyErr_SetString(PyExc_RuntimeError, \"_UFUNC_API is not PyCapsule object\");",
        "PyErr_SetString(PyExc_RuntimeError, \"_UFUNC_API is not"
    ],
    [
        "/* By default do not export API in an .so (was never the case on windows) */",
        "/* By default do not export API in an .so (was"
    ],
    [
        "* The DType classes are inconvenient for the Python generation so exposed",
        "* The DType classes are inconvenient for the"
    ],
    [
        "* manually in the header below  (may be moved).",
        "* manually in the header below (may"
    ],
    [
        "if (numpy == NULL && PyErr_ExceptionMatches(PyExc_ModuleNotFoundError)) {",
        "if (numpy == NULL"
    ],
    [
        "PyErr_SetString(PyExc_RuntimeError, \"_ARRAY_API is not PyCapsule object\");",
        "PyErr_SetString(PyExc_RuntimeError, \"_ARRAY_API is"
    ],
    [
        "* On exceedingly few platforms these sizes may not match, in which case",
        "* On exceedingly few platforms these sizes"
    ],
    [
        "* We do not support older NumPy versions at all.",
        "* We do not support older NumPy versions at"
    ],
    [
        "\"Unfortunately, this is not supported on niche platforms where \"",
        "\"Unfortunately, this is not supported"
    ],
    [
        "* backwards compatible (in the exposed feature subset!) for all practical",
        "* backwards compatible (in the exposed feature subset!) for"
    ],
    [
        "\"Check the section C-API incompatibility at the \"",
        "\"Check the section C-API incompatibility at"
    ],
    [
        "\"for indications on how to solve this problem.\",",
        "\"for indications on how to"
    ],
    [
        "* Perform runtime check of endianness and check it matches the one set by",
        "* Perform runtime check of endianness and check it matches the one"
    ],
    [
        "* the headers (npy_endian.h) as a safeguard",
        "* the headers (npy_endian.h)"
    ],
    [
        "\"FATAL: module compiled as unknown endian\");",
        "\"FATAL: module compiled as"
    ],
    [
        "\"FATAL: module compiled as big endian, but \"",
        "\"FATAL: module compiled as"
    ],
    [
        "\"FATAL: module compiled as little endian, but \"",
        "\"FATAL: module compiled as little"
    ],
    [
        "msg = (\"API mismatch detected, the C API version \"",
        "msg = (\"API mismatch detected,"
    ],
    [
        "\"numbers have to be updated. Current C api version is \"",
        "\"numbers have to be updated. Current"
    ],
    [
        "f\"{apiversion}, with checksum {curapi_hash}, but recorded \"",
        "f\"{apiversion}, with checksum {curapi_hash},"
    ],
    [
        "f\"checksum in _core/codegen_dir/cversions.txt is {api_hash}. \"",
        "f\"checksum in _core/codegen_dir/cversions.txt is {api_hash}."
    ],
    [
        "\"If functions were added in the C API, you have to update \"",
        "\"If functions were added in the C API, you have to update"
    ],
    [
        "help=\"C API version to verify (as a hex string)\"",
        "help=\"C API version to verify (as"
    ],
    [
        "_BoolCodes = Literal[\"bool\", \"bool_\", \"?\", \"|?\", \"=?\", \"<?\", \">?\"]",
        "_BoolCodes = Literal[\"bool\", \"bool_\", \"?\", \"|?\", \"=?\","
    ],
    [
        "_ByteCodes = Literal[\"byte\", \"b\", \"|b\", \"=b\", \"<b\", \">b\"]",
        "_ByteCodes = Literal[\"byte\", \"b\", \"|b\", \"=b\","
    ],
    [
        "_ShortCodes = Literal[\"short\", \"h\", \"|h\", \"=h\", \"<h\", \">h\"]",
        "_ShortCodes = Literal[\"short\", \"h\", \"|h\","
    ],
    [
        "_IntCCodes = Literal[\"intc\", \"i\", \"|i\", \"=i\", \"<i\", \">i\"]",
        "_IntCCodes = Literal[\"intc\", \"i\","
    ],
    [
        "_IntPCodes = Literal[\"intp\", \"int\", \"int_\", \"n\", \"|n\", \"=n\", \"<n\", \">n\"]",
        "_IntPCodes = Literal[\"intp\", \"int\", \"int_\", \"n\", \"|n\", \"=n\","
    ],
    [
        "_LongCodes = Literal[\"long\", \"l\", \"|l\", \"=l\", \"<l\", \">l\"]",
        "_LongCodes = Literal[\"long\", \"l\","
    ],
    [
        "_LongLongCodes = Literal[\"longlong\", \"q\", \"|q\", \"=q\", \"<q\", \">q\"]",
        "_LongLongCodes = Literal[\"longlong\", \"q\", \"|q\","
    ],
    [
        "_UByteCodes = Literal[\"ubyte\", \"B\", \"|B\", \"=B\", \"<B\", \">B\"]",
        "_UByteCodes = Literal[\"ubyte\", \"B\","
    ],
    [
        "_UShortCodes = Literal[\"ushort\", \"H\", \"|H\", \"=H\", \"<H\", \">H\"]",
        "_UShortCodes = Literal[\"ushort\", \"H\","
    ],
    [
        "_UIntCCodes = Literal[\"uintc\", \"I\", \"|I\", \"=I\", \"<I\", \">I\"]",
        "_UIntCCodes = Literal[\"uintc\", \"I\", \"|I\", \"=I\","
    ],
    [
        "_UIntPCodes = Literal[\"uintp\", \"uint\", \"N\", \"|N\", \"=N\", \"<N\", \">N\"]",
        "_UIntPCodes = Literal[\"uintp\", \"uint\", \"N\", \"|N\", \"=N\", \"<N\","
    ],
    [
        "_ULongCodes = Literal[\"ulong\", \"L\", \"|L\", \"=L\", \"<L\", \">L\"]",
        "_ULongCodes = Literal[\"ulong\", \"L\", \"|L\","
    ],
    [
        "_ULongLongCodes = Literal[\"ulonglong\", \"Q\", \"|Q\", \"=Q\", \"<Q\", \">Q\"]",
        "_ULongLongCodes = Literal[\"ulonglong\", \"Q\", \"|Q\", \"=Q\", \"<Q\","
    ],
    [
        "_HalfCodes = Literal[\"half\", \"e\", \"|e\", \"=e\", \"<e\", \">e\"]",
        "_HalfCodes = Literal[\"half\", \"e\", \"|e\","
    ],
    [
        "_SingleCodes = Literal[\"single\", \"f\", \"|f\", \"=f\", \"<f\", \">f\"]",
        "_SingleCodes = Literal[\"single\", \"f\", \"|f\", \"=f\", \"<f\","
    ],
    [
        "_DoubleCodes = Literal[\"double\", \"float\", \"d\", \"|d\", \"=d\", \"<d\", \">d\"]",
        "_DoubleCodes = Literal[\"double\", \"float\", \"d\", \"|d\", \"=d\","
    ],
    [
        "_LongDoubleCodes = Literal[\"longdouble\", \"g\", \"|g\", \"=g\", \"<g\", \">g\"]",
        "_LongDoubleCodes = Literal[\"longdouble\", \"g\","
    ],
    [
        "_CSingleCodes = Literal[\"csingle\", \"F\", \"|F\", \"=F\", \"<F\", \">F\"]",
        "_CSingleCodes = Literal[\"csingle\", \"F\","
    ],
    [
        "_CDoubleCodes = Literal[\"cdouble\", \"complex\", \"D\", \"|D\", \"=D\", \"<D\", \">D\"]",
        "_CDoubleCodes = Literal[\"cdouble\", \"complex\", \"D\","
    ],
    [
        "_CLongDoubleCodes = Literal[\"clongdouble\", \"G\", \"|G\", \"=G\", \"<G\", \">G\"]",
        "_CLongDoubleCodes = Literal[\"clongdouble\", \"G\", \"|G\", \"=G\", \"<G\","
    ],
    [
        "_StrCodes = Literal[\"str\", \"str_\", \"unicode\", \"U\", \"|U\", \"=U\", \"<U\", \">U\"]",
        "_StrCodes = Literal[\"str\", \"str_\", \"unicode\", \"U\", \"|U\", \"=U\","
    ],
    [
        "_BytesCodes = Literal[\"bytes\", \"bytes_\", \"S\", \"|S\", \"=S\", \"<S\", \">S\"]",
        "_BytesCodes = Literal[\"bytes\", \"bytes_\", \"S\", \"|S\", \"=S\","
    ],
    [
        "_VoidCodes = Literal[\"void\", \"V\", \"|V\", \"=V\", \"<V\", \">V\"]",
        "_VoidCodes = Literal[\"void\", \"V\", \"|V\", \"=V\", \"<V\","
    ],
    [
        "_ObjectCodes = Literal[\"object\", \"object_\", \"O\", \"|O\", \"=O\", \"<O\", \">O\"]",
        "_ObjectCodes = Literal[\"object\", \"object_\", \"O\", \"|O\", \"=O\", \"<O\","
    ],
    [
        "_StringCodes = Literal[\"T\", \"|T\", \"=T\", \"<T\", \">T\"]",
        "_StringCodes = Literal[\"T\", \"|T\", \"=T\", \"<T\","
    ],
    [
        "from collections.abc import Collection, Callable, Sequence",
        "from collections.abc import Collection,"
    ],
    [
        "from typing import Any, Protocol, TypeAlias, TypeVar, runtime_checkable, TYPE_CHECKING",
        "from typing import Any, Protocol,"
    ],
    [
        "def __array__(self) -> ndarray[Any, _DType_co]: ...",
        "def __array__(self) ->"
    ],
    [
        "_CharLike_co: TypeAlias = str | bytes",
        "_CharLike_co: TypeAlias = str"
    ],
    [
        "_BoolLike_co: TypeAlias = bool | np.bool",
        "_BoolLike_co: TypeAlias = bool"
    ],
    [
        "_UIntLike_co: TypeAlias = np.unsignedinteger[Any] | _BoolLike_co",
        "_UIntLike_co: TypeAlias = np.unsignedinteger[Any]"
    ],
    [
        "_IntLike_co: TypeAlias = int | np.integer[Any] | _BoolLike_co",
        "_IntLike_co: TypeAlias = int | np.integer[Any]"
    ],
    [
        "_FloatLike_co: TypeAlias = float | np.floating[Any] | _IntLike_co",
        "_FloatLike_co: TypeAlias = float"
    ],
    [
        "_NumberLike_co: TypeAlias = int | float | complex | np.number[Any] | np.bool",
        "_NumberLike_co: TypeAlias = int | float |"
    ],
    [
        "_ScalarLike_co: TypeAlias = int | float | complex | str | bytes | np.generic",
        "_ScalarLike_co: TypeAlias = int | float | complex |"
    ],
    [
        "_VoidLike_co: TypeAlias = tuple[Any, ...] | np.void",
        "_VoidLike_co: TypeAlias = tuple[Any, ...]"
    ],
    [
        "_ShapeLike: TypeAlias = SupportsIndex | Sequence[SupportsIndex]",
        "_ShapeLike: TypeAlias = SupportsIndex |"
    ],
    [
        "def __getitem__(self, index: int, /) -> _T_co | _NestedSequence[_T_co]:",
        "def __getitem__(self, index: int, /) ->"
    ],
    [
        "def __iter__(self, /) -> Iterator[_T_co | _NestedSequence[_T_co]]:",
        "def __iter__(self, /) -> Iterator[_T_co |"
    ],
    [
        "def count(self, value: Any, /) -> int:",
        "def count(self, value: Any, /) ->"
    ],
    [
        "from numpy.ctypeslib import ndpointer, load_library, as_array",
        "from numpy.ctypeslib import"
    ],
    [
        "from numpy.testing import assert_, assert_array_equal, assert_raises, assert_equal",
        "from numpy.testing import assert_,"
    ],
    [
        "reason=\"ctypes not available in this python\")",
        "reason=\"ctypes not available in this"
    ],
    [
        "msg = (\"ctypes is not available on this python: skipping the test\"",
        "msg = (\"ctypes is not available on this python: skipping"
    ],
    [
        "\" (import error was: %s)\" % str(e))",
        "\" (import error was:"
    ],
    [
        "dtdescr = {'names': dtnames, 'formats': dtformats}",
        "dtdescr = {'names': dtnames, 'formats':"
    ],
    [
        "reason=\"ctypes not available on this python installation\")",
        "reason=\"ctypes not available on this"
    ],
    [
        "from importlib.util import LazyLoader, find_spec, module_from_spec",
        "from importlib.util import LazyLoader,"
    ],
    [
        "'._' not in name and '.tests' not in name and '.setup' not in name",
        "'._' not in name and '.tests' not"
    ],
    [
        "from numpy.testing import IS_WASM, IS_INSTALLED, IS_EDITABLE, NUMPY_ROOT",
        "from numpy.testing import IS_WASM,"
    ],
    [
        "INCLUDE_DIR = NUMPY_ROOT / '_core' / 'include'",
        "INCLUDE_DIR = NUMPY_ROOT /"
    ],
    [
        "PKG_CONFIG_DIR = NUMPY_ROOT / '_core' / 'lib' / 'pkgconfig'",
        "PKG_CONFIG_DIR = NUMPY_ROOT / '_core'"
    ],
    [
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"`numpy-config` not expected to be installed\")",
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"`numpy-config` not expected"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"wasm interpreter cannot start subprocess\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"wasm interpreter"
    ],
    [
        "p = subprocess.run(['numpy-config', arg], capture_output=True, text=True)",
        "p = subprocess.run(['numpy-config', arg], capture_output=True,"
    ],
    [
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"numpy must be installed to check its entrypoints\")",
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"numpy must be installed to"
    ],
    [
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"numpy.pc is only available when numpy is installed\")",
        "@pytest.mark.skipif(not IS_INSTALLED, reason=\"numpy.pc is only available when numpy is"
    ],
    [
        "@pytest.mark.skipif(IS_EDITABLE, reason=\"editable installs don't have a numpy.pc\")",
        "@pytest.mark.skipif(IS_EDITABLE, reason=\"editable installs don't"
    ],
    [
        "\"WASM/Pyodide does not use or support Fortran\",",
        "\"WASM/Pyodide does not use or"
    ],
    [
        "\"Editable install doesn't support tests with a compile step\",",
        "\"Editable install doesn't support tests"
    ],
    [
        "def _index(iterable: Iterable[Statement], id: str) -> int:",
        "def _index(iterable: Iterable[Statement], id:"
    ],
    [
        "for lst in [file.defs, cast(\"list[Statement]\", file.imports)]:",
        "for lst in [file.defs,"
    ],
    [
        "FILES += [ROOT / \"distutils\" / \"__init__.pyi\"]",
        "FILES += [ROOT / \"distutils\""
    ],
    [
        "path, expression, msg, 'Expression is of type \"Any\"', lineno",
        "path, expression, msg, 'Expression is"
    ],
    [
        "def test_get_origin(name: type, tup: TypeTup) -> None:",
        "def test_get_origin(name: type, tup: TypeTup) ->"
    ],
    [
        "func.__annotations__ = {\"a\": typ, \"return\": None}",
        "func.__annotations__ = {\"a\": typ, \"return\":"
    ],
    [
        "ref = {\"a\": typ, \"return\": type(None)}",
        "ref = {\"a\": typ,"
    ],
    [
        "def test_get_type_hints_str(name: type, tup: TypeTup) -> None:",
        "def test_get_type_hints_str(name: type, tup: TypeTup)"
    ],
    [
        "PROTOCOLS: dict[str, tuple[type[Any], object]] = {",
        "PROTOCOLS: dict[str, tuple[type[Any], object]]"
    ],
    [
        "def test_isinstance(self, cls: type[Any], obj: object) -> None:",
        "def test_isinstance(self, cls: type[Any], obj: object)"
    ],
    [
        "def test_issubclass(self, cls: type[Any], obj: object) -> None:",
        "def test_issubclass(self, cls: type[Any], obj: object) ->"
    ],
    [
        "\"Protocols with non-method members don't support issubclass()\"",
        "\"Protocols with non-method members"
    ],
    [
        "def __array__(self, dtype: np.typing.DTypeLike = None,",
        "def __array__(self, dtype:"
    ],
    [
        "copy: bool | None = None) -> np.ndarray[Any, np.dtype[np.object_]]:",
        "copy: bool | None ="
    ],
    [
        "def __sub__(self, value: Any) -> Object:",
        "def __sub__(self, value: Any) ->"
    ],
    [
        "def __rsub__(self, value: Any) -> Object:",
        "def __rsub__(self, value: Any) ->"
    ],
    [
        "def __floordiv__(self, value: Any) -> Object:",
        "def __floordiv__(self, value: Any) ->"
    ],
    [
        "def __rfloordiv__(self, value: Any) -> Object:",
        "def __rfloordiv__(self, value: Any) ->"
    ],
    [
        "def __mul__(self, value: Any) -> Object:",
        "def __mul__(self, value: Any) ->"
    ],
    [
        "def __rmul__(self, value: Any) -> Object:",
        "def __rmul__(self, value: Any) ->"
    ],
    [
        "def __pow__(self, value: Any) -> Object:",
        "def __pow__(self, value: Any) ->"
    ],
    [
        "def __rpow__(self, value: Any) -> Object:",
        "def __rpow__(self, value: Any)"
    ],
    [
        "KACF = frozenset({None, \"K\", \"A\", \"C\", \"F\"})",
        "KACF = frozenset({None, \"K\","
    ],
    [
        "ACF = frozenset({None, \"A\", \"C\", \"F\"})",
        "ACF = frozenset({None,"
    ],
    [
        "order_list: list[tuple[frozenset[str | None], Callable[..., Any]]] = [",
        "order_list: list[tuple[frozenset[str | None],"
    ],
    [
        "def func(i: int, j: int, **kwargs: Any) -> SubClass:",
        "def func(i: int, j: int, **kwargs: Any) ->"
    ],
    [
        "np.dtype({\"names\": [\"a\", \"b\"], \"formats\": [int, float]})",
        "np.dtype({\"names\": [\"a\", \"b\"], \"formats\":"
    ],
    [
        "np.dtype({\"names\": [\"a\"], \"formats\": [int], \"titles\": [object]})",
        "np.dtype({\"names\": [\"a\"], \"formats\": [int], \"titles\":"
    ],
    [
        "np.dtype({\"names\": [\"a\"], \"formats\": [int], \"titles\": [object()]})",
        "np.dtype({\"names\": [\"a\"], \"formats\":"
    ],
    [
        "AR_LIKE_b = [[True, True], [True, True]]",
        "AR_LIKE_b = [[True, True], [True,"
    ],
    [
        "from typing import Any, NamedTuple, cast",
        "from typing import Any,"
    ],
    [
        "np.einsum(\"i,i->i\", AR_LIKE_U, AR_LIKE_U, dtype=int, casting=\"unsafe\", out=OUT_f)",
        "np.einsum(\"i,i->i\", AR_LIKE_U, AR_LIKE_U, dtype=int, casting=\"unsafe\","
    ],
    [
        "from numpy._typing import NDArray, ArrayLike, _SupportsArray",
        "from numpy._typing import NDArray,"
    ],
    [
        "self, dtype: None | np.dtype[Any] = None",
        "self, dtype: None | np.dtype[Any]"
    ],
    [
        "def __ge__(self, value: object) -> bool:",
        "def __ge__(self, value: object)"
    ],
    [
        "def __array__(self, dtype: np.typing.DTypeLike | None = None,",
        "def __array__(self, dtype: np.typing.DTypeLike | None"
    ],
    [
        "copy: bool | None = None) -> np.ndarray[Any, np.dtype[np.object_]]:",
        "copy: bool | None = None) ->"
    ],
    [
        "raise ValueError('No replicates found for <%s>' % (r))",
        "raise ValueError('No replicates found for"
    ],
    [
        "if r not in names and not thelist.startswith('_'):",
        "if r not in names"
    ],
    [
        "rule = [i.replace('@comma@', ',') for i in thelist.split(',')]",
        "rule = [i.replace('@comma@', ',')"
    ],
    [
        "print(\"Mismatch in number of replacements (base <{}={}>) \"",
        "print(\"Mismatch in number of replacements (base <{}={}>)"
    ],
    [
        "\"for <{}={}>. Ignoring.\".format(base_rule, ','.join(rules[base_rule]), r, thelist))",
        "\"for <{}={}>. Ignoring.\".format(base_rule, ','.join(rules[base_rule]), r,"
    ],
    [
        "newstr += template_re.sub(namerepl, substr) + '\\n\\n'",
        "newstr += template_re.sub(namerepl, substr)"
    ],
    [
        "static struct PyModuleDef moduledef = {",
        "static struct PyModuleDef moduledef"
    ],
    [
        "s = PyUnicode_FromString(\\\"\"\"\" + numpy_version + \"\"\"\\\");",
        "s = PyUnicode_FromString(\\\"\"\"\" + numpy_version"
    ],
    [
        "* Store the error object inside the dict, so that it could get deallocated.",
        "* Store the error object inside the dict, so"
    ],
    [
        "* (in practice, this is a module, so it likely will not and cannot.)",
        "* (in practice, this is a module, so it likely will"
    ],
    [
        "// signal whether this module supports running with the GIL disabled",
        "// signal whether this module supports running with the GIL"
    ],
    [
        "print('Failed to import new numpy:', e)",
        "print('Failed to import"
    ],
    [
        "print('Found new numpy version %r in %s' %",
        "print('Found new numpy version"
    ],
    [
        "print('Found numpy.distutils version %r in %r' % (",
        "print('Found numpy.distutils version %r in"
    ],
    [
        "print('Found numpy_distutils version %r in %r' % (",
        "print('Found numpy_distutils version %r in %r'"
    ],
    [
        "'Checking availability of supported Fortran compilers:')",
        "'Checking availability of supported"
    ],
    [
        "print('Checking availability of supported Fortran compilers:')",
        "print('Checking availability of"
    ],
    [
        "\"Use the Meson backend instead, or generate wrappers\"",
        "\"Use the Meson backend instead,"
    ],
    [
        "\" without -c and use a custom build script\",",
        "\" without -c and use a"
    ],
    [
        "compile_command = [\"meson\", \"compile\", \"-C\", self.meson_build_dir]",
        "compile_command = [\"meson\","
    ],
    [
        "values = [val.strip(\"'\\\"\") for val in values]",
        "values = [val.strip(\"'\\\"\") for val"
    ],
    [
        "from numpy.testing import assert_array_equal, assert_equal, assert_raises",
        "from numpy.testing import assert_array_equal, assert_equal,"
    ],
    [
        "o(i, :) = transfer(c(i), o(i, :))",
        "o(i, :) ="
    ],
    [
        "o(i, j, :) = transfer(c(i, j), o(i, j, :))",
        "o(i, j, :) = transfer(c(i, j), o(i, j,"
    ],
    [
        "reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "reason=\"PyPy cannot modify tp_doc"
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"common\", \"block.f\")]",
        "sources = [util.getpath(\"tests\","
    ],
    [
        "from numpy._core._type_aliases import c_names_dict as _c_names_dict",
        "from numpy._core._type_aliases import"
    ],
    [
        "request.cls.array = lambda self, dims, intent, obj: Array(",
        "request.cls.array = lambda self,"
    ],
    [
        "\"but not when run in isolation\",",
        "\"but not when run in"
    ],
    [
        "assert str(Expr(Op.APPLY, (\"f\", (), {}))) == \"f()\"",
        "assert str(Expr(Op.APPLY, (\"f\", (),"
    ],
    [
        "assert str(Expr(Op.APPLY, (\"f\", (x, ), {}))) == \"f(x)\"",
        "assert str(Expr(Op.APPLY, (\"f\", (x, ), {}))) =="
    ],
    [
        "assert str(Expr(Op.APPLY, (\"f\", (x, y), {}))) == \"f(x, y)\"",
        "assert str(Expr(Op.APPLY, (\"f\", (x, y), {})))"
    ],
    [
        "assert str(Expr(Op.INDEXING, (\"f\", x))) == \"f[x]\"",
        "assert str(Expr(Op.INDEXING, (\"f\","
    ],
    [
        "assert str(as_ternary(x, y, z)) == \"merge(y, z, x)\"",
        "assert str(as_ternary(x, y, z))"
    ],
    [
        "assert str(as_eq(x, y)) == \"x .eq. y\"",
        "assert str(as_eq(x, y)) =="
    ],
    [
        "assert str(as_ne(x, y)) == \"x .ne. y\"",
        "assert str(as_ne(x, y)) == \"x .ne."
    ],
    [
        "assert str(as_lt(x, y)) == \"x .lt. y\"",
        "assert str(as_lt(x, y)) == \"x .lt."
    ],
    [
        "assert str(as_le(x, y)) == \"x .le. y\"",
        "assert str(as_le(x, y)) == \"x .le."
    ],
    [
        "assert str(as_gt(x, y)) == \"x .gt. y\"",
        "assert str(as_gt(x, y)) == \"x .gt."
    ],
    [
        "assert str(as_ge(x, y)) == \"x .ge. y\"",
        "assert str(as_ge(x, y)) == \"x"
    ],
    [
        "}).tostring(language=language) == \"(x + y) * (x + y)\")",
        "}).tostring(language=language) == \"(x + y)"
    ],
    [
        "x + y).tostring(language=language) == \"x / (x + y)\")",
        "x + y).tostring(language=language) == \"x /"
    ],
    [
        "assert (as_apply(ArithOp.DIV, x - y, x +",
        "assert (as_apply(ArithOp.DIV, x - y,"
    ],
    [
        "y).tostring(language=language) == \"(x - y) / (x + y)\")",
        "y).tostring(language=language) == \"(x - y)"
    ],
    [
        "assert (x + (x - y) / (x + y) +",
        "assert (x + (x - y) / (x +"
    ],
    [
        "assert as_ternary(x, y, z).tostring(language=language) == \"(x?y:z)\"",
        "assert as_ternary(x, y, z).tostring(language=language) =="
    ],
    [
        "assert as_eq(x, y).tostring(language=language) == \"x == y\"",
        "assert as_eq(x, y).tostring(language=language) == \"x"
    ],
    [
        "assert as_ne(x, y).tostring(language=language) == \"x != y\"",
        "assert as_ne(x, y).tostring(language=language) == \"x"
    ],
    [
        "assert as_lt(x, y).tostring(language=language) == \"x < y\"",
        "assert as_lt(x, y).tostring(language=language) == \"x"
    ],
    [
        "assert as_le(x, y).tostring(language=language) == \"x <= y\"",
        "assert as_le(x, y).tostring(language=language) =="
    ],
    [
        "assert as_gt(x, y).tostring(language=language) == \"x > y\"",
        "assert as_gt(x, y).tostring(language=language) == \"x >"
    ],
    [
        "assert as_ge(x, y).tostring(language=language) == \"x >= y\"",
        "assert as_ge(x, y).tostring(language=language) == \"x"
    ],
    [
        "assert (x + y) * z == x * z + y * z",
        "assert (x + y) * z =="
    ],
    [
        "assert z * (x + y) == x * z + y * z",
        "assert z * (x + y) =="
    ],
    [
        "assert s // x == Expr(Op.CONCAT, (s, x))",
        "assert s // x == Expr(Op.CONCAT,"
    ],
    [
        "assert x // s == Expr(Op.CONCAT, (x, s))",
        "assert x // s == Expr(Op.CONCAT, (x,"
    ],
    [
        "assert (x + y).substitute({x: z}) == y + z",
        "assert (x + y).substitute({x: z}) =="
    ],
    [
        "assert (x * y).substitute({x: z}) == y * z",
        "assert (x * y).substitute({x: z}) == y"
    ],
    [
        "assert (x / y).substitute({x: z}) == z / y",
        "assert (x / y).substitute({x: z})"
    ],
    [
        "assert x.substitute({x: y + z}) == y + z",
        "assert x.substitute({x: y + z}) == y"
    ],
    [
        "assert a.substitute({x: y + z}) == as_array((y + z, y))",
        "assert a.substitute({x: y + z}) == as_array((y +"
    ],
    [
        "z).substitute({x: y + z}) == as_ternary(y + z, y, z)",
        "z).substitute({x: y + z}) == as_ternary(y + z, y,"
    ],
    [
        "assert as_eq(x, y).substitute({x: y + z}) == as_eq(y + z, y)",
        "assert as_eq(x, y).substitute({x: y + z}) == as_eq(y +"
    ],
    [
        "assert fromstring(\"x + y\") == x + y",
        "assert fromstring(\"x + y\")"
    ],
    [
        "assert fromstring(\"x * y\") == x * y",
        "assert fromstring(\"x * y\") == x"
    ],
    [
        "assert fromstring(\"x / y\") == x / y",
        "assert fromstring(\"x / y\") == x /"
    ],
    [
        "assert fromstring(\"(x + y) * z\") == (x + y) * z",
        "assert fromstring(\"(x + y) * z\") == (x + y)"
    ],
    [
        "assert fromstring(\"(/x, y/)\") == a, fromstring(\"(/x, y/)\")",
        "assert fromstring(\"(/x, y/)\") == a, fromstring(\"(/x,"
    ],
    [
        "assert fromstring(\"(/(x+y)*z/)\") == as_array(((x + y) * z, ))",
        "assert fromstring(\"(/(x+y)*z/)\") == as_array(((x +"
    ],
    [
        "assert fromstring(\"x?y:z\") == as_ternary(x, y, z)",
        "assert fromstring(\"x?y:z\") =="
    ],
    [
        "assert fromstring(\"(*x) * (*y)\") == as_deref(x) * as_deref(y)",
        "assert fromstring(\"(*x) * (*y)\")"
    ],
    [
        "assert fromstring(\"(*x) * *y\") == as_deref(x) * as_deref(y)",
        "assert fromstring(\"(*x) * *y\") == as_deref(x) *"
    ],
    [
        "assert fromstring(\"*x * *y\") == as_deref(x) * as_deref(y)",
        "assert fromstring(\"*x * *y\") =="
    ],
    [
        "assert fromstring(\"*x**y\") == as_deref(x) * as_deref(y)",
        "assert fromstring(\"*x**y\") == as_deref(x)"
    ],
    [
        "assert fromstring(\"x == y\") == as_eq(x, y)",
        "assert fromstring(\"x == y\") =="
    ],
    [
        "assert fromstring(\"x != y\") == as_ne(x, y)",
        "assert fromstring(\"x != y\") == as_ne(x,"
    ],
    [
        "assert fromstring(\"x < y\") == as_lt(x, y)",
        "assert fromstring(\"x < y\")"
    ],
    [
        "assert fromstring(\"x > y\") == as_gt(x, y)",
        "assert fromstring(\"x > y\") =="
    ],
    [
        "assert fromstring(\"x <= y\") == as_le(x, y)",
        "assert fromstring(\"x <= y\") == as_le(x,"
    ],
    [
        "assert fromstring(\"x >= y\") == as_ge(x, y)",
        "assert fromstring(\"x >= y\") =="
    ],
    [
        "assert fromstring(\"x .eq. y\", language=Language.Fortran) == as_eq(x, y)",
        "assert fromstring(\"x .eq. y\","
    ],
    [
        "assert fromstring(\"x .ne. y\", language=Language.Fortran) == as_ne(x, y)",
        "assert fromstring(\"x .ne. y\","
    ],
    [
        "assert fromstring(\"x .lt. y\", language=Language.Fortran) == as_lt(x, y)",
        "assert fromstring(\"x .lt. y\", language=Language.Fortran) == as_lt(x,"
    ],
    [
        "assert fromstring(\"x .gt. y\", language=Language.Fortran) == as_gt(x, y)",
        "assert fromstring(\"x .gt. y\", language=Language.Fortran) == as_gt(x,"
    ],
    [
        "assert fromstring(\"x .le. y\", language=Language.Fortran) == as_le(x, y)",
        "assert fromstring(\"x .le. y\","
    ],
    [
        "assert fromstring(\"x .ge. y\", language=Language.Fortran) == as_ge(x, y)",
        "assert fromstring(\"x .ge. y\", language=Language.Fortran) == as_ge(x,"
    ],
    [
        "f(y, x - z)).traverse(replace_visit) == (z +",
        "f(y, x - z)).traverse(replace_visit) == (z"
    ],
    [
        "assert as_eq(x, y).traverse(replace_visit) == as_eq(z, y)",
        "assert as_eq(x, y).traverse(replace_visit)"
    ],
    [
        "elif s.op is Op.SYMBOL and s not in function_symbols:",
        "elif s.op is Op.SYMBOL and s not"
    ],
    [
        "(x + f(y, x - z)).traverse(collect_symbols)",
        "(x + f(y, x"
    ],
    [
        "assert symbols == {x, y, z}",
        "assert symbols =="
    ],
    [
        "assert symbols == {x, y, z, f}",
        "assert symbols == {x, y,"
    ],
    [
        "assert (z * x + y).linear_solve(x) == (z, y)",
        "assert (z * x + y).linear_solve(x) =="
    ],
    [
        "assert ((z + y) * x + y).linear_solve(x) == (z + y, y)",
        "assert ((z + y) * x + y).linear_solve(x) =="
    ],
    [
        "assert (z * y * x + y).linear_solve(x) == (z * y, y)",
        "assert (z * y * x + y).linear_solve(x) =="
    ],
    [
        "assert as_numer_denom(x / n) == (x, n)",
        "assert as_numer_denom(x / n) == (x,"
    ],
    [
        "assert as_numer_denom(n / x) == (n, x)",
        "assert as_numer_denom(n / x) == (n,"
    ],
    [
        "assert as_numer_denom(x / y) == (x, y)",
        "assert as_numer_denom(x / y) == (x,"
    ],
    [
        "assert as_numer_denom(n + x / y) == (x + n * y, y)",
        "assert as_numer_denom(n + x / y) =="
    ],
    [
        "assert (y(x) + x).polynomial_atoms() == {y(x), x}",
        "assert (y(x) + x).polynomial_atoms() =="
    ],
    [
        "assert (y(x) * x[y]).polynomial_atoms() == {y(x), x[y]}",
        "assert (y(x) * x[y]).polynomial_atoms() =="
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"callback\", \"foo.f\")]",
        "sources = [util.getpath(\"tests\", \"src\", \"callback\","
    ],
    [
        "reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "reason=\"PyPy cannot modify"
    ],
    [
        "strings = np.array([\"ab\", \"cd\", \"ef\"], dtype=\"c\").T",
        "strings = np.array([\"ab\", \"cd\","
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"string\", \"string.f\")]",
        "sources = [util.getpath(\"tests\", \"src\", \"string\","
    ],
    [
        "\"WASM/Pyodide does not use or support Fortran\",",
        "\"WASM/Pyodide does not use or support"
    ],
    [
        "\"Editable install doesn't support tests with a compile step\",",
        "\"Editable install doesn't support tests with"
    ],
    [
        "\"but not when run in isolation\",",
        "\"but not when run"
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"block_docstring\", \"foo.f\")]",
        "sources = [util.getpath(\"tests\", \"src\","
    ],
    [
        "reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "reason=\"PyPy cannot modify"
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"crackfortran\", \"data_common.f\")]",
        "sources = [util.getpath(\"tests\", \"src\","
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"crackfortran\", \"data_multiplier.f\")]",
        "sources = [util.getpath(\"tests\", \"src\", \"crackfortran\","
    ],
    [
        "sources = [util.getpath(\"tests\", \"src\", \"crackfortran\", \"data_with_comments.f\")]",
        "sources = [util.getpath(\"tests\", \"src\","
    ],
    [
        "@pytest.mark.xfail(IS_PYPY, reason=\"PyPy cannot modify tp_doc after PyType_Ready\")",
        "@pytest.mark.xfail(IS_PYPY, reason=\"PyPy cannot modify"
    ],
    [
        "test_list = [\"a \", \" a\", \"a b c\", \"'abcdefghij'\"]",
        "test_list = [\"a \", \" a\","
    ],
    [
        "assert markinnerspaces(\"a 'b c' \\\\' \\\\'\") == \"a 'b@_@c' \\\\' \\\\'\"",
        "assert markinnerspaces(\"a 'b c' \\\\' \\\\'\") == \"a 'b@_@c' \\\\'"
    ],
    [
        "assert markinnerspaces(r'a \"b c\" \\\" \\\"') == r'a \"b@_@c\" \\\" \\\"'",
        "assert markinnerspaces(r'a \"b c\" \\\" \\\"') =="
    ],
    [
        "assert markinnerspaces(\"a 'b c\\\" \\\" d' e\") == \"a 'b@_@c\\\"@_@\\\"@_@d' e\"",
        "assert markinnerspaces(\"a 'b c\\\" \\\" d' e\") == \"a"
    ],
    [
        "assert markinnerspaces(\"a \\\"b c' ' d\\\" e\") == \"a \\\"b@_@c'@_@'@_@d\\\" e\"",
        "assert markinnerspaces(\"a \\\"b c' ' d\\\" e\") == \"a \\\"b@_@c'@_@'@_@d\\\""
    ],
    [
        "assert markinnerspaces(\"a 'b c' 'd e'\") == \"a 'b@_@c' 'd@_@e'\"",
        "assert markinnerspaces(\"a 'b c' 'd e'\") =="
    ],
    [
        "assert markinnerspaces(r'a \"b c\" \"d e\"') == r'a \"b@_@c\" \"d@_@e\"'",
        "assert markinnerspaces(r'a \"b c\" \"d e\"') =="
    ],
    [
        "pytest.skip(\"CLI command needs a Fortran compiler\")",
        "pytest.skip(\"CLI command needs a"
    ],
    [
        "assert \"lparen got assign\" not in str(rerr)",
        "assert \"lparen got assign\""
    ],
    [
        "@pytest.mark.skipif(platform.system() not in ['Linux', 'Darwin'], reason='Unsupported on this platform for now')",
        "@pytest.mark.skipif(platform.system() not in ['Linux', 'Darwin'], reason='Unsupported on this"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among"
    ],
    [
        "'Max relative difference among violations: inf\\n')",
        "'Max relative difference"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among violations:"
    ],
    [
        "'Max absolute difference among violations: '",
        "'Max absolute difference among"
    ],
    [
        "'Max relative difference among violations: '",
        "'Max relative difference among violations:"
    ],
    [
        "\"assert_warns does not preserver warnings state\")",
        "\"assert_warns does not"
    ],
    [
        "\"assert_warns does not preserver warnings state\")",
        "\"assert_warns does not preserver"
    ],
    [
        "raise AssertionError(\"wrong warning caught by assert_warn\")",
        "raise AssertionError(\"wrong warning caught"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference among"
    ],
    [
        "a = np.array([x, y, x, y])",
        "a = np.array([x, y,"
    ],
    [
        "b = np.array([x, y, x, x])",
        "b = np.array([x, y, x,"
    ],
    [
        "b = np.array([x, y, x, x])",
        "b = np.array([x, y,"
    ],
    [
        "c = np.array([x, y, x, z])",
        "c = np.array([x, y, x,"
    ],
    [
        "'Max relative difference among violations: inf')",
        "'Max relative difference"
    ],
    [
        "y = x + x * eps * nulp",
        "y = x + x *"
    ],
    [
        "y = x - x * epsneg * nulp",
        "y = x - x *"
    ],
    [
        "y = x + x * eps * nulp",
        "y = x + x * eps *"
    ],
    [
        "y = x - x * epsneg * nulp",
        "y = x - x"
    ],
    [
        "assert_equal(msg, \"Differences in strings:\\n- foo\\n+ hello\")",
        "assert_equal(msg, \"Differences in strings:\\n-"
    ],
    [
        "if not IS_EDITABLE and np_dist.locate_file('numpy') != NUMPY_ROOT:",
        "if not IS_EDITABLE and np_dist.locate_file('numpy')"
    ],
    [
        "HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None and not IS_PYSTON",
        "HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None"
    ],
    [
        "raise ValueError(f'value {size_str!r} not a valid size')",
        "raise ValueError(f'value {size_str!r} not a"
    ],
    [
        "all_args = [(func, i, *args) for i in range(max_workers)]",
        "all_args = [(func, i, *args)"
    ],
    [
        "all_args = [(func, *args) for i in range(max_workers)]",
        "all_args = [(func, *args) for i in"
    ],
    [
        "if len(futures) < max_workers and pass_barrier:",
        "if len(futures) <"
    ],
    [
        "if na_object is pd_NA or na_object != \"unset\":",
        "if na_object is pd_NA or"
    ],
    [
        "return [line[s] for s in slices]",
        "return [line[s] for"
    ],
    [
        "return [line[s] for s in slices]",
        "return [line[s] for"
    ],
    [
        "from numpy._core.numeric import asarray, zeros, zeros_like, array, asanyarray",
        "from numpy._core.numeric import asarray, zeros, zeros_like,"
    ],
    [
        "raise IndexError('`indices` must be an integer array')",
        "raise IndexError('`indices` must be an integer"
    ],
    [
        "\"`indices` and `arr` must have the same number of dimensions\")",
        "\"`indices` and `arr` must have the same"
    ],
    [
        "for dim, n in zip(dest_dims, arr_shape):",
        "for dim, n"
    ],
    [
        "warnings.warn(\"Converting input from {} to {} for compatibility.\"",
        "warnings.warn(\"Converting input from {} to"
    ],
    [
        "'weights should have the same shape as a.')",
        "'weights should have the"
    ],
    [
        "'ravel_multi_index', 'unravel_index', 'mgrid', 'ogrid', 'r_', 'c_',",
        "'ravel_multi_index', 'unravel_index', 'mgrid', 'ogrid',"
    ],
    [
        "'s_', 'index_exp', 'ix_', 'ndenumerate', 'ndindex', 'fill_diagonal',",
        "'s_', 'index_exp', 'ix_', 'ndenumerate', 'ndindex',"
    ],
    [
        "ones, zeros_like, arange, concatenate, array, asarray, asanyarray, empty,",
        "ones, zeros_like, arange, concatenate,"
    ],
    [
        "ndarray, take, dot, where, intp, integer, isscalar, absolute",
        "ndarray, take, dot, where, intp,"
    ],
    [
        "ravel, nonzero, partition, mean, any, sum",
        "ravel, nonzero, partition, mean,"
    ],
    [
        "interp as compiled_interp, interp_complex as compiled_interp_complex",
        "interp as compiled_interp,"
    ],
    [
        "'select', 'piecewise', 'trim_zeros', 'copy', 'iterable', 'percentile',",
        "'select', 'piecewise', 'trim_zeros', 'copy', 'iterable',"
    ],
    [
        "'diff', 'gradient', 'angle', 'unwrap', 'sort_complex', 'flip',",
        "'diff', 'gradient', 'angle', 'unwrap',"
    ],
    [
        "'get_virtual_index': lambda n, quantiles: _inverted_cdf(n, quantiles),",
        "'get_virtual_index': lambda n,"
    ],
    [
        "return [broadcast_shape + tuple(dim_sizes[dim] for dim in core_dims)",
        "return [broadcast_shape + tuple(dim_sizes[dim] for dim"
    ],
    [
        "raise ValueError('args can not be empty')",
        "raise ValueError('args can not be"
    ],
    [
        "if func is not self.pyfunc or nin not in self._ufunc:",
        "if func is not self.pyfunc or nin not in"
    ],
    [
        "args = [asarray(arg) for arg in args]",
        "args = [asarray(arg) for"
    ],
    [
        "raise TypeError('wrong number of positional arguments: '",
        "raise TypeError('wrong number of positional arguments:"
    ],
    [
        "args = tuple(asanyarray(arg) for arg in args)",
        "args = tuple(asanyarray(arg) for"
    ],
    [
        "for arg, shape in zip(args, input_shapes)]",
        "for arg, shape in zip(args,"
    ],
    [
        "results = func(*(arg[index] for arg in args))",
        "results = func(*(arg[index] for"
    ],
    [
        "'wrong number of outputs from pyfunc: expected %r, got %r'",
        "'wrong number of outputs from pyfunc: expected %r, got"
    ],
    [
        "for result, core_dims in zip(results, output_core_dims):",
        "for result, core_dims"
    ],
    [
        "for output, result in zip(outputs, results):",
        "for output, result in"
    ],
    [
        "raise ValueError('cannot call `vectorize` with a signature '",
        "raise ValueError('cannot call `vectorize` with a signature"
    ],
    [
        "def _cov_dispatcher(m, y=None, rowvar=None, bias=None, ddof=None,",
        "def _cov_dispatcher(m, y=None, rowvar=None,"
    ],
    [
        "def cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None,",
        "def cov(m, y=None, rowvar=True, bias=False,"
    ],
    [
        "f\"the `interpolation=` argument to {fname} was renamed to \"",
        "f\"the `interpolation=` argument to {fname} was"
    ],
    [
        "\"Users of the modes 'nearest', 'lower', 'higher', or \"",
        "\"Users of the modes 'nearest', 'lower', 'higher', or"
    ],
    [
        "\"'midpoint' are encouraged to review the method they used. \"",
        "\"'midpoint' are encouraged to review the"
    ],
    [
        "\"You shall not pass both `method` and `interpolation`!\\n\"",
        "\"You shall not pass"
    ],
    [
        "\"(`interpolation` is Deprecated in favor of `method`)\")",
        "\"(`interpolation` is Deprecated in favor"
    ],
    [
        "def _compute_virtual_index(n, quantiles, alpha: float, beta: float):",
        "def _compute_virtual_index(n, quantiles, alpha: float,"
    ],
    [
        "axis: int | None = None,",
        "axis: int | None"
    ],
    [
        "return any(c in _writemodes for c in mode)",
        "return any(c in _writemodes for c"
    ],
    [
        "common_type, mintypecode, isreal, iscomplex, isposinf, isneginf,",
        "common_type, mintypecode, isreal,"
    ],
    [
        "TYPE_CODES = np.typecodes[\"AllInteger\"] + np.typecodes[\"AllFloat\"] + \"O\"",
        "TYPE_CODES = np.typecodes[\"AllInteger\"] + np.typecodes[\"AllFloat\"]"
    ],
    [
        "names = ['A', 'a', 'b', 'c']",
        "names = ['A',"
    ],
    [
        "names = ['dates', 'data', 'Other Data', 'mask']",
        "names = ['dates', 'data', 'Other Data',"
    ],
    [
        "\"Tests the use of missing values.\"",
        "\"Tests the use of missing"
    ],
    [
        "\"Make sure that string-to-object functions are properly recognized\"",
        "\"Make sure that string-to-object functions"
    ],
    [
        "\"Make sure we don't lose an explicit default\"",
        "\"Make sure we don't lose an explicit"
    ],
    [
        "\"Check that we're not losing missing values\"",
        "\"Check that we're not losing missing"
    ],
    [
        "ndtype = [('A', int), ('B', float)]",
        "ndtype = [('A', int), ('B',"
    ],
    [
        "np.dtype([('a', int), ('b', float), ('c', float)]))",
        "np.dtype([('a', int), ('b', float), ('c',"
    ],
    [
        "np.dtype([(_, float) for _ in ('a', 'b', 'c')]))",
        "np.dtype([(_, float) for _ in"
    ],
    [
        "apply_along_axis, apply_over_axes, array_split, split, hsplit, dsplit,",
        "apply_along_axis, apply_over_axes, array_split, split, hsplit,"
    ],
    [
        "vsplit, dstack, column_stack, kron, tile, expand_dims, take_along_axis,",
        "vsplit, dstack, column_stack, kron, tile, expand_dims,"
    ],
    [
        "for func, argfunc, kwargs in funcs:",
        "for func, argfunc,"
    ],
    [
        "for axis in list(range(a.ndim)) + [None]:",
        "for axis in"
    ],
    [
        "for x, y in zip(res, desired):",
        "for x, y in zip(res,"
    ],
    [
        "from numpy import fix, isposinf, isneginf",
        "from numpy import fix, isposinf,"
    ],
    [
        "tgt = np.array([True, False, False, False, False, False])",
        "tgt = np.array([True, False,"
    ],
    [
        "tgt = np.array([False, True, False, False, False, False])",
        "tgt = np.array([False, True,"
    ],
    [
        "mgrid, ogrid, ndenumerate, fill_diagonal, diag_indices, diag_indices_from,",
        "mgrid, ogrid, ndenumerate, fill_diagonal,"
    ],
    [
        "index_exp, ndindex, c_, r_, s_, ix_",
        "index_exp, ndindex, c_, r_, s_,"
    ],
    [
        "for f, b in zip(grid_full, grid_broadcast):",
        "for f, b in"
    ],
    [
        "def test_mgrid_size_none_handling(self, start, stop, step, expected):",
        "def test_mgrid_size_none_handling(self, start, stop, step,"
    ],
    [
        "arrays = np.ix_(*[func(sz) for sz in sizes])",
        "arrays = np.ix_(*[func(sz) for"
    ],
    [
        "for k, (a, sz) in enumerate(zip(arrays, sizes)):",
        "for k, (a, sz) in"
    ],
    [
        "bool_a = [True, False, True, True]",
        "bool_a = [True, False, True,"
    ],
    [
        "start = [randint(dim) for dim in shape]",
        "start = [randint(dim) for dim"
    ],
    [
        "slice_ = tuple(slice(*t) for t in zip(start, stop, step))",
        "slice_ = tuple(slice(*t) for t in zip(start, stop,"
    ],
    [
        "assert_equal(high - low, a.size * a.itemsize)",
        "assert_equal(high - low, a.size"
    ],
    [
        "assert_equal(high - low, b.size * b.itemsize)",
        "assert_equal(high - low, b.size"
    ],
    [
        "assert_equal(high - low, b.size * b.itemsize)",
        "assert_equal(high - low, b.size"
    ],
    [
        "ec = np.array([True, False, True, True])",
        "ec = np.array([True, False, True,"
    ],
    [
        "v, j = unique(a, True, False, False)",
        "v, j = unique(a, True,"
    ],
    [
        "v, j = unique(a, False, True, False)",
        "v, j = unique(a,"
    ],
    [
        "v, j = unique(a, False, False, True)",
        "v, j = unique(a,"
    ],
    [
        "msg = base_msg.format('return_index and return_inverse', dt)",
        "msg = base_msg.format('return_index"
    ],
    [
        "msg = base_msg.format('return_index and return_counts', dt)",
        "msg = base_msg.format('return_index and"
    ],
    [
        "msg = base_msg.format('return_inverse and return_counts', dt)",
        "msg = base_msg.format('return_inverse"
    ],
    [
        "dt = [('', 'i'), ('', 'i')]",
        "dt = [('', 'i'), ('',"
    ],
    [
        "msg = \"Unique failed on list of lists\"",
        "msg = \"Unique failed on list"
    ],
    [
        "msg = 'Non-bitwise-equal booleans test failed'",
        "msg = 'Non-bitwise-equal"
    ],
    [
        "result = np.array([[False, True], [True, True]], dtype=bool)",
        "result = np.array([[False, True], [True, True]],"
    ],
    [
        "msg = 'Negative zero equality test failed'",
        "msg = 'Negative zero equality test"
    ],
    [
        "uniq, inv = unique(x, return_inverse=True, axis=axis)",
        "uniq, inv = unique(x, return_inverse=True,"
    ],
    [
        "msg = 'Unique returned different results when asked for index'",
        "msg = 'Unique returned different"
    ],
    [
        "fmt = \"sort order incorrect for integer type '%s'\"",
        "fmt = \"sort order incorrect for"
    ],
    [
        "for actual, expected in zip(res_unique_array_api, res_unique):",
        "for actual, expected in"
    ],
    [
        "ma, angle, average, bartlett, blackman, corrcoef, cov,",
        "ma, angle, average, bartlett, blackman, corrcoef,"
    ],
    [
        "delete, diff, digitize, extract, flipud, gradient, hamming, hanning,",
        "delete, diff, digitize, extract,"
    ],
    [
        "([(), ('a', 'b', 'c'), ('d',)], [('d', 'e')]))",
        "([(), ('a', 'b', 'c'), ('d',)], [('d',"
    ],
    [
        "assert_equal(nfb._parse_gufunc_signature('( x , y )->(  )'),",
        "assert_equal(nfb._parse_gufunc_signature('( x , y )->("
    ],
    [
        "'(  ), ( a,  b,c )  ,(  d)   ->   (d  ,  e)'),",
        "'( ), ( a, b,c ) ,("
    ],
    [
        "([(), ('a', 'b', 'c'), ('d',)], [('d', 'e')]))",
        "([(), ('a', 'b', 'c'), ('d',)], [('d',"
    ],
    [
        "f = vectorize(lambda x: (x, x), signature='()->(),()')",
        "f = vectorize(lambda x: (x,"
    ],
    [
        "with assert_raises_regex(TypeError, 'wrong number of positional'):",
        "with assert_raises_regex(TypeError, 'wrong number of"
    ],
    [
        "ValueError, 'does not have enough dimensions'):",
        "ValueError, 'does not have enough"
    ],
    [
        "ValueError, 'inconsistent size for core dimension'):",
        "ValueError, 'inconsistent size for"
    ],
    [
        "with assert_raises_regex(TypeError, 'wrong number of positional'):",
        "with assert_raises_regex(TypeError, 'wrong"
    ],
    [
        "ValueError, 'inconsistent size for core dimension'):",
        "ValueError, 'inconsistent size"
    ],
    [
        "f = vectorize(lambda x: x, signature='()->(),()')",
        "f = vectorize(lambda x: x,"
    ],
    [
        "with assert_raises_regex(ValueError, 'wrong number of outputs'):",
        "with assert_raises_regex(ValueError, 'wrong"
    ],
    [
        "f = vectorize(lambda x: (x, x), signature='()->()')",
        "f = vectorize(lambda x: (x, x),"
    ],
    [
        "with assert_raises_regex(ValueError, 'wrong number of outputs'):",
        "with assert_raises_regex(ValueError, 'wrong"
    ],
    [
        "f = np.vectorize(lambda x: x, signature='()->()')",
        "f = np.vectorize(lambda x:"
    ],
    [
        "f = np.vectorize(lambda x: x, signature='()->()', otypes='i')",
        "f = np.vectorize(lambda x: x, signature='()->()',"
    ],
    [
        "f = np.vectorize(lambda x: x, signature='(n)->(n)', otypes='i')",
        "f = np.vectorize(lambda x:"
    ],
    [
        "f = np.vectorize(lambda x: x, signature='(n)->(n)')",
        "f = np.vectorize(lambda x: x,"
    ],
    [
        "f = np.vectorize(lambda x: [x], signature='()->(n)', otypes='i')",
        "f = np.vectorize(lambda x: [x],"
    ],
    [
        "mult = np.vectorize(lambda x, y: x * y)",
        "mult = np.vectorize(lambda x,"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work correctly\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors"
    ],
    [
        "result = np.median(d, axis=axis, keepdims=True, out=out)",
        "result = np.median(d, axis=axis,"
    ],
    [
        "with pytest.raises(ValueError, match=\"more dimensions than allowed\"):",
        "with pytest.raises(ValueError, match=\"more dimensions"
    ],
    [
        "with pytest.raises(ValueError, match=\"could not be broadcast\"):",
        "with pytest.raises(ValueError, match=\"could not"
    ],
    [
        "with pytest.raises(ValueError, match=\"could not be broadcast\"):",
        "with pytest.raises(ValueError, match=\"could not"
    ],
    [
        "match = \"unsupported keyword arguments for mode '{}'\".format(mode)",
        "match = \"unsupported keyword"
    ],
    [
        "match = \"mode '{}' is not supported\".format(mode)",
        "match = \"mode '{}' is"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import assert_, assert_equal,"
    ],
    [
        "def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):",
        "def __array_ufunc__(self, ufunc, method,"
    ],
    [
        "for x in inputs + out:",
        "for x in inputs"
    ],
    [
        "if not isinstance(x, self._HANDLED_TYPES + (ArrayLike,)):",
        "if not isinstance(x,"
    ],
    [
        "inputs = tuple(x.value if isinstance(x, ArrayLike) else x",
        "inputs = tuple(x.value if isinstance(x, ArrayLike)"
    ],
    [
        "x.value if isinstance(x, ArrayLike) else x",
        "x.value if isinstance(x, ArrayLike) else"
    ],
    [
        "return tuple(type(self)(x) for x in result)",
        "return tuple(type(self)(x) for x"
    ],
    [
        "return tuple(ArrayLike(r) for r in result)",
        "return tuple(ArrayLike(r) for r"
    ],
    [
        "for result_item, expected_item in zip(result, expected):",
        "for result_item, expected_item"
    ],
    [
        "err_msg = 'failed for operator {}'.format(op)",
        "err_msg = 'failed for"
    ],
    [
        "err_msg = 'failed for operator {}'.format(op)",
        "err_msg = 'failed"
    ],
    [
        "from numpy.testing import assert_array_equal, assert_equal, assert_raises",
        "from numpy.testing import assert_array_equal,"
    ],
    [
        "from tempfile import mkdtemp, mkstemp, NamedTemporaryFile",
        "from tempfile import"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import assert_,"
    ],
    [
        "inarrays = [np.zeros(s) for s in input_shapes]",
        "inarrays = [np.zeros(s) for s in"
    ],
    [
        "outshapes = [a.shape for a in outarrays]",
        "outshapes = [a.shape for a in"
    ],
    [
        "inarrays = [np.zeros(s) for s in input_shapes]",
        "inarrays = [np.zeros(s) for s in"
    ],
    [
        "with assert_raises_regex(TypeError, 'got an unexpected keyword'):",
        "with assert_raises_regex(TypeError, 'got an unexpected"
    ],
    [
        "for input_array, shape, expected in data:",
        "for input_array, shape, expected"
    ],
    [
        "with pytest.raises(ValueError, match='cannot contain negative values'):",
        "with pytest.raises(ValueError, match='cannot"
    ],
    [
        "match='must provide window_shape for all dimensions of `x`'):",
        "match='must provide window_shape for all dimensions"
    ],
    [
        "match='Must provide matching length window_shape and axis'):",
        "match='Must provide matching length window_shape"
    ],
    [
        "match='window shape cannot be larger than input array'):",
        "match='window shape cannot be"
    ],
    [
        "self.info = getattr(obj, 'info', '') + ' finalized'",
        "self.info = getattr(obj, 'info', '') + '"
    ],
    [
        "a_view, b_view = broadcast_arrays(a, b, subok=True)",
        "a_view, b_view = broadcast_arrays(a, b,"
    ],
    [
        "for array_is_broadcast, result in zip(is_broadcast, results):",
        "for array_is_broadcast, result in zip(is_broadcast,"
    ],
    [
        "for array_is_broadcast, result in zip(is_broadcast, results):",
        "for array_is_broadcast, result in zip(is_broadcast,"
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int)])])",
        "dtype=[('a', int), ('b', [('ba',"
    ],
    [
        "self.data = (w, x, y, z)",
        "self.data = (w, x, y,"
    ],
    [
        "(w, x, y, z) = self.data",
        "(w, x, y,"
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int)])])",
        "dtype=[('a', int), ('b', [('ba', float),"
    ],
    [
        "test = rename_fields(a, {'a': 'A', 'bb': 'BB'})",
        "test = rename_fields(a, {'a': 'A',"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', [('ba', float), ('bb', int)])])",
        "ndtype = np.dtype([('a', int), ('b', [('ba', float), ('bb',"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', [])])",
        "ndtype = np.dtype([('a', int),"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', [('ba', float), ('bb', int)])])",
        "ndtype = np.dtype([('a', int), ('b', [('ba',"
    ],
    [
        "ndtype = np.dtype([('a', int), ('b', [])])",
        "ndtype = np.dtype([('a',"
    ],
    [
        "assert_equal(test, {'A': [], 'B': [], 'BA': ['B', ], 'BB': ['B']})",
        "assert_equal(test, {'A': [], 'B': [],"
    ],
    [
        "control = {'A': [], 'B': [], 'BA': ['B'], 'BB': ['B'],",
        "control = {'A': [], 'B': [], 'BA': ['B'], 'BB':"
    ],
    [
        "'BBA': ['B', 'BB'], 'BBB': ['B', 'BB']}",
        "'BBA': ['B', 'BB'],"
    ],
    [
        "point = np.dtype([('x', int), ('y', int)])",
        "point = np.dtype([('x', int), ('y',"
    ],
    [
        "triangle = np.dtype([('a', point), ('b', point), ('c', point)])",
        "triangle = np.dtype([('a', point), ('b', point), ('c',"
    ],
    [
        "return np.dtype([('x{}'.format(i), dt) for i, dt in enumerate(dts)])",
        "return np.dtype([('x{}'.format(i), dt) for i, dt in"
    ],
    [
        "test_dtype_args = [('x', float), ('y', float)]",
        "test_dtype_args = [('x',"
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int), ('bc', [])])])",
        "dtype=[('a', int), ('b', [('ba', float), ('bb',"
    ],
    [
        "self.data = (w, x, y, z)",
        "self.data = (w, x, y,"
    ],
    [
        "(_, x, _, z) = self.data",
        "(_, x, _, z) ="
    ],
    [
        "dtype=[('a', int), ('ba', float), ('bb', int)])",
        "dtype=[('a', int), ('ba', float), ('bb',"
    ],
    [
        "(_, x, y, _) = self.data",
        "(_, x, y,"
    ],
    [
        "(_, x, _, z) = self.data",
        "(_, x, _, z) ="
    ],
    [
        "(w, x, _, _) = self.data",
        "(w, x, _,"
    ],
    [
        "('a', int), ('ba', float), ('bb', int)])",
        "('a', int), ('ba', float), ('bb',"
    ],
    [
        "('b', [('ba', float), ('bb', int), ('bc', [])])])]",
        "('b', [('ba', float), ('bb',"
    ],
    [
        "(_, x, _, _) = self.data",
        "(_, x, _, _)"
    ],
    [
        "test = merge_arrays((x, mx), usemask=True, asrecarray=True)",
        "test = merge_arrays((x, mx), usemask=True,"
    ],
    [
        "(_, x, y, z) = self.data",
        "(_, x, y, z) ="
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int)])])",
        "dtype=[('a', int), ('b', [('ba', float),"
    ],
    [
        "self.data = (w, x, y, z)",
        "self.data = (w,"
    ],
    [
        "(_, x, _, _) = self.data",
        "(_, x, _, _)"
    ],
    [
        "(_, x, _, _) = self.data",
        "(_, x, _, _) ="
    ],
    [
        "dtype=[('a', int), ('b', [('ba', float), ('bb', int)])])",
        "dtype=[('a', int), ('b', [('ba', float),"
    ],
    [
        "self.data = (w, x, y, z)",
        "self.data = (w, x,"
    ],
    [
        "(_, x, _, _) = self.data",
        "(_, x, _, _)"
    ],
    [
        "(_, x, y, _) = self.data",
        "(_, x, y,"
    ],
    [
        "(_, x, _, z) = self.data",
        "(_, x, _,"
    ],
    [
        "(_, x, _, z) = self.data",
        "(_, x, _, z) ="
    ],
    [
        "(_, _, _, z) = self.data",
        "(_, _, _, z)"
    ],
    [
        "adtype = [('A', int), ('B', bool), ('C', float)]",
        "adtype = [('A', int), ('B',"
    ],
    [
        "bdtype = [('A', int), ('B', float), ('C', float)]",
        "bdtype = [('A', int),"
    ],
    [
        "adtype = [(('a', 'A'), int), (('b', 'B'), bool), (('c', 'C'), float)]",
        "adtype = [(('a', 'A'), int), (('b',"
    ],
    [
        "bdtype = [(('a', 'A'), int), (('b', 'B'), bool), (('c', 'C'), float)]",
        "bdtype = [(('a', 'A'), int), (('b', 'B'), bool),"
    ],
    [
        "dtype=[('a', int), ('b', int), ('c', int)])",
        "dtype=[('a', int), ('b', int), ('c',"
    ],
    [
        "dtype=[('a', int), ('b', int), ('d', int)])",
        "dtype=[('a', int), ('b', int), ('d',"
    ],
    [
        "test = join_by('a', a, b, jointype='inner')",
        "test = join_by('a', a,"
    ],
    [
        "test = join_by(('a', 'b'), a, b, 'outer')",
        "test = join_by(('a', 'b'),"
    ],
    [
        "test = join_by(('a', 'b'), a, b, 'leftouter')",
        "test = join_by(('a', 'b'), a, b,"
    ],
    [
        "dtype=[('a', int), ('b', int), ('c', int), ('d', int)])",
        "dtype=[('a', int), ('b', int), ('c',"
    ],
    [
        "j = join_by(['c', 'b'], a, b, jointype='inner', usemask=False)",
        "j = join_by(['c', 'b'], a, b, jointype='inner',"
    ],
    [
        "assert_raises(ValueError, join_by, ['a', 'b', 'b'], a, b)",
        "assert_raises(ValueError, join_by, ['a', 'b',"
    ],
    [
        "dtype=[('a', int), ('b', int), ('c', int)])",
        "dtype=[('a', int), ('b', int),"
    ],
    [
        "dtype=[('a', int), ('b', int), ('d', int)])",
        "dtype=[('a', int), ('b', int),"
    ],
    [
        "dtype=[('k', int), ('a', int), ('b', int), ('c', int)])",
        "dtype=[('k', int), ('a', int), ('b',"
    ],
    [
        "dtype=[('k', int), ('a', int), ('b', int), ('c', int)])",
        "dtype=[('k', int), ('a', int),"
    ],
    [
        "IDS = [k.__name__ for k in NANFUNCS]",
        "IDS = [k.__name__ for k in"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in zip(self.nanfuncs,"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in zip(self.nanfuncs,"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "tgt = [rf(d) for d in _rdat]",
        "tgt = [rf(d) for"
    ],
    [
        "for f, fcmp in zip(self.nanfuncs, [np.greater, np.less]):",
        "for f, fcmp in zip(self.nanfuncs, [np.greater,"
    ],
    [
        "\"attempt to get argm.. of an empty sequence\",",
        "\"attempt to get argm.. of an"
    ],
    [
        "nanfunc_ids = [i.__name__ for i in nanfuncs]",
        "nanfunc_ids = [i.__name__ for i"
    ],
    [
        "def test_nanfunc(self, mat, dtype, nanfunc, func):",
        "def test_nanfunc(self, mat,"
    ],
    [
        "def test_nanfunc_q(self, mat, dtype, nanfunc, func):",
        "def test_nanfunc_q(self, mat, dtype, nanfunc,"
    ],
    [
        "def test_nanfunc_ddof(self, mat, dtype, nanfunc, func):",
        "def test_nanfunc_ddof(self, mat,"
    ],
    [
        "err_msg = \"ddof and correction can't be provided simultaneously.\"",
        "err_msg = \"ddof and correction can't be"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in zip(self.nanfuncs,"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf in"
    ],
    [
        "if nf in {np.nanstd, np.nanvar} and c in 'FDG':",
        "if nf in {np.nanstd, np.nanvar} and c in"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "if nf in {np.nanstd, np.nanvar} and c in 'FDG':",
        "if nf in {np.nanstd, np.nanvar} and c"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "assert_(res is tgt, \"res %s, tgt %s\" % (res, tgt))",
        "assert_(res is tgt, \"res %s, tgt %s\""
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "tgt = [rf(d) for d in _rdat]",
        "tgt = [rf(d) for d"
    ],
    [
        "for f, g in zip(self.nanfuncs, self.stdfuncs):",
        "for f, g in zip(self.nanfuncs,"
    ],
    [
        "for nf, rf in zip(self.nanfuncs, self.stdfuncs):",
        "for nf, rf"
    ],
    [
        "for dtype in [np.bool, np.int_, np.object_]:",
        "for dtype in"
    ],
    [
        "for dtype in [np.bool, np.int_, np.object_]:",
        "for dtype in [np.bool,"
    ],
    [
        "for nf, rf in zip(nanfuncs, stdfuncs):",
        "for nf, rf"
    ],
    [
        "tgt = [rf(d, ddof=ddof) for d in _rdat]",
        "tgt = [rf(d, ddof=ddof) for d in"
    ],
    [
        "dsize = [len(d) for d in _rdat]",
        "dsize = [len(d) for d"
    ],
    [
        "for nf, rf in zip(nanfuncs, stdfuncs):",
        "for nf, rf in zip(nanfuncs,"
    ],
    [
        "tgt = [ddof >= d for d in dsize]",
        "tgt = [ddof >= d for d in"
    ],
    [
        "for f, f_std in zip(self.nanfuncs, self.stdfuncs):",
        "for f, f_std in zip(self.nanfuncs,"
    ],
    [
        "dtype_reference = dtype if f is np.nanmean else ar.real.dtype",
        "dtype_reference = dtype if f"
    ],
    [
        "\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \"ps\", \"fs\", \"as\"",
        "\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \"ps\","
    ],
    [
        "tgt = np.median(mat, axis=axis, out=None, overwrite_input=False)",
        "tgt = np.median(mat, axis=axis,"
    ],
    [
        "res = np.nanmedian(mat, axis=axis, out=None, overwrite_input=False)",
        "res = np.nanmedian(mat, axis=axis,"
    ],
    [
        "result = np.nanmedian(d, axis=axis, keepdims=True, out=out)",
        "result = np.nanmedian(d, axis=axis,"
    ],
    [
        "tgt = [np.median(d) for d in _rdat]",
        "tgt = [np.median(d) for"
    ],
    [
        "a = np.array([[inf,  np.nan], [np.nan, np.nan]])",
        "a = np.array([[inf, np.nan], [np.nan,"
    ],
    [
        "a = np.array([[inf, inf], [inf, inf]])",
        "a = np.array([[inf, inf],"
    ],
    [
        "([np.nan] * i) + [inf] * j)",
        "([np.nan] * i) +"
    ],
    [
        "([np.nan] * i) + [-inf] * j)",
        "([np.nan] * i) + [-inf] *"
    ],
    [
        "result = np.nanpercentile(d, q, axis=axis, keepdims=True, out=out)",
        "result = np.nanpercentile(d, q,"
    ],
    [
        "w_args = {\"weights\": np.ones_like(mat), \"method\": \"inverted_cdf\"}",
        "w_args = {\"weights\":"
    ],
    [
        "out = np.empty_like(tgt) if use_out else None",
        "out = np.empty_like(tgt) if use_out"
    ],
    [
        "out = np.empty_like(tgt) if use_out else None",
        "out = np.empty_like(tgt) if use_out else"
    ],
    [
        "val = np.percentile(mat, perc, axis=axis, keepdims=keepdim)",
        "val = np.percentile(mat, perc,"
    ],
    [
        "x, p, axis=axis, weights=weights, out=out, method=\"inverted_cdf\")",
        "x, p, axis=axis, weights=weights, out=out,"
    ],
    [
        "w_args = {\"weights\": np.ones_like(ar), \"method\": \"inverted_cdf\"}",
        "w_args = {\"weights\": np.ones_like(ar),"
    ],
    [
        "for out in [None, np.empty(arr.shape, dtype=np.bool)]:",
        "for out in [None, np.empty(arr.shape,"
    ],
    [
        "@pytest.mark.parametrize(\"comment\", [\"..\", \"//\", \"@-\", \"this is a comment:\"])",
        "@pytest.mark.parametrize(\"comment\", [\"..\", \"//\", \"@-\","
    ],
    [
        "with pytest.raises(ValueError, match=\"argument must be nonnegative\"):",
        "with pytest.raises(ValueError, match=\"argument must"
    ],
    [
        "with pytest.raises(TypeError, match=\"argument must be an integer\"):",
        "with pytest.raises(TypeError, match=\"argument must be"
    ],
    [
        "with pytest.raises(ValueError, match=\"Illegal value of ndmin keyword\"):",
        "with pytest.raises(ValueError, match=\"Illegal value of"
    ],
    [
        "res = np.loadtxt(txt, dtype=np.dtype([]), delimiter=\",\", usecols=[])",
        "res = np.loadtxt(txt, dtype=np.dtype([]), delimiter=\",\","
    ],
    [
        "expected = np.array([['CAT', 'dog'], ['ΑΒΓ', 'δεζ'], ['ABC', 'def']])",
        "expected = np.array([['CAT', 'dog'], ['ΑΒΓ', 'δεζ'], ['ABC',"
    ],
    [
        "res = np.loadtxt(txt, dtype=dt, delimiter=\",\", converters=conv)",
        "res = np.loadtxt(txt, dtype=dt, delimiter=\",\","
    ],
    [
        "\"converters must be a dictionary mapping columns to converter \"",
        "\"converters must be a dictionary mapping columns to converter"
    ],
    [
        "with pytest.raises(TypeError, match=\"keys of the converters dict\"):",
        "with pytest.raises(TypeError, match=\"keys of the"
    ],
    [
        "with pytest.raises(TypeError, match=\"keys of the converters dict\"):",
        "with pytest.raises(TypeError, match=\"keys of"
    ],
    [
        "with pytest.raises(ValueError, match=\"converter specified for column\"):",
        "with pytest.raises(ValueError, match=\"converter specified"
    ],
    [
        "match=\"values of the converters dictionary must be callable\"):",
        "match=\"values of the converters dictionary must"
    ],
    [
        "res = np.loadtxt(txt, dtype=dtype, delimiter=\",\", quotechar=q)",
        "res = np.loadtxt(txt, dtype=dtype, delimiter=\",\","
    ],
    [
        "res = np.loadtxt(txt, dtype=dtype, delimiter=None, quotechar=q)",
        "res = np.loadtxt(txt, dtype=dtype,"
    ],
    [
        "with pytest.warns(UserWarning, match=\"input contained no data\"):",
        "with pytest.warns(UserWarning, match=\"input contained"
    ],
    [
        "with pytest.warns(UserWarning, match=\"input contained no data\"):",
        "with pytest.warns(UserWarning, match=\"input contained"
    ],
    [
        "with pytest.warns(UserWarning, match=\"input contained no data\"):",
        "with pytest.warns(UserWarning, match=\"input contained no"
    ],
    [
        "res = np.loadtxt(txt, dtype=dtype, delimiter=\",\", quotechar='\"')",
        "res = np.loadtxt(txt, dtype=dtype, delimiter=\",\","
    ],
    [
        "pytest.skip(\"half assignment currently uses Python float converter\")",
        "pytest.skip(\"half assignment currently uses"
    ],
    [
        "pytest.xfail(\"clongdouble assignment is buggy (uses `complex`?).\")",
        "pytest.xfail(\"clongdouble assignment is buggy (uses"
    ],
    [
        "msg = \"Found an unquoted embedded newline within a single line\"",
        "msg = \"Found an unquoted embedded newline"
    ],
    [
        "data = [row.replace(\"\\n\", newline) for row in data]",
        "data = [row.replace(\"\\n\", newline) for row in"
    ],
    [
        "res = np.loadtxt(data, dtype=object, delimiter=\",\", quotechar='\"')",
        "res = np.loadtxt(data,"
    ],
    [
        "match=\"error reading from object, expected an iterable\"):",
        "match=\"error reading from object,"
    ],
    [
        "with pytest.raises(TypeError, match=\"internal error: dtype must\"):",
        "with pytest.raises(TypeError, match=\"internal"
    ],
    [
        "with pytest.raises(TypeError, match=\"encoding must be a unicode\"):",
        "with pytest.raises(TypeError, match=\"encoding must be a"
    ],
    [
        "TypeError, match=\"Comment characters.*cannot include the delimiter\"",
        "TypeError, match=\"Comment characters.*cannot include"
    ],
    [
        "msg = \"control character.*cannot be a newline\"",
        "msg = \"control character.*cannot be"
    ],
    [
        "res = np.loadtxt(txt, dtype=str, delimiter=\" \", max_rows=nmax)",
        "res = np.loadtxt(txt, dtype=str, delimiter=\""
    ],
    [
        "res = np.loadtxt(fname, dtype=str, delimiter=\" \", max_rows=nmax)",
        "res = np.loadtxt(fname, dtype=str, delimiter=\""
    ],
    [
        "r''' Test the .npy file format.",
        "r''' Test the .npy file"
    ],
    [
        ">>> for arr in basic_arrays + record_arrays:",
        ">>> for arr in"
    ],
    [
        "from numpy import histogram, histogramdd, histogram_bin_edges",
        "from numpy import"
    ],
    [
        "a, b = histogram(v, bins, density=True)",
        "a, b ="
    ],
    [
        "a, b = histogram(v, bins, density=False)",
        "a, b = histogram(v, bins,"
    ],
    [
        "a, b = histogram(v, bins, density=True)",
        "a, b = histogram(v,"
    ],
    [
        "rec = sup.record(RuntimeWarning, 'Converting input from .*')",
        "rec = sup.record(RuntimeWarning, 'Converting"
    ],
    [
        "hist, edges = np.histogram([True, True, False])",
        "hist, edges = np.histogram([True,"
    ],
    [
        "nwa, nwb = histogram(v, weights=w, density=True)",
        "nwa, nwb = histogram(v,"
    ],
    [
        "with assert_raises_regex(ValueError, \"max must be larger than\"):",
        "with assert_raises_regex(ValueError, \"max must be larger"
    ],
    [
        "for x, left, right in zip(arr, left_edges, right_edges):",
        "for x, left, right"
    ],
    [
        "with pytest.raises(ValueError, match=\"Too many bins for data range\"):",
        "with pytest.raises(ValueError, match=\"Too many bins"
    ],
    [
        "@pytest.mark.skip(reason=\"Bad memory reports lead to OOM in ci testing\")",
        "@pytest.mark.skip(reason=\"Bad memory reports lead to OOM in ci"
    ],
    [
        "hist = np.histogramdd(sample=sample, bins=(xbins, ybins, zbins))",
        "hist = np.histogramdd(sample=sample, bins=(xbins, ybins,"
    ],
    [
        "return a / (a + b)",
        "return a / (a"
    ],
    [
        "hist, edges = histogramdd((x, y), bins=(x_edges, y_edges))",
        "hist, edges = histogramdd((x,"
    ],
    [
        "assert_equal(q * v + r, u)",
        "assert_equal(q * v"
    ],
    [
        "msg = \"Wrong type, should be complex\"",
        "msg = \"Wrong type,"
    ],
    [
        "msg = \"Wrong type, should be float\"",
        "msg = \"Wrong type,"
    ],
    [
        "msg = \"Wrong type, should be complex\"",
        "msg = \"Wrong type, should"
    ],
    [
        "msg = \"Wrong type, should be float\"",
        "msg = \"Wrong type,"
    ],
    [
        "f\"module 'numpy.fft.helper' has no attribute {attr_name}\")",
        "f\"module 'numpy.fft.helper' has no"
    ],
    [
        "\"The numpy.fft.helper has been made private and renamed to \"",
        "\"The numpy.fft.helper has been made private and renamed"
    ],
    [
        "\"numpy.fft._helper. All four functions exported by it (i.e. fftshift, \"",
        "\"numpy.fft._helper. All four functions exported by"
    ],
    [
        "\"ifftshift, fftfreq, rfftfreq) are available from numpy.fft. \"",
        "\"ifftshift, fftfreq, rfftfreq) are available"
    ],
    [
        "with pytest.raises(TypeError, match=\"must be of ArrayType\"):",
        "with pytest.raises(TypeError, match=\"must be of"
    ],
    [
        "match='Invalid number of FFT data points'):",
        "match='Invalid number of FFT"
    ],
    [
        "for norm in [None, 'backward', 'ortho', 'forward']:",
        "for norm in [None, 'backward', 'ortho',"
    ],
    [
        "with pytest.warns(match='`axes` should not be `None` if `s`'):",
        "with pytest.warns(match='`axes` should not be"
    ],
    [
        "with pytest.warns(match='`axes` should not be `None` if `s`'):",
        "with pytest.warns(match='`axes` should not be"
    ],
    [
        "with pytest.warns(match='array containing `None` values to `s`'):",
        "with pytest.warns(match='array containing `None` values to"
    ],
    [
        "for norm in [None, 'backward', 'ortho', 'forward']:",
        "for norm in [None, 'backward',"
    ],
    [
        "'Function returned wrong value in multithreaded context')",
        "'Function returned wrong value"
    ],
    [
        "raise AssertionError(\"No error should have been raised, \"",
        "raise AssertionError(\"No error should have been raised,"
    ],
    [
        "\"but one was with the following \"",
        "\"but one was with the following"
    ],
    [
        "raise AssertionError(\"No error should have been raised, \"",
        "raise AssertionError(\"No error should have been raised,"
    ],
    [
        "\"but one was with the following \"",
        "\"but one was with the"
    ],
    [
        "scalar = random.integers(lbnd, ubnd, size=size, endpoint=endpoint,",
        "scalar = random.integers(lbnd,"
    ],
    [
        "array = random.integers([lbnd] * size, [ubnd] *",
        "array = random.integers([lbnd] *"
    ],
    [
        "actual = random.integers(lbnd, ubnd, endpoint=endpoint, dtype=dt)",
        "actual = random.integers(lbnd, ubnd, endpoint=endpoint,"
    ],
    [
        "dt = np.bool if dt is bool else dt",
        "dt = np.bool if dt is bool"
    ],
    [
        "sample = self.rfunc(lbnd, ubnd, endpoint=endpoint, dtype=dt)",
        "sample = self.rfunc(lbnd, ubnd,"
    ],
    [
        "sample = self.rfunc(lbnd, ubnd, endpoint=endpoint, dtype=dt)",
        "sample = self.rfunc(lbnd,"
    ],
    [
        "dt = np.bool if dt is bool else dt",
        "dt = np.bool if dt is bool"
    ],
    [
        "sample = self.rfunc([lbnd], [ubnd], endpoint=endpoint, dtype=dt)",
        "sample = self.rfunc([lbnd],"
    ],
    [
        "desired = np.array(['a', 'a', 'c', 'c'])",
        "desired = np.array(['a',"
    ],
    [
        "for conv in [lambda x: np.array([]),",
        "for conv in [lambda x:"
    ],
    [
        "lambda x: [(i, i) for i in x],",
        "lambda x: [(i, i) for i in"
    ],
    [
        "lambda x: np.asarray([[i, i] for i in x]),",
        "lambda x: np.asarray([[i, i]"
    ],
    [
        "lambda x: (np.asarray([(i, i) for i in x],",
        "lambda x: (np.asarray([(i, i) for i"
    ],
    [
        "lambda x: np.asarray([(i, i) for i in x],",
        "lambda x: np.asarray([(i, i) for i in"
    ],
    [
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work in wasm\")",
        "@pytest.mark.skipif(IS_WASM, reason=\"fp errors don't work"
    ],
    [
        "actual = random.multivariate_normal(mean, cov, size, method=method)",
        "actual = random.multivariate_normal(mean, cov,"
    ],
    [
        "with pytest.raises(TypeError, match=\"must not be complex\"):",
        "with pytest.raises(TypeError, match=\"must"
    ],
    [
        "s = random.multivariate_normal(mean, cov, size=(n_s,), method=method)",
        "s = random.multivariate_normal(mean, cov,"
    ],
    [
        "assert_(np.all(r > -np.pi) and np.all(r <= np.pi))",
        "assert_(np.all(r > -np.pi) and np.all(r <="
    ],
    [
        "n_shape = () if isinstance(n, int) else n.shape",
        "n_shape = () if isinstance(n, int) else"
    ],
    [
        "out = func(low, high, endpoint=endpoint, dtype=dt)",
        "out = func(low,"
    ],
    [
        "msg = 'low > high' if endpoint else 'low >= high'",
        "msg = 'low > high' if"
    ],
    [
        "ctor, (bit_gen, ), _ = rg.__reduce__()",
        "ctor, (bit_gen, ),"
    ],
    [
        "from numpy.testing import (assert_equal, assert_allclose, assert_array_equal,",
        "from numpy.testing import"
    ],
    [
        "from Cython.Compiler.Version import version as cython_version",
        "from Cython.Compiler.Version import version as"
    ],
    [
        "reason='Editable install cannot find .pxd headers'",
        "reason='Editable install cannot"
    ],
    [
        "build_dir = tmp_path / 'random' / '_examples' / 'cython'",
        "build_dir = tmp_path / 'random' /"
    ],
    [
        "g = glob.glob(str(target_dir / \"*\" / \"extending.pyx.c\"))",
        "g = glob.glob(str(target_dir / \"*\""
    ],
    [
        "txt_to_find = 'NumPy API declarations from \"numpy/__init__'",
        "txt_to_find = 'NumPy API declarations from"
    ],
    [
        "assert False, (\"Could not find '{}' in C file, \"",
        "assert False, (\"Could not find '{}'"
    ],
    [
        "@pytest.mark.skipif(numba is None or cffi is None,",
        "@pytest.mark.skipif(numba is None or cffi"
    ],
    [
        "from numpy.testing import assert_equal, assert_, assert_array_equal",
        "from numpy.testing import assert_equal,"
    ],
    [
        "pytest.skip(f'Advance is not supported by {bitgen_name}')",
        "pytest.skip(f'Advance is not"
    ],
    [
        "pytest.skip(f'Jump is not supported by {bitgen_name}')",
        "pytest.skip(f'Jump is not supported by"
    ],
    [
        "pytest.skip(f'Vector seeding is not supported by {bitgen_name}')",
        "pytest.skip(f'Vector seeding is not"
    ],
    [
        "assert_(np.all(r > -np.pi) and np.all(r <= np.pi))",
        "assert_(np.all(r > -np.pi) and np.all(r <="
    ],
    [
        "probs = np.array(counts, dtype=dt) / sum(counts)",
        "probs = np.array(counts,"
    ],
    [
        "assert_(np.all(r > -np.pi) and np.all(r <= np.pi))",
        "assert_(np.all(r > -np.pi) and np.all(r <="
    ],
    [
        "probs = np.array(counts, dtype=dt) / sum(counts)",
        "probs = np.array(counts, dtype=dt)"
    ],
    [
        "raise AssertionError(\"No error should have been raised, \"",
        "raise AssertionError(\"No error should have been"
    ],
    [
        "\"but one was with the following \"",
        "\"but one was with"
    ],
    [
        "desired = np.array(['c', 'd', 'c', 'd'])",
        "desired = np.array(['c',"
    ],
    [
        "for conv in [lambda x: np.array([]),",
        "for conv in [lambda"
    ],
    [
        "lambda x: [(i, i) for i in x],",
        "lambda x: [(i, i)"
    ],
    [
        "lambda x: np.asarray([[i, i] for i in x]),",
        "lambda x: np.asarray([[i, i]"
    ],
    [
        "lambda x: (np.asarray([(i, i) for i in x],",
        "lambda x: (np.asarray([(i, i) for i in"
    ],
    [
        "lambda x: np.asarray([(i, i) for i in x],",
        "lambda x: np.asarray([(i, i) for i in"
    ],
    [
        "match=\"you are shuffling a 'dict' object\") as rec:",
        "match=\"you are shuffling a 'dict'"
    ],
    [
        "item_ids = {id(i) for i in items}",
        "item_ids = {id(i) for i in"
    ],
    [
        "assert all(id(i) in item_ids for i in arr)",
        "assert all(id(i) in item_ids for i"
    ],
    [
        "if use_array_like and not isinstance(random, np.random.Generator):",
        "if use_array_like and not"
    ],
    [
        "assert all(id(i) in item_ids for i in arr)",
        "assert all(id(i) in item_ids for"
    ],
    [
        "assert_(np.all(r > -np.pi) and np.all(r <= np.pi))",
        "assert_(np.all(r > -np.pi) and np.all(r"
    ],
    [
        "probs = np.array(counts, dtype=dt) / sum(counts)",
        "probs = np.array(counts,"
    ],
    [
        "mask = delta = ub - lb",
        "mask = delta ="
    ],
    [
        "Building the required library in this example requires a source distribution",
        "Building the required library in this example"
    ],
    [
        "of NumPy or clone of the NumPy git repository since distributions.c is not",
        "of NumPy or clone of the NumPy git repository since"
    ],
    [
        "gcc -shared -o libdistributions.so -fPIC distributions.c \\",
        "gcc -shared -o libdistributions.so"
    ],
    [
        "rem PYTHON_HOME and PYTHON_VERSION are setup dependent, this is an example",
        "rem PYTHON_HOME and PYTHON_VERSION are setup dependent, this is"
    ],
    [
        "raise ValueError(\"Rows not the same size.\")",
        "raise ValueError(\"Rows not the same"
    ],
    [
        "from numpy import matrix, asmatrix, bmat",
        "from numpy import"
    ],
    [
        "C = bmat([[A, A], [A, A]])",
        "C = bmat([[A, A],"
    ],
    [
        "np.all(bmat(\"A,A;A,A\", ldict={'A': A}, gdict={'A': B}) == Aresult))",
        "np.all(bmat(\"A,A;A,A\", ldict={'A': A}, gdict={'A': B})"
    ],
    [
        "from numpy.ma.testutils import (assert_, assert_equal, assert_raises,",
        "from numpy.ma.testutils import (assert_,"
    ],
    [
        "from numpy.ma.core import (masked_array, masked_values, masked, allequal,",
        "from numpy.ma.core import (masked_array,"
    ],
    [
        "a = masked_array(iterator, dtype=[('a', float), ('b', float)])",
        "a = masked_array(iterator, dtype=[('a', float), ('b',"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_array_equal",
        "from numpy.testing import assert_,"
    ],
    [
        "from numpy.testing import assert_, assert_equal, assert_raises",
        "from numpy.testing import assert_,"
    ],
    [
        "coef_str = f\" + {self._repr_latex_scalar(c, parens=True)}\"",
        "coef_str = f\" + {self._repr_latex_scalar(c,"
    ],
    [
        "coef_str = f\" - {self._repr_latex_scalar(-c, parens=True)}\"",
        "coef_str = f\""
    ],
    [
        "if not isinstance(other, numbers.Number) or isinstance(other, bool):",
        "if not isinstance(other, numbers.Number) or"
    ],
    [
        "f\"unsupported types for true division: \"",
        "f\"unsupported types for true division:"
    ],
    [
        "quo = self.__class__(quo, self.domain, self.window, self.symbol)",
        "quo = self.__class__(quo, self.domain, self.window,"
    ],
    [
        "rem = self.__class__(rem, self.domain, self.window, self.symbol)",
        "rem = self.__class__(rem,"
    ],
    [
        "res = self.__class__(coef, self.domain, self.window, self.symbol)",
        "res = self.__class__(coef,"
    ],
    [
        "quo = self.__class__(quo, self.domain, self.window, self.symbol)",
        "quo = self.__class__(quo,"
    ],
    [
        "rem = self.__class__(rem, self.domain, self.window, self.symbol)",
        "rem = self.__class__(rem, self.domain, self.window,"
    ],
    [
        "from numpy._core import array, arange, printoptions",
        "from numpy._core import"
    ],
    [
        "obj._repr_latex_scalar = lambda x, parens=False: str(x)",
        "obj._repr_latex_scalar = lambda x,"
    ],
    [
        "line for line in data if line.startswith('version =')",
        "line for line in data if"
    ],
    [
        "parser.add_argument('--write', help=\"Save version to this file\")",
        "parser.add_argument('--write', help=\"Save version to"
    ],
    [
        "help='Output path is relative to MESON_DIST_ROOT',",
        "help='Output path is relative to"
    ],
    [
        "msg += \" in %s\" % self.name",
        "msg += \" in %s\" %"
    ],
    [
        "if name is None and stacklevel is not None:",
        "if name is None and"
    ],
    [
        "return \"<%s %s name=%r>\" % (",
        "return \"<%s %s name=%r>\" %"
    ],
    [
        "raise TypeError(\"You can only give positional *or* keyword arguments\")",
        "raise TypeError(\"You can only give positional"
    ],
    [
        "raise TypeError(\"You can only give one positional argument\")",
        "raise TypeError(\"You can only"
    ],
    [
        "\"If you pass in a single argument, you must pass in a \"",
        "\"If you pass in a single argument, you must pass in a"
    ],
    [
        "\"dictionary-like object (with a .items() method); you gave %r\"",
        "\"dictionary-like object (with a .items() method); you"
    ],
    [
        "result = self._interpret_inherit(result, defs, inherit, ns)",
        "result = self._interpret_inherit(result,"
    ],
    [
        "def _interpret_inherit(self, body, defs, inherit_template, ns):",
        "def _interpret_inherit(self, body, defs,"
    ],
    [
        "\"You cannot use inheritance without passing in get_template\",",
        "\"You cannot use inheritance without passing in"
    ],
    [
        "def _interpret_codes(self, codes, ns, out, defs):",
        "def _interpret_codes(self, codes, ns, out,"
    ],
    [
        "def _interpret_code(self, code, ns, out, defs):",
        "def _interpret_code(self, code,"
    ],
    [
        "self._interpret_for(vars, expr, content, ns, out, defs)",
        "self._interpret_for(vars, expr, content,"
    ],
    [
        "self, name, signature, body=parts, ns=ns, pos=pos",
        "self, name, signature, body=parts, ns=ns,"
    ],
    [
        "def _interpret_for(self, vars, expr, content, ns, out, defs):",
        "def _interpret_for(self, vars, expr, content,"
    ],
    [
        "\"Need %i items to unpack (got %i items)\"",
        "\"Need %i items to unpack (got %i"
    ],
    [
        "for name, value in zip(vars, item):",
        "for name, value in"
    ],
    [
        "def _interpret_if(self, parts, ns, out, defs):",
        "def _interpret_if(self, parts, ns,"
    ],
    [
        "raise SyntaxError(\"invalid syntax in expression: %s\" % code)",
        "raise SyntaxError(\"invalid syntax in expression: %s\""
    ],
    [
        "\"Cannot decode bytes value %r into unicode \"",
        "\"Cannot decode bytes value %r into"
    ],
    [
        "e.reason + \" in string %r\" % value,",
        "e.reason + \" in string %r\""
    ],
    [
        "elif not self._unicode and isinstance(value, str):",
        "elif not self._unicode and isinstance(value,"
    ],
    [
        "\"Cannot encode unicode value %r into bytes \"",
        "\"Cannot encode unicode value %r"
    ],
    [
        "msg += \" in file %s\" % self.name",
        "msg += \" in file"
    ],
    [
        "\" \".join([\"%s=%r\" % (k, v) for k, v in sorted(self.items())]),",
        "\" \".join([\"%s=%r\" % (k, v) for k,"
    ],
    [
        "self, template, func_name, func_signature, body, ns, pos, bound_self=None",
        "self, template, func_name, func_signature,"
    ],
    [
        "return \"<tempita function %s(%s) at %s:%s>\" % (",
        "return \"<tempita function %s(%s) at %s:%s>\" %"
    ],
    [
        "sig_args, var_args, var_kw, defaults = self._func_signature",
        "sig_args, var_args, var_kw, defaults ="
    ],
    [
        "if not var_kw and name not in sig_args:",
        "if not var_kw and name"
    ],
    [
        "raise TypeError(\"Unexpected argument %s\" % name)",
        "raise TypeError(\"Unexpected argument %s\""
    ],
    [
        "\"Extra position arguments: %s\" % \", \".join([repr(v) for v in args])",
        "\"Extra position arguments: %s\" % \", \".join([repr(v) for v in"
    ],
    [
        "raise TypeError(\"Missing argument: %s\" % name)",
        "raise TypeError(\"Missing argument:"
    ],
    [
        "return \"<%s %s>\" % (self.__class__.__name__, self.__name)",
        "return \"<%s %s>\" %"
    ],
    [
        "return \"<%s around %r>\" % (self.__class__.__name__, self.__template_obj)",
        "return \"<%s around %r>\" % (self.__class__.__name__,"
    ],
    [
        "column = index - string.rfind(\"\\n\", last_index, index)",
        "column = index - string.rfind(\"\\n\", last_index,"
    ],
    [
        "Parses a string into a kind of AST",
        "Parses a string into a kind of"
    ],
    [
        ">>> parse('{{for x, y in z:}}{{continue}}{{endfor}}')",
        ">>> parse('{{for x,"
    ],
    [
        ">>> parse('{{if x}}{{for x in y}}{{endif}}{{endfor}}')",
        ">>> parse('{{if x}}{{for x in"
    ],
    [
        "UFUNCS = [obj for obj in np._core.umath.__dict__.values() if",
        "UFUNCS = [obj for obj in np._core.umath.__dict__.values()"
    ],
    [
        "UFUNCS_UNARY = [uf for uf in UFUNCS if \"O->O\" in uf.types]",
        "UFUNCS_UNARY = [uf for uf in"
    ],
    [
        "if ufunc_insig + dtype not in ufunc.types:",
        "if ufunc_insig + dtype not"
    ],
    [
        "test = [sig for sig in ufunc.types if sig.startswith(st_sig)]",
        "test = [sig for sig in"
    ],
    [
        "param_names = ['ufunc', 'stride_in', 'stride_out', 'dtype']",
        "param_names = ['ufunc', 'stride_in',"
    ],
    [
        "def setup(self, ufunc, stride_in, stride_out, dtype):",
        "def setup(self, ufunc, stride_in, stride_out,"
    ],
    [
        "if ufunc_insig + dtype not in ufunc.types:",
        "if ufunc_insig + dtype"
    ],
    [
        "test = [sig for sig in ufunc.types if sig.startswith(ufunc_insig)]",
        "test = [sig for sig in ufunc.types if"
    ],
    [
        "def time_unary(self, ufunc, stride_in, stride_out, dtype):",
        "def time_unary(self, ufunc, stride_in, stride_out,"
    ],
    [
        "params = [[uf for uf in UFUNCS_UNARY",
        "params = [[uf for"
    ],
    [
        "if uf not in (np.invert, np.bitwise_count)],",
        "if uf not in (np.invert,"
    ],
    [
        "def setup(self, ufunc, stride_in, stride_out, dtype):",
        "def setup(self, ufunc,"
    ],
    [
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L', 'q', 'Q']",
        "['b', 'B', 'h', 'H', 'i',"
    ],
    [
        "[getattr(np, uf) for uf in (",
        "[getattr(np, uf) for"
    ],
    [
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L', 'q', 'Q']",
        "['b', 'B', 'h', 'H', 'i', 'I', 'l',"
    ],
    [
        "[getattr(np, uf) for uf in (",
        "[getattr(np, uf) for"
    ],
    [
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L', 'q', 'Q']",
        "['b', 'B', 'h', 'H', 'i', 'I', 'l', 'L',"
    ],
    [
        "def mandelbrot_set(self, xmin, xmax, ymin, ymax, width, height, maxiter):",
        "def mandelbrot_set(self, xmin, xmax, ymin, ymax, width,"
    ],
    [
        "self.W = self.W - self.alpha * dw",
        "self.W = self.W - self.alpha"
    ],
    [
        "func = {'inplace': num_inplace, 'normal': num_update}[update]",
        "func = {'inplace':"
    ],
    [
        "def __array_function__(self, func, types, args, kwargs):",
        "def __array_function__(self, func, types, args,"
    ],
    [
        "info = \"NumPy CPU features: \" + (info if info else 'nothing enabled')",
        "info = \"NumPy CPU features: \" + (info if info else"
    ],
    [
        "if not ppid or ppid == os.getpid():",
        "if not ppid or ppid =="
    ],
    [
        "params = [float(x) for x in items]",
        "params = [float(x) for x in"
    ],
    [
        "CACHE_ROOT = Path(__file__).resolve().parent.parent / 'env' / 'numpy_benchdata'",
        "CACHE_ROOT = Path(__file__).resolve().parent.parent / 'env'"
    ],
    [
        "params = [['ravel', 'transpose', 'compressed', 'conjugate'],",
        "params = [['ravel', 'transpose', 'compressed',"
    ],
    [
        "self.small = np.ma.array(data, mask=(data <= prop_mask))",
        "self.small = np.ma.array(data,"
    ],
    [
        "self.large = np.ma.array(data, mask=(data <= prop_mask))",
        "self.large = np.ma.array(data, mask=(data"
    ],
    [
        "self.small = np.ma.array(data, mask=(data <= prop_mask))",
        "self.small = np.ma.array(data, mask=(data"
    ],
    [
        "self.large = np.ma.array(data, mask=(data <= prop_mask))",
        "self.large = np.ma.array(data,"
    ],
    [
        "['==', '!=', '<', '<=', '>', '>=']]",
        "['==', '!=', '<', '<=', '>',"
    ],
    [
        "param_names = ['shape', 'dtype', 'contig', 'operator']",
        "param_names = ['shape', 'dtype',"
    ],
    [
        "def setup(self, shape, dtype, contig, operator):",
        "def setup(self, shape,"
    ],
    [
        "def time_compare_identical(self, shape, dtype, contig, operator):",
        "def time_compare_identical(self, shape, dtype, contig,"
    ],
    [
        "def time_compare_different(self, shape, dtype, contig, operator):",
        "def time_compare_different(self, shape,"
    ],
    [
        "res = n + n + n + n + n + n + n + n + n + n",
        "res = n + n + n + n + n"
    ],
    [
        "res = n * n * n * n * n * n * n * n * n * n",
        "res = n * n * n * n * n * n * n * n * n *"
    ],
    [
        "res = [str(x) for x in self.a]",
        "res = [str(x) for x in"
    ],
    [
        "[np.full(shape=[s // n_chunk for s, n_chunk in zip(shape, n_chunks)],",
        "[np.full(shape=[s // n_chunk for s, n_chunk in"
    ],
    [
        "ufuncs = ['abs', 'absolute', 'add', 'arccos', 'arccosh', 'arcsin', 'arcsinh',",
        "ufuncs = ['abs', 'absolute', 'add', 'arccos', 'arccosh', 'arcsin',"
    ],
    [
        "'bitwise_or', 'bitwise_xor', 'cbrt', 'ceil', 'conj', 'conjugate',",
        "'bitwise_or', 'bitwise_xor', 'cbrt', 'ceil', 'conj',"
    ],
    [
        "'floor_divide', 'fmax', 'fmin', 'fmod', 'frexp', 'gcd', 'greater',",
        "'floor_divide', 'fmax', 'fmin', 'fmod', 'frexp', 'gcd',"
    ],
    [
        "'isinf', 'isnan', 'isnat', 'lcm', 'ldexp', 'left_shift', 'less',",
        "'isinf', 'isnan', 'isnat', 'lcm',"
    ],
    [
        "'logical_xor', 'matmul', 'matvec', 'maximum', 'minimum', 'mod',",
        "'logical_xor', 'matmul', 'matvec', 'maximum',"
    ],
    [
        "'modf', 'multiply', 'negative', 'nextafter', 'not_equal', 'positive',",
        "'modf', 'multiply', 'negative',"
    ],
    [
        "'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',",
        "'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan',"
    ],
    [
        "raise ValueError(f\"Bench target `np.{name}` is not a ufunc\")",
        "raise ValueError(f\"Bench target `np.{name}` is not a"
    ],
    [
        "all_ufuncs = (getattr(np, name, None) for name in dir(np))",
        "all_ufuncs = (getattr(np, name, None)"
    ],
    [
        "all_ufuncs = set(filter(lambda f: isinstance(f, np.ufunc), all_ufuncs))",
        "all_ufuncs = set(filter(lambda f: isinstance(f, np.ufunc),"
    ],
    [
        "bench_ufuncs = {getattr(np, name, None) for name in ufuncs}",
        "bench_ufuncs = {getattr(np, name, None) for name in"
    ],
    [
        "missing_ufunc_names = [f.__name__ for f in missing_ufuncs]",
        "missing_ufunc_names = [f.__name__ for"
    ],
    [
        "\"Missing benchmarks for ufuncs %r\" % missing_ufunc_names)",
        "\"Missing benchmarks for ufuncs"
    ],
    [
        "from os.path import join as pjoin",
        "from os.path import join"
    ],
    [
        "param_names = ['dtype', 'indexes', 'sel', 'op']",
        "param_names = ['dtype', 'indexes', 'sel',"
    ],
    [
        "def setup(self, dtype, indexes, sel, op):",
        "def setup(self, dtype,"
    ],
    [
        "code = code % (sel, op)",
        "code = code %"
    ],
    [
        "def time_op(self, dtype, indexes, sel, op):",
        "def time_op(self, dtype,"
    ],
    [
        "from .common import Benchmark, get_squares, get_squares_",
        "from .common import"
    ],
    [
        "from io import SEEK_SET, StringIO, BytesIO",
        "from io import SEEK_SET,"
    ],
    [
        "for date, value in zip(dates, values):",
        "for date, value in zip(dates,"
    ],
    [
        "date_line += (str(date) + ',' + str(value) + '\\n')",
        "date_line += (str(date) + ',' + str(value) +"
    ],
    [
        "self.xarg = [x.astype(ndtype) for x in self.xarg]",
        "self.xarg = [x.astype(ndtype) for x"
    ],
    [
        "self.l_view = [memoryview(a) for a in self.l]",
        "self.l_view = [memoryview(a) for a"
    ],
    [
        "self.x = np.arange(numaxes * size).reshape(numaxes, size)",
        "self.x = np.arange(numaxes"
    ],
    [
        "description=\"a minimal example package (fortran version)\",",
        "description=\"a minimal example package"
    ],
    [
        "title = 'NumPy Enhancement Proposals Documentation'",
        "title = 'NumPy Enhancement"
    ],
    [
        "author, 'NumPyEnhancementProposals', 'One line description of project.',",
        "author, 'NumPyEnhancementProposals', 'One line description of"
    ],
    [
        "replaced_neps = [int(s) for s in replaces]",
        "replaced_neps = [int(s) for s in"
    ]
]