[
[
    "if using_infer_string and dtype == \"object\":",
    "if using_infer_string and dtype"
],
[
    "msg = \"MultiIndex has no single backing array\"",
    "msg = \"MultiIndex has no single"
],
[
    "(pd.Categorical([\"a\", \"b\"]), np.array([\"a\", \"b\"], dtype=object), False),",
    "(pd.Categorical([\"a\", \"b\"]), np.array([\"a\", \"b\"], dtype=object),"
],
[
    "with pytest.raises(ValueError, match=\"Unable to avoid copy while creating\"):",
    "with pytest.raises(ValueError, match=\"Unable to avoid copy"
],
[
    "if using_infer_string and arr.dtype == object and obj.dtype.storage == \"pyarrow\":",
    "if using_infer_string and arr.dtype =="
],
[
    "if using_infer_string and arr.dtype == object and obj.dtype.storage == \"pyarrow\":",
    "if using_infer_string and arr.dtype == object"
],
[
    "msg = r\"to_numpy\\(\\) got an unexpected keyword argument 'foo'\"",
    "msg = r\"to_numpy\\(\\) got an unexpected keyword"
],
[
    "@pytest.mark.parametrize(\"dtype, na_value\", [(float, np.nan), (object, None)])",
    "@pytest.mark.parametrize(\"dtype, na_value\", [(float, np.nan),"
],
[
    "pytest.skip(\"type doesn't allow for NA operations\")",
    "pytest.skip(\"type doesn't allow for"
],
[
    "pytest.skip(\"Test doesn't make sense on empty data\")",
    "pytest.skip(\"Test doesn't make sense on"
],
[
    "unique_values_not_null = [val for val in unique_values_raw if not pd.isnull(val)]",
    "unique_values_not_null = [val for val"
],
[
    "pytest.skip(\"type doesn't allow for NA operations\")",
    "pytest.skip(\"type doesn't allow for"
],
[
    "ser = pd.Series([\"yes\", \"yes\", pd.NA, np.nan, None, pd.NaT])",
    "ser = pd.Series([\"yes\", \"yes\","
],
[
    "mutable_regex = re.compile(\"does not support mutable operations\")",
    "mutable_regex = re.compile(\"does not support"
],
[
    "msg = \"'(_s)?re.(SRE_)?Pattern' object is not callable\"",
    "msg = \"'(_s)?re.(SRE_)?Pattern' object is"
],
[
    "mutable_methods = (\"extend\", \"pop\", \"remove\", \"insert\")",
    "mutable_methods = (\"extend\","
],
[
    "msg = \"^'str' object cannot be interpreted as an integer$\"",
    "msg = \"^'str' object cannot be interpreted"
],
[
    "from pandas._libs import index as libindex",
    "from pandas._libs import index as"
],
[
    "expected = np.array([False, True, False] * num, dtype=bool)",
    "expected = np.array([False, True,"
],
[
    "arr = np.array([\"a\"] * num + [\"a\"] * num + [\"c\"] * num, dtype=self.dtype)",
    "arr = np.array([\"a\"] * num + [\"a\"] * num + [\"c\"] * num,"
],
[
    "arr = np.array([\"a\"] * num + [\"b\"] * num + [\"a\"] * num, dtype=self.dtype)",
    "arr = np.array([\"a\"] * num + [\"b\"] * num + [\"a\"] * num,"
],
[
    "arr = np.array([\"a\", \"b\", \"a\"], dtype=self.dtype)",
    "arr = np.array([\"a\","
],
[
    "arr = np.array([\"a\"] * num + [\"b\"] * num + [\"c\"] * num, dtype=self.dtype)",
    "arr = np.array([\"a\"] * num + [\"b\"] * num + [\"c\"]"
],
[
    "arr = np.array(self.values * num, dtype=self.dtype)",
    "arr = np.array(self.values *"
],
[
    "expected = np.array([False, True, False] * num, dtype=bool)",
    "expected = np.array([False, True, False] *"
],
[
    "r\"Index\\(\\.\\.\\.\\) must be called with a collection of some \"",
    "r\"Index\\(\\.\\.\\.\\) must be called with"
],
[
    "r\"DatetimeIndex\\(\\) must be called with a collection of some \"",
    "r\"DatetimeIndex\\(\\) must be called with a collection of some"
],
[
    "r\"TimedeltaIndex\\(\\) must be called with a collection of some \"",
    "r\"TimedeltaIndex\\(\\) must be called with"
],
[
    "f\"This method is only implemented for DatetimeIndex, PeriodIndex and \"",
    "f\"This method is only implemented for DatetimeIndex, PeriodIndex"
],
[
    "with pytest.raises(TypeError, match=\"Index.name must be a hashable type\"):",
    "with pytest.raises(TypeError, match=\"Index.name must be a hashable"
],
[
    "rf\"unsupported operand type\\(s\\) for \\*: '{typ}' and 'int'\",",
    "rf\"unsupported operand type\\(s\\) for \\*: '{typ}' and"
],
[
    "rf\"unsupported operand type\\(s\\) for \\*: 'int' and '{typ}'\",",
    "rf\"unsupported operand type\\(s\\) for \\*: 'int'"
],
[
    "msg = \"does not support operation '(any|all)'\"",
    "msg = \"does not support"
],
[
    "pytest.skip(f\"Not a valid repr for {type(simple_index).__name__}\")",
    "pytest.skip(f\"Not a valid repr"
],
[
    "pytest.skip(f\"Not a valid repr for {type(simple_index).__name__}\")",
    "pytest.skip(f\"Not a valid repr for"
],
[
    "\"RangeIndex cannot be initialized from data, \"",
    "\"RangeIndex cannot be initialized"
],
[
    "\"MultiIndex and CategoricalIndex are tested separately\"",
    "\"MultiIndex and CategoricalIndex"
],
[
    "elif index.dtype == object and index.inferred_type in [\"boolean\", \"string\"]:",
    "elif index.dtype == object and index.inferred_type"
],
[
    "elif type(index) is Index and not isinstance(index.dtype, np.dtype):",
    "elif type(index) is Index"
],
[
    "isinstance(index.dtype, StringDtype) and index.dtype.storage == \"python\"",
    "isinstance(index.dtype, StringDtype) and index.dtype.storage"
],
[
    "if not isinstance(index, (RangeIndex, IntervalIndex)) and not (",
    "if not isinstance(index, (RangeIndex,"
],
[
    "type(index) is Index and not isinstance(index.dtype, np.dtype)",
    "type(index) is Index and not isinstance(index.dtype,"
],
[
    "msg = \"the 'axis' parameter is not supported\"",
    "msg = \"the 'axis'"
],
[
    "msg = \"the 'order' parameter is not supported\"",
    "msg = \"the 'order' parameter is"
],
[
    "msg = \"the 'axis' parameter is not supported\"",
    "msg = \"the 'axis' parameter is not"
],
[
    "if isinstance(simple_index, (IntervalIndex, PeriodIndex)) or is_numeric_dtype(",
    "if isinstance(simple_index, (IntervalIndex,"
],
[
    "msg = \"slice indices must be integers or None or have an __index__ method\"",
    "msg = \"slice indices must be integers or None"
],
[
    "index.dtype == \"string\" or index.dtype == \"category\"",
    "index.dtype == \"string\" or"
],
[
    "msg = \"loc must be an integer between\"",
    "msg = \"loc must be an"
],
[
    "\"loc must be an integer between\",",
    "\"loc must be"
],
[
    "is_ea_idx = type(index) is Index and not isinstance(index.dtype, np.dtype)",
    "is_ea_idx = type(index) is Index and not"
],
[
    "if not isinstance(index, RangeIndex) and not is_ea_idx:",
    "if not isinstance(index, RangeIndex) and"
],
[
    "msg = \"Lengths must match|could not be broadcast\"",
    "msg = \"Lengths must"
],
[
    "msg = \"Can only compare identically-labeled Series objects\"",
    "msg = \"Can only compare identically-labeled Series"
],
[
    "pytest.skip(f\"Not relevant for Index with {index.dtype}\")",
    "pytest.skip(f\"Not relevant for"
],
[
    "msg = \"isna is not defined for MultiIndex\"",
    "msg = \"isna is"
],
[
    "msg = \"'value' must be a scalar, passed: \"",
    "msg = \"'value' must be a"
],
[
    "expected = np.array([False] * len(idx), dtype=bool)",
    "expected = np.array([False] *"
],
[
    "msg = \"isna is not defined for MultiIndex\"",
    "msg = \"isna is not defined for"
],
[
    "lambda values, index: {i: e for e, i in zip(values, index)},",
    "lambda values, index: {i: e for e, i in"
],
[
    "expected = Index([np.nan] * len(idx), dtype=dtype)",
    "expected = Index([np.nan]"
],
[
    "expected = Index([str(x) for x in idx])",
    "expected = Index([str(x) for x in"
],
[
    "def test_astype_category(self, copy, name, ordered, simple_index):",
    "def test_astype_category(self, copy, name,"
],
[
    "msg = \"ufunc 'invert' not supported for the input types\"",
    "msg = \"ufunc 'invert' not"
],
[
    "msg = \"bad operand|__invert__ is not supported for string dtype\"",
    "msg = \"bad operand|__invert__ is not"
],
[
    "\"Cannot change data-type for array of references.|\"",
    "\"Cannot change data-type for"
],
[
    "\"Cannot change data-type for object array.|\"",
    "\"Cannot change data-type for"
],
[
    "assert type(result) is Index and result.dtype == complex_dtype",
    "assert type(result) is Index"
],
[
    "pytest.skip(\"casting of strings not relevant for RangeIndex\")",
    "pytest.skip(\"casting of strings not relevant"
],
[
    "dtype = object if not using_infer_string else \"str\"",
    "dtype = object if not"
],
[
    "err = tz_naive_fixture is not None",
    "err = tz_naive_fixture is not"
],
[
    "msg = \"Cannot use .astype to convert from timezone-naive dtype to\"",
    "msg = \"Cannot use .astype to convert from timezone-naive dtype"
],
[
    "@pytest.mark.parametrize(\"value\", [[], iter([]), (_ for _ in [])])",
    "@pytest.mark.parametrize(\"value\", [[], iter([]), (_"
],
[
    "(PeriodIndex((_ for _ in []), freq=\"D\"), PeriodIndex),",
    "(PeriodIndex((_ for _ in"
],
[
    "msg = \"When changing to a larger dtype\"",
    "msg = \"When changing"
],
[
    "r\"Cannot change data-type for array of references\\.|\"",
    "r\"Cannot change data-type for array"
],
[
    "r\"Cannot change data-type for object array\\.|\"",
    "r\"Cannot change data-type"
],
[
    "r\"Cannot change data-type for array of strings\\.|\"",
    "r\"Cannot change data-type for"
],
[
    "assert Index([\"a\", \"b\", \"c\"]).equals(Index([\"a\", \"b\", \"c\"]))",
    "assert Index([\"a\", \"b\", \"c\"]).equals(Index([\"a\", \"b\","
],
[
    "\"comp\", [Index([\"a\", \"b\"]), Index([\"a\", \"b\", \"d\"]), [\"a\", \"b\", \"c\"]]",
    "\"comp\", [Index([\"a\", \"b\"]), Index([\"a\", \"b\", \"d\"]), [\"a\", \"b\","
],
[
    "def test_empty_fancy(self, index, dtype, request, using_infer_string):",
    "def test_empty_fancy(self, index, dtype, request,"
],
[
    "if dtype is np.bool_ and using_infer_string and index.dtype == \"string\":",
    "if dtype is np.bool_ and using_infer_string and"
],
[
    "with pytest.raises(ValueError, match=\"length of the boolean indexer\"):",
    "with pytest.raises(ValueError, match=\"length of"
],
[
    "msg = r\"arrays used as indices must be of integer\"",
    "msg = r\"arrays used as indices must be of"
],
[
    "expected = Index([(i,) for i in index])",
    "expected = Index([(i,) for i"
],
[
    "lambda values, index: {i: e for e, i in zip(values, index)},",
    "lambda values, index: {i: e for e, i"
],
[
    "lambda values, index: {i: e for e, i in zip(values, index)},",
    "lambda values, index: {i: e for"
],
[
    "elif type(index) is Index and index.dtype != object:",
    "elif type(index) is Index and"
],
[
    "if using_infer_string and index.dtype == \"string\" and expected:",
    "if using_infer_string and index.dtype"
],
[
    "[[\"a\", \"b\", (\"c\", \"d\")], [\"a\", (\"c\", \"d\"), \"b\"], [(\"c\", \"d\"), \"a\", \"b\"]],",
    "[[\"a\", \"b\", (\"c\", \"d\")], [\"a\", (\"c\", \"d\"),"
],
[
    "@pytest.mark.parametrize(\"to_drop\", [[(\"c\", \"d\"), \"a\"], [\"a\", (\"c\", \"d\")]])",
    "@pytest.mark.parametrize(\"to_drop\", [[(\"c\", \"d\"), \"a\"],"
],
[
    "pytest.skip(\"Test doesn't make sense for empty MultiIndex\")",
    "pytest.skip(\"Test doesn't make sense for empty"
],
[
    "@pytest.mark.parametrize(\"values\", [[\"foo\", \"bar\", \"quux\"], {\"foo\", \"bar\", \"quux\"}])",
    "@pytest.mark.parametrize(\"values\", [[\"foo\", \"bar\", \"quux\"], {\"foo\", \"bar\","
],
[
    "([\"qux\", \"baz\", \"foo\", \"bar\"], [False, False, True, True]),",
    "([\"qux\", \"baz\", \"foo\", \"bar\"], [False, False,"
],
[
    "elif using_infer_string and idx.dtype == \"string\":",
    "elif using_infer_string and idx.dtype"
],
[
    "if nulls_fixture is pd.NaT or nulls_fixture is pd.NA:",
    "if nulls_fixture is pd.NaT"
],
[
    "r\"float\\(\\) argument must be a string or a (real )?number, \"",
    "r\"float\\(\\) argument must be a string or a"
],
[
    "expected = np.array([False, False, True, True])",
    "expected = np.array([False,"
],
[
    "msg = f\"'Level {label} not found'\"",
    "msg = f\"'Level"
],
[
    "msg = rf\"Requested level \\({label}\\) does not match index name \\(foo\\)\"",
    "msg = rf\"Requested level \\({label}\\) does not match"
],
[
    "expected = np.array([True, True, True, True], dtype=bool)",
    "expected = np.array([True, True,"
],
[
    "\"func\", [np.isfinite, np.isinf, np.isnan, np.signbit], ids=lambda x: x.__name__",
    "\"func\", [np.isfinite, np.isinf, np.isnan, np.signbit], ids=lambda"
],
[
    "if func in (np.isfinite, np.isinf, np.isnan):",
    "if func in"
],
[
    "pytest.skip(\"Test doesn't make sense for empty index.\")",
    "pytest.skip(\"Test doesn't make sense for"
],
[
    "if isinstance(index, CategoricalIndex) and index.dtype.ordered is False:",
    "if isinstance(index, CategoricalIndex) and"
],
[
    "with pytest.raises(TypeError, match=\"is not ordered for\"):",
    "with pytest.raises(TypeError, match=\"is"
],
[
    "def test_constructor(self, args, kwargs, start, stop, step, name):",
    "def test_constructor(self, args, kwargs, start, stop, step,"
],
[
    "assert result._range == range(start, stop, step)",
    "assert result._range == range(start,"
],
[
    "msg = \"RangeIndex\\\\(\\\\.\\\\.\\\\.\\\\) must be called with integers\"",
    "msg = \"RangeIndex\\\\(\\\\.\\\\.\\\\.\\\\) must be called"
],
[
    "r\"Index\\(\\.\\.\\.\\) must be called with a collection of some \"",
    "r\"Index\\(\\.\\.\\.\\) must be called with a"
],
[
    "msg = f\"Value needs to be a scalar value, was type {type(args).__name__}\"",
    "msg = f\"Value needs to be a scalar value, was type"
],
[
    "msg = f\"Wrong type {type(args)} for value {args}\"",
    "msg = f\"Wrong type {type(args)} for value"
],
[
    "r\"(RangeIndex.)?from_range\\(\\) got an unexpected keyword argument( 'copy')?\"",
    "r\"(RangeIndex.)?from_range\\(\\) got an unexpected keyword argument("
],
[
    "with pytest.raises(TypeError, match=r\"Wrong type \\<class 'str'\\>\"):",
    "with pytest.raises(TypeError, match=r\"Wrong type \\<class"
],
[
    "with pytest.raises(TypeError, match=r\"Wrong type \\<class 'float'\\>\"):",
    "with pytest.raises(TypeError, match=r\"Wrong"
],
[
    "res, lidx, ridx = index.join(other, how=\"outer\", return_indexers=True)",
    "res, lidx, ridx ="
],
[
    "res, lidx, ridx = index.join(other, how=\"outer\", return_indexers=True)",
    "res, lidx, ridx = index.join(other, how=\"outer\","
],
[
    "res, lidx, ridx = index.join(other, how=\"inner\", return_indexers=True)",
    "res, lidx, ridx = index.join(other,"
],
[
    "res, lidx, ridx = index.join(other, how=\"inner\", return_indexers=True)",
    "res, lidx, ridx = index.join(other, how=\"inner\","
],
[
    "res, lidx, ridx = index.join(other, how=\"left\", return_indexers=True)",
    "res, lidx, ridx = index.join(other,"
],
[
    "res, lidx, ridx = index.join(other, how=\"left\", return_indexers=True)",
    "res, lidx, ridx = index.join(other,"
],
[
    "res, lidx, ridx = index.join(other, how=\"right\", return_indexers=True)",
    "res, lidx, ridx = index.join(other,"
],
[
    "res, lidx, ridx = index.join(other, how=\"right\", return_indexers=True)",
    "res, lidx, ridx = index.join(other, how=\"right\","
],
[
    "res, lidx, ridx = index.join(other, return_indexers=True)",
    "res, lidx, ridx"
],
[
    "\"left, right, expected, expected_lidx, expected_ridx, how\",",
    "\"left, right, expected,"
],
[
    "\"right_type\", [RangeIndex, lambda x: Index(list(x), dtype=x.dtype)]",
    "\"right_type\", [RangeIndex, lambda x: Index(list(x),"
],
[
    "left, right, expected, expected_lidx, expected_ridx, how, right_type",
    "left, right, expected, expected_lidx, expected_ridx,"
],
[
    "result, lidx, ridx = left.join(right_type(right), how=how, return_indexers=True)",
    "result, lidx, ridx = left.join(right_type(right),"
],
[
    "msg = \"Unable to fill values because RangeIndex cannot contain NA\"",
    "msg = \"Unable to fill values"
],
[
    "msg = \"Unable to fill values because RangeIndex cannot contain NA\"",
    "msg = \"Unable to fill values because RangeIndex cannot contain"
],
[
    "mask = np.array([True, True, False, False, False])",
    "mask = np.array([True, True,"
],
[
    "ids=lambda x: repr(x) if isinstance(x, RangeIndex) else x,",
    "ids=lambda x: repr(x) if isinstance(x, RangeIndex) else"
],
[
    "def test_start_stop_step_attrs(self, index, start, stop, step):",
    "def test_start_stop_step_attrs(self, index, start, stop,"
],
[
    "for na in [np.nan, None, pd.NA]:",
    "for na in [np.nan,"
],
[
    "msg = f\"Wrong type {type(start)} for value {start}\"",
    "msg = f\"Wrong type"
],
[
    "\"Cannot change data-type for array of references.|\"",
    "\"Cannot change data-type for"
],
[
    "\"Cannot change data-type for object array.|\"",
    "\"Cannot change data-type for object"
],
[
    "result = ri[[True, True, False, True]]",
    "result = ri[[True,"
],
[
    "with pytest.raises(IndexError, match=\"Boolean index has wrong length\"):",
    "with pytest.raises(IndexError, match=\"Boolean index"
],
[
    "assert getattr(ri, meth)() == getattr(idx, meth)()",
    "assert getattr(ri, meth)() == getattr(idx,"
],
[
    "with pytest.raises(ValueError, match=f\"attempt to get {meth} of an empty sequence\"):",
    "with pytest.raises(ValueError, match=f\"attempt to get"
],
[
    "def test_value_counts(sort, dropna, ascending, normalize, rng):",
    "def test_value_counts(sort, dropna, ascending, normalize,"
],
[
    "r\"Index\\(\\.\\.\\.\\) must be called with a collection of some \"",
    "r\"Index\\(\\.\\.\\.\\) must be called with"
],
[
    "msg = \"could not convert string to float\"",
    "msg = \"could not convert string to"
],
[
    "from pandas._libs import index as libindex",
    "from pandas._libs import index as"
],
[
    "def test_get_slice_bounds_outside(self, side, expected, data, bound):",
    "def test_get_slice_bounds_outside(self, side,"
],
[
    "with pytest.raises(ValueError, match=\"Invalid value for side kwarg\"):",
    "with pytest.raises(ValueError, match=\"Invalid value"
],
[
    "expected = np.array([False, False, True, False, False, True])",
    "expected = np.array([False, False, True, False, False,"
],
[
    "ser = pd.Series([True, False, pd.NA], dtype=\"boolean\")",
    "ser = pd.Series([True, False,"
],
[
    "assert result._left.base is None or result._left.base is not result._right.base",
    "assert result._left.base is None or result._left.base is not"
],
[
    "def test_constructor_numeric(self, closed, name, freq, periods):",
    "def test_constructor_numeric(self, closed, name, freq,"
],
[
    "def test_constructor_timestamp(self, closed, name, freq, periods, tz):",
    "def test_constructor_timestamp(self, closed, name,"
],
[
    "def test_constructor_timedelta(self, closed, name, freq, periods):",
    "def test_constructor_timedelta(self, closed, name,"
],
[
    "def test_early_truncation(self, start, end, freq, expected_endpoint):",
    "def test_early_truncation(self, start,"
],
[
    "\"Of the four parameters: start, end, periods, and freq, \"",
    "\"Of the four parameters: start, end, periods, and freq,"
],
[
    "msg = \"start, end, freq need to be type compatible\"",
    "msg = \"start, end, freq need to"
],
[
    "msg = \"periods must be an integer, got foo\"",
    "msg = \"periods must be"
],
[
    "msg = \"start must be numeric or datetime-like, got foo\"",
    "msg = \"start must be numeric or datetime-like,"
],
[
    "msg = \"freq must be numeric or convertible to DateOffset, got foo\"",
    "msg = \"freq must be numeric or convertible"
],
[
    "msg = \"Start and end cannot both be tz-aware with different timezones\"",
    "msg = \"Start and end cannot both be tz-aware with"
],
[
    "Interval(left, right, closed) if notna(left) else np.nan",
    "Interval(left, right, closed) if notna(left)"
],
[
    "for left, right in zip(expected_left, expected_right)",
    "for left, right in zip(expected_left,"
],
[
    "expected = Index(iv.length for iv in index)",
    "expected = Index(iv.length for iv in"
],
[
    "expected = Index(iv.length if notna(iv) else iv for iv in index)",
    "expected = Index(iv.length if notna(iv) else iv for iv in"
],
[
    "msg = \"can only insert Interval objects and NA into an IntervalArray\"",
    "msg = \"can only insert Interval objects and NA"
],
[
    "msg = \"'value.closed' is 'left', expected 'right'.\"",
    "msg = \"'value.closed' is 'left',"
],
[
    "for closed in {\"left\", \"right\", \"both\", \"neither\"} - {item.closed}:",
    "for closed in {\"left\", \"right\", \"both\","
],
[
    "msg = f\"'value.closed' is '{closed}', expected '{item.closed}'.\"",
    "msg = f\"'value.closed' is"
],
[
    "for na in [np.nan, None, pd.NA]:",
    "for na in [np.nan,"
],
[
    "if data.left.dtype.kind not in [\"m\", \"M\"]:",
    "if data.left.dtype.kind not in [\"m\","
],
[
    "msg = \"can only insert Interval objects and NA into an IntervalArray\"",
    "msg = \"can only insert Interval objects and NA into an"
],
[
    "for other_closed in {\"left\", \"right\", \"both\", \"neither\"} - {closed}:",
    "for other_closed in {\"left\", \"right\", \"both\", \"neither\"}"
],
[
    "with pytest.raises(ValueError, match=\"multi-dimensional indexing not allowed\"):",
    "with pytest.raises(ValueError, match=\"multi-dimensional indexing not"
],
[
    "with pytest.raises(ValueError, match=\"multi-dimensional indexing not allowed\"):",
    "with pytest.raises(ValueError, match=\"multi-dimensional indexing not"
],
[
    "with pytest.raises(ValueError, match=\"multi-dimensional indexing not allowed\"):",
    "with pytest.raises(ValueError, match=\"multi-dimensional"
],
[
    "def test_get_loc_length_one_interval(self, left, right, closed, other_closed):",
    "def test_get_loc_length_one_interval(self, left, right, closed,"
],
[
    "for key in [None, np.nan, NA]:",
    "for key in"
],
[
    "\"cannot handle overlapping indices; use \"",
    "\"cannot handle overlapping"
],
[
    "'\"Cannot get left slice bound for non-unique label: '",
    "'\"Cannot get left slice bound for non-unique"
],
[
    "'\"Cannot get left slice bound for non-unique label: '",
    "'\"Cannot get left slice bound for non-unique"
],
[
    "'\"Cannot get right slice bound for non-unique label: '",
    "'\"Cannot get right slice bound for"
],
[
    "'\"Cannot get right slice bound for non-unique label: '",
    "'\"Cannot get right slice bound for non-unique label:"
],
[
    "\"'can only get slices from an IntervalIndex if bounds are \"",
    "\"'can only get slices from an IntervalIndex"
],
[
    "\"non-overlapping and all monotonic increasing or decreasing'\"",
    "\"non-overlapping and all monotonic increasing"
],
[
    "msg = \"^(?!(left side of interval must be <= right side))\"",
    "msg = \"^(?!(left side of interval"
],
[
    "msg = \"Cannot convert .* to .*; subtypes are incompatible\"",
    "msg = \"Cannot convert .* to"
],
[
    "msg = \"Cannot convert .* to .*; subtypes are incompatible\"",
    "msg = \"Cannot convert .* to .*; subtypes"
],
[
    "def test_repr_missing(self, constructor, expected, using_infer_string, request):",
    "def test_repr_missing(self, constructor,"
],
[
    "if using_infer_string and constructor is Series:",
    "if using_infer_string and"
],
[
    "for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:",
    "for other_closed in {\"right\", \"left\","
],
[
    "assert [level.name for level in index.levels] == list(names)",
    "assert [level.name for level"
],
[
    "assert [level.name for level in idx.levels] == [\"first\", \"second\"]",
    "assert [level.name for level in idx.levels] == [\"first\","
],
[
    "new_names = [name + \"a\" for name in idx.names]",
    "new_names = [name + \"a\" for name in"
],
[
    "shallow_copy.names = [name + \"c\" for name in shallow_copy.names]",
    "shallow_copy.names = [name + \"c\" for name in"
],
[
    "with pytest.raises(TypeError, match=\"MultiIndex.name must be a hashable type\"):",
    "with pytest.raises(TypeError, match=\"MultiIndex.name must be"
],
[
    "level_names = [level.name for level in idx.levels]",
    "level_names = [level.name for level in"
],
[
    "level_names = [level.name for level in index.levels]",
    "level_names = [level.name for level in"
],
[
    "with pytest.raises(ValueError, match=\"name foo occurs multiple times\"):",
    "with pytest.raises(ValueError, match=\"name foo occurs"
],
[
    "({\"x\": \"z\", \"y\": \"x\"}, [\"z\", \"x\", \"z\"]),",
    "({\"x\": \"z\", \"y\": \"x\"}, [\"z\", \"x\","
],
[
    "({\"y\": \"z\", \"a\": \"b\"}, [\"x\", \"z\", \"x\"]),",
    "({\"y\": \"z\", \"a\": \"b\"},"
],
[
    "({\"x\": \"z\", \"y\": \"x\"}, [\"z\", \"x\"]),",
    "({\"x\": \"z\", \"y\": \"x\"}, [\"z\","
],
[
    "msg = \"Can only pass dict-like as `names` for MultiIndex.\"",
    "msg = \"Can only pass dict-like"
],
[
    "with pytest.raises(TypeError, match=\"Can not pass level for dictlike `names`.\"):",
    "with pytest.raises(TypeError, match=\"Can not pass level for dictlike"
],
[
    "major_axis = Index([\"foo\", \"bar\", \"baz\", \"qux\"])",
    "major_axis = Index([\"foo\","
],
[
    "expected = Index([\"foo\", \"bar\", \"baz\", \"qux\"], name=\"first\")",
    "expected = Index([\"foo\", \"bar\", \"baz\","
],
[
    "msg = \"non-zero number of levels/codes\"",
    "msg = \"non-zero"
],
[
    "msg = \"Must pass both levels and codes\"",
    "msg = \"Must pass"
],
[
    "msg = r\"MultiIndex\\.name must be a hashable type\"",
    "msg = r\"MultiIndex\\.name must be"
],
[
    "msg = \"Length of levels and codes must be the same\"",
    "msg = \"Length of levels and codes"
],
[
    "\"NOTE: this index is in an inconsistent state\"",
    "\"NOTE: this index is"
],
[
    "mi = MultiIndex(levels=[levels, levels], codes=[codes, codes], copy=True)",
    "mi = MultiIndex(levels=[levels, levels],"
],
[
    "for lev, level_codes in zip(idx.levels, idx.codes)",
    "for lev, level_codes in zip(idx.levels,"
],
[
    "for lev, level_codes in zip(idx.levels, idx.codes)",
    "for lev, level_codes in"
],
[
    "msg = \"Input must be a list / sequence of array-likes.\"",
    "msg = \"Input must be a list / sequence"
],
[
    "for lev, level_codes in zip(idx.levels, idx.codes)",
    "for lev, level_codes in zip(idx.levels,"
],
[
    "msg = \"Must pass non-zero number of levels/codes\"",
    "msg = \"Must pass non-zero number of"
],
[
    "expected = MultiIndex(levels=[[]] * N, codes=[[]] * N, names=names)",
    "expected = MultiIndex(levels=[[]] * N, codes=[[]] *"
],
[
    "msg = \"Input must be a list / sequence of array-likes\"",
    "msg = \"Input must be a"
],
[
    "msg = \"^all arrays must be same length$\"",
    "msg = \"^all arrays must"
],
[
    "b = Series([\"a\", \"b\", \"c\"], name=\"bar\")",
    "b = Series([\"a\", \"b\", \"c\"],"
],
[
    "msg = \"Cannot infer number of levels from empty list\"",
    "msg = \"Cannot infer number of"
],
[
    "msg = \"Input must be a list / sequence of tuple-likes.\"",
    "msg = \"Input must be a list / sequence"
],
[
    "expected = MultiIndex.from_arrays(arrays=[[], []], names=[\"a\", \"b\"])",
    "expected = MultiIndex.from_arrays(arrays=[[], []],"
],
[
    "msg = \"Names should be list-like for a MultiIndex\"",
    "msg = \"Names should be list-like for"
],
[
    "msg = \"Must pass non-zero number of levels/codes\"",
    "msg = \"Must pass"
],
[
    "\"first, second\", [([], []), ([\"foo\", \"bar\", \"baz\"], []), ([], [\"a\", \"b\", \"c\"])]",
    "\"first, second\", [([], []), ([\"foo\", \"bar\", \"baz\"], []), ([],"
],
[
    "expected = MultiIndex(levels=[first, second], codes=[[], []], names=names)",
    "expected = MultiIndex(levels=[first, second],"
],
[
    "msg = r\"Input must be a list / sequence of iterables|Input must be list-like\"",
    "msg = r\"Input must be a list / sequence"
],
[
    "@pytest.mark.parametrize(\"f\", [lambda x: x, lambda x: Series(x), lambda x: x.values])",
    "@pytest.mark.parametrize(\"f\", [lambda x: x, lambda x:"
],
[
    "msg = \"Input must be a list / sequence of iterables.\"",
    "msg = \"Input must be a list / sequence"
],
[
    "with pytest.raises(TypeError, match=\"Input must be a DataFrame\"):",
    "with pytest.raises(TypeError, match=\"Input must be a"
],
[
    "\"b\": pd.Categorical([\"a\", \"a\", \"b\", \"b\", \"c\", \"c\"], ordered=True),",
    "\"b\": pd.Categorical([\"a\", \"a\", \"b\","
],
[
    "\"c\": [\"x\", \"x\", \"y\", \"z\", \"x\", \"y\"],",
    "\"c\": [\"x\", \"x\", \"y\", \"z\","
],
[
    "pd.Categorical([\"a\", \"a\", \"b\", \"b\", \"c\", \"c\"], ordered=True),",
    "pd.Categorical([\"a\", \"a\", \"b\", \"b\", \"c\","
],
[
    "[\"x\", \"x\", \"y\", \"z\", \"x\", \"y\"],",
    "[\"x\", \"x\", \"y\","
],
[
    "mi_dtypes = {name: mi.levels[i].dtype for i, name in enumerate(mi.names)}",
    "mi_dtypes = {name: mi.levels[i].dtype for"
],
[
    "[[\"a\", \"a\"], [\"a\", \"b\"], [\"b\", \"a\"], [\"b\", \"b\"]],",
    "[[\"a\", \"a\"], [\"a\", \"b\"], [\"b\", \"a\"], [\"b\","
],
[
    "(\"bad_input\", \"Names should be list-like for a MultiIndex\"),",
    "(\"bad_input\", \"Names should be list-like"
],
[
    "([\"a\", \"b\", \"c\"], \"Length of names must match number of levels in MultiIndex\"),",
    "([\"a\", \"b\", \"c\"], \"Length of names must match number"
],
[
    "[[\"a\", \"a\"], [\"a\", \"b\"], [\"b\", \"a\"], [\"b\", \"b\"]],",
    "[[\"a\", \"a\"], [\"a\", \"b\"], [\"b\", \"a\"],"
],
[
    "a = MultiIndex(levels=[[], []], codes=[[], []], names=[\"a\", \"b\"])",
    "a = MultiIndex(levels=[[], []], codes=[[], []], names=[\"a\","
],
[
    "b = MultiIndex.from_arrays(arrays=[[], []], names=[\"a\", \"b\"])",
    "b = MultiIndex.from_arrays(arrays=[[], []], names=[\"a\","
],
[
    "mi = MultiIndex.from_tuples([(x,) for x in arr])",
    "mi = MultiIndex.from_tuples([(x,) for"
],
[
    "exp = \"object\" if not using_infer_string else pd.StringDtype(na_value=np.nan)",
    "exp = \"object\" if not using_infer_string"
],
[
    "msg = \"isna is not defined for MultiIndex\"",
    "msg = \"isna is"
],
[
    "msg = \"invalid how option: xxx\"",
    "msg = \"invalid how option:"
],
[
    "msg = \"isna is not defined for MultiIndex\"",
    "msg = \"isna is"
],
[
    "@pytest.mark.xfail(reason=\"isna is not defined for MultiIndex\")",
    "@pytest.mark.xfail(reason=\"isna is not defined for"
],
[
    "expected = np.array([False] * len(index), dtype=bool)",
    "expected = np.array([False]"
],
[
    "expected = np.array([False] * len(index), dtype=bool)",
    "expected = np.array([False] *"
],
[
    "with pytest.raises(TypeError, match=\"Must pass both levels and codes\"):",
    "with pytest.raises(TypeError, match=\"Must pass both levels"
],
[
    "msg = \"the 'axis' parameter is not supported\"",
    "msg = \"the 'axis' parameter is not"
],
[
    "msg = \"the 'kind' parameter is not supported\"",
    "msg = \"the 'kind' parameter"
],
[
    "msg = \"the 'order' parameter is not supported\"",
    "msg = \"the 'order' parameter is"
],
[
    "[(\"z\", \"a\"), (\"x\", \"a\"), (\"y\", \"b\"), (\"x\", \"b\"), (\"y\", \"a\"), (\"z\", \"b\")],",
    "[(\"z\", \"a\"), (\"x\", \"a\"), (\"y\", \"b\"), (\"x\", \"b\"),"
],
[
    "\"MultiIndex slicing requires the index to be lexsorted: \"",
    "\"MultiIndex slicing requires the index"
],
[
    "[(\"z\", \"a\"), (\"x\", \"a\"), (\"y\", \"b\"), (\"x\", \"b\"), (\"y\", \"a\"), (\"z\", \"b\")],",
    "[(\"z\", \"a\"), (\"x\", \"a\"), (\"y\", \"b\"), (\"x\", \"b\"), (\"y\","
],
[
    "match = \"'<' not supported between instances of 'Timestamp' and 'int'\"",
    "match = \"'<' not supported between instances of 'Timestamp' and"
],
[
    "expected = Index([\"foo\", \"foo\", \"bar\", \"baz\", \"qux\", \"qux\"], name=\"first\")",
    "expected = Index([\"foo\", \"foo\", \"bar\", \"baz\","
],
[
    "exp = CategoricalIndex([\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"])",
    "exp = CategoricalIndex([\"A\", \"A\","
],
[
    "@pytest.mark.parametrize(\"other\", [[\"three\", \"one\", \"two\"], [\"one\"], [\"one\", \"three\"]])",
    "@pytest.mark.parametrize(\"other\", [[\"three\", \"one\", \"two\"], [\"one\"], [\"one\","
],
[
    "jidx, lidx, ridx = midx.join(idx, how=\"inner\", return_indexers=True)",
    "jidx, lidx, ridx = midx.join(idx, how=\"inner\","
],
[
    "jidx, ridx, lidx = idx.join(midx, how=\"inner\", return_indexers=True)",
    "jidx, ridx, lidx = idx.join(midx, how=\"inner\","
],
[
    "jidx, lidx, ridx = midx.join(idx, how=\"left\", return_indexers=True)",
    "jidx, lidx, ridx ="
],
[
    "jidx, ridx, lidx = idx.join(midx, how=\"right\", return_indexers=True)",
    "jidx, ridx, lidx = idx.join(midx, how=\"right\","
],
[
    "idx_copy = idx.copy(**{kwarg: value, \"deep\": deep})",
    "idx_copy = idx.copy(**{kwarg:"
],
[
    "from pandas._libs import index as libindex",
    "from pandas._libs import index as"
],
[
    "msg = r\"take\\(\\) got an unexpected keyword argument 'foo'\"",
    "msg = r\"take\\(\\) got an"
],
[
    "msg = \"the 'out' parameter is not supported\"",
    "msg = \"the 'out'"
],
[
    "msg = \"the 'mode' parameter is not supported\"",
    "msg = \"the 'mode' parameter"
],
[
    "msg = \"isna is not defined for MultiIndex\"",
    "msg = \"isna is not defined"
],
[
    "df = pd.DataFrame({\"a\": r, \"b\": r}, index=MultiIndex.from_arrays([r, r]))",
    "df = pd.DataFrame({\"a\": r,"
],
[
    "msg = \"'Series' object has no attribute 'foo'\"",
    "msg = \"'Series' object"
],
[
    "mutable_regex = re.compile(\"does not support mutable operations\")",
    "mutable_regex = re.compile(\"does not support"
],
[
    "with pytest.raises(ValueError, match=\"assignment destination is read-only\"):",
    "with pytest.raises(ValueError, match=\"assignment destination"
],
[
    "msg = \"Item must have length equal to number of levels\"",
    "msg = \"Item must have length equal to number"
],
[
    "@pytest.mark.parametrize(\"name, exp\", [(\"b\", \"b\"), (\"c\", None)])",
    "@pytest.mark.parametrize(\"name, exp\", [(\"b\", \"b\"),"
],
[
    "\"This method is only implemented for DatetimeIndex, PeriodIndex and \"",
    "\"This method is only implemented for DatetimeIndex,"
],
[
    "exp = {key: [key] for key in idx}",
    "exp = {key: [key]"
],
[
    "msg = \"the 'axis' parameter is not supported\"",
    "msg = \"the 'axis'"
],
[
    "[\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"],",
    "[\"a\", \"b\", \"c\","
],
[
    "[\"a\", \"b\", \"c\", \"x\", \"y\", \"z\"],",
    "[\"a\", \"b\", \"c\","
],
[
    "msg = \"cannot perform __sub__ with this index type: MultiIndex\"",
    "msg = \"cannot perform __sub__"
],
[
    "msg = \"cannot perform __rsub__ with this index type: MultiIndex\"",
    "msg = \"cannot perform __rsub__ with this index"
],
[
    "lambda values, idx: {i: e for e, i in zip(values, idx)},",
    "lambda values, idx: {i: e for"
],
[
    "f\"ufunc '{func.__name__}' not supported for the input types, and the inputs \"",
    "f\"ufunc '{func.__name__}' not supported for the input types, and"
],
[
    "\"could not be safely coerced to any supported types according to \"",
    "\"could not be safely coerced to any supported types"
],
[
    "msg = \"Input must be a list-like of list-likes\"",
    "msg = \"Input must be a list-like of"
],
[
    "msg = \"Product space too large to allocate arrays!\"",
    "msg = \"Product space too large to allocate"
],
[
    "with pytest.raises(ValueError, match=\"Unable to avoid copy while creating\"):",
    "with pytest.raises(ValueError, match=\"Unable to avoid"
],
[
    "msg = \"'name' must be a list / sequence of column names.\"",
    "msg = \"'name' must be a list /"
],
[
    "msg = \"'name' should have same length as number of levels on index.\"",
    "msg = \"'name' should have same length"
],
[
    "pd.Categorical([\"a\", \"a\", \"b\", \"b\", \"c\", \"c\"], ordered=True),",
    "pd.Categorical([\"a\", \"a\", \"b\", \"b\", \"c\", \"c\"],"
],
[
    "[\"x\", \"x\", \"y\", \"z\", \"x\", \"y\"],",
    "[\"x\", \"x\", \"y\","
],
[
    "original_dtypes = {name: mi.levels[i].dtype for i, name in enumerate(mi.names)}",
    "original_dtypes = {name: mi.levels[i].dtype for i, name in"
],
[
    "\"b\": pd.Categorical([\"a\", \"a\", \"b\", \"b\", \"c\", \"c\"], ordered=True),",
    "\"b\": pd.Categorical([\"a\", \"a\", \"b\","
],
[
    "\"c\": [\"x\", \"x\", \"y\", \"z\", \"x\", \"y\"],",
    "\"c\": [\"x\", \"x\", \"y\","
],
[
    "[[\"a\", \"b\", \"c\"], [\"x\", \"y\", \"z\"], [\"q\", \"w\", \"e\"]], names=expected",
    "[[\"a\", \"b\", \"c\"], [\"x\", \"y\", \"z\"],"
],
[
    "with pytest.raises(ValueError, match=\"Cannot create duplicate column labels\"):",
    "with pytest.raises(ValueError, match=\"Cannot create duplicate column"
],
[
    "with pytest.raises(ValueError, match=\"Cannot create duplicate column labels\"):",
    "with pytest.raises(ValueError, match=\"Cannot create duplicate"
],
[
    "from pandas._libs import index as libindex",
    "from pandas._libs import"
],
[
    "result = sorted_idx.slice_locs((\"foo\", \"two\"), (\"qux\", \"one\"))",
    "result = sorted_idx.slice_locs((\"foo\", \"two\"),"
],
[
    "msg = \"[Kk]ey length.*greater than MultiIndex lexsort depth\"",
    "msg = \"[Kk]ey length.*greater"
],
[
    "msg = \"putmask: mask and data must be the same size\"",
    "msg = \"putmask: mask and data"
],
[
    "msg = \"Reindexing only valid with uniquely valued Index objects\"",
    "msg = \"Reindexing only valid with uniquely valued"
],
[
    "msg = \"tolerance not implemented yet for MultiIndex\"",
    "msg = \"tolerance not implemented yet for"
],
[
    "@pytest.mark.parametrize(\"method\", [\"pad\", \"ffill\", \"backfill\", \"bfill\", \"nearest\"])",
    "@pytest.mark.parametrize(\"method\", [\"pad\", \"ffill\","
],
[
    "msg = \"not implemented yet for MultiIndex\"",
    "msg = \"not implemented yet"
],
[
    "msg = \"index must be monotonic increasing or decreasing\"",
    "msg = \"index must be monotonic increasing"
],
[
    "msg = \"limit argument only valid if doing pad, backfill or nearest\"",
    "msg = \"limit argument only valid if doing pad,"
],
[
    "msg = \"tolerance argument only valid if doing pad, backfill or nearest\"",
    "msg = \"tolerance argument only valid if doing"
],
[
    "result = idx[[True, False, True, False, True, True]]",
    "result = idx[[True, False, True,"
],
[
    "index = Index([\"c\", \"a\", \"a\", \"b\", \"b\"])",
    "index = Index([\"c\", \"a\", \"a\","
],
[
    "levels = [[\"a\", \"b\"], [\"c\", \"d\"]]",
    "levels = [[\"a\", \"b\"],"
],
[
    "levels = [[\"a\", \"b\"], [\"c\", \"d\"]]",
    "levels = [[\"a\","
],
[
    "expected = np.array([True, False, False, True])",
    "expected = np.array([True, False, False,"
],
[
    "msg = r\"\\.where is not supported for MultiIndex operations\"",
    "msg = r\"\\.where is not supported"
],
[
    "msg = r\"\\.where is not supported for MultiIndex operations\"",
    "msg = r\"\\.where is not supported for"
],
[
    "assert (\"bar\", \"two\") not in idx",
    "assert (\"bar\", \"two\") not in"
],
[
    "idx = MultiIndex.from_product([[\"a\", \"b\"], [\"c\", \"d\"]])",
    "idx = MultiIndex.from_product([[\"a\","
],
[
    "result = index.get_indexer([keys[i] for i in expected])",
    "result = index.get_indexer([keys[i] for i"
],
[
    "result = index.get_indexer([missing] + [keys[i] for i in idces])",
    "result = index.get_indexer([missing] + [keys[i] for"
],
[
    "msg = \"Must pass both levels and codes\"",
    "msg = \"Must pass both"
],
[
    "ci = pd.CategoricalIndex(list(\"a\" * n) + ([\"abc\"] * n))",
    "ci = pd.CategoricalIndex(list(\"a\" * n) + ([\"abc\"] *"
],
[
    "ci = pd.CategoricalIndex(list(\"a\" * n) + ([\"abc\"] * n))",
    "ci = pd.CategoricalIndex(list(\"a\" * n)"
],
[
    "msg = \"Input must be Index or array-like\"",
    "msg = \"Input must be"
],
[
    "msg = \"other must be a MultiIndex or a list of tuples\"",
    "msg = \"other must be a MultiIndex"
],
[
    "msg = \"other must be a MultiIndex or a list of tuples\"",
    "msg = \"other must be a"
],
[
    "cases = [klass(second.values) for klass in [np.array, Series, list]]",
    "cases = [klass(second.values) for klass in"
],
[
    "msg = \"other must be a MultiIndex or a list of tuples\"",
    "msg = \"other must be a MultiIndex"
],
[
    "cases = [klass(second.values) for klass in [np.array, Series, list]]",
    "cases = [klass(second.values) for klass in [np.array,"
],
[
    "msg = \"other must be a MultiIndex or a list of tuples\"",
    "msg = \"other must be a MultiIndex or a"
],
[
    "idx = MultiIndex.from_product([[\"a\", \"b\"], [\"A\", \"B\"]], names=[\"a\", \"b\"])",
    "idx = MultiIndex.from_product([[\"a\", \"b\"], [\"A\","
],
[
    "[(\"bar\", \"one\"), (\"baz\", \"two\"), (\"foo\", \"two\"), (\"qux\", \"one\"), (\"qux\", \"two\")]",
    "[(\"bar\", \"one\"), (\"baz\", \"two\"), (\"foo\", \"two\"), (\"qux\", \"one\"),"
],
[
    "msg = \"other must be a MultiIndex or a list of tuples\"",
    "msg = \"other must be a MultiIndex"
],
[
    "msg = \"sort order is undefined for incomparable objects\"",
    "msg = \"sort order is undefined for incomparable"
],
[
    "msg = \"'values' is not ordered, please explicitly specify the categories order \"",
    "msg = \"'values' is not ordered, please explicitly specify the categories order"
],
[
    "msg = \"The values in the array are unorderable\"",
    "msg = \"The values in the"
],
[
    "expected = MultiIndex(levels=idx.levels, codes=[[]] * idx.nlevels, names=None)",
    "expected = MultiIndex(levels=idx.levels, codes=[[]]"
],
[
    "expected = MultiIndex(levels=idx.levels, codes=[[]] * idx.nlevels, names=idx.names)",
    "expected = MultiIndex(levels=idx.levels, codes=[[]]"
],
[
    "msg = \"other must be a MultiIndex or a list of tuples\"",
    "msg = \"other must be a MultiIndex"
],
[
    "msg = \"'<' not supported between instances of 'Timestamp' and 'int'\"",
    "msg = \"'<' not supported between instances of 'Timestamp' and"
],
[
    "msg = \"Can only union MultiIndex with MultiIndex or Index of tuples\"",
    "msg = \"Can only union MultiIndex"
],
[
    "with pytest.raises(ValueError, match=\"The 'sort' keyword only takes\"):",
    "with pytest.raises(ValueError, match=\"The 'sort' keyword only"
],
[
    "if index.empty or isinstance(index, (IntervalIndex, CategoricalIndex)):",
    "if index.empty or isinstance(index, (IntervalIndex,"
],
[
    "pytest.skip(f\"No duplicates in an empty {type(index).__name__}\")",
    "pytest.skip(f\"No duplicates in an"
],
[
    "[pd.Categorical([\"a\", \"b\"], categories=[\"a\", \"b\"]), [\"a\", \"b\"]],",
    "[pd.Categorical([\"a\", \"b\"], categories=[\"a\", \"b\"]), [\"a\","
],
[
    "b = pd.Categorical([\"a\", \"b\"], categories=[\"b\", \"a\"], ordered=b_ordered)",
    "b = pd.Categorical([\"a\", \"b\"], categories=[\"b\", \"a\"],"
],
[
    "expected = MultiIndex.from_arrays([a, other], names=[\"x\", \"y\"])",
    "expected = MultiIndex.from_arrays([a, other],"
],
[
    "msg = \"'MultiIndex' object has no attribute 'freq'\"",
    "msg = \"'MultiIndex' object"
],
[
    "msg = r\"take\\(\\) got an unexpected keyword argument 'foo'\"",
    "msg = r\"take\\(\\) got an unexpected keyword"
],
[
    "msg = \"the 'out' parameter is not supported\"",
    "msg = \"the 'out' parameter is not"
],
[
    "msg = \"the 'mode' parameter is not supported\"",
    "msg = \"the 'mode' parameter is not"
],
[
    "msg = \"Can only compare identically-labeled Series objects\"",
    "msg = \"Can only"
],
[
    "all_false = np.array([False, False, False, False])",
    "all_false = np.array([False, False, False,"
],
[
    "expected = np.array([True, False, False, False])",
    "expected = np.array([True, False,"
],
[
    "mi = MultiIndex.from_tuples([(\"a\", \"b\"), (\"b\", \"c\"), (\"c\", \"a\")])",
    "mi = MultiIndex.from_tuples([(\"a\", \"b\"), (\"b\","
],
[
    "result = mi == (\"c\", \"a\")",
    "result = mi == (\"c\","
],
[
    "major_axis = Index([\"foo\", \"bar\", \"baz\", \"qux\"])",
    "major_axis = Index([\"foo\", \"bar\", \"baz\","
],
[
    "for act, exp in zip(actual, expected):",
    "for act, exp in zip(actual,"
],
[
    "with pytest.raises(KeyError, match=\"Level fourth not found\"):",
    "with pytest.raises(KeyError, match=\"Level fourth"
],
[
    "exp = \"object\" if not using_infer_string else pd.StringDtype(na_value=np.nan)",
    "exp = \"object\" if"
],
[
    "exp = \"object\" if not using_infer_string else pd.StringDtype(na_value=np.nan)",
    "exp = \"object\" if"
],
[
    "exp = \"object\" if not using_infer_string else pd.StringDtype(na_value=np.nan)",
    "exp = \"object\" if"
],
[
    "with pytest.raises(IndexError, match=\"not a valid level number\"):",
    "with pytest.raises(IndexError, match=\"not a"
],
[
    "new_names = [name + \"SUFFIX\" for name in index_names]",
    "new_names = [name + \"SUFFIX\""
],
[
    "msg = \"Length of names must match number of levels in MultiIndex\"",
    "msg = \"Length of names must match"
],
[
    "new_levels = [[lev + \"a\" for lev in level] for level in levels]",
    "new_levels = [[lev + \"a\" for lev in level] for"
],
[
    "\"property 'codes' of 'MultiIndex' object has no setter\"",
    "\"property 'codes' of 'MultiIndex'"
],
[
    "new_levels = [[lev + \"a\" for lev in level] for level in levels]",
    "new_levels = [[lev + \"a\" for lev in level] for"
],
[
    "with pytest.raises(TypeError, match=\"Names must be a\"):",
    "with pytest.raises(TypeError, match=\"Names must be"
],
[
    "index = MultiIndex.from_arrays([sizes, colors], names=[\"size\", \"color\"])",
    "index = MultiIndex.from_arrays([sizes,"
],
[
    "expected = MultiIndex.from_arrays([expected_sizes, colors], names=[\"size\", \"color\"])",
    "expected = MultiIndex.from_arrays([expected_sizes,"
],
[
    "div_err = div_err.replace(\" __\", \" __r\")",
    "div_err = div_err.replace(\" __\","
],
[
    "result = MultiIndex.from_product([[\"a\", \"b\", \"c\"], cat]).values",
    "result = MultiIndex.from_product([[\"a\", \"b\", \"c\"],"
],
[
    "result = pd.DataFrame({\"a\": [\"a\", \"b\", \"c\"], \"b\": cat, \"c\": np.array(cat)}).values",
    "result = pd.DataFrame({\"a\": [\"a\", \"b\", \"c\"], \"b\": cat,"
],
[
    "levels=[[\"bar\", \"baz\", \"foo\", \"qux\"], [\"mom\", \"next\", \"zenith\"]],",
    "levels=[[\"bar\", \"baz\", \"foo\", \"qux\"], [\"mom\","
],
[
    "levels=[[\"qux\", \"foo\", \"baz\", \"bar\"], [\"three\", \"two\", \"one\"]],",
    "levels=[[\"qux\", \"foo\", \"baz\", \"bar\"], [\"three\","
],
[
    "levels=[[\"qux\", \"foo\", \"baz\", \"bar\"], [\"zenith\", \"next\", \"mom\"]],",
    "levels=[[\"qux\", \"foo\", \"baz\", \"bar\"],"
],
[
    "expected = np.array([False, False, True, True])",
    "expected = np.array([False, False,"
],
[
    "expected = np.array([False, False, True, True])",
    "expected = np.array([False,"
],
[
    "with pytest.raises(KeyError, match=\"'Level A not found'\"):",
    "with pytest.raises(KeyError, match=\"'Level A not"
],
[
    "with pytest.raises(KeyError, match=\"'Level C not found'\"):",
    "with pytest.raises(KeyError, match=\"'Level"
],
[
    "([(\"b\", np.nan)], [False, False, True], None),",
    "([(\"b\", np.nan)], [False, False,"
],
[
    "midx = MultiIndex.from_arrays([[np.nan, \"a\", \"b\"], [\"c\", \"d\", np.nan]])",
    "midx = MultiIndex.from_arrays([[np.nan, \"a\", \"b\"],"
],
[
    "dropped = idx.drop([(\"foo\", \"two\"), (\"qux\", \"one\")])",
    "dropped = idx.drop([(\"foo\", \"two\"), (\"qux\","
],
[
    "index = MultiIndex.from_tuples([(\"foo\", \"two\"), (\"qux\", \"one\")])",
    "index = MultiIndex.from_tuples([(\"foo\","
],
[
    "mixed_index = MultiIndex.from_tuples([(\"qux\", \"one\"), (\"bar\", \"two\")])",
    "mixed_index = MultiIndex.from_tuples([(\"qux\", \"one\"), (\"bar\","
],
[
    "mixed_index = [\"foo\", (\"qux\", \"one\"), \"two\"]",
    "mixed_index = [\"foo\","
],
[
    "\"at least one level must be left\"",
    "\"at least one level must be"
],
[
    "with pytest.raises(KeyError, match=\"'Level four not found'\"):",
    "with pytest.raises(KeyError, match=\"'Level four not"
],
[
    "df = df.pivot_table(index=\"a\", columns=[\"b\", \"c\"], values=\"d\")",
    "df = df.pivot_table(index=\"a\", columns=[\"b\", \"c\"],"
],
[
    "mi = MultiIndex.from_tuples([(\"blah\", nulls_fixture)], names=[\"name\", \"date\"])",
    "mi = MultiIndex.from_tuples([(\"blah\", nulls_fixture)], names=[\"name\","
],
[
    "msg = r\"labels \\[nan\\] not found in level\"",
    "msg = r\"labels \\[nan\\]"
],
[
    "msg = r\"labels \\['a'\\] not found in level\"",
    "msg = r\"labels \\['a'\\] not found"
],
[
    "major_axis = Index([\"foo\", \"bar\", \"baz\", \"qux\"])",
    "major_axis = Index([\"foo\","
],
[
    "mi = MultiIndex.from_arrays([[], []], names=[\"first\", \"second\"])",
    "mi = MultiIndex.from_arrays([[], []],"
],
[
    "codes = [codes.copy() for i in range(nlevels)]",
    "codes = [codes.copy() for i in"
],
[
    "(\"first\", [False, False, False, True, True, False]),",
    "(\"first\", [False, False, False,"
],
[
    "(\"last\", [False, True, True, False, False, False]),",
    "(\"last\", [False, True, True, False,"
],
[
    "(False, [False, True, True, True, True, False]),",
    "(False, [False, True, True, True, True,"
],
[
    "expected = np.array([False, False, False, True, False, False], dtype=bool)",
    "expected = np.array([False, False, False, True, False, False],"
],
[
    "expected = np.array([True, False, False, False, False, False])",
    "expected = np.array([True, False,"
],
[
    "expected = np.array([True, False, False, True, False, False])",
    "expected = np.array([True, False, False, True,"
],
[
    "[False, False, False, True, False, False, False, True, False, True],",
    "[False, False, False, True, False,"
],
[
    "midx = MultiIndex.from_arrays([vals_a, vals_b], names=[\"a\", \"b\"])",
    "midx = MultiIndex.from_arrays([vals_a,"
],
[
    "expected = MultiIndex.from_arrays([exp_vals_a, exp_vals_b], names=[\"a\", \"b\"])",
    "expected = MultiIndex.from_arrays([exp_vals_a,"
],
[
    "assert [level.name for level in result.levels] == [\"first\", \"second\"]",
    "assert [level.name for level in"
],
[
    "assert [level.name for level in result.levels] == [\"first\", \"second\"]",
    "assert [level.name for level in"
],
[
    "with pytest.raises(TypeError, match=\"Fill method not supported\"):",
    "with pytest.raises(TypeError, match=\"Fill method"
],
[
    "idx.names = target.names = [None, None]",
    "idx.names = target.names"
],
[
    "exp = np.object_ if not using_infer_string else str",
    "exp = np.object_ if"
],
[
    "msg = \"cannot handle a non-unique multi-index!\"",
    "msg = \"cannot handle"
],
[
    "keys = [(\"i\", \"i\"), (\"i\", \"j\"), (\"j\", \"i\"), \"j\"]",
    "keys = [(\"i\", \"i\"), (\"i\","
],
[
    "match=\"limit argument only valid if doing pad, backfill or nearest reindexing\",",
    "match=\"limit argument only valid if doing pad, backfill"
],
[
    "for x, val in zip(periods, field_idx):",
    "for x, val in"
],
[
    "for x, val in zip(periods, field_s):",
    "for x, val"
],
[
    "exp = Index([x.ordinal for x in index])",
    "exp = Index([x.ordinal for x in"
],
[
    "msg = r\"Input has different freq=B from PeriodIndex\\(freq=D\\)\"",
    "msg = r\"Input has"
],
[
    "msg = \"Input has different freq=h from PeriodArray\"",
    "msg = \"Input has different freq=h"
],
[
    "\"searchsorted requires compatible dtype or scalar\",",
    "\"searchsorted requires compatible"
],
[
    "\"value should be a 'Period', 'NaT', or array of those. Got\",",
    "\"value should be a 'Period', 'NaT', or array"
],
[
    "\"property 'freq' of 'PeriodArray' object has no setter\"",
    "\"property 'freq' of 'PeriodArray' object has"
],
[
    "msg = \"Mismatched Period array lengths\"",
    "msg = \"Mismatched Period array"
],
[
    "msg = \"freq not specified and cannot be inferred\"",
    "msg = \"freq not specified and cannot be"
],
[
    "msg = \"'Period' object is not iterable\"",
    "msg = \"'Period' object"
],
[
    "msg = \"specified freq and dtype are different\"",
    "msg = \"specified freq and dtype are"
],
[
    "msg = \"Input has different freq=D from PeriodIndex\\\\(freq=M\\\\)\"",
    "msg = \"Input has different freq=D from"
],
[
    "msg = \"PeriodIndex does not allow floating point in construction\"",
    "msg = \"PeriodIndex does not allow floating point in"
],
[
    "msg = \"Period with BDay freq is deprecated\"",
    "msg = \"Period with"
],
[
    "msg = \"'w' is deprecated and will be removed in a future version.\"",
    "msg = \"'w' is deprecated and will be removed"
],
[
    "msg = \"Period with BDay freq is deprecated\"",
    "msg = \"Period with"
],
[
    "msg = \"Period with BDay freq is deprecated\"",
    "msg = \"Period with BDay"
],
[
    "msg = r\"Input has different freq=W-SUN from PeriodIndex\\(freq=B\\)\"",
    "msg = r\"Input has different"
],
[
    "\"freq\", [\"M\", \"Q\", \"Y\", \"D\", \"B\", \"min\", \"s\", \"ms\", \"us\", \"ns\", \"h\"]",
    "\"freq\", [\"M\", \"Q\", \"Y\", \"D\", \"B\", \"min\", \"s\","
],
[
    "r\"ignore:Period with BDay freq is deprecated:FutureWarning\"",
    "r\"ignore:Period with BDay"
],
[
    "expected = Index([str(num) for num in raw])",
    "expected = Index([str(num) for num in"
],
[
    "assert all(isinstance(resi, str) for resi in res)",
    "assert all(isinstance(resi, str) for resi"
],
[
    "from pandas._libs.tslibs import period as libperiod",
    "from pandas._libs.tslibs import period"
],
[
    "result = idx[[True, True, False, False, False, True, True, False, False, False]]",
    "result = idx[[True, True, False, False, False,"
],
[
    "msg = \"Cannot interpret 'foo' as period\"",
    "msg = \"Cannot interpret 'foo'"
],
[
    "msg = \"Cannot interpret 'foo' as period\"",
    "msg = \"Cannot interpret"
],
[
    "msg = re.escape(f\"Cannot compare dtypes {pi.dtype} and {other.dtype}\")",
    "msg = re.escape(f\"Cannot compare dtypes {pi.dtype} and"
],
[
    "if dtype == \"object\" and isinstance(other, PeriodIndex):",
    "if dtype == \"object\" and isinstance(other,"
],
[
    "f\"Cannot compare dtypes {pi.dtype} and {other.dtype}\",",
    "f\"Cannot compare dtypes {pi.dtype} and"
],
[
    "\" not supported between instances of \",",
    "\" not supported between instances of"
],
[
    "msg = \"Input has different freq=None from PeriodArray\\\\(freq=h\\\\)\"",
    "msg = \"Input has different"
],
[
    "libperiod.IncompatibleFrequency, match=\"Input has different freq=None from\"",
    "libperiod.IncompatibleFrequency, match=\"Input has different freq=None"
],
[
    "expected = pd.Index([NaT._value, NaT._value] + tail, dtype=object)",
    "expected = pd.Index([NaT._value, NaT._value] + tail,"
],
[
    "expected = pd.Index([td, td] + tail, dtype=object)",
    "expected = pd.Index([td, td]"
],
[
    "cond = np.array([True, False, True, True, False])",
    "cond = np.array([True, False,"
],
[
    "msg = \"must be DatetimeIndex or PeriodIndex\"",
    "msg = \"must be DatetimeIndex or"
],
[
    "msg = \"Input has different freq=h\"",
    "msg = \"Input has"
],
[
    "for rng, other, expected in [",
    "for rng, other,"
],
[
    "for rng, other, expected in [",
    "for rng, other, expected"
],
[
    "if sort is None and len(other):",
    "if sort is None and"
],
[
    "msg = \"slice indices must be integers or None or have an __index__ method\"",
    "msg = \"slice indices must be integers or None"
],
[
    "msg = \"slice indices must be integers or None or have an __index__ method\"",
    "msg = \"slice indices must be integers or None or have an"
],
[
    "f\"cannot do slice indexing on {type(idx).__name__} with \"",
    "f\"cannot do slice indexing on {type(idx).__name__}"
],
[
    "r\"these indexers \\[foo\\] of type str\"",
    "r\"these indexers \\[foo\\] of"
],
[
    "\"Of the three parameters: start, end, and periods, exactly two \"",
    "\"Of the three parameters: start, end, and periods,"
],
[
    "\"Of the three parameters: start, end, and periods, exactly two \"",
    "\"Of the three parameters: start, end,"
],
[
    "\"Of the three parameters: start, end, and periods, \"",
    "\"Of the three parameters: start, end, and"
],
[
    "\"Of the three parameters: start, end, and periods, \"",
    "\"Of the three parameters: start, end, and periods,"
],
[
    "msg = \"start and end must not be NaT\"",
    "msg = \"start and end"
],
[
    "msg = \"periods must be an integer, got foo\"",
    "msg = \"periods must be"
],
[
    "result = period_range(start=start, end=end, freq=freq_period, name=\"foo\")",
    "result = period_range(start=start, end=end,"
],
[
    "result = period_range(start=end, end=start, freq=freq_period, name=\"foo\")",
    "result = period_range(start=end,"
],
[
    "result = period_range(start=start, end=end, freq=\"M\", name=\"foo\")",
    "result = period_range(start=start, end=end,"
],
[
    "result = period_range(start=end, end=start, freq=\"M\", name=\"foo\")",
    "result = period_range(start=end, end=start, freq=\"M\","
],
[
    "result = period_range(start=start, end=end, freq=\"M\", name=\"foo\")",
    "result = period_range(start=start,"
],
[
    "result = period_range(start=start, end=end, freq=\"Q\", name=\"foo\")",
    "result = period_range(start=start, end=end,"
],
[
    "idx = period_range(start=start, end=end, freq=\"Q\", name=\"foo\")",
    "idx = period_range(start=start,"
],
[
    "expected = np.array([True, True, True, True, True])",
    "expected = np.array([True, True,"
],
[
    "result = period_range(start=end, end=start, freq=\"W\", name=\"foo\")",
    "result = period_range(start=end, end=start,"
],
[
    "depr_msg = \"Period with BDay freq is deprecated\"",
    "depr_msg = \"Period with BDay freq is"
],
[
    "msg = \"start and end must have same freq\"",
    "msg = \"start and end"
],
[
    "with pytest.raises(ValueError, match=\"Index is not monotonic\"):",
    "with pytest.raises(ValueError, match=\"Index"
],
[
    "msg = \"`freq` argument is not supported for PeriodIndex.shift\"",
    "msg = \"`freq` argument is not supported"
],
[
    "expected = DatetimeIndex([x.to_timestamp(\"D\", \"end\") for x in pindex])",
    "expected = DatetimeIndex([x.to_timestamp(\"D\", \"end\") for"
],
[
    "with pytest.raises(ValueError, match=\"for Period, please use 'M' instead of 'MS'\"):",
    "with pytest.raises(ValueError, match=\"for Period, please"
],
[
    "msg = \"Cannot cast PeriodIndex to dtype\"",
    "msg = \"Cannot cast PeriodIndex"
],
[
    "[str(x) if x is not NaT else None for x in idx], name=\"idx\", dtype=\"str\"",
    "[str(x) if x is not NaT else None"
],
[
    "expected = Index([str(x) for x in idx], name=\"idx\", dtype=object)",
    "expected = Index([str(x) for x in idx], name=\"idx\","
],
[
    "msg = \"How must be one of S or E\"",
    "msg = \"How must be one of S or"
],
[
    "re.escape(f\"{freq} is not supported as period frequency\"),",
    "re.escape(f\"{freq} is not supported as"
],
[
    "\"bh is not supported as period frequency\",",
    "\"bh is not supported as period"
],
[
    "msg = \"must be called with a collection of some kind\"",
    "msg = \"must be called with a collection of"
],
[
    "data, cats, ordered = \"a a b b\".split(), \"c b a\".split(), True",
    "data, cats, ordered = \"a a b b\".split(), \"c b"
],
[
    "msg = \"Cannot specify `categories` or `ordered` together with `dtype`.\"",
    "msg = \"Cannot specify `categories` or `ordered` together with"
],
[
    "msg = \"all inputs must be Index\"",
    "msg = \"all inputs must be"
],
[
    "expected = Index([\"a\", \"a\", \"b\", \"b\", \"c\", \"a\", \"a\", \"d\"])",
    "expected = Index([\"a\", \"a\", \"b\","
],
[
    "expected = Index([\"a\", \"b\", \"d\", \"e\"])",
    "expected = Index([\"a\", \"b\","
],
[
    "msg = \"Categoricals can only be compared if 'categories' are the same\"",
    "msg = \"Categoricals can only be compared"
],
[
    "ci = CategoricalIndex(list(\"aabca\"), categories=[\"c\", \"a\", \"b\"])",
    "ci = CategoricalIndex(list(\"aabca\"),"
],
[
    "ci = CategoricalIndex(list(\"aabca\") + [np.nan], categories=[\"c\", \"a\", \"b\"])",
    "ci = CategoricalIndex(list(\"aabca\") + [np.nan], categories=[\"c\", \"a\","
],
[
    "ci = CategoricalIndex(list(\"aabca\") + [np.nan], categories=[\"c\", \"a\", \"b\"])",
    "ci = CategoricalIndex(list(\"aabca\") + [np.nan], categories=[\"c\","
],
[
    "assert not ci.equals(CategoricalIndex(list(\"aabca\") + [np.nan], ordered=True))",
    "assert not ci.equals(CategoricalIndex(list(\"aabca\") + [np.nan],"
],
[
    "ci = CategoricalIndex([\"A\", \"B\", np.nan, np.nan])",
    "ci = CategoricalIndex([\"A\", \"B\","
],
[
    "other = Index([\"A\", \"B\", \"D\", np.nan])",
    "other = Index([\"A\", \"B\", \"D\","
],
[
    "other = Index([\"a\", \"b\", \"c\"], name=\"B\", dtype=any_string_dtype)",
    "other = Index([\"a\", \"b\", \"c\"], name=\"B\","
],
[
    "[\"B\", \"C\", np.nan], categories=list(\"ABC\"), ordered=True, name=\"xxx\"",
    "[\"B\", \"C\", np.nan], categories=list(\"ABC\"), ordered=True,"
],
[
    "msg = r\"take\\(\\) got an unexpected keyword argument 'foo'\"",
    "msg = r\"take\\(\\) got an"
],
[
    "msg = \"the 'out' parameter is not supported\"",
    "msg = \"the 'out' parameter is not"
],
[
    "msg = \"the 'mode' parameter is not supported\"",
    "msg = \"the 'mode' parameter is"
],
[
    "res, np.array([False, False, False, True, False, True])",
    "res, np.array([False, False, False, True, False,"
],
[
    "expected = np.array([False, True, False, True], dtype=bool)",
    "expected = np.array([False, True,"
],
[
    "msg = \"Reindexing only valid with uniquely valued Index objects\"",
    "msg = \"Reindexing only valid"
],
[
    "msg = \"Reindexing only valid with uniquely valued Index objects\"",
    "msg = \"Reindexing only valid with uniquely valued Index"
],
[
    "msg = \"method pad not yet implemented for CategoricalIndex\"",
    "msg = \"method pad not"
],
[
    "msg = \"method backfill not yet implemented for CategoricalIndex\"",
    "msg = \"method backfill not yet implemented for"
],
[
    "msg = \"method nearest not yet implemented for CategoricalIndex\"",
    "msg = \"method nearest not yet implemented for"
],
[
    "ci = CategoricalIndex(cats, categories=cats, ordered=False, dtype=\"category\")",
    "ci = CategoricalIndex(cats, categories=cats,"
],
[
    "ci = CategoricalIndex([\"a\", \"b\"], categories=[\"a\", \"b\"])",
    "ci = CategoricalIndex([\"a\", \"b\"],"
],
[
    "result = ci.get_indexer(CategoricalIndex([\"b\", \"b\"], categories=[\"a\", \"b\"]))",
    "result = ci.get_indexer(CategoricalIndex([\"b\", \"b\"],"
],
[
    "ci = CategoricalIndex([\"a\", \"b\"], categories=[\"a\", \"b\"])",
    "ci = CategoricalIndex([\"a\","
],
[
    "result = ci.get_indexer(CategoricalIndex([\"b\", \"b\"], categories=[\"b\", \"a\"]))",
    "result = ci.get_indexer(CategoricalIndex([\"b\","
],
[
    "ci = CategoricalIndex([\"a\", \"b\", \"c\", \"d\"])",
    "ci = CategoricalIndex([\"a\","
],
[
    "mask = np.array([True, False, True, False])",
    "mask = np.array([True,"
],
[
    "msg = \"Cannot setitem on a Categorical with a new category\"",
    "msg = \"Cannot setitem on a Categorical"
],
[
    "ci = CategoricalIndex(list(\"aabbca\") + [np.nan], categories=list(\"cabdef\"))",
    "ci = CategoricalIndex(list(\"aabbca\")"
],
[
    "ci = CategoricalIndex([\"a\", \"b\", \"c\", None])",
    "ci = CategoricalIndex([\"a\","
],
[
    "expected = CategoricalIndex([\"a\", \"b\"], categories=[\"a\", \"b\", \"c\"])",
    "expected = CategoricalIndex([\"a\", \"b\"], categories=[\"a\","
],
[
    "from pandas._libs import index as libindex",
    "from pandas._libs import index"
],
[
    "msg = \"Cannot setitem on a Categorical with a new category\"",
    "msg = \"Cannot setitem on a Categorical"
],
[
    "msg = \"Cannot setitem on a Categorical with a new category\"",
    "msg = \"Cannot setitem on a"
],
[
    "b = Series([\"even\", \"odd\", \"even\", \"odd\"], dtype=\"category\")",
    "b = Series([\"even\", \"odd\", \"even\","
],
[
    "c = Series([\"even\", \"odd\", \"even\", \"odd\"])",
    "c = Series([\"even\", \"odd\","
],
[
    "exp = CategoricalIndex([\"odd\", \"even\", \"odd\", np.nan])",
    "exp = CategoricalIndex([\"odd\", \"even\","
],
[
    "exp = Index([\"odd\", \"even\", \"odd\", np.nan])",
    "exp = Index([\"odd\","
],
[
    "msg = \"cannot reindex on an axis with duplicate labels\"",
    "msg = \"cannot reindex on an"
],
[
    "ci = CategoricalIndex([\"a\", \"b\", \"c\", \"a\"])",
    "ci = CategoricalIndex([\"a\", \"b\", \"c\","
],
[
    "msg = \"cannot reindex on an axis with duplicate labels\"",
    "msg = \"cannot reindex on an axis with duplicate"
],
[
    "ci = CategoricalIndex([\"a\", \"b\", \"c\", \"a\"])",
    "ci = CategoricalIndex([\"a\","
],
[
    "msg = \"cannot reindex on an axis with duplicate labels\"",
    "msg = \"cannot reindex on"
],
[
    "ci = CategoricalIndex([\"a\", \"b\", \"c\", \"a\"], categories=[\"a\", \"b\", \"c\", \"d\"])",
    "ci = CategoricalIndex([\"a\", \"b\", \"c\", \"a\"],"
],
[
    "msg = \"cannot reindex on an axis with duplicate labels\"",
    "msg = \"cannot reindex on an axis with"
],
[
    "ci = CategoricalIndex([\"a\", \"b\", \"c\", \"a\"], categories=[\"a\", \"b\", \"c\", \"d\"])",
    "ci = CategoricalIndex([\"a\", \"b\", \"c\", \"a\"], categories=[\"a\", \"b\", \"c\","
],
[
    "cat = CategoricalIndex([\"a\", \"b\", \"c\"], categories=[\"a\", \"b\", \"c\", \"d\"])",
    "cat = CategoricalIndex([\"a\", \"b\", \"c\"], categories=[\"a\","
],
[
    "res, indexer = cat.reindex([\"a\", \"c\", \"c\"])",
    "res, indexer = cat.reindex([\"a\","
],
[
    "CategoricalIndex([\"a\", \"c\", \"c\"], categories=[\"a\", \"b\", \"c\", \"d\"])",
    "CategoricalIndex([\"a\", \"c\", \"c\"], categories=[\"a\", \"b\","
],
[
    "exp = CategoricalIndex([\"a\", \"c\", \"c\"], categories=[\"a\", \"b\", \"c\", \"d\"])",
    "exp = CategoricalIndex([\"a\", \"c\", \"c\"], categories=[\"a\", \"b\", \"c\","
],
[
    "joined, lidx, ridx = left.join(left, return_indexers=True)",
    "joined, lidx, ridx"
],
[
    "res, lidx, ridx = index.join(other, how=\"inner\", return_indexers=True)",
    "res, lidx, ridx ="
],
[
    "res, lidx, ridx = index.join(other_mono, how=\"inner\", return_indexers=True)",
    "res, lidx, ridx ="
],
[
    "res, lidx, ridx = index.join(other, how=\"left\", return_indexers=True)",
    "res, lidx, ridx ="
],
[
    "res, lidx, ridx = index.join(other_mono, how=\"left\", return_indexers=True)",
    "res, lidx, ridx = index.join(other_mono,"
],
[
    "res, lidx, ridx = index.join(other, how=\"right\", return_indexers=True)",
    "res, lidx, ridx = index.join(other, how=\"right\","
],
[
    "res, lidx, ridx = index.join(other_mono, how=\"right\", return_indexers=True)",
    "res, lidx, ridx = index.join(other_mono, how=\"right\","
],
[
    "res, lidx, ridx = index.join(other, how=\"outer\", return_indexers=True)",
    "res, lidx, ridx = index.join(other, how=\"outer\","
],
[
    "res, lidx, ridx = index.join(other_mono, how=\"outer\", return_indexers=True)",
    "res, lidx, ridx = index.join(other_mono,"
],
[
    "res, lidx, ridx = index_large.join(other, how=\"inner\", return_indexers=True)",
    "res, lidx, ridx = index_large.join(other,"
],
[
    "res, lidx, ridx = index_large.join(other, how=\"left\", return_indexers=True)",
    "res, lidx, ridx = index_large.join(other,"
],
[
    "res, lidx, ridx = index_large.join(other_mono, how=\"left\", return_indexers=True)",
    "res, lidx, ridx = index_large.join(other_mono, how=\"left\","
],
[
    "res, lidx, ridx = index_large.join(other, how=\"right\", return_indexers=True)",
    "res, lidx, ridx = index_large.join(other,"
],
[
    "res, lidx, ridx = index_large.join(other, how=\"outer\", return_indexers=True)",
    "res, lidx, ridx = index_large.join(other,"
],
[
    "msg = \"'Cannot get left slice bound for non-unique label: nan'\"",
    "msg = \"'Cannot get left slice"
],
[
    "msg = \"'Cannot get left slice bound for non-unique label: nan\"",
    "msg = \"'Cannot get left slice bound for non-unique"
],
[
    "def test_get_indexer_nearest(self, method, tolerance, indexer, expected):",
    "def test_get_indexer_nearest(self, method,"
],
[
    "with pytest.raises(ValueError, match=\"tolerance size must match\"):",
    "with pytest.raises(ValueError, match=\"tolerance size"
],
[
    "idx = Index([True, False, NA], dtype=dtype)",
    "idx = Index([True,"
],
[
    "msg = f\"Unable to fill values because {name} cannot contain NA\"",
    "msg = f\"Unable to fill values"
],
[
    "rf\"{cls_name}\\(\\.\\.\\.\\) must be called with a collection of \"",
    "rf\"{cls_name}\\(\\.\\.\\.\\) must be called with"
],
[
    "msg = \"Trying to coerce float values to integers\"",
    "msg = \"Trying to coerce float values to"
],
[
    "assert isinstance(result, type(expected)) and result == expected",
    "assert isinstance(result, type(expected)) and"
],
[
    "assert isinstance(result, type(expected)) and result == expected",
    "assert isinstance(result, type(expected)) and"
],
[
    "assert isinstance(result, type(expected)) and result == expected",
    "assert isinstance(result, type(expected)) and result"
],
[
    "assert isinstance(result, type(expected)) and result == expected",
    "assert isinstance(result, type(expected)) and"
],
[
    "assert isinstance(result, type(expected)) and result == expected",
    "assert isinstance(result, type(expected)) and"
],
[
    "assert isinstance(result, type(expected)) and result == expected",
    "assert isinstance(result, type(expected)) and result =="
],
[
    "assert isinstance(result, type(expected)) and result == expected",
    "assert isinstance(result, type(expected)) and result"
],
[
    "assert isinstance(result, type(expected)) and result == expected",
    "assert isinstance(result, type(expected)) and result =="
],
[
    "\"Cannot change data-type for array of references.|\"",
    "\"Cannot change data-type for array of"
],
[
    "\"Cannot change data-type for object array.|\"",
    "\"Cannot change data-type for"
],
[
    "rf\"{index_cls.__name__}\\(\\.\\.\\.\\) must be called with a collection of some \"",
    "rf\"{index_cls.__name__}\\(\\.\\.\\.\\) must be called with a collection of"
],
[
    "msg = \"Trying to coerce object values to integers\"",
    "msg = \"Trying to coerce"
],
[
    "\"Trying to coerce negative values to unsigned integers\",",
    "\"Trying to coerce negative"
],
[
    "\"The elements provided in the data cannot all be casted\",",
    "\"The elements provided in the data"
],
[
    "[list, lambda x: np.array(x, dtype=object), lambda x: Index(x, dtype=object)],",
    "[list, lambda x: np.array(x, dtype=object), lambda x:"
],
[
    "assert isinstance(result, Index) and result.dtype == object",
    "assert isinstance(result, Index) and result.dtype"
],
[
    "assert isinstance(result, Index) and result.dtype == object",
    "assert isinstance(result, Index) and result.dtype"
],
[
    "assert isinstance(result, Index) and result.dtype == dtype",
    "assert isinstance(result, Index) and"
],
[
    "msg = r\"Cannot convert non-finite values \\(NA or inf\\) to integer\"",
    "msg = r\"Cannot convert non-finite values"
],
[
    "actual = index.get_indexer([\"a\", \"b\", \"c\", \"d\"], method=method)",
    "actual = index.get_indexer([\"a\", \"b\","
],
[
    "\"operation 'sub' not supported for dtype 'str'\",",
    "\"operation 'sub' not supported for dtype"
],
[
    "r\"unsupported operand type\\(s\\) for -: 'str' and 'str'\",",
    "r\"unsupported operand type\\(s\\) for -: 'str' and"
],
[
    "idx = Index([\"a\", \"b\", None], dtype=\"object\")",
    "idx = Index([\"a\", \"b\","
],
[
    "index = Index([\"a\", \"b\", nulls_fixture], dtype=object)",
    "index = Index([\"a\", \"b\", nulls_fixture],"
],
[
    "index = Index([\"a\", nulls_fixture, \"b\", nulls_fixture], dtype=object)",
    "index = Index([\"a\", nulls_fixture, \"b\","
],
[
    "index = Index([\"a\", float(\"NaN\"), \"b\", float(\"NaN\")], dtype=object)",
    "index = Index([\"a\", float(\"NaN\"),"
],
[
    "index = Index([\"a\", Decimal(\"NaN\"), \"b\", Decimal(\"NaN\")], dtype=object)",
    "index = Index([\"a\", Decimal(\"NaN\"), \"b\","
],
[
    "msg = \"Passed data is timezone-aware, incompatible with 'tz=None'\"",
    "msg = \"Passed data is timezone-aware, incompatible with"
],
[
    "msg = \"Cannot pass both a timezone-aware dtype and tz=None\"",
    "msg = \"Cannot pass both"
],
[
    "\"Inferred frequency None from passed values does not conform \"",
    "\"Inferred frequency None from passed"
],
[
    "for obj in [ci, carr, cser]:",
    "for obj in [ci,"
],
[
    "with pytest.raises(TypeError, match=\"PeriodDtype data is invalid\"):",
    "with pytest.raises(TypeError, match=\"PeriodDtype data is"
],
[
    "with pytest.raises(TypeError, match=\"PeriodDtype data is invalid\"):",
    "with pytest.raises(TypeError, match=\"PeriodDtype data"
],
[
    "with pytest.raises(TypeError, match=\"PeriodDtype data is invalid\"):",
    "with pytest.raises(TypeError, match=\"PeriodDtype data"
],
[
    "with pytest.raises(TypeError, match=\"PeriodDtype data is invalid\"):",
    "with pytest.raises(TypeError, match=\"PeriodDtype data is"
],
[
    "[{\"tz\": \"dtype.tz\"}, {\"dtype\": \"dtype\"}, {\"dtype\": \"dtype\", \"tz\": \"dtype.tz\"}],",
    "[{\"tz\": \"dtype.tz\"}, {\"dtype\": \"dtype\"}, {\"dtype\": \"dtype\","
],
[
    "kwargs = {key: attrgetter(val)(i) for key, val in kwargs.items()}",
    "kwargs = {key: attrgetter(val)(i) for key,"
],
[
    "[{\"tz\": \"dtype.tz\"}, {\"dtype\": \"dtype\"}, {\"dtype\": \"dtype\", \"tz\": \"dtype.tz\"}],",
    "[{\"tz\": \"dtype.tz\"}, {\"dtype\": \"dtype\"}, {\"dtype\":"
],
[
    "kwargs = {key: attrgetter(val)(i) for key, val in kwargs.items()}",
    "kwargs = {key: attrgetter(val)(i) for key,"
],
[
    "msg = \"cannot supply both a tz and a dtype with a tz\"",
    "msg = \"cannot supply both a tz and a dtype"
],
[
    "msg = \"Mixed timezones detected. Pass utc=True in to_datetime\"",
    "msg = \"Mixed timezones detected."
],
[
    "msg = r\"DatetimeIndex\\(\\.\\.\\.\\) must be called with a collection\"",
    "msg = r\"DatetimeIndex\\(\\.\\.\\.\\) must be called with a"
],
[
    "\"Inferred frequency None from passed values does not conform \"",
    "\"Inferred frequency None from passed values does not conform"
],
[
    "\"cannot supply both a tz and a timezone-naive dtype \"",
    "\"cannot supply both a tz"
],
[
    "msg = \"data is already tz-aware US/Eastern, unable to set specified tz: CET\"",
    "msg = \"data is already tz-aware US/Eastern, unable"
],
[
    "msg = \"cannot supply both a tz and a dtype with a tz\"",
    "msg = \"cannot supply both a tz and a"
],
[
    "msg = \"Unexpected value for 'dtype'\"",
    "msg = \"Unexpected value for"
],
[
    "msg = \"Cannot directly set timezone\"",
    "msg = \"Cannot"
],
[
    "result = date_range(freq=\"D\", start=start, end=end, tz=tz)",
    "result = date_range(freq=\"D\","
],
[
    "def test_constructor_with_int_tz(self, klass, box, tz, dtype):",
    "def test_constructor_with_int_tz(self, klass,"
],
[
    "msg = \"data is already tz-aware US/Central, unable to set specified tz\"",
    "msg = \"data is already tz-aware US/Central,"
],
[
    "msg = \"with no precision is not allowed\"",
    "msg = \"with no precision is not"
],
[
    "idx = Index([\"a\", \"b\", \"c\", \"d\"])",
    "idx = Index([\"a\", \"b\", \"c\","
],
[
    "naive = date_range(start, end, freq=BDay(), tz=None)",
    "naive = date_range(start,"
],
[
    "aware = date_range(start, end, freq=BDay(), tz=\"Asia/Hong_Kong\")",
    "aware = date_range(start, end,"
],
[
    "if inclusive_endpoints == \"left\" and right_match:",
    "if inclusive_endpoints =="
],
[
    "elif inclusive_endpoints == \"right\" and left_match:",
    "elif inclusive_endpoints == \"right\" and"
],
[
    "elif inclusive_endpoints == \"neither\" and left_match and right_match:",
    "elif inclusive_endpoints == \"neither\" and left_match and"
],
[
    "elif inclusive_endpoints == \"neither\" and right_match:",
    "elif inclusive_endpoints == \"neither\""
],
[
    "elif inclusive_endpoints == \"neither\" and left_match:",
    "elif inclusive_endpoints == \"neither\""
],
[
    "from pandas._libs.tslibs.timezones import dateutil_gettz as gettz",
    "from pandas._libs.tslibs.timezones import dateutil_gettz"
],
[
    "msg = \"periods must be an integer, got foo\"",
    "msg = \"periods must be an integer,"
],
[
    "msg = \"periods must be an integer\"",
    "msg = \"periods must be an"
],
[
    "with pytest.raises(TypeError, match=\"pass as a string instead\"):",
    "with pytest.raises(TypeError, match=\"pass as"
],
[
    "@pytest.mark.parametrize(\"freq\", [\"ns\", \"us\", \"ms\", \"min\", \"s\", \"h\", \"D\"])",
    "@pytest.mark.parametrize(\"freq\", [\"ns\", \"us\", \"ms\", \"min\", \"s\", \"h\","
],
[
    "with pytest.raises(OutOfBoundsDatetime, match=\"Cannot generate range with\"):",
    "with pytest.raises(OutOfBoundsDatetime, match=\"Cannot generate range"
],
[
    "msg = \"Neither `start` nor `end` can be NaT\"",
    "msg = \"Neither `start` nor `end` can"
],
[
    "msg = \"Cannot generate range with\"",
    "msg = \"Cannot generate range"
],
[
    "msg = \"Cannot generate range with\"",
    "msg = \"Cannot"
],
[
    "\"Of the four parameters: start, end, periods, and \"",
    "\"Of the four parameters: start,"
],
[
    "\"freq, exactly three must be specified\"",
    "\"freq, exactly three must be"
],
[
    "with pytest.raises(ValueError, match=\"Unable to coerce to Series\"):",
    "with pytest.raises(ValueError, match=\"Unable to coerce to"
],
[
    "with pytest.raises(ValueError, match=\"Unable to coerce to Series\"):",
    "with pytest.raises(ValueError, match=\"Unable to coerce to"
],
[
    "[[True, False, False], [False, True, False], [False, False, True]]",
    "[[True, False, False], [False, True,"
],
[
    "\"Of the four parameters: start, end, periods, and \"",
    "\"Of the four parameters: start,"
],
[
    "\"freq, exactly three must be specified\"",
    "\"freq, exactly three"
],
[
    "dr = date_range(start, end, freq=\"D\", tz=tz)",
    "dr = date_range(start, end, freq=\"D\","
],
[
    "tz = lambda x: maybe_get_tz(\"dateutil/\" + x)",
    "tz = lambda x:"
],
[
    "both_range = date_range(begin, end, inclusive=\"both\", freq=freq)",
    "both_range = date_range(begin, end,"
],
[
    "msg = \"Inferred time zone not equal to passed time zone\"",
    "msg = \"Inferred time zone not"
],
[
    "both_range = date_range(start=start, end=end, freq=\"D\", inclusive=\"both\")",
    "both_range = date_range(start=start, end=end, freq=\"D\","
],
[
    "elif inclusive_endpoints_fixture in (\"left\", \"right\", \"both\"):",
    "elif inclusive_endpoints_fixture in"
],
[
    "\"freq_depr\", [\"m\", \"bm\", \"CBM\", \"SM\", \"BQ\", \"q-feb\", \"y-may\", \"Y-MAY\"]",
    "\"freq_depr\", [\"m\", \"bm\", \"CBM\", \"SM\", \"BQ\", \"q-feb\","
],
[
    "def __init__(self, offset, name) -> None:",
    "def __init__(self, offset, name) ->"
],
[
    "for a, b, c in zip(utc_range, eastern_range, berlin_range):",
    "for a, b, c in zip(utc_range,"
],
[
    "msg = \"Start and end cannot both be tz-aware with different timezones\"",
    "msg = \"Start and end cannot both be tz-aware with"
],
[
    "dates_aware = [conversion.localize_pydatetime(x, tz) for x in dates]",
    "dates_aware = [conversion.localize_pydatetime(x, tz) for"
],
[
    "ex_vals = np.array([Timestamp(x).as_unit(\"ns\")._value for x in dates_aware])",
    "ex_vals = np.array([Timestamp(x).as_unit(\"ns\")._value for x in"
],
[
    "from pandas._libs import index as libindex",
    "from pandas._libs import index"
],
[
    "dr = date_range(st, et, freq=\"h\", name=\"timebucket\")",
    "dr = date_range(st, et,"
],
[
    "expected = Index([pd.NaT._value, pd.NaT._value] + tail, dtype=object)",
    "expected = Index([pd.NaT._value, pd.NaT._value] +"
],
[
    "expected = Index([td, td] + tail, dtype=object)",
    "expected = Index([td, td] + tail,"
],
[
    "msg = r\"take\\(\\) got an unexpected keyword argument 'foo'\"",
    "msg = r\"take\\(\\) got an"
],
[
    "msg = \"the 'out' parameter is not supported\"",
    "msg = \"the 'out' parameter is not"
],
[
    "msg = \"the 'mode' parameter is not supported\"",
    "msg = \"the 'mode' parameter is"
],
[
    "expected = DatetimeIndex(dates, freq=None, name=\"idx\", dtype=idx.dtype)",
    "expected = DatetimeIndex(dates, freq=None,"
],
[
    "locs = np.arange(start, n, step, dtype=np.intp)",
    "locs = np.arange(start,"
],
[
    "msg = \"Cannot index DatetimeIndex with [Tt]imedelta\"",
    "msg = \"Cannot index DatetimeIndex"
],
[
    "msg = \"Could not convert 'foo' to NumPy timedelta\"",
    "msg = \"Could not convert"
],
[
    "with pytest.raises(ValueError, match=\"abbreviation w/o a number\"):",
    "with pytest.raises(ValueError, match=\"abbreviation w/o a"
],
[
    "msg = \"index must be monotonic increasing or decreasing\"",
    "msg = \"index must be monotonic"
],
[
    "self, box, side, year, expected, tz_aware_fixture",
    "self, box, side, year,"
],
[
    "expected = np.array([\"foo\", \"NaT\", \"foo\"], dtype=object)",
    "expected = np.array([\"foo\", \"NaT\","
],
[
    "def test_dti_repr_time_midnight(self, dates, freq, expected_repr, unit):",
    "def test_dti_repr_time_midnight(self, dates, freq,"
],
[
    "for index, expected in zip(idxs, exp):",
    "for index, expected in zip(idxs,"
],
[
    "for rng, other, exp, exp_notsorted in [",
    "for rng, other, exp, exp_notsorted"
],
[
    "cases = [klass(second.values) for klass in [np.array, Series, list]]",
    "cases = [klass(second.values) for klass in"
],
[
    "for rng, other, expected in [",
    "for rng, other,"
],
[
    "if sort is None and len(other):",
    "if sort is None"
],
[
    "early_dr = date_range(start=early_start, end=early_end, tz=tz, freq=MonthEnd())",
    "early_dr = date_range(start=early_start, end=early_end,"
],
[
    "late_dr = date_range(start=late_start, end=late_end, tz=tz, freq=MonthEnd())",
    "late_dr = date_range(start=late_start,"
],
[
    "early_dr = date_range(start=early_start, end=early_end, tz=tz, freq=MonthEnd())",
    "early_dr = date_range(start=early_start, end=early_end,"
],
[
    "late_dr = date_range(start=late_start, end=late_end, tz=tz, freq=MonthEnd())",
    "late_dr = date_range(start=late_start,"
],
[
    "idx = Index([\"a\", \"b\", \"c\", \"d\"])",
    "idx = Index([\"a\","
],
[
    "monthly_group = df.groupby(lambda x: (x.year, x.month))",
    "monthly_group = df.groupby(lambda x:"
],
[
    "reason=\"The inherited freq is incorrect bc dti.freq is incorrect \"",
    "reason=\"The inherited freq is incorrect bc dti.freq"
],
[
    "msg = \"the 'axis' parameter is not supported\"",
    "msg = \"the 'axis' parameter is"
],
[
    "with pytest.raises(NullFrequencyError, match=\"Cannot shift with no freq\"):",
    "with pytest.raises(NullFrequencyError, match=\"Cannot shift"
],
[
    "(\"ME\", \"<MonthEnd> is a non-fixed frequency\"),",
    "(\"ME\", \"<MonthEnd> is"
],
[
    "msg = \"<MonthEnd> is a non-fixed frequency\"",
    "msg = \"<MonthEnd> is a"
],
[
    "def test_ceil_floor_edge(self, test_input, rounder, freq, expected):",
    "def test_ceil_floor_edge(self, test_input,"
],
[
    "expected = Index([item] + list(idx), dtype=object)",
    "expected = Index([item] + list(idx),"
],
[
    "for n, d, expected in cases:",
    "for n, d, expected"
],
[
    "[lambda x: x, lambda x: x.to_pydatetime()],",
    "[lambda x: x, lambda"
],
[
    "[lambda x: x, lambda x: x.to_pydatetime()],",
    "[lambda x: x, lambda"
],
[
    "msg = \"You must pass a freq argument as current index has none.\"",
    "msg = \"You must pass a freq argument as current index has"
],
[
    "f\"{freq} is not supported as period frequency\",",
    "f\"{freq} is not supported"
],
[
    "msg = \"'w-mon' is deprecated and will be removed in a future version.\"",
    "msg = \"'w-mon' is deprecated and will be"
],
[
    "msg = \"'b' is deprecated and will be removed in a future version.\"",
    "msg = \"'b' is deprecated and will"
],
[
    "with pytest.raises((IndexError, ValueError), match=\"out of bounds\"):",
    "with pytest.raises((IndexError, ValueError),"
],
[
    "with pytest.raises(ValueError, match=\"Cannot infer dst time\"):",
    "with pytest.raises(ValueError, match=\"Cannot infer dst"
],
[
    "with pytest.raises(ValueError, match=\"Cannot infer dst time\"):",
    "with pytest.raises(ValueError, match=\"Cannot"
],
[
    "with pytest.raises(ValueError, match=\"Cannot infer dst time\"):",
    "with pytest.raises(ValueError, match=\"Cannot"
],
[
    "TypeError, match=\"Already tz-aware, use tz_convert to convert\"",
    "TypeError, match=\"Already tz-aware, use tz_convert to"
],
[
    "msg = \"Length of ambiguous bool-array must be the same size as vals\"",
    "msg = \"Length of ambiguous bool-array must"
],
[
    "self, start_ts, tz, end_ts, shift, tz_type, unit",
    "self, start_ts, tz, end_ts, shift, tz_type,"
],
[
    "msg = \"The provided timedelta will relocalize on a nonexistent time\"",
    "msg = \"The provided timedelta will relocalize"
],
[
    "msg = \"Cannot use .astype to convert from timezone-aware\"",
    "msg = \"Cannot use .astype"
],
[
    "msg = \"Cannot use .astype to convert from timezone-naive\"",
    "msg = \"Cannot use .astype"
],
[
    "msg = \"Cannot use .astype to convert from timezone-aware\"",
    "msg = \"Cannot use .astype to convert"
],
[
    "msg = \"Cannot cast DatetimeIndex to dtype\"",
    "msg = \"Cannot cast DatetimeIndex"
],
[
    "for x, stamp in zip(converted, rng):",
    "for x, stamp in zip(converted,"
],
[
    "for x, stamp in zip(converted, rng):",
    "for x, stamp in"
],
[
    "for x, stamp in zip(converted, rng):",
    "for x, stamp"
],
[
    "exp = Index([f(x) for x in rng])",
    "exp = Index([f(x) for"
],
[
    "WASM, reason=\"tzset is available only on Unix-like systems, not WASM\"",
    "WASM, reason=\"tzset is available only"
],
[
    "idx = DatetimeIndex(strdates, tz=prefix + \"US/Eastern\")",
    "idx = DatetimeIndex(strdates,"
],
[
    "msg = \"value should be a 'Timedelta', 'NaT', or array of those. Got\"",
    "msg = \"value should be a 'Timedelta', 'NaT', or"
],
[
    "msg = \"TimedeltaArray/Index freq must be a Tick\"",
    "msg = \"TimedeltaArray/Index freq must"
],
[
    "msg = \"Invalid type for timedelta scalar\"",
    "msg = \"Invalid type for timedelta"
],
[
    "assert \"inferred_freq\" not in getattr(result, \"_cache\", {})",
    "assert \"inferred_freq\" not in"
],
[
    "\"Inferred frequency .* from passed values does \"",
    "\"Inferred frequency .* from passed"
],
[
    "msg = \"periods must be an integer\"",
    "msg = \"periods must"
],
[
    "msg = \"periods must be an integer, got foo\"",
    "msg = \"periods must be an integer,"
],
[
    "r\"TimedeltaIndex\\(\\.\\.\\.\\) must be called with a collection of some kind, \"",
    "r\"TimedeltaIndex\\(\\.\\.\\.\\) must be called with a collection of"
],
[
    "\"Inferred frequency None from passed values does not conform to \"",
    "\"Inferred frequency None from passed values does not"
],
[
    "\"Of the four parameters: start, end, periods, and freq, exactly \"",
    "\"Of the four parameters: start, end,"
],
[
    "msg = \"with no precision is not allowed\"",
    "msg = \"with no precision is"
],
[
    "msg = f\"'{unit_depr}' is deprecated and will be removed in a future version.\"",
    "msg = f\"'{unit_depr}' is deprecated and will be removed in a future"
],
[
    "idx = Index([\"a\", \"b\", \"c\", \"d\"])",
    "idx = Index([\"a\", \"b\", \"c\","
],
[
    "msg = \"'TimedeltaIndex' object has no attribute '{}'\"",
    "msg = \"'TimedeltaIndex' object has"
],
[
    "msg = \"'d' is deprecated and will be removed in a future version.\"",
    "msg = \"'d' is deprecated and will"
],
[
    "expected = Index([NaT._value, NaT._value] + tail, dtype=object, name=\"idx\")",
    "expected = Index([NaT._value, NaT._value]"
],
[
    "expected = Index([ts, ts] + tail, dtype=object, name=\"idx\")",
    "expected = Index([ts, ts] + tail,"
],
[
    "msg = r\"take\\(\\) got an unexpected keyword argument 'foo'\"",
    "msg = r\"take\\(\\) got an"
],
[
    "msg = \"the 'out' parameter is not supported\"",
    "msg = \"the 'out' parameter is"
],
[
    "msg = \"the 'mode' parameter is not supported\"",
    "msg = \"the 'mode' parameter is not"
],
[
    "\"cannot do slice indexing on TimedeltaIndex with these \"",
    "\"cannot do slice indexing on"
],
[
    "\"cannot do slice indexing on TimedeltaIndex with these \"",
    "\"cannot do slice indexing on"
],
[
    "msg = \"'d' is deprecated and will be removed in a future version.\"",
    "msg = \"'d' is deprecated and will be removed in a"
],
[
    "for v in [NaT, None, float(\"nan\"), np.nan]:",
    "for v in [NaT, None,"
],
[
    "for v in [NaT, None, float(\"nan\"), np.nan]:",
    "for v in [NaT, None,"
],
[
    "msg = \"'d' is deprecated and will be removed in a future version.\"",
    "msg = \"'d' is deprecated and will be removed in a future"
],
[
    "@pytest.mark.parametrize(\"depr_unit, unit\", [(\"H\", \"hour\"), (\"S\", \"second\")])",
    "@pytest.mark.parametrize(\"depr_unit, unit\", [(\"H\", \"hour\"),"
],
[
    "f\"'{depr_unit}' is deprecated and will be removed in a future version.\"",
    "f\"'{depr_unit}' is deprecated and will be removed in"
],
[
    "@pytest.mark.parametrize(\"unit\", [\"T\", \"t\", \"L\", \"l\", \"U\", \"u\", \"N\", \"n\"])",
    "@pytest.mark.parametrize(\"unit\", [\"T\", \"t\", \"L\", \"l\", \"U\", \"u\", \"N\","
],
[
    "msg = f\"invalid unit abbreviation: {unit}\"",
    "msg = f\"invalid unit abbreviation:"
],
[
    "\"Of the four parameters: start, end, periods, and freq, \"",
    "\"Of the four parameters: start, end, periods,"
],
[
    "def test_timedelta_range_freq_divide_end(self, start, end, freq, expected_periods):",
    "def test_timedelta_range_freq_divide_end(self, start, end,"
],
[
    "with pytest.raises(NullFrequencyError, match=\"Cannot shift with no freq\"):",
    "with pytest.raises(NullFrequencyError, match=\"Cannot shift with"
],
[
    "for n, d, expected in cases:",
    "for n, d,"
],
[
    "expected = Index([item] + list(idx), dtype=object, name=\"idx\")",
    "expected = Index([item] + list(idx), dtype=object,"
],
[
    "expected = Index([\"foo\"] + list(idx), dtype=object)",
    "expected = Index([\"foo\"] +"
],
[
    "with pytest.raises(IndexError, match=\"loc must be an integer between\"):",
    "with pytest.raises(IndexError, match=\"loc must"
],
[
    "with pytest.raises(IndexError, match=\"loc must be an integer between\"):",
    "with pytest.raises(IndexError, match=\"loc must be"
],
[
    "[str(x) if x is not NaT else None for x in idx], name=\"idx\", dtype=\"str\"",
    "[str(x) if x is not NaT else None for x in"
],
[
    "expected = Index([str(x) for x in idx], name=\"idx\", dtype=object)",
    "expected = Index([str(x) for x in"
],
[
    "\"Supported resolutions are 's', 'ms', 'us', 'ns'\"",
    "\"Supported resolutions are 's', 'ms',"
],
[
    "\"Supported resolutions are 's', 'ms', 'us', 'ns'\"",
    "\"Supported resolutions are 's', 'ms', 'us',"
],
[
    "msg = \"Cannot cast TimedeltaIndex to dtype\"",
    "msg = \"Cannot cast TimedeltaIndex to"
],
[
    "return val is not pd.NA and np.isnan(val)",
    "return val is not pd.NA and"
],
[
    "if dtype.na_value is pd.NA and null is pd.NA:",
    "if dtype.na_value is pd.NA and null is"
],
[
    "index = Index([\"a\", \"b\", \"c\"], dtype=any_string_dtype)",
    "index = Index([\"a\", \"b\", \"c\"],"
],
[
    "index = Index([\"a\", \"b\", \"c\"], dtype=any_string_dtype)",
    "index = Index([\"a\","
],
[
    "index = Index([\"a\", \"b\", \"c\"], dtype=any_string_dtype)",
    "index = Index([\"a\", \"b\","
],
[
    "index = Index([\"a\", \"b\", \"a\"], dtype=any_string_dtype)",
    "index = Index([\"a\", \"b\","
],
[
    "index = Index([\"a\", \"b\", \"c\"], dtype=any_string_dtype)",
    "index = Index([\"a\","
],
[
    "index = Index([\"a\", \"b\", nulls_fixture], dtype=any_string_dtype)",
    "index = Index([\"a\", \"b\","
],
[
    "actual = index.get_indexer([\"a\", \"b\", \"c\", \"d\"], method=method)",
    "actual = index.get_indexer([\"a\", \"b\","
],
[
    "\"operation 'sub' not supported for dtype 'str\",",
    "\"operation 'sub' not supported"
],
[
    "r\"unsupported operand type\\(s\\) for -: 'str' and 'str'\",",
    "r\"unsupported operand type\\(s\\) for"
],
[
    "index = Index([\"a\", \"b\", null], dtype=any_string_dtype)",
    "index = Index([\"a\", \"b\","
],
[
    "elif any_string_dtype == \"string\" and not _equivalent_na(",
    "elif any_string_dtype == \"string\""
],
[
    "index = Index([\"a\", \"b\", null], dtype=any_string_dtype)",
    "index = Index([\"a\","
],
[
    "elif any_string_dtype == \"string\" and not _equivalent_na(",
    "elif any_string_dtype == \"string\" and"
],
[
    "index = Index([\"a\", null, \"b\", null], dtype=any_string_dtype)",
    "index = Index([\"a\", null,"
],
[
    "elif any_string_dtype == \"string\" and not _equivalent_na(",
    "elif any_string_dtype == \"string\""
],
[
    "s_start, s_stop = index.slice_locs(in_slice.start, in_slice.stop, in_slice.step)",
    "s_start, s_stop = index.slice_locs(in_slice.start,"
],
[
    "result = index[s_start : s_stop : in_slice.step]",
    "result = index[s_start : s_stop"
],
[
    "index = Index([\"a\", \"a\", \"b\", \"c\", \"d\", \"d\"], dtype=any_string_dtype)",
    "index = Index([\"a\", \"a\", \"b\", \"c\", \"d\", \"d\"],"
],
[
    "def test_drop_duplicates(self, keep, expected, index, idx):",
    "def test_drop_duplicates(self, keep, expected, index,"
],
[
    "for obj in [pi, pi._engine, dti, dti._engine, tdi, tdi._engine]:",
    "for obj in [pi, pi._engine, dti,"
],
[
    "obj: Any, path: FilePath | ReadPickleBuffer | None = None",
    "obj: Any, path: FilePath | ReadPickleBuffer | None ="
],
[
    "STRING_DTYPES: list[Dtype] = [str, \"str\", \"U\"]",
    "STRING_DTYPES: list[Dtype] = [str,"
],
[
    "ENDIAN = {\"little\": \"<\", \"big\": \">\"}[byteorder]",
    "ENDIAN = {\"little\": \"<\","
],
[
    "NULL_OBJECTS = [None, np.nan, pd.NaT, float(\"nan\"), pd.NA, Decimal(\"NaN\")]",
    "NULL_OBJECTS = [None, np.nan, pd.NaT, float(\"nan\"),"
],
[
    "for unit in [\"s\", \"ms\", \"us\", \"ns\"]",
    "for unit in [\"s\","
],
[
    "for tz in [None, \"UTC\", \"US/Pacific\", \"US/Eastern\"]",
    "for tz in [None, \"UTC\", \"US/Pacific\","
],
[
    "TIMEDELTA_PYARROW_DTYPES = [pa.duration(unit) for unit in [\"s\", \"ms\", \"us\", \"ns\"]]",
    "TIMEDELTA_PYARROW_DTYPES = [pa.duration(unit) for unit"
],
[
    "comparison_dunder_methods = [\"__eq__\", \"__ne__\", \"__le__\", \"__lt__\", \"__ge__\", \"__gt__\"]",
    "comparison_dunder_methods = [\"__eq__\", \"__ne__\", \"__le__\", \"__lt__\","
],
[
    "def box_expected(expected, box_cls, transpose: bool = True):",
    "def box_expected(expected, box_cls, transpose:"
],
[
    "expected_warning: type[Warning] | bool | tuple[type[Warning], ...] | None = Warning,",
    "expected_warning: type[Warning] | bool | tuple[type[Warning], ...] | None ="
],
[
    "\"error\", \"ignore\", \"always\", \"default\", \"module\", \"once\"",
    "\"error\", \"ignore\", \"always\", \"default\", \"module\","
],
[
    "match: str | tuple[str | None, ...] | None = None,",
    "match: str | tuple[str | None,"
],
[
    "raise AssertionError(f\"Did not see expected warning of class {warning_name!r}\")",
    "raise AssertionError(f\"Did not see expected warning of"
],
[
    "f\"Did not see warning {warning_name!r} \"",
    "f\"Did not see warning {warning_name!r}"
],
[
    "f\"matching '{match}'. The emitted warning messages are \"",
    "f\"matching '{match}'. The emitted"
],
[
    "expected_warning: type[Warning] | bool | tuple[type[Warning], ...] | None,",
    "expected_warning: type[Warning] | bool |"
],
[
    "\"Warning not set with correct stacklevel. \"",
    "\"Warning not set with"
],
[
    "f\"File where warning is raised: {actual_warning.filename} != \"",
    "f\"File where warning is raised: {actual_warning.filename}"
],
[
    "check_dtype: bool | Literal[\"equiv\"] = \"equiv\",",
    "check_dtype: bool | Literal[\"equiv\"] ="
],
[
    "path: FilePath | BaseBuffer, compression: CompressionOptions",
    "path: FilePath |"
],
[
    "xlabelsize: int | None = None,",
    "xlabelsize: int | None"
],
[
    "xrot: float | None = None,",
    "xrot: float | None ="
],
[
    "ylabelsize: int | None = None,",
    "ylabelsize: int | None"
],
[
    "yrot: float | None = None,",
    "yrot: float |"
],
[
    "figsize: tuple[int, int] | None = None,",
    "figsize: tuple[int, int] | None"
],
[
    "backend: str | None = None,",
    "backend: str | None"
],
[
    "def table(ax: Axes, data: DataFrame | Series, **kwargs) -> Table:",
    "def table(ax: Axes, data: DataFrame"
],
[
    "figsize: tuple[float, float] | None = None,",
    "figsize: tuple[float, float] | None ="
],
[
    "fig, axes = create_subplots(naxes=naxes, figsize=figsize, ax=ax, squeeze=False)",
    "fig, axes = create_subplots(naxes=naxes,"
],
[
    "boundaries_list.append((rmin_ - rdelta_ext, rmax_ + rdelta_ext))",
    "boundaries_list.append((rmin_ - rdelta_ext, rmax_"
],
[
    "ax: Axes | None = None,",
    "ax: Axes |"
],
[
    "return (series - a) / (b - a)",
    "return (series - a) / (b"
],
[
    "for xy, name in zip(s, df.columns):",
    "for xy, name"
],
[
    "ax: Axes | None = None,",
    "ax: Axes |"
],
[
    "fig: Figure | None = None,",
    "fig: Figure |"
],
[
    "samplings = [random.sample(data, size) for _ in range(samples)]",
    "samplings = [random.sample(data, size)"
],
[
    "means = np.array([np.mean(sampling) for sampling in samplings])",
    "means = np.array([np.mean(sampling) for"
],
[
    "medians = np.array([np.median(sampling) for sampling in samplings])",
    "medians = np.array([np.median(sampling) for sampling"
],
[
    "ax: Axes | None = None,",
    "ax: Axes | None ="
],
[
    "raise ValueError(\"Columns must be numeric to be used as xticks\")",
    "raise ValueError(\"Columns must be numeric"
],
[
    "raise ValueError(\"xticks specified must be numeric\")",
    "raise ValueError(\"xticks specified must be"
],
[
    "raise ValueError(\"Length of xticks must match number of columns\")",
    "raise ValueError(\"Length of xticks must"
],
[
    "def autocorrelation_plot(series: Series, ax: Axes | None = None, **kwds) -> Axes:",
    "def autocorrelation_plot(series: Series, ax: Axes | None = None,"
],
[
    "y = [r(loc) for loc in x]",
    "y = [r(loc) for loc in"
],
[
    "def _adjust_bins(self, bins: int | np.ndarray | list[np.ndarray]):",
    "def _adjust_bins(self, bins: int |"
],
[
    "bins = [self._calculate_bins(group, bins) for key, group in grouped]",
    "bins = [self._calculate_bins(group, bins) for key,"
],
[
    "def _calculate_bins(self, data: Series | DataFrame, bins) -> np.ndarray:",
    "def _calculate_bins(self, data: Series | DataFrame, bins)"
],
[
    "\"weights must have the same shape as data, \"",
    "\"weights must have the same shape as"
],
[
    "def _post_plot_logic(self, ax: Axes, data) -> None:",
    "def _post_plot_logic(self, ax: Axes, data)"
],
[
    "\"Frequency\" if self.xlabel is None else self.xlabel",
    "\"Frequency\" if self.xlabel is None"
],
[
    "\"Frequency\" if self.ylabel is None else self.ylabel",
    "\"Frequency\" if self.ylabel is"
],
[
    "self, data, bw_method=None, ind=None, *, weights=None, **kwargs",
    "self, data, bw_method=None, ind=None, *,"
],
[
    "stacking_id: int | None = None,",
    "stacking_id: int | None ="
],
[
    "lines = MPLPlot._plot(ax, ind, y, style=style, **kwds)",
    "lines = MPLPlot._plot(ax, ind,"
],
[
    "def _make_plot_keywords(self, kwds: dict[str, Any], y: np.ndarray) -> None:",
    "def _make_plot_keywords(self, kwds: dict[str, Any], y: np.ndarray)"
],
[
    "def _post_plot_logic(self, ax: Axes, data) -> None:",
    "def _post_plot_logic(self, ax: Axes,"
],
[
    "figsize: tuple[float, float] | None = None,",
    "figsize: tuple[float, float] | None"
],
[
    "\"figsize='default' is no longer supported. \"",
    "\"figsize='default' is no longer supported."
],
[
    "\"Specify figure size by tuple instead\"",
    "\"Specify figure size by tuple"
],
[
    "naxes=naxes, figsize=figsize, sharex=sharex, sharey=sharey, ax=ax, layout=layout",
    "naxes=naxes, figsize=figsize, sharex=sharex,"
],
[
    "for ax, (key, group) in zip(flatten_axes(axes), grouped):",
    "for ax, (key, group)"
],
[
    "figsize: tuple[float, float] | None = None,",
    "figsize: tuple[float, float] |"
],
[
    "xlabelsize: int | None = None,",
    "xlabelsize: int |"
],
[
    "ylabelsize: int | None = None,",
    "ylabelsize: int | None"
],
[
    "def _set_ticklabels(ax: Axes, labels: list[str], is_vertical: bool, **kwargs) -> None:",
    "def _set_ticklabels(ax: Axes, labels: list[str], is_vertical: bool, **kwargs) ->"
],
[
    "from pandas._typing import MatplotlibColor as Color",
    "from pandas._typing import MatplotlibColor"
],
[
    "colormap: Colormap | None = ...,",
    "colormap: Colormap | None"
],
[
    "colormap: Colormap | None = ...,",
    "colormap: Colormap |"
],
[
    "color: Color | Sequence[Color] | None = ...,",
    "color: Color | Sequence[Color] |"
],
[
    "colormap: Colormap | None = ...,",
    "colormap: Colormap | None"
],
[
    "color: dict[str, Color] | Color | Sequence[Color] | None = ...,",
    "color: dict[str, Color] | Color | Sequence[Color] |"
],
[
    ") -> dict[str, Color] | list[Color]: ...",
    ") -> dict[str, Color] |"
],
[
    "colormap: Colormap | None = None,",
    "colormap: Colormap |"
],
[
    "color: dict[str, Color] | Color | Sequence[Color] | None = None,",
    "color: dict[str, Color] | Color | Sequence[Color]"
],
[
    ") -> dict[str, Color] | list[Color]:",
    ") -> dict[str,"
],
[
    "def _get_cmap_instance(colormap: str | Colormap) -> Colormap:",
    "def _get_cmap_instance(colormap: str | Colormap) ->"
],
[
    "def _is_single_color(color: Color | Collection[Color]) -> bool:",
    "def _is_single_color(color: Color | Collection[Color]) ->"
],
[
    "and all(isinstance(x, (int, float)) for x in color)",
    "and all(isinstance(x, (int, float)) for x"
],
[
    "def _get_colors_from_color_type(color_type: str, num_colors: int) -> list[Color]:",
    "def _get_colors_from_color_type(color_type: str, num_colors: int)"
],
[
    "colors = [c[\"color\"] for c in mpl.rcParams[\"axes.prop_cycle\"]]",
    "colors = [c[\"color\"] for c in"
],
[
    "def format_date_labels(ax: Axes, rot) -> None:",
    "def format_date_labels(ax: Axes, rot) ->"
],
[
    "ax, data: DataFrame | Series, rowLabels=None, colLabels=None, **kwargs",
    "ax, data: DataFrame | Series, rowLabels=None, colLabels=None,"
],
[
    "raise ValueError(\"Input data must be DataFrame or Series\")",
    "raise ValueError(\"Input data must"
],
[
    "layout: tuple[int, int] | None = None,",
    "layout: tuple[int, int] | None"
],
[
    "raise ValueError(\"Layout must be a tuple of (rows, columns)\")",
    "raise ValueError(\"Layout must be a tuple of"
],
[
    "layout = (ceil(nplots / ncols), ncols)",
    "layout = (ceil(nplots / ncols),"
],
[
    "layout = (nrows, ceil(nplots / nrows))",
    "layout = (nrows, ceil(nplots"
],
[
    "msg = \"At least one dimension of layout must be positive\"",
    "msg = \"At least one dimension of"
],
[
    "if nrows * ncols < nplots:",
    "if nrows * ncols"
],
[
    "f\"Layout of {nrows}x{ncols} must be larger than required size {nplots}\"",
    "f\"Layout of {nrows}x{ncols} must be larger than"
],
[
    "estimate = (nmax - nmin) / (self._get_unit() * self._get_interval())",
    "estimate = (nmax - nmin)"
],
[
    "f\"{estimate:d} ticks from {dmin} to {dmax}: exceeds Locator.MAXTICKS\"",
    "f\"{estimate:d} ticks from {dmin}"
],
[
    "all_dates = date_range(start=st, end=ed, freq=freq, tz=tz).astype(object)",
    "all_dates = date_range(start=st, end=ed, freq=freq,"
],
[
    "format = np.compress(info[\"min\"] & np.logical_not(info[\"maj\"]), info)",
    "format = np.compress(info[\"min\"]"
],
[
    "self.formatdict = {x: f for (x, _, _, f) in format}",
    "self.formatdict = {x: f for (x, _,"
],
[
    "def orientation(self) -> str | None:",
    "def orientation(self) ->"
],
[
    "by: IndexLabel | None = None,",
    "by: IndexLabel | None"
],
[
    "subplots: bool | Sequence[Sequence[str]] = False,",
    "subplots: bool |"
],
[
    "sharex: bool | None = None,",
    "sharex: bool | None ="
],
[
    "figsize: tuple[float, float] | None = None,",
    "figsize: tuple[float, float] |"
],
[
    "legend: bool | str = True,",
    "legend: bool |"
],
[
    "xlabel: Hashable | None = None,",
    "xlabel: Hashable |"
],
[
    "ylabel: Hashable | None = None,",
    "ylabel: Hashable | None ="
],
[
    "fontsize: int | None = None,",
    "fontsize: int | None"
],
[
    "secondary_y: bool | tuple | list | np.ndarray = False,",
    "secondary_y: bool | tuple | list"
],
[
    "column: IndexLabel | None = None,",
    "column: IndexLabel | None ="
],
[
    "logx: bool | None | Literal[\"sym\"] = False,",
    "logx: bool | None"
],
[
    "logy: bool | None | Literal[\"sym\"] = False,",
    "logy: bool | None | Literal[\"sym\"]"
],
[
    "loglog: bool | None | Literal[\"sym\"] = False,",
    "loglog: bool | None | Literal[\"sym\"] ="
],
[
    "label: Hashable | None = None,",
    "label: Hashable | None ="
],
[
    "col for col in data.columns if is_numeric_dtype(data[col])",
    "col for col in data.columns"
],
[
    "if col not in self.by and is_numeric_dtype(data[col])",
    "if col not in self.by"
],
[
    "if self.by is not None and self._kind == \"hist\":",
    "if self.by is not None and self._kind =="
],
[
    "grid = False if secondary_y else mpl.rcParams[\"axes.grid\"]",
    "grid = False if secondary_y else"
],
[
    "xerr, data = type(self)._parse_errorbars(\"xerr\", xerr, data, nseries)",
    "xerr, data = type(self)._parse_errorbars(\"xerr\", xerr, data,"
],
[
    "yerr, data = type(self)._parse_errorbars(\"yerr\", yerr, data, nseries)",
    "yerr, data = type(self)._parse_errorbars(\"yerr\", yerr, data,"
],
[
    "self.errors = {\"xerr\": xerr, \"yerr\": yerr}",
    "self.errors = {\"xerr\": xerr,"
],
[
    "if not isinstance(secondary_y, (bool, tuple, list, np.ndarray, ABCIndex)):",
    "if not isinstance(secondary_y, (bool, tuple,"
],
[
    "if \"cmap\" in kwds and colormap:",
    "if \"cmap\" in"
],
[
    "raise TypeError(\"Only specify one of `cmap` and `colormap`.\")",
    "raise TypeError(\"Only specify one"
],
[
    "def _validate_sharex(sharex: bool | None, ax, by) -> bool:",
    "def _validate_sharex(sharex: bool | None, ax,"
],
[
    "if ax is None and by is None:",
    "if ax is None and by is"
],
[
    "raise TypeError(\"sharex must be a bool or None\")",
    "raise TypeError(\"sharex must be"
],
[
    "value: bool | None | Literal[\"sym\"],",
    "value: bool |"
],
[
    ") -> bool | None | Literal[\"sym\"]:",
    ") -> bool | None |"
],
[
    "or (isinstance(value, str) and value == \"sym\")",
    "or (isinstance(value, str) and"
],
[
    "f\"keyword '{kwd}' should be bool, None, or 'sym', not '{value}'\"",
    "f\"keyword '{kwd}' should be bool, None,"
],
[
    "subplots: bool | Sequence[Sequence[str]], data: Series | DataFrame, kind: str",
    "subplots: bool | Sequence[Sequence[str]], data: Series | DataFrame, kind:"
],
[
    ") -> bool | list[tuple[int, ...]]:",
    ") -> bool | list[tuple[int,"
],
[
    "def _maybe_right_yaxis(self, ax: Axes, axes_num: int) -> Axes:",
    "def _maybe_right_yaxis(self, ax: Axes, axes_num:"
],
[
    "if self.logy is True or self.loglog is True:",
    "if self.logy is True or self.loglog is"
],
[
    "elif self.logy == \"sym\" or self.loglog == \"sym\":",
    "elif self.logy == \"sym\" or self.loglog"
],
[
    "self.nseries if isinstance(self.subplots, bool) else len(self.subplots)",
    "self.nseries if isinstance(self.subplots, bool) else"
],
[
    "if self.logx is True or self.loglog is True:",
    "if self.logx is True or self.loglog"
],
[
    "elif self.logx == \"sym\" or self.loglog == \"sym\":",
    "elif self.logx == \"sym\""
],
[
    "if self.logy is True or self.loglog is True:",
    "if self.logy is True or"
],
[
    "elif self.logy == \"sym\" or self.loglog == \"sym\":",
    "elif self.logy == \"sym\" or self.loglog"
],
[
    "if self.orientation == \"vertical\" or self.orientation is None:",
    "if self.orientation == \"vertical\" or self.orientation"
],
[
    "def _post_plot_logic(self, ax: Axes, data) -> None:",
    "def _post_plot_logic(self, ax: Axes, data) ->"
],
[
    "\"The length of `title` must equal the number \"",
    "\"The length of `title` must"
],
[
    "\"of columns if using `title` of type `list` \"",
    "\"of columns if using `title` of type"
],
[
    "for ax, title in zip(self.axes, self.title):",
    "for ax, title in zip(self.axes,"
],
[
    "\"Using `title` of type `list` is not supported \"",
    "\"Using `title` of type `list` is not supported"
],
[
    "axis: Axis, rot=None, fontsize: int | None = None",
    "axis: Axis, rot=None, fontsize: int"
],
[
    "def _get_index_name(self) -> str | None:",
    "def _get_index_name(self) -> str"
],
[
    "name = \",\".join([pprint_thing(x) for x in name])",
    "name = \",\".join([pprint_thing(x) for x"
],
[
    "def _get_ax_layer(cls, ax, primary: bool = True):",
    "def _get_ax_layer(cls, ax, primary: bool"
],
[
    "def _get_ax(self, i: int) -> Axes:",
    "def _get_ax(self, i:"
],
[
    "def on_right(self, i: int) -> bool:",
    "def on_right(self, i: int) ->"
],
[
    "if isinstance(self.secondary_y, (tuple, list, np.ndarray, ABCIndex)):",
    "if isinstance(self.secondary_y, (tuple,"
],
[
    "self, colors, kwds: dict[str, Any], col_num: int, label: str",
    "self, colors, kwds: dict[str, Any], col_num:"
],
[
    "data: DataFrame, kind: str = \"hist\"",
    "data: DataFrame, kind: str ="
],
[
    ") -> dict[Hashable, DataFrame | Series]:",
    ") -> dict[Hashable, DataFrame |"
],
[
    "def maybe_resample(series: Series, ax: Axes, kwargs: dict[str, Any]):",
    "def maybe_resample(series: Series, ax: Axes, kwargs:"
],
[
    "\"'how' is not a valid keyword for plotting functions. If plotting \"",
    "\"'how' is not a valid keyword for plotting functions."
],
[
    "\"multiple objects on shared axes, resample manually first.\"",
    "\"multiple objects on shared axes, resample manually"
],
[
    "raise ValueError(\"Cannot use dynamic axis without frequency info\")",
    "raise ValueError(\"Cannot use dynamic"
],
[
    "if ax_freq is not None and freq != ax_freq:",
    "if ax_freq is not None"
],
[
    "elif is_subperiod(freq, ax_freq) or _is_sub(freq, ax_freq):",
    "elif is_subperiod(freq, ax_freq) or _is_sub(freq,"
],
[
    "def _upsample_others(ax: Axes, freq: BaseOffset, kwargs: dict[str, Any]) -> None:",
    "def _upsample_others(ax: Axes, freq: BaseOffset, kwargs: dict[str, Any]) ->"
],
[
    "title: str | None = legend.get_title().get_text()",
    "title: str | None"
],
[
    "for series, plotf, kwds in data:",
    "for series, plotf, kwds"
],
[
    "def decorate_axes(ax: Axes, freq: BaseOffset) -> None:",
    "def decorate_axes(ax: Axes, freq: BaseOffset)"
],
[
    "from pandas.core.internals.managers import BlockManager as _BlockManager",
    "from pandas.core.internals.managers import BlockManager as"
],
[
    "blocks: list[tuple[ArrayLike, np.ndarray]], index: Index, columns: Index",
    "blocks: list[tuple[ArrayLike, np.ndarray]], index: Index,"
],
[
    "\"A value is trying to be set on a copy of a DataFrame or Series \"",
    "\"A value is trying to be set on a copy of a DataFrame or Series"
],
[
    "\"When using the Copy-on-Write mode, such chained assignment never works \"",
    "\"When using the Copy-on-Write mode, such"
],
[
    "\"to update the original DataFrame or Series, because the intermediate \"",
    "\"to update the original DataFrame or Series, because"
],
[
    "\"object on which we are setting values always behaves as a copy.\\n\\n\"",
    "\"object on which we are setting values always"
],
[
    "\"Try using '.loc[row_indexer, col_indexer] = value' instead, to perform \"",
    "\"Try using '.loc[row_indexer, col_indexer] = value' instead, to"
],
[
    "\"the assignment in a single step.\\n\\n\"",
    "\"the assignment in"
],
[
    "\"See the caveats in the documentation: \"",
    "\"See the caveats in"
],
[
    "\"A value is trying to be set on a copy of a DataFrame or Series \"",
    "\"A value is trying to be set on a copy"
],
[
    "\"through chained assignment using an inplace method.\\n\"",
    "\"through chained assignment using an"
],
[
    "\"When using the Copy-on-Write mode, such inplace method never works \"",
    "\"When using the Copy-on-Write mode, such inplace method never works"
],
[
    "\"to update the original DataFrame or Series, because the intermediate \"",
    "\"to update the original DataFrame or Series, because the intermediate"
],
[
    "\"object on which we are setting values always behaves as a copy.\\n\\n\"",
    "\"object on which we are setting values always behaves as"
],
[
    "\"For example, when doing 'df[col].method(value, inplace=True)', try \"",
    "\"For example, when doing 'df[col].method(value,"
],
[
    "\"using 'df.method({col: value}, inplace=True)' instead, to perform \"",
    "\"using 'df.method({col: value}, inplace=True)' instead,"
],
[
    "\"the operation inplace on the original object.\\n\\n\"",
    "\"the operation inplace on the original"
],
[
    "def __init__(self, d: dict[str, Any], prefix: str = \"\") -> None:",
    "def __init__(self, d: dict[str, Any], prefix: str = \"\") ->"
],
[
    "def __setattr__(self, key: str, val: Any) -> None:",
    "def __setattr__(self, key: str, val: Any) ->"
],
[
    "if key in self.d and not isinstance(self.d[key], dict):",
    "if key in self.d and"
],
[
    "raise OptionError(\"You can only set the value of existing options\")",
    "raise OptionError(\"You can only set the value"
],
[
    "raise OptionError(\"No such option\") from err",
    "raise OptionError(\"No such option\")"
],
[
    "s += f\"\\n    [default: {o.defval}] [currently: {get_option(k)}]\"",
    "s += f\"\\n [default:"
],
[
    "s += f\", use `{rkey}` instead.\"",
    "s += f\", use"
]
]